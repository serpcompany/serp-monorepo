[
  {
    "owner": "pingcap",
    "repo": "docs",
    "content": "TITLE: INSERT Statement Examples in TiDB SQL\nDESCRIPTION: Sample SQL statements demonstrating different ways to use the INSERT statement in TiDB. Examples include inserting single values, specifying column names, inserting data from SELECT queries, and inserting multiple rows at once.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-insert.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (a INT);\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> CREATE TABLE t2 LIKE t1;\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> INSERT INTO t1 VALUES (1);\nQuery OK, 1 row affected (0.02 sec)\n\nmysql> INSERT INTO t1 (a) VALUES (1);\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> INSERT INTO t2 SELECT * FROM t1;\nQuery OK, 2 rows affected (0.01 sec)\nRecords: 2  Duplicates: 0  Warnings: 0\n\nmysql> SELECT * FROM t1;\n+------+\n| a    |\n+------+\n|    1 |\n|    1 |\n+------+\n2 rows in set (0.00 sec)\n\nmysql> SELECT * FROM t2;\n+------+\n| a    |\n+------+\n|    1 |\n|    1 |\n+------+\n2 rows in set (0.00 sec)\n\nmysql> INSERT INTO t2 VALUES (2),(3),(4);\nQuery OK, 3 rows affected (0.02 sec)\nRecords: 3  Duplicates: 0  Warnings: 0\n\nmysql> SELECT * FROM t2;\n+------+\n| a    |\n+------+\n|    1 |\n|    1 |\n|    2 |\n|    3 |\n|    4 |\n+------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating Test Tables for EXPLAIN Example\nDESCRIPTION: SQL statements to create sample tables t1 and t2 with an index for demonstrating EXPLAIN functionality in TiDB\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-overview.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1(a INT, b INT);\nCREATE TABLE t2(a INT, b INT, INDEX ia(a));\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with GORM in Golang\nDESCRIPTION: Creates a GORM database connection to TiDB using connection parameters. Configures TLS if required.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-golang-gorm.md#2025-04-18_snippet_0\n\nLANGUAGE: Go\nCODE:\n```\nfunc createDB() *gorm.DB {\n    dsn := fmt.Sprintf(\"%s:%s@tcp(%s:%s)/%s?charset=utf8mb4&tls=%s\",\n        ${tidb_user}, ${tidb_password}, ${tidb_host}, ${tidb_port}, ${tidb_db_name}, ${use_ssl})\n\n    db, err := gorm.Open(mysql.Open(dsn), &gorm.Config{\n        Logger: logger.Default.LogMode(logger.Info),\n    })\n    if err != nil {\n        panic(err)\n    }\n\n    return db\n}\n```\n\n----------------------------------------\n\nTITLE: Defining DROP COLUMN Syntax in EBNF\nDESCRIPTION: This EBNF snippet defines the syntax for the ALTER TABLE statement with DROP COLUMN specification in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-column.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAlterTableStmt\n         ::= 'ALTER' 'IGNORE'? 'TABLE' TableName DropColumnSpec ( ',' DropColumnSpec )*\n\nDropColumnSpec\n         ::= 'DROP' 'COLUMN'? 'IF EXISTS'? ColumnName ( 'RESTRICT' | 'CASCADE' )?\n\nColumnName\n         ::= Identifier ( '.' Identifier ( '.' Identifier )? )?\n```\n\n----------------------------------------\n\nTITLE: Updating Data in TiDB using MySQL Connector/Python\nDESCRIPTION: This code snippet demonstrates how to update data in a TiDB database using MySQL Connector/Python. It establishes a connection, creates a cursor, and executes an UPDATE statement with parameterized values.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-mysql-connector.md#2025-04-18_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nwith get_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        player_id, amount, price=\"1\", 10, 500\n        cursor.execute(\n            \"UPDATE players SET goods = goods + %s, coins = coins + %s WHERE id = %s\",\n            (-amount, price, player_id),\n        )\n```\n\n----------------------------------------\n\nTITLE: Using GROUP BY and WITH ROLLUP for detailed profit analysis in SQL\nDESCRIPTION: This SQL query demonstrates the usage of the GROUP BY clause with the WITH ROLLUP modifier to aggregate and summarize profit data in a single query. It provides results grouped by both year and month, as well as an overall sum.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/group-by-modifier.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT year, month, SUM(profit) AS profit from bank GROUP BY year, month WITH ROLLUP ORDER BY year desc, month desc;\n```\n\n----------------------------------------\n\nTITLE: Basic UPDATE Statement Example in TiDB\nDESCRIPTION: A complete example demonstrating how to create a table, insert data, and then update specific rows using the UPDATE statement with a WHERE clause. The example shows how to update a single column for rows that match a specific condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-update.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> INSERT INTO t1 (c1) VALUES (1), (2), (3);\nQuery OK, 3 rows affected (0.02 sec)\nRecords: 3  Duplicates: 0  Warnings: 0\n\nmysql> SELECT * FROM t1;\n+----+----+\n| id | c1 |\n+----+----+\n|  1 |  1 |\n|  2 |  2 |\n|  3 |  3 |\n+----+----+\n3 rows in set (0.00 sec)\n\nmysql> UPDATE t1 SET c1=5 WHERE c1=3;\nQuery OK, 1 row affected (0.01 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n\nmysql> SELECT * FROM t1;\n+----+----+\n| id | c1 |\n+----+----+\n|  1 |  1 |\n|  2 |  2 |\n|  3 |  5 |\n+----+----+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Inserting Test Data for EXPLAIN ANALYZE Example\nDESCRIPTION: SQL statement to insert three rows of test data into the t1 table for demonstration of the EXPLAIN ANALYZE command.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t1 (c1) VALUES (1), (2), (3);\n```\n\n----------------------------------------\n\nTITLE: Inserting Partial Records in TiDB with SQL\nDESCRIPTION: This SQL statement inserts a record with data for only specific fields (id and name) into the 'person' table. It shows how to add a new record without providing values for all columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-tidb-crud-sql.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO person(id,name) VALUES('2','bob');\n```\n\n----------------------------------------\n\nTITLE: Implementing Pessimistic Transaction Purchase Logic in Python\nDESCRIPTION: Implements book purchase transaction using pessimistic locking to prevent concurrent access conflicts. Includes inventory management, order creation, and user balance updates.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef buy_pessimistic(thread_id: int, order_id: int, book_id: int, user_id: int, amount: int) -> None:\n    connection = create_connection()\n\n    txn_log_header = f\"/* txn {thread_id} */\"\n    if thread_id != 1:\n        txn_log_header = \"\\t\" + txn_log_header\n\n    with connection:\n        with connection.cursor() as cursor:\n            cursor.execute(\"BEGIN PESSIMISTIC\")\n            print(f'{txn_log_header} BEGIN PESSIMISTIC')\n            time.sleep(1)\n\n            try:\n                # read the price of book\n                select_book_for_update = \"SELECT `price` FROM books WHERE id = %s FOR UPDATE\"\n                cursor.execute(select_book_for_update, (book_id,))\n                book = cursor.fetchone()\n                if book is None:\n                    raise Exception(\"book_id not exist\")\n                price = book[0]\n                print(f'{txn_log_header} {select_book_for_update} successful')\n```\n\n----------------------------------------\n\nTITLE: Displaying Execution Plan with Estimated and Actual Rows - SQL\nDESCRIPTION: This snippet represents the execution plan showing estimated rows, actual rows, and associated resources used during query execution. It highlights potential bottlenecks in execution based on discrepancies between estimated and actual metrics.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------...----------------------+\\n| id                                 | estRows   | estCost      | actRows   | task      | access object                                                                          | execution info ...| memory   | disk     |\\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------...----------------------+\\n| TopN_19                            | 1.01      | 461374372.63 | 0         | root      |                                                                                        | time:5m51.1s, l...| 0 Bytes  | 0 Bytes  |\\n| └─IndexJoin_32                     | 1.01      | 460915067.45 | 0         | root      |                                                                                        | time:5m51.1s, l...| 0 Bytes  | N/A      |\\n|   ├─HashJoin_69(Build)             | 1.01      | 460913065.41 | 0         | root      |                                                                                        | time:5m51.1s, l...| 21.6 GB  | 7.65 GB  |\\n|   │ ├─IndexReader_76(Build)        | 1.00      | 18.80        | 256805045 | root      |                                                                                        | time:1m4.1s, lo...| 12.4 MB  | N/A      |\\n|   │ │ └─IndexRangeScan_75          | 1.00      | 186.74       | 256811189 | cop[tikv] | table:orders, index:index_orders_on_adjustment_id(adjustment_id)                       | tikv_task:{proc...| N/A      | N/A      |\\n|   │ └─Projection_74(Probe)         | 30652.93  | 460299612.60 | 1024      | root      |                                                                                        | time:1.08s, loo...| 413.4 KB | N/A      |\\n|   │   └─IndexLookUp_73             | 30652.93  | 460287375.95 | 6144      | root      | partition:all                                                                          | time:1.08s, loo...| 107.8 MB | N/A      |\\n|   │     ├─IndexRangeScan_70(Build) | 234759.64 | 53362737.50  | 390699    | cop[tikv] | table:rates, index:index_rates_on_label_id(label_id)                                   | time:29.6ms, lo...| N/A      | N/A      |\\n|   │     └─Selection_72(Probe)      | 30652.93  | 110373973.91 | 187070    | cop[tikv] |                                                                                        | time:36.8s, loo...| N/A      | N/A      |\\n|   │       └─TableRowIDScan_71      | 234759.64 | 86944962.10  | 390699    | cop[tikv] | table:rates                                                                            | tikv_task:{proc...| N/A      | N/A      |\\n|   └─TableReader_28(Probe)          | 0.00      | 43.64        | 0         | root      |                                                                                        |                ...| N/A      | N/A      |\\n|     └─Selection_27                 | 0.00      | 653.96       | 0         | cop[tikv] |                                                                                        |                ...| N/A      | N/A      |\\n|       └─TableRangeScan_26          | 1.01      | 454.36       | 0         | cop[tikv] | table:labels                                                                           |                ...| N/A      | N/A      |\\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------...----------------------+\n```\n\n----------------------------------------\n\nTITLE: Importing Sample Data via TiUP Demo in TiDB\nDESCRIPTION: Uses the 'tiup demo' command to prepare sample data for the 'bookshop' schema in TiDB. This creates 1,000,000 book records.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup demo bookshop prepare --host 127.0.0.1 --port 4000 --books 1000000\n```\n\n----------------------------------------\n\nTITLE: Verifying Transaction Results with SQL Queries\nDESCRIPTION: SQL queries to verify the final state after transactions: 6 books remain in stock, Alice's order for 4 books was successful, Bob's order failed, and Alice's balance was reduced by the appropriate amount.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT * FROM books;\n+----+--------------------------------------+----------------------+---------------------+-------+--------+\n| id | title                                | type                 | published_at        | stock | price  |\n+----+--------------------------------------+----------------------+---------------------+-------+--------+\n|  1 | Designing Data-Intensive Application | Science & Technology | 2018-09-01 00:00:00 |     6 | 100.00 |\n+----+--------------------------------------+----------------------+---------------------+-------+--------+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM orders;\n+------+---------+---------+---------+---------------------+\n| id   | book_id | user_id | quality | ordered_at          |\n+------+---------+---------+---------+---------------------+\n| 1001 |       1 |       1 |       4 | 2022-04-19 11:03:03 |\n+------+---------+---------+---------+---------------------+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM users;\n+----+----------+----------+\n| id | balance  | nickname |\n+----+----------+----------+\n|  1 | 10000.00 | Bob      |\n|  2 |  9600.00 | Alice    |\n+----+----------+----------+\n2 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Calculating Column Values Using SetClause During Import\nDESCRIPTION: This SQL statement imports a CSV file into a TiDB table and calculates column values during the import process using `SET val=@1*100`. It multiplies the value of the third column (`val`) by 100 before inserting it into the table. `@1` refers to the third column, and the result is stored in the `val` column.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t(id, name, @1) SET val=@1*100 FROM '/path/to/file.csv' WITH skip_rows=1;\n```\n\n----------------------------------------\n\nTITLE: Implementing Semantic Search Query in Python\nDESCRIPTION: Function that performs semantic search by converting query text to embeddings and finding the closest matches in a vector store. It prints results showing the matched documents and their vector distances, demonstrating how conceptually related terms are found.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-python.md#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef print_result(query, result):\n   print(f\"Search result (\\\"{query}\\\"):\\\")\n   for r in result:\n      print(f\"- text: \\\"{r.document}\\\", distance: {r.distance}\")\n\nquery = \"a swimming animal\"\nquery_embedding = text_to_embedding(query)\nsearch_result = vector_store.query(query_embedding, k=3)\nprint_result(query, search_result)\n```\n\n----------------------------------------\n\nTITLE: Verifying Replicated Data in TiDB\nDESCRIPTION: This SQL snippet demonstrates how to verify the integrity of replicated data by querying the `hello_tidb` table in the TiDB database after migration. Confirming the presence and correctness of this data is crucial for successful replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM hello.hello_tidb;\n```\n\n----------------------------------------\n\nTITLE: Creating Covering Index and Analyzing Table\nDESCRIPTION: SQL commands to create a covering index that includes all necessary columns and analyze the table to update statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX logs_covered ON logs(snapshot_id, user_id, status, source_type, target_type, amount); \nANALYZE TABLE logs INDEX logs_covered;\n```\n\n----------------------------------------\n\nTITLE: Querying Data from TiDB with mysql2\nDESCRIPTION: JavaScript code snippet to query a single 'Player' record from TiDB by ID using mysql2.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nextjs.md#2025-04-18_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nconst [rows] = await pool.query('SELECT id, coins, goods FROM players WHERE id = ?;', [1]);\nconsole.log(rows[0]);\n```\n\n----------------------------------------\n\nTITLE: Implementing Optimistic Transaction Purchase Logic in Python\nDESCRIPTION: Handles book purchase transaction with optimistic concurrency control, including inventory check, order creation, and balance updates. Includes retry logic for handling concurrency conflicts.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nbook = cursor.fetchone()\nif book is None:\n    raise Exception(\"book_id not exist\")\nprice, stock = book\nprint(f'{txn_log_header} {select_book_for_update} successful')\n\nif stock < amount:\n    raise Exception(\"book not enough, rollback\")\n\n# update book\nupdate_stock = \"update `books` set stock = stock - %s where id = %s and stock - %s >= 0\"\nrows_affected = cursor.execute(update_stock, (amount, book_id, amount))\nprint(f'{txn_log_header} {update_stock} successful')\n\nif rows_affected == 0:\n    raise Exception(\"stock not enough, rollback\")\n\n# insert order\ninsert_order = \"insert into `orders` (`id`, `book_id`, `user_id`, `quality`) values (%s, %s, %s, %s)\"\ncursor.execute(insert_order, (order_id, book_id, user_id, amount))\nprint(f'{txn_log_header} {insert_order} successful')\n\n# update user\nupdate_user = \"update `users` set `balance` = `balance` - %s where id = %s\"\ncursor.execute(update_user, (amount * price, user_id))\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with node-mysql2 in JavaScript\nDESCRIPTION: Establishes a connection to TiDB using environment variables for configuration. Includes SSL support and error handling.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysql2.md#2025-04-18_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n// Step 1. Import the 'mysql' and 'dotenv' packages.\nimport { createConnection } from \"mysql2/promise\";\nimport dotenv from \"dotenv\";\nimport * as fs from \"fs\";\n\n// Step 2. Load environment variables from .env file to process.env.\ndotenv.config();\n\nasync function main() {\n   // Step 3. Create a connection to the TiDB cluster.\n   const options = {\n      host: process.env.TIDB_HOST || '127.0.0.1',\n      port: process.env.TIDB_PORT || 4000,\n      user: process.env.TIDB_USER || 'root',\n      password: process.env.TIDB_PASSWORD || '',\n      database: process.env.TIDB_DATABASE || 'test',\n      ssl: process.env.TIDB_ENABLE_SSL === 'true' ? {\n         minVersion: 'TLSv1.2',\n         ca: process.env.TIDB_CA_PATH ? fs.readFileSync(process.env.TIDB_CA_PATH) : undefined\n      } : null,\n   }\n   const conn = await createConnection(options);\n\n   // Step 4. Perform some SQL operations...\n\n   // Step 5. Close the connection.\n   await conn.end();\n}\n\nvoid main();\n```\n\n----------------------------------------\n\nTITLE: Advanced Execution Plan Analysis with EXPLAIN ANALYZE\nDESCRIPTION: Demonstrates using EXPLAIN ANALYZE to get detailed runtime execution information for a complex query involving joins and aggregations. Shows actual row counts, execution time, memory usage, and disk utilization.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE\nSELECT SUM(pm.m_count) / COUNT(*) \nFROM (\n    SELECT COUNT(m.name) m_count\n    FROM universe.moons m\n    RIGHT JOIN (\n        SELECT p.id, p.name\n        FROM universe.planet_categories c\n        JOIN universe.planets p\n            ON c.id = p.category_id \n            AND c.name = 'Jovian'\n    ) pc ON m.planet_id = pc.id\n    GROUP BY pc.name\n) pm;\n```\n\n----------------------------------------\n\nTITLE: Creating Roles in TiDB\nDESCRIPTION: This snippet demonstrates how to create roles in TiDB using the `CREATE ROLE` statement. Multiple roles can be created in a single statement.  To execute this statement, the user must have either the `CREATE ROLE` or `CREATE USER` privilege.  Roles are stored in the `mysql.user` table.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE ROLE 'app_developer', 'app_read', 'app_write';\n```\n\n----------------------------------------\n\nTITLE: Implementing Bulk Delete in Java for TiDB\nDESCRIPTION: This Java code demonstrates how to perform a bulk delete operation on the 'ratings' table in TiDB. It deletes records within a specific time range in batches of 1000 rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-delete-data.md#2025-04-18_snippet_5\n\nLANGUAGE: java\nCODE:\n```\npackage com.pingcap.bulkDelete;\n\nimport com.mysql.cj.jdbc.MysqlDataSource;\n\nimport java.sql.*;\nimport java.util.*;\nimport java.util.concurrent.TimeUnit;\n\npublic class BatchDeleteExample\n{\n    public static void main(String[] args) throws InterruptedException {\n        // Configure the example database connection.\n\n        // Create a mysql data source instance.\n        MysqlDataSource mysqlDataSource = new MysqlDataSource();\n\n        // Set server name, port, database name, username and password.\n        mysqlDataSource.setServerName(\"localhost\");\n        mysqlDataSource.setPortNumber(4000);\n        mysqlDataSource.setDatabaseName(\"bookshop\");\n        mysqlDataSource.setUser(\"root\");\n        mysqlDataSource.setPassword(\"\");\n\n        while (true) {\n            batchDelete(mysqlDataSource);\n            TimeUnit.SECONDS.sleep(1);\n        }\n    }\n\n    public static void batchDelete (MysqlDataSource ds) {\n        try (Connection connection = ds.getConnection()) {\n            String sql = \"DELETE FROM `bookshop`.`ratings` WHERE `rated_at` >= ? AND `rated_at` <= ? LIMIT 1000\";\n            PreparedStatement preparedStatement = connection.prepareStatement(sql);\n            Calendar calendar = Calendar.getInstance();\n            calendar.set(Calendar.MILLISECOND, 0);\n\n            calendar.set(2022, Calendar.APRIL, 15, 0, 0, 0);\n            preparedStatement.setTimestamp(1, new Timestamp(calendar.getTimeInMillis()));\n\n            calendar.set(2022, Calendar.APRIL, 15, 0, 15, 0);\n            preparedStatement.setTimestamp(2, new Timestamp(calendar.getTimeInMillis()));\n\n            int count = preparedStatement.executeUpdate();\n            System.out.println(\"delete \" + count + \" data\");\n        } catch (SQLException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Pessimistic Transactions in Java with JDBC\nDESCRIPTION: This Java code demonstrates how to implement pessimistic transactions using JDBC for a bookshop application. It includes methods for creating users and books, and a buy method that handles the transaction logic for purchasing books.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_2\n\nLANGUAGE: java\nCODE:\n```\npackage com.pingcap.txn;\n\nimport com.zaxxer.hikari.HikariDataSource;\n\nimport java.math.BigDecimal;\nimport java.sql.*;\nimport java.util.Arrays;\nimport java.util.concurrent.*;\n\npublic class TxnExample {\n    public static void main(String[] args) throws SQLException, InterruptedException {\n        System.out.println(Arrays.toString(args));\n        int aliceQuantity = 0;\n        int bobQuantity = 0;\n\n        for (String arg: args) {\n            if (arg.startsWith(\"ALICE_NUM\")) {\n                aliceQuantity = Integer.parseInt(arg.replace(\"ALICE_NUM=\", \"\"));\n            }\n\n            if (arg.startsWith(\"BOB_NUM\")) {\n                bobQuantity = Integer.parseInt(arg.replace(\"BOB_NUM=\", \"\"));\n            }\n        }\n\n        HikariDataSource ds = new HikariDataSource();\n        ds.setJdbcUrl(\"jdbc:mysql://localhost:4000/bookshop?useServerPrepStmts=true&cachePrepStmts=true\");\n        ds.setUsername(\"root\");\n        ds.setPassword(\"\");\n\n        // prepare data\n        Connection connection = ds.getConnection();\n        createBook(connection, 1L, \"Designing Data-Intensive Application\", \"Science & Technology\",\n                Timestamp.valueOf(\"2018-09-01 00:00:00\"), new BigDecimal(100), 10);\n        createUser(connection, 1L, \"Bob\", new BigDecimal(10000));\n        createUser(connection, 2L, \"Alice\", new BigDecimal(10000));\n\n        CountDownLatch countDownLatch = new CountDownLatch(2);\n        ExecutorService threadPool = Executors.newFixedThreadPool(2);\n\n        final int finalBobQuantity = bobQuantity;\n        threadPool.execute(() -> {\n            buy(ds, 1, 1000L, 1L, 1L, finalBobQuantity);\n            countDownLatch.countDown();\n        });\n        final int finalAliceQuantity = aliceQuantity;\n        threadPool.execute(() -> {\n            buy(ds, 2, 1001L, 1L, 2L, finalAliceQuantity);\n            countDownLatch.countDown();\n        });\n\n        countDownLatch.await(5, TimeUnit.SECONDS);\n    }\n\n    public static void createUser(Connection connection, Long id, String nickname, BigDecimal balance) throws SQLException  {\n        PreparedStatement insert = connection.prepareStatement(\n                \"INSERT INTO `users` (`id`, `nickname`, `balance`) VALUES (?, ?, ?)\");\n        insert.setLong(1, id);\n        insert.setString(2, nickname);\n        insert.setBigDecimal(3, balance);\n        insert.executeUpdate();\n    }\n\n    public static void createBook(Connection connection, Long id, String title, String type, Timestamp publishedAt, BigDecimal price, Integer stock) throws SQLException {\n        PreparedStatement insert = connection.prepareStatement(\n                \"INSERT INTO `books` (`id`, `title`, `type`, `published_at`, `price`, `stock`) values (?, ?, ?, ?, ?, ?)\");\n        insert.setLong(1, id);\n        insert.setString(2, title);\n        insert.setString(3, type);\n        insert.setTimestamp(4, publishedAt);\n        insert.setBigDecimal(5, price);\n        insert.setInt(6, stock);\n\n        insert.executeUpdate();\n    }\n\n    public static void buy (HikariDataSource ds, Integer threadID,\n                            Long orderID, Long bookID, Long userID, Integer quantity) {\n        String txnComment = \"/* txn \" + threadID + \" */ \";\n\n        try (Connection connection = ds.getConnection()) {\n            try {\n                connection.setAutoCommit(false);\n                connection.createStatement().executeUpdate(txnComment + \"begin pessimistic\");\n\n                // waiting for other thread ran the 'begin pessimistic' statement\n                TimeUnit.SECONDS.sleep(1);\n\n                BigDecimal price = null;\n\n                // read price of book\n                PreparedStatement selectBook = connection.prepareStatement(txnComment + \"select price from books where id = ? for update\");\n                selectBook.setLong(1, bookID);\n                ResultSet res = selectBook.executeQuery();\n                if (!res.next()) {\n                    throw new RuntimeException(\"book not exist\");\n                } else {\n                    price = res.getBigDecimal(\"price\");\n                }\n\n                // update book\n                String updateBookSQL = \"update `books` set stock = stock - ? where id = ? and stock - ? >= 0\";\n                PreparedStatement updateBook = connection.prepareStatement(txnComment + updateBookSQL);\n                updateBook.setInt(1, quantity);\n                updateBook.setLong(2, bookID);\n                updateBook.setInt(3, quantity);\n                int affectedRows = updateBook.executeUpdate();\n\n                if (affectedRows == 0) {\n                    // stock not enough, rollback\n                    connection.createStatement().executeUpdate(txnComment + \"rollback\");\n                    return;\n                }\n\n                // insert order\n                String insertOrderSQL = \"insert into `orders` (`id`, `book_id`, `user_id`, `quality`) values (?, ?, ?, ?)\";\n                PreparedStatement insertOrder = connection.prepareStatement(txnComment + insertOrderSQL);\n                insertOrder.setLong(1, orderID);\n                insertOrder.setLong(2, bookID);\n                insertOrder.setLong(3, userID);\n                insertOrder.setInt(4, quantity);\n                insertOrder.executeUpdate();\n\n                // update user\n                String updateUserSQL = \"update `users` set `balance` = `balance` - ? where id = ?\";\n                PreparedStatement updateUser = connection.prepareStatement(txnComment + updateUserSQL);\n                updateUser.setBigDecimal(1, price.multiply(new BigDecimal(quantity)));\n                updateUser.setLong(2, userID);\n                updateUser.executeUpdate();\n\n                connection.createStatement().executeUpdate(txnComment + \"commit\");\n            } catch (Exception e) {\n                connection.createStatement().executeUpdate(txnComment + \"rollback\");\n                e.printStackTrace();\n            }\n        } catch (SQLException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Java Implementation of Author Book Count Query\nDESCRIPTION: Java method that executes an inner join query to retrieve top 10 authors by book count. Uses JDBC to connect to database and maps results to Author objects.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-join-tables.md#2025-04-18_snippet_1\n\nLANGUAGE: java\nCODE:\n```\npublic List<Author> getTop10AuthorsOrderByBooks() throws SQLException {\n    List<Author> authors = new ArrayList<>();\n    try (Connection conn = ds.getConnection()) {\n        Statement stmt = conn.createStatement();\n        ResultSet rs = stmt.executeQuery(\"\"\"\n        SELECT ANY_VALUE(a.id) AS author_id, ANY_VALUE(a.name) AS author_name, COUNT(ba.book_id) AS books\n        FROM authors a\n        JOIN book_authors ba ON a.id = ba.author_id\n        GROUP BY ba.author_id\n        ORDER BY books DESC\n        LIMIT 10;\n        \"\"\");\n        while (rs.next()) {\n            Author author = new Author();\n            author.setId(rs.getLong(\"author_id\"));\n            author.setName(rs.getString(\"author_name\"));\n            author.setBooks(rs.getInt(\"books\"));\n            authors.add(author);\n        }\n    }\n    return authors;\n}\n```\n\n----------------------------------------\n\nTITLE: Creating global bindings for SELECT statements\nDESCRIPTION: This example shows how to create a global binding for a `SELECT` statement. The binding uses the `use_index` hint to force the optimizer to use the `orders_book_id_idx` index on the `orders` table. This ensures consistent query performance regardless of optimizer choices.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE GLOBAL BINDING USING SELECT /*+ use_index(orders, orders_book_id_idx) */ * FROM orders;\nCREATE GLOBAL BINDING FOR SELECT * FROM orders USING SELECT /*+ use_index(orders, orders_book_id_idx) */ * FROM orders;\n```\n\n----------------------------------------\n\nTITLE: Defining ALTER TABLE ADD INDEX Syntax in EBNF\nDESCRIPTION: This snippet provides the EBNF syntax for the ALTER TABLE ADD INDEX statement. It outlines how indexes can be added to a table in TiDB, including options like index types and visibility options. It requires understanding of EBNF notation and TiDB syntax options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-add-index.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAlterTableStmt\n         ::= 'ALTER' 'IGNORE'? 'TABLE' TableName AddIndexSpec ( ',' AddIndexSpec )*\n\nAddIndexSpec\n         ::= 'ADD' ( ( 'PRIMARY' 'KEY' | ( 'KEY' | 'INDEX' ) 'IF NOT EXISTS'? | 'UNIQUE' ( 'KEY' | 'INDEX' )? ) ( ( Identifier? 'USING' | Identifier 'TYPE' ) IndexType )? | 'FULLTEXT' ( 'KEY' | 'INDEX' )? IndexName ) '(' IndexPartSpecification ( ',' IndexPartSpecification )* ')' IndexOption*\n\nIndexPartSpecification\n         ::= ( ColumnName ( '(' LengthNum ')' )? | '(' Expression ')' ) ( 'ASC' | 'DESC' )\n\nIndexOption\n         ::= 'KEY_BLOCK_SIZE' '='? LengthNum\n           | IndexType\n           | 'WITH' 'PARSER' Identifier\n           | 'COMMENT' stringLit\n           | 'VISIBLE'\n           | 'INVISIBLE'\n           | 'GLOBAL'\n           | 'LOCAL'\n\nIndexType\n         ::= 'BTREE'\n           | 'HASH'\n           | 'RTREE'\n```\n\n----------------------------------------\n\nTITLE: Analyzing HashJoin Operator Execution Information\nDESCRIPTION: Detailed metrics for HashJoin performance, including hash table building, probing, and spill operations with concurrency and time measurements\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n\"build_hash_table\":{\"concurrency\":5, \"time\":\"2.25s\", \"fetch\":\"1.06s\", \"max_partition\":\"1.06s\", \"total_partition\":\"5.27s\", \"max_build\":\"124ms\", \"total_build\":\"439.5ms\"}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Top Slow Queries Example - SQL in TiDB\nDESCRIPTION: This SQL command retrieves the top 3 slowest queries and can be customized to include internal queries or all queries. It's essential for detailed performance evaluations.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW SLOW top 3\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW SLOW top internal 3\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW SLOW top all 5\n```\n\n----------------------------------------\n\nTITLE: Pessimistic Transaction SQL Flow for Preventing Overselling\nDESCRIPTION: SQL transaction flow showing how pessimistic locking prevents overselling. Transaction 2 (Alice) successfully buys 4 books, while Transaction 1 (Bob) tries to buy 7 books but fails and rolls back as there are only 6 books left after Alice's purchase.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\n/* txn 1 */ BEGIN PESSIMISTIC\n    /* txn 2 */ BEGIN PESSIMISTIC\n    /* txn 2 */ SELECT * FROM `books` WHERE `id` = 1 FOR UPDATE\n    /* txn 2 */ UPDATE `books` SET `stock` = `stock` - 4 WHERE `id` = 1 AND `stock` - 4 >= 0\n    /* txn 2 */ INSERT INTO `orders` (`id`, `book_id`, `user_id`, `quality`) values (1001, 1, 1, 4)\n    /* txn 2 */ UPDATE `users` SET `balance` = `balance` - 400.0 WHERE `id` = 2\n    /* txn 2 */ COMMIT\n/* txn 1 */ SELECT * FROM `books` WHERE `id` = 1 FOR UPDATE\n/* txn 1 */ UPDATE `books` SET `stock` = `stock` - 7 WHERE `id` = 1 AND `stock` - 7 >= 0\n/* txn 1 */ ROLLBACK\n```\n\n----------------------------------------\n\nTITLE: Creating Books Table Schema in TiDB\nDESCRIPTION: SQL statement to create a books table with various columns including an auto-random ID, title, type (enum), published date, stock, and price. The table uses UTF8MB4 character set and includes a clustered primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-index-best-practice.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `books` (\n  `id` bigint AUTO_RANDOM NOT NULL,\n  `title` varchar(100) NOT NULL,\n  `type` enum('Magazine', 'Novel', 'Life', 'Arts', 'Comics', 'Education & Reference', 'Humanities & Social Sciences', 'Science & Technology', 'Kids', 'Sports') NOT NULL,\n  `published_at` datetime NOT NULL,\n  `stock` int DEFAULT '0',\n  `price` decimal(15,2) DEFAULT '0.0',\n  PRIMARY KEY (`id`) CLUSTERED\n) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\n```\n\n----------------------------------------\n\nTITLE: SQL Execution for Optimistic Transactions\nDESCRIPTION: This SQL snippet demonstrates the process of executing optimistic transactions. It includes multiple steps such as selecting books, updating stock, and inserting orders, along with handling write conflicts.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\n/* txn 2 */ BEGIN OPTIMISTIC\n/* txn 1 */ BEGIN OPTIMISTIC\n    /* txn 2 */ SELECT * FROM `books` WHERE `id` = 1 FOR UPDATE\n    /* txn 2 */ UPDATE `books` SET `stock` = `stock` - 4 WHERE `id` = 1 AND `stock` - 4 >= 0\n    /* txn 2 */ INSERT INTO `orders` (`id`, `book_id`, `user_id`, `quality`) VALUES (1001, 1, 1, 4)\n    /* txn 2 */ UPDATE `users` SET `balance` = `balance` - 400.0 WHERE `id` = 2\n    /* txn 2 */ COMMIT\n/* txn 1 */ SELECT * FROM `books` WHERE `id` = 1 for UPDATE\n/* txn 1 */ UPDATE `books` SET `stock` = `stock` - 6 WHERE `id` = 1 AND `stock` - 6 >= 0\n/* txn 1 */ INSERT INTO `orders` (`id`, `book_id`, `user_id`, `quality`) VALUES (1000, 1, 1, 6)\n/* txn 1 */ UPDATE `users` SET `balance` = `balance` - 600.0 WHERE `id` = 1\nretry 1 times for 9007 Write conflict, txnStartTS=432618733006225412, conflictStartTS=432618733006225411, conflictCommitTS=432618733006225414, key={tableID=126, handle=1} primary={tableID=114, indexID=1, indexValues={1, 1000, }} [try again later]\n/* txn 1 */ BEGIN OPTIMISTIC\n/* txn 1 */ SELECT * FROM `books` WHERE `id` = 1 FOR UPDATE\n/* txn 1 */ UPDATE `books` SET `stock` = `stock` - 6 WHERE `id` = 1 AND `stock` - 6 >= 0\n/* txn 1 */ INSERT INTO `orders` (`id`, `book_id`, `user_id`, `quality`) VALUES (1000, 1, 1, 6)\n/* txn 1 */ UPDATE `users` SET `balance` = `balance` - 600.0 WHERE `id` = 1\n/* txn 1 */ COMMIT\n```\n\n----------------------------------------\n\nTITLE: Setting TiUP Environment Variables - Shell\nDESCRIPTION: This snippet illustrates how to set up the environment variables needed for TiUP after installation. It also includes a command to check if TiUP was installed correctly.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsource .bash_profile\n```\n\nLANGUAGE: shell\nCODE:\n```\nwhich tiup\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning Global Settings\nDESCRIPTION: Defines global configuration parameters for TiDB Lightning, including status address, server mode, logging settings, and diagnostic log options\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\nstatus-addr = \":8289\"\nserver-mode = false\nlevel = \"info\"\nfile = \"tidb-lightning.log\"\nmax-size = 128\nmax-days = 28\nmax-backups = 14\nenable-diagnose-logs = false\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB System Variables for Performance Optimization\nDESCRIPTION: SQL commands to configure TiDB system variables for optimal performance. Includes settings for plan cache, statistics collection, optimizer behavior, and experimental features. These settings balance performance improvements with potential trade-offs.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_instance_plan_cache=on;\nSET GLOBAL tidb_instance_plan_cache_max_size=2GiB;\nSET GLOBAL tidb_enable_non_prepared_plan_cache=on;\nSET GLOBAL tidb_ignore_prepared_cache_close_stmt=on;\nSET GLOBAL tidb_analyze_column_options='ALL';\nSET GLOBAL tidb_stats_load_sync_wait=2000;\nSET GLOBAL tidb_opt_derive_topn=on;\nSET GLOBAL tidb_runtime_filter_mode=LOCAL;\nSET GLOBAL tidb_opt_enable_mpp_shared_cte_execution=on;\nSET GLOBAL tidb_rc_read_check_ts=on;\nSET GLOBAL tidb_guarantee_linearizability=off;\nSET GLOBAL pd_enable_follower_handle_region=on;\nSET GLOBAL tidb_opt_fix_control = '44262:ON,44389:ON,44823:10000,44830:ON,44855:ON,52869:ON';\n```\n\n----------------------------------------\n\nTITLE: Creating JSON Arrays with JSON_ARRAY()\nDESCRIPTION: Generates JSON arrays from a list of values, supporting mixed data types and multiple elements. Can create empty or populated arrays with integers, strings, or other data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-create.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_ARRAY(1,2,3,4,5), JSON_ARRAY(\"foo\", \"bar\");\n```\n\n----------------------------------------\n\nTITLE: Querying Data from TiDB with Spring Data JPA\nDESCRIPTION: This Java code shows how to retrieve a player entity by ID from TiDB using the findById method provided by JpaRepository.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-spring-boot.md#2025-04-18_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nPlayerBean player = playerRepository.findById(id).orElse(null);\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Updates with Primary Key Scanning in SQL and Java\nDESCRIPTION: This code demonstrates a safe, iterative approach to update database records. It selects batches of up to 1000 unprocessed rows ordered by primary key, multiplies their score values by 2, marks them as processed, and includes a sleep interval to manage resource usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-update-data.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ... WHERE ten_point = false ORDER BY primary_key LIMIT 1000\n```\n\nLANGUAGE: java\nCODE:\n```\nTimeUnit.SECONDS.sleep(1);\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Statement Rollback in TiDB\nDESCRIPTION: Example showing atomic rollback after statement execution failure in TiDB. Failed statements do not take effect, and the transaction remains open for additional changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/transaction-overview.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test (id INT NOT NULL PRIMARY KEY);\nBEGIN;\nINSERT INTO test VALUES (1);\nINSERT INTO tset VALUES (2);  -- Statement does not take effect because \"test\" is misspelled as \"tset\".\nINSERT INTO test VALUES (1),(2);  -- Entire statement does not take effect because it violates a PRIMARY KEY constraint\nINSERT INTO test VALUES (3);\nCOMMIT;\nSELECT * FROM test;\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into TiDB with PyMySQL in Python\nDESCRIPTION: This code snippet demonstrates how to insert data into a TiDB database using PyMySQL. It establishes a connection, creates a cursor, and executes an INSERT SQL statement with parameterized values.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-pymysql.md#2025-04-18_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nwith get_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        player = (\"1\", 1, 1)\n        cursor.execute(\"INSERT INTO players (id, coins, goods) VALUES (%s, %s, %s)\", player)\n```\n\n----------------------------------------\n\nTITLE: Configuring HikariCP Connection Pool Settings for TiDB\nDESCRIPTION: HikariCP connection pool configuration example showing essential parameters for pool size, timeout settings, and connection lifecycle management.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nhikari:\n  maximumPoolSize: 20\n  poolName: hikariCP\n  connectionTimeout: 30000 \n  maxLifetime: 1200000\n  keepaliveTime: 120000\n```\n\n----------------------------------------\n\nTITLE: Retrieving Last Insert ID (SQL)\nDESCRIPTION: The `LAST_INSERT_ID()` function returns the ID of the last row inserted, useful for tracking new entries in tables with `AUTO_INCREMENT` columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/information-functions.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1(id SERIAL);\nQuery OK, 0 rows affected (0.17 sec)\n\nINSERT INTO t1() VALUES();\nQuery OK, 1 row affected (0.03 sec)\n\nINSERT INTO t1() VALUES();\nQuery OK, 1 row affected (0.00 sec)\n\nSELECT LAST_INSERT_ID();\n```\n+------------------+\n| LAST_INSERT_ID() |\n+------------------+\n|                3 |\n+------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Example Output from TiKV Query using EXPLAIN ANALYZE\nDESCRIPTION: This SQL snippet shows an example of the output from the `EXPLAIN ANALYZE` statement when querying with TiKV. The output is a table showing execution information for each stage of the query plan, including execution time, number of rows, and resource unit consumption.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-htap-quickstart.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n    \"id                         | estRows  | actRows | task      | access object | execution info                             | operator info                                 | memory  | disk    \\n    ---------------------------+----------+---------+-----------+---------------+--------------------------------------------+-----------------------------------------------+---------+---------\\n    Sort_5                     | 4019.00  | 28      | root      |               | time:672.7ms, loops:2, RU:1159.679690      | Column#36:desc                                | 18.0 KB | 0 Bytes \\n    └─Projection_7             | 4019.00  | 28      | root      |               | time:672.7ms, loops:6, Concurrency:5       | year(game.games.release_date)->Column#36, ... | 35.5 KB | N/A     \\n      └─HashAgg_15             | 4019.00  | 28      | root      |               | time:672.6ms, loops:6, partial_worker:...  | group by:Column#38, funcs:count(Column#39)... | 56.7 KB | N/A     \\n        └─TableReader_16       | 4019.00  | 28      | root      |               | time:672.4ms, loops:2, cop_task: {num:...  | data:HashAgg_9                                | 3.60 KB | N/A     \\n          └─HashAgg_9          | 4019.00  | 28      | cop[tikv] |               | tikv_task:{proc max:300ms, min:0s, avg...  | group by:year(game.games.release_date), ...   | N/A     | N/A     \\n            └─TableFullScan_14 | 68223.00 | 68223   | cop[tikv] | table:games   | tikv_task:{proc max:290ms, min:0s, avg...  | keep order:false                              | N/A     | N/A     \\n    (6 rows)\"\n```\n\n----------------------------------------\n\nTITLE: Updating Table Schema with binlog-schema\nDESCRIPTION: Example of using the binlog-schema update command to modify the schema for a specific table in a migration task.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-manage-schema.md#2025-04-18_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\noperate-schema set -s mysql-replica-01 task_single -d db_single -t t1 db_single.t1-schema.sql\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with ActiveRecord ORM in Rails\nDESCRIPTION: Ruby code that creates a new Player record with initial coin and goods values using ActiveRecord.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_11\n\nLANGUAGE: ruby\nCODE:\n```\nnew_player = Player.create!(coins: 100, goods: 100)\n```\n\n----------------------------------------\n\nTITLE: Inserting Player Data into TiDB using JDBC in Java\nDESCRIPTION: This code snippet shows how to insert player data into a TiDB database using JDBC. It creates a prepared statement with placeholders for id, coins, and goods, then executes the insert operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-jdbc.md#2025-04-18_snippet_1\n\nLANGUAGE: java\nCODE:\n```\npublic void createPlayer(PlayerBean player) throws SQLException {\n    MysqlDataSource mysqlDataSource = getMysqlDataSource();\n    try (Connection connection = mysqlDataSource.getConnection()) {\n        PreparedStatement preparedStatement = connection.prepareStatement(\"INSERT INTO player (id, coins, goods) VALUES (?, ?, ?)\");\n        preparedStatement.setString(1, player.getId());\n        preparedStatement.setInt(2, player.getCoins());\n        preparedStatement.setInt(3, player.getGoods());\n\n        preparedStatement.execute();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Managing TiDB Schedulers using PD Control Commands\nDESCRIPTION: These commands showcase various operations for managing schedulers in TiDB, including showing, adding, removing, pausing, resuming, and configuring schedulers.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_30\n\nLANGUAGE: bash\nCODE:\n```\n>> scheduler show                                          // Display all created schedulers\n>> scheduler add grant-leader-scheduler 1                  // Schedule all the leaders of the Regions on store 1 to store 1\n>> scheduler add evict-leader-scheduler 1                  // Move all the Region leaders on store 1 out\n>> scheduler config evict-leader-scheduler                 // Display the stores in which the scheduler is located since v4.0.0\n>> scheduler config evict-leader-scheduler add-store 2     // Add leader eviction scheduling for store 2\n>> scheduler config evict-leader-scheduler delete-store 2  // Remove leader eviction scheduling for store 2\n>> scheduler add evict-slow-store-scheduler                // When there is one and only one slow store, evict all Region leaders of that store\n>> scheduler remove grant-leader-scheduler-1               // Remove the corresponding scheduler, and `-1` corresponds to the store ID\n>> scheduler pause balance-region-scheduler 10             // Pause the balance-region scheduler for 10 seconds\n>> scheduler pause all 10                                  // Pause all schedulers for 10 seconds\n>> scheduler resume balance-region-scheduler               // Continue to run the balance-region scheduler\n>> scheduler resume all                                    // Continue to run all schedulers\n>> scheduler config balance-hot-region-scheduler           // Display the configuration of the balance-hot-region scheduler\n>> scheduler describe balance-region-scheduler             // Display the running state and related diagnostic information of the balance-region scheduler\n```\n\n----------------------------------------\n\nTITLE: Updating Data with Sequelize ORM in TypeScript\nDESCRIPTION: This code updates an existing player record by changing its coins and goods values to 700 using Sequelize's update method. It operates on the player object created in the insert operation and logs the updated object.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-sequelize.md#2025-04-18_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nlogger.info('Updating the new player...');\nawait newPlayer.update({ coins: 700, goods: 700 });\nlogger.info('Updated the new player.');\nlogger.info(newPlayer.toJSON());\n```\n\n----------------------------------------\n\nTITLE: Setting Default Value with Auto-Update in SQL\nDESCRIPTION: Creates a 'ratings' table with a default value for 'rated_at' that also updates automatically when the row is modified.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `bookshop`.`ratings` (\n  `book_id` bigint,\n  `user_id` bigint,\n  `score` tinyint,\n  `rated_at` datetime DEFAULT NOW() ON UPDATE NOW(),\n  PRIMARY KEY (`book_id`,`user_id`) CLUSTERED\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring DM Replication Task\nDESCRIPTION: Provides a YAML configuration for a task to replicate incremental data. It configures target TiDB connection details and specifies blocking and allowing lists for tables. It also shows starting point configuration using GTID for binlog.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-to-tidb.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nname: task-test\ntask-mode: incremental\n\ntarget-database:\n  host: \"${host}\"\n  port: 4000\n  user: \"root\"\n  password: \"${password}\"\n\nblock-allow-list:\n  bw-rule-1:\n    do-dbs: [\"${db-name}\"]\n\nmysql-instances:\n  - source-id: \"mysql-01\"\n    block-allow-list: \"bw-rule-1\"\n    meta:\n      binlog-gtid: \"09bec856-ba95-11ea-850a-58f2b4af5188:1-9\"\n```\n\n----------------------------------------\n\nTITLE: Querying Player Data from TiDB using Java and MySQL Connector/J\nDESCRIPTION: This snippet demonstrates how to query player data from a TiDB database using Java and MySQL Connector/J. It establishes a connection, prepares a SQL statement with a parameter, executes the query, and processes the result set.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-jdbc.md#2025-04-18_snippet_2\n\nLANGUAGE: java\nCODE:\n```\npublic void getPlayer(String id) throws SQLException {\n    MysqlDataSource mysqlDataSource = getMysqlDataSourceByEnv();\n    try (Connection connection = mysqlDataSource.getConnection()) {\n        PreparedStatement preparedStatement = connection.prepareStatement(\"SELECT * FROM player WHERE id = ?\");\n        preparedStatement.setString(1, id);\n        preparedStatement.execute();\n\n        ResultSet res = preparedStatement.executeQuery();\n        if(res.next()) {\n            PlayerBean player = new PlayerBean(res.getString(\"id\"), res.getInt(\"coins\"), res.getInt(\"goods\"));\n            System.out.println(player);\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Limited SQL Query - Top Authors\nDESCRIPTION: SQL query showing result limitation using LIMIT clause to return only the first 10 records.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, name, birth_year\nFROM authors\nORDER BY birth_year DESC\nLIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Not Null and Unique Constraints in SQL\nDESCRIPTION: Creates a 'users' table with both UNIQUE and NOT NULL constraints on the 'nickname' column.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `bookshop`.`users` (\n  `id` bigint AUTO_RANDOM,\n  `balance` decimal(15,2),\n  `nickname` varchar(100) UNIQUE NOT NULL,\n  PRIMARY KEY (`id`)\n);\n```\n\n----------------------------------------\n\nTITLE: EXPLAIN ANALYZE with Point Query\nDESCRIPTION: Example of using EXPLAIN ANALYZE on a point query (WHERE id = 1) to show execution statistics like actual rows, execution time, and memory usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT * FROM t1 WHERE id = 1;\n```\n\n----------------------------------------\n\nTITLE: Using Prepared Statements in Java JDBC\nDESCRIPTION: Illustrates how to use prepared statements with Java JDBC to query data from the 'books' table, including error handling.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-prepared-statement.md#2025-04-18_snippet_2\n\nLANGUAGE: java\nCODE:\n```\ntry (Connection connection = ds.getConnection()) {\n    PreparedStatement preparedStatement = connection.prepareStatement(\"SELECT * FROM `books` WHERE `id` = ?\");\n    preparedStatement.setLong(1, 1);\n\n    ResultSet res = preparedStatement.executeQuery();\n    if(!res.next()) {\n        System.out.println(\"No books in the table with id 1\");\n    } else {\n        // got book's info, which id is 1\n        System.out.println(res.getLong(\"id\"));\n        System.out.println(res.getString(\"title\"));\n        System.out.println(res.getString(\"type\"));\n    }\n} catch (SQLException e) {\n    e.printStackTrace();\n}\n```\n\n----------------------------------------\n\nTITLE: Using TiDB Cloud Serverless Driver in Node.js\nDESCRIPTION: JavaScript code demonstrating how to import and use the TiDB Cloud serverless driver to connect to a database and execute a query.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-node-example.md#2025-04-18_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nimport { connect } from '@tidbcloud/serverless'\n\nconst conn = connect({url: 'mysql://[username]:[password]@[host]/[database]'}) // replace with your TiDB Cloud Serverless cluster information\nconsole.log(await conn.execute(\"show tables\"))\n```\n\n----------------------------------------\n\nTITLE: Enabling Index Merge in TiDB\nDESCRIPTION: This SQL statement enables the index merge optimization feature within a TiDB session. It sets the `tidb_enable_index_merge` variable to `ON`, allowing the TiDB optimizer to consider using index merge during query planning. This can potentially improve query performance by leveraging multiple indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-index-merge.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET session tidb_enable_index_merge = ON;\n```\n\n----------------------------------------\n\nTITLE: Sample Resource Group Creation\nDESCRIPTION: Example SQL statements demonstrating how to create resource groups with different configurations including RU_PER_SEC, PRIORITY, and QUERY_LIMIT settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-resource-group.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP RESOURCE GROUP IF EXISTS rg1;\n\nCREATE RESOURCE GROUP IF NOT EXISTS rg1\n  RU_PER_SEC = 100\n  PRIORITY = HIGH\n  BURSTABLE;\n\nCREATE RESOURCE GROUP IF NOT EXISTS rg2\n  RU_PER_SEC = 200 QUERY_LIMIT=(EXEC_ELAPSED='100ms', ACTION=KILL);\n```\n\n----------------------------------------\n\nTITLE: Golang Bulk Update Implementation\nDESCRIPTION: Complete Golang implementation for batch updating ratings. Includes connection handling, batch processing of 1000 records at a time, and safeguards against duplicate updates. Uses primary key ordering for consistent updates.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-update-data.md#2025-04-18_snippet_7\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n    \"database/sql\"\n    \"fmt\"\n    _ \"github.com/go-sql-driver/mysql\"\n    \"strings\"\n    \"time\"\n)\n\nfunc main() {\n    db, err := sql.Open(\"mysql\", \"root:@tcp(127.0.0.1:4000)/bookshop\")\n    if err != nil {\n        panic(err)\n    }\n    defer db.Close()\n\n    bookID, userID := updateBatch(db, true, 0, 0)\n    fmt.Println(\"first time batch update success\")\n    for {\n        time.Sleep(time.Second)\n        bookID, userID = updateBatch(db, false, bookID, userID)\n        fmt.Printf(\"batch update success, [bookID] %d, [userID] %d\\n\", bookID, userID)\n    }\n}\n\n// updateBatch select at most 1000 lines data to update score\nfunc updateBatch(db *sql.DB, firstTime bool, lastBookID, lastUserID int64) (bookID, userID int64) {\n    // select at most 1000 primary keys in five-point scale data\n    var err error\n    var rows *sql.Rows\n\n    if firstTime {\n        rows, err = db.Query(\"SELECT `book_id`, `user_id` FROM `bookshop`.`ratings` \" +\n            \"WHERE `ten_point` != true ORDER BY `book_id`, `user_id` LIMIT 1000\")\n    } else {\n        rows, err = db.Query(\"SELECT `book_id`, `user_id` FROM `bookshop`.`ratings` \"+\n            \"WHERE `ten_point` != true AND `book_id` > ? AND `user_id` > ? \"+\n            \"ORDER BY `book_id`, `user_id` LIMIT 1000\", lastBookID, lastUserID)\n    }\n\n    if err != nil || rows == nil {\n        panic(fmt.Errorf(\"error occurred or rows nil: %+v\", err))\n    }\n\n    // joint all id with a list\n    var idList []interface{}\n    for rows.Next() {\n        var tempBookID, tempUserID int64\n        if err := rows.Scan(&tempBookID, &tempUserID); err != nil {\n            panic(err)\n        }\n        idList = append(idList, tempBookID, tempUserID)\n        bookID, userID = tempBookID, tempUserID\n    }\n\n    bulkUpdateSql := fmt.Sprintf(\"UPDATE `bookshop`.`ratings` SET `ten_point` = true, \"+\n        \"`score` = `score` * 2 WHERE (`book_id`, `user_id`) IN (%s)\", placeHolder(len(idList)))\n    db.Exec(bulkUpdateSql, idList...)\n\n    return bookID, userID\n}\n\n// placeHolder format SQL place holder\nfunc placeHolder(n int) string {\n    holderList := make([]string, n/2, n/2)\n    for i := range holderList {\n        holderList[i] = \"(?,?)\"\n    }\n    return strings.Join(holderList, \",\")\n}\n```\n\n----------------------------------------\n\nTITLE: Using Prepared Statement Batch Operations in Java\nDESCRIPTION: Demonstrates how to use Prepared Statements with batch operations in JDBC. This example shows the process of adding multiple values to a batch and executing them together.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_0\n\nLANGUAGE: java\nCODE:\n```\npstmt = prepare(\"insert into t (a) values(?)\");\npstmt.setInt(1, 10);\npstmt.addBatch();\npstmt.setInt(1, 11);\npstmt.addBatch();\npstmt.setInt(1, 12);\npstmt.executeBatch();\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for CREATE TABLE Statement in TiDB\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax diagram that specifies the complete grammar for the CREATE TABLE statement in TiDB, including all supported options and clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-table.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCreateTableStmt ::=\n    'CREATE' OptTemporary 'TABLE' IfNotExists TableName ( TableElementListOpt CreateTableOptionListOpt PartitionOpt DuplicateOpt AsOpt CreateTableSelectOpt | LikeTableWithOrWithoutParen ) OnCommitOpt\n\nOptTemporary ::=\n    ( 'TEMPORARY' | ('GLOBAL' 'TEMPORARY') )?\n\nIfNotExists ::=\n    ('IF' 'NOT' 'EXISTS')?\n\nTableName ::=\n    Identifier ('.' Identifier)?\n\nTableElementListOpt ::=\n    ( '(' TableElementList ')' )?\n\nTableElementList ::=\n    TableElement ( ',' TableElement )*\n\nTableElement ::=\n    ColumnDef\n|   Constraint\n\nColumnDef ::=\n    ColumnName ( Type | 'SERIAL' ) ColumnOptionListOpt\n\nColumnOptionListOpt ::=\n    ColumnOption*\n\nColumnOptionList ::=\n    ColumnOption*\n\nColumnOption ::=\n    'NOT'? 'NULL'\n|   'AUTO_INCREMENT'\n|   PrimaryOpt 'KEY' ( 'GLOBAL' | 'LOCAL' )?\n|   'UNIQUE' 'KEY'? ( 'GLOBAL' | 'LOCAL' )?\n|   'DEFAULT' DefaultValueExpr\n|   'SERIAL' 'DEFAULT' 'VALUE'\n|   'ON' 'UPDATE' NowSymOptionFraction\n|   'COMMENT' stringLit\n|   ConstraintKeywordOpt 'CHECK' '(' Expression ')' EnforcedOrNotOrNotNullOpt\n|   GeneratedAlways 'AS' '(' Expression ')' VirtualOrStored\n|   ReferDef\n|   'COLLATE' CollationName\n|   'COLUMN_FORMAT' ColumnFormat\n|   'STORAGE' StorageMedia\n|   'AUTO_RANDOM' OptFieldLen\n\nConstraint ::=\n    IndexDef\n|   ForeignKeyDef\n\nIndexDef ::=\n    ( 'INDEX' | 'KEY' ) IndexName? '(' KeyPartList ')' IndexOption?\n\nKeyPartList ::=\n    KeyPart ( ',' KeyPart )*\n\nKeyPart ::=\n    ColumnName ( '(' Length ')')? ( 'ASC' | 'DESC' )?\n|   '(' Expression ')' ( 'ASC' | 'DESC' )?\n\nIndexOption ::=\n    'COMMENT' String\n|   ( 'VISIBLE' | 'INVISIBLE' )\n|   ('USING' | 'TYPE') ('BTREE' | 'RTREE' | 'HASH')\n|   ( 'GLOBAL' | 'LOCAL' )\n\nForeignKeyDef\n         ::= ( 'CONSTRAINT' Identifier )? 'FOREIGN' 'KEY'\n             Identifier? '(' ColumnName ( ',' ColumnName )* ')'\n             'REFERENCES' TableName '(' ColumnName ( ',' ColumnName )* ')'\n             ( 'ON' 'DELETE' ReferenceOption )?\n             ( 'ON' 'UPDATE' ReferenceOption )?\n\nReferenceOption\n         ::= 'RESTRICT'\n           | 'CASCADE'\n           | 'SET' 'NULL'\n           | 'SET' 'DEFAULT'\n           | 'NO' 'ACTION'\n\nCreateTableOptionListOpt ::=\n    TableOptionList?\n\nPartitionOpt ::=\n    ( 'PARTITION' 'BY' PartitionMethod PartitionNumOpt SubPartitionOpt PartitionDefinitionListOpt )?\n\nDuplicateOpt ::=\n    ( 'IGNORE' | 'REPLACE' )?\n\nTableOptionList ::=\n    TableOption ( ','? TableOption )*\n\nTableOption ::=\n    PartDefOption\n|   DefaultKwdOpt ( CharsetKw EqOpt CharsetName | 'COLLATE' EqOpt CollationName )\n|   ( 'AUTO_INCREMENT' | 'AUTO_ID_CACHE' | 'AUTO_RANDOM_BASE' | 'AVG_ROW_LENGTH' | 'CHECKSUM' | 'TABLE_CHECKSUM' | 'KEY_BLOCK_SIZE' | 'DELAY_KEY_WRITE' | 'SHARD_ROW_ID_BITS' | 'PRE_SPLIT_REGIONS' ) EqOpt LengthNum\n|   ( 'CONNECTION' | 'ENGINE_ATTRIBUTE' | 'PASSWORD' | 'COMPRESSION' ) EqOpt stringLit\n|   RowFormat\n|   ( 'STATS_PERSISTENT' | 'PACK_KEYS' ) EqOpt StatsPersistentVal\n|   ( 'STATS_AUTO_RECALC' | 'STATS_SAMPLE_PAGES' ) EqOpt ( LengthNum | 'DEFAULT' )\n|   'STORAGE' ( 'MEMORY' | 'DISK' )\n|   'SECONDARY_ENGINE' EqOpt ( 'NULL' | StringName )\n|   'UNION' EqOpt '(' TableNameListOpt ')'\n|   'ENCRYPTION' EqOpt EncryptionOpt\n|    'TTL' EqOpt TimeColumnName '+' 'INTERVAL' Expression TimeUnit (TTLEnable EqOpt ( 'ON' | 'OFF' ))? (TTLJobInterval EqOpt stringLit)?\n|   PlacementPolicyOption\n\nOnCommitOpt ::=\n    ('ON' 'COMMIT' 'DELETE' 'ROWS')?\n\nPlacementPolicyOption ::=\n    \"PLACEMENT\" \"POLICY\" EqOpt PolicyName\n|   \"PLACEMENT\" \"POLICY\" (EqOpt | \"SET\") \"DEFAULT\"\n\nDefaultValueExpr ::=\n    NowSymOptionFractionParentheses\n|   SignedLiteral\n|   NextValueForSequenceParentheses\n|   BuiltinFunction\n\nBuiltinFunction ::=\n    '(' BuiltinFunction ')'\n|   identifier '(' ')'\n|   identifier '(' ExpressionList ')'\n|   \"REPLACE\" '(' ExpressionList ')'\n\nNowSymOptionFractionParentheses ::=\n    '(' NowSymOptionFractionParentheses ')'\n|   NowSymOptionFraction\n\nNowSymOptionFraction ::=\n    NowSym\n|   NowSymFunc '(' ')'\n|   NowSymFunc '(' NUM ')'\n|   CurdateSym '(' ')'\n|   \"CURRENT_DATE\"\n\nNextValueForSequenceParentheses ::=\n    '(' NextValueForSequenceParentheses ')'\n|   NextValueForSequence\n\nNextValueForSequence ::=\n    \"NEXT\" \"VALUE\" forKwd TableName\n|   \"NEXTVAL\" '(' TableName ')'\n```\n\n----------------------------------------\n\nTITLE: Checking Granted Privileges for a User in TiDB\nDESCRIPTION: This snippet demonstrates how to check the granted privileges for a specific user in TiDB using the `SHOW GRANTS` statement. It displays the privileges directly granted to the user and the roles assigned to the user. To check privilege-related information of another user, you need the `SELECT` privilege on the `mysql` database.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS FOR 'dev1'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Querying Book Details Using Multiple Non-recursive CTEs in SQL\nDESCRIPTION: This SQL snippet uses multiple non-recursive CTEs to query detailed information about books written by a specific author, including average ratings and order counts.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-common-table-expression.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nWITH books_authored_by_rm AS (\n    SELECT *\n    FROM books b\n    LEFT JOIN book_authors ba ON b.id = ba.book_id\n    WHERE author_id = 2299112019\n), books_with_average_ratings AS (\n    SELECT\n        b.id AS book_id,\n        AVG(r.score) AS average_rating\n    FROM books_authored_by_rm b\n    LEFT JOIN ratings r ON b.id = r.book_id\n    GROUP BY b.id\n), books_with_orders AS (\n    SELECT\n        b.id AS book_id,\n        COUNT(*) AS orders\n    FROM books_authored_by_rm b\n    LEFT JOIN orders o ON b.id = o.book_id\n    GROUP BY b.id\n)\nSELECT\n    b.id AS `book_id`,\n    b.title AS `book_title`,\n    br.average_rating AS `average_rating`,\n    bo.orders AS `orders`\nFROM\n    books_authored_by_rm b\n    LEFT JOIN books_with_average_ratings br ON b.id = br.book_id\n    LEFT JOIN books_with_orders bo ON b.id = bo.book_id\n;\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with PyMySQL in Python\nDESCRIPTION: This function establishes a connection to a TiDB database using PyMySQL. It configures the connection parameters including host, port, user, password, and database name. It also handles SSL configuration if a CA certificate path is provided.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-pymysql.md#2025-04-18_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom pymysql import Connection\nfrom pymysql.cursors import DictCursor\n\n\ndef get_connection(autocommit: bool = True) -> Connection:\n    config = Config()\n    db_conf = {\n        \"host\": ${tidb_host},\n        \"port\": ${tidb_port},\n        \"user\": ${tidb_user},\n        \"password\": ${tidb_password},\n        \"database\": ${tidb_db_name},\n        \"autocommit\": autocommit,\n        \"cursorclass\": DictCursor,\n    }\n\n    if ${ca_path}:\n        db_conf[\"ssl_verify_cert\"] = True\n        db_conf[\"ssl_verify_identity\"] = True\n        db_conf[\"ssl_ca\"] = ${ca_path}\n\n    return pymysql.connect(**db_conf)\n```\n\n----------------------------------------\n\nTITLE: Querying Using Generated Column Index\nDESCRIPTION: Demonstrates how to query the table using the generated column index for improved performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/generated-columns.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT name, id FROM person WHERE city = 'Beijing';\n```\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT name, id FROM person WHERE city = 'Beijing';\n```\n\n----------------------------------------\n\nTITLE: Historical Order Trend Analysis using Window Functions\nDESCRIPTION: SQL query using window functions to analyze historical ordering trends for a specific book. Uses SUM() as window function with ORDER BY clause to calculate cumulative orders over time.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-hybrid-oltp-and-olap-queries.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nWITH orders_group_by_month AS (\n  SELECT DATE_FORMAT(ordered_at, '%Y-%c') AS month, COUNT(*) AS orders\n  FROM orders\n  WHERE book_id = 3461722937\n  GROUP BY 1\n)\nSELECT\nmonth,\nSUM(orders) OVER(ORDER BY month ASC) as acc\nFROM orders_group_by_month\nORDER BY month ASC;\n```\n\n----------------------------------------\n\nTITLE: Starting a Transaction in TiDB\nDESCRIPTION: Examples of starting a new transaction using BEGIN and START TRANSACTION statements. These statements are interchangeable and automatically commit any existing transaction before starting a new one.\nSOURCE: https://github.com/pingcap/docs/blob/master/transaction-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSTART TRANSACTION;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSTART TRANSACTION WITH CONSISTENT SNAPSHOT;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSTART TRANSACTION WITH CAUSAL CONSISTENCY ONLY;\n```\n\n----------------------------------------\n\nTITLE: Golang Bulk Insert Implementation\nDESCRIPTION: Shows a bulk insert implementation in Go using database/sql package. Includes transaction handling and dynamic SQL generation for batch processing.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-insert-data.md#2025-04-18_snippet_3\n\nLANGUAGE: golang\nCODE:\n```\npackage main\n\nimport (\n    \"database/sql\"\n    \"strings\"\n\n    _ \"github.com/go-sql-driver/mysql\"\n)\n\ntype Player struct {\n    ID    string\n    Coins int\n    Goods int\n}\n\nfunc bulkInsertPlayers(db *sql.DB, players []Player, batchSize int) error {\n    tx, err := db.Begin()\n    if err != nil {\n        return err\n    }\n\n    stmt, err := tx.Prepare(buildBulkInsertSQL(batchSize))\n    if err != nil {\n        return err\n    }\n\n    defer stmt.Close()\n\n    for len(players) > batchSize {\n        if _, err := stmt.Exec(playerToArgs(players[:batchSize])...); err != nil {\n            tx.Rollback()\n            return err\n        }\n\n        players = players[batchSize:]\n    }\n\n    if len(players) != 0 {\n        if _, err := tx.Exec(buildBulkInsertSQL(len(players)), playerToArgs(players)...); err != nil {\n            tx.Rollback()\n            return err\n        }\n    }\n\n    if err := tx.Commit(); err != nil {\n        tx.Rollback()\n        return err\n    }\n\n    return nil\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Historical Data with AS OF TIMESTAMP in SQL\nDESCRIPTION: Demonstrates how to query book data from a specific point in time using the AS OF TIMESTAMP clause. Shows various timestamp formats including exact time, relative time intervals, and bounded staleness.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-stale-read.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, title, type, price FROM books AS OF TIMESTAMP '2022-04-20 15:20:00' ORDER BY published_at DESC LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Storing Documents with Vector Embeddings\nDESCRIPTION: Python code that demonstrates how to insert documents with their corresponding vector embeddings into the TiDB database using SQLAlchemy session.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nwith Session(engine) as session:\n   session.add(Document(content=\"dog\", embedding=[1, 2, 1]))\n   session.add(Document(content=\"fish\", embedding=[1, 2, 4]))\n   session.add(Document(content=\"tree\", embedding=[1, 0, 0]))\n   session.commit()\n```\n\n----------------------------------------\n\nTITLE: Enabling Distributed Task Execution in TiDB\nDESCRIPTION: This SQL command activates the TiDB Distributed eXecution Framework (DXF) by setting the tidb_enable_dist_task system variable to ON. Enabling DXF allows multiple TiDB nodes to execute DDL tasks and IMPORT INTO operations in parallel, significantly improving performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.5.0.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_dist_task = ON;\n```\n\n----------------------------------------\n\nTITLE: Setting Password for a New User in TiDB\nDESCRIPTION: Create a new user with a specific password using CREATE USER with IDENTIFIED BY clause, which hashes and stores the password securely.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'test'@'localhost' IDENTIFIED BY 'mypass';\n```\n\n----------------------------------------\n\nTITLE: Hibernate Configuration for TiDB\nDESCRIPTION: XML configuration for setting up Hibernate ORM connection to TiDB, including dialect and connection properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connect-to-tidb.md#2025-04-18_snippet_5\n\nLANGUAGE: xml\nCODE:\n```\n<?xml version='1.0' encoding='utf-8'?>\n<!DOCTYPE hibernate-configuration PUBLIC\n        \"-//Hibernate/Hibernate Configuration DTD 3.0//EN\"\n        \"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd\">\n<hibernate-configuration>\n    <session-factory>\n        <property name=\"hibernate.connection.driver_class\">com.mysql.cj.jdbc.Driver</property>\n        <property name=\"hibernate.dialect\">org.hibernate.dialect.TiDBDialect</property>\n        <property name=\"hibernate.connection.url\">jdbc:mysql://{host}:{port}/{database}?user={user}&amp;password={password}</property>\n    </session-factory>\n</hibernate-configuration>\n```\n\n----------------------------------------\n\nTITLE: Generating Basic Execution Plan in TiDB\nDESCRIPTION: Example of using EXPLAIN statement to display the execution plan for a SQL query that counts trips within a specific date range. Shows operator hierarchy, estimated rows, and task distribution across TiDB components.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT COUNT(*) FROM trips WHERE start_date BETWEEN '2017-07-01 00:00:00' AND '2017-07-01 23:59:59';\n```\n\n----------------------------------------\n\nTITLE: Using JSON_EXTRACT and Arrow Operators in SQL\nDESCRIPTION: Demonstrates JSON_EXTRACT function and arrow operators (-> and ->>) for extracting values from JSON documents.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-search.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_EXTRACT('{\"foo\": \"bar\", \"aaa\": 5}', '$.foo');\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    j->'$.foo',\n    JSON_EXTRACT(j, '$.foo')\nFROM (\n    SELECT\n        '{\"foo\": \"bar\", \"aaa\": 5}' AS j\n    ) AS tbl;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    j->'$.foo',\n    JSON_EXTRACT(j, '$.foo')\n    j->>'$.foo',\n    JSON_UNQUOTE(JSON_EXTRACT(j, '$.foo'))\nFROM (\n    SELECT\n        '{\"foo\": \"bar\", \"aaa\": 5}' AS j\n    ) AS tbl;\n```\n\n----------------------------------------\n\nTITLE: Basic SQL DELETE Statement\nDESCRIPTION: Basic SQL syntax for deleting data from a table with a WHERE clause filter\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-delete-data.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nDELETE FROM {table} WHERE {filter}\n```\n\n----------------------------------------\n\nTITLE: Inserting or Updating Data in TiDB with Spring Data JPA\nDESCRIPTION: This Java code demonstrates how to insert or update a player entity in TiDB using the save method from JpaRepository.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-spring-boot.md#2025-04-18_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nplayerRepository.save(player);\n```\n\n----------------------------------------\n\nTITLE: Creating a Secondary Index for Performance Optimization in TiDB\nDESCRIPTION: Creates a secondary index on the 'title' column of the 'books' table to improve query performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX title_idx ON books (title);\n```\n\n----------------------------------------\n\nTITLE: Collecting Column Statistics on Table Partitions in TiDB\nDESCRIPTION: SQL syntax for collecting statistics on specific columns of specific partitions in a table. This allows for highly targeted statistics collection to reduce overhead.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE TableName PARTITION PartitionNameList [COLUMNS ColumnNameList|PREDICATE COLUMNS|ALL COLUMNS] [WITH NUM BUCKETS|TOPN|CMSKETCH DEPTH|CMSKETCH WIDTH]|[WITH NUM SAMPLES|WITH FLOATNUM SAMPLERATE];\n```\n\n----------------------------------------\n\nTITLE: DELETE Statement Usage Example in TiDB\nDESCRIPTION: A complete example demonstrating how to use the DELETE statement in TiDB. The example shows table creation, data insertion, selecting data before and after deletion, and the DELETE operation itself.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-delete.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5);\nQuery OK, 5 rows affected (0.03 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\nmysql> SELECT * FROM t1;\n+----+----+\n| id | c1 |\n+----+----+\n|  1 |  1 |\n|  2 |  2 |\n|  3 |  3 |\n|  4 |  4 |\n|  5 |  5 |\n+----+----+\n5 rows in set (0.00 sec)\n\nmysql> DELETE FROM t1 WHERE id = 4;\nQuery OK, 1 row affected (0.02 sec)\n\nmysql> SELECT * FROM t1;\n+----+----+\n| id | c1 |\n+----+----+\n|  1 |  1 |\n|  2 |  2 |\n|  3 |  3 |\n|  5 |  5 |\n+----+----+\n4 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating Indexed JSON Column in TiDB\nDESCRIPTION: Example of creating a table with a JSON column and indexing a specific field using a generated column. The snippet demonstrates how to store and query JSON data with an index on the population field.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-json.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE city (\n    id INT PRIMARY KEY,\n    detail JSON,\n    population INT AS (JSON_EXTRACT(detail, '$.population')),\n    index index_name (population)\n    );\nINSERT INTO city (id,detail) VALUES (1, '{\"name\": \"Beijing\", \"population\": 100}');\nSELECT id FROM city WHERE population >= 100;\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into TiDB using Hibernate in Java\nDESCRIPTION: This Java code snippet shows how to insert data into TiDB using Hibernate. It opens a session and persists a new PlayerBean object to the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-hibernate.md#2025-04-18_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\ntry (Session session = sessionFactory.openSession()) {\n    session.persist(new PlayerBean(\"id\", 1, 1));\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Sequelize Connection to TiDB in TypeScript\nDESCRIPTION: This code snippet demonstrates how to establish a connection to TiDB using Sequelize ORM in a TypeScript environment. It includes configuration for SSL and custom CA certificates if required.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-sequelize.md#2025-04-18_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// src/lib/tidb.ts\nimport { Sequelize } from 'sequelize';\n\nexport function initSequelize() {\n  return new Sequelize({\n    dialect: 'mysql',\n    host: process.env.TIDB_HOST || 'localhost',     // TiDB host, for example: {gateway-region}.aws.tidbcloud.com\n    port: Number(process.env.TIDB_PORT) || 4000,    // TiDB port, default: 4000\n    username: process.env.TIDB_USER || 'root',      // TiDB user, for example: {prefix}.root\n    password: process.env.TIDB_PASSWORD || 'root',  // TiDB password\n    database: process.env.TIDB_DB_NAME || 'test',   // TiDB database name, default: test\n    dialectOptions: {\n      ssl:\n        process.env?.TIDB_ENABLE_SSL === 'true'     // (Optional) Enable SSL\n          ? {\n              minVersion: 'TLSv1.2',\n              rejectUnauthorized: true,\n              ca: process.env.TIDB_CA_PATH          // (Optional) Path to the custom CA certificate\n                ? readFileSync(process.env.TIDB_CA_PATH)\n                : undefined,\n            }\n          : null,\n    },\n}\n\nexport async function getSequelize() {\n  if (!sequelize) {\n    sequelize = initSequelize();\n    try {\n      await sequelize.authenticate();\n      logger.info('Connection has been established successfully.');\n    } catch (error) {\n      logger.error('Unable to connect to the database:');\n      logger.error(error);\n      throw error;\n    }\n  }\n  return sequelize;\n}\n```\n\n----------------------------------------\n\nTITLE: Set Password Syntax\nDESCRIPTION: This EBNF diagram defines the syntax of the SET PASSWORD statement. It shows how to specify the user account and the new password, including optional FOR clause and PASSWORD function.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-password.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\n\"SET\" \"PASSWORD\" ( \"FOR\" Username )? \"=\" ( stringLit | \"PASSWORD\" \"(\" stringLit \")\" )\n```\n\n----------------------------------------\n\nTITLE: Using LIMIT_TO_COP Hint in TiDB SQL\nDESCRIPTION: Example of using the LIMIT_TO_COP hint to push down LIMIT and TopN operations to the coprocessor, optimizing performance by reducing data transfer between storage and compute layers.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_34\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ LIMIT_TO_COP() */ * FROM t WHERE a = 1 AND b > 10 ORDER BY c LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: SQL Example of ADMIN RESUME DDL Usage\nDESCRIPTION: Example showing how to use the ADMIN RESUME DDL JOBS statement to resume one or more paused DDL jobs using their job IDs.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-resume-ddl.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nADMIN RESUME DDL JOBS job_id [, job_id] ...;\n```\n\n----------------------------------------\n\nTITLE: Creating, Showing, and Dropping Tables in TiDB\nDESCRIPTION: Commands for table management, including creating a table with columns and data types, showing the table creation statement, and dropping a table.\nSOURCE: https://github.com/pingcap/docs/blob/master/basic-sql-operations.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_name column_name data_type constraint;\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE person (\n    id INT,\n    name VARCHAR(255),\n    birthday DATE\n    );\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE table person;\n```\n\nLANGUAGE: sql\nCODE:\n```\nDROP TABLE person;\n```\n\n----------------------------------------\n\nTITLE: Streamlined Vector Search and SQL Query in Python\nDESCRIPTION: Combines vector search and SQL query in a single operation to retrieve detailed airport information based on semantic similarity.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nsearch_query = f\"\"\"\n    SELECT\n        VEC_Cosine_Distance(se.embedding, :query_vector) as distance,\n        ar.*,\n        se.document as airport_review\n    FROM\n        airplan_routes ar\n    JOIN\n        {TABLE_NAME} se ON ar.airport_code = JSON_UNQUOTE(JSON_EXTRACT(se.meta, '$.airport_code'))\n    ORDER BY distance ASC\n    LIMIT 5;\n\"\"\"\nquery_vector = embeddings.embed_query(semantic_query)\nparams = {\"query_vector\": str(query_vector)}\nairport_details = vector_store.tidb_vector_client.execute(search_query, params)\nairport_details.get(\"result\")\n```\n\n----------------------------------------\n\nTITLE: Executing Optimistic and Pessimistic Transactions in Go\nDESCRIPTION: This Go snippet includes functions for running transactions, preparing data, and executing buy operations with both optimistic and pessimistic concurrency control. It uses the TiDB SQL driver and implements retry logic for handling transaction conflicts.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_4\n\nLANGUAGE: Go\nCODE:\n```\nfunc runTxn(db *sql.DB, optimistic bool, optimisticRetryTimes int, txnFunc func(*util.TiDBSqlTx) error) {\n    var err error\n    var txn *util.TiDBSqlTx\n    if optimistic {\n        txn, err = util.TiDBSqlBegin(db, \"BEGIN OPTIMISTIC\")\n    } else {\n        txn, err = util.TiDBSqlBegin(db, \"BEGIN PESSIMISTIC\")\n    }\n    if err != nil {\n        fmt.Printf(\"[runTxn] begin failed, err: %+v\\n\", err)\n        return\n    }\n\n    defer func() {\n        if p := recover(); p != nil {\n            txn.Rollback()\n            panic(p)\n        }\n    }()\n\n    if err := txnFunc(txn); err != nil {\n        txn.Rollback()\n        fmt.Printf(\"[runTxn] got an error, rollback: %+v\\n\", err)\n    } else {\n        err = txn.Commit()\n        if mysqlErr, ok := err.(*mysql.MySQLError); ok && optimistic && optimisticRetryTimes != 0 {\n            if _, retryableError := retryErrorCodeSet[mysqlErr.Number]; retryableError {\n                fmt.Printf(\"[runTxn] got a retryable error, rest time: %d\\n\", optimisticRetryTimes-1)\n                runTxn(db, optimistic, optimisticRetryTimes-1, txnFunc)\n                return\n            }\n        }\n\n        if err == nil {\n            fmt.Println(\"[runTxn] commit success\")\n        }\n    }\n}\n\nfunc prepareData(db *sql.DB, optimistic bool) {\n    runTxn(db, optimistic, retryTimes, func(txn *util.TiDBSqlTx) error {\n        publishedAt, err := time.Parse(\"2006-01-02 15:04:05\", \"2018-09-01 00:00:00\")\n        if err != nil {\n            return err\n        }\n\n        if err = createBook(txn, 1, \"Designing Data-Intensive Application\",\n            \"Science & Technology\", publishedAt, decimal.NewFromInt(100), 10); err != nil {\n            return err\n        }\n\n        if err = createUser(txn, 1, \"Bob\", decimal.NewFromInt(10000)); err != nil {\n            return err\n        }\n\n        if err = createUser(txn, 2, \"Alice\", decimal.NewFromInt(10000)); err != nil {\n            return err\n        }\n\n        return nil\n    })\n}\n\nfunc buyPessimistic(db *sql.DB, goroutineID, orderID, bookID, userID, amount int) {\n    // ... (implementation details)\n}\n\nfunc buyOptimistic(db *sql.DB, goroutineID, orderID, bookID, userID, amount int) {\n    // ... (implementation details)\n}\n\nfunc createBook(txn *util.TiDBSqlTx, id int, title, bookType string,\n    publishedAt time.Time, price decimal.Decimal, stock int) error {\n    _, err := txn.ExecContext(context.Background(),\n        \"INSERT INTO `books` (`id`, `title`, `type`, `published_at`, `price`, `stock`) values (?, ?, ?, ?, ?, ?)\",\n        id, title, bookType, publishedAt, price, stock)\n    return err\n}\n\nfunc createUser(txn *util.TiDBSqlTx, id int, nickname string, balance decimal.Decimal) error {\n    _, err := txn.ExecContext(context.Background(),\n        \"INSERT INTO `users` (`id`, `nickname`, `balance`) VALUES (?, ?, ?)\",\n        id, nickname, balance)\n    return err\n}\n```\n\n----------------------------------------\n\nTITLE: JSON Response for DM Task Status Query\nDESCRIPTION: This snippet provides a sample JSON response from the query-status command. It includes detailed information about the task status, including source statuses, subtask statuses, and various metrics for different processing units like Sync, Load, and Dump.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-query-status.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"result\": true,\n    \"msg\": \"\",\n    \"sources\": [\n        {\n            \"result\": true,\n            \"msg\": \"\",\n            \"sourceStatus\": {\n                \"source\": \"mysql-replica-01\",\n                \"worker\": \"worker1\",\n                \"result\": null,\n                \"relayStatus\": null\n            },\n            \"subTaskStatus\": [\n                {\n                    \"name\": \"test\",\n                    \"stage\": \"Running\",\n                    \"unit\": \"Sync\",\n                    \"result\": null,\n                    \"unresolvedDDLLockID\": \"test-`test`.`t_target`\",\n                    \"sync\": {\n                        \"masterBinlog\": \"(bin.000001, 3234)\",\n                        \"masterBinlogGtid\": \"c0149e17-dff1-11e8-b6a8-0242ac110004:1-14\",\n                        \"syncerBinlog\": \"(bin.000001, 2525)\",\n                        \"syncerBinlogGtid\": \"\",\n                        \"blockingDDLs\": [\n                            \"USE `test`; ALTER TABLE `test`.`t_target` DROP COLUMN `age`;\"\n                        ],\n                        \"unresolvedGroups\": [\n                            {\n                                \"target\": \"`test`.`t_target`\",\n                                \"DDLs\": [\n                                    \"USE `test`; ALTER TABLE `test`.`t_target` DROP COLUMN `age`;\"\n                                ],\n                                \"firstPos\": \"(bin|000001.000001, 3130)\",\n                                \"synced\": [\n                                    \"`test`.`t2`\"\n                                    \"`test`.`t3`\"\n                                    \"`test`.`t1`\"\n                                ],\n                                \"unsynced\": [\n                                ]\n                            }\n                        ],\n                        \"synced\": false,\n                        \"totalRows\": \"12\",\n                        \"totalRps\": \"1\",\n                        \"recentRps\": \"1\"\n                    }\n                }\n            ]\n        },\n        {\n            \"result\": true,\n            \"msg\": \"\",\n            \"sourceStatus\": {\n                \"source\": \"mysql-replica-02\",\n                \"worker\": \"worker2\",\n                \"result\": null,\n                \"relayStatus\": null\n            },\n            \"subTaskStatus\": [\n                {\n                    \"name\": \"test\",\n                    \"stage\": \"Running\",\n                    \"unit\": \"Load\",\n                    \"result\": null,\n                    \"unresolvedDDLLockID\": \"\",\n                    \"load\": {\n                        \"finishedBytes\": \"115\",\n                        \"totalBytes\": \"452\",\n                        \"progress\": \"25.44 %\",\n                        \"bps\": \"2734\"\n                    }\n                }\n            ]\n        },\n        {\n            \"result\": true,\n            \"sourceStatus\": {\n                \"source\": \"mysql-replica-03\",\n                \"worker\": \"worker3\",\n                \"result\": null,\n                \"relayStatus\": null\n            },\n            \"subTaskStatus\": [\n                {\n                    \"name\": \"test\",\n                    \"stage\": \"Paused\",\n                    \"unit\": \"Load\",\n                    \"result\": {\n                        \"isCanceled\": false,\n                        \"errors\": [\n                            {\n                                \"Type\": \"ExecSQL\",\n                                \"msg\": \"Error 1062: Duplicate entry '1155173304420532225' for key 'PRIMARY'\\n/home/jenkins/workspace/build_dm/go/src/github.com/pingcap/tidb-enterprise-tools/loader/db.go:160: \\n/home/jenkins/workspace/build_dm/go/src/github.com/pingcap/tidb-enterprise-tools/loader/db.go:105: \\n/home/jenkins/workspace/build_dm/go/src/github.com/pingcap/tidb-enterprise-tools/loader/loader.go:138: file test.t1.sql\"\n                            }\n                        ],\n                        \"detail\": null\n                    },\n                    \"unresolvedDDLLockID\": \"\",\n                    \"load\": {\n                        \"finishedBytes\": \"0\",\n                        \"totalBytes\": \"156\",\n                        \"progress\": \"0.00 %\",\n                        \"bps\": \"0\"\n                    }\n                }\n            ]\n        },\n        {\n            \"result\": true,\n            \"msg\": \"\",\n            \"sourceStatus\": {\n                \"source\": \"mysql-replica-04\",\n                \"worker\": \"worker4\",\n                \"result\": null,\n                \"relayStatus\": null\n            },\n            \"subTaskStatus\": [\n                {\n                    \"name\": \"test\",\n                    \"stage\": \"Running\",\n                    \"unit\": \"Dump\",\n                    \"result\": null,\n                    \"unresolvedDDLLockID\": \"\",\n                    \"dump\": {\n                        \"totalTables\": \"10\",\n                        \"completedTables\": \"3\",\n                        \"finishedBytes\": \"2542\",\n                        \"finishedRows\": \"32\",\n                        \"estimateTotalRows\": \"563\",\n                        \"progress\": \"30.52 %\",\n                        \"bps\": \"445\"\n                    }\n                }\n            ]\n        },\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Calling Draft Endpoint with curl in TiDB Cloud\nDESCRIPTION: Example of using curl to call a draft version of an endpoint in TiDB Cloud Data Service. Requires digest authentication with API keys and an explicit header to specify that the draft version should be used.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-get-started.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user '<Public Key>:<Private Key>' \\\n  --request GET 'https://<region>.data.tidbcloud.com/api/v1beta/app/<App ID>/endpoint/<Endpoint Path>' \\\n  --header 'endpoint-type: draft'\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Concurrent Updates in TiDB Transaction Isolation\nDESCRIPTION: This SQL example demonstrates how concurrent transactions attempt to update the same row, showing how TiDB's Repeatable Read isolation level handles conflicts differently from MySQL. In optimistic transactions, the second commit fails and rolls back, while in pessimistic transactions, the second update waits for the lock.\nSOURCE: https://github.com/pingcap/docs/blob/master/transaction-isolation-levels.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t1(id int);\ninsert into t1 values(0);\n\nstart transaction;              |               start transaction;\nselect * from t1;               |               select * from t1;\nupdate t1 set id=id+1;          |               update t1 set id=id+1; -- In pessimistic transactions, the `update` statement executed later waits for the lock until the transaction holding the lock commits or rolls back and releases the row lock.\ncommit;                         |\n                                |               commit; -- The transaction commit fails and rolls back. Pessimistic transactions can commit successfully.\n```\n\n----------------------------------------\n\nTITLE: Task Configuration JSON Format\nDESCRIPTION: The JSON structure for a replication task configuration, detailing all available configuration options including task settings, target database connection parameters, filtering rules, and migration behavior settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_27\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"task-1\",\n  \"task_mode\": \"all\",\n  \"shard_mode\": \"pessimistic\",\n  \"meta_schema\": \"dm-meta\",\n  \"enhance_online_schema_change\": true,\n  \"on_duplicate\": \"overwrite\",\n  \"target_config\": {\n    \"host\": \"127.0.0.1\",\n    \"port\": 3306,\n    \"user\": \"root\",\n    \"password\": \"123456\",\n    \"security\": {\n      \"ssl_ca_content\": \"\",\n      \"ssl_cert_content\": \"\",\n      \"ssl_key_content\": \"\",\n      \"cert_allowed_cn\": [\n        \"string\"\n      ]\n    }\n  },\n  \"binlog_filter_rule\": {\n    \"rule-1\": {\n      \"ignore_event\": [\n        \"all dml\"\n      ],\n      \"ignore_sql\": [\n        \"^Drop\"\n      ]\n    },\n    \"rule-2\": {\n      \"ignore_event\": [\n        \"all dml\"\n      ],\n      \"ignore_sql\": [\n        \"^Drop\"\n      ]\n    },\n    \"rule-3\": {\n      \"ignore_event\": [\n        \"all dml\"\n      ],\n      \"ignore_sql\": [\n        \"^Drop\"\n      ]\n    }\n  },\n  \"table_migrate_rule\": [\n    {\n      \"source\": {\n        \"source_name\": \"source-name\",\n        \"schema\": \"db-*\",\n        \"table\": \"tb-*\"\n      },\n      \"target\": {\n        \"schema\": \"db1\",\n        \"table\": \"tb1\"\n      },\n      \"binlog_filter_rule\": [\n        \"rule-1\",\n        \"rule-2\",\n        \"rule-3\",\n      ]\n    }\n  ],\n  \"source_config\": {\n    \"full_migrate_conf\": {\n      \"export_threads\": 4,\n      \"import_threads\": 16,\n      \"data_dir\": \"./exported_data\",\n      \"consistency\": \"auto\"\n      \"import_mode\": \"physical\",\n      \"sorting_dir\": \"./sort_dir\",\n      \"disk_quota\": \"80G\",\n      \"checksum\": \"required\",\n      \"analyze\": \"optional\",\n      \"range_concurrency\": 0,\n      \"compress-kv-pairs\": \"\",\n      \"pd_addr\": \"\",\n      \"on_duplicate_logical\": \"error\",\n      \"on_duplicate_physical\": \"none\"\n    },\n    \"incr_migrate_conf\": {\n      \"repl_threads\": 16,\n      \"repl_batch\": 100\n    },\n    \"source_conf\": [\n      {\n        \"source_name\": \"mysql-replica-01\",\n        \"binlog_name\": \"binlog.000001\",\n        \"binlog_pos\": 4,\n        \"binlog_gtid\": \"03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170\"\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Database Schema using SQL\nDESCRIPTION: Creates a database schema and a table with specific constraints using SQL. The schema `example` and table `t` are created with a primary key and a unique non-null VARCHAR column.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n\"mkdir example && cd example\\n\\necho 'CREATE SCHEMA example;' > example-schema-create.sql\\necho 'CREATE TABLE t(a TINYINT PRIMARY KEY, b VARCHAR(12) NOT NULL UNIQUE);' > example.t-schema.sql\"\n```\n\n----------------------------------------\n\nTITLE: Querying Data from TiDB with node-mysql2 in JavaScript\nDESCRIPTION: Shows how to query a single Player record by ID from the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysql2.md#2025-04-18_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nconst [rows] = await conn.query('SELECT id, coins, goods FROM players WHERE id = ?;', [1]);\nconsole.log(rows[0]);\n```\n\n----------------------------------------\n\nTITLE: Executing Hash Join Query with EXPLAIN in TiDB\nDESCRIPTION: Example of a hash join query using the HASH_JOIN hint between tables t1 and t2, showing how to view the execution plan using EXPLAIN.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ HASH_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Creating a table and explaining a select query in TiDB\nDESCRIPTION: This code snippet demonstrates how to create a simple table, insert data into it, and then use the `EXPLAIN` statement to view the query execution plan for a `SELECT` statement. The `EXPLAIN` statement provides insights into how TiDB intends to execute the query, including the indexes used and the order of operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (id INT NOT NULL PRIMARY KEY auto_increment, a INT NOT NULL, pad1 VARCHAR(255), INDEX(a));\nINSERT INTO t VALUES (1, 1, 'aaa'),(2,2, 'bbb');\nEXPLAIN SELECT * FROM t WHERE a = 1;\n```\n\n----------------------------------------\n\nTITLE: Explain Query with use_index hint and error\nDESCRIPTION: This SQL code demonstrates the use of the `use_index` hint with a multi-valued index and shows that it might return an error due to limitations in the implementation. The query attempts to select rows from table `t3` where conditions involving `member of` operator are met.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nmysql> EXPLAIN SELECT /*+ use_index(t3, idx) */ * FROM t3 WHERE ((1 member of (j)) AND (2 member of (j))) OR ((3 member of (j)) AND (4 member of (j)));\nERROR 1815 (HY000): Internal : Cant find a proper physical plan for this query\n```\n\n----------------------------------------\n\nTITLE: Deleting Data with MyBatis in XML\nDESCRIPTION: This XML configuration defines a mapper for deleting player data from a TiDB database using MyBatis. It includes a delete statement to remove a player record based on the primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-mybatis.md#2025-04-18_snippet_6\n\nLANGUAGE: XML\nCODE:\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.pingcap.model.PlayerMapper\">\n    <delete id=\"deleteByPrimaryKey\" parameterType=\"java.lang.String\">\n    delete from player\n    where id = #{id,jdbcType=VARCHAR}\n    </delete>\n</mapper>\n```\n\n----------------------------------------\n\nTITLE: Configuring MyBatis for TiDB Connection\nDESCRIPTION: XML configuration for MyBatis to connect to TiDB. It sets up the database connection pool and transaction manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-mybatis.md#2025-04-18_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n        PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n<configuration>\n    <settings>\n        <setting name=\"cacheEnabled\" value=\"true\"/>\n        <setting name=\"lazyLoadingEnabled\" value=\"false\"/>\n        <setting name=\"aggressiveLazyLoading\" value=\"true\"/>\n        <setting name=\"logImpl\" value=\"LOG4J\"/>\n    </settings>\n\n    <environments default=\"development\">\n        <environment id=\"development\">\n            <!-- JDBC transaction manager -->\n            <transactionManager type=\"JDBC\"/>\n            <!-- Database pool -->\n            <dataSource type=\"POOLED\">\n                <property name=\"driver\" value=\"com.mysql.cj.jdbc.Driver\"/>\n                <property name=\"url\" value=\"${tidb_jdbc_url}\"/>\n                <property name=\"username\" value=\"${tidb_user}\"/>\n                <property name=\"password\" value=\"${tidb_password}\"/>\n            </dataSource>\n        </environment>\n    </environments>\n    <mappers>\n        <mapper resource=\"${mapper_location}.xml\"/>\n    </mappers>\n</configuration>\n```\n\n----------------------------------------\n\nTITLE: Configuring Sync Processing Unit - YAML\nDESCRIPTION: This snippet details the settings for the sync processing unit, including the worker count for applying binlogs, batch size for SQL statements, and options for safe mode operation and statement compaction during data migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/task-configuration-file-full.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nsyncers:\n  global:                            # The configuration name of the processing unit.\n    worker-count: 16                 # The number of concurrent threads that apply binlogs which have been transferred to the local (16 by default).\n    batch: 100                       # The number of SQL statements in a transaction batch that the sync processing unit replicates to the downstream database (100 by default).\n    enable-ansi-quotes: true         # Enable this argument if `sql-mode: \"ANSI_QUOTES\"` is set in the `session`\n    safe-mode: false\n    safe-mode-duration: \"60s\"\n    compact: false\n    multiple-rows: true\n```\n\n----------------------------------------\n\nTITLE: Complex Query with Member Of Operator and Multiple OR Conditions\nDESCRIPTION: Example showing how TiDB handles a complex query with the MEMBER OF operator when multiple OR conditions are combined with AND. In this case, TiDB cannot fully optimize all conditions simultaneously.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t6, idx, idx2) */ * FROM t6 WHERE a=1 AND (1 member of (j) OR 2 member of (k)) and (b = 1 OR b = 2);\nEXPLAIN SELECT /*+ use_index_merge(t6, idx, idx2) */ * FROM t6 WHERE a=1 AND ((1 member of (j) AND b = 1) OR (1 member of (j) AND b = 2) OR (2 member of (k) AND b = 1) OR (2 member of (k) AND b = 2));\n```\n\n----------------------------------------\n\nTITLE: Performing K-Nearest Neighbor Vector Search\nDESCRIPTION: Python code that performs a top-3 nearest neighbor search based on cosine distance between document embeddings and a query vector.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nwith Session(engine) as session:\n   distance = Document.embedding.cosine_distance([1, 2, 3]).label('distance')\n   results = session.query(\n      Document, distance\n   ).order_by(distance).limit(3).all()\n```\n\n----------------------------------------\n\nTITLE: Using EXPLAIN for analyzing a COUNT query in TiDB SQL\nDESCRIPTION: This SQL example uses EXPLAIN to analyze how TiDB would process a query that counts trips from a specific date range in the bikeshare database. The query helps understand the execution plan before actually running the query.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT count(*) FROM trips WHERE start_date BETWEEN '2017-07-01 00:00:00' AND '2017-07-01 23:59:59';\n```\n\n----------------------------------------\n\nTITLE: Implementing Transaction Helper Functions in Go\nDESCRIPTION: This Go code snippet defines helper functions for managing transactions in a Go application. It includes error handling for common transaction-related errors and a function to run transactions with retry logic for optimistic transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_3\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n    \"context\"\n    \"database/sql\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/go-sql-driver/mysql\"\n    \"github.com/pingcap-inc/tidb-example-golang/util\"\n    \"github.com/shopspring/decimal\"\n)\n\ntype TxnFunc func(txn *util.TiDBSqlTx) error\n\nconst (\n    ErrWriteConflict      = 9007 // Transactions in TiKV encounter write conflicts.\n    ErrInfoSchemaChanged  = 8028 // table schema changes\n    ErrForUpdateCantRetry = 8002 // \"SELECT FOR UPDATE\" commit conflict\n    ErrTxnRetryable       = 8022 // The transaction commit fails and has been rolled back\n)\n\nconst retryTimes = 5\n\nvar retryErrorCodeSet = map[uint16]interface{}{\n    ErrWriteConflict:      nil,\n    ErrInfoSchemaChanged:  nil,\n    ErrForUpdateCantRetry: nil,\n    ErrTxnRetryable:       nil,\n}\n\nfunc runTxn(db *sql.DB, optimistic bool, optimisticRetryTimes int, txnFunc TxnFunc) {\n    txn, err := util.TiDBSqlBegin(db, !optimistic)\n    if err != nil {\n        panic(err)\n    }\n\n    err = txnFunc(txn)\n    if err != nil {\n        txn.Rollback()\n        if mysqlErr, ok := err.(*mysql.MySQLError); ok && optimistic && optimisticRetryTimes != 0 {\n            if _, retryableError := retryErrorCodeSet[mysqlErr.Number]; retryableError {\n                fmt.Printf(\"[runTxn] got a retryable error, rest time: %d\\n\", optimisticRetryTimes-1)\n                runTxn(db, optimistic, optimisticRetryTimes-1, txnFunc)\n                return\n            }\n        }\n\n\n```\n\n----------------------------------------\n\nTITLE: Creating and Analyzing a Table\nDESCRIPTION: This SQL snippet creates a table named `t1`, inserts data into it, analyzes the table statistics using `ANALYZE TABLE`, and then displays the health of the statistics using `SHOW STATS_HEALTHY`. The expected output after analyzing the table is 100% health.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-healthy.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE TABLE t1 (\\n id INT NOT NULL PRIMARY KEY auto_increment,\\n b INT NOT NULL,\\n pad VARBINARY(255),\\n INDEX(b)\\n);\\n\\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM dual;\\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\\nSELECT SLEEP(1);\\nANALYZE TABLE t1;\\nSHOW STATS_HEALTHY; # should be 100% healthy\"\n```\n\n----------------------------------------\n\nTITLE: Primary Key Constraint Examples\nDESCRIPTION: Shows various scenarios of primary key constraint usage including single column, nullable columns, multiple primary keys, and composite keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (a INT NOT NULL PRIMARY KEY);\n\nCREATE TABLE t2 (a INT NULL PRIMARY KEY);\n\nCREATE TABLE t3 (a INT NOT NULL PRIMARY KEY, b INT NOT NULL PRIMARY KEY);\n\nCREATE TABLE t4 (a INT NOT NULL, b INT NOT NULL, PRIMARY KEY (a,b));\n```\n\n----------------------------------------\n\nTITLE: Performing Vector Search with Distance Threshold\nDESCRIPTION: Python code that searches for documents whose cosine distance from the query vector is less than a specified threshold of 0.2.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nwith Session(engine) as session:\n    distance = Document.embedding.cosine_distance([1, 2, 3]).label('distance')\n    results = session.query(\n        Document, distance\n    ).filter(distance < 0.2).order_by(distance).limit(3).all()\n```\n\n----------------------------------------\n\nTITLE: Downloading and Extracting Bikeshare Data with Bash\nDESCRIPTION: This script creates a directory for the data, downloads the Capital Bikeshare trip data ZIP files for years 2010-2017, and extracts all files. The process requires approximately 3GB of disk space.\nSOURCE: https://github.com/pingcap/docs/blob/master/import-example-data.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p bikeshare-data && cd bikeshare-data\n\ncurl -L --remote-name-all https://s3.amazonaws.com/capitalbikeshare-data/{2010..2017}-capitalbikeshare-tripdata.zip\nunzip \\*-tripdata.zip\n```\n\n----------------------------------------\n\nTITLE: Granting INSERT, UPDATE, DELETE Privileges to a Role in TiDB\nDESCRIPTION: This snippet demonstrates how to grant `INSERT`, `UPDATE`, and `DELETE` privileges on the `app_db` database to the `app_write` role.  This allows users with the `app_write` role to modify data within the specified database. The user executing this statement needs appropriate grant privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nGRANT INSERT, UPDATE, DELETE ON app_db.* TO 'app_write'@'%';\n```\n\n----------------------------------------\n\nTITLE: Querying Table Statistics Metadata in TiDB\nDESCRIPTION: This SQL query shows metadata about table statistics for a specific table named 'T2' using the SHOW STATS_META statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW STATS_META WHERE table_name='T2'\\G;\n```\n\n----------------------------------------\n\nTITLE: Performing CRUD Operations with Prisma Client\nDESCRIPTION: Execute insert, query, and delete operations using Prisma Client with the TiDB Cloud adapter.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-prisma-example.md#2025-04-18_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n// Insert\nconst user = await prisma.user.create({\n  data: {\n    email: 'test@pingcap.com',\n    name: 'test',\n  },\n})\nconsole.log(user)\n\n// Query\nconsole.log(await prisma.user.findMany())\n\n// Delete\nawait prisma.user.delete({\n   where: {\n      id: user.id,\n   },\n})\n```\n\n----------------------------------------\n\nTITLE: DM Cluster Configuration YAML\nDESCRIPTION: Example YAML configuration for deploying a DM cluster with 3 master nodes, 3 worker nodes, and monitoring components. Includes global settings and server-specific configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nglobal:\n  user: \"tidb\"\n  ssh_port: 22\n  deploy_dir: \"/dm-deploy\"\n  data_dir: \"/dm-data\"\n\nserver_configs:\n  master:\n    log-level: info\n  worker:\n    log-level: info\n\nmaster_servers:\n  - host: 10.0.1.11\n    name: master1\n    ssh_port: 22\n    port: 8261\n    config:\n      log-level: info\n  - host: 10.0.1.18\n    name: master2\n    ssh_port: 22\n    port: 8261\n  - host: 10.0.1.19\n    name: master3\n    ssh_port: 22\n    port: 8261\n\nworker_servers:\n  - host: 10.0.1.12\n    ssh_port: 22\n    port: 8262\n    config:\n      log-level: info\n  - host: 10.0.1.19\n    ssh_port: 22\n    port: 8262\n\nmonitoring_servers:\n  - host: 10.0.1.13\n    ssh_port: 22\n    port: 9090\n\ngrafana_servers:\n  - host: 10.0.1.14\n    port: 3000\n\nalertmanager_servers:\n  - host: 10.0.1.15\n    ssh_port: 22\n    web_port: 9093\n```\n\n----------------------------------------\n\nTITLE: Index Join Query Execution Plan\nDESCRIPTION: Shows an execution plan for an index join operation between tables t1 and t2. The plan includes table scans, index lookups, and detailed performance metrics including timing, memory usage, and data access patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------------+----------+---------+-----------+------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+-----------+------+\n| id                               | estRows  | actRows | task      | access object                | execution info                                                                                                                                                                                                                                                                                                                                                               | operator info                                                                                                             | memory    | disk |\n+----------------------------------+----------+---------+-----------+------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+-----------+------+\n| IndexJoin_12                     | 90000.00 | 0       | root      |                              | time:65.6ms, loops:1, inner:{total:129.7ms, concurrency:5, task:7, construct:7.13ms, fetch:122.5ms, build:16.4µs}, probe:2.54ms                                                                                                                                                                                                                                              | inner join, inner:IndexLookUp_11, outer key:test.t1.id, inner key:test.t2.t1_id, equal cond:eq(test.t1.id, test.t2.t1_id) | 28.7 MB   | N/A  |\n| ├─TableReader_33(Build)          | 9955.54  | 10000   | root      |                              | time:15.4ms, loops:16, cop_task: {num: 11, max: 1.52ms, min: 211.5µs, avg: 416.8µs, p95: 1.52ms, rpc_num: 11, rpc_time: 4.36ms, copr_cache_hit_ratio: 1.00, distsql_concurrency: 15}                                                                                                                                                                                         | data:Selection_32                                                                                                         | 13.9 MB   | N/A  |\n| │ └─Selection_32                 | 9955.54  | 10000   | cop[tikv] |                              | tikv_task:{proc max:104ms, min:3ms, avg: 24.4ms, p80:33ms, p95:104ms, iters:113, tasks:11}, scan_detail: {get_snapshot_time: 185µs, rocksdb: {block: {}}}                                                                                                                                                                                                                    | eq(test.t1.int_col, 1)                                                                                                    | N/A       | N/A  |\n| │   └─TableFullScan_31           | 71010.00 | 71010   | cop[tikv] | table:t1                     | tikv_task:{proc max:101ms, min:3ms, avg: 23.8ms, p80:33ms, p95:101ms, iters:113, tasks:11}                                                                                                                                                                                                                                                                                   | keep order:false                                                                                                          | N/A       | N/A  |\n| └─IndexLookUp_11(Probe)          | 90000.00 | 0       | root      |                              | time:115.6ms, loops:7                                                                                                                                                                                                                                                                                                                                                        |                                                                                                                           | 555 Bytes | N/A  |\n|   ├─IndexRangeScan_9(Build)      | 90000.00 | 0       | cop[tikv] | table:t2, index:t1_id(t1_id) | time:114.3ms, loops:7, cop_task: {num: 7, max: 42ms, min: 1.3ms, avg: 16.2ms, p95: 42ms, tot_proc: 71ms, rpc_num: 7, rpc_time: 113.2ms, copr_cache_hit_ratio: 0.29, distsql_concurrency: 15}, tikv_task:{proc max:37ms, min:0s, avg: 11.3ms, p80:20ms, p95:37ms, iters:7, tasks:7}, scan_detail: {total_keys: 9296, get_snapshot_time: 141.9µs, rocksdb: {block: {cache_hit_count: 18592}}}  | range: decided by [eq(test.t2.t1_id, test.t1.id)], keep order:false                                                       | N/A       | N/A  |\n|   └─TableRowIDScan_10(Probe)     | 90000.00 | 0       | cop[tikv] | table:t2                     |                                                                                                                                                                                                                                                                                                                                                                              | keep order:false                                                                                                          | N/A       | N/A  |\n+----------------------------------+----------+---------+-----------+------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+-----------+------+\n```\n\n----------------------------------------\n\nTITLE: Deleting Data with TypeORM in TypeScript\nDESCRIPTION: This code shows how to delete a Player record by ID using TypeORM. It removes the specified Player from the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nawait this.dataSource.manager.delete(Player, {\n  id: 101\n});\n```\n\n----------------------------------------\n\nTITLE: Batch Update to Avoid Deadlocks\nDESCRIPTION: SQL statement that updates multiple rows in a single operation to avoid deadlocks. This approach reduces the risk of deadlocks by acquiring all necessary locks at once.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-troubleshoot.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE books SET stock=stock-1 WHERE id IN (1, 2);\n```\n\n----------------------------------------\n\nTITLE: Creating Tables with Clustered Indexes in SQL\nDESCRIPTION: Examples of creating tables with explicit CLUSTERED or NONCLUSTERED primary key specifications using different syntax variations.\nSOURCE: https://github.com/pingcap/docs/blob/master/clustered-indexes.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a BIGINT PRIMARY KEY CLUSTERED, b VARCHAR(255));\nCREATE TABLE t (a BIGINT PRIMARY KEY NONCLUSTERED, b VARCHAR(255));\nCREATE TABLE t (a BIGINT KEY CLUSTERED, b VARCHAR(255));\nCREATE TABLE t (a BIGINT KEY NONCLUSTERED, b VARCHAR(255));\nCREATE TABLE t (a BIGINT, b VARCHAR(255), PRIMARY KEY(a, b) CLUSTERED);\nCREATE TABLE t (a BIGINT, b VARCHAR(255), PRIMARY KEY(a, b) NONCLUSTERED);\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with CHECK Constraints in TiDB\nDESCRIPTION: This snippet demonstrates creating a table with multiple CHECK constraints, including named constraints and an unenforced constraint.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a INT CHECK(a > 10) NOT ENFORCED, b INT, c INT, CONSTRAINT c1 CHECK (b > c));\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with GORM in Golang\nDESCRIPTION: Inserts a new Player record into the database using GORM's Create method.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-golang-gorm.md#2025-04-18_snippet_1\n\nLANGUAGE: Go\nCODE:\n```\ndb.Create(&Player{ID: \"id\", Coins: 1, Goods: 1})\n```\n\n----------------------------------------\n\nTITLE: Creating Orders Stream in ksqlDB - SQL\nDESCRIPTION: Defines a ksqlDB stream named `orders` to access the `tidb_tpcc_orders` topic. The stream specifies field names and data types along with Kafka topic and configuration parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_13\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE STREAM orders (o_id INTEGER, o_d_id INTEGER, o_w_id INTEGER, o_c_id INTEGER, o_entry_d STRING, o_carrier_id INTEGER, o_ol_cnt INTEGER, o_all_local INTEGER) WITH (kafka_topic='tidb_tpcc_orders', partitions=3, value_format='AVRO');\n```\n\n----------------------------------------\n\nTITLE: Merging Data into Snowflake Table - SQL\nDESCRIPTION: A `MERGE INTO` SQL statement for synchronizing data from `TEST_ITEM_STREAM` to `TEST_ITEM`. It involves deleting, updating, or inserting records based on change log content.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\n--Merge data into the TEST_ITEM table\nmerge into TEST_ITEM n\n  using\n      -- Query TEST_ITEM_STREAM\n      (SELECT RECORD_METADATA:key as k, RECORD_CONTENT:val as v from TEST_ITEM_STREAM) stm\n      -- Match the stream with table on the condition that i_id is equal\n      on k:i_id = n.i_id\n  -- If the TEST_ITEM table contains a record that matches i_id and v is empty, delete this record\n  when matched and IS_NULL_VALUE(v) = true then\n      delete\n\n  -- If the TEST_ITEM table contains a record that matches i_id and v is not empty, update this record\n  when matched and IS_NULL_VALUE(v) = false then\n      update set n.i_data = v:i_data, n.i_im_id = v:i_im_id, n.i_name = v:i_name, n.i_price = v:i_price\n\n  -- If the TEST_ITEM table does not contain a record that matches i_id, insert this record\n  when not matched then\n      insert\n          (i_data, i_id, i_im_id, i_name, i_price)\n      values\n          (v:i_data, v:i_id, v:i_im_id, v:i_name, v:i_price)\n;\n```\n\n----------------------------------------\n\nTITLE: Range Partitioning by Job Code\nDESCRIPTION: This example demonstrates Range partitioning on the `employees` table using the `job_code` column. The partitions are defined based on job code ranges, grouping employees into regular, office/customer support, and managerial personnel. This allows for efficient querying based on job code categories.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT NOT NULL\n)\n\nPARTITION BY RANGE (job_code) (\n    PARTITION p0 VALUES LESS THAN (100),\n    PARTITION p1 VALUES LESS THAN (1000),\n    PARTITION p2 VALUES LESS THAN (10000)\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Basic TTL\nDESCRIPTION: Creates a table with TTL attribute specifying that data should be deleted 3 months after creation time.\nSOURCE: https://github.com/pingcap/docs/blob/master/time-to-live.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n    id int PRIMARY KEY,\n    created_at TIMESTAMP\n) TTL = `created_at` + INTERVAL 3 MONTH;\n```\n\n----------------------------------------\n\nTITLE: Python Batch Insert Implementation\nDESCRIPTION: Demonstrates batch insertion using Python with MySQLdb. Includes connection handling and batch processing with executemany.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-insert-data.md#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport MySQLdb\nconnection = MySQLdb.connect(\n    host=\"127.0.0.1\",\n    port=4000,\n    user=\"root\",\n    password=\"\",\n    database=\"bookshop\",\n    autocommit=True\n)\n\nwith get_connection(autocommit=True) as connection:\n    with connection.cursor() as cur:\n        player_list = random_player(1919)\n        for idx in range(0, len(player_list), 114):\n            cur.executemany(\"INSERT INTO player (id, coins, goods) VALUES (%s, %s, %s)\", player_list[idx:idx + 114])\n```\n\n----------------------------------------\n\nTITLE: Configuring Physical Import Mode in TiDB Lightning\nDESCRIPTION: A complete TOML configuration file example for executing data import using TiDB Lightning's physical import mode. It demonstrates how to configure logging, data sources, conflict handling strategies, TiKV importer settings, TiDB connection details, and post-import verification options.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-physical-import-mode-usage.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\n# log\nlevel = \"info\"\nfile = \"tidb-lightning.log\"\nmax-size = 128 # MB\nmax-days = 28\nmax-backups = 14\n\n# Checks the cluster minimum requirements before start.\ncheck-requirements = true\n\n[mydumper]\n# The local data source directory or the URI of the external storage. For more information about the URI of the external storage, see https://docs.pingcap.com/tidb/v6.6/backup-and-restore-storages#uri-format.\ndata-source-dir = \"/data/my_database\"\n\n[conflict]\n# Starting from v7.3.0, a new version of strategy is introduced to handle conflicting data. The default value is \"\". Starting from v8.0.0, TiDB Lightning optimizes the conflict strategy for both physical and logical import modes.\n# - \"\": TiDB Lightning does not detect or handle conflicting data. If the source file contains conflicting primary or unique key records, the subsequent step reports an error.\n# - \"error\": when detecting conflicting primary or unique key records in the imported data, TiDB Lightning terminates the import and reports an error.\n# - \"replace\": when encountering conflicting primary or unique key records, TiDB Lightning retains the latest data and overwrites the old data.\n#              The conflicting data are recorded in the `lightning_task_info.conflict_view` view of the target TiDB cluster.\n#              In the `lightning_task_info.conflict_view` view, if the `is_precheck_conflict` field for a row is `0`, it means that the conflicting data recorded in that row is detected by postprocess conflict detection; if the `is_precheck_conflict` field for a row is `1`, it means that conflicting data recorded in that row is detected by pre-import conflict detection.\n#              You can manually insert the correct records into the target table based on your application requirements. Note that the target TiKV must be v5.2.0 or later versions.\nstrategy = \"\"\n# Controls whether to enable pre-import conflict detection, which checks conflicts in data before importing it to TiDB. The default value is false, indicating that TiDB Lightning only checks conflicts after the import. If you set it to true, TiDB Lightning checks conflicts both before and after the import. This parameter can be used only in the physical import mode. In scenarios where the number of conflict records is greater than 1,000,000, it is recommended to set `precheck-conflict-before-import = true` for better performance in conflict detection. In other scenarios, it is recommended to disable it.\n# precheck-conflict-before-import = false\n# threshold = 10000\n# Starting from v8.1.0, there is no need to configure `max-record-rows` manually, because TiDB Lightning automatically assigns the value of `max-record-rows` with the value of `threshold`, regardless of the user input. `max-record-rows` will be deprecated in a future release.\n# max-record-rows = 10000\n\n[tikv-importer]\n# Import mode. \"local\" means using the physical import mode.\nbackend = \"local\"\n\n# The `duplicate-resolution` parameter is deprecated starting from v8.0.0 and will be removed in a future release. For more information, see <https://docs.pingcap.com/tidb/stable/tidb-lightning-physical-import-mode-usage#the-old-version-of-conflict-detection-deprecated-in-v800>.\n# If you set `duplicate-resolution = 'none'` and do not set `conflict.strategy`, TiDB Lightning will automatically assign `\"\"` to `conflict.strategy`. \n# If you set `duplicate-resolution = 'remove'` and do not set `conflict.strategy`, TiDB Lightning will automatically assign \"replace\" to `conflict.strategy` and enable the new version of conflict detection. \n# The method to resolve the conflicting data.\nduplicate-resolution = 'none'\n\n# The directory of local KV sorting.\nsorted-kv-dir = \"./some-dir\"\n\n# Limits the bandwidth in which TiDB Lightning writes data into each TiKV\n# node in the physical import mode. 0 by default, which means no limit.\n# store-write-bwlimit = \"128MiB\"\n\n# Specifies whether Physical Import Mode adds indexes via SQL. The default value is `false`, which means that TiDB Lightning will encode both row data and index data into KV pairs and import them into TiKV together. This mechanism is consistent with that of the historical versions. If you set it to `true`, it means that TiDB Lightning adds indexes via SQL after importing the row data.\n# The benefit of adding indexes via SQL is that you can separately import data and import indexes, and import data more quickly. After the data is imported, even if the indexes fail to be added, it does not affect the consistency of the imported data.\n# add-index-by-sql = false\n\n[tidb]\n# The information of the target cluster. The address of any tidb-server from the cluster.\nhost = \"172.16.31.1\"\nport = 4000\nuser = \"root\"\n# Configure the password to connect to TiDB. Either plaintext or Base64 encoded.\npassword = \"\"\n# Required. Table schema information is fetched from TiDB via this status-port.\nstatus-port = 10080\n# Required. The address of any pd-server from the cluster. Starting from v7.6.0, TiDB supports setting multiple PD addresses.\npd-addr = \"172.16.31.4:2379,56.78.90.12:3456\"\n# tidb-lightning imports the TiDB library, and generates some logs.\n# Set the log level of the TiDB library.\nlog-level = \"error\"\n\n[post-restore]\n# Specifies whether to perform `ADMIN CHECKSUM TABLE <table>` for each table to verify data integrity after importing.\n# The following options are available:\n# - \"required\" (default): Perform admin checksum after importing. If checksum fails, TiDB Lightning will exit with failure.\n# - \"optional\": Perform admin checksum. If checksum fails, TiDB Lightning will report a WARN log but ignore any error.\n# - \"off\": Do not perform checksum after importing.\n# Note that since v4.0.8, the default value has changed from \"true\" to \"required\".\n#\n# Note:\n# 1. Checksum failure usually means import exception (data loss or data inconsistency), so it is recommended to always enable Checksum.\n# 2. For backward compatibility, bool values \"true\" and \"false\" are also allowed for this field.\n# \"true\" is equivalent to \"required\" and \"false\" is equivalent to \"off\".\nchecksum = \"required\"\n\n# Specifies whether to perform `ANALYZE TABLE <table>` for each table after checksum is done.\n# Options available for this field are the same as `checksum`. However, the default value for this field is \"optional\".\nanalyze = \"optional\"\n```\n\n----------------------------------------\n\nTITLE: Defining Server Configuration for TiDB and TiKV\nDESCRIPTION: This YAML snippet details the 'server_configs' for TiDB and TiKV within a TiUP cluster. It sets TiDB parameters such as lease duration and token limit, and TiKV parameters like log level and minimum thread count. The 'server_configs' section is crucial for service-specific settings, allowing configurations to be overwritten by instance-specific settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  tidb:\n    lease: \"45s\"\n    split-table: true\n    token-limit: 1000\n    instance.tidb_enable_ddl: true\n  tikv:\n    log-level: \"info\"\n    readpool.unified.min-thread-count: 1\n\n```\n\n----------------------------------------\n\nTITLE: Demonstrating SQL Comparison Operators\nDESCRIPTION: This snippet showcases various SQL comparison operators including BETWEEN, COALESCE, equality, inequality, and NULL checks. It demonstrates the syntax and usage of these operators in SQL queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/operators.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM table WHERE column BETWEEN 1 AND 10;\nSELECT COALESCE(column1, column2, 'default') FROM table;\nSELECT * FROM table WHERE column = 'value';\nSELECT * FROM table WHERE column <=> NULL;\nSELECT * FROM table WHERE column > 100;\nSELECT GREATEST(column1, column2, column3) FROM table;\nSELECT * FROM table WHERE column IN (1, 2, 3);\nSELECT * FROM table WHERE column IS NULL;\nSELECT * FROM table WHERE column LIKE 'pattern%';\nSELECT * FROM table WHERE column ILIKE 'pattern%';\n```\n\n----------------------------------------\n\nTITLE: Java Implementation of Books with Ratings Query\nDESCRIPTION: Java method that executes a LEFT JOIN query to get latest books with their average ratings. Handles NULL ratings for unrated books.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-join-tables.md#2025-04-18_snippet_3\n\nLANGUAGE: java\nCODE:\n```\npublic List<Book> getLatestBooksWithAverageScore() throws SQLException {\n    List<Book> books = new ArrayList<>();\n    try (Connection conn = ds.getConnection()) {\n        Statement stmt = conn.createStatement();\n        ResultSet rs = stmt.executeQuery(\"\"\"\n        SELECT b.id AS book_id, ANY_VALUE(b.title) AS book_title, AVG(r.score) AS average_score\n        FROM books b\n        LEFT JOIN ratings r ON b.id = r.book_id\n        GROUP BY b.id\n        ORDER BY b.published_at DESC\n        LIMIT 10;\n        \"\"\");\n        while (rs.next()) {\n            Book book = new Book();\n            book.setId(rs.getLong(\"book_id\"));\n            book.setTitle(rs.getString(\"book_title\"));\n            book.setAverageScore(rs.getFloat(\"average_score\"));\n            books.add(book);\n        }\n    }\n    return books;\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-line SQL Insert Statement\nDESCRIPTION: Demonstrates how to insert multiple rows of data in a single SQL statement. This method is generally faster than executing multiple single-line insertions.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-insert-data.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO `player` (`id`, `coins`, `goods`) VALUES (1, 1000, 1), (2, 230, 2), (3, 300, 5);\n```\n\n----------------------------------------\n\nTITLE: Check User Privileges with SQL Statements\nDESCRIPTION: Shows how to use the `SHOW GRANTS` SQL statement to verify what privileges a user has been assigned. This operation helps maintain security by auditing user permissions. Inputs include SQL commands targeting the user of interest, and the output provides a list of user's granted privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/privilege-management.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS FOR 'root'@'%';\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER `rw_user`@`192.168.%`;\nGRANT SELECT ON *.* TO `rw_user`@`192.168.%`;\nGRANT INSERT, UPDATE ON `test`.`write_table` TO `rw_user`@`192.168.%`;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS FOR `rw_user`@`192.168.%`;\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into TiDB with mysql2\nDESCRIPTION: JavaScript code snippet to insert a single 'Player' record into TiDB using mysql2.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nextjs.md#2025-04-18_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nconst [rsh] = await pool.query('INSERT INTO players (coins, goods) VALUES (?, ?);', [100, 100]);\nconsole.log(rsh.insertId);\n```\n\n----------------------------------------\n\nTITLE: Configuring Event Filters in TiCDC (TOML)\nDESCRIPTION: Shows how to set up event filter rules in TiCDC using TOML syntax. Event filters allow filtering out specific DML and DDL events based on various conditions such as event type, SQL pattern, and value expressions.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-filter.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[filter]\n\n[[filter.event-filters]]\nmatcher = [\"test.worker\"]\nignore-event = [\"insert\"]\nignore-sql = [\"^drop\", \"add column\"]\nignore-delete-value-expr = \"name = 'john'\"\nignore-insert-value-expr = \"id >= 100\"\nignore-update-old-value-expr = \"age < 18 or name = 'lili'\"\nignore-update-new-value-expr = \"gender = 'male' and age > 18\"\n```\n\n----------------------------------------\n\nTITLE: Utilizing Hypothetical Indexes for Query Optimization\nDESCRIPTION: This example shows how to use hypothetical indexes in SQL queries to experiment with index designs without creating physical indexes. It also demonstrates its effect on query execution plans.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a INT, b INT, c INT);\nQuery OK, 0 rows affected (0.02 sec)\n\nEXPLAIN FORMAT='verbose' SELECT a, b FROM t WHERE a=1 AND b=1;\n+-------------------------+----------+------------+-----------+---------------+----------------------------------+\n| id                      | estRows  | estCost    | task      | access object | operator info                    |\n+-------------------------+----------+------------+-----------+---------------+----------------------------------+\n| TableReader_7           | 0.01     | 392133.42  | root      |               | data:Selection_6                 |\n| └─Selection_6           | 0.01     | 5882000.00 | cop[tikv] |               | eq(test.t.a, 1), eq(test.t.b, 1) |\n|   └─TableFullScan_5     | 10000.00 | 4884000.00 | cop[tikv] | table:t       | keep order:false, stats:pseudo   |\n+-------------------------+----------+------------+-----------+---------------+----------------------------------+\n\nEXPLAIN FORMAT='verbose' SELECT /*+ HYPO_INDEX(t, idx_ab, a, b) */ a, b FROM t WHERE a=1 AND b=1;\n+------------------------+---------+---------+-----------+-----------------------------+-------------------------------------------------+\n| id                     | estRows | estCost | task      | access object               | operator info                                   |\n+------------------------+---------+---------+-----------+-----------------------------+-------------------------------------------------+\n| IndexReader_6          | 0.10    | 2.20    | root      |                             | index:IndexRangeScan_5                          |\n| └─IndexRangeScan_5     | 0.10    | 20.35   | cop[tikv] | table:t, index:idx_ab(a, b) | range:[1 1,1 1], keep order:false, stats:pseudo |\n+------------------------+---------+---------+-----------+-----------------------------+-------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Configuring IPTables Rules for TiDB Port Security\nDESCRIPTION: Shell commands to configure iptables rules that restrict access to TiDB ports, allowing only specific ports (4000 and 9000) for external access while maintaining internal component communication.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices-for-security-configuration.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n# Allow internal port communication from the whitelist of component IP addresses\nsudo iptables -A INPUT -s internal IP address range -j ACCEPT\n\n# Only open ports 4000 and 9000 to external users\nsudo iptables -A INPUT -p tcp --dport 4000 -j ACCEPT\nsudo iptables -A INPUT -p tcp --dport 9000 -j ACCEPT\n\n# Deny all other traffic by default\nsudo iptables -P INPUT DROP\n```\n\n----------------------------------------\n\nTITLE: TiDB System Variable Settings Definition\nDESCRIPTION: Documentation of TiDB system variables with their scopes, ranges, and functionalities. Includes settings for GOGC tuning, transaction handling, join operations, and executor concurrency.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_44\n\nLANGUAGE: markdown\nCODE:\n```\n### tidb_gogc_tuner_max_value\n- Scope: GLOBAL\n- Persists to cluster: Yes\n- Type: Integer\n- Default value: `500`\n- Range: `[10, 2147483647]`\n\n### tidb_guarantee_linearizability\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Type: Boolean\n- Default value: `ON`\n\n### tidb_hash_join_concurrency\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Type: Integer\n- Default value: `-1`\n- Range: `[1, 256]`\n- Unit: Threads\n```\n\n----------------------------------------\n\nTITLE: Defining SET Column in TiDB\nDESCRIPTION: Syntax for creating a SET column that can hold multiple predefined string values with example.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSET('value1','value2',...) [CHARACTER SET charset_name] [COLLATE collation_name]\n\n# For example:\nSET('1', '2') NOT NULL\n```\n\n----------------------------------------\n\nTITLE: Using MPP_1PHASE_AGG Hint for MPP Mode Aggregation in SQL\nDESCRIPTION: Uses the MPP_1PHASE_AGG hint to force the optimizer to use the one-phase aggregation algorithm in MPP mode. This hint only takes effect when using TiFlash MPP mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ MPP_1PHASE_AGG() */ COUNT(*) FROM t1, t2 WHERE t1.a > 10 GROUP BY t1.id;\n```\n\n----------------------------------------\n\nTITLE: Setting Placement Rules via SQL Interface in TiDB\nDESCRIPTION: Shows the syntax for creating or altering placement policies in TiDB, allowing users to specify tables and partitions to be scheduled to specific regions, data centers, racks, hosts, or with replica count rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.0.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n[CREATE | ALTER] PLACEMENT POLICY\n```\n\n----------------------------------------\n\nTITLE: Creating and Dropping Databases in TiDB\nDESCRIPTION: Commands for database creation and deletion, including the generic syntax and specific examples with optional parameters like IF NOT EXISTS.\nSOURCE: https://github.com/pingcap/docs/blob/master/basic-sql-operations.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE db_name [options];\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE IF NOT EXISTS samp_db;\n```\n\nLANGUAGE: sql\nCODE:\n```\nDROP DATABASE samp_db;\n```\n\n----------------------------------------\n\nTITLE: Filtering Vector Search Results with Exclusion Criteria in Python\nDESCRIPTION: Demonstrates how to perform a vector search with metadata filters to exclude specific documents. This example filters out documents where the book metadata field equals 'paul_graham'.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.core.vector_stores.types import (\n   MetadataFilter,\n   MetadataFilters,\n)\n\nquery_engine = index.as_query_engine(\n   filters=MetadataFilters(\n      filters=[\n         MetadataFilter(key=\"book\", value=\"paul_graham\", operator=\"!=\"),\n      ]\n   ),\n   similarity_top_k=2,\n)\nresponse = query_engine.query(\"What did the author learn?\")\nprint(textwrap.fill(str(response), 100))\n```\n\n----------------------------------------\n\nTITLE: Creating and Renaming Database User Example\nDESCRIPTION: Complete example showing the process of creating a new user, checking their grants, renaming the user, and verifying the changes. Demonstrates the full workflow of user management operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-rename-user.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser' IDENTIFIED BY 'mypassword';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS FOR 'newuser';\n```\n\nLANGUAGE: sql\nCODE:\n```\nRENAME USER 'newuser' TO 'testuser';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS FOR 'testuser';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS FOR 'newuser';\n```\n\n----------------------------------------\n\nTITLE: ALTER INDEX EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the ALTER INDEX statement, showing the grammar rules for altering table indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-index.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAlterTableStmt\n         ::= 'ALTER' 'IGNORE'? 'TABLE' TableName AlterIndexSpec ( ',' AlterIndexSpec )*\n\nAlterIndexSpec\n         ::= 'ALTER' 'INDEX' Identifier ( 'VISIBLE' | 'INVISIBLE' )\n```\n\n----------------------------------------\n\nTITLE: Searching Nearest Neighbor Documents with Vector Similarity\nDESCRIPTION: Python code for performing a vector search to find the top-3 most similar documents based on cosine distance between document embeddings and a query vector.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-peewee.md#2025-04-18_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndistance = Document.embedding.cosine_distance([1, 2, 3]).alias('distance')\nresults = Document.select(Document, distance).order_by(distance).limit(3)\n```\n\n----------------------------------------\n\nTITLE: Creating a User with IP Restriction in TiDB SQL\nDESCRIPTION: SQL statement to create a new user 'newuser2' that can only log in from IP address 192.168.1.1 in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser2'@'192.168.1.1' IDENTIFIED BY 'newuserpassword';\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Source for DM\nDESCRIPTION: Defines a data source for DM using a YAML configuration file. The snippet enables GTID for binlog pulling if the MySQL server supports it. Necessary parameters include the host, user, and password.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-to-tidb.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nsource-id: \"mysql-01\"\nenable-gtid: true\nfrom:\n  host: \"${host}\"\n  user: \"root\"\n  password: \"${password}\"\n  port: 3306\n```\n\n----------------------------------------\n\nTITLE: Table Row Key Format in TiDB Storage\nDESCRIPTION: Example of how row data keys are encoded in TiDB storage using table_id and row_id, which is essential for understanding region splitting.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_4\n\nLANGUAGE: Go\nCODE:\n```\nt[table_id]_r[row_id]\n```\n\n----------------------------------------\n\nTITLE: Deleting Data from TiDB using MySQL Connector/Python\nDESCRIPTION: This code snippet shows how to delete data from a TiDB database using MySQL Connector/Python. It establishes a connection, creates a cursor, and executes a DELETE statement with a parameterized value.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-mysql-connector.md#2025-04-18_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nwith get_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        player_id = \"1\"\n        cursor.execute(\"DELETE FROM players WHERE id = %s\", (player_id,))\n```\n\n----------------------------------------\n\nTITLE: Creating Database and Table with AI in SQL Editor\nDESCRIPTION: Example of using AI to generate SQL for creating a table and inserting sample data in the TiDB Cloud SQL Editor\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-quickstart.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nuse test;\n\n-- create a new table t with id and name \nCREATE TABLE\n  `t` (`id` INT, `name` VARCHAR(255));\n\n-- add 3 rows \nINSERT INTO\n  `t` (`id`, `name`)\nVALUES\n  (1, 'row1'),\n  (2, 'row2'),\n  (3, 'row3');\n\n-- query all\nSELECT\n  `id`,\n  `name`\nFROM\n  `t`;\n```\n\n----------------------------------------\n\nTITLE: Create Composite Multi-Valued Index\nDESCRIPTION: This snippet shows how to create a composite index that includes a regular column (`name`) and a multi-valued index (`zipcode`). The multi-valued index part can appear in any position in the composite index.  Dependencies include a JSON column and the `CAST` function.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE customers (\n    id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    name CHAR(10),\n    custinfo JSON,\n    INDEX zips(name, (CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)))\n);\n\n```\n\n----------------------------------------\n\nTITLE: Explain MIN query with TableFullScan in TiDB\nDESCRIPTION: This SQL statement demonstrates the use of `TableFullScan` when finding the minimum value of an unindexed column (`pad1`) in a TiDB table (`t1`). The `EXPLAIN` statement reveals that `TableFullScan` is used, requiring a full scan of the table in TiKV, making it less efficient than using an index.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-indexes.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT MIN(pad1) FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Deleting Data from TiDB with Go-MySQL-Driver\nDESCRIPTION: Example of deleting data from a 'player' table using Go-MySQL-Driver. It demonstrates executing a DELETE SQL statement with a parameterized WHERE clause to remove specific records.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-golang-sql-driver.md#2025-04-18_snippet_4\n\nLANGUAGE: Go\nCODE:\n```\nopenDB(\"mysql\", func(db *sql.DB) {\n    deleteSQL = \"DELETE FROM player WHERE id=?\"\n    _, err := db.Exec(deleteSQL, \"id\")\n\n    if err != nil {\n        panic(err)\n    }\n})\n```\n\n----------------------------------------\n\nTITLE: Deleting Data from Player Model using Django ORM in Python\nDESCRIPTION: This snippet shows how to delete data from the Player model using Django ORM. It includes examples of deleting a single object and deleting multiple objects that match a filter condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# delete a single object\nplayer = Player.objects.get(name=\"player1\")\nplayer.delete()\n\n# delete multiple objects\nPlayer.objects.filter(coins=100).delete()\n```\n\n----------------------------------------\n\nTITLE: Importing S&P 500 Dataset for Analysis in TiDB Cloud Serverless SQL\nDESCRIPTION: This SQL snippet is used to retrieve sector-wise analysis of companies from the S&P 500 dataset. It aggregates the data to count companies, total market capitalization, and average revenue growth, ranking them accordingly.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/dev-guide-bi-looker-studio.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT sector,\n        COUNT(*)                                                                      AS companies,\n        ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC )                                   AS companies_ranking,\n        SUM(market_cap)                                                               AS total_market_cap,\n        ROW_NUMBER() OVER (ORDER BY SUM(market_cap) DESC )                            AS total_market_cap_ranking,\n        SUM(revenue_growth * weight) / SUM(weight)                                    AS avg_revenue_growth,\n        ROW_NUMBER() OVER (ORDER BY SUM(revenue_growth * weight) / SUM(weight) DESC ) AS avg_revenue_growth_ranking\n    FROM companies\n        LEFT JOIN index_compositions ic ON companies.stock_symbol = ic.stock_symbol\n    GROUP BY sector\n    ORDER BY 5 ASC;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with List COLUMNS Partitioning by Hire Date in SQL\nDESCRIPTION: This example shows how to create a table 'employees_2' using List COLUMNS partitioning based on the 'hired' column of DATE type. It divides employees into 4 partitions based on their hire week.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_23\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE employees_2 (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT,\n    city VARCHAR(15)\n)\nPARTITION BY LIST COLUMNS(hired) (\n    PARTITION pWeek_1 VALUES IN('2020-02-01', '2020-02-02', '2020-02-03',\n        '2020-02-04', '2020-02-05', '2020-02-06', '2020-02-07'),\n    PARTITION pWeek_2 VALUES IN('2020-02-08', '2020-02-09', '2020-02-10',\n        '2020-02-11', '2020-02-12', '2020-02-13', '2020-02-14'),\n    PARTITION pWeek_3 VALUES IN('2020-02-15', '2020-02-16', '2020-02-17',\n        '2020-02-18', '2020-02-19', '2020-02-20', '2020-02-21'),\n    PARTITION pWeek_4 VALUES IN('2020-02-22', '2020-02-23', '2020-02-24',\n        '2020-02-25', '2020-02-26', '2020-02-27', '2020-02-28')\n);\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with MySQL Shell\nDESCRIPTION: Command to connect to TiDB using MySQL Shell with SQL mode enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connect-to-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nmysqlsh --sql mysql://root@<tidb_server_host>:4000\n```\n\n----------------------------------------\n\nTITLE: Querying Statement Summary Tables for High-Frequency SELECT Statements in SQL\nDESCRIPTION: This SQL query identifies SELECT statements executed more than 10 times in the past two weeks with multiple execution plans and no existing bindings. It generates binding statements for the top 100 high-frequency queries using their fastest execution plans.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nWITH stmts AS (\n  SELECT * FROM INFORMATION_SCHEMA.CLUSTER_STATEMENTS_SUMMARY\n  UNION ALL\n  SELECT * FROM INFORMATION_SCHEMA.CLUSTER_STATEMENTS_SUMMARY_HISTORY \n),\nbest_plans AS (\n  SELECT plan_digest, `digest`, avg_latency, \n  CONCAT('create global binding from history using plan digest \"', plan_digest, '\"') as binding_stmt \n  FROM stmts t1\n  WHERE avg_latency = (SELECT min(avg_latency) FROM stmts t2\n                       WHERE t2.`digest` = t1.`digest`)\n)\n\nSELECT any_value(digest_text) as query, \n       SUM(exec_count) as exec_count, \n       plan_hint, binding_stmt\nFROM stmts, best_plans\nWHERE stmts.`digest` = best_plans.`digest`\n  AND summary_begin_time > DATE_SUB(NOW(), interval 14 day)\n  AND stmt_type = 'Select'\n  AND schema_name NOT IN ('INFORMATION_SCHEMA', 'mysql')\n  AND plan_in_binding = 0\nGROUP BY stmts.`digest`\n  HAVING COUNT(DISTINCT(stmts.plan_digest)) > 1\n         AND SUM(exec_count) > 10\nORDER BY SUM(exec_count) DESC LIMIT 100;\n```\n\n----------------------------------------\n\nTITLE: AWS KMS Key Policy Configuration for TiDB Cloud CMEK\nDESCRIPTION: JSON configuration for AWS KMS key policy to enable TiDB Cloud encryption access with specific permissions for EBS and S3 encryption\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-encrypt-cmek.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Id\": \"cmek-policy\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Allow access through EBS for all principals in the account that are authorized to use EBS\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"*\"\n            },\n            \"Action\": [\n                \"kms:Encrypt\",\n                \"kms:Decrypt\",\n                \"kms:ReEncrypt*\",\n                \"kms:GenerateDataKey*\",\n                \"kms:CreateGrant\",\n                \"kms:DescribeKey\"\n            ],\n            \"Resource\": \"*\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"kms:CallerAccount\": \"<pingcap-account>\",\n                    \"kms:ViaService\": \"ec2.<region>.amazonaws.com\"\n                }\n            }\n        },\n        {\n            \"Sid\": \"Allow TiDB cloud role to use KMS to store encrypted backup to S3\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::<pingcap-account>:root\"\n            },\n            \"Action\": [\n                \"kms:Decrypt\",\n                \"kms:GenerateDataKey\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Using LEADING Hint for Join Order\nDESCRIPTION: Example showing how to use the LEADING hint to control the order of table joins in a multi-table query. The optimizer will join tables in the specified order.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_37\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ LEADING(t1, t2) */ * FROM t1, t2, t3 WHERE t1.id = t2.id and t2.id = t3.id;\n```\n\n----------------------------------------\n\nTITLE: Showing All Tables in a Database in TiDB\nDESCRIPTION: This SQL command lists all tables in the bookshop database, using the SHOW TABLES statement which is compatible with MySQL syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES IN `bookshop`;\n```\n\n----------------------------------------\n\nTITLE: Checking Table Consistency in TiDB SQL\nDESCRIPTION: This SQL snippet demonstrates how to use the ADMIN CHECK TABLE command to check the consistency of all data and corresponding indexes in one or more tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-check-table-index.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN CHECK TABLE tbl_name [, tbl_name] ...;\n```\n\n----------------------------------------\n\nTITLE: Book Type Analysis using Partitioned Window Functions\nDESCRIPTION: Complex SQL query using window functions with PARTITION BY clause to analyze historical ordering trends across different book types. Includes joins and multiple CTEs for data aggregation.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-hybrid-oltp-and-olap-queries.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nWITH orders_group_by_month AS (\n    SELECT\n        b.type AS book_type,\n        DATE_FORMAT(ordered_at, '%Y-%c') AS month,\n        COUNT(*) AS orders\n    FROM orders o\n    LEFT JOIN books b ON o.book_id = b.id\n    WHERE b.type IS NOT NULL\n    GROUP BY book_type, month\n), acc AS (\n    SELECT\n        book_type,\n        month,\n        SUM(orders) OVER(PARTITION BY book_type ORDER BY book_type, month ASC) as acc\n    FROM orders_group_by_month\n    ORDER BY book_type, month ASC\n)\nSELECT * FROM acc;\n```\n\n----------------------------------------\n\nTITLE: DROP DATABASE Example in TiDB SQL\nDESCRIPTION: This SQL example demonstrates how to use the DROP DATABASE statement in TiDB. It shows checking available databases with SHOW DATABASES, dropping the 'test' database, and confirming the database was removed with another SHOW DATABASES query.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-database.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| INFORMATION_SCHEMA |\n| PERFORMANCE_SCHEMA |\n| mysql              |\n| test               |\n+--------------------+\n4 rows in set (0.00 sec)\n\nmysql> DROP DATABASE test;\nQuery OK, 0 rows affected (0.25 sec)\n\nmysql> SHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| INFORMATION_SCHEMA |\n| PERFORMANCE_SCHEMA |\n| mysql              |\n+--------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Importing Data Files from Amazon S3\nDESCRIPTION: This SQL statement imports a data file from an Amazon S3 bucket into a TiDB table.  The URI includes the bucket name, file path, access key, and secret access key. It is important to handle credentials securely.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t FROM 's3://bucket-name/test.csv?access-key=XXX&secret-access-key=XXX';\n```\n\n----------------------------------------\n\nTITLE: Original Slow Query in TiDB\nDESCRIPTION: Initial SQL query with multiple conditions that requires index lookup of 2,597,411 rows and takes 46.4 seconds to execute.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  SUM(`logs`.`amount`)\nFROM\n  `logs`\nWHERE\n  `logs`.`user_id` = 1111\n  AND `logs`.`snapshot_id` IS NULL\n  AND `logs`.`status` IN ('complete', 'failure')\n  AND `logs`.`source_type` != 'online'\n  AND (\n    `logs`.`source_type` IN ('user', 'payment')\n    OR `logs`.`source_type` IN (\n      'bank_account',\n    )\n    AND `logs`.`target_type` IN ('bank_account')\n  );\n```\n\n----------------------------------------\n\nTITLE: CREATE INDEX Example with Query Optimization in TiDB\nDESCRIPTION: Example showing how to create a table, insert data, examine query performance without an index, create an index, and observe the improved query execution plan. It also demonstrates creating a unique index.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\nQuery OK, 0 rows affected (0.10 sec)\n\nmysql> INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5);\nQuery OK, 5 rows affected (0.02 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\nmysql> EXPLAIN SELECT * FROM t1 WHERE c1 = 3;\n+-------------------------+----------+-----------+---------------+--------------------------------+\n| id                      | estRows  | task      | access object | operator info                  |\n+-------------------------+----------+-----------+---------------+--------------------------------+\n| TableReader_7           | 10.00    | root      |               | data:Selection_6               |\n| └─Selection_6           | 10.00    | cop[tikv] |               | eq(test.t1.c1, 3)              |\n|   └─TableFullScan_5     | 10000.00 | cop[tikv] | table:t1      | keep order:false, stats:pseudo |\n+-------------------------+----------+-----------+---------------+--------------------------------+\n3 rows in set (0.00 sec)\n\nmysql> CREATE INDEX c1 ON t1 (c1);\nQuery OK, 0 rows affected (0.30 sec)\n\nmysql> EXPLAIN SELECT * FROM t1 WHERE c1 = 3;\n+------------------------+---------+-----------+------------------------+---------------------------------------------+\n| id                     | estRows | task      | access object          | operator info                               |\n+------------------------+---------+-----------+------------------------+---------------------------------------------+\n| IndexReader_6          | 10.00   | root      |                        | index:IndexRangeScan_5                      |\n| └─IndexRangeScan_5     | 10.00   | cop[tikv] | table:t1, index:c1(c1) | range:[3,3], keep order:false, stats:pseudo |\n+------------------------+---------+-----------+------------------------+---------------------------------------------+\n2 rows in set (0.00 sec)\n\nmysql> ALTER TABLE t1 DROP INDEX c1;\nQuery OK, 0 rows affected (0.30 sec)\n\nmysql> CREATE UNIQUE INDEX c1 ON t1 (c1);\nQuery OK, 0 rows affected (0.31 sec)\n```\n\n----------------------------------------\n\nTITLE: Explaining Primary Key Query Execution Plan in TiDB\nDESCRIPTION: This EXPLAIN statement shows the execution plan for the primary key query, revealing the use of a Point_Get operation for optimal performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM books WHERE id = 896;\n```\n\n----------------------------------------\n\nTITLE: Binding Session to Resource Group in SQL - TiDB\nDESCRIPTION: The snippet demonstrates how to bind the current session to a specified resource group in TiDB. This binding limits the resource usage of the session according to the defined quotas. The prerequisite is having the necessary privileges when the strict mode is enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-ru-groups.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSET RESOURCE GROUP rg1;\n```\n\n----------------------------------------\n\nTITLE: Checking TiFlash Replica Progress in SQL\nDESCRIPTION: These SQL queries check the progress of TiFlash replicas for the 'books' and 'orders' tables in the 'bookshop' schema. The PROGRESS and AVAILABLE columns indicate completion status and availability.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-hybrid-oltp-and-olap-queries.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = 'bookshop' and TABLE_NAME = 'books';\nSELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = 'bookshop' and TABLE_NAME = 'orders';\n```\n\n----------------------------------------\n\nTITLE: Deploying a TiDB Cluster\nDESCRIPTION: This snippet explains how to deploy a TiDB cluster using the `tiup cluster deploy` command. Users must provide the cluster name, version, and topology file.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster deploy <cluster-name> <version> <topology.yaml> [flags]\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster deploy -p prod-cluster v8.5.0 /tmp/topology.yaml\n```\n\nLANGUAGE: bash\nCODE:\n```\nPlease confirm your topology:\nTiDB Cluster: prod-cluster\nTiDB Version: v8.5.0\nType        Host          Ports                            OS/Arch       Directories\n----        ----          -----                            -------       -----------\npd          172.16.5.134  2379/2380                        linux/x86_64  deploy/pd-2379,data/pd-2379\npd          172.16.5.139  2379/2380                        linux/x86_64  deploy/pd-2379,data/pd-2379\npd          172.16.5.140  2379/2380                        linux/x86_64  deploy/pd-2379,data/pd-2379\ntiproxy     172.16.5.144  6000/3080                        linux/x86_64  deploy/tiproxy-6000\ntikv        172.16.5.134  20160/20180                      linux/x86_64  deploy/tikv-20160,data/tikv-20160\ntikv        172.16.5.139  20160/20180                      linux/x86_64  deploy/tikv-20160,data/tikv-20160\ntikv        172.16.5.140  20160/20180                      linux/x86_64  deploy/tikv-20160,data/tikv-20160\ntidb        172.16.5.134  4000/10080                       linux/x86_64  deploy/tidb-4000\ntidb        172.16.5.139  4000/10080                       linux/x86_64  deploy/tidb-4000\ntidb        172.16.5.140  4000/10080                       linux/x86_64  deploy/tidb-4000\ntiflash     172.16.5.141  9000/8123/3930/20170/20292/8234  linux/x86_64  deploy/tiflash-9000,data/tiflash-9000\ntiflash     172.16.5.142  9000/8123/3930/20170/20292/8234  linux/x86_64  deploy/tiflash-9000,data/tiflash-9000\ntiflash     172.16.5.143  9000/8123/3930/20170/20292/8234  linux/x86_64  deploy/tiflash-9000,data/tiflash-9000\nprometheus  172.16.5.134  9090         deploy/prometheus-9090,data/prometheus-9090\ngrafana     172.16.5.134  3000         deploy/grafana-3000\nAttention:\n    1. If the topology is not what you expected, check your yaml file.\n    2. Please confirm there is no port/directory conflicts in same host.\nDo you want to continue? [y/N]:\n```\n\n----------------------------------------\n\nTITLE: Optimizing Multiple Max/Min Functions Query in SQL\nDESCRIPTION: Example of how TiDB optimizes a query with multiple max/min functions. The original query is rewritten as a Cartesian product of two subqueries, each optimized for a single max/min function.\nSOURCE: https://github.com/pingcap/docs/blob/master/max-min-eliminate.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nselect max(a) - min(a) from t\n```\n\nLANGUAGE: sql\nCODE:\n```\nselect max_a - min_a\nfrom\n    (select max(a) as max_a from t) t1,\n    (select min(a) as min_a from t) t2\n```\n\nLANGUAGE: sql\nCODE:\n```\nselect max_a - min_a\nfrom\n    (select max(a) as max_a from (select a from t where a is not null order by a desc limit 1) t) t1,\n    (select min(a) as min_a from (select a from t where a is not null order by a asc limit 1) t) t2\n```\n\n----------------------------------------\n\nTITLE: BOOLEAN Type Declaration in SQL\nDESCRIPTION: Syntax for declaring BOOLEAN type which is equivalent to TINYINT(1)\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-numeric.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nBOOLEAN\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning for Parallel Import\nDESCRIPTION: Configuration file for TiDB Lightning to enable parallel import with detailed settings for data source, backend, and storage paths\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-distributed-import.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\nstatus-addr = \":8289\"\n\n[mydumper]\ndata-source-dir = \"/path/to/source-dir\"\n\n[tikv-importer]\nparallel-import = true\nbackend = \"local\"\nsorted-kv-dir = \"/path/to/sorted-dir\"\n```\n\n----------------------------------------\n\nTITLE: CREATE SEQUENCE SQL Syntax\nDESCRIPTION: SQL syntax for creating a sequence in TiDB with optional parameters for customization.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-sequence.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE [TEMPORARY] SEQUENCE [IF NOT EXISTS] sequence_name\n    [ INCREMENT [ BY | = ] increment ]\n    [ MINVALUE [=] minvalue | NO MINVALUE | NOMINVALUE ]\n    [ MAXVALUE [=] maxvalue | NO MAXVALUE | NOMAXVALUE ]\n    [ START [ WITH | = ] start ]\n    [ CACHE [=] cache | NOCACHE | NO CACHE]\n    [ CYCLE | NOCYCLE | NO CYCLE]\n    [table_options]\n```\n\n----------------------------------------\n\nTITLE: Querying Aurora Binlog Position\nDESCRIPTION: This SQL command is used to get the current binlog position in Aurora, which is needed for incremental migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW MASTER STATUS;\n```\n\n----------------------------------------\n\nTITLE: Using NO_MERGE_JOIN Optimizer Hint - SQL\nDESCRIPTION: Demonstrates how to use the NO_MERGE_JOIN optimizer hint to instruct the optimizer to avoid using the sort-merge join strategy for the specified tables, allowing for greater control over the join methods utilized in the query.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ NO_MERGE_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Checking TiFlash Replica Status for Tables in TiDB\nDESCRIPTION: This SQL query retrieves the status of TiFlash replicas for a specific table or all tables in a database. It shows availability and replication progress.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = '<db_name>' and TABLE_NAME = '<table_name>';\n```\n\n----------------------------------------\n\nTITLE: Exporting MySQL Data with Dumpling\nDESCRIPTION: Example command to export data from MySQL using Dumpling. It specifies the host, port, user, threads, file size, database, and output directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/get-started-with-tidb-lightning.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup dumpling -h 127.0.0.1 -P 3306 -u root -t 16 -F 256MB -B test -f 'test.t[12]' -o /data/my_database/\n```\n\n----------------------------------------\n\nTITLE: Creating an Index on the 'published_at' Column in TiDB\nDESCRIPTION: SQL statement to create an index named 'idx_book_published_at' on the 'published_at' column of the 'books' table to optimize queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-secondary-indexes.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX `idx_book_published_at` ON `bookshop`.`books` (`bookshop`.`books`.`published_at`);\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into TiDB (TypeScript)\nDESCRIPTION: Inserts a single Player record into the database and returns the insert ID. Uses a prepared statement to prevent SQL injection.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst [rsh] = await pool.query('INSERT INTO players (coins, goods) VALUES (?, ?);', [100, 100]);\nconsole.log(rsh.insertId);\n```\n\n----------------------------------------\n\nTITLE: Adding TiDB-JDBC Maven Dependency\nDESCRIPTION: Maven configuration for adding the TiDB-JDBC connector dependency to a Java project.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-choose-driver-or-orm.md#2025-04-18_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>io.github.lastincisor</groupId>\n  <artifactId>mysql-connector-java</artifactId>\n  <version>8.0.29-tidb-1.0.0</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Querying with JSON Overlap and IndexMerge in TiDB\nDESCRIPTION: These EXPLAIN statements demonstrate how TiDB uses IndexMerge for queries with JSON_OVERLAPS functions on multi-valued indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1) */ * FROM t4 WHERE json_overlaps(j->'$.a', '[1, 2]') OR json_overlaps(j->'$.a', '[3, 4]');\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1) */ * FROM t4 WHERE json_overlaps(j->'$.a', '[1, 2]') OR json_length(j->'$.a') = 3;\nSHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with mysql2 in Next.js\nDESCRIPTION: JavaScript code to establish a connection pool to TiDB using mysql2 with environment variables for configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nextjs.md#2025-04-18_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n// src/lib/tidb.js\nimport mysql from 'mysql2';\n\nlet pool = null;\n\nexport function connect() {\n  return mysql.createPool({\n    host: process.env.TIDB_HOST, // TiDB host, for example: {gateway-region}.aws.tidbcloud.com\n    port: process.env.TIDB_PORT || 4000, // TiDB port, default: 4000\n    user: process.env.TIDB_USER, // TiDB user, for example: {prefix}.root\n    password: process.env.TIDB_PASSWORD, // The password of TiDB user.\n    database: process.env.TIDB_DATABASE || 'test', // TiDB database name, default: test\n    ssl: {\n      minVersion: 'TLSv1.2',\n      rejectUnauthorized: true,\n    },\n    connectionLimit: 1, // Setting connectionLimit to \"1\" in a serverless function environment optimizes resource usage, reduces costs, ensures connection stability, and enables seamless scalability.\n    maxIdle: 1, // max idle connections, the default value is the same as `connectionLimit`\n    enableKeepAlive: true,\n  });\n}\n\nexport function getPool() {\n  if (!pool) {\n    pool = createPool();\n  }\n  return pool;\n}\n```\n\n----------------------------------------\n\nTITLE: Semantic Search Results Output\nDESCRIPTION: Sample output showing the results of the semantic search query, displaying matched terms and their vector distances. The results demonstrate how the system finds conceptually related terms like 'fish' for a query about swimming animals.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-python.md#2025-04-18_snippet_7\n\nLANGUAGE: plain\nCODE:\n```\nSearch result (\"a swimming animal\"):\n- text: \"fish\", distance: 0.4562914811223072\n- text: \"dog\", distance: 0.6469335836410557\n- text: \"tree\", distance: 0.798545178640937\n```\n\n----------------------------------------\n\nTITLE: Create Multi-Valued Index\nDESCRIPTION: This snippet demonstrates how to create a multi-valued index using the `CAST(... AS ... ARRAY)` function in the index definition. The index is created on a JSON column, extracting the 'zipcode' array as unsigned integers. Dependencies include a JSON column and the `CAST` function.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE customers (\n    id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    name CHAR(10),\n    custinfo JSON,\n    INDEX zips((CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)))\n);\n\n```\n\n----------------------------------------\n\nTITLE: Querying Books with Primary Key in SQL\nDESCRIPTION: This SQL query demonstrates efficient data retrieval using the primary key 'id' to filter books, resulting in fast execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM books WHERE id = 896;\n```\n\n----------------------------------------\n\nTITLE: Range Partitioning by Timestamp\nDESCRIPTION: This SQL statement creates a table `quarterly_report_status` partitioned by the `report_updated` timestamp column, converted to a Unix timestamp using the `UNIX_TIMESTAMP()` function. This allows for partitioning data based on specific time ranges, which is useful for managing time-series data and historical reports.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE quarterly_report_status (\n    report_id INT NOT NULL,\n    report_status VARCHAR(20) NOT NULL,\n    report_updated TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP\n)\n\nPARTITION BY RANGE ( UNIX_TIMESTAMP(report_updated) ) (\n    PARTITION p0 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-01-01 00:00:00') ),\n    PARTITION p1 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-04-01 00:00:00') ),\n    PARTITION p2 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-07-01 00:00:00') ),\n    PARTITION p3 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-10-01 00:00:00') ),\n    PARTITION p4 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-01-01 00:00:00') ),\n    PARTITION p5 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-04-01 00:00:00') ),\n    PARTITION p6 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-07-01 00:00:00') ),\n    PARTITION p7 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-10-01 00:00:00') ),\n    PARTITION p8 VALUES LESS THAN ( UNIX_TIMESTAMP('2010-01-01 00:00:00') ),\n    PARTITION p9 VALUES LESS THAN (MAXVALUE)\n);\n```\n\n----------------------------------------\n\nTITLE: Optimized Execution Plan\nDESCRIPTION: Execution plan after implementing the covering index, showing improved performance with reduced execution time of 90ms.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------------+------------+---------+-----------+---------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------+\n| id                            | estRows    | actRows | task      | access object                                                                                                                   | execution info                              |\n+-------------------------------+------------+---------+-----------+---------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------+\n| HashAgg_13                    | 1.00       | 1       | root      |                                                                                                                                 | time:90ms, loops:2, RU:158.885311,       ...|\n| └─IndexReader_14              | 1.00       | 1       | root      |                                                                                                                                 | time:89.8ms, loops:2, cop_task: {num: 1, ...|\n|   └─HashAgg_6                 | 1.00       | 1       | cop[tikv] |                                                                                                                                 | tikv_task:{time:88ms, loops:52},         ...|\n|     └─Selection_12            | 5245632.33 | 52863   | cop[tikv] |                                                                                                                                 | tikv_task:{time:80ms, loops:52}          ...|\n|       └─IndexRangeScan_11     | 5245632.33 | 52863   | cop[tikv] | table:logs, index:logs_covered(snapshot_id, user_id, status, source_type, target_type, amount)                                  | tikv_task:{time:60ms, loops:52}          ...|\n+-------------------------------+------------+---------+-----------+---------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB Cloud using Node.js\nDESCRIPTION: This code snippet demonstrates how to execute a query against a TiDB Cloud Dedicated cluster using Node.js's `mysql2` library. It establishes a connection with TLS configured, executes a SELECT DATABASE() query, and prints the database name to the console.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tls-connect-to-dedicated.md#2025-04-18_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\nvar mysql = require('mysql2');\nvar fs = require('fs');\nvar connection = mysql.createConnection({\n  host: 'tidb.srgnqxji5bc.clusters.staging.tidb-cloud.com',\n  port: 4000,\n  user: 'root',\n  password: '<your_password>',\n  database: 'test',\n  ssl: {\n    ca: fs.readFileSync('ca.pem'),\n    minVersion: 'TLSv1.2',\n    rejectUnauthorized: true\n  }\n});\nconnection.connect(function(err) {\n  if (err) {\n    throw err\n  }\n  connection.query('SELECT DATABASE();', function(err, rows) {\n    if (err) {\n      throw err\n    }\n    console.log(rows[0]['DATABASE()']);\n    connection.end()\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Range Partitioned Table to Handle NULL in SQL\nDESCRIPTION: This SQL snippet shows how to create a Range partitioned table and demonstrates how NULL values are handled in Range partitioning.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_33\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t1 (\n    c1 INT,\n    c2 VARCHAR(20)\n)\n\nPARTITION BY RANGE(c1) (\n    PARTITION p0 VALUES LESS THAN (0),\n    PARTITION p1 VALUES LESS THAN (10),\n    PARTITION p2 VALUES LESS THAN MAXVALUE\n);\n```\n\n----------------------------------------\n\nTITLE: Calculating Cumulative Distribution with CUME_DIST() in SQL\nDESCRIPTION: This snippet demonstrates the use of CUME_DIST() window function to calculate the cumulative distribution of values within a group. It uses a recursive CTE to generate sample data.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/window-functions.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nWITH RECURSIVE cte(n) AS (\n    SELECT 1\n    UNION\n    SELECT\n        n+2\n    FROM\n        cte\n    WHERE\n        n<6\n)\nSELECT\n    *,\n    CUME_DIST() OVER(ORDER BY n)\nFROM\n    cte;\n```\n\n----------------------------------------\n\nTITLE: Stream Aggregation Example Setup in TiDB\nDESCRIPTION: This SQL snippet creates a table `t2` with an `id` and `col1` column, inserts some data, and then uses the `EXPLAIN` statement with the `STREAM_AGG()` hint to force Stream Aggregation for a `GROUP BY` query on `col1`. It shows how Stream Aggregation works before any indexes are added.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-aggregation.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t2 (id INT NOT NULL PRIMARY KEY, col1 INT NOT NULL);\nINSERT INTO t2 VALUES (1, 9),(2, 3),(3,1),(4,8),(6,3);\nEXPLAIN SELECT /*+ STREAM_AGG() */ col1, count(*) FROM t2 GROUP BY col1;\n```\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.11 sec)\n\nQuery OK, 5 rows affected (0.01 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\n+------------------------------+----------+-----------+---------------+---------------------------------------------------------------------------------------------+\n| id                           | estRows  | task      | access object | operator info                                                                               |\n+------------------------------+----------+-----------+---------------+---------------------------------------------------------------------------------------------+\n| Projection_4                 | 8000.00  | root      |               | test.t2.col1, Column#3                                                                      |\n| └─StreamAgg_8                | 8000.00  | root      |               | group by:test.t2.col1, funcs:count(1)->Column#3, funcs:firstrow(test.t2.col1)->test.t2.col1 |\n|   └─Sort_13                  | 10000.00 | root      |               | test.t2.col1                                                                                |\n|     └─TableReader_12         | 10000.00 | root      |               | data:TableFullScan_11                                                                       |\n|       └─TableFullScan_11     | 10000.00 | cop[tikv] | table:t2      | keep order:false, stats:pseudo                                                              |\n+------------------------------+----------+-----------+---------------+---------------------------------------------------------------------------------------------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Retrieving View Information in TiDB SQL\nDESCRIPTION: This snippet shows how to retrieve information about a view using the SHOW CREATE VIEW statement. It displays the creation statement for the book_with_ratings view.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-views.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW CREATE VIEW book_with_ratings\\G\n```\n\n----------------------------------------\n\nTITLE: Fetching Repositories from TiDB Using SQL\nDESCRIPTION: This SQL snippet retrieves all rows from the `test.repository` table, which corresponds to the Data App's endpoint for fetching repository data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-oas-with-nextjs.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test.repository;\n```\n\n----------------------------------------\n\nTITLE: Checking a User's Privileges using a Single Role in TiDB\nDESCRIPTION: This snippet shows how to check the privileges a user has through a specific role using the `SHOW GRANTS ... USING` statement in TiDB.  This statement shows what privileges the user effectively has by virtue of the role. To check privilege-related information of another user, you need the `SELECT` privilege on the `mysql` database.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS FOR 'read_user1'@'localhost' USING 'app_read';\n```\n\n----------------------------------------\n\nTITLE: Deploying DM Cluster Using TiUP Shell Command\nDESCRIPTION: Shell command syntax for deploying a new DM cluster using tiup. Requires cluster name, version number, and topology file as mandatory parameters. Supports optional flags for user authentication and connection settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-deploy.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm deploy <cluster-name> <version> <topology.yaml> [flags]\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Cloud Serverless Connection with Individual Parameters in TypeScript\nDESCRIPTION: This snippet demonstrates how to configure a connection to TiDB Cloud Serverless using individual parameters such as host, username, password, and database. It also sets the arrayMode option to true for better performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = {\n  host: '<host>',\n  username: '<user>',\n  password: '<password>',\n  database: '<database>',\n  arrayMode: true,\n}\n\nconst conn = connect(config)\n```\n\n----------------------------------------\n\nTITLE: Explaining Query Execution Plan in TiDB\nDESCRIPTION: Using the EXPLAIN statement to view the execution plan for the query that selects books published in 2022.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-secondary-indexes.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM `bookshop`.`books` WHERE `published_at` >= '2022-01-01 00:00:00' AND `published_at` < '2023-01-01 00:00:00';\n```\n\n----------------------------------------\n\nTITLE: Demonstrating SQL Rewriting in DM Safe Mode\nDESCRIPTION: Example of how DM rewrites SQL statements in safe mode to ensure idempotency. INSERT statements are changed to REPLACE, and UPDATE statements are split into DELETE and REPLACE operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-safe-mode.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO dummydb.dummytbl (id, int_value, str_value) VALUES (123, 999, 'abc');\nUPDATE dummydb.dummytbl SET int_value = 888999 WHERE int_value = 999;   -- Suppose there is no other record with int_value = 999\nUPDATE dummydb.dummytbl SET id = 999 WHERE id = 888;    -- Update the primary key\n```\n\nLANGUAGE: SQL\nCODE:\n```\nREPLACE INTO dummydb.dummytbl (id, int_value, str_value) VALUES (123, 999, 'abc');\nDELETE FROM dummydb.dummytbl WHERE id = 123;\nREPLACE INTO dummydb.dummytbl (id, int_value, str_value) VALUES (123, 888999, 'abc');\nDELETE FROM dummydb.dummytbl WHERE id = 888;\nREPLACE INTO dummydb.dummytbl (id, int_value, str_value) VALUES (999, 888888, 'abc888');\n```\n\n----------------------------------------\n\nTITLE: Golang DateTime Range Deletion\nDESCRIPTION: Golang implementation for deleting data within a specific time range using the database/sql package\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-delete-data.md#2025-04-18_snippet_3\n\nLANGUAGE: Golang\nCODE:\n```\npackage main\n\nimport (\n    \"database/sql\"\n    \"fmt\"\n    \"time\"\n\n    _ \"github.com/go-sql-driver/mysql\"\n)\n\nfunc main() {\n    db, err := sql.Open(\"mysql\", \"root:@tcp(127.0.0.1:4000)/bookshop\")\n    if err != nil {\n        panic(err)\n    }\n    defer db.Close()\n\n    startTime := time.Date(2022, 04, 15, 0, 0, 0, 0, time.UTC)\n    endTime := time.Date(2022, 04, 15, 0, 15, 0, 0, time.UTC)\n\n    bulkUpdateSql := fmt.Sprintf(\"DELETE FROM `bookshop`.`ratings` WHERE `rated_at` >= ? AND `rated_at` <= ?\")\n    result, err := db.Exec(bulkUpdateSql, startTime, endTime)\n    if err != nil {\n        panic(err)\n    }\n    _, err = result.RowsAffected()\n    if err != nil {\n        panic(err)\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Backing Up the Entire TiDB Cluster\nDESCRIPTION: Example of backing up all user databases in a TiDB cluster to local storage, excluding system tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-backup.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP DATABASE * TO 'local:///mnt/backup/full/';\n```\n\n----------------------------------------\n\nTITLE: Analyzing TiDB Execution Plan with Runtime Filter\nDESCRIPTION: This SQL execution plan shows the performance improvements achieved by enabling Runtime Filter, including reduced IO and improved hash join performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/runtime-filter.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------------------+-------------+---------+--------------+---------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+---------+------+\n| TableReader_53                         | 37343.19    | 59574   | root         |                     | time:162.1ms, loops:82, RU:0.000000, cop_task: {num: 47, max: 0s, min: 0s, avg: 0s, p95: 0s, copr_cache_hit_ratio: 0.00}                                                                                                                                                                                                                                                                             | MppVersion: 1, data:ExchangeSender_52                                                                                                         | 12.7 KB | N/A  |\n| └─ExchangeSender_52                    | 37343.19    | 59574   | mpp[tiflash] |                     | tiflash_task:{proc max:160.8ms, min:154.3ms, avg: 157.6ms, p80:160.8ms, p95:160.8ms, iters:86, tasks:2, threads:16}                                                                                                                                                                                                                                                                                  | ExchangeType: PassThrough                                                                                                                     | N/A     | N/A  |\n|   └─Projection_51                      | 37343.19    | 59574   | mpp[tiflash] |                     | tiflash_task:{proc max:160.8ms, min:154.3ms, avg: 157.6ms, p80:160.8ms, p95:160.8ms, iters:86, tasks:2, threads:16}                                                                                                                                                                                                                                                                                  | tpcds50.catalog_sales.cs_ship_date_sk                                                                                                         | N/A     | N/A  |\n|     └─HashJoin_48                      | 37343.19    | 59574   | mpp[tiflash] |                     | tiflash_task:{proc max:160.8ms, min:154.3ms, avg: 157.6ms, p80:160.8ms, p95:160.8ms, iters:86, tasks:2, threads:16}                                                                                                                                                                                                                                                                                  | inner join, equal:[eq(tpcds50.date_dim.d_date_sk, tpcds50.catalog_sales.cs_ship_date_sk)], runtime filter:0[IN] <- tpcds50.date_dim.d_date_sk | N/A     | N/A  |\n|       ├─ExchangeReceiver_29(Build)     | 1.00        | 2       | mpp[tiflash] |                     | tiflash_task:{proc max:132.3ms, min:130.8ms, avg: 131.6ms, p80:132.3ms, p95:132.3ms, iters:2, tasks:2, threads:16}                                                                                                                                                                                                                                                                                   |                                                                                                                                               | N/A     | N/A  |\n|       │ └─ExchangeSender_28            | 1.00        | 1       | mpp[tiflash] |                     | tiflash_task:{proc max:131ms, min:0s, avg: 65.5ms, p80:131ms, p95:131ms, iters:1, tasks:2, threads:1}                                                                                                                                                                                                                                                                                                | ExchangeType: Broadcast, Compression: FAST                                                                                                    | N/A     | N/A  |\n|       │   └─TableFullScan_26           | 1.00        | 1       | mpp[tiflash] | table:date_dim      | tiflash_task:{proc max:3.01ms, min:0s, avg: 1.51ms, p80:3.01ms, p95:3.01ms, iters:1, tasks:2, threads:1}, tiflash_scan:{dtfile:{total_scanned_packs:2, total_skipped_packs:12, total_scanned_rows:16384, total_skipped_rows:97625, total_rs_index_load_time: 0ms, total_read_time: 0ms}, total_create_snapshot_time: 0ms, total_local_region_num: 1, total_remote_region_num: 0}                     | pushed down filter:eq(tpcds50.date_dim.d_date, 2002-02-01 00:00:00.000000), keep order:false                                                  | N/A     | N/A  |\n|       └─Selection_31(Probe)            | 71638034.00 | 5308995 | mpp[tiflash] |                     | tiflash_task:{proc max:39.8ms, min:24.3ms, avg: 32.1ms, p80:39.8ms, p95:39.8ms, iters:86, tasks:2, threads:16}                                                                                                                                                                                                                                                                                       | not(isnull(tpcds50.catalog_sales.cs_ship_date_sk))                                                                                            | N/A     | N/A  |\n|         └─TableFullScan_30             | 71997669.00 | 5335549 | mpp[tiflash] | table:catalog_sales | tiflash_task:{proc max:36.8ms, min:23.3ms, avg: 30.1ms, p80:36.8ms, p95:36.8ms, iters:86, tasks:2, threads:16}, tiflash_scan:{dtfile:{total_scanned_packs:660, total_skipped_packs:12451, total_scanned_rows:5335549, total_skipped_rows:100905778, total_rs_index_load_time: 2ms, total_read_time: 47ms}, total_create_snapshot_time: 0ms, total_local_region_num: 194, total_remote_region_num: 0} | pushed down filter:empty, keep order:false, runtime filter:0[IN] -> tpcds50.catalog_sales.cs_ship_date_sk                                     | N/A     | N/A  |\n+----------------------------------------+-------------+---------+--------------+---------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+---------+------+\n```\n\n----------------------------------------\n\nTITLE: Creating Users Table with Basic Columns\nDESCRIPTION: Example of creating a users table with basic columns including id (bigint), nickname (varchar), and balance (decimal) fields.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `bookshop`.`users` (\n  `id` bigint,\n  `nickname` varchar(100),\n  `balance` decimal(15,2)\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Database Connection in Rails with ActiveRecord\nDESCRIPTION: Database configuration in database.yml that establishes connection to TiDB using environment variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_10\n\nLANGUAGE: yml\nCODE:\n```\ndefault: &default\n  adapter: mysql2\n  encoding: utf8mb4\n  pool: <%= ENV.fetch(\"RAILS_MAX_THREADS\") { 5 } %>\n  url: <%= ENV[\"DATABASE_URL\"] %>\n\ndevelopment:\n  <<: *default\n\ntest:\n  <<: *default\n  database: quickstart_test\n\nproduction:\n  <<: *default\n```\n\n----------------------------------------\n\nTITLE: Encoding an Index Key with TIDB_ENCODE_INDEX_KEY\nDESCRIPTION: The function encodes an index key, essential for internal database operations or migration cases where direct key manipulation is required.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_30\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id int PRIMARY KEY, a int, KEY `idx` (a));\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES(1,1);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_ENCODE_INDEX_KEY('test', 't', 'idx', 1, 1);\n```\n\n----------------------------------------\n\nTITLE: Querying Vector Index Build Progress in TiDB\nDESCRIPTION: This SQL query retrieves information about vector index building progress from the INFORMATION_SCHEMA.TIFLASH_INDEXES system table. It shows statistics on indexed and non-indexed rows in both stable and delta layers.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-index.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.TIFLASH_INDEXES;\n```\n\n----------------------------------------\n\nTITLE: Hibernate Configuration for TiDB Connection\nDESCRIPTION: XML configuration file for setting up Hibernate connection to TiDB database, including connection properties and batch size settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-update-data.md#2025-04-18_snippet_9\n\nLANGUAGE: xml\nCODE:\n```\n<?xml version='1.0' encoding='utf-8'?>\n<!DOCTYPE hibernate-configuration PUBLIC\n        \"-//Hibernate/Hibernate Configuration DTD 3.0//EN\"\n        \"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd\">\n<hibernate-configuration>\n    <session-factory>\n\n        <!-- Database connection settings -->\n        <property name=\"hibernate.connection.driver_class\">com.mysql.cj.jdbc.Driver</property>\n        <property name=\"hibernate.dialect\">org.hibernate.dialect.TiDBDialect</property>\n        <property name=\"hibernate.connection.url\">jdbc:mysql://localhost:4000/movie</property>\n        <property name=\"hibernate.connection.username\">root</property>\n        <property name=\"hibernate.connection.password\"></property>\n        <property name=\"hibernate.connection.autocommit\">false</property>\n        <property name=\"hibernate.jdbc.batch_size\">20</property>\n\n        <!-- Optional: Show SQL output for debugging -->\n        <property name=\"hibernate.show_sql\">true</property>\n        <property name=\"hibernate.format_sql\">true</property>\n    </session-factory>\n</hibernate-configuration>\n```\n\n----------------------------------------\n\nTITLE: Using Resource Groups for Resource Control\nDESCRIPTION: Example showing how to execute a query using a specific resource group for resource isolation.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_51\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ RESOURCE_GROUP(rg1) */ * FROM t limit 10;\n```\n\n----------------------------------------\n\nTITLE: Configuring sync-diff-inspector with Specific Table Names\nDESCRIPTION: This TOML configuration example for sync-diff-inspector is used when the number of upstream sharded tables is small, and the table naming pattern is not consistent. It specifies the connections to MySQL and TiDB instances, route rules for table mapping, and tasks for comparing downstream tables with upstream tables. Key parameters include \"check-thread-count\" which determines the number of goroutines, and \"export-fix-sql\" for exporting SQL to reconcile data inconsistencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/shard-diff.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n# Diff Configuration.\n\n######################### Global config #########################\n\n# The number of goroutines created to check data. The number of connections between upstream and downstream databases are slightly greater than this value\ncheck-thread-count = 4\n\n# If enabled, SQL statements is exported to fix inconsistent tables\nexport-fix-sql = true\n\n# Only compares the table structure instead of the data\ncheck-struct-only = false\n\n######################### Datasource config #########################\n[data-sources.mysql1]\n    host = \"127.0.0.1\"\n    port = 3306\n    user = \"root\"\n    password = \"\"\n\n    route-rules = [\"rule1\"]\n\n[data-sources.mysql2]\n    host = \"127.0.0.1\"\n    port = 3306\n    user = \"root\"\n    password = \"\"\n\n    route-rules = [\"rule2\"]\n\n[data-sources.tidb0]\n    host = \"127.0.0.1\"\n    port = 4000\n    user = \"root\"\n    password = \"\"\n\n########################### Routes ###########################\n[routes.rule1]\nschema-pattern = \"test\"        # Matches the schema name of the data source. Supports the wildcards \"*\" and \"?\"\ntable-pattern = \"table-[1-2]\"  # Matches the table name of the data source. Supports the wildcards \"*\" and \"?\"\ntarget-schema = \"test\"         # The name of the schema in the target database\ntarget-table = \"table-0\"       # The name of the target table\n\n[routes.rule2]\nschema-pattern = \"test\"      # Matches the schema name of the data source. Supports the wildcards \"*\" and \"?\"\ntable-pattern = \"table-3\"    # Matches the table name of the data source. Supports the wildcards \"*\" and \"?\"\ntarget-schema = \"test\"       # The name of the schema in the target database\ntarget-table = \"table-0\"     # The name of the target table\n\n######################### Task config #########################\n[task]\n    output-dir = \"./output\"\n\n    source-instances = [\"mysql1\", \"mysql2\"]\n\n    target-instance = \"tidb0\"\n\n    # The tables of downstream databases to be compared. Each table needs to contain the schema name and the table name, separated by '.'\n    target-check-tables = [\"test.table-0\"]\n```\n\n----------------------------------------\n\nTITLE: Handling Unique Constraints in Optimistic Transactions\nDESCRIPTION: This example demonstrates lazy checking of unique constraints in optimistic transactions, where constraint violations are detected only at commit time.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN OPTIMISTIC;\nINSERT INTO users (username) VALUES ('jane'), ('chris'), ('bill');\n```\n\n----------------------------------------\n\nTITLE: Encoding BOOTSTRAP Event in TiCDC - JSON\nDESCRIPTION: This snippet presents the JSON format for a BOOTSTRAP event in TiCDC, which includes schema information of a table. It contains fields such as version, type, commit timestamp, build timestamp, and a detailed tableSchema object, highlighting the necessary columns and indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-simple-protocol.md#2025-04-18_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"version\":1,\n   \"type\":\"BOOTSTRAP\",\n   \"commitTs\":0,\n   \"buildTs\":1708924603278,\n   \"tableSchema\":{\n      \"schema\":\"simple\",\n      \"table\":\"new_user\",\n      \"tableID\":148,\n      \"version\":447984074911121426,\n      \"columns\":[\n         {\n            \"name\":\"id\",\n            \"dataType\":{\n               \"mysqlType\":\"int\",\n               \"charset\":\"binary\",\n               \"collate\":\"binary\",\n               \"length\":11\n            },\n            \"nullable\":false,\n            \"default\":null\n         },\n         {\n            \"name\":\"name\",\n            \"dataType\":{\n               \"mysqlType\":\"varchar\",\n               \"charset\":\"utf8mb4\",\n               \"collate\":\"utf8mb4_bin\",\n               \"length\":255\n            },\n            \"nullable\":true,\n            \"default\":null\n         },\n         {\n            \"name\":\"age\",\n            \"dataType\":{\n               \"mysqlType\":\"int\",\n               \"charset\":\"binary\",\n               \"collate\":\"binary\",\n               \"length\":11\n            },\n            \"nullable\":true,\n            \"default\":null\n         },\n         {\n            \"name\":\"score\",\n            \"dataType\":{\n               \"mysqlType\":\"float\",\n               \"charset\":\"binary\",\n               \"collate\":\"binary\",\n               \"length\":12\n            },\n            \"nullable\":true,\n            \"default\":null\n         }\n      ],\n      \"indexes\":[\n         {\n            \"name\":\"primary\",\n            \"unique\":true,\n            \"primary\":true,\n            \"nullable\":false,\n            \"columns\":[\n               \"id\"\n            ]\n         }\n      ]\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Assigning Values in SELECT Statement\nDESCRIPTION: Demonstrates how to both read and assign values to user-defined variables in a single SELECT statement using the := operator.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @a1, @a2, @a3, @a4 := @a1+@a2+@a3;\n```\n\n----------------------------------------\n\nTITLE: Index Lookup Query in TiDB\nDESCRIPTION: Query using IndexLookup operator when filter condition exists but index doesn't fully cover data\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nselect * from t where a=2\n```\n\n----------------------------------------\n\nTITLE: Identifying Top Slow Queries Using SQL in TiDB\nDESCRIPTION: This SQL command retrieves the slowest N query records recently executed in TiDB. It can be filtered to show either internal queries, all queries, or user-specific queries, aiding in performance analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW SLOW TOP [internal | all] N\n```\n\n----------------------------------------\n\nTITLE: Loading and Splitting Documents for Vector Embedding\nDESCRIPTION: Loads the sample document and splits it into smaller chunks of text using LangChain's CharacterTextSplitter to prepare it for vector embedding.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nloader = TextLoader(\"data/how_to/state_of_the_union.txt\")\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(documents)\n```\n\n----------------------------------------\n\nTITLE: Implementing Bulk Delete in Golang for TiDB\nDESCRIPTION: This Golang code demonstrates how to perform a bulk delete operation on the 'ratings' table in TiDB. It deletes records within a specific time range in batches of 1000 rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-delete-data.md#2025-04-18_snippet_6\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n    \"database/sql\"\n    \"fmt\"\n    \"time\"\n\n    _ \"github.com/go-sql-driver/mysql\"\n)\n\nfunc main() {\n    db, err := sql.Open(\"mysql\", \"root:@tcp(127.0.0.1:4000)/bookshop\")\n    if err != nil {\n        panic(err)\n    }\n    defer db.Close()\n\n    affectedRows := int64(-1)\n    startTime := time.Date(2022, 04, 15, 0, 0, 0, 0, time.UTC)\n    endTime := time.Date(2022, 04, 15, 0, 15, 0, 0, time.UTC)\n\n    for affectedRows != 0 {\n        affectedRows, err = deleteBatch(db, startTime, endTime)\n        if err != nil {\n            panic(err)\n        }\n    }\n}\n\n// deleteBatch delete at most 1000 lines per batch\nfunc deleteBatch(db *sql.DB, startTime, endTime time.Time) (int64, error) {\n    bulkUpdateSql := fmt.Sprintf(\"DELETE FROM `bookshop`.`ratings` WHERE `rated_at` >= ? AND `rated_at` <= ? LIMIT 1000\")\n    result, err := db.Exec(bulkUpdateSql, startTime, endTime)\n    if err != nil {\n        return -1, err\n    }\n    affectedRows, err := result.RowsAffected()\n    if err != nil {\n        return -1, err\n    }\n\n    fmt.Printf(\"delete %d data\\n\", affectedRows)\n    return affectedRows, nil\n}\n```\n\n----------------------------------------\n\nTITLE: Left Join Query for Books with Ratings\nDESCRIPTION: SQL query demonstrating LEFT JOIN between books and ratings tables to show books with their average ratings. Includes unrated books by using LEFT JOIN.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-join-tables.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT b.id AS book_id, ANY_VALUE(b.title) AS book_title, AVG(r.score) AS average_score\nFROM books b\nLEFT JOIN ratings r ON b.id = r.book_id\nGROUP BY b.id\nORDER BY b.published_at DESC\nLIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Filtering Query Results in TiDB with SQL\nDESCRIPTION: This SQL statement selects all columns from the 'person' table with a condition that filters for records where the ID is less than 5. It demonstrates how to use the WHERE clause to retrieve only data that meets specific criteria.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-tidb-crud-sql.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM person WHERE id < 5;\n```\n\n----------------------------------------\n\nTITLE: Restoring Cluster to Specific Timestamp with FLASHBACK in SQL\nDESCRIPTION: New SQL syntax to restore a cluster to a specific point in time within the Garbage Collection lifetime, allowing quick recovery from DML misoperations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.4.0.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nFLASHBACK CLUSTER TO TIMESTAMP\n```\n\n----------------------------------------\n\nTITLE: Defining Expression Syntax in EBNF for TiDB\nDESCRIPTION: This EBNF definition outlines the syntax rules for composing expressions in TiDB, which are fundamental to forming SQL queries. It includes definitions for expression types such as predicates and bit expressions, and it specifies how these elements can be combined using logical operators. This syntax is critical for developers working with TiDB's parser and building SQL queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/expression-syntax.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\n\"Expression ::=\\n    ( singleAtIdentifier assignmentEq | 'NOT' | Expression ( logOr | 'XOR' | logAnd ) ) Expression\\n|   'MATCH' '(' ColumnNameList ')' 'AGAINST' '(' BitExpr FulltextSearchModifierOpt ')\"\\n|   PredicateExpr ( IsOrNotOp 'NULL' | CompareOp ( ( singleAtIdentifier assignmentEq )? PredicateExpr | AnyOrAll SubSelect ) )* ( IsOrNotOp ( trueKwd | falseKwd | 'UNKNOWN' ) )?\\n\\n\"PredicateExpr ::=\\n    BitExpr ( BetweenOrNotOp BitExpr 'AND' BitExpr )* ( InOrNotOp ( '(' ExpressionList ')' | SubSelect ) | LikeOrNotOp SimpleExpr LikeEscapeOpt | RegexpOrNotOp SimpleExpr )?\\n\\n\"BitExpr ::=\\n    BitExpr ( ( '|' | '&' | '<<' | '>>' | '*' | '/' | '%' | 'DIV' | 'MOD' | '^' ) BitExpr | ( '+' | '-' ) ( BitExpr | \"INTERVAL\" Expression TimeUnit ) )\\n|   SimpleExpr\\n\\n\"SimpleExpr ::=\\n    SimpleIdent ( ( '->' | '->>' ) stringLit )?\\n|   FunctionCallKeyword\\n|   FunctionCallNonKeyword\\n|   FunctionCallGeneric\\n|   SimpleExpr ( 'COLLATE' CollationName | pipes SimpleExpr )\\n|   WindowFuncCall\\n|   Literal\\n|   paramMarker\\n|   Variable\\n|   SumExpr\\n|   ( '!' | '~' | '-' | '+' | 'NOT' | 'BINARY' ) SimpleExpr\\n|   'EXISTS'? SubSelect\\n|   ( ( '(' ( ExpressionList ',' )? | 'ROW' '(' ExpressionList ',' ) Expression | builtinCast '(' Expression 'AS' CastType | ( 'DEFAULT' | 'VALUES' ) '(' SimpleIdent | 'CONVERT' '(' Expression ( ',' CastType | 'USING' CharsetName ) ) ')\\n|   'CASE' ExpressionOpt WhenClause+ ElseOpt 'END'\n```\n\n----------------------------------------\n\nTITLE: Configuring Hibernate for TiDB Connection in XML\nDESCRIPTION: This XML snippet shows how to configure Hibernate to connect to TiDB. It includes database connection settings, dialect configuration, and optional SQL output for debugging.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-hibernate.md#2025-04-18_snippet_0\n\nLANGUAGE: XML\nCODE:\n```\n<?xml version='1.0' encoding='utf-8'?>\n<!DOCTYPE hibernate-configuration PUBLIC\n        \"-//Hibernate/Hibernate Configuration DTD 3.0//EN\"\n        \"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd\">\n<hibernate-configuration>\n    <session-factory>\n\n        <!-- Database connection settings -->\n        <property name=\"hibernate.connection.driver_class\">com.mysql.cj.jdbc.Driver</property>\n        <property name=\"hibernate.dialect\">org.hibernate.dialect.TiDBDialect</property>\n        <property name=\"hibernate.connection.url\">${tidb_jdbc_url}</property>\n        <property name=\"hibernate.connection.username\">${tidb_user}</property>\n        <property name=\"hibernate.connection.password\">${tidb_password}</property>\n        <property name=\"hibernate.connection.autocommit\">false</property>\n\n        <!-- Required so a table can be created from the 'PlayerDAO' class -->\n        <property name=\"hibernate.hbm2ddl.auto\">create-drop</property>\n\n        <!-- Optional: Show SQL output for debugging -->\n        <property name=\"hibernate.show_sql\">true</property>\n        <property name=\"hibernate.format_sql\">true</property>\n    </session-factory>\n</hibernate-configuration>\n```\n\n----------------------------------------\n\nTITLE: Showing SQL Warnings for Inapplicable Join Hints - SQL\nDESCRIPTION: This SQL snippet demonstrates how to show warnings related to join hints when collation incompatibility occurs in a join query. This helps to understand optimizer behaviors in such cases.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_58\n\nLANGUAGE: sql\nCODE:\n```\nSHOW WARNINGS;\n+---------+------+----------------------------------------------------------------------------+\n| Level   | Code | Message                                                                    |\n+---------+------+----------------------------------------------------------------------------+\n| Warning | 1815 | Optimizer Hint /*+ INL_JOIN(t1) */ or /*+ TIDB_INLJ(t1) */ is inapplicable |\n+---------+------+----------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Range Partitioning by Store ID\nDESCRIPTION: This example demonstrates Range partitioning on the `employees` table using the `store_id` column. The table is partitioned into four partitions (`p0`, `p1`, `p2`, `p3`) based on ranges of `store_id` values, allowing for efficient querying and deletion of data based on store ID ranges.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT NOT NULL\n)\n\nPARTITION BY RANGE (store_id) (\n    PARTITION p0 VALUES LESS THAN (6),\n    PARTITION p1 VALUES LESS THAN (11),\n    PARTITION p2 VALUES LESS THAN (16),\n    PARTITION p3 VALUES LESS THAN (21)\n);\n```\n\n----------------------------------------\n\nTITLE: Querying with IndexMerge on Multi-Valued JSON Indexes in TiDB\nDESCRIPTION: These EXPLAIN statements show how TiDB uses IndexMerge to access multi-valued indexes and normal indexes for queries with JSON member checks and equality conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t3, k1, k2, ka) */ * FROM t3 WHERE 1 member of (j1->'$.path') OR a = 3;\nEXPLAIN SELECT /*+ use_index_merge(t3, k1, k2, ka) */ * FROM t3 WHERE 1 member of (j1->'$.path') AND 2 member of (j2->'$.path') AND (a = 3);\n```\n\n----------------------------------------\n\nTITLE: Setting Global Time Zone in TiDB\nDESCRIPTION: SQL commands to set the time zone at the global level with examples.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-time-zone.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL time_zone = ${time-zone-value};\nSET GLOBAL time_zone = 'UTC';\n```\n\n----------------------------------------\n\nTITLE: Creating SQL User for Index Insight in TiDB Cloud\nDESCRIPTION: SQL statements to create a new user with required privileges for the Index Insight feature. This includes read access to information_schema and mysql, as well as PROCESS and REFERENCES privileges for all databases.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/index-insight.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE user 'index_insight_user'@'%' IDENTIFIED by 'random_password';\nGRANT SELECT ON information_schema.* TO 'index_insight_user'@'%';\nGRANT SELECT ON mysql.* TO 'index_insight_user'@'%';\nGRANT PROCESS, REFERENCES ON *.* TO 'index_insight_user'@'%';\nFLUSH PRIVILEGES;\n```\n\n----------------------------------------\n\nTITLE: Deleting Data from TiDB with Ruby\nDESCRIPTION: Ruby function to delete a player record from the database by ID, returning the number of affected rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_12\n\nLANGUAGE: ruby\nCODE:\n```\ndef delete_player_by_id(client, id)\n  result = client.query(\n    \"DELETE FROM players WHERE id = #{id};\"\n  )\n  client.affected_rows\nend\n```\n\n----------------------------------------\n\nTITLE: Verifying plan cache using EXPLAIN FORMAT in TiDB\nDESCRIPTION: This SQL snippet uses the `EXPLAIN FORMAT='plan_cache'` statement to verify whether a given query can utilize the plan cache. This statement returns a warning message if the query cannot use the cache, explaining the reason.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-non-prepared-plan-cache.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN FORMAT='plan_cache' SELECT * FROM (SELECT a+1 FROM t) t;\n```\n\n----------------------------------------\n\nTITLE: INL_JOIN Hint with Built-in Functions\nDESCRIPTION: Shows how INL_JOIN hint fails when built-in functions are used on join columns, and demonstrates the solution using tidb_enable_inl_join_inner_multi_pattern.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_55\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id varchar(10) primary key, tname varchar(10));\nCREATE TABLE t2 (id varchar(10) primary key, tname varchar(10));\nEXPLAIN SELECT /*+ INL_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id=t2.id and SUBSTR(t1.tname,1,2)=SUBSTR(t2.tname,1,2);\n```\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------+----------+-----------+---------------+-----------------------------------------------------------------------+\n| id                           | estRows  | task      | access object | operator info                                                         |\n+------------------------------+----------+-----------+---------------+-----------------------------------------------------------------------+\n| HashJoin_12                  | 12500.00 | root      |               | inner join, equal:[eq(test.t1.id, test.t2.id) eq(Column#5, Column#6)] |\n| ├─Projection_17(Build)       | 10000.00 | root      |               | test.t2.id, test.t2.tname, substr(test.t2.tname, 1, 2)->Column#6      |\n| │ └─TableReader_19           | 10000.00 | root      |               | data:TableFullScan_18                                                 |\n| │   └─TableFullScan_18       | 10000.00 | cop[tikv] | table:t2      | keep order:false, stats:pseudo                                        |\n| └─Projection_14(Probe)       | 10000.00 | root      |               | test.t1.id, test.t1.tname, substr(test.t1.tname, 1, 2)->Column#5      |\n|   └─TableReader_16           | 10000.00 | root      |               | data:TableFullScan_15                                                 |\n|     └─TableFullScan_15       | 10000.00 | cop[tikv] | table:t1      | keep order:false, stats:pseudo                                        |\n+------------------------------+----------+-----------+---------------+-----------------------------------------------------------------------+\n7 rows in set, 1 warning (0.01 sec)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSET @@tidb_enable_inl_join_inner_multi_pattern=ON;\nEXPLAIN SELECT /*+ INL_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id=t2.id AND SUBSTR(t1.tname,1,2)=SUBSTR(t2.tname,1,2);\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_max_chunk_size for Query Execution\nDESCRIPTION: Sets the maximum number of rows in a chunk during query execution. This affects memory usage and cache locality. The recommended value is no larger than 65536, with a single chunk not exceeding 16 MiB of memory.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_46\n\nLANGUAGE: SQL\nCODE:\n```\nSET [SESSION | GLOBAL] tidb_max_chunk_size = <value>;\n```\n\n----------------------------------------\n\nTITLE: Querying with GROUP BY and WITH ROLLUP in SQL\nDESCRIPTION: This SQL statement demonstrates how to use the GROUP BY clause along with the WITH ROLLUP modifier to aggregate data across multiple dimensions. It counts entries grouped by columns a, b, and c, and provides summary results for each grouping.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/group-by-modifier.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT count(1) FROM t GROUP BY a,b,c WITH ROLLUP;\n```\n\n----------------------------------------\n\nTITLE: Querying with IN Subquery in TiDB\nDESCRIPTION: Execution plan for a query with IN subquery, showing how TiDB rewrites it as a JOIN operation with a DISTINCT aggregation. This demonstrates the internal transformation of 'IN (SELECT...)' to improve performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/subquery-optimization.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nexplain select * from t1 where t1.a in (select t2.a from t2);\n```\n\n----------------------------------------\n\nTITLE: Creating Users Table with AUTO_RANDOM Primary Key\nDESCRIPTION: Example showing how to create a users table with an AUTO_RANDOM primary key to avoid hotspots in write-intensive scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `bookshop`.`users` (\n  `id` bigint AUTO_RANDOM,\n  `balance` decimal(15,2),\n  `nickname` varchar(100),\n  PRIMARY KEY (`id`)\n);\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into TiDB using MySQL Connector/Python\nDESCRIPTION: This code snippet demonstrates how to insert data into a TiDB database using MySQL Connector/Python. It establishes a connection, creates a cursor, and executes an INSERT statement with parameterized values.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-mysql-connector.md#2025-04-18_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nwith get_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        player = (\"1\", 1, 1)\n        cursor.execute(\"INSERT INTO players (id, coins, goods) VALUES (%s, %s, %s)\", player)\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Expression Index in SQL\nDESCRIPTION: Illustrates how to define an expression index directly when creating a new table. This approach combines table creation and index definition in a single statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t1 (\n    col1 CHAR(10), \n    col2 CHAR(10),\n    INDEX ((LOWER(col1)))\n);\n```\n\n----------------------------------------\n\nTITLE: FLASHBACK DATABASE Syntax in TiDB\nDESCRIPTION: SQL syntax for the FLASHBACK DATABASE statement, which allows restoring a dropped database with optional renaming capability.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-database.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nFLASHBACK DATABASE DBName [TO newDBName]\n```\n\n----------------------------------------\n\nTITLE: Checking Table Statistics Health in TiDB\nDESCRIPTION: This SQL query displays the health status of table statistics for a specific table named 'T2' using the SHOW STATS_HEALTHY statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW STATS_HEALTHY WHERE table_name='T2'\\G;\n```\n\n----------------------------------------\n\nTITLE: Showing Database Information in TiDB\nDESCRIPTION: Commands for displaying database information, including listing all databases, using a specific database, and showing all tables in a database.\nSOURCE: https://github.com/pingcap/docs/blob/master/basic-sql-operations.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW DATABASES;\n```\n\nLANGUAGE: sql\nCODE:\n```\nUSE mysql;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES FROM mysql;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning with TOML\nDESCRIPTION: Configures TiDB Lightning to enable strict SQL mode, use the local backend for import, replace duplicates during conflict resolution, and skip up to 10 errors. Key parameters include `max-error`, `backend`, `strategy`, `data-source-dir`, `host`, `port`, `user`, `password`, and `sql-mode`.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n\"cat <<EOF > config.toml\\n\\n        [lightning]\\n        max-error = 10\\n\\n        [tikv-importer]\\n        backend = 'local'\\n        sorted-kv-dir = '/tmp/lightning-tmp/'\\n\\n        [conflict]\\n        strategy = 'replace'\\n        [mydumper]\\n        data-source-dir = '.'\\n        [tidb]\\n        host = '127.0.0.1'\\n        port = 4000\\n        user = 'root'\\n        password = ''\\n        sql-mode = 'STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE'\\n\\n    EOF\"\n```\n\n----------------------------------------\n\nTITLE: Adding an Index with ALTER TABLE and Explaining Query Improvement\nDESCRIPTION: SQL statements to add an index to the c1 column and then verify that the same query now uses an index range scan instead of a full table scan, demonstrating improved query performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t1 ADD INDEX (c1);\nEXPLAIN SELECT * FROM t1 WHERE c1 = 3;\n```\n\n----------------------------------------\n\nTITLE: Importing Multiple Data Files Using Wildcards\nDESCRIPTION: This SQL statement imports multiple CSV files into a TiDB table using wildcards. The wildcard `*` is used to specify a pattern for the file names, allowing multiple files to be imported in a single statement. The files `file-01.csv`, `file-02.csv`, and `file-03.csv` in the `/path/to/` directory will be imported.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t FROM '/path/to/file-*.csv';\n```\n\n----------------------------------------\n\nTITLE: Running Java Optimistic Transaction Example\nDESCRIPTION: This snippet demonstrates how to run a Java program that executes optimistic transactions. It uses the Maven build tool to package the application and then runs it with specified parameters for Alice and Bob's purchases.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nmvn clean package\njava -jar target/plain-java-txn-0.0.1-jar-with-dependencies.jar ALICE_NUM=4 BOB_NUM=6\n```\n\n----------------------------------------\n\nTITLE: Creating a Global Binding in TiDB SQL\nDESCRIPTION: The command creates a global binding for a specific SQL query that selects all records from table 't' while utilizing index 'a'. This binding helps optimize query execution for the specified conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_36\n\nLANGUAGE: sql\nCODE:\n```\nCREATE GLOBAL BINDING for SELECT * FROM t WHERE a < 100 AND b < 100 USING SELECT * FROM t use index(a) WHERE a < 100 AND b < 100;\n```\n\n----------------------------------------\n\nTITLE: Grant Privileges with SQL\nDESCRIPTION: Illustrates the use of the SQL `GRANT` statement in TiDB to assign specific or all privileges to a user. Prerequisites include knowledge of the SQL mode settings and the existing database structure. The expected input is a SQL command specifying the privileges and the user, and the output is the database modification status. It is crucial to note security risks such as inadvertently creating users with empty passwords if SQL mode `NO_AUTO_CREATE_USER` is not set.\nSOURCE: https://github.com/pingcap/docs/blob/master/privilege-management.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nGRANT SELECT ON test.* TO 'xxx'@'%';\n```\n\nLANGUAGE: sql\nCODE:\n```\nGRANT ALL PRIVILEGES ON *.* TO 'xxx'@'%';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSET sql_mode=DEFAULT;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@sql_mode;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM mysql.user WHERE user='idontexist';\n```\n\nLANGUAGE: sql\nCODE:\n```\nGRANT ALL PRIVILEGES ON test.* TO 'idontexist';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT user,host,authentication_string FROM mysql.user WHERE user='idontexist';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSET @@sql_mode='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION';\n```\n\nLANGUAGE: sql\nCODE:\n```\nGRANT ALL PRIVILEGES ON `te%`.* TO genius;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT user,host,db FROM mysql.db WHERE user='genius';\n```\n\n----------------------------------------\n\nTITLE: Adding Unique Index Requirements for Partitioned Tables - SQL\nDESCRIPTION: This snippet outlines the requirements for adding a unique index to partitioned tables, emphasizing that relevant columns must be included in the unique index to satisfy partitioning constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_61\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCREATE TABLE t (a varchar(20), b blob,\n    UNIQUE INDEX (a(5)))\n    PARTITION by range columns (a) (\n    PARTITION p0 values less than ('aaaaa'),\n    PARTITION p1 values less than ('bbbbb'),\n    PARTITION p2 values less than ('ccccc'));\n```\n```sql\nERROR 8264 (HY000): Global Index is needed for index 'a', since the unique index is not including all partitioning columns, and GLOBAL is not given as IndexOption\n```\n```\n\n----------------------------------------\n\nTITLE: Java Batch Insert Implementation\nDESCRIPTION: Demonstrates batch insertion using Java JDBC with PreparedStatement. Includes transaction handling and batch processing for optimal performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-insert-data.md#2025-04-18_snippet_2\n\nLANGUAGE: java\nCODE:\n```\ntry (Connection connection = ds.getConnection()) {\n    connection.setAutoCommit(false);\n\n    PreparedStatement pstmt = connection.prepareStatement(\"INSERT INTO player (id, coins, goods) VALUES (?, ?, ?)\"))\n\n    // first player\n    pstmt.setInt(1, 1);\n    pstmt.setInt(2, 1000);\n    pstmt.setInt(3, 1);\n    pstmt.addBatch();\n\n    // second player\n    pstmt.setInt(1, 2);\n    pstmt.setInt(2, 230);\n    pstmt.setInt(3, 2);\n    pstmt.addBatch();\n\n    pstmt.executeBatch();\n    connection.commit();\n} catch (SQLException e) {\n    e.printStackTrace();\n}\n```\n\n----------------------------------------\n\nTITLE: Running the Django Development Server\nDESCRIPTION: Django command to start the development server, optionally specifying a custom port.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\npython manage.py runserver\n# Or with a custom port:\npython manage.py runserver 8080\n```\n\n----------------------------------------\n\nTITLE: Query TiCDC Syncpoint - SQL\nDESCRIPTION: This SQL query retrieves syncpoint data from the downstream TiDB, showing upstream and downstream TSOs and their timestamps. It's useful for checking the replication progress in scenarios where the Syncpoint feature is enabled in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM tidb_cdc.syncpoint_v1;\n```\n\n----------------------------------------\n\nTITLE: Querying with json_member_of using OR/AND in TiDB SQL\nDESCRIPTION: Demonstrates how TiDB optimizes queries with multiple json_member_of conditions connected by OR or AND operators using index merge.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1, mvi2) */ * FROM t4 WHERE 1 member of (j->'$.a') AND 2 member of (j->'$.b') AND 3 member of (j->'$.a');\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1, mvi2) */ * FROM t4 WHERE 1 member of (j->'$.a') OR 2 member of (j->'$.b') OR 3 member of (j->'$.a');\n```\n\n----------------------------------------\n\nTITLE: Modifying Tables with Non-Clustered Indexes\nDESCRIPTION: Examples of adding and dropping non-clustered primary keys using ALTER TABLE commands.\nSOURCE: https://github.com/pingcap/docs/blob/master/clustered-indexes.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t ADD PRIMARY KEY(b, a) NONCLUSTERED;\nALTER TABLE t ADD PRIMARY KEY(b, a);\nALTER TABLE t DROP PRIMARY KEY;\nALTER TABLE t DROP INDEX `PRIMARY`;\n```\n\n----------------------------------------\n\nTITLE: Using USE_INDEX_MERGE Hint in TiDB SQL\nDESCRIPTION: Example of using the USE_INDEX_MERGE hint to tell the optimizer to use index merge access method with specified indexes for a table with OR conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_36\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ USE_INDEX_MERGE(t1, idx_a, idx_b, idx_c) */ * FROM t1 WHERE t1.a > 10 OR t1.b > 10;\n```\n\n----------------------------------------\n\nTITLE: Showing the CREATE SCHEMA statement with IF NOT EXISTS in TiDB\nDESCRIPTION: This SQL statement shows the `CREATE SCHEMA` statement for the 'test' schema, using the `IF NOT EXISTS` clause. It retrieves the exact SQL statement including the compatibility annotations that can be used to recreate the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-database.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE SCHEMA IF NOT EXISTS test;\n```\n\n----------------------------------------\n\nTITLE: Using JSON_SET() to Update JSON Values in SQL\nDESCRIPTION: The JSON_SET() function allows updating existing values in a JSON document. In this example, it updates the 'version' property from 1.1 to 1.2 in a JSON object.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-modify.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SET('{\"version\": 1.1, \"name\": \"example\"}','$.version',1.2);\n```\n\n----------------------------------------\n\nTITLE: Querying Data from TiDB with Ruby\nDESCRIPTION: Ruby function to retrieve a player record by ID, executing a SELECT query and returning the first matching result.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_10\n\nLANGUAGE: ruby\nCODE:\n```\ndef get_player_by_id(client, id)\n  result = client.query(\n    \"SELECT id, coins, goods FROM players WHERE id = #{id};\"\n  )\n  result.first\nend\n```\n\n----------------------------------------\n\nTITLE: Using Pre-Split Regions in Table Creation in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a table with the 'PRE_SPLIT_REGIONS' option, allowing for evenly pre-splitting into regions upon table creation, geared for improved data distribution.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_31\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (..., PRE_SPLIT_REGIONS = 4);\n```\n\n----------------------------------------\n\nTITLE: Using Spring @Transactional Annotation\nDESCRIPTION: Example usage of @Transactional annotation in Spring to demarcate transaction boundaries. The annotation starts the transaction before method execution and commits it after completion. The behavior can be customized through Propagation settings for nested transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_12\n\nLANGUAGE: java\nCODE:\n```\n@Transactional\n```\n\n----------------------------------------\n\nTITLE: Creating an Admin User with Limited Privileges in TiDB\nDESCRIPTION: Create an admin user that can only connect from localhost with a password, typically used for administrative tasks with restricted privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'admin'@'localhost' IDENTIFIED BY 'admin_pass';\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB Cloud using JDBC\nDESCRIPTION: This code snippet shows how to execute a query against a TiDB Cloud Dedicated cluster using JDBC. It establishes a connection using the provided connection string, executes a SELECT DATABASE() query, and prints the database name. The snippet depends on the MySQL Connector/J library and requires handling potential SQL exceptions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tls-connect-to-dedicated.md#2025-04-18_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nimport com.mysql.jdbc.Driver;\nimport java.sql.*;\n\nclass Main {\n  public static void main(String args[]) throws SQLException, ClassNotFoundException {\n    Class.forName(\"com.mysql.cj.jdbc.Driver\");\n    try {\n      Connection conn = DriverManager.getConnection(\"jdbc:mysql://tidb.srgnqxji5bc.clusters.staging.tidb-cloud.com:4000/test?user=root&password=<your_password>&sslMode=VERIFY_IDENTITY&tlsVersions=TLSv1.2&trustCertificateKeyStoreUrl=file:<your_custom_truststore_path>&trustCertificateKeyStorePassword=<your_truststore_password>\");\n      Statement stmt = conn.createStatement();\n      try {\n        ResultSet rs = stmt.executeQuery(\"SELECT DATABASE();\");\n        if (rs.next()) {\n          System.out.println(\"using db:\" + rs.getString(1));\n        }\n      } catch (Exception e) {\n        System.out.println(\"exec error:\" + e);\n      }\n    } catch (Exception e) {\n      System.out.println(\"connect error:\" + e);\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using VALUES() in ON DUPLICATE KEY UPDATE with INSERT in SQL\nDESCRIPTION: This example demonstrates how to use the VALUES() function to reference column values in the ON DUPLICATE KEY UPDATE clause of an INSERT statement, which is useful for handling duplicate keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id INT PRIMARY KEY, c1 INT);\nINSERT INTO t1 VALUES (1,51),(2,52),(3,53),(4,54),(5,55);\nINSERT INTO t1 VALUES(2,22),(4,44) ON DUPLICATE KEY UPDATE c1=VALUES(id)+100;\nTABLE t1;\n```\n\n----------------------------------------\n\nTITLE: Inserting Vector Data in SQL\nDESCRIPTION: Shows how to insert valid vector data into a table with a Vector column.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-data-types.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO vector_table VALUES (1, '[0.3, 0.5, -0.1]');\n\nINSERT INTO vector_table VALUES (2, NULL);\n```\n\n----------------------------------------\n\nTITLE: Committing a Transaction in TiDB\nDESCRIPTION: Example of committing a transaction using the COMMIT statement. This applies all changes made in the current transaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/transaction-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCOMMIT;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Slow Query Log in TiDB\nDESCRIPTION: This code snippet shows a sample slow query log entry in TiDB, providing detailed information about query execution time, number of COP tasks, and processing times on TiKV nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\n# Query_time: 0.18085\n...\n# Num_cop_tasks: 1\n# Cop_process: Avg_time: 170ms P90_time: 170ms Max_time: 170ms Max_addr: 10.6.131.78\n# Cop_wait: Avg_time: 1ms P90_time: 1ms Max_time: 1ms Max_Addr: 10.6.131.78\n```\n\n----------------------------------------\n\nTITLE: Using TiDB Cloud Serverless Driver in Vercel Edge Function\nDESCRIPTION: Example of integrating the TiDB Cloud Serverless Driver with a Vercel Edge Function to execute SQL queries in an edge environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_3\n\nLANGUAGE: ts\nCODE:\n```\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\nimport { connect } from '@tidbcloud/serverless'\nexport const runtime = 'edge'\n\nexport async function GET(request: NextRequest) {\n  const conn = connect({url: process.env.DATABASE_URL})\n  const result = await conn.execute('show tables')\n  return NextResponse.json({result});\n}\n```\n\n----------------------------------------\n\nTITLE: Optimizing Index Access Range in TiDB\nDESCRIPTION: Improvement in constructing more precise index access ranges for complex filter conditions, enhancing query performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.3.0.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\n((idx_col_1 > 1) or (idx_col_1 = 1 and idx_col_2 > 10)) and ((idx_col_1 < 10) or (idx_col_1 = 10 and idx_col_2 < 20))\n```\n\n----------------------------------------\n\nTITLE: Creating Expression Index in TiDB\nDESCRIPTION: SQL statement demonstrating how to create an expression index based on the YEAR function of the published_at column.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-index-best-practice.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX published_year_idx ON books ((YEAR(published_at)));\n```\n\n----------------------------------------\n\nTITLE: Using SELECT ... INTO OUTFILE with Field Formatting in SQL\nDESCRIPTION: Writes the result of a SQL query to a specified file, formatting the fields as comma-separated values and enclosing each field in double quotes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-select.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT * FROM t INTO OUTFILE '/tmp/tmp_file2' FIELDS TERMINATED BY ',' ENCLOSED BY '\"';\nQuery OK, 3 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: EXPLAIN ANALYZE Syntax in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax diagram for the EXPLAIN ANALYZE statement in TiDB, showing the various forms and options available including table descriptions and explainable statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\nExplainSym ::=\n    'EXPLAIN'\n|   'DESCRIBE'\n|    'DESC'\n\nExplainStmt ::=\n    ExplainSym ( TableName ColumnName? | 'ANALYZE'? ExplainableStmt | 'FOR' 'CONNECTION' NUM | 'FORMAT' '=' ( stringLit | ExplainFormatType ) ( 'FOR' 'CONNECTION' NUM | ExplainableStmt ) )\n\nExplainableStmt ::=\n    SelectStmt\n|   DeleteFromStmt\n|   UpdateStmt\n|   InsertIntoStmt\n|   ReplaceIntoStmt\n|   UnionStmt\n```\n\n----------------------------------------\n\nTITLE: Scaling Out TiFlash Cluster Using TiUP in Shell\nDESCRIPTION: This shell command uses TiUP to scale out the TiFlash cluster by adding new nodes according to the topology specified in the scale-out.topo.yaml file.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-disaggregated-and-s3.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster scale-out mycluster ./scale-out.topo.yaml\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with SQLAlchemy Engine\nDESCRIPTION: Python code to set up a connection to TiDB using SQLAlchemy by loading connection parameters from environment variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport dotenv\n\nfrom sqlalchemy import Column, Integer, create_engine, Text\nfrom sqlalchemy.orm import declarative_base, Session\nfrom tidb_vector.sqlalchemy import VectorType\n\ndotenv.load_dotenv()\n\ntidb_connection_string = os.environ['TIDB_DATABASE_URL']\nengine = create_engine(tidb_connection_string)\n```\n\n----------------------------------------\n\nTITLE: Creating an INSERT Prepared Statement in SQL\nDESCRIPTION: Demonstrates how to create a prepared statement for inserting data into the 'books' table with multiple placeholders.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-prepared-statement.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nPREPARE `books_insert` FROM 'INSERT INTO `books` (`title`, `type`, `stock`, `price`, `published_at`) VALUES (?, ?, ?, ?, ?);';\n```\n\n----------------------------------------\n\nTITLE: Expression Usage in SQL Statements\nDESCRIPTION: Demonstrates the contexts where expressions can be used in SQL statements, including ORDER BY, HAVING, WHERE, and SET clauses. Expressions can include literals, column names, NULL, built-in functions, and operators.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/functions-and-operators-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT column FROM table WHERE expression ORDER BY expression\n```\n\nLANGUAGE: SQL\nCODE:\n```\nUPDATE table SET column = expression WHERE condition\n```\n\n----------------------------------------\n\nTITLE: Creating a User with SSL Requirement in TiDB SQL\nDESCRIPTION: SQL statement to create a new user 'newuser3' that is required to use SSL connection for login in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser3'@'%' IDENTIFIED BY 'newuserpassword' REQUIRE SSL;\n```\n\n----------------------------------------\n\nTITLE: Querying Blocked Transaction Information in TiDB\nDESCRIPTION: SQL query to identify information about transactions that are blocking a specific transaction. This query joins data_lock_waits with cluster_tidb_trx tables and uses tidb_decode_sql_digests function to translate SQL digests into readable statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-lock-conflicts.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nselect l.key, trx.*, tidb_decode_sql_digests(trx.all_sql_digests) as sqls from information_schema.data_lock_waits as l join information_schema.cluster_tidb_trx as trx on l.current_holding_trx_id = trx.id where l.trx_id = 426831965449355272\\G\n```\n\n----------------------------------------\n\nTITLE: Executing Database Initialization Script in MySQL CLI\nDESCRIPTION: This shell command runs a database initialization script (init.sql) using the MySQL command-line client, connecting to a TiDB server with the specified host, port, and credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\nmysql\n    -u root \\\n    -h {host} \\\n    -P {port} \\\n    -p {password} \\\n    < init.sql\n```\n\n----------------------------------------\n\nTITLE: Inserting or Updating Book Rating in SQL\nDESCRIPTION: Example of using INSERT ON DUPLICATE KEY UPDATE to insert a new book rating or update an existing one if the user has already rated the book.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-update-data.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO `ratings`\n    (`book_id`, `user_id`, `score`, `rated_at`)\nVALUES\n    (1000, 1, 5, NOW())\nON DUPLICATE KEY UPDATE `score` = 5, `rated_at` = NOW();\n```\n\n----------------------------------------\n\nTITLE: Recommended Approach for Inserting into Tables with AUTO_RANDOM Primary Key\nDESCRIPTION: The recommended way to insert data into a table with an AUTO_RANDOM primary key by omitting the AUTO_RANDOM column and letting TiDB generate the value automatically.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-insert-data.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO `bookshop`.`users` (`balance`, `nickname`) VALUES (0.00, 'nicky');\n```\n\n----------------------------------------\n\nTITLE: Executing an INSERT Prepared Statement in SQL\nDESCRIPTION: Shows how to set multiple parameter values and execute the previously created prepared statement to insert a new book.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-prepared-statement.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSET @title = 'TiDB Developer Guide';\nSET @type = 'Science & Technology';\nSET @stock = 100;\nSET @price = 0.0;\nSET @published_at = NOW();\nEXECUTE `books_insert` USING @title, @type, @stock, @price, @published_at;\n```\n\n----------------------------------------\n\nTITLE: Validating Data Consistency with sync-diff-inspector\nDESCRIPTION: This shell command runs the sync-diff-inspector tool to compare data consistency between the upstream and downstream TiDB clusters, ensuring that all data has been replicated correctly after migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nsync_diff_inspector -C ./config.yaml\n\n```\n\n----------------------------------------\n\nTITLE: PREPARE Statement Example\nDESCRIPTION: Demonstrates a basic example of using the PREPARE statement in TiDB. It includes preparing a statement, setting a user variable, executing the prepared statement with the variable, and deallocating the prepared statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-prepare.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\n\"mysql> PREPARE mystmt FROM 'SELECT ? as num FROM DUAL';\\\nQuery OK, 0 rows affected (0.00 sec)\\\n\\\nmysql> SET @number = 5;\\\nQuery OK, 0 rows affected (0.00 sec)\\\n\\\nmysql> EXECUTE mystmt USING @number;\\\n+------+\\\n| num  |\\\n+------+\\\n| 5    |\\\n+------+\\\n1 row in set (0.00 sec)\\\n\\\nmysql> DEALLOCATE PREPARE mystmt;\\\nQuery OK, 0 rows affected (0.00 sec)\"\n```\n\n----------------------------------------\n\nTITLE: TiFlash Compression Method Configuration Parameter (New)\nDESCRIPTION: New TiFlash parameter that specifies the compression algorithm used. Options include LZ4, zstd, and LZ4HC (all case insensitive), with LZ4 as the default value.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_16\n\nLANGUAGE: toml\nCODE:\n```\nprofiles.default.dt_compression_method\n```\n\n----------------------------------------\n\nTITLE: Verifying SQL Bindings in TiDB SQL Before Upgrade\nDESCRIPTION: This SQL command retrieves the SQL queries associated with the current bindings and allows for verification against the new version prior to upgrading. Incorrect queries must be deleted to ensure compatibility.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_38\n\nLANGUAGE: sql\nCODE:\n```\nSELECT bind_sql FROM mysql.bind_info WHERE status = 'using';\n```\n\n----------------------------------------\n\nTITLE: Performing Nearest Neighbor Search with Cosine Distance\nDESCRIPTION: Query to find the top 3 documents closest to a given vector using cosine distance in TiDB Vector Search via Django ORM.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nresults = Document.objects.annotate(\n   distance=CosineDistance('embedding', [1, 2, 3])\n).order_by('distance')[:3]\n```\n\n----------------------------------------\n\nTITLE: Inserting data into TiDB with mysql.js\nDESCRIPTION: JavaScript code snippet showing how to insert a single Player record into TiDB and return the ID of the newly created record.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysqljs.md#2025-04-18_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nconn.query('INSERT INTO players (coins, goods) VALUES (?, ?);', [100, 100], (err, ok) => {\n   if (err) {\n       console.error(err);\n   } else {\n       console.log(ok.insertId);\n   }\n});\n```\n\n----------------------------------------\n\nTITLE: Creating and Modifying a Sequence Example\nDESCRIPTION: Example demonstrating how to create a sequence and then modify its increment value using ALTER SEQUENCE. The example shows the effect of the modification on the sequence values.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-sequence.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SEQUENCE s1;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT NEXTVAL(s1);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT NEXTVAL(s1);\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER SEQUENCE s1 INCREMENT=2;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT NEXTVAL(s1);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT NEXTVAL(s1);\n```\n\n----------------------------------------\n\nTITLE: Using JSON_SEARCH in SQL\nDESCRIPTION: Demonstrates JSON_SEARCH function to find one or all matches of a string within a JSON document.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-search.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SEARCH('{\"a\": [\"aa\", \"bb\", \"cc\"], \"b\": [\"cc\", \"dd\"]}','one','cc');\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SEARCH('{\"a\": [\"aa\", \"bb\", \"cc\"], \"b\": [\"cc\", \"dd\"]}','all','cc');\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud using Node.js\nDESCRIPTION: This snippet demonstrates how to connect to a TiDB Cloud Dedicated cluster using Node.js's `mysql2` library with TLS enabled. It requires specifying the path to the CA certificate, setting the minimum TLS version, and enabling unauthorized rejection in the SSL configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tls-connect-to-dedicated.md#2025-04-18_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nvar connection = mysql.createConnection({\n  host: 'tidb.srgnqxji5bc.clusters.staging.tidb-cloud.com',\n  port: 4000,\n  user: 'root',\n  password: '<your_password>',\n  database: 'test',\n  ssl: {\n    ca: fs.readFileSync('ca.pem'),\n    minVersion: 'TLSv1.2',\n    rejectUnauthorized: true\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Setting and Using User-Defined Variables in TiDB\nDESCRIPTION: SQL commands demonstrating how to set a user-defined variable and use it in a subsequent query in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-variable.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSET @myvar := 5;\nSELECT @myvar, @myvar + 1;\n```\n\n----------------------------------------\n\nTITLE: Query to Locate Partitioned Tables in TiDB\nDESCRIPTION: This SQL query retrieves a list of all partitioned tables in the database, excluding system schemas. It uses the `information_schema.PARTITIONS` table to identify partitioned tables based on the `TIDB_PARTITION_ID` column and concatenates the schema and table names.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_80\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DISTINCT CONCAT(TABLE_SCHEMA,'.', TABLE_NAME)\n    FROM information_schema.PARTITIONS\n    WHERE TIDB_PARTITION_ID IS NOT NULL\n    AND TABLE_SCHEMA NOT IN ('INFORMATION_SCHEMA', 'mysql', 'sys', 'PERFORMANCE_SCHEMA', 'METRICS_SCHEMA');\n```\n\nLANGUAGE: sql\nCODE:\n```\n+\n| concat(TABLE_SCHEMA,'.',TABLE_NAME) |\n+\n| test.t                              |\n+\n1 row in set (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Enabling a Data Source with cURL in Shell\nDESCRIPTION: This example demonstrates how to enable a data source by making a POST request to the DM API. When enabled, all subtasks that rely on this data source will be started in batch.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'POST' \\\n  'http://127.0.0.1:8261/api/v1/sources/mysql-01/enable' \\\n  -H 'accept: */*' \\\n  -H 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Creating and Granting Analytics Role\nDESCRIPTION: SQL commands to create an analytics team role, grant privileges, create a user, and assign the role to the user.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-revoke-role.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE ROLE analyticsteam;\nQuery OK, 0 rows affected (0.02 sec)\n\nGRANT SELECT ON test.* TO analyticsteam;\nQuery OK, 0 rows affected (0.02 sec)\n\nCREATE USER jennifer;\nQuery OK, 0 rows affected (0.01 sec)\n\nGRANT analyticsteam TO jennifer;\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Inserting or Updating Book Rating in Java\nDESCRIPTION: Java code example using JDBC to execute an INSERT ON DUPLICATE KEY UPDATE statement for inserting or updating a book rating.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-update-data.md#2025-04-18_snippet_5\n\nLANGUAGE: java\nCODE:\n```\n// ds is an entity of com.mysql.cj.jdbc.MysqlDataSource\n\ntry (Connection connection = ds.getConnection()) {\n    PreparedStatement p = connection.prepareStatement(\"INSERT INTO `ratings` (`book_id`, `user_id`, `score`, `rated_at`)\nVALUES (?, ?, ?, NOW()) ON DUPLICATE KEY UPDATE `score` = ?, `rated_at` = NOW()\");\n    p.setInt(1, 1000);\n    p.setInt(2, 1);\n    p.setInt(3, 5);\n    p.setInt(4, 5);\n    p.executeUpdate();\n} catch (SQLException e) {\n    e.printStackTrace();\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Global Bindings from Query History in TiDB\nDESCRIPTION: This snippet demonstrates the process of creating global bindings from query history in TiDB. It includes executing various SQL operations, collecting plan digests, creating global bindings, and verifying their effects using the LAST_PLAN_FROM_BINDING variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-binding.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @digests:=GROUP_CONCAT(plan_digest) FROM information_schema.statements_summary_history WHERE table_names LIKE '%test.t1%' AND stmt_type != 'CreateTable';\n\nCREATE GLOBAL BINDING FROM HISTORY USING PLAN DIGEST @digests;\n\nSHOW GLOBAL BINDINGS;\n\nINSERT INTO t1 SELECT * FROM t2 WHERE a = 1;\nSELECT @@LAST_PLAN_FROM_BINDING;\n\nUPDATE t1, t2 SET t1.a = 1 WHERE t1.b = t2.a;\nSELECT @@LAST_PLAN_FROM_BINDING;\n\nDELETE t1 FROM t1 JOIN t2 WHERE t1.b = t2.a;\nSELECT @@LAST_PLAN_FROM_BINDING;\n\nSELECT * FROM t1 WHERE t1.a IN (SELECT a FROM t2);\nSELECT @@LAST_PLAN_FROM_BINDING;\n```\n\n----------------------------------------\n\nTITLE: Importing Data from SQL File to TiDB Cloud using MySQL CLI\nDESCRIPTION: Command for importing data from an SQL file into TiDB Cloud using MySQL CLI. The command includes connection parameters such as username, host, port, database name, and SSL configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-with-mysql-cli.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmysql --comments --connect-timeout 150 -u '<your_username>' -h <your_cluster_host> -P 4000 -D test --ssl-mode=VERIFY_IDENTITY --ssl-ca=<your_ca_path> -p <your_password> < product_data.sql\n```\n\n----------------------------------------\n\nTITLE: Data Summary Object Structure in JavaScript\nDESCRIPTION: Structure of the DataSummaryObject returned in the job status response. This object contains detailed information about the database including tables, columns, relationships, and AI-generated descriptions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n{\n    \"cluster_id\": \"10140100115280519574\", // The cluster ID\n    \"data_summary_id\": 304823, // The data summary ID\n    \"database\": \"sp500insight\", // The database name\n    \"default\": false, // Whether this data summary is the default one\n    \"status\": \"done\", // The status of the data summary\n    \"description\": {\n        \"system\": \"Data source for financial analysis and decision-making in stock market\", // The description of the data summary generated by AI\n        \"user\": \"Data summary for SP500 Insight\" // The description of the data summary provided by the user\n    },\n    \"keywords\": [\"User_Stock_Selection\", \"Index_Composition\"], // Keywords of the data summary\n    \"relationships\": {\n        \"companies\": {\n            \"referencing_table\": \"...\", // The table that references the `companies` table\n            \"referencing_table_column\": \"...\" // The column that references the `companies` table\n            \"referenced_table\": \"...\", // The table that the `companies` table references\n            \"referenced_table_column\": \"...\" // The column that the `companies` table references\n        }\n    }, // Relationships between tables\n    \"summary\": \"Financial data source for stock market analysis\", // The summary of the data summary\n    \"tables\": { // Tables in the database\n      \"companies\": {\n        \"name\": \"companies\" // The table name\n        \"description\": \"This table provides comprehensive...\", // The description of the table\n        \"columns\": {\n          \"city\": { // Columns in the table\n            \"name\": \"city\" // The column name\n            \"description\": \"The city where the company is headquartered.\", // The description of the column\n          }\n        },\n      },\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using STREAM_AGG Hint for Aggregation in SQL\nDESCRIPTION: Uses the STREAM_AGG hint to force the optimizer to use the stream aggregation algorithm for all aggregate functions. This generally consumes less memory but takes longer processing time, recommended for large data volumes.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ STREAM_AGG() */ count(*) from t1, t2 where t1.a > 10 group by t1.id;\n```\n\n----------------------------------------\n\nTITLE: Defining a Single-Column Foreign Key\nDESCRIPTION: This SQL snippet demonstrates how to define a simple single-column foreign key in TiDB, establishing a relationship between a parent and child table.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE parent (\n    id INT KEY\n);\n\nCREATE TABLE child (\n    id INT,\n    pid INT,\n    INDEX idx_pid (pid),\n    FOREIGN KEY (pid) REFERENCES parent(id) ON DELETE CASCADE\n);\n```\n\n----------------------------------------\n\nTITLE: Recovering Truncated Table Example\nDESCRIPTION: Example demonstrating how to recover a table that was truncated by renaming it during recovery.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-table.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nTRUNCATE TABLE t;\nFLASHBACK TABLE t TO t1;\n```\n\n----------------------------------------\n\nTITLE: Using JDBC Batch Methods with TiDB\nDESCRIPTION: Example demonstrating how to use prepared statements with batch operations in JDBC. This shows the pattern of setting parameters and adding multiple operations to a batch before execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_7\n\nLANGUAGE: java\nCODE:\n```\npstmt = prepare(\"INSERT INTO `t` (a) values(?)\");\npstmt.setInt(1, 10);\npstmt.addBatch();\npstmt.setInt(1, 11);\npstmt.addBatch();\npstmt.setInt(1, 12);\npstmt.executeBatch();\n```\n\n----------------------------------------\n\nTITLE: Querying Books with Title Filter in SQL\nDESCRIPTION: This SQL query selects the title and price of books where the title matches 'Marian Yost'. It demonstrates the need for a covering index to optimize performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT title, price FROM books WHERE title = 'Marian Yost';\n```\n\n----------------------------------------\n\nTITLE: Creating a Next.js Project\nDESCRIPTION: This shell command initializes a new Next.js project named `hello-repos` using Yarn. It's the starting point for developing the user's application.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-oas-with-nextjs.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nyarn create next-app hello-repos\n```\n\n----------------------------------------\n\nTITLE: Configuring Shard Mode in TiDB DM\nDESCRIPTION: YAML configuration snippet showing how to set the shard-mode parameter for TiDB Data Migration. The pessimistic mode enables sharding DDL merge functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-shard-merge.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nshard-mode: \"pessimistic\"\n# The shard merge mode. Optional modes are \"\"/\"pessimistic\"/\"optimistic\". The \"\" mode is used by default\n# which means sharding DDL merge is disabled. If the task is a shard merge task, set it to the \"pessimistic\"\n# mode. After getting a deep understanding of the principles and restrictions of the \"optimistic\" mode, you\n# can set it to the \"optimistic\" mode.\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Character Set and Collation\nDESCRIPTION: SQL syntax for creating or altering a table with specific character set and collation settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE tbl_name (column_list)\n    [[DEFAULT] CHARACTER SET charset_name]\n    [COLLATE collation_name]]\n\nALTER TABLE tbl_name\n    [[DEFAULT] CHARACTER SET charset_name]\n    [COLLATE collation_name]\n```\n\n----------------------------------------\n\nTITLE: Hash Join Execution Plan in TiDB\nDESCRIPTION: A detailed execution plan showing a hash join operation between two tables with associated performance metrics and resource usage statistics. The plan demonstrates a sub-optimal hash join chosen over an index join.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------+----------+---------+-----------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+---------+---------+\n| id                           | estRows  | actRows | task      | access object | execution info                                                                                                                                                                                                                                                                                                             | operator info                                     | memory  | disk    |\n+------------------------------+----------+---------+-----------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+---------+---------+\n| HashJoin_33                  | 90000.00 | 0       | root      |               | time:306.3ms, loops:1, build_hash_table:{total:20.5ms, fetch:17.1ms, build:3.45ms}, probe:{concurrency:5, total:1.53s, max:305.9ms, probe:17.1ms, fetch:1.51s}                                                                                                                                                             | inner join, equal:[eq(test.t1.id, test.t2.t1_id)] | 32.0 MB | 0 Bytes |\n| ├─TableReader_42(Build)      | 9955.54  | 10000   | root      |               | time:19.6ms, loops:12, cop_task: {num: 11, max: 1.07ms, min: 246.1µs, avg: 600µs, p95: 1.07ms, rpc_num: 11, rpc_time: 6.17ms, copr_cache_hit_ratio: 1.00, distsql_concurrency: 15}                                                                                                                                         | data:Selection_41                                 | 19.7 MB | N/A     |\n| │ └─Selection_41             | 9955.54  | 10000   | cop[tikv] |               | tikv_task:{proc max:104ms, min:3ms, avg: 24.4ms, p80:33ms, p95:104ms, iters:113, tasks:11}, scan_detail: {get_snapshot_time: 282.9µs, rocksdb: {block: {}}}                                                                                                                                                                | eq(test.t1.int_col, 1)                            | N/A     | N/A     |\n| │   └─TableFullScan_40       | 71010.00 | 71010   | cop[tikv] | table:t1      | tikv_task:{proc max:101ms, min:3ms, avg: 23.8ms, p80:33ms, p95:101ms, iters:113, tasks:11}                                                                                                                                                                                                                                 | keep order:false                                  | N/A     | N/A     |\n| └─TableReader_44(Probe)      | 90000.00 | 90000   | root      |               | time:289.2ms, loops:91, cop_task: {num: 24, max: 108.2ms, min: 252.8µs, avg: 31.3ms, p95: 106.1ms, max_proc_keys: 10687, p95_proc_keys: 9184, tot_proc: 445ms, rpc_num: 24, rpc_time: 750.4ms, copr_cache_hit_ratio: 0.62, distsql_concurrency: 15}                                                                        | data:TableFullScan_43                             | 58.6 MB | N/A     |\n|   └─TableFullScan_43         | 90000.00 | 90000   | cop[tikv] | table:t2      | tikv_task:{proc max:31ms, min:3ms, avg: 13.3ms, p80:24ms, p95:30ms, iters:181, tasks:24}, scan_detail: {total_process_keys: 69744, total_process_keys_size: 217533936, total_keys: 139497, get_snapshot_time: 730.2µs, rocksdb: {delete_skipped_count: 44208, key_skipped_count: 253431, block: {cache_hit_count: 3527}}}  | keep order:false                                  | N/A     | N/A     |\n+------------------------------+----------+---------+-----------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+---------+---------+\n```\n\n----------------------------------------\n\nTITLE: Querying Top 50 Eldest Authors Using Non-recursive CTE in Java\nDESCRIPTION: This Java snippet shows how to execute a SQL query with a non-recursive CTE to retrieve information about the 50 oldest authors and the number of books they've written.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-common-table-expression.md#2025-04-18_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\npublic List<Author> getTop50EldestAuthorInfoByCTE() throws SQLException {\n    List<Author> authors = new ArrayList<>();\n    try (Connection conn = ds.getConnection()) {\n        Statement stmt = conn.createStatement();\n        ResultSet rs = stmt.executeQuery(\"\"\"\n            WITH top_50_eldest_authors_cte AS (\n                SELECT a.id, a.name, (IFNULL(a.death_year, YEAR(NOW())) - a.birth_year) AS age\n                FROM authors a\n                ORDER BY age DESC\n                LIMIT 50\n            )\n            SELECT\n                ANY_VALUE(ta.id) AS author_id,\n                ANY_VALUE(ta.name) AS author_name,\n                ANY_VALUE(ta.age) AS author_age,\n                COUNT(*) AS books\n            FROM top_50_eldest_authors_cte ta\n            LEFT JOIN book_authors ba ON ta.id = ba.author_id\n            GROUP BY ta.id;\n        \"\"\");\n        while (rs.next()) {\n            Author author = new Author();\n            author.setId(rs.getLong(\"author_id\"));\n            author.setName(rs.getString(\"author_name\"));\n            author.setAge(rs.getShort(\"author_age\"));\n            author.setBooks(rs.getInt(\"books\"));\n            authors.add(author);\n        }\n    }\n    return authors;\n}\n```\n\n----------------------------------------\n\nTITLE: Cartesian Join Analysis\nDESCRIPTION: Example showing how to identify inefficient Cartesian product joins in query execution plans, which should be avoided due to their multiplicative effect on result set size.\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain select * from t t1, t t2 where t1.a>t2.a;\n```\n\n----------------------------------------\n\nTITLE: Importing a CSV File with Headers in TiDB\nDESCRIPTION: This SQL statement demonstrates how to import a CSV file into a TiDB table while skipping the header row. The `skip_rows=1` option is used to ignore the first row of the CSV file, which is typically the header row containing column names.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t FROM '/path/to/file.csv' WITH skip_rows=1;\n```\n\n----------------------------------------\n\nTITLE: Configuring DM Task in YAML\nDESCRIPTION: This YAML snippet configures a DM task for migrating and merging MySQL shards. It includes the task name, mode (full and incremental), shard mode (pessimistic), meta-schema, target database connection details, MySQL instance configurations, route rules, and filter rules. The configuration specifies how to merge data from sharded tables in MySQL to a single table in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-shards-to-tidb.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n\"name: \\\"shard_merge\\\"               # The name of the task. Should be globally unique.\n# Task mode. You can set it to the following:\n# - full: Performs only full data migration (incremental replication is skipped)\n# - incremental: Only performs real-time incremental replication using binlog. (full data migration is skipped)\n# - all: Performs both full data migration and incremental replication. For migrating small to medium amount of data here, use this option.\ntask-mode: all\n# Required for the MySQL shards. By default, the \\\"pessimistic\\\" mode is used.\n# If you have a deep understanding of the principles and usage limitations of the optimistic mode, you can also use the \\\"optimistic\\\" mode.\n# For more information, see [Merge and Migrate Data from Sharded Tables](https://docs.pingcap.com/tidb/dev/feature-shard-merge/)\nshard-mode: \\\"pessimistic\\\"\nmeta-schema: \\\"dm_meta\\\"                        # A schema will be created in the downstream database to store the metadata\nignore-checking-items: [\\\"auto_increment_ID\\\"]  # In this example, there are auto-incremental primary keys upstream, so you do not need to check this item.\n\ntarget-database:\n  host: \\\"${host}\\\"                             # For example: 192.168.0.1\n  port: 4000\n  user: \\\"root\\\"\n  password: \\\"${password}\\\"                     # Plaintext passwords are supported but not recommended. It is recommended that you use dmctl encrypt to encrypt plaintext passwords.\n\nmysql-instances:\n  -\n    source-id: \\\"mysql-01\\\"                                    # ID of the data source, which is source-id in source1.yaml\n    route-rules: [\\\"sale-route-rule\\\"]                         # Table route rules applied to the data source\n    filter-rules: [\\\"store-filter-rule\\\", \\\"sale-filter-rule\\\"]  # Binlog event filter rules applied to the data source\n    block-allow-list:  \\\"log-bak-ignored\\\"                     # Block & Allow Lists rules applied to the data source\n  -\n    source-id: \\\"mysql-02\\\"\n    route-rules: [\\\"sale-route-rule\\\"]\n    filter-rules: [\\\"store-filter-rule\\\", \\\"sale-filter-rule\\\"]\n    block-allow-list:  \\\"log-bak-ignored\\\"\n\n# Configurations for merging MySQL shards\nroutes:\n  sale-route-rule:\n    schema-pattern: \\\"store_*\\\"                               # Merge schemas store_01 and store_02 to the store schema in the downstream\n    table-pattern: \\\"sale_*\\\"                                 # Merge tables sale_01 and sale_02 of schemas store_01 and store_02 to the sale table in the downstream\n    target-schema: \\\"store\\\"\n    target-table:  \\\"sale\\\"\n    # Optional. Used for extracting the source information of sharded schemas and tables and writing the information to the user-defined columns in the downstream. If these options are configured, you need to manually create a merged table in the downstream. For details, see the following table routing setting.\n    # extract-table:                                        # Extracts and writes the table name suffix without the sale_ part to the c-table column of the merged table. For example, 01 is extracted and written to the c-table column for the sharded table sale_01.\n    #   table-regexp: \\\"sale_(.*)\\\"\n    #   target-column: \\\"c_table\\\"\n    # extract-schema:                                       # Extracts and writes the schema name suffix without the store_ part to the c_schema column of the merged table. For example, 02 is extracted and written to the c_schema column for the sharded schema store_02.\n    #   schema-regexp: \\\"store_(.*)\\\"\n    #   target-column: \\\"c_schema\\\"\n    # extract-source:                                       # Extracts and writes the source instance information to the c_source column of the merged table. For example, mysql-01 is extracted and written to the c_source column for the data source mysql-01.\n    #   source-regexp: \\\"(.*)\\\"\n    #   target-column: \\\"c_source\\\"\n\n# Filters out some DDL events.\nfilters:\n  sale-filter-rule:           # Filter name.\n    schema-pattern: \\\"store_*\\\" # The binlog events or DDL SQL statements of upstream MySQL instance schemas that match schema-pattern are filtered by the rules below.\n    table-pattern: \\\"sale_*\\\"   # The binlog events or DDL SQL statements of upstream MySQL instance tables that match table-pattern are filtered by the rules below.\n    events: [\\\"truncate table\\\", \\\"drop table\\\", \\\"delete\\\"]   # The binlog event array.\n    action: Ignore                                       # The string (`Do`/`Ignore`). `Do` is the allow list. `Ignore` is the block list.\n  store-filter-rule:\n    schema-pattern: \\\"store_*\\\"\n    events: [\\\"drop database\\\"]\n    action: Ignore\"\n```\n\n----------------------------------------\n\nTITLE: Performing Vector Search with TiDB and LlamaIndex in Python\nDESCRIPTION: Creates a query engine from a TiDB vector store index and performs a semantic similarity search. This demonstrates the basic vector search capability using the default query mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nquery_engine = index.as_query_engine()\nresponse = query_engine.query(\"What did the author do?\")\nprint(textwrap.fill(str(response), 100))\n```\n\n----------------------------------------\n\nTITLE: Defining SET TRANSACTION Syntax in EBNF\nDESCRIPTION: This code snippet defines the syntax for the SET TRANSACTION statement using EBNF notation. It outlines how variables, passwords, and transaction parameters can be set globally or per session.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-transaction.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nSetStmt ::=\n    'SET' ( VariableAssignmentList |\n    'PASSWORD' ('FOR' Username)? '=' PasswordOpt |\n    ( 'GLOBAL'| 'SESSION' )? 'TRANSACTION' TransactionChars |\n    'CONFIG' ( Identifier | stringLit) ConfigItemName EqOrAssignmentEq SetExpr )\n\nTransactionChars ::=\n    ( 'ISOLATION' 'LEVEL' IsolationLevel | 'READ' 'WRITE' | 'READ' 'ONLY' AsOfClause? )\n\nIsolationLevel ::=\n    ( 'REPEATABLE' 'READ' | 'READ' ( 'COMMITTED' | 'UNCOMMITTED' ) | 'SERIALIZABLE' )\n\nAsOfClause ::=\n    ( 'AS' 'OF' 'TIMESTAMP' Expression)\n```\n\n----------------------------------------\n\nTITLE: Querying Data in TiDB SQL\nDESCRIPTION: Retrieves all data from table 't' to verify the initial insertion. Shows the current state of the table with three rows of data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-read-staleness.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nselect * from t;\n```\n\n----------------------------------------\n\nTITLE: Optimizing Single Max/Min Function Query in SQL\nDESCRIPTION: Example of how TiDB optimizes a query with a single max function. The original query is rewritten to use a subquery with ORDER BY and LIMIT, allowing for efficient index usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/max-min-eliminate.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nselect max(a) from t\n```\n\nLANGUAGE: sql\nCODE:\n```\nselect max(a) from (select a from t where a is not null order by a desc limit 1) t\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW MASTER STATUS in SQL\nDESCRIPTION: This code snippet demonstrates how to execute the SHOW MASTER STATUS command in SQL to retrieve the latest TSO from the TiDB database. It requires a running TiDB instance to connect to. The expected output consists of a table with columns File, Position, Binlog_Do_DB, Binlog_Ignore_DB, and Executed_Gtid_Set, detailing the binlog status.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-master-status.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW MASTER STATUS;\n```\n\n----------------------------------------\n\nTITLE: Calling Deployed Endpoint with curl in TiDB Cloud\nDESCRIPTION: Example of using curl to call a deployed (online) endpoint in TiDB Cloud Data Service. Uses digest authentication with public and private API keys to securely access the endpoint.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-get-started.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user '<Public Key>:<Private Key>' \\\n  --request GET 'https://<region>.data.tidbcloud.com/api/v1beta/app/<App ID>/endpoint/<Endpoint Path>'\n```\n\n----------------------------------------\n\nTITLE: Using Parameter Variables in SQL Statements\nDESCRIPTION: Shows how to use parameter variables in SQL statements for creating dynamic endpoints. Parameters are defined as placeholders using ${parameter_name} syntax and can have data types, default values, and test values configured.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-get-started.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM table_name WHERE id = ${ID}\n```\n\n----------------------------------------\n\nTITLE: Optimizing Statistics Collection\nDESCRIPTION: These SQL statements adjust the concurrency settings to accelerate the collection of statistics. By increasing the concurrency for building stats, distsql scans, and index serial scans, the statistics collection process can be significantly sped up, especially for large tables. These settings are applied before running the `ANALYZE TABLE` statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v6.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n\"SET tidb_build_stats_concurrency=16;\\nSET tidb_distsql_scan_concurrency=16;\\nSET tidb_index_serial_scan_concurrency=16;\"\n```\n\n----------------------------------------\n\nTITLE: Analyzing Query Execution with EXPLAIN ANALYZE in TiDB\nDESCRIPTION: This SQL snippet demonstrates using EXPLAIN ANALYZE to identify performance bottlenecks in a query execution plan, showing execution time for different stages including TiKV tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\n+----------------------------+---------+---------+-----------+---------------+------------------------------------------------------------------------------+---------------------------------+-----------+------+\n| id                         | estRows | actRows | task      | access object | execution info                                                               | operator info                   | memory    | disk |\n+----------------------------+---------+---------+-----------+---------------+------------------------------------------------------------------------------+---------------------------------+-----------+------+\n| StreamAgg_16               | 1.00    | 1       | root      |               | time:170.08572ms, loops:2                                                     | funcs:count(Column#5)->Column#3 | 372 Bytes | N/A  |\n| └─TableReader_17           | 1.00    | 1       | root      |               | time:170.080369ms, loops:2, rpc num: 1, rpc time:17.023347ms, proc keys:28672 | data:StreamAgg_8                | 202 Bytes | N/A  |\n|   └─StreamAgg_8            | 1.00    | 1       | cop[tikv] |               | time:170ms, loops:29                                                          | funcs:count(1)->Column#5        | N/A       | N/A  |\n|     └─TableFullScan_15     | 7.00    | 28672   | cop[tikv] | table:t       | time:170ms, loops:29                                                          | keep order:false, stats:pseudo  | N/A       | N/A  |\n+----------------------------+---------+---------+-----------+---------------+------------------------------------------------------------------------------+---------------------------------+-----------+------+\n```\n\n----------------------------------------\n\nTITLE: Grant and Revoke Privileges with Escapes and Identifiers\nDESCRIPTION: Demonstrates how to use escape characters and different quotation types correctly in SQL privilege management. When dealing with exact and fuzzy matching, it is critical to use backticks for identifiers and single quotes for strings to avoid syntax errors. This section provides insights into handling special characters in database and table names, illustrating best practices for preventing security or syntax issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/privilege-management.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nGRANT ALL PRIVILEGES ON `te\\%`.* TO 'genius'@'localhost';\n```\n\nLANGUAGE: sql\nCODE:\n```\nGRANT ALL PRIVILEGES ON 'test'.* TO 'genius'@'localhost';\n```\n\nLANGUAGE: sql\nCODE:\n```\nGRANT ALL PRIVILEGES ON `test`.* TO 'genius'@'localhost';\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `select` (id int);\n```\n\n----------------------------------------\n\nTITLE: Implementing Bulk Delete in Python for TiDB\nDESCRIPTION: This Python code demonstrates how to perform a bulk delete operation on the 'ratings' table in TiDB. It deletes records within a specific time range in batches of 1000 rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-delete-data.md#2025-04-18_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport MySQLdb\nimport datetime\nimport time\nconnection = MySQLdb.connect(\n    host=\"127.0.0.1\",\n    port=4000,\n    user=\"root\",\n    password=\"\",\n    database=\"bookshop\",\n    autocommit=True\n)\nwith connection:\n    with connection.cursor() as cursor:\n        start_time = datetime.datetime(2022, 4, 15)\n        end_time = datetime.datetime(2022, 4, 15, 0, 15)\n        affect_rows = -1\n        while affect_rows != 0:\n            delete_sql = \"DELETE FROM `bookshop`.`ratings` WHERE `rated_at` >= %s AND  `rated_at` <= %s LIMIT 1000\"\n            affect_rows = cursor.execute(delete_sql, (start_time, end_time))\n            print(f'delete {affect_rows} data')\n            time.sleep(1)\n```\n\n----------------------------------------\n\nTITLE: Execution Plan for Optimized Multiple Max/Min Functions Query in SQL\nDESCRIPTION: Displays the execution plan for the optimized query with multiple max/min functions, showing how TiDB uses index scans and limits to efficiently retrieve both the maximum and minimum values.\nSOURCE: https://github.com/pingcap/docs/blob/master/max-min-eliminate.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain select max(a)-min(a) from t;\n+------------------------------------+---------+-----------+-------------------------+-------------------------------------+\n| id                                 | estRows | task      | access object           | operator info                       |\n+------------------------------------+---------+-----------+-------------------------+-------------------------------------+\n| Projection_17                      | 1.00    | root      |                         | minus(Column#4, Column#5)->Column#6 |\n| └─HashJoin_18                      | 1.00    | root      |                         | CARTESIAN inner join                |\n|   ├─StreamAgg_45(Build)            | 1.00    | root      |                         | funcs:min(test.t.a)->Column#5       |\n|   │ └─Limit_49                     | 1.00    | root      |                         | offset:0, count:1                   |\n|   │   └─IndexReader_59             | 1.00    | root      |                         | index:Limit_58                      |\n|   │     └─Limit_58                 | 1.00    | cop[tikv] |                         | offset:0, count:1                   |\n|   │       └─IndexFullScan_57       | 1.00    | cop[tikv] | table:t, index:idx_a(a) | keep order:true, stats:pseudo       |\n|   └─StreamAgg_24(Probe)            | 1.00    | root      |                         | funcs:max(test.t.a)->Column#4       |\n|     └─Limit_28                     | 1.00    | root      |                         | offset:0, count:1                   |\n|       └─IndexReader_38             | 1.00    | root      |                         | index:Limit_37                      |\n|         └─Limit_37                 | 1.00    | cop[tikv] |                         | offset:0, count:1                   |\n|           └─IndexFullScan_36       | 1.00    | cop[tikv] | table:t, index:idx_a(a) | keep order:true, desc, stats:pseudo |\n+------------------------------------+---------+-----------+-------------------------+-------------------------------------+\n12 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Vector Arithmetic in SQL\nDESCRIPTION: Demonstrates arithmetic operations on vector data types, including addition and subtraction.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-data-types.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT VEC_FROM_TEXT('[4]') + VEC_FROM_TEXT('[5]');\n\nSELECT VEC_FROM_TEXT('[2,3,4]') - VEC_FROM_TEXT('[1,2,3]');\n```\n\n----------------------------------------\n\nTITLE: Finding Hot Keys Causing Lock Queueing in TiDB\nDESCRIPTION: This SQL query helps identify hot keys that frequently cause lock conflicts by aggregating data from the data_lock_waits table and ordering by frequency.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-lock-conflicts.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nselect `key`, count(*) as `count` from information_schema.data_lock_waits group by `key` order by `count` desc;\n```\n\n----------------------------------------\n\nTITLE: Creating a Global Binding with Execution Time Limit - SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a global binding for a select statement to limit its execution time to 1 millisecond using the MAX_EXECUTION_TIME hint. This is useful for managing potentially runaway queries in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/sql-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE GLOBAL BINDING for\n    SELECT * FROM t1, t2 WHERE t1.id = t2.id\nUSING\n    SELECT /*+ MAX_EXECUTION_TIME(1) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Example of Creating and Using a New Database\nDESCRIPTION: Practical example demonstrating how to create a new database, switch to it, create a table, and verify the table creation.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-database.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE DATABASE mynewdatabase;\nQuery OK, 0 rows affected (0.09 sec)\n\nmysql> USE mynewdatabase;\nDatabase changed\nmysql> CREATE TABLE t1 (a int);\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> SHOW TABLES;\n+-------------------------+\n| Tables_in_mynewdatabase |\n+-------------------------+\n| t1                      |\n+-------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Executing Prepared Statements with Parameters in TiDB SQL\nDESCRIPTION: Example of preparing a statement, setting a variable, executing the prepared statement with a parameter, and deallocating the prepared statement in TiDB SQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-execute.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> PREPARE mystmt FROM 'SELECT ? as num FROM DUAL';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SET @number = 5;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> EXECUTE mystmt USING @number;\n+------+\n| num  |\n+------+\n| 5    |\n+------+\n1 row in set (0.00 sec)\n\nmysql> DEALLOCATE PREPARE mystmt;\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying Authors Older Than Average Age Using Subquery in SQL\nDESCRIPTION: This SQL query selects authors from the 'authors' table whose age is greater than the average age. It uses a self-contained subquery as a comparison operator operand.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-subqueries.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM authors a1 WHERE (IFNULL(a1.death_year, YEAR(NOW())) - a1.birth_year) > (\n    SELECT\n        AVG(IFNULL(a2.death_year, YEAR(NOW())) - a2.birth_year) AS average_age\n    FROM\n        authors a2\n)\n```\n\n----------------------------------------\n\nTITLE: Listing Projects with ticloud CLI in Shell\nDESCRIPTION: Commands to list all accessible projects using the TiDB Cloud CLI. It includes the main command and its alias, along with an example of using the JSON output format.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-project-list.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud project list [flags]\n```\n\nLANGUAGE: shell\nCODE:\n```\nticloud project ls [flags]\n```\n\nLANGUAGE: shell\nCODE:\n```\nticloud project list\n```\n\nLANGUAGE: shell\nCODE:\n```\nticloud project list -o json\n```\n\n----------------------------------------\n\nTITLE: Configuring SASL/GSSAPI User Authentication in Kafka\nDESCRIPTION: This snippet demonstrates how to set up SASL/GSSAPI authentication for Kafka using user authentication. It illustrates the required parameters including the Kerberos config path, service name, and user credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"kafka://127.0.0.1:9092/topic-name?kafka-version=2.4.0&sasl-mechanism=gssapi&sasl-gssapi-auth-type=user&sasl-gssapi-kerberos-config-path=/etc/krb5.conf&sasl-gssapi-service-name=kafka&sasl-gssapi-user=alice/for-kafka&sasl-gssapi-password=alice-secret&sasl-gssapi-realm=example.com\"\n```\n\n----------------------------------------\n\nTITLE: Killing a DML Statement in TiDB\nDESCRIPTION: This snippet describes how to kill a DML statement in TiDB. It involves first finding the TiDB instance address and session ID using `information_schema.cluster_processlist`, and then running the kill command. If Global Kill is enabled (TiDB v6.1.0+), simply execute `kill session_id`.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/manage-cluster-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nkill session_id\n```\n\n----------------------------------------\n\nTITLE: Performing Similarity Search with Scores in Python using TiDB Vector Store\nDESCRIPTION: This code demonstrates how to use similarity_search_with_score() method to retrieve the top k documents with the lowest vector space distance scores from TiDB vector store. A lower score indicates higher similarity between the document and query.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndocs_with_score = vector_store.similarity_search_with_score(query, k=3)\nfor doc, score in docs_with_score:\n   print(\"-\" * 80)\n   print(\"Score: \", score)\n   print(doc.page_content)\n   print(\"-\" * 80)\n```\n\n----------------------------------------\n\nTITLE: SQL Queries for Estimating Data Volume in MySQL\nDESCRIPTION: SQL statements to estimate the data volume in MySQL before exporting with Dumpling. The first query calculates the size of all schemas, while the second query identifies the five largest tables in the database to help plan for sufficient storage space in the target TiKV cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-requirements.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n-- Calculate the size of all schemas\nSELECT\n  TABLE_SCHEMA,\n  FORMAT_BYTES(SUM(DATA_LENGTH)) AS 'Data Size',\n  FORMAT_BYTES(SUM(INDEX_LENGTH)) 'Index Size'\nFROM\n  information_schema.tables\nGROUP BY\n  TABLE_SCHEMA;\n\n-- Calculate the 5 largest tables\nSELECT \n  TABLE_NAME,\n  TABLE_SCHEMA,\n  FORMAT_BYTES(SUM(data_length)) AS 'Data Size',\n  FORMAT_BYTES(SUM(index_length)) AS 'Index Size',\n  FORMAT_BYTES(SUM(data_length+index_length)) AS 'Total Size'\nFROM\n  information_schema.tables\nGROUP BY\n  TABLE_NAME,\n  TABLE_SCHEMA\nORDER BY\n  SUM(DATA_LENGTH+INDEX_LENGTH) DESC\nLIMIT\n  5;\n```\n\n----------------------------------------\n\nTITLE: Creating Combined Index in TiDB\nDESCRIPTION: SQL statement demonstrating how to create a combined index on title and published_at columns in the books table.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-index-best-practice.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX title_published_at_idx ON books (title, published_at);\n```\n\n----------------------------------------\n\nTITLE: Creating a user with TLS requirement in TiDB\nDESCRIPTION: This SQL command creates a new user in TiDB named 'u1' with a password 'my_random_password'. The `REQUIRE SSL` clause enforces that this user must connect to the TiDB server using a TLS encrypted connection. This ensures that all communication for this user is protected from eavesdropping and tampering.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-clients-and-servers.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'u1'@'%' IDENTIFIED BY 'my_random_password' REQUIRE SSL;\n```\n\n----------------------------------------\n\nTITLE: SQL EXPLAIN for IndexReader Optimization\nDESCRIPTION: These SQL EXPLAIN statements demonstrate the difference in execution plans when using a covering index versus when a table lookup is required. The first example uses `IndexLookUp` and `TableRowIDScan`, whereas the second example demonstrates using the `IndexReader` operator when all required columns are present in the index.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-indexes.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t1 WHERE intkey = 123;\nEXPLAIN SELECT id FROM t1 WHERE intkey = 123;\n```\n\n----------------------------------------\n\nTITLE: Using NO_INDEX_HASH_JOIN Optimizer Hint - SQL\nDESCRIPTION: This snippet describes how to apply the NO_INDEX_HASH_JOIN hint to prevent the optimizer from utilizing the index nested loop hash join method on the specified tables, allowing for greater flexibility in query performance tuning.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ NO_INDEX_HASH_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Querying JSON Arrays with Member Of Operator Using Index Merge\nDESCRIPTION: SQL example showing how TiDB uses Index Merge when querying with MEMBER OF operator across different conditions. The query demonstrates combining conditions with OR operator on different indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t6, idx, idx2) */ * FROM t6 WHERE a=1 AND (1 member of (j) OR 2 member of (k));\n```\n\n----------------------------------------\n\nTITLE: Executing Raw SQL Queries with TypeORM in TypeScript\nDESCRIPTION: This code demonstrates how to execute a raw SQL query using TypeORM. It retrieves the TiDB version and logs it to the console.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nconst rows = await dataSource.query('SELECT VERSION() AS tidb_version;');\nconsole.log(rows[0]['tidb_version']);\n```\n\n----------------------------------------\n\nTITLE: Querying Persisted ANALYZE Configurations Using SQL\nDESCRIPTION: This SQL query retrieves the persisted ANALYZE configurations for a specified table in TiDB. It joins the analyze_options table with information_schema.tables to filter results based on the database and table name. The expected input parameters include db_name and table_name, representing the database and table for which configurations are queried.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT sample_num, sample_rate, buckets, topn, column_choice, column_ids FROM mysql.analyze_options opt JOIN information_schema.tables tbl ON opt.table_id = tbl.tidb_table_id WHERE tbl.table_schema = '{db_name}' AND tbl.table_name = '{table_name}';\n```\n\n----------------------------------------\n\nTITLE: SHOW PLUGINS Syntax Definition in TiDB\nDESCRIPTION: This EBNF diagram defines the syntax of the SHOW PLUGINS statement in TiDB. It shows that the statement can optionally include a `ShowLikeOrWhere` clause for filtering results.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-plugins.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\n\"ShowPluginsStmt ::= \\n    \\\"SHOW\\\" \\\"PLUGINS\\\" ShowLikeOrWhere?\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Reading Data from TiKV with TiSpark\nDESCRIPTION: This code snippet illustrates how to read data from TiKV using Spark SQL within the TiSpark framework. It ensures that the context is set to the correct database catalog before executing a SELECT statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_2\n\nLANGUAGE: scala\nCODE:\n```\n```\nspark.sql(\"use tidb_catalog\")\nspark.sql(\"select count(*) from ${database}.${table}\").show\n```\n```\n\n----------------------------------------\n\nTITLE: Creating a Doctor Table and Inserting Records in Go with SQL\nDESCRIPTION: This snippet shows two Go functions: one for creating a doctors table with fields for id, name, on-call status, and shift assignment, and another for inserting doctor records into the table. The functions use SQL statements executed through a database connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-restraints.md#2025-04-18_snippet_5\n\nLANGUAGE: go\nCODE:\n```\nfunc createDoctor(db *sql.DB, id int, name string, onCall bool, shiftID int) error {\n    _, err := db.Exec(\"INSERT INTO `doctors` (`id`, `name`, `on_call`, `shift_id`) VALUES (?, ?, ?, ?)\",\n        id, name, onCall, shiftID)\n    return err\n}\n```\n\n----------------------------------------\n\nTITLE: Querying with STRAIGHT_JOIN and USING Clause in TiDB\nDESCRIPTION: Support for the SELECT ... STRAIGHT_JOIN ... USING ( ... ) statement in TiDB, which allows more control over join order and optimization.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.3.0.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT ... STRAIGHT_JOIN ... USING ( ... )\n```\n\n----------------------------------------\n\nTITLE: Creating Paging Metadata for Clustered Index Table in SQL\nDESCRIPTION: This SQL query generates paging metadata for a clustered index table named 'ratings'. It uses concatenation and padding functions to create unique keys, and window functions to assign row numbers for paging. The result includes page numbers, start and end keys for each page, and page sizes.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-paginate-results.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    floor((t1.row_num - 1) / 10000) + 1 AS page_num,\n    min(mvalue) AS start_key,\n    max(mvalue) AS end_key,\n    count(*) AS page_size\nFROM (\n    SELECT\n        concat('(', LPAD(book_id, 19, 0), ',', LPAD(user_id, 19, 0), ')') AS mvalue,\n        row_number() OVER (ORDER BY book_id, user_id) AS row_num\n    FROM ratings\n) t1\nGROUP BY page_num\nORDER BY page_num;\n```\n\n----------------------------------------\n\nTITLE: Creating and Modifying Index Visibility Example\nDESCRIPTION: Example showing how to create a table with a unique index and modify its visibility to invisible.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-index.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (c1 INT, UNIQUE(c1));\nALTER TABLE t1 ALTER INDEX c1 INVISIBLE;\n```\n\n----------------------------------------\n\nTITLE: Creating TiFlash Replicas for Tables in SQL\nDESCRIPTION: These SQL commands create TiFlash replicas for the 'books' and 'orders' tables. TiFlash is a columnar storage engine that can improve performance for analytical queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-hybrid-oltp-and-olap-queries.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE books SET TIFLASH REPLICA 1;\nALTER TABLE orders SET TIFLASH REPLICA 1;\n```\n\n----------------------------------------\n\nTITLE: Retrieving First Value with FIRST_VALUE() in SQL\nDESCRIPTION: This snippet demonstrates the FIRST_VALUE() window function with different partition and ordering clauses. It shows how partitioning affects the result of the function.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/window-functions.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n    n,\n    FIRST_VALUE(n) OVER (PARTITION BY n MOD 2 ORDER BY n),\n    FIRST_VALUE(n) OVER (PARTITION BY n <= 2 ORDER BY n)\nFROM (\n    SELECT 1 AS 'n'\n    UNION\n    SELECT 2\n    UNION\n    SELECT 3\n    UNION\n    SELECT 4\n) a\nORDER BY\n    n;\n```\n\n----------------------------------------\n\nTITLE: Configuring Terraform for Local File Import to TiDB Cloud\nDESCRIPTION: Terraform configuration for importing a local CSV file to a TiDB Cloud Serverless cluster. It defines provider requirements, authentication, and import resource configuration with CSV format settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-import-resource.md#2025-04-18_snippet_1\n\nLANGUAGE: terraform\nCODE:\n```\nterraform {\n required_providers {\n   tidbcloud = {\n     source = \"tidbcloud/tidbcloud\"\n   }\n }\n}\n\nprovider \"tidbcloud\" {\n  public_key = \"your_public_key\"\n  private_key = \"your_private_key\"\n}\n\nresource \"tidbcloud_import\" \"example_local\" {\n  project_id  = \"your_project_id\"\n  cluster_id  = \"your_cluster_id\"\n  type        = \"LOCAL\"\n  data_format = \"CSV\"\n  csv_format = {\n    separator = \";\"\n  }\n  target_table = {\n    database = \"test\"\n    table  = \"import_test\"\n  }\n  file_name = \"your_csv_path\"\n}\n```\n\n----------------------------------------\n\nTITLE: Getting Region Read Progress with TiKV Control\nDESCRIPTION: This command retrieves details about a Region's RegionReadProgress and resolver. It helps diagnose issues related to Stale Read and safe-ts. The command accepts optional parameters to control logging behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_30\n\nLANGUAGE: shell\nCODE:\n```\n./tikv-ctl --host 127.0.0.1:20160 get-region-read-progress -r 14 --log --min-start-ts 0\n```\n\n----------------------------------------\n\nTITLE: JSON_VALID Validation Examples\nDESCRIPTION: Demonstrates using JSON_VALID() to check if strings contain valid JSON syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-return.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_VALID('{\"foo\"=\"bar\"}');\nSELECT JSON_VALID('{\"foo\": \"bar\"}');\n```\n\n----------------------------------------\n\nTITLE: Viewing Transaction Isolation Level in SQL\nDESCRIPTION: This SQL command allows you to view the current transaction isolation level for your session. It uses the SHOW VARIABLES statement to display the value of the transaction_isolation system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/transaction-isolation-levels.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW VARIABLES LIKE 'transaction_isolation';\n```\n\n----------------------------------------\n\nTITLE: Using HASH_JOIN Optimizer Hint in TiDB SQL\nDESCRIPTION: This snippet demonstrates how to use the HASH_JOIN optimizer hint to force TiDB to use the Hash Join algorithm for joining tables. It includes an EXPLAIN statement to preview the execution plan.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-join-tables.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ HASH_JOIN(b, r) */ b.id AS book_id, ANY_VALUE(b.title) AS book_title, AVG(r.score) AS average_score\nFROM books b\nLEFT JOIN ratings r ON b.id = r.book_id\nGROUP BY b.id\nORDER BY b.published_at DESC\nLIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Creating a resource group with RU limit\nDESCRIPTION: This SQL statement creates a resource group named `rg2` with an RU backfill rate of 600 RUs per second, and does not allow applications in this resource group to overrun resources. The `IF NOT EXISTS` clause ensures that the statement does not fail if the resource group already exists.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-ru-groups.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE RESOURCE GROUP IF NOT EXISTS rg2 RU_PER_SEC = 600;\"\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud Serverless Cluster with Cluster ID\nDESCRIPTION: This snippet demonstrates connecting to a TiDB Cloud Serverless cluster using the cluster ID in non-interactive mode.  The `-c` flag specifies the cluster ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-shell.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless shell -c <cluster-id>\n```\n\n----------------------------------------\n\nTITLE: Querying Vector Table Contents\nDESCRIPTION: Simple SELECT statement to verify the inserted vector data.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-sql.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM embedded_documents;\n```\n\n----------------------------------------\n\nTITLE: Creating MySQL Table with Various Data Types in SQL\nDESCRIPTION: This SQL snippet defines a table 't' with various columns of different MySQL types including int, decimal, char, varchar, binary, varbinary, enum, set, and bit. It sets up a primary key on the 'id' column.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (\n    id     int auto_increment,\n    c_decimal    decimal(10, 4) null,\n    c_char       char(16)      null,\n    c_varchar    varchar(16)   null,\n    c_binary     binary(16)    null,\n    c_varbinary  varbinary(16) null,\n    c_enum enum('a','b','c') null,\n    c_set  set('a','b','c')  null,\n    c_bit  bit(64)            null,\n    constraint pk\n        primary key (id)\n);\n```\n\n----------------------------------------\n\nTITLE: Replace DDL During Migration Errors\nDESCRIPTION: This bash command is utilized to replace the current DDL error with new SQL statements during interrupted migration tasks, ensuring that migration can continue without issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nbinlog replace -h\n```\n\n----------------------------------------\n\nTITLE: Creating and Altering Table in TiFlash\nDESCRIPTION: This SQL snippet demonstrates how to create a table in TiFlash, modify the table to enable TiFlash replication, and perform basic data manipulation including insert, update, and delete operations. It highlights the initial state of data before and after enabling the FastScan feature, showcasing potential outdated records that may be returned.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-fastscan.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (a INT PRIMARY KEY, b INT);\nALTER TABLE t1 SET TIFLASH REPLICA 1;\nINSERT INTO t1 VALUES(1,2);\nINSERT INTO t1 VALUES(10,20);\nUPDATE t1 SET b = 4 WHERE a = 1;\nDELETE FROM t1 WHERE a = 10;\nSET SESSION tidb_isolation_read_engines='tiflash';\n\nSELECT * FROM t1;\n+------+------+\n| a    | b    |\n+------+------+\n|    1 |    4 |\n+------+------+\n\nSET SESSION tiflash_fastscan=ON;\nSELECT * FROM t1;\n+------+------+\n| a    | b    |\n+------+------+\n|    1 |    2 |\n|    1 |    4 |\n|   10 |   20 |\n+------+------+\n```\n\n----------------------------------------\n\nTITLE: Pausing and Resuming DDL Jobs in TiDB\nDESCRIPTION: SQL commands to pause and resume multiple DDL jobs in TiDB using ADMIN PAUSE DDL JOBS and ADMIN RESUME DDL JOBS statements. These operations allow users to temporarily halt DDL operations during peak times and resume them later to reduce impact on application workloads.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.2.0.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN PAUSE DDL JOBS 1,2;\nADMIN RESUME DDL JOBS 1,2;\n```\n\n----------------------------------------\n\nTITLE: Paginating Query Results with SQL LIMIT\nDESCRIPTION: Demonstrates how to use the LIMIT statement in SQL to paginate query results, with an example of fetching the latest published books.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-paginate-results.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM books\nORDER BY published_at DESC\nLIMIT 0, 10;\n```\n\n----------------------------------------\n\nTITLE: Example of Granting Privileges to a New User in TiDB\nDESCRIPTION: A practical SQL example demonstrating how to create a new user and grant all privileges on a specific database to that user, followed by verifying the granted privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-grant-privileges.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE USER 'newuser' IDENTIFIED BY 'mypassword';\nQuery OK, 1 row affected (0.02 sec)\n\nmysql> GRANT ALL ON test.* TO 'newuser';\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> SHOW GRANTS FOR 'newuser';\n+-------------------------------------------------+\n| Grants for newuser@%                            |\n+-------------------------------------------------+\n| GRANT USAGE ON *.* TO 'newuser'@'%'             |\n| GRANT ALL PRIVILEGES ON test.* TO 'newuser'@'%' |\n+-------------------------------------------------+\n2 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Executing ANALYZE TABLE Statement for Full Statistics Collection in TiDB\nDESCRIPTION: SQL statement syntax for manually collecting statistics on tables in TiDB. This command supports various parameters to customize the collection behavior including bucket size, TopN values, and CMSketch configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE TableNameList [WITH NUM BUCKETS|TOPN|CMSKETCH DEPTH|CMSKETCH WIDTH]|[WITH NUM SAMPLES|WITH FLOATNUM SAMPLERATE];\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with JSON and Generated Column\nDESCRIPTION: Creates a table with a JSON column and a virtual generated column for indexing the city field from the JSON data.\nSOURCE: https://github.com/pingcap/docs/blob/master/generated-columns.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE person (\n    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    name VARCHAR(255) NOT NULL,\n    address_info JSON,\n    city VARCHAR(64) AS (JSON_UNQUOTE(JSON_EXTRACT(address_info, '$.city'))),\n    KEY (city)\n);\n```\n\n----------------------------------------\n\nTITLE: Performing Semantic Search with Jina AI Embeddings in TiDB using Python\nDESCRIPTION: This code snippet demonstrates how to generate embeddings for a query using Jina AI API, and then perform a semantic search in TiDB. It calculates the cosine distance between the query embedding and document embeddings stored in a vector table, returning the most relevant document.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-jinaai-embedding.md#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nquery = 'What is TiDB?'\n# Generate the embedding for the query via Jina AI API.\nquery_embedding = generate_embeddings(query)\n\nwith Session(engine) as session:\n    print('- The Most Relevant Document and Its Distance to the Query:')\n    doc, distance = session.query(\n        Document,\n        Document.content_vec.cosine_distance(query_embedding).label('distance')\n    ).order_by(\n        'distance'\n    ).limit(1).first()\n    print(f'  - distance: {distance}\\n'\n          f'    content: {doc.content}')\n```\n\n----------------------------------------\n\nTITLE: Querying HTAP Data in TiDB Cloud Using SQL\nDESCRIPTION: This SQL snippet is an example query to analyze data using the HTAP features of TiDB Cloud. It retrieves the number of games released every year, along with their average price and playtime, grouped by release year and ordered in descending order. This query assumes the data is already replicated in TiFlash and might yield better performance due to the optimized analytical capabilities of the columnar storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-htap-quickstart.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  YEAR(`release_date`) AS `release_year`,\n  COUNT(*) AS `games_released`,\n  AVG(`price`) AS `average_price`,\n  AVG(`average_playtime_forever`) AS `average_playtime`\nFROM\n  `games`\nGROUP BY\n  `release_year`\nORDER BY\n  `release_year` DESC;\n```\n\n----------------------------------------\n\nTITLE: Analyzing TiKV Instance Performance in TiDB Slow Query Log\nDESCRIPTION: This snippet from a TiDB slow query log shows the Cop_wait field, which can help identify if a specific TiKV instance is busy and causing query slowdown.\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\n# Cop_wait: Avg_time: 1ms P90_time: 2ms Max_time: 110ms Max_Addr: 10.6.131.78\n```\n\n----------------------------------------\n\nTITLE: Displaying TiDB Cluster Status with TiUP\nDESCRIPTION: This command shows the status of each component in a TiDB cluster named 'prod-cluster', including role, host, ports, status, and data/deploy directories.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster display prod-cluster\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS for TiCDC via CLI\nDESCRIPTION: This code shows an example of configuring TLS for TiCDC using command-line arguments. It uses the `cdc server` command and specifies the paths to the CA certificate, server certificate, and server key using the `--ca`, `--cert`, and `--key` parameters, enabling secure communication.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n        ```bash\n        cdc server --pd=https://127.0.0.1:2379 --log-file=ticdc.log --addr=0.0.0.0:8301 --advertise-addr=127.0.0.1:8301 --ca=/path/to/ca.pem --cert=/path/to/ticdc-cert.pem --key=/path/to/ticdc-key.pem\n        ```\n```\n\n----------------------------------------\n\nTITLE: Rewritable INSERT Statements with ON DUPLICATE KEY UPDATE\nDESCRIPTION: Shows INSERT statements with ON DUPLICATE KEY UPDATE clauses that can be rewritten when using values() function, making them eligible for batch optimization.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\ninsert into t (a) values (10) on duplicate key update a = values(a);\ninsert into t (a) values (11) on duplicate key update a = values(a);\ninsert into t (a) values (12) on duplicate key update a = values(a);\n```\n\n----------------------------------------\n\nTITLE: ALTER RANGE Usage Examples in SQL\nDESCRIPTION: SQL examples demonstrating the creation of placement policies and their application using ALTER RANGE. It shows how to create policies with specific constraints and apply them to global data and metadata ranges.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-range.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE PLACEMENT POLICY `deploy111` CONSTRAINTS='{\"+ region=us-east-1\":1, \"+region=us-east-2\": 1, \"+region=us-west-1\": 1}';\nCREATE PLACEMENT POLICY `five_replicas` FOLLOWERS=4;\n\nALTER RANGE global PLACEMENT POLICY = \"deploy111\";\nALTER RANGE meta PLACEMENT POLICY = \"five_replicas\";\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cluster with peewee ORM\nDESCRIPTION: Python code for establishing a database connection to TiDB using the peewee ORM. Includes configuration for SSL connections with two different MySQL drivers.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-peewee.md#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport dotenv\n\nfrom peewee import Model, MySQLDatabase, SQL, TextField\nfrom tidb_vector.peewee import VectorField\n\ndotenv.load_dotenv()\n\n# Using `pymysql` as the driver.\nconnect_kwargs = {\n    'ssl_verify_cert': True,\n    'ssl_verify_identity': True,\n}\n\n# Using `mysqlclient` as the driver.\n# connect_kwargs = {\n#     'ssl_mode': 'VERIFY_IDENTITY',\n#     'ssl': {\n#         # Root certificate default path\n#         # https://docs.pingcap.com/tidbcloud/secure-connections-to-serverless-clusters/#root-certificate-default-path\n#         'ca': os.environ.get('TIDB_CA_PATH', '/path/to/ca.pem'),\n#     },\n# }\n\ndb = MySQLDatabase(\n    database=os.environ.get('TIDB_DATABASE', 'test'),\n    user=os.environ.get('TIDB_USERNAME', 'root'),\n    password=os.environ.get('TIDB_PASSWORD', ''),\n    host=os.environ.get('TIDB_HOST', 'localhost'),\n    port=int(os.environ.get('TIDB_PORT', '4000')),\n    **connect_kwargs,\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Range INTERVAL Partitioning in SQL\nDESCRIPTION: Example of creating an 'employees' table using Range INTERVAL partitioning on the 'id' column with an interval of 100, defining the first partition less than 100 and the last partition less than 10000, with a MAXVALUE partition.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    id int unsigned NOT NULL,\n    fname varchar(30),\n    lname varchar(30),\n    hired date NOT NULL DEFAULT '1970-01-01',\n    separated date DEFAULT '9999-12-31',\n    job_code int,\n    store_id int NOT NULL\n) PARTITION BY RANGE (id)\nINTERVAL (100) FIRST PARTITION LESS THAN (100) LAST PARTITION LESS THAN (10000) MAXVALUE PARTITION\n```\n\n----------------------------------------\n\nTITLE: Querying with WITH ROLLUP and GROUPING Function in TiDB\nDESCRIPTION: Support for executing queries with the WITH ROLLUP modifier and the GROUPING function in TiDB nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.3.0.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT ... WITH ROLLUP ... GROUPING(...)\n```\n\n----------------------------------------\n\nTITLE: Explaining Index Join Execution in SQL (TiDB)\nDESCRIPTION: This SQL snippet demonstrates how to explain the execution plan for an index join operation. It provides insight into row estimates and operator details in the execution plan for the specified join query.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ INL_JOIN(t1, t2) */ * FROM t1 INNER JOIN t2 ON t1.id = t2.t1_id;\n```\n\n----------------------------------------\n\nTITLE: Creating a Global Temporary Table in TiDB - SQL\nDESCRIPTION: This code snippet demonstrates how to create a global temporary table named 'users' in TiDB, specifying the structure of the table with necessary columns and constraints. It also sets the ON COMMIT behavior to DELETE ROWS, meaning data is cleared after each transaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/temporary-tables.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE GLOBAL TEMPORARY TABLE users (\n    id BIGINT,\n    name VARCHAR(100),\n    city VARCHAR(50),\n    PRIMARY KEY(id)\n) ON COMMIT DELETE ROWS;\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP Package Manager\nDESCRIPTION: Downloads and installs TiUP package manager using curl command over HTTPS.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Configuring TiFlash Late Materialization at Session Level in SQL\nDESCRIPTION: SQL commands to enable or disable the TiFlash late materialization feature for the current session using the tidb_opt_enable_late_materialization system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-late-materialization.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET SESSION tidb_opt_enable_late_materialization=OFF;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSET SESSION tidb_opt_enable_late_materialization=ON;\n```\n\n----------------------------------------\n\nTITLE: Using USE_INDEX Hint for Index Selection in SQL\nDESCRIPTION: Uses the USE_INDEX hint to tell the optimizer to use only the specified indexes (idx1, idx2) for a table (t1). This restricts index selection to only those indexes listed in the hint.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ USE_INDEX(t1, idx1, idx2) */ * FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Querying with mixed conditions where IndexMerge is inapplicable in TiDB\nDESCRIPTION: Execution plan showing when TiDB cannot use IndexMerge due to incompatible conditions. The json_length function cannot be accessed with IndexMerge directly, causing a fallback to table scan.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1) */ * FROM t4 WHERE json_overlaps(j->'$.a', '[1, 2]') OR json_length(j->'$.a') = 3;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------+----------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------------------+\n| id                      | estRows  | task      | access object | operator info                                                                                                                      |\n+-------------------------+----------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------------------+\n| Selection_5             | 8000.00  | root      |               | or(json_overlaps(json_extract(test.t4.j, \"$.a\"), cast(\"[1, 2]\", json BINARY)), eq(json_length(json_extract(test.t4.j, \"$.a\")), 3)) |\n| └─TableReader_7         | 10000.00 | root      |               | data:TableFullScan_6                                                                                                               |\n|   └─TableFullScan_6     | 10000.00 | cop[tikv] | table:t4      | keep order:false, stats:pseudo                                                                                                     |\n+-------------------------+----------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------------------+\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW WARNINGS;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+---------+------+----------------------------+\n| Level   | Code | Message                    |\n+---------+------+----------------------------+\n| Warning | 1105 | IndexMerge is inapplicable |\n+---------+------+----------------------------+\n```\n\n----------------------------------------\n\nTITLE: Java DAO Implementation - Query Authors\nDESCRIPTION: Java Data Access Object implementation for querying authors using JDBC connection and ResultSet processing.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_2\n\nLANGUAGE: java\nCODE:\n```\npublic class AuthorDAO {\n\n    // Omit initialization of instance variables.\n\n    public List<Author> getAuthors() throws SQLException {\n        List<Author> authors = new ArrayList<>();\n\n        try (Connection conn = ds.getConnection()) {\n            Statement stmt = conn.createStatement();\n            ResultSet rs = stmt.executeQuery(\"SELECT id, name FROM authors\");\n            while (rs.next()) {\n                Author author = new Author();\n                author.setId(rs.getLong(\"id\"));\n                author.setName(rs.getString(\"name\"));\n                authors.add(author);\n            }\n        }\n        return authors;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using AGG_TO_COP Hint in TiDB SQL\nDESCRIPTION: Example of using the AGG_TO_COP hint to push down aggregate operations to the coprocessor, which can improve query performance by reducing data transfer.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_33\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ AGG_TO_COP() */ sum(t1.a) from t t1;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Replica Read Staleness\nDESCRIPTION: This code snippet shows how to configure TiDB to read historical data within a specified time range using session variables. It sets the `tidb_replica_read` variable to `leader_and_follower` and the `tidb_read_staleness` variable to `-5`, which instructs TiDB to read the latest historical data within the last 5 seconds from the nearest leader or follower node. The purpose is to enable low-latency, high-throughput read requests in quasi-real-time scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.4.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_replica_read=leader_and_follower\nset @@tidb_read_staleness=\"-5\"\n```\n\n----------------------------------------\n\nTITLE: Reading User-Defined Variables with SELECT\nDESCRIPTION: Shows how to read the values of multiple user-defined variables using a SELECT statement in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @a1, @a2, @a3\n```\n\n----------------------------------------\n\nTITLE: Disabling Index Merge with NO_INDEX_MERGE Hint\nDESCRIPTION: Example showing how to disable the index merge feature using the NO_INDEX_MERGE hint.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_43\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ NO_INDEX_MERGE() */ * from t where t.a > 0 or t.b > 0;\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with Ruby mysql2 Client\nDESCRIPTION: Ruby code to establish a connection to TiDB using the mysql2 gem with options loaded from environment variables, including optional TLS configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_8\n\nLANGUAGE: ruby\nCODE:\n```\nrequire 'dotenv/load'\nrequire 'mysql2'\nDotenv.load # Load the environment variables from the .env file\n\noptions = {\n  host: ENV['DATABASE_HOST'] || '127.0.0.1',\n  port: ENV['DATABASE_PORT'] || 4000,\n  username: ENV['DATABASE_USER'] || 'root',\n  password: ENV['DATABASE_PASSWORD'] || '',\n  database: ENV['DATABASE_NAME'] || 'test'\n}\noptions.merge(ssl_mode: :verify_identity) unless ENV['DATABASE_ENABLE_SSL'] == 'false'\noptions.merge(sslca: ENV['DATABASE_SSL_CA']) if ENV['DATABASE_SSL_CA']\nclient = Mysql2::Client.new(options)\n```\n\n----------------------------------------\n\nTITLE: Preparing Sysbench for Database Testing in Bash\nDESCRIPTION: This is a shell command to prepare a database using Sysbench for performance testing by creating 32 tables with 10 million rows each in the 'sbtest' database. Customizable variables include host, port, threads, and password.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v6.5-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsysbench oltp_common \\\n   --threads=${THREAD} \\\n   --db-driver=mysql \\\n   --mysql-db=sbtest \\\n   --mysql-host=${HOST} \\\n   --mysql-port=${PORT} \\\n   --mysql-user=root \\\n   --mysql-password=${PASSWORD} \\\n   prepare --tables=32 --table-size=10000000\n```\n\n----------------------------------------\n\nTITLE: Listing Serverless Clusters in Interactive Mode\nDESCRIPTION: Example of listing all TiDB Cloud Serverless clusters using the CLI in interactive mode. This command will prompt the user for any required information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-list.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless list\n```\n\n----------------------------------------\n\nTITLE: Topology File Configuration for No-sudo Mode\nDESCRIPTION: Configure topology file with user mode and appropriate deployment directories\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-no-sudo-mode.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nglobal:\n  user: \"tidb\"\n  systemd_mode: \"user\"\n  ssh_port: 22\n  deploy_dir: \"data/tidb-deploy\"\n  data_dir: \"data/tidb-data\"\n  arch: \"amd64\"\n```\n\n----------------------------------------\n\nTITLE: Updating Data in TiDB with Ruby\nDESCRIPTION: Ruby function to update an existing player record by incrementing their coins and goods values, returning the number of affected rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_11\n\nLANGUAGE: ruby\nCODE:\n```\ndef update_player(client, player_id, inc_coins, inc_goods)\n  result = client.query(\n    \"UPDATE players SET coins = coins + #{inc_coins}, goods = goods + #{inc_goods} WHERE id = #{player_id};\"\n  )\n  client.affected_rows\nend\n```\n\n----------------------------------------\n\nTITLE: Basic SQL Query Explanation with EXPLAIN\nDESCRIPTION: Demonstrates how to use the EXPLAIN command to inspect query execution plan, showing the operator details, estimated rows, and task distribution\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT 1;\n```\n\n----------------------------------------\n\nTITLE: Java JDBC Bulk Update Implementation\nDESCRIPTION: Java implementation using JDBC for batch updating ratings. Features similar functionality to the Golang version with batch processing and update tracking.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-update-data.md#2025-04-18_snippet_8\n\nLANGUAGE: java\nCODE:\n```\npackage com.pingcap.bulkUpdate;\n\nimport com.mysql.cj.jdbc.MysqlDataSource;\n\nimport java.sql.*;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.concurrent.TimeUnit;\n\npublic class BatchUpdateExample {\n    static class UpdateID {\n        private Long bookID;\n        private Long userID;\n\n        public UpdateID(Long bookID, Long userID) {\n            this.bookID = bookID;\n            this.userID = userID;\n        }\n\n        public Long getBookID() {\n            return bookID;\n        }\n\n        public void setBookID(Long bookID) {\n            this.bookID = bookID;\n        }\n\n        public Long getUserID() {\n            return userID;\n        }\n\n        public void setUserID(Long userID) {\n            this.userID = userID;\n        }\n\n        @Override\n        public String toString() {\n            return \"[bookID] \" + bookID + \", [userID] \" + userID ;\n        }\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        // Configure the example database connection.\n\n        // Create a mysql data source instance.\n        MysqlDataSource mysqlDataSource = new MysqlDataSource();\n\n        // Set server name, port, database name, username and password.\n        mysqlDataSource.setServerName(\"localhost\");\n        mysqlDataSource.setPortNumber(4000);\n        mysqlDataSource.setDatabaseName(\"bookshop\");\n        mysqlDataSource.setUser(\"root\");\n        mysqlDataSource.setPassword(\"\");\n\n        UpdateID lastID = batchUpdate(mysqlDataSource, null);\n\n        System.out.println(\"first time batch update success\");\n        while (true) {\n            TimeUnit.SECONDS.sleep(1);\n            lastID = batchUpdate(mysqlDataSource, lastID);\n            System.out.println(\"batch update success, [lastID] \" + lastID);\n        }\n    }\n\n    public static UpdateID batchUpdate (MysqlDataSource ds, UpdateID lastID) {\n        try (Connection connection = ds.getConnection()) {\n            UpdateID updateID = null;\n\n            PreparedStatement selectPs;\n\n            if (lastID == null) {\n                selectPs = connection.prepareStatement(\n                        \"SELECT `book_id`, `user_id` FROM `bookshop`.`ratings` \" +\n                        \"WHERE `ten_point` != true ORDER BY `book_id`, `user_id` LIMIT 1000\");\n            } else {\n                selectPs = connection.prepareStatement(\n                        \"SELECT `book_id`, `user_id` FROM `bookshop`.`ratings` \"+\n                            \"WHERE `ten_point` != true AND `book_id` > ? AND `user_id` > ? \"+\n                            \"ORDER BY `book_id`, `user_id` LIMIT 1000\");\n\n                selectPs.setLong(1, lastID.getBookID());\n                selectPs.setLong(2, lastID.getUserID());\n            }\n\n            List<Long> idList = new LinkedList<>();\n            ResultSet res = selectPs.executeQuery();\n            while (res.next()) {\n                updateID = new UpdateID(\n                        res.getLong(\"book_id\"),\n                        res.getLong(\"user_id\")\n                );\n                idList.add(updateID.getBookID());\n                idList.add(updateID.getUserID());\n            }\n\n            if (idList.isEmpty()) {\n                System.out.println(\"no data should update\");\n                return null;\n            }\n\n            String updateSQL = \"UPDATE `bookshop`.`ratings` SET `ten_point` = true, \"+\n                    \"`score` = `score` * 2 WHERE (`book_id`, `user_id`) IN (\" +\n                    placeHolder(idList.size() / 2) + \")\";\n            PreparedStatement updatePs = connection.prepareStatement(updateSQL);\n            for (int i = 0; i < idList.size(); i++) {\n                updatePs.setLong(i + 1, idList.get(i));\n            }\n            int count = updatePs.executeUpdate();\n            System.out.println(\"update \" + count + \" data\");\n\n            return updateID;\n        } catch (SQLException e) {\n            e.printStackTrace();\n        }\n\n        return null;\n    }\n\n    public static String placeHolder(int n) {\n        StringBuilder sb = new StringBuilder();\n        for (int i = 0; i < n ; i++) {\n            sb.append(i == 0 ? \"(?,?)\" : \",(?,?)\");\n        }\n\n        return sb.toString();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing SQL Query with EXPLAIN for MPP Task Analysis\nDESCRIPTION: This SQL query demonstrates how to use EXPLAIN to analyze the execution plan of an MPP query, showing the breakdown of tasks and their dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-mintso-scheduler.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT count(*) FROM t0 a JOIN t0 b ON a.id = b.id;\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud using MySQL CLI\nDESCRIPTION: This snippet demonstrates how to connect to a TiDB Cloud Dedicated cluster using the MySQL command-line interface (CLI) with TLS enabled. It requires specifying the path to the CA certificate (`ssl-ca`) and enforcing TLS with identity verification (`ssl-mode=VERIFY_IDENTITY`). The snippet also demonstrates restricting TLS protocol versions using `--tls-version`.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tls-connect-to-dedicated.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nmysql --connect-timeout 15 --ssl-mode=VERIFY_IDENTITY --ssl-ca=ca.pem --tls-version=\"TLSv1.2\" -u root -h tidb.eqlfbdgthh8.clusters.staging.tidb-cloud.com -P 4000 -D test -p\n```\n\n----------------------------------------\n\nTITLE: Inner Join Query for Author Book Counts\nDESCRIPTION: SQL query that joins authors and book_authors tables to find the most prolific authors. Uses INNER JOIN with grouping and ordering to show authors with the most books.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-join-tables.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ANY_VALUE(a.id) AS author_id, ANY_VALUE(a.name) AS author_name, COUNT(ba.book_id) AS books\nFROM authors a\nJOIN book_authors ba ON a.id = ba.author_id\nGROUP BY ba.author_id\nORDER BY books DESC\nLIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Performing a Vector Search Query with LangChain\nDESCRIPTION: Demonstrates how to execute a semantic search query against the vector database to find relevant information in the embedded documents.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nquery = \"What did the president say about Ketanji Brown Jackson\"\n```\n\n----------------------------------------\n\nTITLE: Executing Terraform Import Command\nDESCRIPTION: This command demonstrates how to execute a Terraform import operation, allowing a user to bring an existing cluster into Terraform's management context. The command illustrates the steps necessary to ensure successful import.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform import tidbcloud_cluster.import_cluster 1372813089189561287,1379661944630264072\n\ntidbcloud_cluster.import_cluster: Importing from ID \"1372813089189561287,1379661944630264072\"...\ntidbcloud_cluster.import_cluster: Import prepared!\n  Prepared tidbcloud_cluster for import\ntidbcloud_cluster.import_cluster: Refreshing state... [id=1379661944630264072]\n\nImport successful!\n\nThe resources that were imported are shown above. These resources are now in\nyour Terraform state and will henceforth be managed by Terraform.\n```\n\n----------------------------------------\n\nTITLE: Supported Data Sources for TiDB Lightning\nDESCRIPTION: TiDB Lightning can read data from local storage, Amazon S3, and Google Cloud Storage\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- Local\n- [Amazon S3](/external-storage-uri.md#amazon-s3-uri-format)\n- [Google Cloud Storage](/external-storage-uri.md#gcs-uri-format)\n```\n\n----------------------------------------\n\nTITLE: Using SELECT ... INTO OUTFILE with Custom Line Terminators in SQL\nDESCRIPTION: Writes the result of a SQL query to a specified file, formatting the fields and using a custom line terminator. This illustrates using single quotes for encapsulation and a custom end line sequence.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-select.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT * FROM t INTO OUTFILE '/tmp/tmp_file3'\n    -> FIELDS TERMINATED BY ',' ENCLOSED BY '\\'' LINES TERMINATED BY '<<<\\n';\nQuery OK, 3 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Listing Tables with Attached Placement Policies SQL\nDESCRIPTION: The SQL query identifies tables associated with placement policies, guiding users in managing and reviewing storage configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.tables WHERE tidb_placement_policy_name IS NOT NULL;\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW PROCESSLIST SQL Command\nDESCRIPTION: Demonstrates how to list current database sessions, showing connection details like ID, user, host, database, and current query information\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-processlist.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW PROCESSLIST;\n+------+------+-----------------+------+---------+------+------------+------------------+\n| Id   | User | Host            | db   | Command | Time | State      | Info             |\n+------+------+-----------------+------+---------+------+------------+------------------+\n|    5 | root | 127.0.0.1:45970 | test | Query   |    0 | autocommit | SHOW PROCESSLIST |\n+------+------+-----------------+------+---------+------+------------+------------------+\n1 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Adding Documents with Metadata to TiDBVectorStore in Python\nDESCRIPTION: Demonstrates how to add documents with metadata to TiDBVectorStore using Python, including text content and a 'title' field as metadata.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nvector_store.add_texts(\n    texts=[\n        \"TiDB Vector offers advanced, high-speed vector processing capabilities, enhancing AI workflows with efficient data handling and analytics support.\",\n        \"TiDB Vector, starting as low as $10 per month for basic usage\",\n    ],\n    metadatas=[\n        {\"title\": \"TiDB Vector functionality\"},\n        {\"title\": \"TiDB Vector Pricing\"},\n    ],\n)\n```\n\n----------------------------------------\n\nTITLE: Pushing SQL Expressions Down to TiFlash\nDESCRIPTION: This SQL snippet demonstrates creating a table, setting TiFlash replica, inserting data, and executing an EXPLAIN query to illustrate how expressions are pushed down to TiFlash. The purpose is to perform computation on TiFlash to minimize network transmission and enhance performance. Dependencies include a running TiDB cluster with TiFlash enabled. Key parameters involve the table schema and inserted data. Output includes an EXPLAIN table with task execution details.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-supported-pushdown-calculations.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id INT PRIMARY KEY, a INT);\nALTER TABLE t SET TIFLASH REPLICA 1;\nINSERT INTO t(id,a) VALUES (1,2),(2,4),(11,2),(12,4),(13,4),(14,7);\n\nEXPLAIN SELECT MAX(id + a) FROM t GROUP BY a;\n\n+------------------------------------+---------+--------------+---------------+---------------------------------------------------------------------------+\n| id                                 | estRows | task         | access object | operator info                                                             |\n+------------------------------------+---------+--------------+---------------+---------------------------------------------------------------------------+\n| TableReader_45                     | 4.80    | root         |               | data:ExchangeSender_44                                                    |\n| └─ExchangeSender_44                | 4.80    | mpp[tiflash] |               | ExchangeType: PassThrough                                                 |\n|   └─Projection_39                  | 4.80    | mpp[tiflash] |               | Column#3                                                                  |\n|     └─HashAgg_37                   | 4.80    | mpp[tiflash] |               | group by:Column#9, funcs:max(Column#8)->Column#3                          |\n|       └─Projection_46              | 6.00    | mpp[tiflash] |               | plus(test.t.id, test.t.a)->Column#8, test.t.a                             |\n|         └─ExchangeReceiver_23      | 6.00    | mpp[tiflash] |               |                                                                           |\n|           └─ExchangeSender_22      | 6.00    | mpp[tiflash] |               | ExchangeType: HashPartition, Hash Cols: [name: test.t.a, collate: binary] |\n|             └─TableFullScan_21     | 6.00    | mpp[tiflash] | table:t       | keep order:false, stats:pseudo                                            |\n+------------------------------------+---------+--------------+---------------+---------------------------------------------------------------------------+\n8 rows in set (0.18 sec)\n```\n\n----------------------------------------\n\nTITLE: Explaining Optimized Query Execution Plan in TiDB\nDESCRIPTION: This EXPLAIN statement shows the improved execution plan after creating the covering index, demonstrating that only an index scan is needed without table lookup.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT title, price FROM books WHERE title = 'Marian Yost';\n```\n\n----------------------------------------\n\nTITLE: Defining Prisma Data Models for TiDB\nDESCRIPTION: Prisma schema defining Player and Profile models with their relationships and mappings to TiDB tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_6\n\nLANGUAGE: prisma\nCODE:\n```\n// Define a Player model, which represents the `players` table.\nmodel Player {\n  id        Int      @id @default(autoincrement())\n  name      String   @unique(map: \"uk_player_on_name\") @db.VarChar(50)\n  coins     Decimal  @default(0)\n  goods     Int      @default(0)\n  createdAt DateTime @default(now()) @map(\"created_at\")\n  profile   Profile?\n\n  @@map(\"players\")\n}\n\n// Define a Profile model, which represents the `profiles` table.\nmodel Profile {\n  playerId  Int    @id @map(\"player_id\")\n  biography String @db.Text\n\n  // Define a 1:1 relation between the `Player` and `Profile` models with foreign key.\n  player    Player @relation(fields: [playerId], references: [id], onDelete: Cascade, map: \"fk_profile_on_player_id\")\n\n  @@map(\"profiles\")\n}\n```\n\n----------------------------------------\n\nTITLE: Seeding Sample Data in TiDB\nDESCRIPTION: Command to populate the database with sample data.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nbundle exec rails db:seed\n```\n\n----------------------------------------\n\nTITLE: Deleting Documents from TiDB Vector Store in Python\nDESCRIPTION: Shows how to delete a specific document from the TiDB vector store using its document ID. This is useful for removing outdated or irrelevant information from the search index.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ntidbvec.delete(documents[0].doc_id)\n```\n\n----------------------------------------\n\nTITLE: Replaying Read-Only Traffic in SQL\nDESCRIPTION: SQL example showing how to use the READ_ONLY option in TRAFFIC REPLAY syntax to replay only read-only SQL statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-traffic-replay.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nTRAFFIC REPLAY FROM \"/tmp/traffic\" USER=\"u1\" PASSWORD=\"123456\" READ_ONLY=true;\n```\n\n----------------------------------------\n\nTITLE: Java Implementation - Limited Authors Query\nDESCRIPTION: Java implementation for querying authors with a limit parameter using PreparedStatement.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_8\n\nLANGUAGE: java\nCODE:\n```\npublic List<Author> getAuthorsWithLimit(Integer limit) throws SQLException {\n    List<Author> authors = new ArrayList<>();\n    try (Connection conn = ds.getConnection()) {\n        PreparedStatement stmt = conn.prepareStatement(\"\"\"\n            SELECT id, name, birth_year\n            FROM authors\n            ORDER BY birth_year DESC\n            LIMIT ?;\n            \"\"\");\n        stmt.setInt(1, limit);\n        ResultSet rs = stmt.executeQuery();\n        while (rs.next()) {\n            Author author = new Author();\n            author.setId(rs.getLong(\"id\"));\n            author.setName(rs.getString(\"name\"));\n            author.setBirthYear(rs.getShort(\"birth_year\"));\n            authors.add(author);\n        }\n    }\n    return authors;\n}\n```\n\n----------------------------------------\n\nTITLE: Golang Program for Preventing Overselling Example\nDESCRIPTION: This Golang snippet shows how to compile and run a program that keeps track of inventory while preventing overselling. It increases Bob's order to 7 books.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\ngo build -o bin/txn\n./bin/txn -a 4 -b 7 -o true\n```\n\n----------------------------------------\n\nTITLE: Querying Default Value of tidb_opt_range_max_size in TiDB\nDESCRIPTION: This SQL query retrieves the default value of the tidb_opt_range_max_size variable, which is 64 MiB (67108864 bytes) and represents the upper limit of memory usage for the optimizer to build scan ranges.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_68\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@tidb_opt_range_max_size;\n```\n\n----------------------------------------\n\nTITLE: TiUP Cluster Upgrade Command Usage\nDESCRIPTION: Shows the complete syntax and flags available for the TiUP cluster upgrade command, which performs rolling upgrades of TiDB clusters while preserving cluster availability.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nUsage:\n  cluster upgrade <cluster-name> <version> [flags]\n\nFlags:\n      --force                  Force upgrade won't transfer leader\n  -h, --help                   help for upgrade\n      --transfer-timeout int   Timeout in seconds when transferring PD and TiKV store leaders (default 600)\n\nGlobal Flags:\n      --ssh string          (Experimental) The executor type. Optional values are 'builtin', 'system', and 'none'.\n      --wait-timeout int  Timeout of waiting the operation\n      --ssh-timeout int   Timeout in seconds to connect host via SSH, ignored for operations that don't need an SSH connection. (default 5)\n  -y, --yes               Skip all confirmations and assumes 'yes'\n```\n\n----------------------------------------\n\nTITLE: Setting Transaction Isolation Level in SQL\nDESCRIPTION: This SQL command allows you to modify the transaction isolation level for your current session. This example sets the isolation level to READ-COMMITTED, which is one of the standard isolation levels in database systems.\nSOURCE: https://github.com/pingcap/docs/blob/master/transaction-isolation-levels.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET SESSION transaction_isolation = 'READ-COMMITTED';\n```\n\n----------------------------------------\n\nTITLE: Explaining Query Performance Without an Index\nDESCRIPTION: SQL EXPLAIN statement showing that a query without an index requires a full table scan, which is generally less efficient for selective queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t1 WHERE c1 = 3;\n```\n\n----------------------------------------\n\nTITLE: Executing SQL with Array and Full Result Options in TypeScript\nDESCRIPTION: This snippet demonstrates how to connect to the TiDB Cloud serverless driver and execute a SQL query while configuring the options to return results as arrays and in full result format. These options can improve performance and provide more detailed output.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst conn = connect({url: process.env['DATABASE_URL'] || 'mysql://[username]:[password]@[host]/[database]'});\nconst results = await conn.execute('select * from test',null,{arrayMode:true,fullResult:true});\n```\n\n----------------------------------------\n\nTITLE: Analyzing Index Join Performance in SQL (TiDB)\nDESCRIPTION: This SQL snippet explores the performance of an index join compared to other join types by executing and analyzing different join strategies with the EXPLAIN ANALYZE command.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- DROP previously added index\nALTER TABLE t2 DROP INDEX t1_id;\n\nEXPLAIN ANALYZE SELECT /*+ INL_JOIN(t1, t2) */  * FROM t1 INNER JOIN t2 ON t1.id = t2.t1_id WHERE t1.int_col = 1;\nEXPLAIN ANALYZE SELECT /*+ HASH_JOIN(t1, t2) */  * FROM t1 INNER JOIN t2 ON t1.id = t2.t1_id WHERE t1.int_col = 1;\nEXPLAIN ANALYZE SELECT * FROM t1 INNER JOIN t2 ON t1.id = t2.t1_id WHERE t1.int_col = 1;\n```\n\n----------------------------------------\n\nTITLE: Replacing Unsupported DDL with Shell Command\nDESCRIPTION: Replaces an unsupported DDL statement with equivalent commands using the binlog replace tool. It splits the addition of a new column from the application of the UNIQUE constraint to bypass TiDB's limitations. The command targets the specified task and requires access to the shell environment where the replace tool is available.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n» binlog replace test \"ALTER TABLE `db1`.`tbl1` ADD COLUMN `new_col` INT;ALTER TABLE `db1`.`tbl1` ADD UNIQUE(`new_col`)\";\n```\n\n----------------------------------------\n\nTITLE: Running Golang Optimistic Transaction Example\nDESCRIPTION: This snippet shows how to build and execute a Golang program for handling optimistic transactions. It compiles the application and runs it with parameters for two users' purchases.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\ngo build -o bin/txn\n./bin/txn -a 4 -b 6 -o true\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Multi-Valued JSON Indexes in TiDB\nDESCRIPTION: This SQL snippet creates a table 't3' with JSON columns and multi-valued indexes on JSON paths, as well as a normal index on an integer column.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t3(j1 JSON, j2 JSON, a INT, INDEX k1((CAST(j1->'$.path' AS SIGNED ARRAY))), INDEX k2((CAST(j2->'$.path' AS SIGNED ARRAY))), INDEX ka(a));\n```\n\n----------------------------------------\n\nTITLE: Creating a Sample Table with Index in TiDB\nDESCRIPTION: SQL to create a test table with an auto-increment primary key, an indexed integer column, and a binary data column, then populating it with random data through multiple INSERT statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-indexes.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n id INT NOT NULL PRIMARY KEY auto_increment,\n intkey INT NOT NULL,\n pad1 VARBINARY(1024),\n INDEX (intkey)\n);\n\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1024), RANDOM_BYTES(1024) FROM dual;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\n```\n\n----------------------------------------\n\nTITLE: Setting FetchSize for Streaming Results in JDBC\nDESCRIPTION: Configure JDBC to use streaming results by setting FetchSize to Integer.MIN_VALUE. This prevents client-side caching and enables streaming reads from the network connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nInteger.MIN_VALUE\n```\n\n----------------------------------------\n\nTITLE: DROP USER Syntax Definition in EBNF\nDESCRIPTION: The formal syntax definition for the DROP USER statement in Extended Backus-Naur Form (EBNF). It shows that the statement can include an optional 'IF EXISTS' clause and requires a list of usernames.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-user.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDropUserStmt ::=\n    'DROP' 'USER' ( 'IF' 'EXISTS' )? UsernameList\n\nUsername ::=\n    StringName ('@' StringName | singleAtIdentifier)? | 'CURRENT_USER' OptionalBraces\n```\n\n----------------------------------------\n\nTITLE: Deleting Books by Page in SQL\nDESCRIPTION: Shows how to delete books on a specific page using the page meta information obtained from the efficient paging method.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-paginate-results.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM books\nWHERE\n    id BETWEEN 268996 AND 213168525\nORDER BY id;\n```\n\n----------------------------------------\n\nTITLE: Installing MySQL 8.0 Client on macOS\nDESCRIPTION: Commands to install and configure MySQL 8.0 client on macOS using Homebrew to resolve authentication plugin issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connect-to-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbrew install mysql-client@8.0\nbrew unlink mysql\nbrew link mysql-client@8.0\n```\n\n----------------------------------------\n\nTITLE: Configuring Region Concurrency for CPU Optimization\nDESCRIPTION: Recommends limiting TiDB Lightning's CPU usage to 75% of logical CPUs to prevent resource contention and optimize performance\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-logical-import-mode.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nregion-concurrency: 75%\n```\n\n----------------------------------------\n\nTITLE: Querying STATISTICS Table Structure in TiDB\nDESCRIPTION: Shows how to view the structure of the STATISTICS table in the information_schema database using DESC command.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-statistics.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC statistics;\n```\n\n----------------------------------------\n\nTITLE: Creating and Applying Placement Rules\nDESCRIPTION: SQL commands for creating placement policies and applying them to tables for region-based replica management\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-multi-replica.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY primary_rule_for_region1 PRIMARY_REGION=\"Region1\" REGIONS=\"Region1, Region2,Region3\";\nCREATE PLACEMENT POLICY secondary_rule_for_region2 PRIMARY_REGION=\"Region2\" REGIONS=\"Region1,Region2,Region3\";\n\nALTER TABLE tpcc.warehouse PLACEMENT POLICY=primary_rule_for_region1;\nALTER TABLE tpcc.district PLACEMENT POLICY=primary_rule_for_region1;\n\nSELECT STORE_ID, address, leader_count, label FROM TIKV_STORE_STATUS ORDER BY store_id;\n```\n\n----------------------------------------\n\nTITLE: Creating Partitioned Tables for Partition Pruning Examples in SQL\nDESCRIPTION: Examples of creating partitioned tables to demonstrate partition pruning scenarios in TiDB. The tables use range partitioning based on different column expressions.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_51\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t1 (x int) partition by range (x) (\n        partition p0 values less than (5),\n        partition p1 values less than (10));\ncreate table t2 (x int);\n```\n\nLANGUAGE: sql\nCODE:\n```\nexplain select * from t1 left join t2 on t1.x = t2.x where t2.x > 5;\n```\n\nLANGUAGE: sql\nCODE:\n```\nexplain select * from t1 left join t2 on t1.x = t2.x and t2.x > 5;\n```\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t1 (x int) partition by range (x) (\n        partition p0 values less than (5),\n        partition p1 values less than (10));\n```\n\nLANGUAGE: sql\nCODE:\n```\nexplain select * from t2 where x < (select * from t1 where t2.x < t1.x and t2.x < 2);\n```\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (id int) partition by range (id) (\n        partition p0 values less than (5),\n        partition p1 values less than (10));\nselect * from t where id > 6;\n```\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (dt datetime) partition by range (to_days(id)) (\n        partition p0 values less than (to_days('2020-04-01')),\n        partition p1 values less than (to_days('2020-05-01')));\nselect * from t where dt > '2020-04-18';\n```\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (ts timestamp(3) not null default current_timestamp(3))\npartition by range (floor(unix_timestamp(ts))) (\n        partition p0 values less than (unix_timestamp('2020-04-01 00:00:00')),\n        partition p1 values less than (unix_timestamp('2020-05-01 00:00:00')));\nselect * from t where ts > '2020-04-18 02:00:42.123';\n```\n\n----------------------------------------\n\nTITLE: Storing Embeddings in TiDB\nDESCRIPTION: Process for generating embeddings from text and storing them in TiDB vector storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-jinaai-embedding.md#2025-04-18_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nTEXTS = [\n   'Jina AI offers best-in-class embeddings, reranker and prompt optimizer, enabling advanced multimodal AI.',\n   'TiDB is an open-source MySQL-compatible database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads.',\n]\ndata = []\n\nfor text in TEXTS:\n    # Generate embeddings for the texts via Jina AI API.\n    embedding = generate_embeddings(text)\n    data.append({\n        'text': text,\n        'embedding': embedding\n    })\n\nwith Session(engine) as session:\n   print('- Inserting Data to TiDB...')\n   for item in data:\n      print(f'  - Inserting: {item[\"text\"]}')\n      session.add(Document(\n         content=item['text'],\n         content_vec=item['embedding']\n      ))\n   session.commit()\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Clustered Index in SQL\nDESCRIPTION: Creates a 'ratings' table with a composite primary key using book_id and user_id, and creates a clustered index on that primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `bookshop`.`ratings` (\n  `book_id` bigint,\n  `user_id` bigint,\n  `score` tinyint,\n  `rated_at` datetime,\n  PRIMARY KEY (`book_id`,`user_id`) CLUSTERED\n);\n```\n\n----------------------------------------\n\nTITLE: Managing Schedulers with pd-ctl in TiDB\nDESCRIPTION: This snippet shows pd-ctl commands for managing schedulers in TiDB, including showing current schedulers, removing balance-leader-scheduler, and adding evict-leader-scheduler.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/pd-scheduling-best-practices.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n- `scheduler show`: Shows currently running schedulers in the system\n- `scheduler remove balance-leader-scheduler`: Removes (disable) balance-leader-scheduler\n- `scheduler add evict-leader-scheduler 1`: Adds a scheduler to remove all leaders in Store 1\n```\n\n----------------------------------------\n\nTITLE: Generating and Storing Document Embeddings in TiDB\nDESCRIPTION: Creates a vector index from documents by generating embeddings and storing them in the TiDB vector store using the configured storage context.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nstorage_context = StorageContext.from_defaults(vector_store=tidbvec)\nindex = VectorStoreIndex.from_documents(\n   documents, storage_context=storage_context, show_progress=True\n)\n```\n\n----------------------------------------\n\nTITLE: Optimized Column Selection in SQL Queries\nDESCRIPTION: Examples demonstrating efficient column selection versus inefficient SELECT * queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql-best-practices.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM books WHERE title = 'Marian Yost';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT title, price FROM books WHERE title = 'Marian Yost';\n```\n\n----------------------------------------\n\nTITLE: Benchmarking using TiUP Bench (Bash)\nDESCRIPTION: These commands demonstrate how to initiate different benchmark workloads using the TiUP bench component. Each command targets a specific benchmark type: TPC-C, TPC-H, CH-benCHmark, YCSB, and RawSQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench tpcc   # Benchmark a database using TPC-C\ntiup bench tpch   # Benchmark a database using TPC-H\ntiup bench ch     # Benchmark a database using CH-benCHmark\ntiup bench ycsb   # Benchmark a database using YCSB\ntiup bench rawsql # Benchmark a database using arbitrary SQL files\n```\n\n----------------------------------------\n\nTITLE: Similarity Search with Metadata Filter in Python\nDESCRIPTION: Shows how to perform a similarity search with metadata filters in TiDBVectorStore using Python, including printing the results.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndocs_with_score = vector_store.similarity_search_with_score(\n    \"Introduction to TiDB Vector\", filter={\"title\": \"TiDB Vector functionality\"}, k=4\n)\nfor doc, score in docs_with_score:\n    print(\"-\" * 80)\n    print(\"Score: \", score)\n    print(doc.page_content)\n    print(\"-\" * 80)\n```\n\n----------------------------------------\n\nTITLE: Creating Composite Index for Order Optimization - SQL\nDESCRIPTION: This SQL statement creates a composite index on the orders table using user_id, mode, id, created_at, and label_id as columns. The index aims to improve query performance by optimizing filtering and sorting mechanisms in related queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX idx_composite ON orders(user_id, mode, id, created_at, label_id);\nANALYZE TABLE orders index idx_composite;\n```\n\n----------------------------------------\n\nTITLE: Basic ALTER PLACEMENT POLICY Example\nDESCRIPTION: Example showing how placement policies are created and altered, demonstrating that ALTER replaces rather than merges policies.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-placement-policy.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY p1 FOLLOWERS=4;\nALTER PLACEMENT POLICY p1 PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\";\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Clustered Index in SQL\nDESCRIPTION: This SQL statement demonstrates how to create a table with a clustered index in TiDB. Having a clustered index helps in efficient data retrieval and storage based on the primary key order. The prerequisites include enabling the clustered index feature in the TiDB configuration or explicitly using the CLUSTERED keyword in the SQL statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `t` (`a` VARCHAR(255), `b` INT, PRIMARY KEY (`a`, `b`) CLUSTERED);\n```\n\n----------------------------------------\n\nTITLE: Running Database Migrations for Django TiDB Project\nDESCRIPTION: Command to apply database migrations to set up the required schema in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython manage.py migrate\n```\n\n----------------------------------------\n\nTITLE: Committing or Rolling Back Transactions in TiDB SQL\nDESCRIPTION: This snippet demonstrates how to commit or roll back a transaction in TiDB using SQL commands. These statements are used to either confirm changes made during a transaction or discard them.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCOMMIT\nROLLBACK\n```\n\n----------------------------------------\n\nTITLE: Table Naming Pattern Examples\nDESCRIPTION: Examples demonstrating naming patterns for different types of tables including temporary, backup, and business operation tables\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-object-naming-guidelines.md#2025-04-18_snippet_1\n\nLANGUAGE: text\nCODE:\n```\ntmp_t_crm_relation_0425\nbak_t_crm_relation_20170425\ntmp_st_{business code}_{creator abbreviation}_{date}\nt_crm_ec_record_YYYY{MM}{dd}\n```\n\n----------------------------------------\n\nTITLE: Creating Test Tables and Running Index Advisor\nDESCRIPTION: Example showing how to create test tables, run sample queries, and generate index recommendations using RECOMMEND INDEX RUN command. The example creates two tables with 5,000 rows each and runs three different query patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (a INT, b INT, c INT, d INT);\nCREATE TABLE t2 (a INT, b INT, c INT, d INT);\n\n-- Run some queries in this workload.\nSELECT a, b FROM t1 WHERE a=1 AND b<=5;\nSELECT d FROM t1 ORDER BY d LIMIT 10;\nSELECT * FROM t1, t2 WHERE t1.a=1 AND t1.d=t2.d;\n\nRECOMMEND INDEX RUN;\n```\n\n----------------------------------------\n\nTITLE: Analyzing TiFlash Query Execution with EXPLAIN ANALYZE in TiDB\nDESCRIPTION: This SQL query demonstrates how to use EXPLAIN ANALYZE to determine whether a query is using TiFlash replicas in HTAP mode. The presence of ExchangeSender and ExchangeReceiver operators in the execution plan indicates that the MPP mode is active.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-htap.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nUSE test;\nEXPLAIN ANALYZE SELECT\n    l_orderkey,\n    SUM(\n        l_extendedprice * (1 - l_discount)\n    ) AS revenue,\n    o_orderdate,\n    o_shippriority\nFROM\n    customer,\n    orders,\n    lineitem\nWHERE\n    c_mktsegment = 'BUILDING'\nAND c_custkey = o_custkey\nAND l_orderkey = o_orderkey\nAND o_orderdate < DATE '1996-01-01'\nAND l_shipdate > DATE '1996-02-01'\nGROUP BY\n    l_orderkey,\n    o_orderdate,\n    o_shippriority\nORDER BY\n    revenue DESC,\n    o_orderdate\nlimit 10;\n```\n\n----------------------------------------\n\nTITLE: Viewing SQL Execution Plan with Physical Execution Information\nDESCRIPTION: Example of using tidb_decode_plan to view detailed execution information after enabling the collection of physical execution information. This helps in understanding query performance characteristics including timing and memory usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nselect tidb_decode_plan('jAOIMAk1XzE3CTAJMQlmdW5jczpjb3VudChDb2x1bW4jNyktPkMJC/BMNQkxCXRpbWU6MTAuOTMxNTA1bXMsIGxvb3BzOjIJMzcyIEJ5dGVzCU4vQQoxCTMyXzE4CTAJMQlpbmRleDpTdHJlYW1BZ2dfOQkxCXQRSAwyNzY4LkgALCwgcnBjIG51bTogMQkMEXMQODg0MzUFK0hwcm9jIGtleXM6MjUwMDcJMjA2HXsIMgk1BWM2zwAAMRnIADcVyAAxHcEQNQlOL0EBBPBbCjMJMTNfMTYJMQkzMTI4MS44NTc4MTk5MDUyMTcJdGFibGU6dCwgaW5kZXg6aWR4KGEpLCByYW5nZTpbLWluZiw1MDAwMCksIGtlZXAgb3JkZXI6ZmFsc2UJMjUBrgnQVnsA');\n```\n\n----------------------------------------\n\nTITLE: TiDB Cloud Management Operations\nDESCRIPTION: List of available management operations for TiDB Cloud Serverless clusters, including cluster and branch management, maintenance, and GitHub integration\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-console-auditing.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Operation              | Description                                                                     |\n|------------------------|---------------------------------------------------------------------------------|\n| SetSpendLimit          | Edit the spending limit of a TiDB Cloud Serverless scalable cluster             |\n| UpdateMaintenanceWindow| Modify maintenance window start time                                            |\n| DeferMaintenanceTask   | Defer a maintenance task                                                        |\n| CreateBranch           | Create a TiDB Cloud Serverless branch                                           |\n| DeleteBranch           | Delete a TiDB Cloud Serverless branch                                           |\n| SetBranchRootPassword  | Set root password for a TiDB Cloud Serverless branch                            |\n| ConnectBranchGitHub    | Connect the cluster with a GitHub repository to enable branching integration    |\n| DisconnectBranchGitHub | Disconnect the cluster from a GitHub repository to disable branching integration|\n```\n\n----------------------------------------\n\nTITLE: Basic TiDB SELECT Query Example\nDESCRIPTION: Example showing table creation, data insertion, and basic SELECT query execution in TiDB. Demonstrates creating a simple table with auto-increment primary key, inserting multiple rows, and retrieving all records.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-select.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5);\nQuery OK, 5 rows affected (0.03 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\nmysql> SELECT * FROM t1;\n+----+----+\n| id | c1 |\n+----+----+\n|  1 |  1 |\n|  2 |  2 |\n|  3 |  3 |\n|  4 |  4 |\n|  5 |  5 |\n+----+----+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Calculating MySQL Database and Table Sizes\nDESCRIPTION: SQL queries to estimate the data volume in MySQL by calculating sizes of all schemas and the 5 largest tables. This helps in planning the migration storage requirements.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-to-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\n-- Calculate the size of all schemas\nSELECT\n  TABLE_SCHEMA,\n  FORMAT_BYTES(SUM(DATA_LENGTH)) AS 'Data Size',\n  FORMAT_BYTES(SUM(INDEX_LENGTH)) 'Index Size'\nFROM\n  information_schema.tables\nGROUP BY\n  TABLE_SCHEMA;\n\n-- Calculate the 5 largest tables\nSELECT \n  TABLE_NAME,\n  TABLE_SCHEMA,\n  FORMAT_BYTES(SUM(data_length)) AS 'Data Size',\n  FORMAT_BYTES(SUM(index_length)) AS 'Index Size',\n  FORMAT_BYTES(SUM(data_length+index_length)) AS 'Total Size'\nFROM\n  information_schema.tables\nGROUP BY\n  TABLE_NAME,\n  TABLE_SCHEMA\nORDER BY\n  SUM(DATA_LENGTH+INDEX_LENGTH) DESC\nLIMIT\n  5;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning for SQL File Import (TOML)\nDESCRIPTION: TOML configuration file for TiDB Lightning to import data from SQL files. It specifies logging settings, backend mode, data source directory, and target TiDB cluster information.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-sql-files-to-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[lightning]\nlevel = \"info\"\nfile = \"tidb-lightning.log\"\n\n[tikv-importer]\nbackend = \"local\"\nsorted-kv-dir = \"${sorted-kv-dir}\"\n\n[mydumper]\ndata-source-dir = \"${data-path}\"\n\n[tidb]\nhost = ${host}\nport = ${port}\nuser = \"${user_name}\"\npassword = \"${password}\"\nstatus-port = ${status-port}\npd-addr = \"${ip}:${port}\"\n```\n\n----------------------------------------\n\nTITLE: Hibernate SessionFactory Initialization\nDESCRIPTION: Java code example showing how to initialize Hibernate SessionFactory using the configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connect-to-tidb.md#2025-04-18_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nSessionFactory sessionFactory = new Configuration().configure(\"hibernate.cfg.xml\").buildSessionFactory();\n```\n\n----------------------------------------\n\nTITLE: Adding Columns in TiDB Using SQL\nDESCRIPTION: This section demonstrates how to add columns to a TiDB table using SQL. The example shows a series of commands to create a table, insert data, and add new columns with default values and after existing columns. The operations showcase TiDB's ability to perform online column additions without blocking table access.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-add-column.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT);\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> INSERT INTO t1 VALUES (NULL);\nQuery OK, 1 row affected (0.02 sec)\n\nmysql> SELECT * FROM t1;\n+----+\n| id |\n+----+\n|  1 |\n+----+\n1 row in set (0.00 sec)\n\nmysql> ALTER TABLE t1 ADD COLUMN c1 INT NOT NULL;\nQuery OK, 0 rows affected (0.28 sec)\n\nmysql> SELECT * FROM t1;\n+----+----+\n| id | c1 |\n+----+----+\n|  1 |  0 |\n+----+----+\n1 row in set (0.00 sec)\n\nmysql> ALTER TABLE t1 ADD c2 INT NOT NULL AFTER c1;\nQuery OK, 0 rows affected (0.28 sec)\n\nmysql> SELECT * FROM t1;\n+----+----+----+\n| id | c1 | c2 |\n+----+----+----+\n|  1 |  0 |  0 |\n+----+----+----+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a Table and Adding Data for ALTER TABLE Example\nDESCRIPTION: SQL commands to create a test table with an auto-increment primary key and insert some sample data, which will be used to demonstrate ALTER TABLE operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\nINSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5);\n```\n\n----------------------------------------\n\nTITLE: Examples of RESTORE SQL Statement Usage\nDESCRIPTION: Demonstrations on executing the RESTORE statement in TiDB. Examples include restoring all databases, a partial database, specific tables, and using external storage systems like S3. Performance tuning solutions are illustrated with parameters like RATE_LIMIT and CHECKSUM. The provided snippets are essential for practical applications of database restorations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-restore.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nRESTORE DATABASE * FROM 'local:///mnt/backup/2020/04/';\n```\n\nLANGUAGE: sql\nCODE:\n```\nRESTORE DATABASE `test` FROM 'local:///mnt/backup/2020/04/';\n```\n\nLANGUAGE: sql\nCODE:\n```\nRESTORE TABLE `test`.`sbtest01`, `test`.`sbtest02` FROM 'local:///mnt/backup/2020/04/';\n```\n\nLANGUAGE: sql\nCODE:\n```\nRESTORE DATABASE * FROM 's3://example-bucket-2020/backup-05/';\n```\n\nLANGUAGE: sql\nCODE:\n```\nRESTORE DATABASE * FROM 's3://example-bucket-2020/backup-05/'\n    SEND_CREDENTIALS_TO_TIKV = FALSE;\n```\n\nLANGUAGE: sql\nCODE:\n```\nRESTORE DATABASE * FROM 's3://example-bucket-2020/backup-06/'\n    RATE_LIMIT = 120 MB/SECOND\n    CONCURRENCY = 64\n    CHECKSUM = FALSE;\n```\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP DATABASE `test` TO 's3://example-bucket/full-backup'  SNAPSHOT = 413612900352000;\nBACKUP DATABASE `test` TO 's3://example-bucket/inc-backup-1' SNAPSHOT = 414971854848000 LAST_BACKUP = 413612900352000;\nBACKUP DATABASE `test` TO 's3://example-bucket/inc-backup-2' SNAPSHOT = 416353458585600 LAST_BACKUP = 414971854848000;\n```\n\nLANGUAGE: sql\nCODE:\n```\nRESTORE DATABASE * FROM 's3://example-bucket/full-backup';\nRESTORE DATABASE * FROM 's3://example-bucket/inc-backup-1';\nRESTORE DATABASE * FROM 's3://example-bucket/inc-backup-2';\n```\n\n----------------------------------------\n\nTITLE: Verifying Empty Bindings in TiDB\nDESCRIPTION: Confirms that all bindings have been removed by showing an empty result set.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-binding.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GLOBAL BINDINGS;\n```\n\n----------------------------------------\n\nTITLE: Initializing an Empty TiUP Repository\nDESCRIPTION: Creates an empty TiUP repository in the specified directory, which is the first step in creating a custom mirror.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ntiup mirror init /data/mirror\n```\n\n----------------------------------------\n\nTITLE: Running Update Index Test with Sysbench\nDESCRIPTION: Bash command for executing the update index benchmark test with Sysbench, which tests the performance of index updates in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nsysbench --config-file=config oltp_update_index --tables=32 --table-size=10000000 --db-ps-mode=auto --rand-type=uniform run\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for BEGIN TRANSACTION in TiDB\nDESCRIPTION: Formal EBNF syntax definition for the START TRANSACTION/BEGIN statement in TiDB, showing the various options including PESSIMISTIC/OPTIMISTIC modes, READ WRITE/ONLY options, and timestamp-related clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-start-transaction.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nBeginTransactionStmt ::=\n    'BEGIN' ( 'PESSIMISTIC' | 'OPTIMISTIC' )?\n|   'START' 'TRANSACTION' ( 'READ' ( 'WRITE' | 'ONLY' ( ( 'WITH' 'TIMESTAMP' 'BOUND' TimestampBound )? | AsOfClause ) ) | 'WITH' 'CONSISTENT' 'SNAPSHOT' | 'WITH' 'CAUSAL' 'CONSISTENCY' 'ONLY' )?\n\nAsOfClause ::=\n    ( 'AS' 'OF' 'TIMESTAMP' Expression)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Partition Pruning with a SELECT Query in SQL\nDESCRIPTION: This SQL snippet shows a SELECT query that benefits from partition pruning by targeting specific region_code values, which fall into only two of the four partitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_50\n\nLANGUAGE: sql\nCODE:\n```\nSELECT fname, lname, region_code, dob\n    FROM t1\n    WHERE region_code > 125 AND region_code < 130;\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying Table with Unique Index in TiDB\nDESCRIPTION: Example showing table creation with a unique index and a query that demonstrates index selection based on pre-rules. The query uses a unique index with point ranges requiring table access.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t(a INT PRIMARY KEY, b INT, c INT, UNIQUE INDEX idx_b(b));\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> EXPLAIN FORMAT = 'verbose' SELECT b, c FROM t WHERE b = 3 OR b = 6;\n+-------------------+---------+---------+------+-------------------------+------------------------------+\n| id                | estRows | estCost | task | access object           | operator info                |\n+-------------------+---------+---------+------+-------------------------+------------------------------+\n| Batch_Point_Get_5 | 2.00    | 8.80    | root | table:t, index:idx_b(b) | keep order:false, desc:false |\n+-------------------+---------+---------+------+-------------------------+------------------------------+\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SHOW WARNINGS;\n+-------+------+-------------------------------------------------------------------------------------------+\n| Level | Code | Message                                                                                   |\n+-------+------+-------------------------------------------------------------------------------------------+\n| Note  | 1105 | unique index idx_b of t is selected since the path only has point ranges with double scan |\n+-------+------+-------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Executing Foreign Key Operations with EXPLAIN ANALYZE in SQL\nDESCRIPTION: Demonstrates how to use the EXPLAIN ANALYZE statement to view execution details of foreign key operations. It focuses on the DELETE operation and illustrates foreign key cascade behavior along with operator execution times.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain analyze delete from parent where id = 1;\n+----------------------------------+---------+---------+-----------+---------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------+-----------+------+\n| id                               | estRows | actRows | task      | access object                   | execution info                                                                                                                                                                               | operator info                               | memory    | disk |\n+----------------------------------+---------+---------+-----------+---------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------+-----------+------+\n| Delete_2                         | N/A     | 0       | root      |                                 | time:117.3µs, loops:1                                                                                                                                                                        | N/A                                         | 380 Bytes | N/A  |\n| ├─Point_Get_1                    | 1.00    | 1       | root      | table:parent                    | time:63.6µs, loops:2, Get:{num_rpc:1, total_time:29.9µs}                                                                                                                                     | handle:1                                    | N/A       | N/A  |\n| └─Foreign_Key_Cascade_3          | 0.00    | 0       | root      | table:child, index:idx_pid      | total:1.28ms, foreign_keys:1                                                                                                                                                                 | foreign_key:fk_1, on_delete:CASCADE         | N/A       | N/A  |\n|   └─Delete_7                     | N/A     | 0       | root      |                                 | time:904.8µs, loops:1                                                                                                                                                                        | N/A                                         | 1.11 KB   | N/A  |\n|     └─IndexLookUp_11             | 10.00   | 1       | root      |                                 | time:869.5µs, loops:2, index_task: {total_time: 371.1µs, fetch_handle: 357.3µs, build: 1.25µs, wait: 12.5µs}, table_task: {total_time: 382.6µs, num: 1, concurrency: 5}                      |                                             | 9.13 KB   | N/A  |\n|       ├─IndexRangeScan_9(Build)  | 10.00   | 1       | cop[tikv] | table:child, index:idx_pid(pid) | time:351.2µs, loops:3, cop_task: {num: 1, max: 282.3µs, proc_keys: 0, rpc_num: 1, rpc_time: 263µs, copr_cache_hit_ratio: 0.00, distsql_concurrency: 15}, tikv_task:{time:220.2µs, loops:0}   | range:[1,1], keep order:false, stats:pseudo | N/A       | N/A  |\n|       └─TableRowIDScan_10(Probe) | 10.00   | 1       | cop[tikv] | table:child                     | time:223.9µs, loops:2, cop_task: {num: 1, max: 168.8µs, proc_keys: 0, rpc_num: 1, rpc_time: 154.5µs, copr_cache_hit_ratio: 0.00, distsql_concurrency: 15}, tikv_task:{time:145.6µs, loops:0} | keep order:false, stats:pseudo              | N/A       | N/A  |\n+----------------------------------+---------+---------+-----------+---------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------+-----------+------+\n\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for TiDB AWS Lambda Project\nDESCRIPTION: npm command to install required packages including mysql2 for the sample application.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Analyzing Query Execution Plan with TiFlash in TiDB\nDESCRIPTION: This EXPLAIN ANALYZE statement shows the execution plan for the analytical query, verifying whether TiFlash is being used to process the query.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT HOUR(`rated_at`), AVG(`score`) FROM `bookshop`.`ratings` GROUP BY HOUR(`rated_at`);\n```\n\n----------------------------------------\n\nTITLE: Raw Data Structure Example in TiDB\nDESCRIPTION: Example showing the initial data structure before the Expand operator is applied, with columns for year, month, day, and profit.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/group-by-modifier.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n+------+-------+------+------------+\n| year | month | day  | profit     |\n+------+-------+------+------------+\n| 2000 | Jan   |    1 | 10.3000000 |\n+------+-------+------+------------+\n```\n\n----------------------------------------\n\nTITLE: Configuring Load Base Split with SQL in TiDB\nDESCRIPTION: Shows how to modify Load Base Split parameters including QPS threshold, byte threshold, and CPU usage threshold using SQL statements in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-load-base-split.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n# Set the QPS threshold to 1500\nSET config tikv split.qps-threshold=1500;\n# Set the byte threshold to 15 MiB (15 * 1024 * 1024)\nSET config tikv split.byte-threshold=15728640;\n# Set the CPU usage threshold to 50%\nSET config tikv split.region-cpu-overload-threshold-ratio=0.5;\n```\n\n----------------------------------------\n\nTITLE: Handling Binlog Schema Mismatch in DM\nDESCRIPTION: This JSON snippet represents an error encountered when the number of columns in the upstream binlog does not match the columns in the downstream table schema. It alerts users of the column count mismatch issue during data migration using DM (Data Migration tool).\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-with-more-columns-downstream.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"errors\": [\n        {\n            \"ErrCode\": 36027,\n            \"ErrClass\": \"sync-unit\",\n            \"ErrScope\": \"internal\",\n            \"ErrLevel\": \"high\",\n            \"Message\": \"startLocation: [position: (mysql-bin.000001, 2022), gtid-set:09bec856-ba95-11ea-850a-58f2b4af5188:1-9 ], endLocation: [ position: (mysql-bin.000001, 2022), gtid-set: 09bec856-ba95-11ea-850a-58f2b4af5188:1-9]: gen insert sqls failed, schema: log, table: messages: Column count doesn't match value count: 3 (columns) vs 2 (values)\",\n            \"RawCause\": \"\",\n            \"Workaround\": \"\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with UNIQUE Key Constraint\nDESCRIPTION: This snippet demonstrates creating a 'users' table with a UNIQUE KEY constraint on the 'username' column to ensure all usernames are unique.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nDROP TABLE IF EXISTS users;\nCREATE TABLE users (\n id INT NOT NULL PRIMARY KEY AUTO_INCREMENT,\n username VARCHAR(60) NOT NULL,\n UNIQUE KEY (username)\n);\nINSERT INTO users (username) VALUES ('dave'), ('sarah'), ('bill');\n```\n\n----------------------------------------\n\nTITLE: Truncating a Partition in SQL\nDESCRIPTION: This SQL snippet demonstrates how to delete all data from a specific partition in a Hash partitioned table.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_44\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE example TRUNCATE PARTITION p0;\n```\n\n----------------------------------------\n\nTITLE: Querying Variables by Value\nDESCRIPTION: SQL example demonstrating how to query all variables with a specific value (300) using SHOW VARIABLES with a WHERE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-variables.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW VARIABLES WHERE Value=300;\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud using Python\nDESCRIPTION: This snippet demonstrates how to connect to a TiDB Cloud Dedicated cluster using Python's `mysqlclient` library with TLS enabled. It requires setting the `ssl_mode` to `VERIFY_IDENTITY` and specifying the path to the CA certificate using the `ssl` parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tls-connect-to-dedicated.md#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nhost=\"tidb.srgnqxji5bc.clusters.staging.tidb-cloud.com\", user=\"root\", password=\"<your_password>\", port=4000, database=\"test\", ssl_mode=\"VERIFY_IDENTITY\", ssl={\"ca\": \"ca.pem\"}\n```\n\n----------------------------------------\n\nTITLE: Creating Tables with Foreign Key References in SQL\nDESCRIPTION: This SQL snippet demonstrates creating parent and child tables with a foreign key reference. However, the 'REFERENCES' clause in the child table is ignored by both MySQL and TiDB when not part of a 'FOREIGN KEY' definition.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_12\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE parent (\n    id INT KEY\n);\n\nCREATE TABLE child (\n    id INT,\n    pid INT REFERENCES parent(id)\n);\n\nSHOW CREATE TABLE child;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Tables for Statistics\nDESCRIPTION: These SQL statements analyze several tables in the `tpcc` database to collect statistics. Accurate statistics help the TiDB optimizer generate optimal execution plans for queries, improving performance. This step is performed before running the TPC-C tests.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v6.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n\"ANALYZE TABLE customer;\\nANALYZE TABLE district;\\nANALYZE TABLE history;\\nANALYZE TABLE item;\\nANALYZE TABLE new_order;\\nANALYZE TABLE order_line;\\nANALYZE TABLE orders;\\nANALYZE TABLE stock;\\nANALYZE TABLE warehouse;\"\n```\n\n----------------------------------------\n\nTITLE: Using JSON_CONTAINS_PATH in SQL\nDESCRIPTION: Shows usage of JSON_CONTAINS_PATH to check if a JSON document contains data at specific paths. Returns 1 if path exists, 0 if not.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-search.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_CONTAINS_PATH('{\"foo\": \"bar\", \"aaa\": 5}','all','$.foo');\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_CONTAINS_PATH('{\"foo\": \"bar\", \"aaa\": 5}','all','$.bar');\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_CONTAINS_PATH('{\"foo\": \"bar\", \"aaa\": 5}','all','$.foo', '$.aaa');\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Column Pruning with SELECT Statement in TiDB SQL\nDESCRIPTION: This SQL query demonstrates column pruning by selecting only column 'a' from table 't' with a filter condition on column 'b'. In this example, columns 'c' and 'd' can be pruned since they are not used in either the selection or filtering operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/column-pruning.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nselect a from t where b> 5\n```\n\n----------------------------------------\n\nTITLE: Resuming a TiDB Cloud Cluster Configuration\nDESCRIPTION: This snippet changes the pause status of the TiDB Cloud cluster by setting 'paused' to false within the configuration structure. It prepares the cluster for resumption.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_13\n\nLANGUAGE: hcl\nCODE:\n```\nconfig = {\n    paused = false\n    root_password = \"Your_root_password1.\"\n    port          = 4000\n    ...\n  }\n```\n\n----------------------------------------\n\nTITLE: Configuring Spring Boot Application for TiDB Connection\nDESCRIPTION: This YAML configuration sets up the datasource and JPA properties for connecting to TiDB using Spring Boot. It includes environment variable placeholders for connection details.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-spring-boot.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nspring:\n  datasource:\n    url: ${TIDB_JDBC_URL:jdbc:mysql://localhost:4000/test}\n    username: ${TIDB_USER:root}\n    password: ${TIDB_PASSWORD:}\n    driver-class-name: com.mysql.cj.jdbc.Driver\n  jpa:\n    show-sql: true\n    database-platform: org.hibernate.dialect.TiDBDialect\n    hibernate:\n      ddl-auto: create-drop\n```\n\n----------------------------------------\n\nTITLE: Validating Password Strength in TiDB\nDESCRIPTION: These SQL queries illustrate the use of the VALIDATE_PASSWORD_STRENGTH() function in TiDB, which evaluates a password's strength against the current complexity policy, returning a score from 0 to 100.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> SELECT VALIDATE_PASSWORD_STRENGTH('weak');\n+------------------------------------+\n| VALIDATE_PASSWORD_STRENGTH('weak') |\n+------------------------------------+\n|                                 25 |\n+------------------------------------+\n1 row in set (0.01 sec)\n\nmysql> SELECT VALIDATE_PASSWORD_STRENGTH('lessweak$_@123');\n+----------------------------------------------+\n| VALIDATE_PASSWORD_STRENGTH('lessweak$_@123') |\n+----------------------------------------------+\n|                                           50 |\n+----------------------------------------------+\n1 row in set (0.01 sec)\n\nmysql> SELECT VALIDATE_PASSWORD_STRENGTH('N0Tweak$_@123!');\n+----------------------------------------------+\n| VALIDATE_PASSWORD_STRENGTH('N0Tweak$_@123!') |\n+----------------------------------------------+\n|                                          100 |\n+----------------------------------------------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation for VS Code TiDB Connection\nDESCRIPTION: Markdown content detailing the prerequisites and setup process for connecting Visual Studio Code to TiDB databases using the SQLTools extension. Includes compatibility notes and installation instructions.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-gui-vscode-sqltools.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: Connect to TiDB with Visual Studio Code\nsummary: Learn how to connect to TiDB using Visual Studio Code or GitHub Codespaces.\n---\n\n# Connect to TiDB with Visual Studio Code\n\nTiDB is a MySQL-compatible database, and [Visual Studio Code (VS Code)](https://code.visualstudio.com/) is a lightweight but powerful source code editor. This tutorial uses the [SQLTools](https://marketplace.visualstudio.com/items?itemName=mtxr.sqltools) extension which supports TiDB as an [official driver](https://marketplace.visualstudio.com/items?itemName=mtxr.sqltools-driver-mysql).\n\nIn this tutorial, you can learn how to connect to your TiDB cluster using Visual Studio Code.\n\n> **Note:**\n>\n> - This tutorial is compatible with TiDB Cloud Serverless, TiDB Cloud Dedicated, and TiDB Self-Managed.\n> - This tutorial also works with Visual Studio Code Remote Development environments, such as [GitHub Codespaces](https://github.com/features/codespaces), [Visual Studio Code Dev Containers](https://code.visualstudio.com/docs/devcontainers/containers), and [Visual Studio Code WSL](https://code.visualstudio.com/docs/remote/wsl).\n\n## Prerequisites\n\nTo complete this tutorial, you need:\n\n- [Visual Studio Code](https://code.visualstudio.com/#alt-downloads) **1.72.0** or later versions.\n- [SQLTools MySQL/MariaDB/TiDB](https://marketplace.visualstudio.com/items?itemName=mtxr.sqltools-driver-mysql) extension for Visual Studio Code. To install it, you can use one of the following methods:\n    - Click <a href=\"vscode:extension/mtxr.sqltools-driver-mysql\">this link</a>  to launch VS Code and install the extension directly.\n    - Navigate to [VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=mtxr.sqltools-driver-mysql) and click **Install**.\n    - On the **Extensions** tab of your VS Code, search for `mtxr.sqltools-driver-mysql` to get the **SQLTools MySQL/MariaDB/TiDB** extension, and then click **Install**.\n- A TiDB cluster.\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Vector Column in SQL\nDESCRIPTION: Demonstrates how to create a table with a Vector column of fixed dimension 3.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-data-types.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE vector_table (\n    id INT PRIMARY KEY,\n    embedding VECTOR(3)\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Manual Workload Snapshot\nDESCRIPTION: SQL command to manually trigger a workload snapshot collection.\nSOURCE: https://github.com/pingcap/docs/blob/master/workload-repository.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nADMIN CREATE WORKLOAD SNAPSHOT;\n```\n\n----------------------------------------\n\nTITLE: Deploying TiDB Clusters using TiUP Playground\nDESCRIPTION: Commands to create upstream and downstream TiDB clusters using TiUP Playground and view their status.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n# Create an upstream cluster\ntiup --tag upstream playground --host 0.0.0.0 --db 1 --pd 1 --kv 1 --tiflash 0 --ticdc 1\n# Create a downstream cluster\ntiup --tag downstream playground --host 0.0.0.0 --db 1 --pd 1 --kv 1 --tiflash 0 --ticdc 1\n# View cluster status\ntiup status\n```\n\n----------------------------------------\n\nTITLE: Querying View Information from INFORMATION_SCHEMA in SQL\nDESCRIPTION: This SQL query retrieves metadata for all views in the database by querying the INFORMATION_SCHEMA.VIEWS table. It provides detailed information about each view's definition and properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/views.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nselect * from information_schema.views;\n```\n\n----------------------------------------\n\nTITLE: Terraform Configuration for Amazon S3 Import to TiDB Cloud\nDESCRIPTION: Terraform configuration for importing data from Amazon S3 buckets to a TiDB Cloud cluster. It includes configurations for both CSV and Parquet data formats with AWS role-based access.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-import-resource.md#2025-04-18_snippet_2\n\nLANGUAGE: terraform\nCODE:\n```\nterraform {\n  required_providers {\n    tidbcloud = {\n      source = \"tidbcloud/tidbcloud\"\n    }\n  }\n}\n\nprovider \"tidbcloud\" {\n  public_key  = \"your_public_key\"\n  private_key = \"your_private_key\"\n}\n\nresource \"tidbcloud_import\" \"example_s3_csv\" {\n  project_id   = \"your_project_id\"\n  cluster_id   = \"your_cluster_id\"\n  type         = \"S3\"\n  data_format  = \"CSV\"\n  aws_role_arn = \"your_arn\"\n  source_url   = \"your_url\"\n}\n\nresource \"tidbcloud_import\" \"example_s3_parquet\" {\n  project_id   = \"your_project_id\"\n  cluster_id   = \"your_cluster_id\"\n  type         = \"S3\"\n  data_format  = \"Parquet\"\n  aws_role_arn = \"your_arn\"\n  source_url   = \"your_url\"\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Row-Level Checksum in TiDB\nDESCRIPTION: Demonstrates enabling the row-level checksum feature in TiDB by setting the global system variable tidb_enable_row_level_checksum to ON. This allows using the TIDB_ROW_CHECKSUM function.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_row_level_checksum = ON;\n```\n\n----------------------------------------\n\nTITLE: Filtering Documents by Vector Distance Threshold\nDESCRIPTION: Query to find documents within a specific distance threshold from a query vector using Django ORM with TiDB Vector Search.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nresults = Document.objects.annotate(\n   distance=CosineDistance('embedding', [1, 2, 3])\n).filter(distance__lt=0.2).order_by('distance')[:3]\n```\n\n----------------------------------------\n\nTITLE: Querying Data with Hibernate in Java\nDESCRIPTION: This snippet demonstrates how to query data from TiDB using Hibernate ORM. It opens a session, retrieves a PlayerBean object by its ID, and prints the result.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-hibernate.md#2025-04-18_snippet_3\n\nLANGUAGE: java\nCODE:\n```\ntry (Session session = sessionFactory.openSession()) {\n    PlayerBean player = session.get(PlayerBean.class, \"id\");\n    System.out.println(player);\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Aggregate Pushdown in TiDB\nDESCRIPTION: This SQL statement enables the `tidb_opt_agg_push_down` option, which allows TiDB to push down aggregate operations to TiFlash for potentially improved performance. It is a session-level setting, so it only affects the current connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n\"mysql> set @@tidb_opt_agg_push_down = ON;\\nQuery OK, 0 rows affected (0.00 sec)\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Hash Partitioning by Store ID in SQL\nDESCRIPTION: This example demonstrates how to create a Hash partitioned table 'employees' divided into 4 partitions based on the 'store_id' column.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_25\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT\n)\n\nPARTITION BY HASH(store_id)\nPARTITIONS 4;\n```\n\n----------------------------------------\n\nTITLE: TiDB JSON Array Sorting Example\nDESCRIPTION: Example demonstrating TiDB's ability to sort JSON arrays, which differs from MySQL's behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-json.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(j JSON);\nINSERT INTO t VALUES ('[1,2,3,4]');\nINSERT INTO t VALUES ('[5]');\nSELECT j FROM t WHERE j < JSON_ARRAY(5);\nSELECT j FROM t ORDER BY j;\n```\n\n----------------------------------------\n\nTITLE: Enabling Non-Prepared Plan Cache in TiDB\nDESCRIPTION: Enables the non-prepared plan cache feature using a session variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-non-prepared-plan-cache.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSET @@tidb_enable_non_prepared_plan_cache=ON;\n```\n\n----------------------------------------\n\nTITLE: Defining Django Model for Player in Python\nDESCRIPTION: This snippet defines a Django model class 'Player' with fields for name, coins, goods, and timestamps. It sets up the structure for a player entity in the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom django.db import models\n\nclass Player(models.Model):\n    name = models.CharField(max_length=32, blank=False, null=False)\n    coins = models.IntegerField(default=100)\n    goods = models.IntegerField(default=1)\n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n```\n\n----------------------------------------\n\nTITLE: Using QB_NAME to Define Query Block Names - SQL\nDESCRIPTION: This SQL snippet shows how to use the QB_NAME hint to define a new name for a query block. Specifying QB_NAME can help avoid ambiguities when dealing with complex queries and multiple nested subqueries.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ QB_NAME(QB1) */ * FROM (SELECT * FROM t) t1, (SELECT * FROM t) t2;\n```\n\n----------------------------------------\n\nTITLE: Verifying Vector Index Usage with EXPLAIN in TiDB\nDESCRIPTION: This EXPLAIN query demonstrates how to check if a vector index is being used for a cosine distance search with a LIMIT clause. The presence of 'annIndex:' in the operator info indicates that the vector index is being utilized.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-index.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM vector_table_with_index\nORDER BY VEC_COSINE_DISTANCE(embedding, '[1, 2, 3]')\nLIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Querying Data from Player Model using Django ORM in Python\nDESCRIPTION: This snippet shows how to query data from the Player model using Django ORM. It includes examples of retrieving a single object, filtering objects, and getting all objects.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# get a single object\nplayer = Player.objects.get(name=\"player1\")\n\n# get multiple objects\nfiltered_players = Player.objects.filter(name=\"player1\")\n\n# get all objects\nall_players = Player.objects.all()\n```\n\n----------------------------------------\n\nTITLE: Using Vector Index for KNN Search in TiDB\nDESCRIPTION: Example of performing K-nearest neighbor search query using a vector index with the ORDER BY and LIMIT clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-index.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM foo\nORDER BY VEC_COSINE_DISTANCE(embedding, '[1, 2, 3, 4, 5]')\nLIMIT 10\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed for Replicating to Confluent Cloud\nDESCRIPTION: Command template to create a TiCDC changefeed that replicates incremental data from TiDB to Confluent Cloud using the Avro protocol with appropriate authentication and configuration settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc:v<CLUSTER_VERSION> cli changefeed create --server=\"http://127.0.0.1:8300\" --sink-uri=\"kafka://<broker_endpoint>/ticdc-meta?protocol=avro&replication-factor=3&enable-tls=true&auto-create-topic=true&sasl-mechanism=plain&sasl-user=<broker_api_key>&sasl-password=<broker_api_secret>\" --schema-registry=\"https://<schema_registry_api_key>:<schema_registry_api_secret>@<schema_registry_endpoint>\" --changefeed-id=\"confluent-changefeed\" --config changefeed.conf\n```\n\n----------------------------------------\n\nTITLE: Querying Specific Page Data from Clustered Index Table in SQL\nDESCRIPTION: This SQL query demonstrates how to select all records from a specific page (in this case, page 1) of the 'ratings' table. It uses the start and end keys generated from the paging metadata to define the range of records to be selected.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-paginate-results.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ratings\nWHERE\n    (book_id > 268996 AND book_id < 140982742)\n    OR (\n        book_id = 268996 AND user_id >= 92104804\n    )\n    OR (\n        book_id = 140982742 AND user_id <= 374645100\n    )\nORDER BY book_id, user_id;\n```\n\n----------------------------------------\n\nTITLE: Querying Electric Bike Trips from Bikeshare Database in SQL\nDESCRIPTION: This SQL query selects all columns from the 'trips' table, filtering for electric bikes and limiting the result to 10 records. It demonstrates how to filter data based on a specific condition and limit the output for analysis or display purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-sample-data.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nselect * from `trips` where rideable_type=\"electric_bike\" limit 10;\n```\n\n----------------------------------------\n\nTITLE: Calculating L1 Distance in TiDB SQL\nDESCRIPTION: VEC_L1_DISTANCE function calculates the Manhattan distance between two vectors. The vectors must have the same dimension.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-functions-and-operators.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VEC_L1_DISTANCE('[0,0]', '[3,4]');\n```\n\n----------------------------------------\n\nTITLE: Efficient Table Truncation in SQL\nDESCRIPTION: Example of using TRUNCATE instead of DELETE for removing all data from a table.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql-best-practices.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nTRUNCATE TABLE t;\n```\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM t;\n```\n\n----------------------------------------\n\nTITLE: Backing Up Data from TiDB Cluster\nDESCRIPTION: This SQL snippet performs backup of the entire TiDB database to an S3-compatible storage, securely transferring data from the primary cluster. The command uses cloud storage credentials and outputs metadata including backup size and timestamp.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP DATABASE * TO '`s3://backup?access-key=minio&secret-access-key=miniostorage&endpoint=http://10.0.1.10:6060&force-path-style=true`';\n```\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------+----------+--------------------+---------------------+---------------------+\n| Destination          | Size     | BackupTS           | Queue Time          | Execution Time      |\n+----------------------+----------+--------------------+---------------------+---------------------+\n| s3://backup          | 10315858 | 431434047157698561 | 2022-02-25 19:57:59 | 2022-02-25 19:57:59 |\n+----------------------+----------+--------------------+---------------------+---------------------+\n1 row in set (2.11 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting Session Level Configuration for TiDB Transactions - SQL\nDESCRIPTION: This snippet demonstrates how to enable automatic retry and set the retry limit at the session level for TiDB transactions. It is crucial for handling transient errors during optimistic transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimistic-transaction.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_disable_txn_auto_retry = OFF;\nSET tidb_retry_limit = 10;\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into TiDB with Ruby\nDESCRIPTION: Ruby function to insert a new player record into the database with coins and goods values, returning the auto-generated ID of the inserted record.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_9\n\nLANGUAGE: ruby\nCODE:\n```\ndef create_player(client, coins, goods)\n  result = client.query(\n    \"INSERT INTO players (coins, goods) VALUES (#{coins}, #{goods});\"\n  )\n  client.last_id\nend\n```\n\n----------------------------------------\n\nTITLE: Configuring Bidirectional Replication Mode in TiCDC\nDESCRIPTION: TOML configuration to enable bidirectional replication mode in TiCDC. This configuration should be added to the config file specified by the --config parameter when creating a changefeed.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-bidirectional-replication.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n# Whether to enable the bi-directional replication mode\nbdr-mode = true\n```\n\n----------------------------------------\n\nTITLE: Enabling the non-prepared plan cache in TiDB\nDESCRIPTION: This SQL snippet sets the `tidb_enable_non_prepared_plan_cache` system variable to `ON`, which enables the non-prepared plan cache for the current session.  Enabling this cache allows TiDB to reuse execution plans for non-prepared statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-non-prepared-plan-cache.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_enable_non_prepared_plan_cache = ON;\n```\n\n----------------------------------------\n\nTITLE: Performing TiDB Point-in-Time Recovery\nDESCRIPTION: Restores the cluster to a specific point in time using both snapshot and log backup data from S3 storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-guide.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore point --pd \"${PD_IP}:2379\" \\\n--storage='s3://backup-101/logbackup?access-key=${access-key}&secret-access-key=${secret-access-key}' \\\n--full-backup-storage='s3://backup-101/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}' \\\n--restored-ts '2022-05-15 18:00:00+0800'\n```\n\n----------------------------------------\n\nTITLE: Displaying TiDB Cluster Status\nDESCRIPTION: Command to view the status of all components in a TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/maintain-tidb-using-tiup.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster display ${cluster-name}\n```\n\n----------------------------------------\n\nTITLE: Sample CSV Data for TiDB Import\nDESCRIPTION: Example CSV file structure containing product data with headers and three sample records. This file format includes product_id, product_name, and price columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-with-mysql-cli.md#2025-04-18_snippet_2\n\nLANGUAGE: csv\nCODE:\n```\nproduct_id,product_name,price\n4,Laptop,999.99\n5,Smartphone,499.99\n6,Tablet,299.99\n```\n\n----------------------------------------\n\nTITLE: Describing TIDB_HOT_REGIONS_HISTORY Table Schema in SQL\nDESCRIPTION: This SQL query describes the schema of the TIDB_HOT_REGIONS_HISTORY table in the information_schema database, showing all fields and their data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-hot-regions-history.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC tidb_hot_regions_history;\n```\n\n----------------------------------------\n\nTITLE: SQL EXPLAIN for Point_Get and Batch_Point_Get Operators\nDESCRIPTION: These SQL statements, along with their corresponding EXPLAIN outputs, demonstrate how TiDB uses the `Point_Get` and `Batch_Point_Get` operators for retrieving data directly using a primary key (`id`) or a unique key (`unique_key`). The `ALTER TABLE` and `UPDATE` commands create the unique key.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-indexes.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t1 WHERE id = 1234;\nEXPLAIN SELECT * FROM t1 WHERE id IN (1234,123);\n\nALTER TABLE t1 ADD unique_key INT;\nUPDATE t1 SET unique_key = id;\nALTER TABLE t1 ADD UNIQUE KEY (unique_key);\n\nEXPLAIN SELECT * FROM t1 WHERE unique_key = 1234;\nEXPLAIN SELECT * FROM t1 WHERE unique_key IN (1234, 123);\n```\n\n----------------------------------------\n\nTITLE: Querying Specific Variable by Name\nDESCRIPTION: SQL example showing how to query a specific variable (tidb_window_concurrency) using SHOW VARIABLES with a WHERE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-variables.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW VARIABLES WHERE Variable_name=\"tidb_window_concurrency\";\n```\n\n----------------------------------------\n\nTITLE: TiDB System Variables Documentation Links\nDESCRIPTION: A collection of system variables and their references in TiDB documentation, covering memory management, optimization, query processing, and other configuration options.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variable-reference.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### tidb_max_paging_size\n\nReferenced in:\n\n- [System Variables](/system-variables.md#tidb_max_paging_size-new-in-v630)\n- [TiDB 6.3.0 Release Notes](/releases/release-6.3.0.md)\n```\n\n----------------------------------------\n\nTITLE: Restoring TiDB Full Backup Data\nDESCRIPTION: Command to perform a full restore of the specified backup data in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-use-overview.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup br restore\n```\n\n----------------------------------------\n\nTITLE: Analyzing Timestamp Acquisition Time in TiDB Slow Query Log\nDESCRIPTION: This slow query log snippet shows the Query_time and Wait_TS fields, which can be compared to determine if getting timestamps is causing query slowdown in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\n# Query_time: 0.0300000\n...\n# Wait_TS: 0.02500000\n```\n\n----------------------------------------\n\nTITLE: Generating Fibonacci Numbers Using Recursive CTE in SQL\nDESCRIPTION: This SQL snippet demonstrates how to use a recursive CTE to generate a sequence of Fibonacci numbers up to the 10th number in the sequence.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-common-table-expression.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nWITH RECURSIVE fibonacci (n, fib_n, next_fib_n) AS\n(\n  SELECT 1, 0, 1\n  UNION ALL\n  SELECT n + 1, next_fib_n, fib_n + next_fib_n FROM fibonacci WHERE n < 10\n)\nSELECT * FROM fibonacci;\n```\n\n----------------------------------------\n\nTITLE: Updating Data in Player Model using Django ORM in Python\nDESCRIPTION: This snippet demonstrates how to update data in the Player model using Django ORM. It shows both updating a single object and updating multiple objects that match a filter condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# update a single object\nplayer = Player.objects.get(name=\"player1\")\nplayer.coins = 200\nplayer.save()\n\n# update multiple objects\nPlayer.objects.filter(coins=100).update(coins=200)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Union-Type Index Merge in TiDB\nDESCRIPTION: Shows two query execution plans: one without index merge (using NO_INDEX_MERGE hint) and one with index merge (using USE_INDEX_MERGE hint) for OR conditions. The second plan demonstrates a union-type index merge that combines results from multiple indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-index-merge.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ NO_INDEX_MERGE() */ * FROM t WHERE a = 1 OR b = 1;\n\n+-------------------------+----------+-----------+---------------+--------------------------------------+\n| id                      | estRows  | task      | access object | operator info                        |\n+-------------------------+----------+-----------+---------------+--------------------------------------+\n| TableReader_7           | 19.99    | root      |               | data:Selection_6                     |\n| └─Selection_6           | 19.99    | cop[tikv] |               | or(eq(test.t.a, 1), eq(test.t.b, 1)) |\n|   └─TableFullScan_5     | 10000.00 | cop[tikv] | table:t       | keep order:false, stats:pseudo       |\n+-------------------------+----------+-----------+---------------+--------------------------------------+\nEXPLAIN SELECT /*+ USE_INDEX_MERGE(t) */ * FROM t WHERE a > 1 OR b > 1;\n+-------------------------------+---------+-----------+-------------------------+------------------------------------------------+\n| id                            | estRows | task      | access object           | operator info                                  |\n+-------------------------------+---------+-----------+-------------------------+------------------------------------------------+\n| IndexMerge_8                  | 5555.56 | root      |                         | type: union                                    |\n| ├─IndexRangeScan_5(Build)     | 3333.33 | cop[tikv] | table:t, index:idx_a(a) | range:(1,+inf], keep order:false, stats:pseudo |\n| ├─IndexRangeScan_6(Build)     | 3333.33 | cop[tikv] | table:t, index:idx_b(b) | range:(1,+inf], keep order:false, stats:pseudo |\n| └─TableRowIDScan_7(Probe)     | 5555.56 | cop[tikv] | table:t                 | keep order:false, stats:pseudo                 |\n+-------------------------------+---------+-----------+-------------------------+------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Displaying Auto-Analyze Variables in TiDB\nDESCRIPTION: This SQL query shows the values of TiDB's auto-analyze related system variables, which control automatic statistics collection.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW VARIABLES LIKE 'tidb\\_auto\\_analyze%';\n```\n\n----------------------------------------\n\nTITLE: Updating a View in TiDB SQL\nDESCRIPTION: This snippet demonstrates how to update an existing view in TiDB using the CREATE OR REPLACE VIEW statement. It modifies the book_with_ratings view to include the published_at column.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-views.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE OR REPLACE VIEW book_with_ratings AS\nSELECT b.id AS book_id, ANY_VALUE(b.title), ANY_VALUE(b.published_at) AS book_title, AVG(r.score) AS average_score\nFROM books b\nLEFT JOIN ratings r ON b.id = r.book_id\nGROUP BY b.id;\n```\n\n----------------------------------------\n\nTITLE: Executing Non-Transactional Bulk Delete in TiDB\nDESCRIPTION: This SQL statement demonstrates how to perform a non-transactional bulk delete operation on the 'ratings' table in TiDB. It uses the BATCH ON syntax to delete records within a specific time range in batches of 1000 rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-delete-data.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nBATCH ON `rated_at` LIMIT 1000 DELETE FROM `ratings` WHERE `rated_at` >= \"2022-04-15 00:00:00\" AND  `rated_at` <= \"2022-04-15 00:15:00\";\n```\n\n----------------------------------------\n\nTITLE: Transaction Thread Configuration and Execution in Python\nDESCRIPTION: Sets up and executes concurrent purchase transactions using threads. Configures transaction type (optimistic/pessimistic) and handles multiple simultaneous purchase attempts.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\noptimistic = os.environ.get('OPTIMISTIC')\nalice = os.environ.get('ALICE')\nbob = os.environ.get('BOB')\n\nif not (optimistic and alice and bob):\n    raise Exception(\"please use \\\"OPTIMISTIC=<is_optimistic> ALICE=<alice_num> \"\n                    \"BOB=<bob_num> python3 txn_example.py\\\" to start this script\")\n\nprepare_data()\n\nif bool(optimistic) is True:\n    buy_func = buy_optimistic\nelse:\n    buy_func = buy_pessimistic\n\nbob_thread = Thread(target=buy_func, kwargs={\n    \"thread_id\": 1, \"order_id\": 1000, \"book_id\": 1, \"user_id\": 1, \"amount\": int(bob)})\nalice_thread = Thread(target=buy_func, kwargs={\n    \"thread_id\": 2, \"order_id\": 1001, \"book_id\": 1, \"user_id\": 2, \"amount\": int(alice)})\n\nbob_thread.start()\nalice_thread.start()\nbob_thread.join(timeout=10)\nalice_thread.join(timeout=10)\n```\n\n----------------------------------------\n\nTITLE: Collecting Index Statistics on Table Partitions in TiDB\nDESCRIPTION: SQL syntax for collecting index statistics on specific partitions of a table. The PartitionNameList specifies which partitions to analyze, and IndexNameList specifies which indexes to analyze.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE TableName PARTITION PartitionNameList INDEX [IndexNameList] [WITH NUM BUCKETS|TOPN|CMSKETCH DEPTH|CMSKETCH WIDTH]|[WITH NUM SAMPLES|WITH FLOATNUM SAMPLERATE];\n```\n\n----------------------------------------\n\nTITLE: Filtering Results After Vector Search in TiDB\nDESCRIPTION: Example of using vector index with filters by first querying for K-Nearest neighbors and then applying the filter condition to maintain index usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-index.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n-- For the following query, the `WHERE` filter is performed after KNN, so the vector index cannot be used:\n\nSELECT * FROM\n(\n  SELECT * FROM vec_table\n  ORDER BY VEC_COSINE_DISTANCE(embedding, '[1, 2, 3]')\n  LIMIT 5\n) t\nWHERE category = \"document\";\n\n-- Note that this query might return fewer than 5 results if some are filtered out.\n```\n\n----------------------------------------\n\nTITLE: Reorganizing Partitions in SQL\nDESCRIPTION: SQL statements to split, merge, and reorganize partitions in RANGE and LIST partitioned tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_39\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE members REORGANIZE PARTITION `p1990to2010` INTO\n(PARTITION p1990 VALUES LESS THAN (2000),\n PARTITION p2000 VALUES LESS THAN (2010),\n PARTITION p2010 VALUES LESS THAN (2020),\n PARTITION p2020 VALUES LESS THAN (2030),\n PARTITION pMax VALUES LESS THAN (MAXVALUE));\n\nALTER TABLE member_level REORGANIZE PARTITION l5_6 INTO\n(PARTITION l5 VALUES IN (5),\n PARTITION l6 VALUES IN (6));\n\nALTER TABLE members REORGANIZE PARTITION pBefore1950,p1950 INTO (PARTITION pBefore1960 VALUES LESS THAN (1960));\n\nALTER TABLE member_level REORGANIZE PARTITION l1,l2 INTO (PARTITION l1_2 VALUES IN (1,2));\n\nALTER TABLE members REORGANIZE PARTITION pBefore1960,p1960,p1970,p1980,p1990,p2000,p2010,p2020,pMax INTO\n(PARTITION p1800 VALUES LESS THAN (1900),\n PARTITION p1900 VALUES LESS THAN (2000),\n PARTITION p2000 VALUES LESS THAN (2100));\n\nALTER TABLE member_level REORGANIZE PARTITION l1_2,l3,l4,l5,l6 INTO\n(PARTITION lOdd VALUES IN (1,3,5),\n PARTITION lEven VALUES IN (2,4,6));\n```\n\n----------------------------------------\n\nTITLE: Viewing TiDB Cluster List\nDESCRIPTION: This snippet shows the command to view the list of TiDB clusters that have been deployed using TiUP. The output will display relevant information about each cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster list\n```\n\nLANGUAGE: bash\nCODE:\n```\nStarting /root/.tiup/components/cluster/v1.12.3/cluster list\nName          User  Version    Path                                               PrivateKey\n----          ----  -------    ----                                               ----------\nprod-cluster  tidb  v8.5.0    /root/.tiup/storage/cluster/clusters/prod-cluster  /root/.tiup/storage/cluster/clusters/prod-cluster/ssh/id_rsa\n```\n\n----------------------------------------\n\nTITLE: Setting All Roles as Default for a User in TiDB\nDESCRIPTION: This snippet demonstrates how to set all roles granted to a user as their default roles using the `SET DEFAULT ROLE ALL` statement. When `dev1@localhost` logs in, all roles granted to them will be automatically enabled. You need to grant the role to the user before setting the default role.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSET DEFAULT ROLE ALL TO 'dev1'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Explaining Index Merge with Multi-column Indexes\nDESCRIPTION: This SQL snippet illustrates the use of Index Merge on tables with multi-column indexes in TiDB. It demonstrates how TiDB utilizes such indexes to optimize queries with nested `OR` and `AND` conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t5, idx, idx2) */ * FROM t5 WHERE (a=1 AND 1 member of (j)) OR (b=2 AND 2 member of (k));\n```\n\n----------------------------------------\n\nTITLE: Creating Parent and Child Tables with Foreign Key in SQL\nDESCRIPTION: This SQL code creates two tables, 'parent' and 'child', in the 'test' database. The 'child' table has a foreign key constraint referencing the 'id' column in the 'parent' table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-referential-constraints.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE test.parent (\n  id INT NOT NULL AUTO_INCREMENT,\n  PRIMARY KEY (id)\n);\n\nCREATE TABLE test.child (\n  id INT NOT NULL AUTO_INCREMENT,\n  name varchar(255) NOT NULL,\n  parent_id INT DEFAULT NULL,\n  PRIMARY KEY (id),\n  CONSTRAINT fk_parent FOREIGN KEY (parent_id) REFERENCES parent (id) ON UPDATE CASCADE ON DELETE RESTRICT\n);\n```\n\n----------------------------------------\n\nTITLE: PD Microservice Topology Configuration\nDESCRIPTION: This YAML configuration file provides a simple template for deploying a PD microservice topology using TiUP. It defines global settings, and configurations for PD, TiDB, TiKV, TSO, Scheduling, Prometheus, and Grafana servers, including specifying the `pd_mode` as `ms` to enable PD microservices. The host configurations use IP addresses to specify the server locations.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-microservices-deployment-topology.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n```yaml\n# # Global variables are applied to all deployments and used as the default value of\n# # the deployments if a specific deployment value is missing.\nglobal:\n  user: \"tidb\"\n  ssh_port: 22\n  deploy_dir: \"/tidb-deploy\"\n  data_dir: \"/tidb-data\"\n  listen_host: 0.0.0.0\n  arch: \"amd64\"\n  pd_mode: \"ms\" # To enable PD microservices, you must specify this field as \"ms\".\n\nmonitored:\n  node_exporter_port: 9200\n  blackbox_exporter_port: 9215\n\n# # Specifies the configuration of PD servers.\npd_servers:\n  - host: 10.0.1.3\n  - host: 10.0.1.4\n  - host: 10.0.1.5\n\n# # Specifies the configuration of TiDB servers.\ntidb_servers:\n  - host: 10.0.1.1\n  - host: 10.0.1.2\n\n# # Specifies the configuration of TiKV servers.\ntikv_servers:\n  - host: 10.0.1.10\n  - host: 10.0.1.11\n  - host: 10.0.1.12\n\n# # Specifies the configuration of TSO servers.\ntso_servers:\n  - host: 10.0.1.6\n  - host: 10.0.1.7\n\n# # Specifies the configuration of Scheduling servers.\nscheduling_servers:\n  - host: 10.0.1.8\n  - host: 10.0.1.9\n\n# # Specifies the configuration of Prometheus servers.\nmonitoring_servers:\n  - host: 10.0.1.13\n\n# # Specifies the configuration of Grafana servers.\ngrafana_servers:\n  - host: 10.0.1.13\n```\n```\n\n----------------------------------------\n\nTITLE: Restoring Full Backup to New Cluster\nDESCRIPTION: Restore the full backup to the newly deployed cluster, including system tables\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup br:${cluster_version} restore full --pd ${pd_host}:${pd_port} -s ${backup_location} --with-sys-table\n```\n\n----------------------------------------\n\nTITLE: Compacting Full Table in TiFlash\nDESCRIPTION: SQL statement to compact an entire table's TiFlash replica. This process rewrites physical data to clean up deleted rows and merge multiple versions of updated data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE employees COMPACT TIFLASH REPLICA;\n```\n\n----------------------------------------\n\nTITLE: SQL Query with CAST Function Fix\nDESCRIPTION: Fixed incorrect query results when casting negative numbers to CHAR type using SELECT CAST statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.7.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CAST(n AS CHAR)\n```\n\n----------------------------------------\n\nTITLE: Explain AVG and ANY_VALUE query with TableFullScan in TiDB\nDESCRIPTION: This SQL statement shows a scenario where `IndexFullScan` cannot be used because the query requires additional columns (`pad1`) from the table. The `EXPLAIN` statement reveals that `TableFullScan` is used instead, as the `ANY_VALUE(pad1)` function requires accessing the `pad1` column, which is not part of the `intkey` index.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-indexes.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT AVG(intkey), ANY_VALUE(pad1) FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Illustrating SQL Logical Operators\nDESCRIPTION: This snippet demonstrates the usage of logical operators in SQL, including AND, OR, NOT, and XOR. These operators are used to combine or negate conditions in SQL queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/operators.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM table WHERE condition1 AND condition2;\nSELECT * FROM table WHERE condition1 OR condition2;\nSELECT * FROM table WHERE NOT condition;\nSELECT * FROM table WHERE condition1 XOR condition2;\n```\n\n----------------------------------------\n\nTITLE: Viewing Execution Plans for Foreign Keys with EXPLAIN in SQL\nDESCRIPTION: Uses the EXPLAIN statement in SQL to show execution plans for DML statements involving foreign key constraint checks. This example showcases how to view the detailed plan for an INSERT operation affecting foreign key constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain insert into child values (1,1);\n+-----------------------+---------+------+---------------+-------------------------------+\n| id                    | estRows | task | access object | operator info                 |\n+-----------------------+---------+------+---------------+-------------------------------+\n| Insert_1              | N/A     | root |               | N/A                           |\n| └─Foreign_Key_Check_3 | 0.00    | root | table:parent  | foreign_key:fk_1, check_exist |\n+-----------------------+---------+------+---------------+-------------------------------+\n\n```\n\n----------------------------------------\n\nTITLE: Checking Data Analysis Status with TiDB Cloud API in Bash\nDESCRIPTION: Example of calling the /v2/jobs/{job_id} endpoint to check the status of a database analysis job. This request requires the job ID returned from the previous data summary generation step.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user ${PUBLIC_KEY}:${PRIVATE_KEY} --request GET 'https://<region>.data.dev.tidbcloud.com/api/v1beta/app/chat2query-<ID>`/endpoint/v2/jobs/{job_id}'\\\n --header 'content-type: application/json'\n```\n\n----------------------------------------\n\nTITLE: TiDB ADMIN PLUGINS Management\nDESCRIPTION: SQL statements for enabling and disabling TiDB plugins.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nADMIN PLUGINS ENABLE plugin_name [, plugin_name] ...;\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN PLUGINS DISABLE plugin_name [, plugin_name] ...;\n```\n\n----------------------------------------\n\nTITLE: Collecting Statistics on Predicate Columns in TiDB\nDESCRIPTION: SQL syntax for collecting statistics on predicate columns (columns used in WHERE, JOIN, ORDER BY, GROUP BY). This syntax also collects statistics on indexed columns and all indexes in the table.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE TableName PREDICATE COLUMNS [WITH NUM BUCKETS|TOPN|CMSKETCH DEPTH|CMSKETCH WIDTH]|[WITH NUM SAMPLES|WITH FLOATNUM SAMPLERATE];\n```\n\n----------------------------------------\n\nTITLE: Analyzing Table and Rechecking Status in SQL\nDESCRIPTION: This SQL snippet shows how to analyze a table using the ANALYZE TABLE command followed by a second execution of the SHOW TABLE STATUS command to observe any changes in the table's statistics after running the analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-status.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nmysql> ANALYZE TABLE t1;\nQuery OK, 0 rows affected (0.12 sec)\n\nmysql> SHOW TABLE STATUS LIKE 't1'\\G\n*************************** 1. row ***************************\n           Name: t1\n         Engine: InnoDB\n        Version: 10\n     Row_format: Compact\n           Rows: 5\n Avg_row_length: 16\n    Data_length: 80\nMax_data_length: 0\n   Index_length: 0\n      Data_free: 0\n Auto_increment: 30001\n    Create_time: 2019-04-19 08:32:06\n    Update_time: NULL\n     Check_time: NULL\n      Collation: utf8mb4_bin\n       Checksum:\n Create_options:\n        Comment:\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Backing Up Data in TiDB\nDESCRIPTION: This SQL command performs a backup of the upstream database to a specified S3-compatible storage, with a defined rate limit to mitigate performance impact during the backup process.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nMySQL [(none)]> BACKUP DATABASE * TO 's3://backup?access-key=minio&secret-access-key=miniostorage&endpoint=http://${HOST_IP}:6060&force-path-style=true' RATE_LIMIT = 120 MB/SECOND;\n\n```\n+---------------+----------+--------------------+---------------------+---------------------+\n| Destination   | Size     | BackupTS           | Queue Time          | Execution Time      |\n+---------------+----------+--------------------+---------------------+---------------------+\n| s3://backup   | 10315858 | 431434047157698561 | 2022-02-25 19:57:59 | 2022-02-25 19:57:59 |\n+---------------+----------+--------------------+---------------------+---------------------+\n1 row in set (2.11 sec)\n```\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with Errors using SQL\nDESCRIPTION: Prepares data with intentional errors like NULL values in NOT NULL columns, duplicate primary keys and unique values, values exceeding column length, and values overflowing TINYINT. This SQL script is used as input for TiDB Lightning.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n\"cat <<EOF > example.t.1.sql\\n\\n        INSERT INTO t (a, b) VALUES\\n        (0, NULL),              -- column is NOT NULL\\n        (1, 'one'),\\n        (2, 'two'),\\n        (40, 'forty'),          -- conflicts with the other 40 below\\n        (54, 'fifty-four'),     -- conflicts with the other 'fifty-four' below\\n        (77, 'seventy-seven'),  -- the string is longer than 12 characters\\n        (600, 'six hundred'),   -- the number overflows TINYINT\\n        (40, 'forty'),         -- conflicts with the other 40 above\\n        (42, 'fifty-four');     -- conflicts with the other 'fifty-four' above\\n\\n    EOF\"\n```\n\n----------------------------------------\n\nTITLE: Initializing TiDB Test Tables\nDESCRIPTION: SQL commands to create and populate test tables in both TiDB instances with identifying data.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\nmysql -u root -h 127.0.0.1 -P 4001 << EOF\nDROP TABLE IF EXISTS test.tidb_server;\nCREATE TABLE test.tidb_server (server_name VARCHAR(255));\nINSERT INTO test.tidb_server (server_name) VALUES ('tidb-server01-port-4001');\nEOF\n\nmysql -u root -h 127.0.0.1 -P 4002 << EOF\nDROP TABLE IF EXISTS test.tidb_server;\nCREATE TABLE test.tidb_server (server_name VARCHAR(255));\nINSERT INTO test.tidb_server (server_name) VALUES ('tidb-server02-port-4002');\nEOF\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_plan_replayer_capture in TiDB\nDESCRIPTION: Enables the PLAN REPLAYER CAPTURE feature, allowing for plan replaying. Default ON allows capturing for performance analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_40\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): No\n- Type: Boolean\n- Default value: `ON`\n- This variable controls whether to enable the `PLAN REPLAYER CAPTURE` feature.\n```\n\n----------------------------------------\n\nTITLE: Creating Documents with Vector Embeddings\nDESCRIPTION: Code to create document records with vector embeddings in TiDB using Django ORM.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nDocument.objects.create(content=\"dog\", embedding=[1, 2, 1])\nDocument.objects.create(content=\"fish\", embedding=[1, 2, 4])\nDocument.objects.create(content=\"tree\", embedding=[1, 0, 0])\n```\n\n----------------------------------------\n\nTITLE: Lock Tables Definition Syntax\nDESCRIPTION: This code snippet shows the syntax for the `LOCK TABLES` and `UNLOCK TABLES` statements in TiDB using EBNF notation. It defines the structure for locking and unlocking tables, including the specification of table names and lock types (READ or WRITE).\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-lock-tables-and-unlock-tables.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\n\"LockTablesDef\\n         ::= 'LOCK' ( 'TABLES' | 'TABLE' ) TableName LockType ( ',' TableName LockType)*\\n\\n\\nUnlockTablesDef\\n         ::= 'UNLOCK' 'TABLES'\\n\\nLockType\\n         ::= 'READ' ('LOCAL')?\\n           | 'WRITE' ('LOCAL')?\"\n```\n\n----------------------------------------\n\nTITLE: Creating Tables and Explaining a Query with a Subquery in TiDB\nDESCRIPTION: Example of creating two tables, inserting data, and using EXPLAIN to show how TiDB pre-executes subqueries by default during optimization.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1(a int);\nINSERT INTO t1 VALUES(1);\nCREATE TABLE t2(a int);\nEXPLAIN SELECT * FROM t2 WHERE a = (SELECT a FROM t1);\n```\n\n----------------------------------------\n\nTITLE: Creating and Removing SQL Plan Binding Using SQL Statement in TiDB\nDESCRIPTION: This snippet demonstrates creating a table, inserting data, creating a session binding, and then removing it using the SQL statement. It shows the impact on query execution plans before and after applying the binding.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-binding.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n  id INT NOT NULL PRIMARY KEY auto_increment,\n  b INT NOT NULL,\n  pad VARBINARY(255),\n  INDEX(b)\n);\n\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM dual;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\n\nANALYZE TABLE t1;\n\nEXPLAIN ANALYZE SELECT * FROM t1 WHERE b = 123;\n\nCREATE SESSION BINDING FOR\n  SELECT * FROM t1 WHERE b = 123\n USING\n  SELECT * FROM t1 IGNORE INDEX (b) WHERE b = 123;\n\nEXPLAIN ANALYZE SELECT * FROM t1 WHERE b = 123;\n\nSHOW SESSION BINDINGS\\G\n\nDROP SESSION BINDING FOR SELECT * FROM t1 WHERE b = 123;\n\nEXPLAIN ANALYZE SELECT * FROM t1 WHERE b = 123;\n\nSHOW SESSION BINDINGS\\G\n```\n\n----------------------------------------\n\nTITLE: Disabling Optimization Rules in TiDB\nDESCRIPTION: SQL commands to disable specific optimization rules by inserting them into the mysql.opt_rule_blacklist table and reloading the configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/blocklist-control-plan.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO mysql.opt_rule_blacklist VALUES(\"join_reorder\"), (\"topn_push_down\");\n```\n\n----------------------------------------\n\nTITLE: Scaling In TiDB Cluster to Remove PD Microservice Nodes\nDESCRIPTION: This command removes specified PD microservice nodes from the TiDB cluster using TiUP. It's part of the process to switch from microservices mode to regular mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster scale-in <cluster-name> --node 10.0.1.8:3379,10.0.1.9:3379\n```\n\n----------------------------------------\n\nTITLE: Showing All Configurations\nDESCRIPTION: This SQL statement shows how to display all configurations of the TiDB components. It retrieves and displays all the configuration parameters and their corresponding values from the TiDB system.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-config.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"SHOW CONFIG;\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Skyline-Pruning in TiDB SQL\nDESCRIPTION: This example shows how skyline-pruning works in TiDB by creating a table with multiple indexes and examining which indexes remain after pruning when querying with specific conditions. The query results show that indexes idx_b and idx_e are excluded by skyline-pruning in favor of idx_b_c.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t(a INT PRIMARY KEY, b INT, c INT, d INT, e INT, INDEX idx_b(b), INDEX idx_b_c(b, c), INDEX idx_e(e));\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> EXPLAIN FORMAT = 'verbose' SELECT * FROM t WHERE b = 2 AND c > 4;\n+-------------------------------+---------+---------+-----------+------------------------------+----------------------------------------------------+\n| id                            | estRows | estCost | task      | access object                | operator info                                      |\n+-------------------------------+---------+---------+-----------+------------------------------+----------------------------------------------------+\n| IndexLookUp_10                | 33.33   | 738.29  | root      |                              |                                                    |\n| ├─IndexRangeScan_8(Build)     | 33.33   | 2370.00 | cop[tikv] | table:t, index:idx_b_c(b, c) | range:(2 4,2 +inf], keep order:false, stats:pseudo |\n| └─TableRowIDScan_9(Probe)     | 33.33   | 2370.00 | cop[tikv] | table:t                      | keep order:false, stats:pseudo                     |\n+-------------------------------+---------+---------+-----------+------------------------------+----------------------------------------------------+\n3 rows in set, 1 warning (0.00 sec)\n\nmysql> SHOW WARNINGS;\n+-------+------+------------------------------------------------------------------------------------------+\n| Level | Code | Message                                                                                  |\n+-------+------+------------------------------------------------------------------------------------------+\n| Note  | 1105 | [t,idx_b_c] remain after pruning paths for t given Prop{SortItems: [], TaskTp: rootTask} |\n+-------+------+------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Loading Data into TiDB using LOAD DATA statement\nDESCRIPTION: This SQL code demonstrates how to use the `LOAD DATA` statement in TiDB to import data from a local file into an existing table. It specifies the table schema and the fields to be imported.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-import-local-files.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE TABLE `import_test` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(64) NOT NULL,\n  `address` varchar(64) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\nLOAD DATA LOCAL INFILE 'load.txt' INTO TABLE import_test FIELDS TERMINATED BY ',' (name, address);\"\n```\n\n----------------------------------------\n\nTITLE: Using MPP_2PHASE_AGG Hint for MPP Mode Aggregation in SQL\nDESCRIPTION: Uses the MPP_2PHASE_AGG hint to force the optimizer to use the two-phase aggregation algorithm in MPP mode. This hint only takes effect when using TiFlash MPP mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ MPP_2PHASE_AGG() */ COUNT(*) FROM t1, t2 WHERE t1.a > 10 GROUP BY t1.id;\n```\n\n----------------------------------------\n\nTITLE: Performing Point-in-Time Recovery for TiDB\nDESCRIPTION: Command to restore TiDB data to any specific time point within the backup retention period, using both full and log backups.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-use-overview.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntiup br restore point\n```\n\n----------------------------------------\n\nTITLE: Configuring TiProxy and TiDB Servers for Label-based Load Balancing in YAML\nDESCRIPTION: This YAML configuration demonstrates how to set up TiProxy and TiDB servers for label-based load balancing, including component versions, server configurations, and labels for resource isolation between transaction and BI workloads.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-load-balance.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ncomponent_versions:\n  tiproxy: \"v1.1.0\"\n\nserver_configs:\n  tiproxy:\n    balance.label-name: \"app\"\n  tidb:\n    graceful-wait-before-shutdown: 15\n\ntiproxy_servers:\n  - host: tiproxy-host-1\n    config:\n      labels: {\"app\": \"Order\"}\n      ha.virtual-ip: \"10.0.1.10/24\"\n      ha.interface: \"eth0\"\n  - host: tiproxy-host-2\n    config:\n      labels: {\"app\": \"Order\"}\n      ha.virtual-ip: \"10.0.1.10/24\"\n      ha.interface: \"eth0\"\n  - host: tiproxy-host-3\n    config:\n      labels: {\"app\": \"BI\"}\n      ha.virtual-ip: \"10.0.1.20/24\"\n      ha.interface: \"eth0\"\n  - host: tiproxy-host-4\n    config:\n      labels: {\"app\": \"BI\"}\n      ha.virtual-ip: \"10.0.1.20/24\"\n      ha.interface: \"eth0\"\n\ntidb_servers:\n  - host: tidb-host-1\n    config:\n      labels: {\"app\": \"Order\"}\n  - host: tidb-host-2\n    config:\n      labels: {\"app\": \"Order\"}\n  - host: tidb-host-3\n    config:\n      labels: {\"app\": \"BI\"}\n  - host: tidb-host-4\n    config:\n      labels: {\"app\": \"BI\"}\n\ntikv_servers:\n  - host: tikv-host-1\n  - host: tikv-host-2\n  - host: tikv-host-3\n\npd_servers:\n  - host: pd-host-1\n  - host: pd-host-2\n  - host: pd-host-3\n```\n\n----------------------------------------\n\nTITLE: Using the `cluster` command to show cluster information\nDESCRIPTION: This example shows how to use the `cluster` command to retrieve the basic information of the TiDB cluster. This returns a JSON object containing the cluster ID and maximum peer count.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n>> cluster                                     // To show the cluster information\n{\n  \"id\": 6493707687106161130,\n  \"max_peer_count\": 3\n}\n```\n\n----------------------------------------\n\nTITLE: Triggering Table Rebalancing - TiCDC - Shell\nDESCRIPTION: This example demonstrates how to manually trigger the load balancing of all tables within a specific replication task, identified by its `changefeed_id`, using a POST request.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://127.0.0.1:8300/api/v1/changefeeds/test1/tables/rebalance_table\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with MySQL Client Using TLS\nDESCRIPTION: Command for connecting to a TiDB server using the MySQL client with TLS certificates. This specifies the paths to the client certificate, client key, and CA certificate for secure authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/certificate-authentication.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nmysql -utest -h0.0.0.0 -P4000 --ssl-cert /path/to/client-cert.new.pem --ssl-key /path/to/client-key.new.pem --ssl-ca /path/to/ca-cert.pem\n```\n\n----------------------------------------\n\nTITLE: Updating Player Data with Prisma in JavaScript\nDESCRIPTION: This snippet demonstrates how to update an existing Player record using Prisma's update method. It increments the coins and goods fields for the Player with ID 101.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_11\n\nLANGUAGE: javascript\nCODE:\n```\nawait prisma.player.update({\n   where: {\n      id: 101,\n   },\n   data: {\n      coins: {\n         increment: 50,\n      },\n      goods: {\n         increment: 50,\n      },\n   }\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring TiProxy HA with YAML\nDESCRIPTION: This YAML configuration outlines high availability settings for TiProxy, focusing on network interface bindings and virtual IP allocations. It is used to ensure continuous connectivity by dynamically binding virtual IPs to available TiProxy instances. The configuration requires permissions to bind IP addresses and only works on Linux.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-configuration.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  tiproxy:\n    ha.virtual-ip: \"10.0.1.10/24\"\n    ha.interface: \"eth0\"\n```\n\n----------------------------------------\n\nTITLE: Setting Default Value for Column in SQL\nDESCRIPTION: Creates a 'ratings' table with a default value for the 'rated_at' column using the NOW() function.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `bookshop`.`ratings` (\n  `book_id` bigint,\n  `user_id` bigint,\n  `score` tinyint,\n  `rated_at` datetime DEFAULT NOW(),\n  PRIMARY KEY (`book_id`,`user_id`) CLUSTERED\n);\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP Cluster Template Command in Shell\nDESCRIPTION: The basic syntax for running the tiup cluster template command. This command outputs a default topology template containing 3 PD, 3 TiKV, 3 TiDB, 2 TiFlash, and monitoring instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-template.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster template [flags]\n```\n\n----------------------------------------\n\nTITLE: Displaying TiDB Dashboard Location Using TiUP\nDESCRIPTION: Command to view the address of the PD instance running TiDB Dashboard using the TiUP deployment tool. Requires TiUP Cluster v1.0.3 or later.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-security.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster display CLUSTER_NAME --dashboard\n```\n\n----------------------------------------\n\nTITLE: Querying Expensive Queries from TiDB Logs\nDESCRIPTION: SQL query to retrieve expensive query warnings from the TiDB cluster log, filtering for specific time ranges and warning patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-diagnostics-usage.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.cluster_log WHERE type='tidb' AND time >= '2020-03-08 01:46:30' AND time < '2020-03-08 01:51:30' AND level = 'warn' AND message LIKE '%expensive_query%'\\G\n```\n\n----------------------------------------\n\nTITLE: Configuring Auto Analyze in TiDB SQL\nDESCRIPTION: SQL commands to configure automatic statistics collection in TiDB. These settings adjust the threshold for auto analyze, set the time window for execution, and can help maintain more accurate statistics for query optimization.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-cpu-issues.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nset global tidb_auto_analyze_ratio=0.2;\nset global tidb_auto_analyze_start_time='00:00 +0800';\nset global tidb_auto_analyze_end_time='06:00 +0800';\n```\n\n----------------------------------------\n\nTITLE: TiDB Configuration Parameters Migration\nDESCRIPTION: Documentation of configuration parameters being migrated from configuration files to system variables in TiDB v6.1.0, including changes in parameter management and default behaviors\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.0.md#2025-04-18_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\nConfiguration items like `committer-concurrency`, `mem-quota-query`, `oom-action` replaced by corresponding system variables\n```\n\n----------------------------------------\n\nTITLE: Creating a Table Schema SQL Statement for TiDB Cloud Import\nDESCRIPTION: SQL statement to create a table named 'mytable' with three columns (ID, REGION, COUNT) to be included in a table schema file when importing CSV files from Amazon S3 or GCS into TiDB Cloud.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-csv-files.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE mytable (\nID INT,\nREGION VARCHAR(20),\nCOUNT INT );\n```\n\n----------------------------------------\n\nTITLE: Starting a Read-Only Transaction with Historical Timestamp in SQL\nDESCRIPTION: SQL command to begin a transaction that reads data as it existed at a specific point in time, enabling consistent stale reads across multiple queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nstart transaction read only as of timestamp '2021-05-26 16:45:26';\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB via ProxySQL using MySQL Client\nDESCRIPTION: Command to connect to TiDB through ProxySQL using the MySQL client on the local machine.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nmysql -u root -h 127.0.0.1 -P 6033\n```\n\n----------------------------------------\n\nTITLE: DRY RUN QUERY for Debugging Non-Transactional DML\nDESCRIPTION: Using the DRY RUN QUERY option to debug and confirm the query statement that causes an error in non-transactional DML statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nBATCH ON test.t2.id LIMIT 1 \nDRY RUN QUERY INSERT INTO t \nSELECT t2.id, t2.v, t3.id FROM t2, t3 WHERE t2.id = t3.id\n```\n\n----------------------------------------\n\nTITLE: Correct Usage of SET_VAR in Top-level Queries\nDESCRIPTION: This snippet demonstrates the correct application of `SET_VAR` in a top-level query, where it effectively alters the execution time limit for queries by specifying it outside of subqueries, thereby ensuring it takes effect.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_63\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> SELECT /*+ SET_VAR(MAX_EXECUTION_TIME=123) */ @@MAX_EXECUTION_TIME, a FROM (SELECT 1 as a) t;\\n+----------------------+---+\\n| @@MAX_EXECUTION_TIME | a |\\n+----------------------+---+\\n|                  123 | 1 |\\n+----------------------+---+\\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Response Format for Changefeed Creation\nDESCRIPTION: This JSON object describes the response format for a changefeed creation request, detailing configurations and parameters like 'config', 'checkpoint_time', and 'error'. Understanding this response format is crucial for interpreting API outcomes.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"admin_job_type\": 0,\n  \"checkpoint_time\": \"string\",\n  \"checkpoint_ts\": 0,\n  \"config\": {\n    \"bdr_mode\": true,\n    \"case_sensitive\": false,\n    \"check_gc_safe_point\": true,\n    \"consistent\": {\n      \"flush_interval\": 0,\n      \"level\": \"string\",\n      \"max_log_size\": 0,\n      \"storage\": \"string\"\n    },\n    \"enable_old_value\": true,\n    \"enable_sync_point\": true,\n    \"filter\": {\n      \"event_filters\": [\n        {\n          \"ignore_delete_value_expr\": \"string\",\n          \"ignore_event\": [\n            \"string\"\n          ],\n          \"ignore_insert_value_expr\": \"string\",\n          \"ignore_sql\": [\n            \"string\"\n          ],\n          \"ignore_update_new_value_expr\": \"string\",\n          \"ignore_update_old_value_expr\": \"string\",\n          \"matcher\": [\n            \"string\"\n          ]\n        }\n      ],\n      \"ignore_txn_start_ts\": [\n        0\n      ],\n      \"rules\": [\n        \"string\"\n      ]\n    },\n    \"force_replicate\": true,\n    \"ignore_ineligible_table\": true,\n    \"memory_quota\": 0,\n    \"mounter\": {\n      \"worker_num\": 0\n    },\n    \"sink\": {\n      \"column_selectors\": [\n        {\n          \"columns\": [\n            \"string\"\n          ],\n          \"matcher\": [\n            \"string\"\n          ]\n        }\n      ],\n      \"csv\": {\n        \"delimiter\": \"string\",\n        \"include_commit_ts\": true,\n        \"null\": \"string\",\n        \"quote\": \"string\"\n      },\n      \"date_separator\": \"string\",\n      \"dispatchers\": [\n        {\n          \"matcher\": [\n            \"string\"\n          ],\n          \"partition\": \"string\",\n          \"topic\": \"string\"\n        }\n      ],\n      \"enable_partition_separator\": true,\n      \"encoder_concurrency\": 0,\n      \"protocol\": \"string\",\n      \"schema_registry\": \"string\",\n      \"terminator\": \"string\",\n      \"transaction_atomicity\": \"string\"\n    },\n    \"sync_point_interval\": \"string\",\n    \"sync_point_retention\": \"string\"\n  },\n  \"create_time\": \"string\",\n  \"creator_version\": \"string\",\n  \"error\": {\n    \"addr\": \"string\",\n    \"code\": \"string\",\n    \"message\": \"string\"\n  },\n  \"id\": \"string\",\n  \"resolved_ts\": 0,\n  \"sink_uri\": \"string\",\n  \"start_ts\": 0,\n  \"state\": \"string\",\n  \"target_ts\": 0,\n  \"task_status\": [\n    {\n      \"capture_id\": \"string\",\n      \"table_ids\": [\n        0\n      ]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: TiCDC Kafka Message Format\nDESCRIPTION: This JSON snippet shows the structure of Kafka messages output by TiCDC, which includes metadata such as the timestamp, schema name, and table name for each change event.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"ts\":<TS>,\n    \"scm\":<Schema Name>,\n    \"tbl\":<Table Name>,\n    \"t\":1\n}\n```\n\n----------------------------------------\n\nTITLE: Using NO_HASH_JOIN Hint in SQL Queries\nDESCRIPTION: The NO_HASH_JOIN hint instructs the optimizer not to use the hash join algorithm for the specified tables, forcing it to consider other join algorithms instead.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ NO_HASH_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB Cloud using Go\nDESCRIPTION: This code snippet demonstrates how to execute a query against a TiDB Cloud Dedicated cluster using Go's `go-sql-driver/mysql` library. It establishes a connection with TLS configured, executes a SELECT DATABASE() query, and prints the database name. The snippet depends on the `go-sql-driver/mysql` library and requires handling potential errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tls-connect-to-dedicated.md#2025-04-18_snippet_7\n\nLANGUAGE: go\nCODE:\n```\npackage main\nimport (\n  \"crypto/tls\"\n  \"crypto/x509\"\n  \"database/sql\"\n  \"fmt\"\n  \"io/ioutil\"\n  \"log\"\n\n  \"github.com/go-sql-driver/mysql\"\n)\nfunc main() {\n  rootCertPool := x509.NewCertPool()\n  pem, err := ioutil.ReadFile(\"ca.pem\")\n  if err != nil {\n    log.Fatal(err)\n  }\n  if ok := rootCertPool.AppendCertsFromPEM(pem); !ok {\n    log.Fatal(\"Failed to append PEM.\")\n  }\n  mysql.RegisterTLSConfig(\"tidb\", &tls.Config{\n    RootCAs:    rootCertPool,\n    MinVersion: tls.VersionTLS12,\n    ServerName: \"tidb.srgnqxji5bc.clusters.staging.tidb-cloud.com\",\n  })\n  db, err := sql.Open(\"mysql\", \"root:<your_password>@tcp(tidb.srgnqxji5bc.clusters.staging.tidb-cloud.com:4000)/test?tls=tidb\")\n  if err != nil {\n    log.Fatal(\"failed to connect database\", err)\n  }\n  defer db.Close()\n\n  var dbName string\n  err = db.QueryRow(\"SELECT DATABASE();\").Scan(&dbName)\n  if err != nil {\n    log.Fatal(\"failed to execute query\", err)\n  }\n  fmt.Println(dbName)\n}\n```\n\n----------------------------------------\n\nTITLE: Querying SQL Latency for Employee Table\nDESCRIPTION: This SQL query checks for average latency and execution count of point queries on the `employee` table where the query text matches a specific pattern. Dependencies include access to TiDB's statement summary tables. The input is a SQL `LIKE` query pattern, and the output is average latency, execution count, and sample queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/statement-summary-tables.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT avg_latency, exec_count, query_sample_text\n    FROM information_schema.statements_summary\n    WHERE digest_text LIKE 'select * from employee%';\n```\n\nLANGUAGE: sql\nCODE:\n```\n+-------------+------------+------------------------------------------+\n| avg_latency | exec_count | query_sample_text                        |\n+-------------+------------+------------------------------------------+\n|     1042040 |          2 | select * from employee where name='eric' |\n|      345053 |          3 | select * from employee where id=3100     |\n+-------------+------------+------------------------------------------+\n2 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with PRE_SPLIT_REGIONS in TiDB\nDESCRIPTION: This example demonstrates how to create a table with pre-split regions by setting SHARD_ROW_ID_BITS=4 and PRE_SPLIT_REGIONS=2. This configuration will create 5 regions in total: 4 regions for table data and 1 region for the index.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_32\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a INT, b INT, INDEX idx1(a)) SHARD_ROW_ID_BITS = 4 PRE_SPLIT_REGIONS=2;\n```\n\n----------------------------------------\n\nTITLE: Running Transaction Example in Python\nDESCRIPTION: Shell command to run the Python transaction example with Alice buying 4 books and Bob buying 7 books from a limited inventory of 10 books, using pessimistic transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nOPTIMISTIC=False ALICE=4 BOB=7 python3 txn_example.py\n```\n\n----------------------------------------\n\nTITLE: Managing DDL Jobs with Pause and Resume Operations in TiDB\nDESCRIPTION: These SQL commands demonstrate how to pause and resume resource-intensive DDL jobs to optimize resource utilization. The commands work with multiple job IDs (1 and 2 in this example) and allow for controlling the execution timing of operations like creating indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.5.0.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nADMIN PAUSE DDL JOBS 1,2;\nADMIN RESUME DDL JOBS 1,2;\n```\n\n----------------------------------------\n\nTITLE: Updating Data with MyBatis in XML\nDESCRIPTION: This XML configuration defines a mapper for updating player data in a TiDB database using MyBatis. It includes an update statement to modify player coins and goods based on the primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-mybatis.md#2025-04-18_snippet_5\n\nLANGUAGE: XML\nCODE:\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.pingcap.model.PlayerMapper\">\n    <update id=\"updateByPrimaryKey\" parameterType=\"com.pingcap.model.Player\">\n    update player\n    set coins = #{coins,jdbcType=INTEGER},\n      goods = #{goods,jdbcType=INTEGER}\n    where id = #{id,jdbcType=VARCHAR}\n    </update>\n</mapper>\n```\n\n----------------------------------------\n\nTITLE: Importing Cluster Information using PLAN REPLAYER\nDESCRIPTION: This SQL command facilitates the import of a previously exported ZIP file back into a TiDB cluster, allowing for the restoration of schemas and statistics. It is recommended to disable auto analyze to prevent overwriting of imported statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-replayer.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nPLAN REPLAYER LOAD 'file_name';\n```\n\nLANGUAGE: sql\nCODE:\n```\nPLAN REPLAYER LOAD 'plan_replayer.zip';\n```\n\nLANGUAGE: sql\nCODE:\n```\nset @@global.tidb_enable_auto_analyze = OFF;\n```\n\n----------------------------------------\n\nTITLE: Restoring Data to TiDB Cluster\nDESCRIPTION: This SQL snippet restores a previously backed-up database from S3 storage to the secondary TiDB cluster. It uses cloud storage credentials and outputs metadata about the restored backup.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nRESTORE DATABASE * FROM '`s3://backup?access-key=minio&secret-access-key=miniostorage&endpoint=http://10.0.1.10:6060&force-path-style=true`';\n```\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------+----------+----------+---------------------+---------------------+\n| Destination          | Size     | BackupTS | Queue Time          | Execution Time      |\n+----------------------+----------+----------+---------------------+---------------------+\n| s3://backup          | 10315858 | 0        | 2022-02-25 20:03:59 | 2022-02-25 20:03:59 |\n+----------------------+----------+----------+---------------------+---------------------+\n1 row in set (41.85 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting TiDB Service Scope for Distributed Execution\nDESCRIPTION: Using the tidb_service_scope system variable to control which TiDB nodes execute ADD INDEX or IMPORT INTO statements. This allows for resource isolation to prevent impact on business operations while maintaining optimal performance for these resource-intensive operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.5.0.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ntidb_service_scope\n```\n\n----------------------------------------\n\nTITLE: Deleting SQL User after Deactivating Index Insight\nDESCRIPTION: SQL statement to delete the user created for the Index Insight feature after deactivation. Replace 'username' with the actual username used.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/index-insight.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP USER 'username';\n```\n\n----------------------------------------\n\nTITLE: Querying Index Advisor Results\nDESCRIPTION: Shows how to query the mysql.index_advisor_results system table to view the stored index recommendations. This table contains detailed information about recommended indexes including creation time, table details, and workload impact.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM mysql.index_advisor_results;\n```\n\n----------------------------------------\n\nTITLE: Query Results from TiDB Cloud Sample Data\nDESCRIPTION: The results of querying the trips table, showing trip records with details including ride ID, bike type, timestamps, station information, coordinates, and membership type.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-sample-data.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n+-----------------+---------------+---------------------+---------------------+--------------------+------------------+-------------------------------------------+----------------+-----------+------------+-----------+------------+---------------+\n| ride_id         | rideable_type | started_at          | ended_at            | start_station_name | start_station_id | end_station_name                          | end_station_id | start_lat | start_lng  | end_lat   | end_lng    | member_casual |\n+-----------------+---------------+---------------------+---------------------+--------------------+------------------+-------------------------------------------+----------------+-----------+------------+-----------+------------+---------------+\n| E291FF5018      | classic_bike  | 2021-01-02 11:12:38 | 2021-01-02 11:23:47 | 12th & U St NW     |            31268 | 7th & F St NW / National Portrait Gallery |          31232 | 38.916786 |  -77.02814 |  38.89728 | -77.022194 | member        |\n| E76F3605D0      | docked_bike   | 2020-09-13 00:44:11 | 2020-09-13 00:59:38 | 12th & U St NW     |            31268 | 17th St & Massachusetts Ave NW            |          31267 | 38.916786 |  -77.02814 | 38.908142 |  -77.03836 | casual        |\n| FFF0B75414      | docked_bike   | 2020-09-28 16:47:53 | 2020-09-28 16:57:30 | 12th & U St NW     |            31268 | 17th St & Massachusetts Ave NW            |          31267 | 38.916786 |  -77.02814 | 38.908142 |  -77.03836 | casual        |\n| C3F2C16949      | docked_bike   | 2020-09-13 00:42:03 | 2020-09-13 00:59:43 | 12th & U St NW     |            31268 | 17th St & Massachusetts Ave NW            |          31267 | 38.916786 |  -77.02814 | 38.908142 |  -77.03836 | casual        |\n| 1C7EC91629      | docked_bike   | 2020-09-28 16:47:49 | 2020-09-28 16:57:26 | 12th & U St NW     |            31268 | 17th St & Massachusetts Ave NW            |          31267 | 38.916786 |  -77.02814 | 38.908142 |  -77.03836 | member        |\n| A3A38BCACA      | classic_bike  | 2021-01-14 09:52:53 | 2021-01-14 10:00:51 | 12th & U St NW     |            31268 | 10th & E St NW                            |          31256 | 38.916786 |  -77.02814 | 38.895912 |  -77.02606 | member        |\n| EC4943257E      | electric_bike | 2021-01-28 10:06:52 | 2021-01-28 10:16:28 | 12th & U St NW     |            31268 | 10th & E St NW                            |          31256 | 38.916843 | -77.028206 |  38.89607 |  -77.02608 | member        |\n| D4070FBFA7      | classic_bike  | 2021-01-12 09:50:51 | 2021-01-12 09:59:41 | 12th & U St NW     |            31268 | 10th & E St NW                            |          31256 | 38.916786 |  -77.02814 | 38.895912 |  -77.02606 | member        |\n| 6EABEF3CAB      | classic_bike  | 2021-01-09 15:00:43 | 2021-01-09 15:18:30 | 12th & U St NW     |            31268 | 1st & M St NE                             |          31603 | 38.916786 |  -77.02814 | 38.905697 | -77.005486 | member        |\n| 2F5CC89018      | electric_bike | 2021-01-02 01:47:07 | 2021-01-02 01:58:29 | 12th & U St NW     |            31268 | 3rd & H St NE                             |          31616 | 38.916836 |  -77.02815 |  38.90074 |  -77.00219 | member        |\n```\n\n----------------------------------------\n\nTITLE: Restarting TiDB Cluster\nDESCRIPTION: Command to restart a TiDB cluster to refresh and report metrics addresses for Dashboard monitoring.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster start CLUSTER_NAME\n```\n\n----------------------------------------\n\nTITLE: Viewing DDL Progress in TiDB\nDESCRIPTION: SQL command to check the progress of current DDL jobs using ADMIN SHOW DDL, which displays schema version, owner, running jobs and their details including row count and state.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/sql-faq.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW DDL;\n```\n\n----------------------------------------\n\nTITLE: Using COLLATE Clause in Expressions\nDESCRIPTION: Example showing how to use the COLLATE clause to specify collation in string comparisons.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 'a' = _utf8mb4 'A' collate utf8mb4_general_ci;\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into TiDB with node-mysql2 in JavaScript\nDESCRIPTION: Demonstrates how to insert a single Player record into the database and retrieve the insert ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysql2.md#2025-04-18_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nconst [rsh] = await conn.query('INSERT INTO players (coins, goods) VALUES (?, ?);', [100, 100]);\nconsole.log(rsh.insertId);\n```\n\n----------------------------------------\n\nTITLE: Applying IF Logic in SQL\nDESCRIPTION: The IF function is used to execute different actions based on the truth value of an expression. It checks a condition and returns one of two possible values. Usage requires a compatible SQL database. It accepts a condition, a value to return if true, and a value to return if false.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/control-flow-functions.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nIF(condition, value_if_true, value_if_false)\n```\n\nLANGUAGE: sql\nCODE:\n```\nWITH RECURSIVE d AS (SELECT 1 AS n UNION ALL SELECT n+1 FROM d WHERE n<10)\nSELECT n, IF(n MOD 2, \"odd\", \"even\") FROM d;\n```\n\n----------------------------------------\n\nTITLE: Using SEMI_JOIN_REWRITE Hint for EXISTS Subqueries\nDESCRIPTION: The SEMI_JOIN_REWRITE hint tells the optimizer to rewrite semi-join queries into ordinary join queries, which can lead to better execution plans for EXISTS subqueries based on data distribution.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t WHERE EXISTS (SELECT /*+ SEMI_JOIN_REWRITE() */ 1 FROM t1 WHERE t1.a = t.a);\n```\n\n----------------------------------------\n\nTITLE: Using FULL GROUP BY Syntax with Student Test Data\nDESCRIPTION: A SQL query demonstrating the correct FULL GROUP BY syntax where all non-aggregated columns in the SELECT clause are included in the GROUP BY clause. This ensures a stable result set by properly grouping student information by both class and student name.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-unstable-result-set.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    `a`.`class`,\n    `a`.`stuname`,\n    max( `b`.`courscore` )\nFROM\n    `stu_info` `a`\n    JOIN `stu_score` `b` ON `a`.`stuno` = `b`.`stuno`\nGROUP BY\n    `a`.`class`,\n    `a`.`stuname`\nORDER BY\n    `a`.`class`,\n    `a`.`stuname`;\n```\n\n----------------------------------------\n\nTITLE: Adjusting Raft Base Tick Interval in TiKV Configuration\nDESCRIPTION: YAML configuration example showing how to adjust the raft-base-tick-interval parameter in the TiKV raftstore section to reduce message frequency.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/massive-regions-best-practices.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n[raftstore]\nraft-base-tick-interval = \"2s\"\n```\n\n----------------------------------------\n\nTITLE: Create a resource group with runaway query management\nDESCRIPTION: This SQL statement creates a resource group named 'rg1' with a quota of 500 RUs per second. It defines a runaway query as one that exceeds 60 seconds of execution time and configures the system to lower the priority of such queries to COOLDOWN.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\n\"CREATE RESOURCE GROUP IF NOT EXISTS rg1 RU_PER_SEC = 500 QUERY_LIMIT=(EXEC_ELAPSED='60s', ACTION=COOLDOWN);\"\n```\n\n----------------------------------------\n\nTITLE: Creating Covering Index in SQL\nDESCRIPTION: This SQL statement creates a new covering index 'title_price_idx' that includes both the title and price columns, optimizing the query performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX title_price_idx ON books (title, price);\n```\n\n----------------------------------------\n\nTITLE: Creating a table for testing in TiDB\nDESCRIPTION: This SQL snippet creates a table named 't' with two integer columns, 'a' and 'b', and an index on column 'b'. This table is used for demonstrating the non-prepared plan cache.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-non-prepared-plan-cache.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a INT, b INT, KEY(b));\n```\n\n----------------------------------------\n\nTITLE: Complex Multi-Table Join Execution Plan\nDESCRIPTION: Complex SQL query involving joins between planets and stars tables, demonstrating advanced execution plan with index range scan, hash join, and multiple sorting operators\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN \nSELECT t5.name \nFROM (\n    SELECT p.name, p.gravity, p.distance_from_sun \n    FROM universe.planets p \n    JOIN universe.stars s\n        ON s.id = p.sun_id \n        AND s.name = 'Sun'\n    ORDER BY p.distance_from_sun ASC \n    LIMIT 5\n) t5\nORDER BY t5.gravity DESC \nLIMIT 3;\n```\n\n----------------------------------------\n\nTITLE: Configuring package.json for ES Module Support in Node.js\nDESCRIPTION: JSON configuration in package.json to specify ES module usage and list the TiDB Cloud serverless driver dependency.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-node-example.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"module\",\n  \"dependencies\": {\n    \"@tidbcloud/serverless\": \"^0.0.7\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Identifying Recent Slow Queries Using SQL in TiDB\nDESCRIPTION: This SQL command retrieves the most recent N slow query records from TiDB. It is helpful for monitoring and diagnosing performance issues related to slow queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW SLOW recent N\n```\n\n----------------------------------------\n\nTITLE: Explain output example\nDESCRIPTION: This code snippet shows the sample output of an `EXPLAIN` statement. It displays the id, estRows, task, access object, and operator info columns. This allows you to better understand how the query is being processed and identify any potential bottlenecks.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.96 sec)\n\nQuery OK, 2 rows affected (0.02 sec)\nRecords: 2  Duplicates: 0  Warnings: 0\n\n+-------------------------------+---------+-----------+---------------------+---------------------------------------------+\n| id                            | estRows | task      | access object       | operator info                               |\n+-------------------------------+---------+-----------+---------------------+---------------------------------------------+\n| IndexLookUp_10                | 10.00   | root      |                     |                                             |\n| ├─IndexRangeScan_8(Build)     | 10.00   | cop[tikv] | table:t, index:a(a) | range:[1,1], keep order:false, stats:pseudo |\n| └─TableRowIDScan_9(Probe)     | 10.00   | cop[tikv] | table:t             | keep order:false, stats:pseudo              |\n+-------------------------------+---------+-----------+---------------------+---------------------------------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Starting a TiDB Cluster\nDESCRIPTION: This snippet outlines the command used to start a TiDB cluster after deployment. It also mentions how to check the cluster name if forgotten.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster start prod-cluster\n```\n\n----------------------------------------\n\nTITLE: JSON Modification Functions\nDESCRIPTION: Functions for modifying JSON documents including appending, inserting, removing, and replacing values.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nJSON_APPEND()\nJSON_ARRAY_APPEND()\nJSON_ARRAY_INSERT()\nJSON_INSERT()\nJSON_MERGE_PATCH()\nJSON_MERGE_PRESERVE()\nJSON_REMOVE()\nJSON_REPLACE()\nJSON_SET()\nJSON_UNQUOTE()\n```\n\n----------------------------------------\n\nTITLE: Querying Data with GORM in Golang\nDESCRIPTION: Retrieves a Player record from the database by ID using GORM's Find method.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-golang-gorm.md#2025-04-18_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nvar queryPlayer Player\ndb.Find(&queryPlayer, \"id = ?\", \"id\")\n```\n\n----------------------------------------\n\nTITLE: Finding HAProxy Process ID in Bash\nDESCRIPTION: Command to identify the running HAProxy process, which is needed before stopping the service.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/haproxy-best-practices.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nps -ef | grep haproxy\n```\n\n----------------------------------------\n\nTITLE: Granting All Privileges to Global User in TiDB\nDESCRIPTION: Grant all privileges on all databases to the user 'finley'@'%' with the GRANT OPTION, allowing this user to grant privileges to other users.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nGRANT ALL PRIVILEGES ON *.* TO 'finley'@'%' WITH GRANT OPTION;\n```\n\n----------------------------------------\n\nTITLE: Granting Roles to Users in TiDB\nDESCRIPTION: This snippet shows how to grant roles to users in TiDB using the `GRANT` statement.  Multiple roles can be granted to multiple users in a single statement. To execute this statement, the user needs the `SUPER` privilege.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nGRANT 'app_developer' TO 'dev1'@'localhost';\nGRANT 'app_read' TO 'read_user1'@'localhost', 'read_user2'@'localhost';\nGRANT 'app_read', 'app_write' TO 'rw_user1'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Starting TiDB Cluster After Offline Upgrade in Shell\nDESCRIPTION: This command starts the TiDB cluster after an offline upgrade has been completed. It is necessary because the cluster is not automatically restarted after an offline upgrade.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster start <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: DDL_JOBS Sample Query Results\nDESCRIPTION: Shows example output of three DDL jobs including table creation operations with their complete details like timing, state, and full CREATE TABLE statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-ddl-jobs.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n*************************** 1. row ***************************\n      JOB_ID: 44\n     DB_NAME: mysql\n  TABLE_NAME: opt_rule_blacklist\n    JOB_TYPE: create table\nSCHEMA_STATE: public\n   SCHEMA_ID: 3\n    TABLE_ID: 43\n   ROW_COUNT: 0\n  START_TIME: 2020-07-06 15:24:27\n    END_TIME: 2020-07-06 15:24:27\n       STATE: synced\n       QUERY: CREATE TABLE IF NOT EXISTS mysql.opt_rule_blacklist (\n        name char(100) NOT NULL\n    );\n*************************** 2. row ***************************\n      JOB_ID: 42\n     DB_NAME: mysql\n  TABLE_NAME: expr_pushdown_blacklist\n    JOB_TYPE: create table\nSCHEMA_STATE: public\n   SCHEMA_ID: 3\n    TABLE_ID: 41\n   ROW_COUNT: 0\n  START_TIME: 2020-07-06 15:24:27\n    END_TIME: 2020-07-06 15:24:27\n       STATE: synced\n       QUERY: CREATE TABLE IF NOT EXISTS mysql.expr_pushdown_blacklist (\n        name char(100) NOT NULL,\n        store_type char(100) NOT NULL DEFAULT 'tikv,tiflash,tidb',\n        reason varchar(200)\n    );\n*************************** 3. row ***************************\n      JOB_ID: 40\n     DB_NAME: mysql\n  TABLE_NAME: stats_top_n\n    JOB_TYPE: create table\nSCHEMA_STATE: public\n   SCHEMA_ID: 3\n    TABLE_ID: 39\n   ROW_COUNT: 0\n  START_TIME: 2020-07-06 15:24:26\n    END_TIME: 2020-07-06 15:24:27\n       STATE: synced\n       QUERY: CREATE TABLE if not exists mysql.stats_top_n (\n        table_id bigint(64) NOT NULL,\n        is_index tinyint(2) NOT NULL,\n        hist_id bigint(64) NOT NULL,\n        value longblob,\n        count bigint(64) UNSIGNED NOT NULL,\n        index tbl(table_id, is_index, hist_id)\n    );\n```\n\n----------------------------------------\n\nTITLE: TPC-DS Query Execution Plan Without Runtime Filter\nDESCRIPTION: SQL query execution plan showing detailed performance metrics when Runtime Filter is disabled. Query joins catalog_sales and date_dim tables with a execution time of 0.38 seconds.\nSOURCE: https://github.com/pingcap/docs/blob/master/runtime-filter.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT cs_ship_date_sk FROM catalog_sales, date_dim WHERE d_date = '2002-2-01' AND cs_ship_date_sk = d_date_sk;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Aggregation Execution Plan in TiDB\nDESCRIPTION: Uses the EXPLAIN statement to show how TiDB optimizes an aggregation query (COUNT(*)) across multiple regions. It highlights the StreamAgg operation's role in aggregating data at different stages within the TiDB and TiKV architecture.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-aggregation.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT COUNT(*) FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Setting Specific Default Roles for a User in TiDB\nDESCRIPTION: This snippet shows how to set specific roles as the default roles for a user using the `SET DEFAULT ROLE` statement. When `rw_user1@localhost` logs in, the `app_read` and `app_write` roles are automatically enabled. You need to grant the role to the user before setting the default role.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSET DEFAULT ROLE app_read, app_write TO 'rw_user1'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Using Manual Hint with Table Aliases in TiDB SQL\nDESCRIPTION: This SQL query shows how to use manual hints with table aliases to specify TiFlash replicas for multiple tables in a join operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tidb-to-read-tiflash.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nselect /*+ read_from_storage(tiflash[alias_a,alias_b]) */ ... from table_name_1 as alias_a, table_name_2 as alias_b where alias_a.column_1 = alias_b.column_2;\n```\n\n----------------------------------------\n\nTITLE: Adjusting Index Creation Parameters in TiDB\nDESCRIPTION: Configure TiDB parameters to control index creation speed and resource consumption. The parameters tidb_ddl_reorg_worker_cnt, tidb_ddl_reorg_batch_size, and tidb_ddl_reorg_priority can be adjusted based on system resource availability and monitoring results.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-cpu-issues.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ntidb_ddl_reorg_worker_cnt\ntidb_ddl_reorg_batch_size\ntidb_ddl_reorg_priority\n```\n\n----------------------------------------\n\nTITLE: Deleting Data from TiKV using Spark SQL\nDESCRIPTION: Shows how to delete data from TiKV using Spark SQL with a specific catalog and conditional deletion\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nspark.sql(\"use tidb_catalog\")\nspark.sql(\"delete from ${database}.${table} where xxx\")\n```\n\n----------------------------------------\n\nTITLE: Querying Books Published in a Specific Year in TiDB\nDESCRIPTION: SQL query to select all books published in the year 2022 from the 'books' table.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-secondary-indexes.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM `bookshop`.`books` WHERE `published_at` >= '2022-01-01 00:00:00' AND `published_at` < '2023-01-01 00:00:00';\n```\n\n----------------------------------------\n\nTITLE: Creating a user with X.509 authentication requirement\nDESCRIPTION: This SQL command creates a user 'u1' that requires X.509 certificate-based authentication. This means that the user must present a valid certificate during the TLS handshake to be authenticated. This provides an additional layer of security, ensuring that only clients with valid certificates can connect.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-clients-and-servers.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'u1'@'%'  REQUIRE X509;\n```\n\n----------------------------------------\n\nTITLE: Writing Data to TiKV using TiSpark DataSource API\nDESCRIPTION: The following snippet demonstrates how to use the Spark DataSource API to write data to TiKV while ensuring ACID compliance. It includes setting up the necessary connection options.\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_3\n\nLANGUAGE: scala\nCODE:\n```\n```\nval tidbOptions: Map[String, String] = Map(\n  \"tidb.addr\" -> \"127.0.0.1\",\n  \"tidb.password\" -> \"\",\n  \"tidb.port\" -> \"4000\",\n  \"tidb.user\" -> \"root\"\n)\n\nval customerDF = spark.sql(\"select * from customer limit 100000\")\n\ncustomerDF.write\n.format(\"tidb\")\n.option(\"database\", \"tpch_test\")\n.option(\"table\", \"cust_test_select\")\n.options(tidbOptions)\n.mode(\"append\")\n.save()\n```\n```\n\n----------------------------------------\n\nTITLE: Running the Demo Application\nDESCRIPTION: Command to execute the SQLAlchemy quickstart demo script that demonstrates vector search capabilities.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython sqlalchemy-quickstart.py\n```\n\n----------------------------------------\n\nTITLE: Range INTERVAL with COLUMNS Partitioning in SQL\nDESCRIPTION: Example of creating a monthly_report_status table using Range INTERVAL with COLUMNS partitioning on the report_date column with a monthly interval, spanning from 2000-01-01 to 2025-01-01.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE monthly_report_status (\n    report_id int NOT NULL,\n    report_status varchar(20) NOT NULL,\n    report_date date NOT NULL\n)\nPARTITION BY RANGE COLUMNS (report_date)\nINTERVAL (1 MONTH) FIRST PARTITION LESS THAN ('2000-01-01') LAST PARTITION LESS THAN ('2025-01-01')\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning with TOML\nDESCRIPTION: This snippet illustrates the configuration of TiDB Lightning using a TOML file. It includes settings for logging, data sources, the backend, target database connection, and table mapping rules. It is crucial to replace placeholders with actual values relevant to the deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\n# Logs\nlevel = \"info\"\nfile = \"tidb-lightning.log\"\n\n[mydumper]\ndata-source-dir = ${data-path}\n\n[tikv-importer]\n# Choose a local backend.\n# \"local\": The default mode. It is used for large data volumes greater than 1 TiB. During migration, downstream TiDB cannot provide services.\n# \"tidb\": Used for data volumes less than 1 TiB. During migration, downstream TiDB can provide services normally.\n# For more information, see [TiDB Lightning Backends](https://docs.pingcap.com/tidb/stable/tidb-lightning-backends)\nbackend = \"local\"\n# Set the temporary directory for the sorted key value pairs. It must be empty.\n# The free space must be greater than the size of the dataset to be imported.\n# It is recommended that you use a directory different from `data-source-dir` to get better migration performance by consuming I/O resources exclusively.\nsorted-kv-dir = \"${sorted-kv-dir}\"\n\n# Set the renaming rules ('routes') from source to target tables, in order to support merging different table shards into a single target table. Here you migrate `table1` and `table2` in `my_db1`, and `table3` and `table4` in `my_db2`, to the target `table5` in downstream `my_db`.\n[[mydumper.files]]\npattern = '(^|/)my_db1\\.table[1-2]\\.\\.*\\.sql$'\nschema = \"my_db\"\ntable = \"table5\"\ntype = \"sql\"\n\n[[mydumper.files]]\npattern = '(^|/)my_db2\\.table[3-4]\\.\\.*\\.sql$'\nschema = \"my_db\"\ntable = \"table5\"\ntype = \"sql\"\n\n# Information of the target TiDB cluster. For example purposes only. Replace the IP address with your IP address.\n[tidb]\n# Information of the target TiDB cluster.\n# Values here are only for illustration purpose. Replace them with your own values.\nhost = ${host}           # For example: \"172.16.31.1\"\nport = ${port}           # For example: 4000\nuser = \"${user_name}\"    # For example: \"root\"\npassword = \"${password}\" # For example: \"rootroot\"\nstatus-port = ${status-port} # The table information is read from the status port. For example: 10080\n# the IP address of the PD cluster. TiDB Lightning gets some information through the PD cluster.\n# For example: \"172.16.31.3:2379\".\n# When backend = \"local\", make sure that the values of status-port and pd-addr are correct. Otherwise an error will occur.\npd-addr = \"${ip}:${port}\"\n```\n\n----------------------------------------\n\nTITLE: Non-Rewritable INSERT Statements with ON DUPLICATE KEY UPDATE\nDESCRIPTION: Shows INSERT statements with ON DUPLICATE KEY UPDATE clauses that cannot be rewritten into a single statement due to different update values.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ninsert into t (a) values (10) on duplicate key update a = 10;\ninsert into t (a) values (11) on duplicate key update a = 11;\ninsert into t (a) values (12) on duplicate key update a = 12;\n```\n\n----------------------------------------\n\nTITLE: Setting Up and Using Partition Selection in SQL\nDESCRIPTION: Demonstrates the partition selection feature in TiDB where queries can target specific partitions using the PARTITION option in SELECT statements. Shows creating a partitioned table, inserting data, and querying specific partitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_52\n\nLANGUAGE: sql\nCODE:\n```\nSET @@sql_mode = '';\n\nCREATE TABLE employees  (\n    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    fname VARCHAR(25) NOT NULL,\n    lname VARCHAR(25) NOT NULL,\n    store_id INT NOT NULL,\n    department_id INT NOT NULL\n)\n\nPARTITION BY RANGE(id)  (\n    PARTITION p0 VALUES LESS THAN (5),\n    PARTITION p1 VALUES LESS THAN (10),\n    PARTITION p2 VALUES LESS THAN (15),\n    PARTITION p3 VALUES LESS THAN MAXVALUE\n);\n\nINSERT INTO employees VALUES\n    ('', 'Bob', 'Taylor', 3, 2), ('', 'Frank', 'Williams', 1, 2),\n    ('', 'Ellen', 'Johnson', 3, 4), ('', 'Jim', 'Smith', 2, 4),\n    ('', 'Mary', 'Jones', 1, 1), ('', 'Linda', 'Black', 2, 3),\n    ('', 'Ed', 'Jones', 2, 1), ('', 'June', 'Wilson', 3, 1),\n    ('', 'Andy', 'Smith', 1, 3), ('', 'Lou', 'Waters', 2, 4),\n    ('', 'Jill', 'Stone', 1, 4), ('', 'Roger', 'White', 3, 2),\n    ('', 'Howard', 'Andrews', 1, 2), ('', 'Fred', 'Goldberg', 3, 3),\n    ('', 'Barbara', 'Brown', 2, 3), ('', 'Alice', 'Rogers', 2, 2),\n    ('', 'Mark', 'Morgan', 3, 3), ('', 'Karen', 'Cole', 3, 2);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM employees PARTITION (p1);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM employees PARTITION (p0, p2)\n    WHERE lname LIKE 'S%';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, CONCAT(fname, ' ', lname) AS name\n    FROM employees PARTITION (p0) ORDER BY lname;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT store_id, COUNT(department_id) AS c\n    FROM employees PARTITION (p1,p2,p3)\n    GROUP BY store_id HAVING c > 4;\n```\n\n----------------------------------------\n\nTITLE: Querying using OR with json_overlaps and IndexMerge in TiDB\nDESCRIPTION: Execution plan showing how TiDB uses IndexMerge to access a multi-valued index when conditions are connected with OR. The plan shows index range scans for different values in the JSON array.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n| id                               | estRows | task      | access object                                                               | operator info                                                                                                                                              |\n+----------------------------------+---------+-----------+-----------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Selection_5                      | 31.95   | root      |                                                                             | or(json_overlaps(json_extract(test.t4.j, \"$.a\"), cast(\"[1, 2]\", json BINARY)), json_overlaps(json_extract(test.t4.j, \"$.a\"), cast(\"[3, 4]\", json BINARY))) |\n| └─IndexMerge_11                  | 39.94   | root      |                                                                             | type: union                                                                                                                                                |\n|   ├─IndexRangeScan_6(Build)      | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[1,1], keep order:false, stats:pseudo                                                                                                                |\n|   ├─IndexRangeScan_7(Build)      | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[2,2], keep order:false, stats:pseudo                                                                                                                |\n|   ├─IndexRangeScan_8(Build)      | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[3,3], keep order:false, stats:pseudo                                                                                                                |\n|   ├─IndexRangeScan_9(Build)      | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[4,4], keep order:false, stats:pseudo                                                                                                                |\n|   └─TableRowIDScan_10(Probe)     | 39.94   | cop[tikv] | table:t4                                                                    | keep order:false, stats:pseudo                                                                                                                             |\n```\n\n----------------------------------------\n\nTITLE: Viewing Original SQL for a Specific DDL Job\nDESCRIPTION: This command retrieves the original SQL statement that was executed for a specific DDL job identified by its job_id. It helps track what schema changes were actually attempted.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW DDL JOBS;\nADMIN SHOW DDL JOB QUERIES 51;\n```\n\n----------------------------------------\n\nTITLE: Enabling MPP Mode in TiDB\nDESCRIPTION: This SQL command enables MPP (Massively Parallel Processing) mode in TiDB. MPP mode can significantly improve query performance for complex analytical queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_enforce_mpp = ON;\n```\n\n----------------------------------------\n\nTITLE: Querying Default Roles in TiDB\nDESCRIPTION: SQL query to display default role assignments for users from the mysql.default_roles system table.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM mysql.default_roles;\n```\n\n----------------------------------------\n\nTITLE: Brief Format EXPLAIN Output\nDESCRIPTION: Demonstrates using the 'brief' format in EXPLAIN to simplify operator ID representation in the execution plan\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN FORMAT = \"brief\" DELETE FROM t1 WHERE c1 = 3;\n```\n\n----------------------------------------\n\nTITLE: Foreign Key Constraint Implementation\nDESCRIPTION: Shows how to create and manage foreign key relationships between tables in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE users (\n id INT NOT NULL PRIMARY KEY AUTO_INCREMENT,\n doc JSON\n);\nCREATE TABLE orders (\n id INT NOT NULL PRIMARY KEY AUTO_INCREMENT,\n user_id INT NOT NULL,\n doc JSON,\n FOREIGN KEY fk_user_id (user_id) REFERENCES users(id)\n);\n\nSELECT table_name, column_name, constraint_name, referenced_table_name, referenced_column_name\nFROM information_schema.key_column_usage WHERE table_name IN ('users', 'orders');\n\nALTER TABLE orders DROP FOREIGN KEY fk_user_id;\nALTER TABLE orders ADD FOREIGN KEY fk_user_id (user_id) REFERENCES users(id);\n```\n\n----------------------------------------\n\nTITLE: Equality Comparison Partition Pruning\nDESCRIPTION: Demonstrates partition pruning with equality comparison using a simple Range partitioned table with three partitions. Shows how the query only accesses the relevant partition for a specific value.\nSOURCE: https://github.com/pingcap/docs/blob/master/partition-pruning.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (x int) partition by range (x) (\n    partition p0 values less than (5),\n    partition p1 values less than (10),\n    partition p2 values less than (15)\n    );\nexplain select * from t where x = 3;\n```\n\n----------------------------------------\n\nTITLE: Granting All Privileges to Local User in TiDB\nDESCRIPTION: Grant all privileges on all databases to the user 'finley'@'localhost' with the GRANT OPTION, allowing this user to grant privileges to other users.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nGRANT ALL PRIVILEGES ON *.* TO 'finley'@'localhost' WITH GRANT OPTION;\n```\n\n----------------------------------------\n\nTITLE: Working with Binary Literals in User-Defined Variables\nDESCRIPTION: Shows different ways to handle binary literals when setting user-defined variables, including direct assignment, numeric conversion, and explicit casting.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSET @v1 = b'1000001';\nSET @v2 = b'1000001'+0;\nSET @v3 = CAST(b'1000001' AS UNSIGNED);\n```\n\n----------------------------------------\n\nTITLE: Executing SQL Commands via Chat2Data Endpoint with Curl in Bash\nDESCRIPTION: This bash code snippet demonstrates how to call the Chat2Data v1 endpoint using curl for generating and executing SQL statements through natural language instructions. Essential parameters include cluster ID, database name, table names, and the instruction for SQL commands. The snippet requires an API key, and the server URL must be tailored to the intended geographical region.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user ${PUBLIC_KEY}:${PRIVATE_KEY} --request POST 'https://<region>.data.dev.tidbcloud.com/api/v1beta/app/chat2query-<ID>/endpoint/chat2data'\\\n --header 'content-type: application/json'\\\n --data-raw '{\n    \"cluster_id\": \"10939961583884005252\",\n    \"database\": \"sp500insight\",\n    \"tables\": [\"users\"],\n    \"instruction\": \"count the users\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Using Multiple Optimizer Hints in a Query - SQL\nDESCRIPTION: This snippet demonstrates how to apply multiple optimizer hints within a SQL SELECT statement to influence the query execution plan. Hints such as USE_INDEX, HASH_AGG, and HASH_JOIN are combined to optimize performance. Expected output is the count of rows retrieved from the tables specified in the query.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ USE_INDEX(t1, idx1), HASH_AGG(), HASH_JOIN(t1) */ count(*) FROM t t1, t t2 WHERE t1.a = t2.b;\n```\n\n----------------------------------------\n\nTITLE: Configuring External Storage for Large Messages in TiCDC Kafka Sink (TOML)\nDESCRIPTION: This configuration snippet shows how to set up TiCDC Kafka sink to send large messages to external storage when they exceed the size limit. It specifies the storage option and the URI for the external storage service.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_18\n\nLANGUAGE: TOML\nCODE:\n```\n[sink.kafka-config.large-message-handle]\nlarge-message-handle-option = \"claim-check\"\nclaim-check-storage-uri = \"s3://claim-check-bucket\"\n```\n\n----------------------------------------\n\nTITLE: Creating Schema with UTF8MB4 Character Set\nDESCRIPTION: Example of creating a schema with UTF8MB4 character set and general case-insensitive collation.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SCHEMA test1 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\n```\n\n----------------------------------------\n\nTITLE: Explaining SQL Query Execution Plan in TiDB\nDESCRIPTION: This snippet demonstrates how to use the EXPLAIN statement to analyze a SQL query's execution plan in TiDB, checking for runtime filter effects. The query targets the catalog_sales and date_dim tables, filtering results based on a specific date.\nSOURCE: https://github.com/pingcap/docs/blob/master/runtime-filter.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT cs_ship_date_sk FROM catalog_sales, date_dim\nWHERE d_date = '2002-2-01' AND\n     cs_ship_date_sk = d_date_sk;\n```\n\n----------------------------------------\n\nTITLE: TiCDC Configuration for Filtering DDL Events (TOML)\nDESCRIPTION: This TOML configuration defines a filter rule to ignore specific DDL events (create table, drop table, truncate table, rename table) for tables matching the 'test.t*' pattern, specifically focusing on the 'test.t1' table. It demonstrates how to configure TiCDC to selectively replicate or ignore DDL and DML operations based on defined rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-ddl.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n\n[filter]\nrules = ['test.t*']\n\nmatcher = [\"test.t1\"] # This filter rule applies only to the t1 table in the test database.\nignore-event = [\"create table\", \"drop table\", \"truncate table\", \"rename table\"]\n\n```\n\n----------------------------------------\n\nTITLE: Defining a Vector Field Model with peewee\nDESCRIPTION: Python code for defining a peewee model with a vector field to store document embeddings. Creates a table with a text content field and a 3-dimensional vector embedding field.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-peewee.md#2025-04-18_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass Document(Model):\n    class Meta:\n        database = db\n        table_name = 'peewee_demo_documents'\n\n    content = TextField()\n    embedding = VectorField(3)\n```\n\n----------------------------------------\n\nTITLE: Querying DM-worker Information (Shell/JSON)\nDESCRIPTION: Example of using curl to query DM-worker information via the API and the expected JSON response.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/cluster/workers' \\\n  -H 'accept: application/json'\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"total\": 1,\n  \"data\": [\n    {\n      \"name\": \"worker1\",\n      \"addr\": \"127.0.0.1:8261\",\n      \"bound_stage\": \"bound\",\n      \"bound_source_name\": \"mysql-01\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Users Table in TiDB\nDESCRIPTION: SQL statement to create a users table in TiDB Cloud Serverless cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-drizzle-example.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `test`.`users` (\n `id` BIGINT PRIMARY KEY auto_increment,\n `full_name` TEXT,\n `phone` VARCHAR(256)\n);\n```\n\n----------------------------------------\n\nTITLE: Executing ROW_NUMBER Window Function with TiDB SQL\nDESCRIPTION: This SQL snippet creates a table and inserts sample data, followed by executing an EXPLAIN query to illustrate the plan for a window function utilizing ROW_NUMBER. The task hint 'mpp[tiflash]' shows that the operation can be pushed down to TiFlash, which is preferred for distributed execution and efficiency. Dependencies include TiDB and TiFlash configured for replica handling.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-supported-pushdown-calculations.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id INT PRIMARY KEY, c1 VARCHAR(100));\nALTER TABLE t SET TIFLASH REPLICA 1;\nINSERT INTO t VALUES(1,\"foo\"),(2,\"bar\"),(3,\"bar foo\"),(10,\"foo\"),(20,\"bar\"),(30,\"bar foo\");\n\nEXPLAIN SELECT id, ROW_NUMBER() OVER (PARTITION BY id > 10) FROM t;\n+----------------------------------+----------+--------------+---------------+---------------------------------------------------------------------------------------------------------------+\n| id                               | estRows  | task         | access object | operator info                                                                                                 |\n+----------------------------------+----------+--------------+---------------+---------------------------------------------------------------------------------------------------------------+\n| TableReader_30                   | 10000.00 | root         |               | MppVersion: 1, data:ExchangeSender_29                                                                         |\n| └─ExchangeSender_29              | 10000.00 | mpp[tiflash] |               | ExchangeType: PassThrough                                                                                     |\n|   └─Projection_7                 | 10000.00 | mpp[tiflash] |               | test.t.id, Column#5, stream_count: 4                                                                          |\n|     └─Window_28                  | 10000.00 | mpp[tiflash] |               | row_number()->Column#5 over(partition by Column#4 rows between current row and current row), stream_count: 4  |\n|       └─Sort_14                  | 10000.00 | mpp[tiflash] |               | Column#4, stream_count: 4                                                                                     |\n|         └─ExchangeReceiver_13    | 10000.00 | mpp[tiflash] |               | stream_count: 4                                                                                               |\n|           └─ExchangeSender_12    | 10000.00 | mpp[tiflash] |               | ExchangeType: HashPartition, Compression: FAST, Hash Cols: [name: Column#4, collate: binary], stream_count: 4 |\n|             └─Projection_10      | 10000.00 | mpp[tiflash] |               | test.t.id, gt(test.t.id, 10)->Column#4                                                                        |\n|               └─TableFullScan_11 | 10000.00 | mpp[tiflash] | table:t       | keep order:false, stats:pseudo                                                                                |\n+----------------------------------+----------+--------------+---------------+---------------------------------------------------------------------------------------------------------------+\n9 rows in set (0.0073 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Node Labels in Command Line\nDESCRIPTION: The command sets labels for TiKV nodes, which are prerequisites for placement policies. Required labels include 'region', 'zone', and 'host', essential for configuring data placement.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntikv-server --labels region=<region>,zone=<zone>,host=<host>\n```\n\n----------------------------------------\n\nTITLE: Using User-Defined Variables with PREPARE Statements\nDESCRIPTION: Shows how to use user-defined variables with PREPARE statements, including storing the SQL query in a variable and passing parameters using EXECUTE.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSET @s = 'SELECT SQRT(POW(?,2) + POW(?,2)) AS hypotenuse';\nPREPARE stmt FROM @s;\nSET @a = 6;\nSET @b = 8;\nEXECUTE stmt USING @a, @b;\n```\n\n----------------------------------------\n\nTITLE: Update Multiple Tables Syntax Differences\nDESCRIPTION: Highlights the necessity to specify fields when updating multiple tables in TiDB as opposed to Oracle's method.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE test1 SET(test1.name,test1.age) = (SELECT test2.name,test2.age FROM test2 WHERE test2.id=test1.id)\n```\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE test1,test2 SET test1.name=test2.name,test1.age=test2.age WHERE test1.id=test2.id\n```\n\n----------------------------------------\n\nTITLE: Creating New TiCDC Changefeed for TiDB Replication\nDESCRIPTION: Command to create a new TiCDC changefeed that replicates data from the primary cluster to the secondary cluster. The changefeed connects to the TiCDC node at 172.16.6.122:8300 and uses MySQL sink protocol to replicate to the secondary cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\n# Create a changefeed\ntiup cdc cli changefeed create --server=http://172.16.6.122:8300 --sink-uri=\"mysql://root:@172.16.6.125:4000\" --changefeed-id=\"primary-to-secondary\"\n```\n\n----------------------------------------\n\nTITLE: Explaining Index Merge Usage in SQL\nDESCRIPTION: This SQL snippet demonstrates the behavior of the Index Merge feature in TiDB when both `OR` and `AND` conditions are present. The snippet highlights how TiDB handles and optimizes these queries using Index Merge.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1, mvi2) */ * FROM t4 WHERE 1 member of (j->'$.a') AND (2 member of (j->'$.b') OR 3 member of (j->'$.a'));\n```\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1, mvi2) */ * FROM t4 WHERE 1 member of (j->'$.a') OR (2 member of (j->'$.b') AND 3 member of (j->'$.a'));\n```\n\n----------------------------------------\n\nTITLE: Querying Data from TiDB with mysqlclient in Python\nDESCRIPTION: This code snippet shows how to execute a SELECT query on a TiDB table using mysqlclient and fetch the result.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-mysqlclient.md#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwith get_mysqlclient_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT count(*) FROM players\")\n        print(cur.fetchone()[0])\n```\n\n----------------------------------------\n\nTITLE: Enabling Runtime Filter in TiDB (SQL)\nDESCRIPTION: This SQL snippet illustrates how to enable the Runtime Filter feature in TiDB by setting the system variable `tidb_runtime_filter_mode` to `LOCAL`.\nSOURCE: https://github.com/pingcap/docs/blob/master/runtime-filter.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_runtime_filter_mode=\"LOCAL\";\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW VARIABLES LIKE \"tidb_runtime_filter_mode\";\n```\n\n----------------------------------------\n\nTITLE: SQL Endpoint Response Format in JSON\nDESCRIPTION: Example JSON response from a SQL endpoint showing the structure of returned data including column metadata, row results, and query execution details. The response includes information about column types, nullability, actual row data, and query performance metrics like latency and row counts.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-get-started.md#2025-04-18_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"sql_endpoint\",\n  \"data\": {\n    \"columns\": [\n      {\n        \"col\": \"id\",\n        \"data_type\": \"BIGINT\",\n        \"nullable\": false\n      },\n      {\n        \"col\": \"type\",\n        \"data_type\": \"VARCHAR\",\n        \"nullable\": false\n      }\n    ],\n    \"rows\": [\n      {\n        \"id\": \"20008295419\",\n        \"type\": \"CreateEvent\"\n      }\n    ],\n    \"result\": {\n      \"code\": 200,\n      \"message\": \"Query OK!\",\n      \"start_ms\": 1678965476709,\n      \"end_ms\": 1678965476839,\n      \"latency\": \"130ms\",\n      \"row_count\": 1,\n      \"row_affect\": 0,\n      \"limit\": 50\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Scaling Out TiDB Cluster\nDESCRIPTION: This command initiates the scale-out process for the TiDB cluster using the specified scale-out configuration file. It adds the new nodes defined in the configuration to the existing cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster scale-out <cluster-name> scale-out.yml [-p] [-i /home/root/.ssh/gcp_rsa]\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Repository Table in TiDB\nDESCRIPTION: This SQL snippet creates a `repository` table in the `test` database and inserts sample data. It serves as the foundational data structure for the Next.js application.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-oas-with-nextjs.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n-- Select the database\nUSE test;\n\n-- Create the table\nCREATE TABLE repository (\n        id int NOT NULL PRIMARY KEY AUTO_INCREMENT,\n        name varchar(64) NOT NULL,\n        url varchar(256) NOT NULL\n);\n\n-- Insert some sample data into the table\nINSERT INTO repository (name, url)\nVALUES ('tidb', 'https://github.com/pingcap/tidb'),\n        ('tikv', 'https://github.com/tikv/tikv'),\n        ('pd', 'https://github.com/tikv/pd'),\n        ('tiflash', 'https://github.com/pingcap/tiflash');\n```\n\n----------------------------------------\n\nTITLE: Accessing Previous Row with LAG() in SQL\nDESCRIPTION: This example uses the LAG() window function to access the value from the previous row. It uses a recursive CTE to generate a sequence of numbers and demonstrates default behavior when no previous row exists.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/window-functions.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nWITH RECURSIVE cte(n) AS (\n    SELECT 1\n    UNION\n    SELECT\n        n+1\n    FROM\n        cte\n    WHERE\n        n<10\n)\nSELECT\n    n,\n    LAG(n) OVER ()\nFROM\n    cte;\n```\n\n----------------------------------------\n\nTITLE: MySQL Arithmetic Operators\nDESCRIPTION: Basic arithmetic operators supported in MySQL and TiDB including addition, subtraction, multiplication, division, integer division, modulo, and unary minus.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/numeric-functions-and-operators.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n+    # Addition\n-    # Subtraction\n*    # Multiplication\n/    # Division\nDIV   # Integer division\n%, MOD # Modulo\n-    # Unary minus\n```\n\n----------------------------------------\n\nTITLE: Enabling Aggregation Pushdown for TiDB\nDESCRIPTION: These SQL commands enable pushdown optimizations for aggregation operations in TiDB, which can enhance performance by reducing data transfer and processing times.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\n-- Enable regular aggregation pushdown\nSET GLOBAL tidb_opt_agg_push_down = ON;\n\n-- Enable distinct aggregation pushdown\nSET GLOBAL tidb_opt_distinct_agg_push_down = ON;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with AUTO_INCREMENT and Observing Cache Behavior\nDESCRIPTION: This snippet demonstrates how AUTO_INCREMENT values can appear to jump dramatically when operations are performed against different TiDB servers due to each server having its own cache of AUTO_INCREMENT values.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a int PRIMARY KEY AUTO_INCREMENT, b timestamp NOT NULL DEFAULT NOW());\nINSERT INTO t (a) VALUES (NULL), (NULL), (NULL);\nINSERT INTO t (a) VALUES (NULL);\nSELECT * FROM t;\n```\n\n----------------------------------------\n\nTITLE: Analyzing IndexJoin Operator Execution in TiDB\nDESCRIPTION: This snippet shows the execution information for the `IndexJoin` operator in TiDB. It details the time consumed by the inner worker (total, concurrency, task count, construct, fetch, and build) and the probe time. Analyzing these metrics helps in identifying performance bottlenecks during index join operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_6\n\nLANGUAGE: None\nCODE:\n```\n\"inner:{total:4.297515932s, concurrency:5, task:17, construct:97.96291ms, fetch:4.164310088s, build:35.219574ms}, probe:53.574945ms\"\n```\n\n----------------------------------------\n\nTITLE: UUID Conversion Functions in TiDB\nDESCRIPTION: Shows usage of BIN_TO_UUID() and UUID_TO_BIN() functions for converting between text and binary UUID formats. Includes examples with optional ordering parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET @a := UUID();\n\nSELECT UUID_TO_BIN(@a);\n\nSELECT BIN_TO_UUID(0x9A17B457EB6D11EEBACF5405DB7AAD56);\n\nSELECT UUID_TO_BIN(@a, 1);\n\nSELECT BIN_TO_UUID(0x11EEEB6D9A17B457BACF5405DB7AAD56, 1);\n```\n\n----------------------------------------\n\nTITLE: Generating TPC-H Test Data - Shell\nDESCRIPTION: Generates a dataset based on the TPC-H benchmark using TiUP bench tool. The '--sf=1 prepare' flag specifies the scale factor for data generation. Successful execution indicates the dataset is ready for testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-htap.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup bench tpch --sf=1 prepare\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Generated Column Index Replacement\nDESCRIPTION: Illustrates how TiDB replaces expressions with equivalent generated columns for index usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/generated-columns.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(a int);\ndesc select a+1 from t where a+1=3;\n\nalter table t add column b bigint as (a+1) virtual;\nalter table t add index idx_b(b);\ndesc select a+1 from t where a+1=3;\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Disabled TTL\nDESCRIPTION: Creates a table with TTL attribute but initially disables the automatic cleanup functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/time-to-live.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n    id int PRIMARY KEY,\n    created_at TIMESTAMP\n) TTL = `created_at` + INTERVAL 3 MONTH TTL_ENABLE = 'OFF';\n```\n\n----------------------------------------\n\nTITLE: Attempting to Insert NULL into a NOT NULL Field\nDESCRIPTION: This example demonstrates the error that occurs when trying to insert NULL into the 'age' column, which is defined with a NOT NULL constraint.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO users (id,age,last_login) VALUES (NULL,NULL,NOW());\n```\n\n----------------------------------------\n\nTITLE: DROP VIEW Usage Example in SQL\nDESCRIPTION: A comprehensive example demonstrating the creation of a table and view, followed by dropping the view. The example shows that dropping a view does not affect the underlying table data.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-view.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5);\nQuery OK, 5 rows affected (0.03 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\nmysql> CREATE VIEW v1 AS SELECT * FROM t1 WHERE c1 > 2;\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> SELECT * FROM t1;\n+----+----+\n| id | c1 |\n+----+----+\n|  1 |  1 |\n|  2 |  2 |\n|  3 |  3 |\n|  4 |  4 |\n|  5 |  5 |\n+----+----+\n5 rows in set (0.00 sec)\n\nmysql> SELECT * FROM v1;\n+----+----+\n| id | c1 |\n+----+----+\n|  3 |  3 |\n|  4 |  4 |\n|  5 |  5 |\n+----+----+\n3 rows in set (0.00 sec)\n\nmysql> DROP VIEW v1;\nQuery OK, 0 rows affected (0.23 sec)\n\nmysql> SELECT * FROM t1;\n+----+----+\n| id | c1 |\n+----+----+\n|  1 |  1 |\n|  2 |  2 |\n|  3 |  3 |\n|  4 |  4 |\n|  5 |  5 |\n+----+----+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Using JSON_KEYS in SQL\nDESCRIPTION: Shows usage of JSON_KEYS function to extract top-level keys from JSON objects as a JSON array.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-search.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_KEYS('{\"name\": {\"first\": \"John\", \"last\": \"Doe\"}, \"type\": \"Person\"}');\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_KEYS('{\"name\": {\"first\": \"John\", \"last\": \"Doe\"}, \"type\": \"Person\"}', '$.name');\n```\n\n----------------------------------------\n\nTITLE: Copying Parquet Files from HDFS to Local Filesystem\nDESCRIPTION: Shell command to copy the exported parquet files from HDFS to the local file system using the hdfs dfs -get command.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-parquet-files-to-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\nhdfs dfs -get /path/in/hdfs /path/in/local\n```\n\n----------------------------------------\n\nTITLE: Dropping a Placement Policy in TiDB\nDESCRIPTION: Shows how to drop a placement policy that is not attached to any table or partition using the DROP PLACEMENT POLICY statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nDROP PLACEMENT POLICY myplacementpolicy;\n```\n\n----------------------------------------\n\nTITLE: Using NO_INDEX_JOIN Optimizer Hint - SQL\nDESCRIPTION: Demonstrates the NO_INDEX_JOIN optimizer hint which informs the system not to employ the index nested loop join for the designated tables, providing developers with enhanced control over join algorithms in SQL queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ NO_INDEX_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Setting TIFLASH Replicas for Tables - SQL\nDESCRIPTION: This SQL command sets TiFlash replica for specific tables in the 'test' database, enabling columnar storage engine usage. Ensures that data from specified tables is copied to TiFlash for advanced analytics involving HTAP capabilities.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-htap.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE test.customer SET TIFLASH REPLICA 1;\nALTER TABLE test.orders SET TIFLASH REPLICA 1;\nALTER TABLE test.lineitem SET TIFLASH REPLICA 1;\n```\n\n----------------------------------------\n\nTITLE: Querying CLUSTER_INFO Table for Topology Information in TiDB\nDESCRIPTION: This SQL query retrieves all information from the CLUSTER_INFO table, showing instance types, addresses, versions, Git hash values, and runtime information for all components in the TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-info.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM cluster_info;\n```\n\n----------------------------------------\n\nTITLE: Identifying Unsupported Data Types in MariaDB\nDESCRIPTION: SQL query to find columns using data types not supported by TiDB, such as UUID, INET4, and INET6. This helps in planning data type conversions during migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-mariadb.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n  TABLE_SCHEMA,\n  TABLE_NAME,\n  COLUMN_NAME,\n  DATA_TYPE\nFROM\n  information_schema.columns\nWHERE\n  DATA_TYPE IN('INET4','INET6','UUID');\n```\n\n----------------------------------------\n\nTITLE: Using Follower Read in Java DAO\nDESCRIPTION: Demonstrates how to use Follower Read in a Java DAO class to balance read load between leader and follower nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-follower-read.md#2025-04-18_snippet_2\n\nLANGUAGE: java\nCODE:\n```\npublic static class AuthorDAO {\n\n    // Omit initialization of instance variables...\n\n    public void getAuthorsByFollowerRead() throws SQLException {\n        try (Connection conn = ds.getConnection()) {\n            // Enable the follower read feature.\n            FollowerReadHelper.setSessionReplicaRead(conn, FollowReadMode.LEADER_AND_FOLLOWER);\n\n            // Read the authors list for 100000 times.\n            Random random = new Random();\n            for (int i = 0; i < 100000; i++) {\n                Integer birthYear = 1920 + random.nextInt(100);\n                List<Author> authors = this.getAuthorsByBirthYear(birthYear);\n                System.out.println(authors.size());\n            }\n        }\n    }\n\n    public List<Author> getAuthorsByBirthYear(Integer birthYear) throws SQLException {\n        List<Author> authors = new ArrayList<>();\n        try (Connection conn = ds.getConnection()) {\n            PreparedStatement stmt = conn.prepareStatement(\"SELECT id, name FROM authors WHERE birth_year = ?\");\n            stmt.setInt(1, birthYear);\n            ResultSet rs = stmt.executeQuery();\n            while (rs.next()) {\n                Author author = new Author();\n                author.setId( rs.getLong(\"id\"));\n                author.setName(rs.getString(\"name\"));\n                authors.add(author);\n            }\n        }\n        return authors;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting tidb_read_staleness for Historical Data Access in TiDB\nDESCRIPTION: Sets the tidb_read_staleness system variable to \"-5\", which instructs TiDB to read data from a timestamp within the last 5 seconds. This enables reading historical data before recent updates.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-read-staleness.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nset @@tidb_read_staleness=\"-5\";\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP via Online Deployment - Shell\nDESCRIPTION: This snippet shows how to install TiUP on the control machine using an online method. It involves a single command that uses curl to download and execute the installation script.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with TypeORM in TypeScript\nDESCRIPTION: This code demonstrates how to insert a single Player record using TypeORM. It creates a new Player object and saves it to the database, returning the created object with an auto-generated ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst player = new Player('Alice', 100, 100);\nawait this.dataSource.manager.save(player);\n```\n\n----------------------------------------\n\nTITLE: Scale-Out Configuration for TiKV Servers\nDESCRIPTION: This INI configuration defines the settings for a new TiKV server. It specifies the host, SSH port, TiKV port, status port, deployment directory, data directory, and log directory for the new TiKV instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_3\n\nLANGUAGE: ini\nCODE:\n```\n\"tikv_servers:\\n- host: 10.0.1.5\\n  ssh_port: 22\\n  port: 20160\\n  status_port: 20180\\n  deploy_dir: /tidb-deploy/tikv-20160\\n  data_dir: /tidb-data/tikv-20160\\n  log_dir: /tidb-deploy/tikv-20160/log\"\n```\n\n----------------------------------------\n\nTITLE: Restoring TiDB Incremental Backup Data\nDESCRIPTION: This command restores an incremental backup from the specified S3 storage location to the TiDB cluster. The full backup must be restored first before applying this incremental backup.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-incremental-guide.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full --pd \"${PD_IP}:2379\" \\\n--storage \"s3://backup-101/snapshot-202209081330/incr?access-key=${access-key}&secret-access-key=${secret-access-key}\"\n```\n\n----------------------------------------\n\nTITLE: Creating Role and User in TiDB\nDESCRIPTION: SQL commands to create a new role 'analyticsteam', grant privileges, create a user 'jennifer', and assign the role to the user.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-role.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE ROLE analyticsteam;\nGRANT SELECT ON test.* TO analyticsteam;\nCREATE USER jennifer;\nGRANT analyticsteam TO jennifer;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Slow Query Execution Details\nDESCRIPTION: Shows how to use EXPLAIN ANALYZE to get detailed execution information about slow query information retrieval, including initialization time, file reading, and parsing metrics.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-slow-query.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT * FROM INFORMATION_SCHEMA.SLOW_QUERY LIMIT 1\\G\n```\n\n----------------------------------------\n\nTITLE: Custom Monitoring Configuration in TiUP YAML\nDESCRIPTION: YAML configuration example for customizing monitoring components (Grafana, Prometheus, Alertmanager) in a TiDB cluster by specifying custom paths for dashboards, rules, and configuration files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\n---\n\ngrafana_servers:\n  - host: 172.16.5.134\n    dashboard_dir: /path/to/local/dashboards/dir\n\nmonitoring_servers:\n  - host: 172.16.5.134\n    rule_dir: /path/to/local/rules/dir\n\nalertmanager_servers:\n  - host: 172.16.5.134\n    config_file: /path/to/local/alertmanager.yml\n```\n\n----------------------------------------\n\nTITLE: Creating Expression Index on LOWER Function in SQL\nDESCRIPTION: Demonstrates how to create an expression index on the LOWER function applied to a column. This allows efficient querying on the lowercase version of the column values.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE INDEX idx1 ON t1 ((LOWER(col1)));\n```\n\n----------------------------------------\n\nTITLE: Querying Cache Hit Rate in TiDB\nDESCRIPTION: Queries the statements_summary table to view plan cache statistics including execution count and cache hits.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-non-prepared-plan-cache.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT digest_text, query_sample_text, exec_count, plan_in_cache, plan_cache_hits FROM INFORMATION_SCHEMA.STATEMENTS_SUMMARY WHERE query_sample_text LIKE '%SELECT * FROM %';\n```\n\n----------------------------------------\n\nTITLE: Basic BR PITR Help Command\nDESCRIPTION: Shows the help information for the 'tiup br restore point' command, displaying available flags and parameters for PITR operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore point --help\n```\n\n----------------------------------------\n\nTITLE: Using TIDB_ENCODE_SQL_DIGEST to Get Digest for Another Query\nDESCRIPTION: Shows that different queries with the same structure produce the same digest. This example uses 'SELECT 2' which normalizes to the same pattern as 'SELECT 1'.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_ENCODE_SQL_DIGEST('SELECT 2');\n```\n\n----------------------------------------\n\nTITLE: Calculating SHA-2 Hash in SQL\nDESCRIPTION: The `SHA2(str, n)` function computes a SHA-2 hash using the specified algorithm indicated by the argument n, returning NULL for unsupported algorithms.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SHA2('abc',224);\n```\n\n----------------------------------------\n\nTITLE: Node Disk Usage Alert Rule\nDESCRIPTION: PromQL query to monitor disk space usage, triggering when available space is less than 20% (usage > 80%)\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_19\n\nLANGUAGE: promql\nCODE:\n```\nnode_filesystem_avail_bytes{fstype=~\"(ext.|xfs)\", mountpoint!~\"/boot\"} / node_filesystem_size_bytes{fstype=~\"(ext.|xfs)\", mountpoint!~\"/boot\"} * 100 <= 20\n```\n\n----------------------------------------\n\nTITLE: Demonstrating PREPARE, EXECUTE, and DEALLOCATE Workflow in TiDB SQL\nDESCRIPTION: Example SQL code demonstrating the complete workflow of prepared statements: creating a prepared statement with PREPARE, setting a parameter value, executing the statement with EXECUTE, and finally releasing the statement with DEALLOCATE PREPARE.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-deallocate.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> PREPARE mystmt FROM 'SELECT ? as num FROM DUAL';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SET @number = 5;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> EXECUTE mystmt USING @number;\n+------+\n| num  |\n+------+\n| 5    |\n+------+\n1 row in set (0.00 sec)\n\nmysql> DEALLOCATE PREPARE mystmt;\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Accessing Project Information with Terraform and TiDB Cloud Provider\nDESCRIPTION: Configuration to retrieve project information from TiDB Cloud using the tidbcloud_projects data source. This snippet shows how to set up the provider, query projects with pagination, and output the results.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_0\n\nLANGUAGE: terraform\nCODE:\n```\nterraform {\n  required_providers {\n    tidbcloud = {\n      source = \"tidbcloud/tidbcloud\"\n    }\n  }\n}\n\nprovider \"tidbcloud\" {\n  public_key = \"your_public_key\"\n  private_key = \"your_private_key\"\n  sync = true\n}\n\ndata \"tidbcloud_projects\" \"example_project\" {\n  page      = 1\n  page_size = 10\n}\n\noutput \"projects\" {\n  value = data.tidbcloud_projects.example_project.items\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring S3 Access Link for Minio\nDESCRIPTION: The S3-compatible access link for the configured Minio server, including endpoint, access key, secret key, and bucket information.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ns3://backup?access-key=minio&secret-access-key=miniostorage&endpoint=http://${HOST_IP}:6060&force-path-style=true\n```\n\n----------------------------------------\n\nTITLE: SQL Operator Precedence Definition\nDESCRIPTION: Lists SQL operators in order of precedence from highest to lowest. Shows which operators have equal precedence by grouping them on the same line. Includes arithmetic, logical, comparison, and special operators.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/operators.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nINTERVAL\nBINARY, COLLATE\n!\n- (unary minus), ~ (unary bit inversion)\n^\n*, /, DIV, %, MOD\n-, +\n<<, >>\n&\n|\n= (comparison), <=>, >=, >, <=, <, <>, !=, IS, LIKE, REGEXP, IN\nBETWEEN, CASE, WHEN, THEN, ELSE\nNOT\nAND, &&\nXOR\nOR, ||\n= (assignment), :=\n```\n\n----------------------------------------\n\nTITLE: Index Reader Query in TiDB\nDESCRIPTION: Query using IndexReader operator to read data when only indexed columns are needed\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nselect a from t where a=2\n```\n\n----------------------------------------\n\nTITLE: Defining CREATE USER Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the CREATE USER statement in TiDB, including options for authentication, connection limits, and account attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCreateUserStmt ::=\n    'CREATE' 'USER' IfNotExists UserSpecList RequireClauseOpt ConnectionOptions PasswordOption LockOption AttributeOption ResourceGroupNameOption\n\nIfNotExists ::=\n    ('IF' 'NOT' 'EXISTS')?\n\nUserSpecList ::=\n    UserSpec ( ',' UserSpec )*\n\nRequireClauseOpt ::=\n    ( 'REQUIRE' 'NONE' | 'REQUIRE' 'SSL' | 'REQUIRE' 'X509' | 'REQUIRE' RequireList )?\n\nRequireList ::=\n    ( \"ISSUER\" stringLit | \"SUBJECT\" stringLit | \"CIPHER\" stringLit | \"SAN\" stringLit | \"TOKEN_ISSUER\" stringLit )*\n\nUserSpec ::=\n    Username AuthOption\n\nAuthOption ::=\n    ( 'IDENTIFIED' ( 'BY' ( AuthString | 'PASSWORD' HashString ) | 'WITH' StringName ( 'BY' AuthString | 'AS' HashString )? ) )?\n\nStringName ::=\n    stringLit\n|   Identifier\n\nConnectionOptions ::=\n    ( 'WITH' 'MAX_USER_CONNECTIONS' N )?\n\nPasswordOption ::= ( 'PASSWORD' 'EXPIRE' ( 'DEFAULT' | 'NEVER' | 'INTERVAL' N 'DAY' )?\n| 'PASSWORD' 'HISTORY' ( 'DEFAULT' | N )\n| 'PASSWORD' 'REUSE' 'INTERVAL' ( 'DEFAULT' | N 'DAY' )\n| 'PASSWORD' 'REQUIRE' 'CURRENT' 'DEFAULT'\n| 'FAILED_LOGIN_ATTEMPTS' N\n| 'PASSWORD_LOCK_TIME' ( N | 'UNBOUNDED' ) )*\n\nLockOption ::= ( 'ACCOUNT' 'LOCK' | 'ACCOUNT' 'UNLOCK' )?\n\nAttributeOption ::= ( 'COMMENT' CommentString | 'ATTRIBUTE' AttributeString )?\n\nResourceGroupNameOption::= ( 'RESOURCE' 'GROUP' Identifier)?\n\nRequireClauseOpt ::= ('REQUIRE' ('NONE' | 'SSL' | 'X509' | RequireListElement ('AND'? RequireListElement)*))?\n\nRequireListElement ::= 'ISSUER' Issuer | 'SUBJECT' Subject | 'CIPHER' Cipher | 'SAN' SAN | 'TOKEN_ISSUER' TokenIssuer\n```\n\n----------------------------------------\n\nTITLE: Analyzing Query Execution Plan with Aggregate Pushdown\nDESCRIPTION: This SQL statement uses the `explain analyze` command to generate a detailed execution plan for a query that joins two tables (t1 and t2), filters the results based on a join condition (t1.a = t2.b), and then groups the results by t1.a and counts the occurrences. The execution plan shows how TiDB distributes the query execution across different components, including TiFlash, and provides performance statistics for each operator.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n\"mysql> explain analyze select count(*) from t1 join t2 where t1.a = t2.b group by t1.a;\\n+------------------------------------------------------+--------------+-----------+--------------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+--------+------+\\n| id                                                   | estRows      | actRows   | task         | access object | execution info                                                                                                                                                                                                                                                                                                                            | operator info                                                                                                                 | memory | disk |\\n+------------------------------------------------------+--------------+-----------+--------------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+--------+------+\\n| TableReader_85                                       | 20.00        | 20        | root         |               | time:432.4ms, loops:2, cop_task: {num: 19, max: 0s, min: 0s, avg: 0s, p95: 0s, copr_cache_hit_ratio: 0.00}                                                                                                                                                                                                                                | data:ExchangeSender_84                                                                                                        | N/A    | N/A  |\\n| └─ExchangeSender_84                                  | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:431.1ms, min:429.3ms, avg: 430.4ms, p80:431.1ms, p95:431.1ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                       | ExchangeType: PassThrough                                                                                                     | N/A    | N/A  |\\n|   └─Projection_83                                    | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:430.1ms, min:429.3ms, avg: 429.7ms, p80:430.1ms, p95:430.1ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                       | Column#43                                                                                                                     | N/A    | N/A  |\\n|     └─HashAgg_82                                     | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:430.1ms, min:429.3ms, avg: 429.7ms, p80:430.1ms, p95:430.1ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                       | group by:test.t1.a, funcs:count(Column#44)->Column#43, stream_count: 20                                                       | N/A    | N/A  |\\n|       └─ExchangeReceiver_78                          | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:430.1ms, min:429.3ms, avg: 429.7ms, p80:430.1ms, p95:430.1ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                       | stream_count: 20                                                                                                              | N/A    | N/A  |\\n|         └─ExchangeSender_77                          | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:427ms, min:0s, avg: 142.3ms, p80:427ms, p95:427ms, iters:60, tasks:3, threads:60}                                                                                                                                                                                                                                  | ExchangeType: HashPartition, Hash Cols: [name: test.t1.a, collate: binary], stream_count: 20                                  | N/A    | N/A  |\\n|           └─HashJoin_76                              | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:426ms, min:0s, avg: 142ms, p80:426ms, p95:426ms, iters:60, tasks:3, threads:60}                                                                                                                                                                                                                                    | inner join, equal:[eq(test.t1.a, test.t2.b)]                                                                                  | N/A    | N/A  |\\n|             ├─ExchangeReceiver_36(Build)             | 20.00        | 60        | mpp[tiflash] |               | tiflash_task:{proc max:374ms, min:0s, avg: 124.7ms, p80:374ms, p95:374ms, iters:46, tasks:3, threads:60}                                                                                                                                                                                                                                  |                                                                                                                               | N/A    | N/A  |\\n|             │ └─ExchangeSender_35                    | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:373.7ms, min:0s, avg: 124.6ms, p80:373.7ms, p95:373.7ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                            | ExchangeType: Broadcast                                                                                                       | N/A    | N/A  |\\n|             │   └─Projection_31                      | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:373.7ms, min:0s, avg: 124.6ms, p80:373.7ms, p95:373.7ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                            | Column#44, test.t2.b                                                                                                          | N/A    | N/A  |\\n|             │     └─HashAgg_32                       | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:373.7ms, min:0s, avg: 124.6ms, p80:373.7ms, p95:373.7ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                            | group by:test.t2.b, funcs:sum(Column#45)->Column#44, funcs:firstrow(test.t2.b)->test.t2.b, stream_count: 20                   | N/A    | N/A  |\n```\n\n----------------------------------------\n\nTITLE: Disabling Autocommit in TiDB\nDESCRIPTION: Examples of disabling autocommit behavior on a session or global level using the SET statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/transaction-overview.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET autocommit = 0;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL autocommit = 0;\n```\n\n----------------------------------------\n\nTITLE: IP Address Functions in TiDB\nDESCRIPTION: Examples of IP address conversion functions including INET_ATON(), INET_NTOA(), INET6_ATON(), INET6_NTOA(), and IP validation functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT INET_ATON('127.0.0.1');\n\nSELECT INET_NTOA(2130706433);\n\nSELECT INET6_ATON('::1');\n\nSELECT INET6_NTOA(0x00000000000000000000000000000001);\n\nSELECT IS_IPV4('127.0.0.1');\n\nSELECT IS_IPV4_COMPAT(INET6_ATON('::127.0.0.1'));\n```\n\n----------------------------------------\n\nTITLE: Inserting Valid Data with AUTO_INCREMENT and NOT NULL Fields\nDESCRIPTION: This example shows inserting a row where NULL is allowed for the AUTO_INCREMENT column, as TiDB will automatically generate a sequence number.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO users (id,age,last_login) VALUES (NULL,123,NOW());\n```\n\n----------------------------------------\n\nTITLE: Offline Cluster Upgrade Using TiUP\nDESCRIPTION: Perform an offline upgrade of the new TiDB cluster to the target version\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster stop <new_cluster_name>      # Stop the cluster\ntiup cluster upgrade <new_cluster_name> <v_target_version> --offline  # Perform offline upgrade\ntiup cluster start <new_cluster_name>     # Start the cluster\n```\n\n----------------------------------------\n\nTITLE: Cross-Database Execution Plan Binding in TiDB\nDESCRIPTION: Demonstrates creating a cross-database binding using wildcard syntax to apply execution plans across multiple databases with similar schemas\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.6.0.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE GLOBAL BINDING FOR\nUSING\n    SELECT /*+ merge_join(t1, t2) */ t1.id, t2.amount\n    FROM *.t1, *.t2\n    WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Assigning Expression Results to User-Defined Variables\nDESCRIPTION: Shows how to assign the result of an expression that uses other variables to a user-defined variable in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET @c = @a + @b;\n```\n\n----------------------------------------\n\nTITLE: Querying TiFlash Replicas in TiDB\nDESCRIPTION: This SQL query checks if any table has more TiFlash replicas than the number of TiFlash nodes after scale-in.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.tiflash_replica WHERE REPLICA_COUNT >  'tobe_left_nodes';\n```\n\n----------------------------------------\n\nTITLE: Sample Database Schema - JSON\nDESCRIPTION: This JSON snippet shows an example schema structure generated for a database-level DDL event, detailing the schema name, the query performed, and the version.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"Table\": \"\",\n  \"Schema\": \"schema1\",\n  \"Version\": 1,\n  \"TableVersion\": 441349361156227000,\n  \"Query\": \"CREATE DATABASE `schema1`\",\n  \"Type\": 1,\n  \"TableColumns\": null,\n  \"TableColumnsTotal\": 0\n}\n```\n\n----------------------------------------\n\nTITLE: Explain Analyze Query in TiDB\nDESCRIPTION: This SQL statement uses `EXPLAIN ANALYZE` to execute the specified query and provide detailed information about the execution plan, including actual execution times, row counts, and other statistics. It helps identify performance bottlenecks and inaccurate estimates within the query.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n\"EXPLAIN ANALYZE SELECT count(*) FROM trips WHERE start_date BETWEEN '2017-07-01 00:00:00' AND '2017-07-01 23:59:59';\"\n```\n\n----------------------------------------\n\nTITLE: Using TIDB_ROW_CHECKSUM to Calculate Row Checksum\nDESCRIPTION: Demonstrates using the TIDB_ROW_CHECKSUM function to calculate a checksum value for a specific row in the table. This can be useful for data integrity verification.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *, TIDB_ROW_CHECKSUM() FROM t WHERE id = 1;\n```\n\n----------------------------------------\n\nTITLE: Example JSON Response for Session Start\nDESCRIPTION: This JSON snippet shows a typical response from the `/v3/sessions` endpoint after a session is successfully started. It includes the session ID, creation timestamp, creator's email, organization ID, and the session name. This session ID is crucial for subsequent interactions with the Chat2Query API.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-sessions.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"code\": 200,\n    \"msg\": \"\",\n    \"result\": {\n    \"messages\": [],\n    \"meta\": {\n        \"created_at\": 1718948875, // A UNIX timestamp indicating when the session is created\n        \"creator\": \"<Your email>\", // The creator of the session\n        \"name\": \"<Your session name>\", // The name of the session\n        \"org_id\": \"1\", // The organization ID\n        \"updated_at\": 1718948875 // A UNIX timestamp indicating when the session is updated\n    },\n    \"session_id\": 305685 // The session ID\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying TIDB_SERVERS_INFO Table in SQL\nDESCRIPTION: This SQL query selects all columns from the TIDB_SERVERS_INFO table, displaying information about TiDB servers in the cluster including DDL ID, IP, ports, version, and other details.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-servers-info.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM TIDB_SERVERS_INFO\\G\n```\n\n----------------------------------------\n\nTITLE: Calculating SHA-1 Hash in SQL\nDESCRIPTION: The `SHA1(expr)` function computes a 160-bit SHA-1 hash for the provided expression.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SHA1('abc');\n```\n\n----------------------------------------\n\nTITLE: Querying Multiple Data Sources with Different Catalogs\nDESCRIPTION: Demonstrates reading and joining tables from different data sources like Hive and TiDB using Spark SQL catalogs\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n// Read from Hive\nspark.sql(\"select * from spark_catalog.default.t\").show\n\n// Join Hive tables and TiDB tables\nspark.sql(\"select t1.id,t2.id from spark_catalog.default.t t1 left join tidb_catalog.test.t t2\").show\n```\n\n----------------------------------------\n\nTITLE: Alter a resource group to kill runaway queries and watch similar queries\nDESCRIPTION: This SQL statement alters the existing resource group 'rg1' to terminate runaway queries that exceed 60 seconds (ACTION=KILL). Additionally, it configures a watch (WATCH=SIMILAR) that, for the next 10 minutes (DURATION='10m'), will immediately mark and terminate any queries with a similar pattern to identified runaway queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\n\"ALTER RESOURCE GROUP rg1 QUERY_LIMIT=(EXEC_ELAPSED='60s', ACTION=KILL, WATCH=SIMILAR DURATION='10m');\"\n```\n\n----------------------------------------\n\nTITLE: Getting Export Information in Non-Interactive Mode using Shell Command\nDESCRIPTION: This snippet shows how to fetch export information from a TiDB Cloud Serverless cluster in non-interactive mode by specifying required flags. Users must provide the cluster ID and export ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-describe.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export describe -c <cluster-id> -e <export-id>\n```\n\n----------------------------------------\n\nTITLE: Disabling TiDB Workload Repository\nDESCRIPTION: SQL command to disable the Workload Repository by clearing the destination variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/workload-repository.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_workload_repository_dest = '';\n```\n\n----------------------------------------\n\nTITLE: Using Roles in TiDB\nDESCRIPTION: SQL commands demonstrating how to use roles, including showing grants, setting roles, and querying tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-role.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS;\nSHOW TABLES in test;\nSET ROLE analyticsteam;\nSHOW GRANTS;\nSHOW TABLES IN test;\n```\n\n----------------------------------------\n\nTITLE: Using HASH_AGG Hint for Aggregation in SQL\nDESCRIPTION: Uses the HASH_AGG hint to force the optimizer to use the hash aggregation algorithm for all aggregate functions. This allows concurrent execution with multiple threads for higher speed but consumes more memory.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ HASH_AGG() */ count(*) from t1, t2 where t1.a > 10 group by t1.id;\n```\n\n----------------------------------------\n\nTITLE: Analyze Table and Explain Analyze in TiDB\nDESCRIPTION: This SQL code first analyzes the `trips` table to update statistics, then uses `EXPLAIN ANALYZE` to execute the count query and display its execution plan with updated estimates. This helps to see the impact of updated statistics on the query plan and performance estimates.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n\"ANALYZE TABLE trips;\\nEXPLAIN ANALYZE SELECT count(*) FROM trips WHERE start_date BETWEEN '2017-07-01 00:00:00' AND '2017-07-01 23:59:59';\"\n```\n\n----------------------------------------\n\nTITLE: Unicode Collation Comparison for German Characters\nDESCRIPTION: SQL query comparing German character 'ß' with 'ss' using different Unicode collations to demonstrate collation strictness.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  'ss' COLLATE utf8mb4_general_ci = 'ß',\n  'ss' COLLATE utf8mb4_unicode_ci = 'ß',\n  'ss' COLLATE utf8mb4_0900_ai_ci = 'ß',\n  'ss' COLLATE utf8mb4_0900_bin = 'ß'\n\\G\n```\n\n----------------------------------------\n\nTITLE: Viewing Execution Plan for TiDB Query - SQL\nDESCRIPTION: This SQL snippet displays the execution plan for a query on the 'tidb_query_duration' table. It shows details such as estimated rows and operators used in the plan, confirming the time step change to 30 seconds.\nSOURCE: https://github.com/pingcap/docs/blob/master/metrics-schema.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\ndesc select * from metrics_schema.tidb_query_duration where value is not null and time>='2020-03-25 23:40:00' and time <= '2020-03-25 23:42:00' and quantile=0.99;\n```\n\n----------------------------------------\n\nTITLE: Adding a watch list item with similar SQL matching\nDESCRIPTION: This code snippet adds a watch item to the `rg1` resource group. The SQL is parsed into SQL Digest for matching using the `SIMILAR` option. If `ACTION` is not specified, it uses the configured `ACTION` for the `rg1` resource group.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n\"QUERY WATCH ADD RESOURCE GROUP rg1 SQL TEXT SIMILAR TO 'select * from test.t2';\"\n```\n\n----------------------------------------\n\nTITLE: Query Result for Correlated Subquery With NO_DECORRELATE Hint in SQL\nDESCRIPTION: Shows the execution plan for the correlated subquery with the NO_DECORRELATE hint. The optimizer maintains the Apply operator rather than performing decorrelation, preserving the original filter condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------------------+-----------+-----------+------------------------+--------------------------------------------------------------------------------------+\n| id                                       | estRows   | task      | access object          | operator info                                                                        |\n+------------------------------------------+-----------+-----------+------------------------+--------------------------------------------------------------------------------------+\n| Projection_10                            | 10000.00  | root      |                        | test.t1.a, test.t1.b                                                                 |\n| └─Apply_12                               | 10000.00  | root      |                        | CARTESIAN inner join, other cond:lt(cast(test.t1.a, decimal(10,0) BINARY), Column#7) |\n|   ├─TableReader_14(Build)                | 10000.00  | root      |                        | data:TableFullScan_13                                                                |\n|   │ └─TableFullScan_13                   | 10000.00  | cop[tikv] | table:t1               | keep order:false, stats:pseudo                                                       |\n|   └─MaxOneRow_15(Probe)                  | 10000.00  | root      |                        |                                                                                      |\n|     └─StreamAgg_20                       | 10000.00  | root      |                        | funcs:sum(Column#14)->Column#7                                                       |\n|       └─Projection_45                    | 100000.00 | root      |                        | cast(test.t2.a, decimal(10,0) BINARY)->Column#14                                     |\n|         └─IndexLookUp_44                 | 100000.00 | root      |                        |                                                                                      |\n|           ├─IndexRangeScan_42(Build)     | 100000.00 | cop[tikv] | table:t2, index:idx(b) | range: decided by [eq(test.t2.b, test.t1.b)], keep order:false, stats:pseudo         |\n|           └─TableRowIDScan_43(Probe)     | 100000.00 | cop[tikv] | table:t2               | keep order:false, stats:pseudo                                                       |\n+------------------------------------------+-----------+-----------+------------------------+--------------------------------------------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: TiCDC Changefeed Configuration\nDESCRIPTION: TOML configuration for TiCDC changefeed to enable consistent replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\n[consistent]\nlevel = \"eventual\"\nstorage = \"s3://redo?access-key=minio&secret-access-key=miniostorage&endpoint=http://172.16.6.125:6060&force-path-style=true\"\n```\n\n----------------------------------------\n\nTITLE: Updating Player Data in TiDB using Java and MySQL Connector/J\nDESCRIPTION: This snippet shows how to update player data in a TiDB database using Java and MySQL Connector/J. It establishes a connection, prepares an UPDATE statement with parameters, and executes the update operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-jdbc.md#2025-04-18_snippet_3\n\nLANGUAGE: java\nCODE:\n```\npublic void updatePlayer(String id, int amount, int price) throws SQLException {\n    MysqlDataSource mysqlDataSource = getMysqlDataSourceByEnv();\n    try (Connection connection = mysqlDataSource.getConnection()) {\n        PreparedStatement transfer = connection.prepareStatement(\"UPDATE player SET goods = goods + ?, coins = coins + ? WHERE id=?\");\n        transfer.setInt(1, -amount);\n        transfer.setInt(2, price);\n        transfer.setString(3, id);\n        transfer.execute();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Data in TiDB (TypeScript)\nDESCRIPTION: Updates the coins and goods for a Player with a specific ID. Uses a prepared statement to safely update multiple fields.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nconst [rsh] = await pool.query(\n    'UPDATE players SET coins = coins + ?, goods = goods + ? WHERE id = ?;',\n    [50, 50, 1]\n);\nconsole.log(rsh.affectedRows);\n```\n\n----------------------------------------\n\nTITLE: Unsetting tidb_read_staleness in TiDB SQL\nDESCRIPTION: Resets the tidb_read_staleness system variable to an empty string, which returns the session to reading the latest data instead of historical data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-read-staleness.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nset @@tidb_read_staleness=\"\";\n```\n\n----------------------------------------\n\nTITLE: Configuring LOAD DATA Transaction Size in TiDB\nDESCRIPTION: This SQL snippet demonstrates how to set the transaction size for LOAD DATA operations using the tidb_dml_batch_size parameter. This optimization allows for better control over duplicate value checks based on transaction size.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-beta.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_dml_batch_size = 20000;\n```\n\n----------------------------------------\n\nTITLE: Aggregating Values into a JSON Array in SQL - TiDB\nDESCRIPTION: The snippet demonstrates how to use the JSON_ARRAYAGG function to aggregate values from a column into a JSON array format. It aggregates inputs based on a specified key and returns them as a single JSON array. This is useful for transforming multiple row values into a single JSON structure.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-aggregate.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_ARRAYAGG(v) FROM (SELECT 1 'v' UNION SELECT 2);\n```\n\n----------------------------------------\n\nTITLE: Batch Insert Using Prepared Statements in Java\nDESCRIPTION: Implementation of efficient batch insert operations using prepared statements in Java to avoid repeated SQL parsing overhead.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql-best-practices.md#2025-04-18_snippet_2\n\nLANGUAGE: java\nCODE:\n```\npublic void batchInsert(Connection connection) throws SQLException {\n    PreparedStatement statement = connection.prepareStatement(\n            \"INSERT INTO `t` (`id`) VALUES (?), (?), (?), (?), (?)\");\n    for (int i = 0; i < 1000; i ++) {\n        statement.setInt(i % 5 + 1, i);\n\n        if (i % 5 == 4) {\n            statement.executeUpdate();\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_parallel_apply in TiDB\nDESCRIPTION: Enables concurrency for the Apply operator, enhancing execution speed for correlated subqueries. Default is OFF, with a control mechanism using the tidb_executor_concurrency variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_35\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): No\n- Type: Boolean\n- Default value: `OFF`\n- This variable controls whether to enable concurrency for the `Apply` operator.\n```\n\n----------------------------------------\n\nTITLE: Filtering data with WHERE clause in Dumpling\nDESCRIPTION: Uses the --where option to export only data that matches a specific SQL expression condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntiup dumpling -u root -P 4000 -h 127.0.0.1 -o /tmp/test --where \"id < 100\"\n```\n\n----------------------------------------\n\nTITLE: Configure TiDB Lightning in TOML\nDESCRIPTION: This snippet provides an example of a TiDB Lightning global configuration in TOML format. The configuration includes settings such as HTTP port for web interface and log details. Key fields include 'status-addr' for setting the HTTP port and various logging parameters. Users must ensure the configuration file is placed in the correct directory on the relevant node. Outputs include logs and metrics as configured, and users must adhere to proper indentation rules when editing.\nSOURCE: https://github.com/pingcap/docs/blob/master/resources/doc-templates/template-task.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n### tidb-lightning global configuration\n\n[lightning]\n# The HTTP port used to pull the web interface and Prometheus metrics. Set to 0 to disable the port.\nstatus-addr = ':8289'\n\n# Switch to server mode and use the web interface\n# For details, see the \"TiDB Lightning Web UI\" document.\nserver-mode = false\n\n# log\nlevel = \"info\"\nfile = \"tidb-lightning.log\"\nmax-size = 128 # MB\nmax-days = 28\nmax-backups = 14\n\n```\n\n----------------------------------------\n\nTITLE: Basic Multi-valued Index Creation and Query Examples\nDESCRIPTION: Examples showing the creation of a multi-valued index on a JSON column and different query patterns using IndexMerge with various JSON functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (j JSON, INDEX idx((CAST(j->'$.path' AS SIGNED ARRAY)))); -- Uses '$.path' as the path to create a multi-valued index\nQuery OK, 0 rows affected (0.04 sec)\n\nmysql> EXPLAIN SELECT /*+ use_index_merge(t1, idx) */ * FROM t1 WHERE (1 MEMBER OF (j->'$.path'));\n+---------------------------------+---------+-----------+-----------------------------------------------------------------------------+------------------------------------------------------------------------+\n| id                              | estRows | task      | access object                                                               | operator info                                                          |\n+---------------------------------+---------+-----------+-----------------------------------------------------------------------------+------------------------------------------------------------------------+\n| Selection_5                     | 8000.00 | root      |                                                                             | json_memberof(cast(1, json BINARY), json_extract(test.t1.j, \"$.path\")) |\n| └─IndexMerge_8                  | 10.00   | root      |                                                                             | type: union                                                            |\n|   ├─IndexRangeScan_6(Build)     | 10.00   | cop[tikv] | table:t1, index:idx(cast(json_extract(`j`, _utf8'$.path') as signed array)) | range:[1,1], keep order:false, stats:pseudo                            |\n|   └─TableRowIDScan_7(Probe)     | 10.00   | cop[tikv] | table:t1                                                                    | keep order:false, stats:pseudo                                         |\n+---------------------------------+---------+-----------+-----------------------------------------------------------------------------+------------------------------------------------------------------------+\n4 rows in set, 1 warning (0.00 sec)\n\nmysql> EXPLAIN SELECT /*+ use_index_merge(t1, idx) */ * FROM t1 WHERE JSON_CONTAINS((j->'$.path'), '[1, 2, 3]');\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------+---------------------------------------------+\n| id                            | estRows | task      | access object                                                               | operator info                               |\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------+---------------------------------------------+\n| IndexMerge_9                  | 10.00   | root      |                                                                             | type: intersection                          |\n| ├─IndexRangeScan_5(Build)     | 10.00   | cop[tikv] | table:t1, index:idx(cast(json_extract(`j`, _utf8'$.path') as signed array)) | range:[1,1], keep order:false, stats:pseudo |\n| ├─IndexRangeScan_6(Build)     | 10.00   | cop[tikv] | table:t1, index:idx(cast(json_extract(`j`, _utf8'$.path') as signed array)) | range:[2,2], keep order:false, stats:pseudo |\n| ├─IndexRangeScan_7(Build)     | 10.00   | cop[tikv] | table:t1, index:idx(cast(json_extract(`j`, _utf8'$.path') as signed array)) | range:[3,3], keep order:false, stats:pseudo |\n| └─TableRowIDScan_8(Probe)     | 10.00   | cop[tikv] | table:t1                                                                    | keep order:false, stats:pseudo              |\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------+---------------------------------------------+\n5 rows in set (0.00 sec)\n\nmysql> EXPLAIN SELECT /*+ use_index_merge(t1, idx) */ * FROM t1 WHERE JSON_OVERLAPS((j->'$.path'), '[1, 2, 3]');\n+---------------------------------+---------+-----------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------------+\n| id                              | estRows | task      | access object                                                               | operator info                                                                    |\n+---------------------------------+---------+-----------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------------+\n| Selection_5                     | 8000.00 | root      |                                                                             | json_overlaps(json_extract(test.t1.j, \"$.path\"), cast(\"[1, 2, 3]\", json BINARY)) |\n| └─IndexMerge_10                 | 10.00   | root      |                                                                             | type: union                                                                      |\n|   ├─IndexRangeScan_6(Build)     | 10.00   | cop[tikv] | table:t1, index:idx(cast(json_extract(`j`, _utf8'$.path') as signed array)) | range:[1,1], keep order:false, stats:pseudo                                      |\n|   ├─IndexRangeScan_7(Build)     | 10.00   | cop[tikv] | table:t1, index:idx(cast(json_extract(`j`, _utf8'$.path') as signed array)) | range:[2,2], keep order:false, stats:pseudo                                      |\n|   ├─IndexRangeScan_8(Build)     | 10.00   | cop[tikv] | table:t1, index:idx(cast(json_extract(`j`, _utf8'$.path') as signed array)) | range:[3,3], keep order:false, stats:pseudo                                      |\n|   └─TableRowIDScan_9(Probe)     | 10.00   | cop[tikv] | table:t1                                                                    | keep order:false, stats:pseudo                                                   |\n+---------------------------------+---------+-----------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------------+\n6 rows in set, 1 warning (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a Partitioned Table with Global Indexes in TiDB\nDESCRIPTION: This SQL snippet demonstrates how to create a partitioned table with global and local indexes in TiDB. It shows the syntax for specifying global unique and non-unique indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_62\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t1 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    UNIQUE KEY uidx12(col1, col2) GLOBAL,\n    UNIQUE KEY uidx3(col3),\n    KEY idx1(col1) GLOBAL\n)\nPARTITION BY HASH(col3)\nPARTITIONS 4;\n```\n\n----------------------------------------\n\nTITLE: Creating Table with UTF8MB4 Collation\nDESCRIPTION: Example of creating a table with UTF8MB4 character set and general case-insensitive collation, demonstrating collation configuration at table level.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a varchar(20) charset utf8mb4 collate utf8mb4_general_ci PRIMARY KEY);\n```\n\n----------------------------------------\n\nTITLE: Disabling Batch Create Table in TiDB BR Restore Command\nDESCRIPTION: This command demonstrates how to disable the Batch Create Table feature by setting --ddl-batch-size to 1 when using the TiUP br restore command.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-batch-create-table.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full \\\n--storage local:///br_data/ --pd \"${PD_IP}:2379\" --log-file restore.log \\\n--ddl-batch-size=1\n```\n\n----------------------------------------\n\nTITLE: Ignoring Checkpoint Errors in TiDB Lightning with Shell\nDESCRIPTION: This shell snippet allows users to ignore errors in checkpoint records of TiDB Lightning. Users are advised to only use this when certain errors can be ignored to prevent data loss, with a reliance on final checksum checks for accuracy.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-checkpoints.md#2025-04-18_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ntidb-lightning-ctl --checkpoint-error-ignore='`schema`.`table`'\ntidb-lightning-ctl --checkpoint-error-ignore=all\n```\n\n----------------------------------------\n\nTITLE: Demonstrating tidb_constraint_check_in_place_pessimistic=OFF with Pessimistic Transactions in SQL\nDESCRIPTION: This example shows how setting tidb_constraint_check_in_place_pessimistic to OFF with pessimistic transactions defers uniqueness checking until transaction commit time, temporarily allowing conflicting inserts.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_constraint_check_in_place_pessimistic=OFF;\ncreate table t (i int key);\ninsert into t values (1);\nbegin pessimistic;\ninsert into t values (1);\n\nQuery OK, 1 row affected\n\ntidb> commit; -- Check only when a transaction is committed.\n\nERROR 1062 : Duplicate entry '1' for key 't.PRIMARY'\n```\n\n----------------------------------------\n\nTITLE: Encoding a Database Password with Base64\nDESCRIPTION: This command encodes a database password using Base64. Encoding passwords is a recommended practice for securing credentials in the configuration of sink URIs for replication tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-mysql.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\necho -n '12345678' | base64   # '12345678' is the password to be encoded.\n```\n\nLANGUAGE: shell\nCODE:\n```\nMTIzNDU2Nzg=\n```\n\n----------------------------------------\n\nTITLE: Creating Range and List Partitioned Tables in SQL\nDESCRIPTION: SQL statements to create example RANGE and LIST partitioned tables for members and member levels.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_35\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE members (\n    id int,\n    fname varchar(255),\n    lname varchar(255),\n    dob date,\n    data json\n)\nPARTITION BY RANGE (YEAR(dob)) (\n PARTITION pBefore1950 VALUES LESS THAN (1950),\n PARTITION p1950 VALUES LESS THAN (1960),\n PARTITION p1960 VALUES LESS THAN (1970),\n PARTITION p1970 VALUES LESS THAN (1980),\n PARTITION p1980 VALUES LESS THAN (1990),\n PARTITION p1990 VALUES LESS THAN (2000));\n\nCREATE TABLE member_level (\n id int,\n level int,\n achievements json\n)\nPARTITION BY LIST (level) (\n PARTITION l1 VALUES IN (1),\n PARTITION l2 VALUES IN (2),\n PARTITION l3 VALUES IN (3),\n PARTITION l4 VALUES IN (4),\n PARTITION l5 VALUES IN (5));\n```\n\n----------------------------------------\n\nTITLE: Checking TiDB Cluster Status Using TiUP Command\nDESCRIPTION: This snippet demonstrates how to use the TiUP command to display the status of a specified TiDB cluster. It helps in determining if the cluster is running normally by checking the status of each node.\nSOURCE: https://github.com/pingcap/docs/blob/master/post-installation-check.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster display tidb-test\n```\n\n----------------------------------------\n\nTITLE: Creating a Table Schema in SQL for TiDB Cloud Parquet Import\nDESCRIPTION: A SQL statement to create a table schema in TiDB Cloud. This table schema file should be named 'mydb.mytable-schema.sql' and placed in the same Amazon S3 or GCS directory as the Parquet files to be imported.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-parquet-files.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE mytable (\nID INT,\nREGION VARCHAR(20),\nCOUNT INT );\n```\n\n----------------------------------------\n\nTITLE: Using 'NEXT VALUE FOR' Syntax with Sequence\nDESCRIPTION: Demonstrates an alternative syntax for getting the next value of a sequence using 'NEXT VALUE FOR'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-sequence.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT next value for seq;\n```\n\n----------------------------------------\n\nTITLE: Enabling Follower Read in SQL\nDESCRIPTION: Sets the tidb_replica_read variable to enable Follower Read for the current session or globally.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-follower-read.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET [GLOBAL] tidb_replica_read = 'follower';\n```\n\n----------------------------------------\n\nTITLE: Configuring PD for TiKV Label Levels in Three AZs\nDESCRIPTION: YAML configuration snippet for setting up Placement Driver (PD) with TiKV label levels for a three availability zone deployment. This configuration helps PD manage and schedule TiKV instances across different zones.\nSOURCE: https://github.com/pingcap/docs/blob/master/three-data-centers-in-two-cities-deployment.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  pd:\n    replication.location-labels: [\"az\",\"replication zone\",\"rack\",\"host\"]\n```\n\n----------------------------------------\n\nTITLE: Executing TRACE with JSON Format in TiDB SQL\nDESCRIPTION: Example of using the TRACE statement with 'json' format to analyze a SELECT query execution on the mysql.user table. The JSON output can be used with the TiDB trace viewer for graphical analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-trace.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nTRACE FORMAT='json' SELECT * FROM mysql.user;\n```\n\n----------------------------------------\n\nTITLE: Using SQL Assignment Operators\nDESCRIPTION: This snippet shows how to use assignment operators in SQL, specifically the '=' and ':=' operators. These are typically used in SET statements or UPDATE clauses to assign values to variables or columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/operators.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSET @variable = 'value';\nUPDATE table SET column = 'new_value' WHERE condition;\nSET @another_variable := 'another_value';\n```\n\n----------------------------------------\n\nTITLE: SQL Statement: LOAD DATA Enhancement\nDESCRIPTION: TiDB extends LOAD DATA functionality to support data import from cloud storage services like S3 and GCS, improving data loading capabilities\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.0.0.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nLOAD DATA\n```\n\n----------------------------------------\n\nTITLE: Connection Pool Size Formula for SSD Systems\nDESCRIPTION: Recommended formula for calculating connection pool size when using solid-state drives (SSD). This simplified formula is based on CPU core count.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nconnections = (number of cores * 4)\n```\n\n----------------------------------------\n\nTITLE: Querying CHARACTER_SETS Table Contents\nDESCRIPTION: Demonstrates how to retrieve all character set information from the CHARACTER_SETS table, showing character set names, default collations, descriptions, and maximum lengths.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-character-sets.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM `CHARACTER_SETS`;\n```\n\n----------------------------------------\n\nTITLE: Querying Batch-Dividing Statement SQL\nDESCRIPTION: This snippet demonstrates querying the batch-dividing statement during the execution of a non-transactional DML operation in TiDB. The usage of 'DRY RUN QUERY' prevents the execution of further DML operations and outputs the query statement used for batch division. Dependencies: TiDB database. Parameters: Batch size set by 'LIMIT'. Outputs: SQL query used for selecting the set of IDs. Ensures the non-execution of subsequent DML operations for analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nBATCH ON id LIMIT 2 DRY RUN QUERY DELETE FROM t WHERE v < 6;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------------------------------------------------------------+\n| query statement                                                                |\n+--------------------------------------------------------------------------------+\n| SELECT `id` FROM `test`.`t` WHERE (`v` < 6) ORDER BY IF(ISNULL(`id`),0,1),`id` |\n+--------------------------------------------------------------------------------+\n1 row in set\n```\n\n----------------------------------------\n\nTITLE: Querying Index Usage Statistics in TiDB\nDESCRIPTION: These code snippets show the SQL tables and views introduced in TiDB 8.0.0 for monitoring index usage statistics, which helps in assessing index efficiency and optimizing index design.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nINFORMATION_SCHEMA.TIDB_INDEX_USAGE\n```\n\nLANGUAGE: sql\nCODE:\n```\nsys.schema_unused_indexes\n```\n\n----------------------------------------\n\nTITLE: Collecting Statistics on All Columns and Indexes in TiDB\nDESCRIPTION: SQL syntax for collecting statistics on all columns and indexes in a table. This is the most comprehensive statistics collection command but may cause higher overhead.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE TableName ALL COLUMNS [WITH NUM BUCKETS|TOPN|CMSKETCH DEPTH|CMSKETCH WIDTH]|[WITH NUM SAMPLES|WITH FLOATNUM SAMPLERATE];\n```\n\n----------------------------------------\n\nTITLE: Analyzing HashJoinV1 Operator Execution in TiDB\nDESCRIPTION: This snippet shows the execution information for the `HashJoin` operator V1 in TiDB. It includes metrics for build hash table (total, fetch, build) and probe (concurrency, total, max, probe, fetch). Analyzing these metrics helps in identifying performance bottlenecks during hash join operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_8\n\nLANGUAGE: None\nCODE:\n```\n\"build_hash_table:{total:146.071334ms, fetch:110.338509ms, build:35.732825ms}, probe:{concurrency:5, total:857.162518ms, max:171.48271ms, probe:125.341665ms, fetch:731.820853ms}\"\n```\n\n----------------------------------------\n\nTITLE: Disabling Decorrelation via Rule Blacklist in TiDB\nDESCRIPTION: Shows how to disable the decorrelation optimization globally by adding it to the optimizer rule blacklist.\nSOURCE: https://github.com/pingcap/docs/blob/master/correlated-subquery-optimization.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\ninsert into mysql.opt_rule_blacklist values(\"decorrelate\");\nadmin reload opt_rule_blacklist;\nexplain select * from t1 where t1.a < (select sum(t2.a) from t2 where t2.b = t1.b);\n```\n\n----------------------------------------\n\nTITLE: Adding Vector Index to Existing Table in TiDB\nDESCRIPTION: Multiple ways to create a vector index on an existing table that already has a vector column, with options for explicitly specifying the HNSW algorithm.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-index.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE VECTOR INDEX idx_embedding ON foo ((VEC_COSINE_DISTANCE(embedding)));\nALTER TABLE foo ADD VECTOR INDEX idx_embedding ((VEC_COSINE_DISTANCE(embedding)));\n\n-- You can also explicitly specify \"USING HNSW\" to build the vector search index.\nCREATE VECTOR INDEX idx_embedding ON foo ((VEC_COSINE_DISTANCE(embedding))) USING HNSW;\nALTER TABLE foo ADD VECTOR INDEX idx_embedding ((VEC_COSINE_DISTANCE(embedding))) USING HNSW;\n```\n\n----------------------------------------\n\nTITLE: Showing Create Table for tidb_query_duration\nDESCRIPTION: This snippet executes a SQL command to show the creation statement of the `tidb_query_duration` table in `metrics_schema`. It defines the structure of the table including its columns and data types, essential for understanding how to interact with the monitoring data.\nSOURCE: https://github.com/pingcap/docs/blob/master/metrics-schema.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE metrics_schema.tidb_query_duration;\n```\n\n----------------------------------------\n\nTITLE: Validating UUIDs with IS_UUID() in SQL\nDESCRIPTION: This function tests whether the given argument is a valid UUID. It returns 1 if the argument is a valid UUID, otherwise 0.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT IS_UUID('eb48c08c-eb71-11ee-bacf-5405db7aad56');\n```\n\n----------------------------------------\n\nTITLE: Using AUTO_RANDOM in TiDB SQL\nDESCRIPTION: Support for the `AUTO_RANDOM` feature in TiDB, allowing automatic generation of random IDs. This includes caching for retrying statements and recovering tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.1.0-rc.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t (id BIGINT AUTO_RANDOM);\n```\n\n----------------------------------------\n\nTITLE: Setting Global Memory Limits for TiDB\nDESCRIPTION: This SQL code snippet sets the global memory limit and garbage collection trigger for the TiDB server. This configuration helps to optimize memory usage and prevent frequent garbage collection cycles, which can improve import efficiency, especially during Global Sort operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_server_memory_limit_gc_trigger=1;\nSET GLOBAL tidb_server_memory_limit='75%';\n```\n\n----------------------------------------\n\nTITLE: Setting SQL Mode in TiDB\nDESCRIPTION: This SQL snippet demonstrates how to set the SQL mode for either a session or globally in TiDB. Requires SUPER privilege for global settings. The 'modes' parameter should be a comma-separated list of desired SQL modes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-mode.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET [ SESSION | GLOBAL ] sql_mode='modes';\n```\n\n----------------------------------------\n\nTITLE: Backing Up Specific Tables in TiDB\nDESCRIPTION: Examples showing how to back up individual tables or multiple tables to local storage in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-backup.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP TABLE `test`.`sbtest01` TO 'local:///mnt/backup/sbtest01/';\n```\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP TABLE sbtest02, sbtest03, sbtest04 TO 'local:///mnt/backup/sbtest/';\n```\n\n----------------------------------------\n\nTITLE: Executing CASE Statements in SQL\nDESCRIPTION: The CASE operator in SQL performs conditional logic to generate custom results based on the conditions specified. Dependencies include SQL databases such as TiDB that support control flow functions. It evaluates conditions in the order specified and returns a result corresponding to the first true condition, otherwise returns a default result.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/control-flow-functions.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCASE\n    WHEN condition1 THEN result1\n    WHEN condition2 THEN result2\n    ...\n    ELSE default_result\nEND\n```\n\nLANGUAGE: sql\nCODE:\n```\nWITH RECURSIVE d AS (SELECT 1 AS n UNION ALL SELECT n+1 FROM d WHERE n<10)\nSELECT n, CASE WHEN n MOD 2 THEN \"odd\" ELSE \"even\" END FROM d;\n```\n\n----------------------------------------\n\nTITLE: Creating Changefeed in TiDB Cluster\nDESCRIPTION: This shell command creates a changefeed for replicating data between primary and secondary TiDB clusters. It requires TiCDC, server address, and sink URI parameters and optionally uses start timestamps.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc cli changefeed create --server=http://10.1.1.9:8300 \\\n--sink-uri=\"mysql://{username}:{password}@10.1.1.4:4000\" \\\n--changefeed-id=\"dr-primary-to-secondary\" --start-ts=\"431434047157698561\"\n```\n\n----------------------------------------\n\nTITLE: Disabling Garbage Collection in TiDB\nDESCRIPTION: This SQL snippet is used to disable garbage collection (GC) in the primary TiDB cluster to prevent the deletion of historical data during the backup process. It is critical to ensure data integrity during migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_enable=FALSE;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@global.tidb_gc_enable;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------+\n| @@global.tidb_gc_enable |\n+-------------------------+\n|                       0 |\n+-------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into a Local Temporary Table\nDESCRIPTION: Demonstrates inserting data into a local temporary table in a session, ensuring that the data is session-specific and does not conflict with other sessions.\nSOURCE: https://github.com/pingcap/docs/blob/master/temporary-tables.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO users(id, name, city) VALUES(1001, 'Davis', 'LosAngeles');\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Self-Managed Connection String\nDESCRIPTION: Creates a .env file with the connection string for a self-managed TiDB cluster, specifying user, password, host, port, and database.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-python.md#2025-04-18_snippet_2\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_DATABASE_URL=\"mysql+pymysql://<USER>:<PASSWORD>@<HOST>:<PORT>/<DATABASE>\"\n# For example: TIDB_DATABASE_URL=\"mysql+pymysql://root@127.0.0.1:4000/test\"\n```\n\n----------------------------------------\n\nTITLE: Defining ADMIN CHECK Syntax in EBNF for TiDB SQL\nDESCRIPTION: This EBNF snippet defines the syntax for the ADMIN CHECK statement in TiDB, including options for checking tables or indexes with optional handle ranges.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-check-table-index.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nAdminCheckStmt ::=\n    'ADMIN' 'CHECK' ( 'TABLE' TableNameList | 'INDEX' TableName Identifier ( HandleRange ( ',' HandleRange )* )? ) \n\nTableNameList ::=\n    TableName ( ',' TableName )*\n\nHandleRange ::= '(' Int64Num ',' Int64Num ')'\n```\n\n----------------------------------------\n\nTITLE: Configuring Full Import Migration Task in YAML\nDESCRIPTION: YAML configuration for creating a full mode migration task in DM. It specifies the target database, source details, and mydumper settings for optimized data export.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-performance-test.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n---\nname: test-full\ntask-mode: full\n\ntarget-database:\n  host: \"192.168.0.1\"\n  port: 4000\n  user: \"root\"\n  password: \"\"\n\nmysql-instances:\n  -\n    source-id: \"source-1\"\n    block-allow-list:  \"instance\"\n    mydumper-config-name: \"global\"\n    loader-thread: 16\n\nblock-allow-list:\n  instance:\n    do-dbs: [\"dm_benchmark\"]\n\nmydumpers:\n  global:\n    rows: 32000\n    threads: 32\n```\n\n----------------------------------------\n\nTITLE: SHOW TRAFFIC JOBS SQL Statement Syntax\nDESCRIPTION: Demonstrates the EBNF syntax for the SHOW TRAFFIC JOBS statement in TiDB. This statement allows users to view traffic capture or replay jobs executed by TiProxy in the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-traffic-jobs.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nTrafficStmt ::=\n    \"SHOW\" \"TRAFFIC\" \"JOBS\"\n```\n\n----------------------------------------\n\nTITLE: Local INFILE example\nDESCRIPTION: This example demonstrates how to use the LOAD DATA LOCAL INFILE statement to load data from a local file into a TiDB table. It specifies the field delimiter as a comma, the enclosing character as a double quote, and ignores the first line of the file.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-load-data.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nLOAD DATA LOCAL INFILE '/mnt/evo970/data-sets/bikeshare-data/2017Q4-capitalbikeshare-tripdata.csv' INTO TABLE trips FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\\r\\n' IGNORE 1 LINES (duration, start_date, end_date, start_station_number, start_station, end_station_number, end_station, bike_number, member_type);\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Composite Primary Key for Shard Merging\nDESCRIPTION: SQL schema showing how to use composite primary keys to handle auto-increment conflicts during shard merging. The example converts a single column primary key to a composite primary key using an additional UUID column.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/shard-merge-best-practices.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `tbl_multi_pk` (\n  `auto_pk_c1` bigint NOT NULL,\n  `uuid_c2` bigint NOT NULL,\n  `content_c3` text,\n  PRIMARY KEY (`auto_pk_c1`)\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `tbl_multi_pk_c2` (\n  `auto_pk_c1` bigint NOT NULL,\n  `uuid_c2` bigint NOT NULL,\n  `content_c3` text,\n  PRIMARY KEY (`auto_pk_c1`,`uuid_c2`)\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\n```\n\n----------------------------------------\n\nTITLE: Viewing TiUP Cluster Audit Logs\nDESCRIPTION: Commands for viewing cluster operation audit logs using the tiup cluster audit command. Shows both listing all audits and viewing specific audit details by ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster audit\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster audit 4BLhr0\n```\n\n----------------------------------------\n\nTITLE: Updating Author Name in SQL\nDESCRIPTION: Example of updating an author's name in the authors table using an UPDATE statement with a WHERE clause to filter by ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-update-data.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE `authors` SET `name` = \"Helen Haruki\" WHERE `id` = 1;\n```\n\n----------------------------------------\n\nTITLE: Querying using AND with json_contains for IndexMerge in TiDB\nDESCRIPTION: Execution plan showing how TiDB uses IndexMerge with 'intersection' type for conditions connected with AND. Each json_contains condition is evaluated using a separate index range scan.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1) */ * FROM t4 WHERE json_contains(j->'$.a', '[1, 2]') AND json_contains(j->'$.a', '[3, 4]');\n```\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------+---------------------------------------------+\n| id                            | estRows | task      | access object                                                               | operator info                               |\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------+---------------------------------------------+\n| IndexMerge_10                 | 0.00    | root      |                                                                             | type: intersection                          |\n| ├─IndexRangeScan_5(Build)     | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[1,1], keep order:false, stats:pseudo |\n| ├─IndexRangeScan_6(Build)     | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[2,2], keep order:false, stats:pseudo |\n| ├─IndexRangeScan_7(Build)     | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[3,3], keep order:false, stats:pseudo |\n| ├─IndexRangeScan_8(Build)     | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[4,4], keep order:false, stats:pseudo |\n| └─TableRowIDScan_9(Probe)     | 0.00    | cop[tikv] | table:t4                                                                    | keep order:false, stats:pseudo              |\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------+---------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Selecting Specific Physical Plan\nDESCRIPTION: Example showing how to force optimizer to select the third physical plan during optimization.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_50\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ NTH_PLAN(3) */ count(*) from t where a > 5;\n```\n\n----------------------------------------\n\nTITLE: Deleting Data in TiDB with LIMIT\nDESCRIPTION: This snippet demonstrates how to delete data in TiDB in batches using the `DELETE` statement with a `LIMIT` clause. This approach is recommended for deleting large amounts of data to avoid exceeding transaction size limits. It deletes through the loop and uses `Affected Rows == 0` as a condition to end the loop.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/migration-tidb-faq.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n\"Delete from t where xx limit 5000;\"\n```\n\n----------------------------------------\n\nTITLE: DROP USER Usage Examples in SQL\nDESCRIPTION: Practical examples demonstrating the usage of DROP USER statement in TiDB, including error handling, using IF EXISTS clause, creating users, granting permissions, and then dropping them.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-user.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> DROP USER idontexist;\nERROR 1396 (HY000): Operation DROP USER failed for idontexist@%\n\nmysql> DROP USER IF EXISTS 'idontexist';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> CREATE USER 'newuser' IDENTIFIED BY 'mypassword';\nQuery OK, 1 row affected (0.02 sec)\n\nmysql> GRANT ALL ON test.* TO 'newuser';\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> SHOW GRANTS FOR 'newuser';\n+-------------------------------------------------+\n| Grants for newuser@%                            |\n+-------------------------------------------------+\n| GRANT USAGE ON *.* TO 'newuser'@'%'             |\n| GRANT ALL PRIVILEGES ON test.* TO 'newuser'@'%' |\n+-------------------------------------------------+\n2 rows in set (0.00 sec)\n\nmysql> REVOKE ALL ON test.* FROM 'newuser';\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> SHOW GRANTS FOR 'newuser';\n+-------------------------------------+\n| Grants for newuser@%                |\n+-------------------------------------+\n| GRANT USAGE ON *.* TO 'newuser'@'%' |\n+-------------------------------------+\n1 row in set (0.00 sec)\n\nmysql> DROP USER 'newuser';\nQuery OK, 0 rows affected (0.14 sec)\n\nmysql> SHOW GRANTS FOR 'newuser';\nERROR 1141 (42000): There is no such grant defined for user 'newuser' on host '%'\n```\n\n----------------------------------------\n\nTITLE: Configuring Import Mode Backend in TiDB Lightning\nDESCRIPTION: Specifies the backend for logical import mode, which is set to 'tidb' to enable SQL-based data import with ACID guarantees\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-logical-import-mode.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nbackend: tidb\n```\n\n----------------------------------------\n\nTITLE: Checking Table Data and Index Consistency in TiDB\nDESCRIPTION: This SQL command checks the consistency between the data and indexes of a specified table. It's crucial after a recovery to ensure no data loss or corruption occurred.\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nADMIN CHECK TABLE table_name;\n```\n\n----------------------------------------\n\nTITLE: Verifying garbage collection settings in TiDB\nDESCRIPTION: SQL query to verify that garbage collection has been disabled in TiDB. The output shows '0' which indicates that garbage collection is disabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@global.tidb_gc_enable;\n+-------------------------+\n| @@global.tidb_gc_enable |\n+-------------------------+\n|                       0 |\n+-------------------------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_instance_plan_cache in TiDB\nDESCRIPTION: This variable controls the experimental Instance Plan Cache feature, allowing sessions within a TiDB instance to share execution plans for better memory utilization, but is not recommended for production until more stable.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_32\n\nLANGUAGE: markdown\nCODE:\n```\n> **Warning:**\n>\n> Currently, Instance Plan Cache is an experimental feature. It is not recommended that you use it in the production environment. This feature might be changed or removed without prior notice. If you find a bug, you can report an [issue](https://github.com/pingcap/tidb/issues) on GitHub.\n\n- Scope: GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): No\n- Type: Boolean\n- Default value: `OFF`\n- This variable controls whether to enable the Instance Plan Cache feature. This feature implements instance-level execution plan cache, which allows all sessions within the same TiDB instance to share the execution plan cache.\n```\n\n----------------------------------------\n\nTITLE: Using 10% Index Selectivity Ratio in TiDB SQL\nDESCRIPTION: Example showing query execution with a value of 0.1 (10%) for tidb_opt_ordering_index_selectivity_ratio. This assumes that 10% of rows will be scanned before finding qualified rows, which results in approximately 99,085 rows to scan.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_58\n\nLANGUAGE: sql\nCODE:\n```\n> SET SESSION tidb_opt_ordering_index_selectivity_ratio = 0.1;\n\n> EXPLAIN SELECT * FROM t USE INDEX (ia) WHERE b <= 9000 ORDER BY a LIMIT 1;\n+-----------------------------------+----------+-----------+-----------------------+---------------------------------+\n| id                                | estRows  | task      | access object         | operator info                   |\n+-----------------------------------+----------+-----------+-----------------------+---------------------------------+\n| Limit_12                          | 1.00     | root      |                       | offset:0, count:1               |\n| └─Projection_22                   | 1.00     | root      |                       | test.t.a, test.t.b, test.t.c    |\n|   └─IndexLookUp_21                | 1.00     | root      |                       |                                 |\n|     ├─IndexFullScan_18(Build)     | 99085.21 | cop[tikv] | table:t, index:ia(a)  | keep order:true                 |\n|     └─Selection_20(Probe)         | 1.00     | cop[tikv] |                       | le(test.t.b, 9000)              |\n|       └─TableRowIDScan_19         | 99085.21 | cop[tikv] | table:t               | keep order:false                |\n+-----------------------------------+----------+-----------+-----------------------+---------------------------------+\n```\n\n----------------------------------------\n\nTITLE: DDL Administration Command Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for ADMIN SHOW DDL commands, including options for showing jobs, job queries, and optional WHERE clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAdminShowDDLStmt ::=\n    'ADMIN' 'SHOW' 'DDL'\n    (\n        'JOBS' Int64Num? WhereClauseOptional\n    |   'JOB' 'QUERIES' NumList\n    |   'JOB' 'QUERIES' 'LIMIT' m ( ('OFFSET' | ',') n )?\n    )?\n\nNumList ::=\n    Int64Num ( ',' Int64Num )*\n\nWhereClauseOptional ::=\n    WhereClause?\n```\n\n----------------------------------------\n\nTITLE: Python DateTime Range Deletion\nDESCRIPTION: Python implementation for deleting data within a specific time range using MySQLdb\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-delete-data.md#2025-04-18_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nimport MySQLdb\nimport datetime\nimport time\nconnection = MySQLdb.connect(\n    host=\"127.0.0.1\",\n    port=4000,\n    user=\"root\",\n    password=\"\",\n    database=\"bookshop\",\n    autocommit=True\n)\nwith connection:\n    with connection.cursor() as cursor:\n        start_time = datetime.datetime(2022, 4, 15)\n        end_time = datetime.datetime(2022, 4, 15, 0, 15)\n        delete_sql = \"DELETE FROM `bookshop`.`ratings` WHERE `rated_at` >= %s AND `rated_at` <= %s\"\n        affect_rows = cursor.execute(delete_sql, (start_time, end_time))\n        print(f'delete {affect_rows} data')\n```\n\n----------------------------------------\n\nTITLE: TiDB TABLESAMPLE Query Example\nDESCRIPTION: Example demonstrating the use of TABLESAMPLE clause for sampling data from a large table, comparing results between sampled and full table queries with aggregation functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-select.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT AVG(s_quantity), COUNT(s_quantity) FROM stock TABLESAMPLE REGIONS();\n+-----------------+-------------------+\n| AVG(s_quantity) | COUNT(s_quantity) |\n+-----------------+-------------------+\n|         59.5000 |                 4 |\n+-----------------+-------------------+\n1 row in set (0.00 sec)\n\nmysql> SELECT AVG(s_quantity), COUNT(s_quantity) FROM stock;\n+-----------------+-------------------+\n| AVG(s_quantity) | COUNT(s_quantity) |\n+-----------------+-------------------+\n|         54.9729 |           1000000 |\n+-----------------+-------------------+\n1 row in set (0.52 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating Global Bindings Using Plan Digests\nDESCRIPTION: Two methods for creating global bindings using plan digests from statement history, including direct digest specification and using variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-binding.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT query_sample_text, stmt_type, table_names, plan_digest FROM information_schema.statements_summary_history WHERE table_names LIKE '%test.t1%' AND stmt_type != 'CreateTable';\nCREATE GLOBAL BINDING FROM HISTORY USING PLAN DIGEST 'e72819cf99932f63a548156dbf433adda60e10337e89dcaa8638b4caf16f64d8,c291edc36b2482738d3389d335f37efc76290be2930330fe5034c5f4c42eeb36';\n```\n\n----------------------------------------\n\nTITLE: Creating a Table for Examples\nDESCRIPTION: SQL statement to create a simple table named t1 with an integer primary key for demonstration purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-table.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1(id INT PRIMARY KEY);\n```\n\n----------------------------------------\n\nTITLE: Retrieving TiFlash Placement Rules\nDESCRIPTION: Curl command to fetch all TiFlash placement rules configured in PD, helping diagnose replication configuration\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ncurl http://<pd-ip>:<pd-port>/pd/api/v1/config/rules/group/tiflash\n```\n\n----------------------------------------\n\nTITLE: Resetting AUTO_INCREMENT with Warning and Testing New Allocations\nDESCRIPTION: This snippet shows the behavior when attempting to reset AUTO_INCREMENT to 0, which results in a warning and uses the next available value instead, demonstrating how the cache is effectively cleared across all TiDB nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t AUTO_INCREMENT = 0;\nQuery OK, 0 rows affected, 1 warning (0.07 sec)\n\nSHOW WARNINGS;\n+---------+------+-------------------------------------------------------------------------+\n| Level   | Code | Message                                                                 |\n+---------+------+-------------------------------------------------------------------------+\n| Warning | 1105 | Can't reset AUTO_INCREMENT to 0 without FORCE option, using 101 instead |\n+---------+------+-------------------------------------------------------------------------+\n1 row in set (0.01 sec)\n\nINSERT INTO t VALUES();\nQuery OK, 1 row affected (0.02 sec)\n\nSELECT * FROM t;\n+-----+\n| a   |\n+-----+\n|   1 |\n|  50 |\n| 101 |\n+-----+\n3 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating Changefeed in TiCDC\nDESCRIPTION: This shell command creates a changefeed in TiCDC to replicate data changes from an upstream TiDB cluster to a downstream cluster, specifying necessary parameters including server and sink URI.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc cli changefeed create --server=http://172.16.6.122:8300 --sink-uri=\"mysql://root:@172.16.6.125:4000\" --changefeed-id=\"upstream-to-downstream\" --start-ts=\"431434047157698561\"\n\n```\n\n----------------------------------------\n\nTITLE: Adding Index to Table in TiDB\nDESCRIPTION: This SQL statement adds an index to the `start_date` column of the `trips` table. Adding an index allows the query optimizer to use index-based lookups instead of full table scans, significantly improving query performance when filtering on `start_date`.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n\"ALTER TABLE trips ADD INDEX (start_date);\"\n```\n\n----------------------------------------\n\nTITLE: Creating Table and Inserting Data in TiDB Cloud\nDESCRIPTION: SQL commands to create a 'person' table and insert sample data in TiDB Cloud Serverless cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-kysely-example.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `test`.`person`  (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(255) NULL DEFAULT NULL,\n  `gender` enum('male','female') NULL DEFAULT NULL,\n  PRIMARY KEY (`id`) USING BTREE\n);\n\ninsert into test.person values (1,'pingcap','male')\n```\n\n----------------------------------------\n\nTITLE: Creating Extended Statistics for Correlated Columns\nDESCRIPTION: Creates a correlation-type extended statistics object for two columns in the sample table, which will help the optimizer make better decisions.\nSOURCE: https://github.com/pingcap/docs/blob/master/extended-statistics.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t ADD STATS_EXTENDED s1 correlation(col1, col2);\n```\n\n----------------------------------------\n\nTITLE: Restoring TiDB Cluster from Snapshot Backup\nDESCRIPTION: Command for restoring a TiDB cluster from a previously created snapshot backup. It specifies the PD address and S3 storage location containing the backup data.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-guide.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full --pd \"${PD_IP}:2379\" \\\n--storage \"s3://backup-101/snapshot-202209081330?access-key=${access-key}&secret-access-key=${secret-access-key}\"\n```\n\n----------------------------------------\n\nTITLE: Querying Data Size by Schema in MySQL\nDESCRIPTION: This SQL query calculates the total data and index size for all schemas in a MySQL database. It helps estimate the storage requirements for data migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-hardware-and-software-requirements.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n  TABLE_SCHEMA,\n  FORMAT_BYTES(SUM(DATA_LENGTH)) AS 'Data Size',\n  FORMAT_BYTES(SUM(INDEX_LENGTH)) 'Index Size'\nFROM\n  information_schema.tables\nGROUP BY\n  TABLE_SCHEMA;\n```\n\n----------------------------------------\n\nTITLE: Reorganizing Data Using ALTER TABLE in SQL\nDESCRIPTION: This snippet provides an example of modifying a column's data type from INT to VARCHAR. The sample illustrates how TiDB manages data changes that require reorganization, highlighting processing duration and potential errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-modify-column.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id int not null primary key AUTO_INCREMENT, col1 INT);\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t1 (col1) VALUES (12345),(67890);\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t1 MODIFY col1 VARCHAR(5);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE t1\\G\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t1 MODIFY column col1 varchar(4);\n```\n\n----------------------------------------\n\nTITLE: Getting Current Role (SQL)\nDESCRIPTION: The `CURRENT_ROLE()` function retrieves the current role associated with the session, which is crucial for role-based access control.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/information-functions.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_ROLE();\n```\n+----------------+\n| CURRENT_ROLE() |\n+----------------+\n| NONE           |\n+----------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Range Partitioning by Separation Year\nDESCRIPTION: This example demonstrates Range partitioning on the `employees` table using the separation year extracted from the `separated` column. The `YEAR()` function is used in the partitioning expression, allowing for grouping employees based on their separation year.  `MAXVALUE` is used to capture all separations after the last defined year.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT\n)\n\nPARTITION BY RANGE ( YEAR(separated) ) (\n    PARTITION p0 VALUES LESS THAN (1991),\n    PARTITION p1 VALUES LESS THAN (1996),\n    PARTITION p2 VALUES LESS THAN (2001),\n    PARTITION p3 VALUES LESS THAN MAXVALUE\n);\n```\n\n----------------------------------------\n\nTITLE: Execute TiUP Cluster Start Command in Shell\nDESCRIPTION: This command starts all services or specific services in a named TiDB cluster. It supports various options for fine-grained control over which nodes and roles to start. The cluster name is required, and flags are optional.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-start.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster start <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Stopping a Replication Task with cURL (DM API)\nDESCRIPTION: This example demonstrates how to stop a running replication task using the DM API. The POST request halts the replication process for the specified task.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_33\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'POST' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1/stop' \\\n  -H 'accept: */*'\n```\n\n----------------------------------------\n\nTITLE: Configuring TiProxy with TOML\nDESCRIPTION: This snippet provides a TOML configuration example for TiProxy, illustrating essential parameters such as proxy address and security settings. Dependencies include a compatible TOML parser, and TiProxy-specific tools like TiUP or TiDB Operator. This file configures port settings for SQL services, high availability with virtual IPs, and security using TLS settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-configuration.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[proxy]\naddr = \"0.0.0.0:6000\"\nmax-connections = 100\n\n[api]\naddr = \"0.0.0.0:3080\"\n\n[ha]\nvirtual-ip = \"10.0.1.10/24\"\ninterface = \"eth0\"\n\n[security]\n[security.cluster-tls]\nskip-ca = true\n\n[security.sql-tls]\nskip-ca = true\n```\n\n----------------------------------------\n\nTITLE: Using MERGE Hint with CTEs\nDESCRIPTION: Examples of using the MERGE hint to optimize common table expressions (CTE) by disabling materialization and enabling inline expansion.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_39\n\nLANGUAGE: sql\nCODE:\n```\nWITH CTE AS (SELECT /*+ MERGE() */ * FROM tc WHERE tc.a < 60) SELECT * FROM CTE WHERE CTE.a < 18;\n\nWITH CTE1 AS (SELECT * FROM t1), CTE2 AS (WITH CTE3 AS (SELECT /*+ MERGE() */ * FROM t2), CTE4 AS (SELECT * FROM t3) SELECT * FROM CTE3, CTE4) SELECT * FROM CTE1, CTE2;\n```\n\n----------------------------------------\n\nTITLE: Setting Global Transaction Mode in TiDB - SQL\nDESCRIPTION: This snippet sets the global transaction mode for newly created sessions to pessimistic. This configuration results in all non-autocommit transactions using pessimistic by default until overridden by a session-level setting.\nSOURCE: https://github.com/pingcap/docs/blob/master/pessimistic-transaction.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_txn_mode = 'pessimistic';\n```\n\n----------------------------------------\n\nTITLE: Viewing Binding Cache Status in TiDB\nDESCRIPTION: SQL command to show the binding cache status, including number of bindings in cache, total bindings in the system, memory usage, and total memory quota.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSHOW binding_cache status;\n```\n\n----------------------------------------\n\nTITLE: SQL Leading and Straight Join Hints\nDESCRIPTION: Join order hint syntax for optimizing query performance, including LEADING hint for specifying join prefix order and STRAIGHT_JOIN for maintaining FROM clause order.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.0.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nLEADING\nSTRAIGHT_JOIN\n```\n\n----------------------------------------\n\nTITLE: Using SAVEPOINT in a Transaction in TiDB SQL\nDESCRIPTION: Demonstrates the usage of SAVEPOINT, ROLLBACK TO SAVEPOINT, and RELEASE SAVEPOINT within a transaction, including data insertion and querying results.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-savepoint.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nBEGIN;\n\nINSERT INTO t1 VALUES (1);\n\nSAVEPOINT sp1;\n\nINSERT INTO t1 VALUES (2);\n\nSAVEPOINT sp2;\n\nRELEASE SAVEPOINT sp2;\n\nROLLBACK TO SAVEPOINT sp1;\n\nCOMMIT;\n\nSELECT * FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Storing Documents with Vector Embeddings in TiDB\nDESCRIPTION: Python code showing how to create document records with vector embeddings using peewee. Inserts three sample documents with their corresponding 3-dimensional vector representations.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-peewee.md#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nDocument.create(content='dog', embedding=[1, 2, 1])\nDocument.create(content='fish', embedding=[1, 2, 4])\nDocument.create(content='tree', embedding=[1, 0, 0])\n```\n\n----------------------------------------\n\nTITLE: Examining Transactions Waiting on a Specific Key in TiDB\nDESCRIPTION: This SQL query joins data_lock_waits with cluster_tidb_trx to find transactions waiting on a specific key, filtering by key value to analyze lock conflicts.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-lock-conflicts.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nselect trx.* from information_schema.data_lock_waits as l left join information_schema.cluster_tidb_trx as trx on l.trx_id = trx.id where l.key = \"7480000000000000415F728000000000000001\"\\G\n```\n\n----------------------------------------\n\nTITLE: Creating User with Default Password Expiration in SQL\nDESCRIPTION: SQL command to create a new user that follows the global password expiration policy rather than having an account-level override.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_18\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE USER 'test'@'localhost' PASSWORD EXPIRE DEFAULT;\n```\n\n----------------------------------------\n\nTITLE: Successful TiDB Variable Modification\nDESCRIPTION: This SQL statement confirms that the modification of the `tidb_slow_log_threshold` variable was successful.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Cloud Dedicated Connection String\nDESCRIPTION: Environment variable configuration for connecting to TiDB Cloud Dedicated with TLS and CA certificate path.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_5\n\nLANGUAGE: dotenv\nCODE:\n```\nDATABASE_URL='mysql2://{user}:{password}@{host}:{port}/{database}?ssl_mode=verify_identity&sslca=/path/to/ca.pem'\n```\n\n----------------------------------------\n\nTITLE: Insert Duplicate Values in Same Record\nDESCRIPTION: These snippets illustrate inserting records with duplicate values within the same JSON array field. While duplicates within a record are allowed, different records cannot share duplicate values if the index is unique. Assumes table t1 exists.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n-- Insert succeeded\nmysql> INSERT INTO t1 VALUES('[1,1,2]');\nmysql> INSERT INTO t1 VALUES('[3,3,3,4,4,4]');\n\n-- Insert failed\nmysql> INSERT INTO t1 VALUES('[1,2]');\nmysql> INSERT INTO t1 VALUES('[2,3]');\n\n```\n\n----------------------------------------\n\nTITLE: SQL Execution for Preventing Overselling Transactions\nDESCRIPTION: This SQL snippet outlines the execution of transactions while preventing overselling. It includes selection and updating logic along with rollback scenarios based on stock availability.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\n/* txn 1 */ BEGIN OPTIMISTIC\n    /* txn 2 */ BEGIN OPTIMISTIC\n    /* txn 2 */ SELECT * FROM `books` WHERE `id` = 1 FOR UPDATE\n    /* txn 2 */ UPDATE `books` SET `stock` = `stock` - 4 WHERE `id` = 1 AND `stock` - 4 >= 0\n    /* txn 2 */ INSERT INTO `orders` (`id`, `book_id`, `user_id`, `quality`) VALUES (1001, 1, 1, 4)\n    /* txn 2 */ UPDATE `users` SET `balance` = `balance` - 400.0 WHERE `id` = 2\n    /* txn 2 */ COMMIT\n/* txn 1 */ SELECT * FROM `books` WHERE `id` = 1 FOR UPDATE\n/* txn 1 */ UPDATE `books` SET `stock` = `stock` - 7 WHERE `id` = 1 AND `stock` - 7 >= 0\n/* txn 1 */ INSERT INTO `orders` (`id`, `book_id`, `user_id`, `quality`) VALUES (1000, 1, 1, 7)\n/* txn 1 */ UPDATE `users` SET `balance` = `balance` - 700.0 WHERE `id` = 1\nretry 1 times for 9007 Write conflict, txnStartTS=432619094333980675, conflictStartTS=432619094333980676, conflictCommitTS=432619094333980678, key={tableID=126, handle=1} primary={tableID=114, indexID=1, indexValues={1, 1000, }} [try again later]\n/* txn 1 */ BEGIN OPTIMISTIC\n/* txn 1 */ SELECT * FROM `books` WHERE `id` = 1 FOR UPDATE\nFail -> out of stock\n/* txn 1 */ ROLLBACK\n```\n\n----------------------------------------\n\nTITLE: Describing the COLUMNS Table Structure in INFORMATION_SCHEMA\nDESCRIPTION: This SQL snippet demonstrates how to view the structure of the COLUMNS table in the INFORMATION_SCHEMA database, showing all the fields available for column metadata.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-columns.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC COLUMNS;\n```\n\n----------------------------------------\n\nTITLE: Estimating Table Size in TiDB using SQL\nDESCRIPTION: This SQL query estimates the size of a table in TiDB by querying the `information_schema.TIKV_REGION_STATUS` table. It calculates both the approximate size before compression and the estimated size after compression, taking into account the `store_size_amplification` factor which represents the average compression ratio.  The `@dbname` and `@table_name` variables need to be replaced with the appropriate database and table names.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/manage-cluster-faq.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n  db_name,\n  table_name,\n  ROUND(SUM(total_size / cnt), 2) Approximate_Size,\n  ROUND(\n    SUM(\n      total_size / cnt / (\n        SELECT\n          ROUND(AVG(value), 2)\n        FROM\n          METRICS_SCHEMA.store_size_amplification\n        WHERE\n          value > 0\n      )\n    ),\n    2\n  ) Disk_Size\nFROM\n  (\n    SELECT\n      db_name,\n      table_name,\n      region_id,\n      SUM(Approximate_Size) total_size,\n      COUNT(*) cnt\n    FROM\n      information_schema.TIKV_REGION_STATUS\n    WHERE\n      db_name = @dbname\n      AND table_name IN (@table_name)\n    GROUP BY\n      db_name,\n      table_name,\n      region_id\n  ) tabinfo\nGROUP BY\n  db_name,\n  table_name;\n```\n\n----------------------------------------\n\nTITLE: Daily Analysis Results Materialization\nDESCRIPTION: Example showing how to save daily analysis results by aggregating detail data using INSERT INTO SELECT.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-results-materialization.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET @@sql_mode='NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO';\n\nINSERT INTO daily_data (rec_date, customer_id, daily_fee)\nSELECT DATE(ts), customer_id, sum(detail_fee) FROM detail_data WHERE DATE(ts) > DATE('2023-1-1 12:2:3') GROUP BY DATE(ts), customer_id;\n```\n\n----------------------------------------\n\nTITLE: Topic Expression Matching Rules for Kafka Sink Dispatchers\nDESCRIPTION: This snippet outlines the rules for defining topic expressions in Kafka sink dispatchers, including how to create flexible routing policies based on schema and table names.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_11\n\nLANGUAGE: toml\nCODE:\n```\n    matcher = ['test1.table1', 'test2.table2'], topic = \"hello_{schema}_{table}\"\n    matcher = ['test3.*', 'test4.*'], topic = \"hello_{schema}_world\"\n    matcher = ['test5.*, 'test6.*'], topic = \"hard_code_topic_name\"\n    matcher = ['*.*'], topic = \"{schema}_{table}\"\n\n```\n\n----------------------------------------\n\nTITLE: Checking Imported Data with MySQL CLI\nDESCRIPTION: MySQL CLI command to verify the successful import of data into the TiDB Cloud cluster by selecting all records from the target table.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-import-resource.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test.import_test;\n```\n\n----------------------------------------\n\nTITLE: Autowiring PlayerRepository in Spring Boot\nDESCRIPTION: This Java code snippet shows how to autowire the PlayerRepository interface in a Spring component for dependency injection.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-spring-boot.md#2025-04-18_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n@Autowired\nprivate PlayerRepository playerRepository;\n```\n\n----------------------------------------\n\nTITLE: Calculating L2 Norm in TiDB SQL\nDESCRIPTION: VEC_L2_NORM function calculates the Euclidean norm of a vector.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-functions-and-operators.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VEC_L2_NORM('[3,4]');\n```\n\n----------------------------------------\n\nTITLE: Configuring Coprocessor Cache for Read-heavy Workloads\nDESCRIPTION: This TOML configuration sets up optimal parameters for the coprocessor cache in TiDB to enhance query performance for read-heavy workloads. Key parameters include capacity, admission thresholds, and process timing settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_9\n\nLANGUAGE: toml\nCODE:\n```\n[tikv-client.copr-cache]\ncapacity-mb = 4096\nadmission-max-ranges = 5000\nadmission-max-result-mb = 10\nadmission-min-process-ms = 0\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP Cluster Component - Shell\nDESCRIPTION: This command installs the TiUP cluster component necessary for managing TiDB clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster\n```\n\n----------------------------------------\n\nTITLE: Querying Specific Columns in TiDB with SQL\nDESCRIPTION: This SQL statement selects only the 'name' column from the 'person' table. It shows how to retrieve specific fields rather than all columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-tidb-crud-sql.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT name FROM person;\n```\n\n----------------------------------------\n\nTITLE: Counting Slow Queries per TiDB Node in SQL\nDESCRIPTION: SQL query to count the number of slow queries for each TiDB node in a cluster within a specific time range.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nselect instance, count(*) from information_schema.cluster_slow_query where time >= \"2020-03-06 00:00:00\" and time < now() group by instance;\n```\n\n----------------------------------------\n\nTITLE: Window Function with ORDER BY Example\nDESCRIPTION: Example showing optimization of window function with ORDER BY clause, demonstrating TopN operator derivation.\nSOURCE: https://github.com/pingcap/docs/blob/master/derive-topn-from-window.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id int, value int);\nSET tidb_opt_derive_topn=on;\nEXPLAIN SELECT * FROM (SELECT ROW_NUMBER() OVER (ORDER BY value) AS rownumber FROM t) dt WHERE rownumber <= 3;\n```\n\n----------------------------------------\n\nTITLE: Ranking Rows with DENSE_RANK() in SQL\nDESCRIPTION: This example shows how to use the DENSE_RANK() window function to rank rows without gaps in case of ties. It uses a subquery to generate sample data with duplicate values.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/window-functions.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n    *,\n    DENSE_RANK() OVER (ORDER BY n)\nFROM (\n    SELECT 5 AS 'n'\n    UNION ALL\n    SELECT 8\n    UNION ALL\n    SELECT 5\n    UNION ALL\n    SELECT 30\n    UNION ALL\n    SELECT 31\n    UNION ALL\n    SELECT 32) a;\n```\n\n----------------------------------------\n\nTITLE: Using RECOMMEND INDEX Statement Syntax in TiDB\nDESCRIPTION: The basic syntax for using the RECOMMEND INDEX statement in TiDB to analyze historical workloads or specific SQL statements and generate index recommendations.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nRECOMMEND INDEX RUN [ FOR <SQL> ] [<Options>] \n```\n\n----------------------------------------\n\nTITLE: Creating a Range Partitioned Table in SQL\nDESCRIPTION: This SQL snippet creates a partitioned table 't' using range partitioning based on column 'a', specifying three partitions with defined value limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t ( a INT, b INT, INDEX idx(b)) PARTITION BY RANGE( a ) (PARTITION p1 VALUES LESS THAN (10000), PARTITION p2 VALUES LESS THAN (20000), PARTITION p3 VALUES LESS THAN (MAXVALUE));\n```\n\n----------------------------------------\n\nTITLE: Check TPC-C Consistency with TiUP Bench (Bash)\nDESCRIPTION: This command checks the data consistency for a TPC-C benchmark with 4 warehouses. It utilizes the `check` subcommand of the TiUP bench tpcc component to verify the integrity of the data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench tpcc --warehouses 4 check\n```\n\n----------------------------------------\n\nTITLE: Using AutoRandom Keyword for Primary Key\nDESCRIPTION: Demonstrates how to use the AutoRandom keyword in column attribute to automatically assign random integers to primary keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-beta.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t (id BIGINT PRIMARY KEY AUTO_RANDOM);\n```\n\n----------------------------------------\n\nTITLE: Creating and Altering a Table with TiFlash Replica in TiDB\nDESCRIPTION: SQL commands to create a table and set up a TiFlash replica, followed by adding a column. This example demonstrates the schema change that affects Stale Read functionality with TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/stale-read.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\ncreate table t1(id int);\nalter table t1 set tiflash replica 1;\n```\n\n----------------------------------------\n\nTITLE: Running Sysbench Prepare Command to Load Data - Shell\nDESCRIPTION: This shell command executes Sysbench in 'prepare' mode to load 32 tables with 10 million rows into the 'sbtest' database. It's a critical step in setting up the test environment to ensure adequate data is available for benchmarking.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nsysbench oltp_common \\\n         --threads=${THREAD} \\\n         --db-driver=mysql \\\n         --mysql-db=sbtest \\\n         --mysql-host=${HOST} \\\n         --mysql-port=${PORT} \\\n         --mysql-user=root \\\n         --mysql-password=${PASSWORD} \\\n         prepare --tables=32 --table-size=10000000\n```\n\n----------------------------------------\n\nTITLE: Querying Prometheus API for TiKV Engine Size\nDESCRIPTION: Example of using curl to query Prometheus API through Grafana's datasource proxy. The query retrieves TiKV engine size metrics over a time range with authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/grafana-monitor-best-practices.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -u user:pass 'http://__grafana_ip__:3000/api/datasources/proxy/1/api/v1/query_range?query=sum(tikv_engine_size_bytes%7Binstancexxxxxxxxx20180%22%7D)%20by%20(instance)&start=1565879269&end=1565882869&step=30' |python -m json.tool\n```\n\n----------------------------------------\n\nTITLE: Signing Server Certificate with CA for TiDB Authentication\nDESCRIPTION: Command to sign the server certificate request with the CA key and certificate. This creates a server certificate that clients can verify using the CA certificate.\nSOURCE: https://github.com/pingcap/docs/blob/master/certificate-authentication.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nsudo openssl x509 -req -in server-req.pem -days 365000 -CA ca-cert.pem -CAkey ca-key.pem -set_serial 01 -out server-cert.pem\n```\n\n----------------------------------------\n\nTITLE: Checking Current SQL Mode\nDESCRIPTION: This SQL statement allows users to query the current SQL mode setting in the active session. No prerequisites required.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-mode.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT @@sql_mode;\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB Server Status - Bash/JSON\nDESCRIPTION: Example of querying the TiDB server status endpoint to check server health and get basic information like connections and version. The endpoint returns a JSON response with connection count, version number, and Git hash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-monitoring-api.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:10080/status\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n    connections: 0,\n    version: \"8.0.11-TiDB-v8.5.0\",\n    git_hash: \"778c3f4a5a716880bcd1d71b257c8165685f0d70\"\n}\n```\n\n----------------------------------------\n\nTITLE: Binding Statement to Resource Group in SQL - TiDB\nDESCRIPTION: This snippet illustrates how to bind a SQL statement to a specific resource group using a hint. This allows for resource management at the statement level and is applicable to various SQL command types. Proper privileges are required in strict mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-ru-groups.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ RESOURCE_GROUP(rg1) */ * FROM t limit 10;\n```\n\n----------------------------------------\n\nTITLE: Checking Log Backup Status in Shell\nDESCRIPTION: Example command for querying the status of a specific TiDB log backup task, showing the task name and PD address.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log status --task-name=pitr --pd=\"${PD_IP}:2379\"\n```\n\n----------------------------------------\n\nTITLE: Output of Column Information for the Test Table\nDESCRIPTION: This shows the detailed metadata retrieved from the COLUMNS table for the test.t1 table, displaying all available column attributes in a vertically formatted output.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-columns.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n*************************** 1. row ***************************\n           TABLE_CATALOG: def\n            TABLE_SCHEMA: test\n              TABLE_NAME: t1\n             COLUMN_NAME: a\n        ORDINAL_POSITION: 1\n          COLUMN_DEFAULT: NULL\n             IS_NULLABLE: YES\n               DATA_TYPE: int\nCHARACTER_MAXIMUM_LENGTH: NULL\n  CHARACTER_OCTET_LENGTH: NULL\n       NUMERIC_PRECISION: 11\n           NUMERIC_SCALE: 0\n      DATETIME_PRECISION: NULL\n      CHARACTER_SET_NAME: NULL\n          COLLATION_NAME: NULL\n             COLUMN_TYPE: int(11)\n              COLUMN_KEY:\n                   EXTRA:\n              PRIVILEGES: select,insert,update,references\n          COLUMN_COMMENT:\n   GENERATION_EXPRESSION:\n1 row in set (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW TABLE STATUS with Like Clause in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a table, insert data into it, and then use the SHOW TABLE STATUS command to retrieve statistics about the table, specifically using a LIKE clause to filter results based on the table name.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-status.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5);\nQuery OK, 5 rows affected (0.02 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\nmysql> SHOW TABLE STATUS LIKE 't1'\\G\n*************************** 1. row ***************************\n           Name: t1\n         Engine: InnoDB\n        Version: 10\n     Row_format: Compact\n           Rows: 0\n Avg_row_length: 0\n    Data_length: 0\nMax_data_length: 0\n   Index_length: 0\n      Data_free: 0\n Auto_increment: 30001\n    Create_time: 2019-04-19 08:32:06\n    Update_time: NULL\n     Check_time: NULL\n      Collation: utf8mb4_bin\n       Checksum:\n Create_options:\n        Comment:\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Enabling Cross-database Binding Feature in TiDB\nDESCRIPTION: Enables the cross-database binding feature by setting the tidb_opt_enable_fuzzy_binding system variable to 1.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_24\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_opt_enable_fuzzy_binding=1;\n```\n\n----------------------------------------\n\nTITLE: Analytical Query Using TiFlash in TiDB\nDESCRIPTION: This SQL query performs an analytical operation on the ratings table, calculating the average score grouped by hour of the day. This type of aggregation query benefits from TiFlash's columnar storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT HOUR(`rated_at`), AVG(`score`) FROM `bookshop`.`ratings` GROUP BY HOUR(`rated_at`);\n```\n\n----------------------------------------\n\nTITLE: Adding a CHECK Constraint with ALTER TABLE\nDESCRIPTION: This example shows how to add a CHECK constraint to an existing table using the ALTER TABLE statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t ADD CONSTRAINT CHECK (1 < c);\n```\n\n----------------------------------------\n\nTITLE: Defining Warning Alert Rule for TiCDC Memory Abnormal Usage in YAML\nDESCRIPTION: YAML configuration for a warning alert rule that triggers when the TiCDC heap memory usage exceeds 10 GiB.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-alert-rules.md#2025-04-18_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\ngo_memstats_heap_alloc_bytes{job=\"ticdc\"} > 1e+10\n```\n\n----------------------------------------\n\nTITLE: Key-Value Mapping: Table Data\nDESCRIPTION: This code snippet demonstrates the rule for encoding each row of data as a (Key, Value) key-value pair in TiDB.  `tablePrefix` and `recordPrefixSep` are special string constants used to distinguish other data in Key space. The key consists of the table ID and row ID, while the value contains the column data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-computing.md#2025-04-18_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n\"Key:   tablePrefix{TableID}_recordPrefixSep{RowID}\\nValue: [col1, col2, col3, col4]\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Hash Partitioning by Hire Year in SQL\nDESCRIPTION: This snippet shows how to create a Hash partitioned table 'employees' divided into 4 partitions based on the hire year extracted from the 'hired' column.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_26\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT\n)\n\nPARTITION BY HASH( YEAR(hired) )\nPARTITIONS 4;\n```\n\n----------------------------------------\n\nTITLE: Clearing AUTO_INCREMENT Cache with ALTER TABLE\nDESCRIPTION: This snippet demonstrates how to clear the auto-increment ID cache using ALTER TABLE with AUTO_INCREMENT = 0, which is useful for ensuring data consistency in scenarios like data migration or mixed ID allocation modes.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a int AUTO_INCREMENT key) AUTO_ID_CACHE 100;\nQuery OK, 0 rows affected (0.02 sec)\n\nINSERT INTO t VALUES();\nQuery OK, 1 row affected (0.02 sec)\n\nINSERT INTO t VALUES(50);\nQuery OK, 1 row affected (0.00 sec)\n\nSELECT * FROM t;\n+----+\n| a  |\n+----+\n|  1 |\n| 50 |\n+----+\n2 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Restoring Encrypted Snapshots\nDESCRIPTION: Command to restore encrypted backup data using AES-128-CTR encryption method with specified encryption key.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full\\\n    --pd \"${PD_IP}:2379\" \\\n    --storage \"s3://${backup_collection_addr}/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --crypter.method aes128-ctr \\\n    --crypter.key 0123456789abcdef0123456789abcdef\n```\n\n----------------------------------------\n\nTITLE: Configuring Operator-level Spilling for Hash Aggregation in SQL\nDESCRIPTION: These SQL statements demonstrate enabling operator-level spilling for Hash Aggregation operators by setting a 10 GiB threshold, reducing the memory usage of the GROUP BY query from 29.55 GiB to 12.80 GiB.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-spill-disk.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_max_bytes_before_tiflash_external_group_by = 10737418240;\nSELECT\n  l_orderkey,\n  MAX(L_COMMENT),\n  MAX(L_SHIPMODE),\n  MAX(L_SHIPINSTRUCT),\n  MAX(L_SHIPDATE),\n  MAX(L_EXTENDEDPRICE)\nFROM lineitem\nGROUP BY l_orderkey\nHAVING SUM(l_quantity) > 314;\n```\n\n----------------------------------------\n\nTITLE: Viewing RU Statistics by Group - TiDB\nDESCRIPTION: This snippet provides an example of how to query a system table to view historical RU consumption data by resource group. This is key for evaluating resource allocation and usage over time.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-ru-groups.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM request_unit_by_group LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Amazon S3 Backup Command\nDESCRIPTION: Command for backing up snapshot data to Amazon S3 using BR with access key authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full -u \"${PD_IP}:2379\" \\\n--storage \"s3://external/backup-20220915?access-key=${access-key}&secret-access-key=${secret-access-key}\"\n```\n\n----------------------------------------\n\nTITLE: Creating AWS IAM Policy for S3 Access in JSON\nDESCRIPTION: This JSON policy defines permissions required for TiDB Cloud Serverless to access an S3 bucket. It grants specific permissions for reading and writing objects and listing bucket contents, with placeholders for the bucket ARN and directory paths.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-external-storage.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:GetObjectVersion\",\n                \"s3:PutObject\"\n            ],\n            \"Resource\": \"<Your S3 bucket ARN>/<Directory of your source data>/*\"\n        },\n        {\n            \"Sid\": \"VisualEditor1\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:ListBucket\"\n            ],\n            \"Resource\": \"<Your S3 bucket ARN>\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Global SQL Mode in TiDB\nDESCRIPTION: SQL command to set the global SQL mode in TiDB, followed by queries to verify the change at both global and session levels.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-variable.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL sql_mode = 'STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER';\nSHOW GLOBAL VARIABLES LIKE 'sql_mode';\nSHOW SESSION VARIABLES LIKE 'sql_mode';\n```\n\n----------------------------------------\n\nTITLE: Destroying Checkpoint After Checksum Error in TiDB Lightning\nDESCRIPTION: Command to delete corrupted data after a checksum error, allowing TiDB Lightning to reimport the affected tables. Used when encountering the 'checksum failed: checksum mismatched' error.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/troubleshoot-tidb-lightning.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntidb-lightning-ctl --config conf/tidb-lightning.toml --checkpoint-error-destroy=all\n```\n\n----------------------------------------\n\nTITLE: Deleting Data from TiDB with mysql2\nDESCRIPTION: JavaScript code snippet to delete a 'Player' record from TiDB by ID using mysql2.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nextjs.md#2025-04-18_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\nconst [rsh] = await pool.query('DELETE FROM players WHERE id = ?;', [1]);\nconsole.log(rsh.affectedRows);\n```\n\n----------------------------------------\n\nTITLE: DDL State Transition Example for ADD INDEX Operation\nDESCRIPTION: Shows the state transition sequence that occurs during an ADD INDEX operation in TiDB, from initial absence to public availability.\nSOURCE: https://github.com/pingcap/docs/blob/master/ddl-introduction.md#2025-04-18_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nabsent -> delete only -> write only -> write reorg -> public\n```\n\n----------------------------------------\n\nTITLE: Querying Inactive Indexes with sys.schema_unused_indexes\nDESCRIPTION: This SQL statement utilizes the sys.schema_unused_indexes view to check for indexes that have not been used since the last startup of TiDB instances. This can help in deciding which indexes may be made invisible or deleted.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT START_TIME,UPTIME FROM INFORMATION_SCHEMA.CLUSTER_INFO WHERE TYPE='tidb';\n```\n\n----------------------------------------\n\nTITLE: Creating Table and Setting TiFlash Replica in SQL\nDESCRIPTION: This snippet demonstrates how to create a table and enable TiFlash replica settings within a database. Prerequisites include having a TiDB database system with TiFlash enabled. Parameters such as the table name and field types are defined. The inputs are SQL commands to create a table and set a replica, with no direct outputs, though subsequent queries will be affected by this configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-supported-pushdown-calculations.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id INT PRIMARY KEY, a INT);\nALTER TABLE t SET TIFLASH REPLICA 1;\n```\n\n----------------------------------------\n\nTITLE: Creating a Scale-Out Configuration for TiCDC\nDESCRIPTION: Example YAML configuration file for scaling out TiCDC nodes in an existing TiDB cluster using TiUP. Defines three TiCDC servers with their host addresses, garbage collection TTL, and data directories.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/deploy-ticdc.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncdc_servers:\n  - host: 10.1.1.1\n    gc-ttl: 86400\n    data_dir: /tidb-data/cdc-8300\n  - host: 10.1.1.2\n    gc-ttl: 86400\n    data_dir: /tidb-data/cdc-8300\n  - host: 10.0.1.4\n    gc-ttl: 86400\n    data_dir: /tidb-data/cdc-8300\n```\n\n----------------------------------------\n\nTITLE: Starting a Local Import Task with Custom CSV Format in TiDB Cloud CLI\nDESCRIPTION: Example of starting a local data import task with custom CSV format settings. This command allows specification of CSV separator, delimiter, backslash escape behavior, and trailing separator trimming.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-start.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import start --local.file-path <file-path> --cluster-id <cluster-id> --file-type CSV --local.target-database <target-database> --local.target-table <target-table> --csv.separator \\\" --csv.delimiter \\' --csv.backslash-escape=false --csv.trim-last-separator=true\n```\n\n----------------------------------------\n\nTITLE: Creating a Partitioned Table with Hash Partitioning in SQL\nDESCRIPTION: This SQL snippet creates a partitioned table named 't' using hash partitioning on column 'a' and divides it into two partitions. It includes an index on the column 'a' for optimized queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a INT, b INT, INDEX idx(a)) PARTITION BY HASH(a) PARTITIONS 2;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with AUTO_INCREMENT Primary Key in TiDB\nDESCRIPTION: Example of creating a table with an AUTO_INCREMENT primary key column and inserting values without explicitly specifying the auto-increment column values.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id int PRIMARY KEY AUTO_INCREMENT, c int);\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t(c) VALUES (1);\nINSERT INTO t(c) VALUES (2);\nINSERT INTO t(c) VALUES (3), (4), (5);\n```\n\n----------------------------------------\n\nTITLE: Viewing Last 10 DDL Jobs in TiDB\nDESCRIPTION: Shows the most recent 10 completed DDL jobs in the current job queue, displaying job details like ID, database name, table name, job type, schema state, and execution status.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW DDL JOBS;\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into Player Model using Django ORM in Python\nDESCRIPTION: This snippet demonstrates how to insert data into the Player model using Django ORM. It shows both single object creation and bulk creation of multiple objects.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# insert a single object\nplayer = Player.objects.create(name=\"player1\", coins=100, goods=1)\n\n# bulk insert multiple objects\nPlayer.objects.bulk_create([\n    Player(name=\"player1\", coins=100, goods=1),\n    Player(name=\"player2\", coins=200, goods=2),\n    Player(name=\"player3\", coins=300, goods=3),\n])\n```\n\n----------------------------------------\n\nTITLE: Cloning the Sample Application Repository\nDESCRIPTION: Commands to clone the sample code repository and navigate to the project directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/tidb-samples/tidb-nodejs-prisma-quickstart.git\ncd tidb-nodejs-prisma-quickstart\n```\n\n----------------------------------------\n\nTITLE: Configuring TiSpark Worker Nodes in YAML\nDESCRIPTION: Example configuration for TiSpark worker nodes specifying the host machines where worker processes will be deployed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\ntispark_workers:\n  - host: 10.0.1.22\n  - host: 10.0.1.23\n```\n\n----------------------------------------\n\nTITLE: Setting DML Execution Type for TiDB\nDESCRIPTION: This SQL command sets the execution mode of DML statements in TiDB to 'bulk', optimizing performance for large write operations and reducing memory usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSET SESSION tidb_dml_type = \"bulk\";\n```\n\n----------------------------------------\n\nTITLE: Password Complexity Check Example in TiDB\nDESCRIPTION: This SQL example demonstrates a failed password update due to not meeting the required length policy, indicating how TiDB enforces password complexity policies on plaintext passwords.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'test'@'localhost' IDENTIFIED BY 'abc';\nERROR 1819 (HY000): Require Password Length: 8\n```\n\n----------------------------------------\n\nTITLE: Prepared statement with member of operator and plan cache\nDESCRIPTION: This SQL code prepares and executes a statement that selects from table `t5` using the `member of` operator on the indexed JSON column `j1`. It checks if the query plan is cached by examining the `@@last_plan_from_cache` variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nmysql> PREPARE st FROM 'SELECT /*+ use_index(t5, idx1) */ * FROM t5 WHERE (? member of (j1))';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SET @a=1;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> EXECUTE st USING @a;\nEmpty set (0.01 sec)\n\nmysql> EXECUTE st USING @a;\nEmpty set (0.00 sec)\n\nmysql> SELECT @@last_plan_from_cache;\n+------------------------+\n| @@last_plan_from_cache |\n+------------------------+\n|                      1 |\n+------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Using STRAIGHT_JOIN for Join Order Control\nDESCRIPTION: Example demonstrating how to force join order based on FROM clause table sequence.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_49\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ STRAIGHT_JOIN() */ * FROM t t1, t t2 WHERE t1.a = t2.a;\n```\n\n----------------------------------------\n\nTITLE: Showing Specific Import Job - SQL\nDESCRIPTION: This SQL command retrieves detailed information about a specific import job identified by the provided job ID. Access to this information is restricted to the creator of the job or users with elevated permissions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-import-job.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW IMPORT JOB 60001;\n```\n\n----------------------------------------\n\nTITLE: Locking and Analyzing a Specific Partition in TiDB\nDESCRIPTION: This SQL snippet demonstrates locking statistics for a specific partition (p1) with LOCK STATS PARTITION, checking locked status, and attempting to analyze. The ANALYZE statement skips the locked partition as shown in the warnings.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nmysql> LOCK STATS t PARTITION p1;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SHOW STATS_LOCKED;\n+---------+------------+----------------+--------+\n| Db_name | Table_name | Partition_name | Status |\n+---------+------------+----------------+--------+\n| test    | t          | p1             | locked |\n+---------+------------+----------------+--------+\n1 row in set (0.00 sec)\n\nmysql> ANALYZE TABLE t PARTITION p1;\nQuery OK, 0 rows affected, 2 warnings (0.01 sec)\n\nmysql> SHOW WARNINGS;\n+---------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Level   | Code | Message                                                                                                                                                              |\n+---------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Note    | 1105 | Analyze use auto adjusted sample rate 1.000000 for table test.t's partition p1, reason to use this rate is \"TiDB assumes that the table is empty, use sample-rate=1\" |\n| Warning | 1105 | skip analyze locked table: test.t partition (p1)                                                                                                                     |\n+---------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n2 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Viewing Truncated Result from TIDB_DECODE_SQL_DIGESTS Function\nDESCRIPTION: Shows the output of TIDB_DECODE_SQL_DIGESTS with a truncation length of 10 characters. The third statement exceeds this length, so it's truncated and appended with '...'.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n+---------------------------------------+\n| TIDB_DECODE_SQL_DIGESTS(@digests, 10) |\n+---------------------------------------+\n| [\"begin\",null,\"select * f...\"]        |\n+---------------------------------------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Pushing TopN to Coprocessors in Storage Layer\nDESCRIPTION: SQL example demonstrating how TopN operator is pushed down to TiKV Coprocessors for data filtering, where each Coprocessor returns only 10 records to TiDB before final aggregation.\nSOURCE: https://github.com/pingcap/docs/blob/master/topn-limit-push-down.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id int primary key, a int not null);\nexplain select * from t order by a limit 10;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Clusters in ProxySQL\nDESCRIPTION: This SQL script adds a TiDB Cloud Dedicated cluster to ProxySQL's mysql_servers table and applies the changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO mysql_servers(hostgroup_id, hostname, port) \nVALUES \n  (\n    0,\n    '<tidb cloud dedicated cluster host>', \n    <tidb cloud dedicated cluster port>\n  );\nLOAD mysql servers TO runtime;\nSAVE mysql servers TO DISK;\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure AD Environment Variables for TiKV Service\nDESCRIPTION: A systemd service configuration example for setting up Azure AD environment variables for a TiKV node. This configuration enables Azure AD authentication for backup and restore operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\n[Service]\nEnvironment=\"AZURE_CLIENT_ID=aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa\"\nEnvironment=\"AZURE_TENANT_ID=aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa\"\nEnvironment=\"AZURE_CLIENT_SECRET=aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Kafka Consumer for TiCDC Avro Data Verification in Go\nDESCRIPTION: This code snippet demonstrates how to create a Kafka consumer in Go to read TiCDC data encoded with Avro, decode the messages, and verify the checksum. It uses the kafka-go library for Kafka operations and includes error handling and logging.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-checksum-verification.md#2025-04-18_snippet_0\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n    \"context\"\n    \"encoding/binary\"\n    \"encoding/json\"\n    \"hash/crc32\"\n    \"io\"\n    \"math\"\n    \"net/http\"\n    \"strconv\"\n    \"strings\"\n\n    \"github.com/linkedin/goavro/v2\"\n    \"github.com/pingcap/log\"\n    \"github.com/pingcap/tidb/parser/mysql\"\n    \"github.com/pingcap/tidb/types\"\n    \"github.com/pingcap/tiflow/pkg/errors\"\n    \"github.com/segmentio/kafka-go\"\n    \"go.uber.org/zap\"\n)\n\nconst (\n    // The first byte of the Confluent Avro wire format is always 0.\n    // For more details, see https://docs.confluent.io/platform/current/schema-registry/fundamentals/serdes-develop/index.html#wire-format.\n    magicByte = uint8(0)\n)\n\nfunc main() {\n    var (\n        kafkaAddr         = \"127.0.0.1:9092\"\n        schemaRegistryURL = \"http://127.0.0.1:8081\"\n\n        topic           = \"avro-checksum-test\"\n        consumerGroupID = \"avro-checksum-test\"\n    )\n\n    consumer := kafka.NewReader(kafka.ReaderConfig{\n        Brokers:  []string{kafkaAddr},\n        GroupID:  consumerGroupID,\n        Topic:    topic,\n        MaxBytes: 10e6, // 10MB\n    })\n    defer consumer.Close()\n\n    ctx := context.Background()\n    log.Info(\"start consuming ...\", zap.String(\"kafka\", kafkaAddr), zap.String(\"topic\", topic), zap.String(\"groupID\", consumerGroupID))\n    for {\n        // 1. Fetch the kafka message.\n        message, err := consumer.FetchMessage(ctx)\n        if err != nil {\n            log.Error(\"read kafka message failed\", zap.Error(err))\n        }\n\n        value := message.Value\n        if len(value) == 0 {\n            log.Info(\"delete event does not have value, skip checksum verification\", zap.String(\"topic\", topic))\n        }\n\n        // 2. Decode the value to get the corresponding value map and schema map.\n        valueMap, valueSchema, err := getValueMapAndSchema(value, schemaRegistryURL)\n        if err != nil {\n            log.Panic(\"decode kafka value failed\", zap.String(\"topic\", topic), zap.ByteString(\"value\", value), zap.Error(err))\n        }\n\n        // 3. Calculate and verify checksum value using the value map and schema map obtained in the previous step.\n        err = CalculateAndVerifyChecksum(valueMap, valueSchema)\n        if err != nil {\n            log.Panic(\"calculate checksum failed\", zap.String(\"topic\", topic), zap.ByteString(\"value\", value), zap.Error(err))\n        }\n\n        // 4. Commit offset after the data is successfully consumed.\n        if err := consumer.CommitMessages(ctx, message); err != nil {\n            log.Error(\"commit kafka message failed\", zap.Error(err))\n            break\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Available Character Sets in TiDB\nDESCRIPTION: SQL query to display all supported character sets in TiDB system.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CHARACTER SET;\n```\n\n----------------------------------------\n\nTITLE: Starting a Log Backup Task in Shell\nDESCRIPTION: Example command for starting a TiDB log backup task, specifying the task name, PD address, and Amazon S3 storage location with access credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log start \\\n  --task-name=pitr \\\n  --pd=\"${PD_IP}:2379\" \\\n  --storage='s3://backup-101/logbackup?access-key=${access-key}&secret-access-key=${secret-access-key}'\n```\n\n----------------------------------------\n\nTITLE: Splitting a Region of a Partitioned Table in SQL\nDESCRIPTION: This SQL snippet splits the data in the range [0,10000] of each partition of table 't' into four regions, allowing for better data distribution and performance tuning.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nsplit partition table t between (0) and (10000) regions 4;\n```\n\n----------------------------------------\n\nTITLE: Creating a Database Schema in SQL for TiDB Cloud Data Import\nDESCRIPTION: A SQL statement to create a database in TiDB Cloud. This database schema file should be named 'mydb-schema-create.sql' and placed in the same Amazon S3 or GCS directory as the Parquet files to be imported.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-parquet-files.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE mydb;\n```\n\n----------------------------------------\n\nTITLE: Creating Table Without Primary Key for Shard Merging\nDESCRIPTION: SQL schema demonstrating how to create a table without a primary key to handle auto-increment conflicts during shard merging. The example shows converting a primary key to a regular index while maintaining a unique key constraint.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/shard-merge-best-practices.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `tbl_no_pk` (\n  `auto_pk_c1` bigint NOT NULL,\n  `uk_c2` bigint NOT NULL,\n  `content_c3` text,\n  PRIMARY KEY (`auto_pk_c1`),\n  UNIQUE KEY `uk_c2` (`uk_c2`)\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `tbl_no_pk_2` (\n  `auto_pk_c1` bigint NOT NULL,\n  `uk_c2` bigint NOT NULL,\n  `content_c3` text,\n  INDEX (`auto_pk_c1`),\n  UNIQUE KEY `uk_c2` (`uk_c2`)\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\n```\n\n----------------------------------------\n\nTITLE: Importing Required Python Packages for LlamaIndex Integration\nDESCRIPTION: Imports necessary Python modules and classes from llama_index to work with document readers, vector stores, and storage contexts.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport textwrap\n\nfrom llama_index.core import SimpleDirectoryReader, StorageContext\nfrom llama_index.core import VectorStoreIndex\nfrom llama_index.vector_stores.tidbvector import TiDBVectorStore\n```\n\n----------------------------------------\n\nTITLE: Configuring MySQL Data Source in YAML\nDESCRIPTION: Configuration file for setting up MySQL data source connection details including host, credentials and GTID settings\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/migrate-data-using-dm.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsource-id: \"mysql-replica-01\"\nenable-gtid: false\n\nfrom:\n  host: \"172.16.10.81\"\n  user: \"root\"\n  password: \"VjX8cEeTX+qcvZ3bPaO4h0C80pe/1aU=\"\n  port: 3306\n```\n\n----------------------------------------\n\nTITLE: Creating a User Profile with ticloud config create\nDESCRIPTION: This command creates a user profile to store profile settings in TiDB Cloud CLI. It can be used in both interactive and non-interactive modes. Before creating a profile, a TiDB Cloud API Key is required.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-create.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud config create [flags]\n```\n\n----------------------------------------\n\nTITLE: Appending Length-Prefixed Values in Go\nDESCRIPTION: This function appends a length-prefixed value to a byte slice buffer. It first appends the length of the value as a 32-bit little-endian integer, then appends the value itself.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-checksum-verification.md#2025-04-18_snippet_6\n\nLANGUAGE: Go\nCODE:\n```\nfunc appendLengthValue(buf []byte, val []byte) []byte {\n    buf = binary.LittleEndian.AppendUint32(buf, uint32(len(val)))\n    buf = append(buf, val...)\n    return buf\n}\n```\n\n----------------------------------------\n\nTITLE: Setting SQL Execution Timeout\nDESCRIPTION: Use max_execution_time to limit the execution time of a single SQL statement. This only affects read-only SQL statements and has a precision of 100ms.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-timeouts-in-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSET max_execution_time = 5000;\n```\n\n----------------------------------------\n\nTITLE: Enabling TiFlash Replica for HTAP in TiDB\nDESCRIPTION: This SQL command creates one TiFlash replica for the ratings table in the bookshop database, enabling HTAP (Hybrid Transactional and Analytical Processing) capabilities.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE `bookshop`.`ratings` SET TIFLASH REPLICA 1;\n```\n\n----------------------------------------\n\nTITLE: Create DM Migration Task Configuration\nDESCRIPTION: This YAML configuration defines a DM migration task. It specifies the task name, mode (full, incremental, or all), target TiDB database connection details, and source MySQL instance(s) along with block/allow list configurations.  This is the minimum configuration to perform the migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-to-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n\"# Task name. Each of the multiple tasks running at the same time must have a unique name.\nname: \\\"test\\\"\\n# Task mode. Options are:\n# full: only performs full data migration.\n# incremental: only performs binlog real-time replication.\n# all: full data migration + binlog real-time replication.\ntask-mode: \\\"all\\\"\\n# The configuration of the target TiDB database.\ntarget-database:\n  host: \\\"${host}\\\"                   # For example: 172.16.10.83\n  port: 4000\n  user: \\\"root\\\"\n  password: \\\"${password}\\\"           # Plaintext password is supported but not recommended. It is recommended to use dmctl encrypt to encrypt the plaintext password before using the password.\n\n# The configuration of all MySQL instances of source database required for the current migration task.\nmysql-instances:\n-\n  # The ID of an upstream instance or a replication group\n  source-id: \\\"mysql-01\\\"\n  # The names of the block list and allow list configuration of the schema name or table name that is to be migrated. These names are used to reference the global configuration of the block and allowlist. For the global configuration, refer to the `block-allow-list` configuration below.\n  block-allow-list: \\\"listA\\\"\\n\n# The global configuration of blocklist and allowlist. Each instance is referenced by a configuration item name.\nblock-allow-list:\n  listA:                              # name\n    do-tables:                        # The allowlist of upstream tables that need to be migrated.\n    - db-name: \\\"test_db\\\"              # The schema name of the table to be migrated.\n      tbl-name: \\\"test_table\\\"          # The name of the table to be migrated.\n\"\n```\n\n----------------------------------------\n\nTITLE: Managing TLS for SQL Connections in TiDB\nDESCRIPTION: Controls the use of TLS for SQL connections with various options to enforce, disable, or prefer TLS connections. The security settings must be properly configured for optimal performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_15\n\nLANGUAGE: markdown\nCODE:\n```\nValue options:\n    * `\"\"`: forces TLS (the same as \"cluster\") if the [`[tidb.security]`](#tidbsecurity) section is populated. Otherwise, the same as \"false\".\n    * `\"false\"`: disables TLS.\n    * `\"cluster\"`: forces TLS and verifies the server's certificate with the CA specified in the [`[tidb.security]`](#tidbsecurity) section.\n    * `\"skip-verify\"`: forces TLS but does not verify the server's certificate. Note that this setting is insecure.\n    * `\"preferred\"`: the same as \"skip-verify\", but if the server does not support TLS, fall back to the unencrypted connection.\n```\n\n----------------------------------------\n\nTITLE: Creating User and Resource Groups Example\nDESCRIPTION: SQL example showing how to create a user, create resource groups, and bind a user to a resource group.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-resource-group.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'user1';\nCREATE RESOURCE GROUP 'rg1' RU_PER_SEC = 1000;\nALTER USER 'user1' RESOURCE GROUP `rg1`;\n```\n\n----------------------------------------\n\nTITLE: Backing up TiDB Data to Azure Blob Storage with Azure AD\nDESCRIPTION: This command demonstrates how to use BR to back up a full TiDB cluster to Azure Blob Storage using Azure AD authentication. It specifies the PD endpoint and the Azure storage path with the account name.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full -u \"${PD_IP}:2379\" \\\n--storage \"azure://external/backup-20220915?account-name=${account-name}\"\n```\n\n----------------------------------------\n\nTITLE: Dropping Columns from Tables\nDESCRIPTION: These SQL statements drop the `Name` column from `tbl00` and `tbl02` respectively. This simulates the process of removing the same column from all sharded tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-shard-merge-optimistic.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER TABLE `tbl00` DROP COLUMN `Name`;\nALTER TABLE `tbl02` DROP COLUMN `Name`;\n```\n```\n\n----------------------------------------\n\nTITLE: Aggregating profits by year with SQL\nDESCRIPTION: This SQL query retrieves the total profit aggregated by year from the 'bank' table using a GROUP BY clause. It summarizes the data effectively for yearly profit analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/group-by-modifier.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT year, SUM(profit) AS profit FROM bank GROUP BY year;\n```\n\n----------------------------------------\n\nTITLE: Setting Password Complexity Level in TiDB\nDESCRIPTION: This SQL command sets the password complexity level to LOW in TiDB, which adjusts the stringency of the password requirements based on predefined policies.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL validate_password.policy = LOW;\n```\n\n----------------------------------------\n\nTITLE: Updating Data with ActiveRecord ORM in Rails\nDESCRIPTION: Ruby code that updates a Player record's coins and goods attributes using ActiveRecord's update method.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_13\n\nLANGUAGE: ruby\nCODE:\n```\nplayer.update(coins: 50, goods: 50)\n```\n\n----------------------------------------\n\nTITLE: Pushing Predicates to Storage Layer\nDESCRIPTION: Demonstrates how simple predicates can be pushed down to TiKV layer for early data filtering, reducing network transmission costs\nSOURCE: https://github.com/pingcap/docs/blob/master/predicate-push-down.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id int primary key, a int);\nexplain select * from t where a < 1;\n```\n\n----------------------------------------\n\nTITLE: Executing Transaction Operations with Prisma Client\nDESCRIPTION: Perform transaction operations using Prisma Client, demonstrating success and failure scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-prisma-example.md#2025-04-18_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nconst createUser1 = prisma.user.create({\n  data: {\n    email: 'test1@pingcap.com',\n    name: 'test1',\n  },\n})\nconst createUser2 = prisma.user.create({\n  data: {\n    email: 'test1@pingcap.com',\n    name: 'test1',\n  },\n})\nconst createUser3 = prisma.user.create({\n  data: {\n    email: 'test2@pingcap.com',\n    name: 'test2',\n  },\n})\n\ntry {\n  await prisma.$transaction([createUser1, createUser2]) // Operations fail because the email address is duplicated\n} catch (e) {\n  console.log(e)\n}\n\ntry {\n  await prisma.$transaction([createUser2, createUser3]) // Operations success because the email address is unique\n} catch (e) {\n  console.log(e)\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS for PD\nDESCRIPTION: This code snippet details the configuration of TLS settings for the PD component in the configuration file. It defines the paths for the CA certificate, server certificate, and server key to enable secure communication between PD and other cluster components using HTTPS.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n\t\t```toml\n        [security]\n        ## The path for certificates. An empty string means that secure connections are disabled.\n        # Path of the file that contains a list of trusted SSL CAs. If it is set, the following settings `cert_path` and `key_path` are also needed.\n        cacert-path = \"/path/to/ca.pem\"\n        # Path of the file that contains X509 certificate in PEM format.\n        cert-path = \"/path/to/pd-server.pem\"\n        # Path of the file that contains X509 key in PEM format.\n        key-path = \"/path/to/pd-server-key.pem\"\n        ```\n```\n\n----------------------------------------\n\nTITLE: Verifying TiDB Cluster Status\nDESCRIPTION: Displays the running status of the TiDB cluster named 'tidb-test', showing component status including whether they are 'Up' and running properly.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster display tidb-test\n```\n\n----------------------------------------\n\nTITLE: Showing Column Statistics with Last Analyzed Timestamp in SQL\nDESCRIPTION: Retrieves statistics for columns in table 't' that have been analyzed, filtering for columns with a non-null last_analyzed_at timestamp.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\n-- Specify `last_analyzed_at IS NOT NULL` to show the columns for which statistics have been collected.\nSHOW COLUMN_STATS_USAGE\nWHERE db_name = 'test' AND table_name = 't' AND last_analyzed_at IS NOT NULL;\n```\n\n----------------------------------------\n\nTITLE: Querying Collation Status in TiDB\nDESCRIPTION: SQL query to check whether the new collation framework is enabled by querying the mysql.tidb system table.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VARIABLE_VALUE FROM mysql.tidb WHERE VARIABLE_NAME='new_collation_enabled';\n```\n\n----------------------------------------\n\nTITLE: TiDB Lightning Configuration for Data Import\nDESCRIPTION: This TOML configuration file is used by TiDB Lightning to import the data snapshot from Aurora stored in S3 into TiDB. It includes connection details and data source configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_4\n\nLANGUAGE: TOML\nCODE:\n```\n[tidb]\nhost = ${host}\nport = ${port}\nuser = \"${user_name}\"\npassword = \"${password}\"\nstatus-port = ${status-port}\npd-addr = \"${ip}:${port}\"\n\n[tikv-importer]\nbackend = \"local\"\nsorted-kv-dir = \"${path}\"\n\n[mydumper]\ndata-source-dir = \"${s3_path}\"\n\n[[mydumper.files]]\npattern = '(?i)^(?:[^/]*/)*([a-z0-9_]+)\\.([a-z0-9_]+)/(?:[^/]*/)*(?:[a-z0-9\\-_.]+\\.(parquet))$'\nschema = '$1'\ntable = '$2'\ntype = '$3'\n```\n\n----------------------------------------\n\nTITLE: Executing TRACE with Row Format in TiDB SQL\nDESCRIPTION: Example of using the TRACE statement with 'row' format to analyze a SELECT query execution on the mysql.user table. The output provides a hierarchical view of operations, start times, and durations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-trace.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nTRACE FORMAT='row' SELECT * FROM mysql.user;\n```\n\n----------------------------------------\n\nTITLE: Creating a Locked User Account in TiDB SQL\nDESCRIPTION: SQL statement to create a new user 'newuser5' with a locked account in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser5'@'%' ACCOUNT LOCK;\n```\n\n----------------------------------------\n\nTITLE: Directory structure of jaffle_shop dbt project\nDESCRIPTION: Overview of the jaffle_shop project file structure showing the organization of models, seeds, and configuration files in a typical dbt project.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n.\n├── LICENSE\n├── README.md\n├── dbt_project.yml\n├── etc\n│    ├── dbdiagram_definition.txt\n│    └── jaffle_shop_erd.png\n├── models\n│    ├── customers.sql\n│    ├── docs.md\n│    ├── orders.sql\n│    ├── overview.md\n│    ├── schema.yml\n│    └── staging\n│        ├── schema.yml\n│        ├── stg_customers.sql\n│        ├── stg_orders.sql\n│        └── stg_payments.sql\n└── seeds\n    ├── raw_customers.csv\n    ├── raw_orders.csv\n    └── raw_payments.csv\n```\n\n----------------------------------------\n\nTITLE: Daily Index Region Splitting in SQL\nDESCRIPTION: This SQL statement splits index 'idx2' in table 't' into 30 Regions, representing daily intervals over the month of June 2020.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT TABLE t INDEX idx2 BETWEEN (\"2020-06-01 00:00:00\") AND (\"2020-07-01 00:00:00\") REGIONS 30;\n```\n\n----------------------------------------\n\nTITLE: SQL Savepoint Example for Nested Transactions\nDESCRIPTION: This SQL example demonstrates the savepoint mechanism in TiDB, showing how to create a savepoint, roll back to it, and then release it within a transaction. The example inserts values into table T2 and rolls back partially.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-restraints.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nmysql> BEGIN;\nmysql> INSERT INTO T2 VALUES(100);\nmysql> SAVEPOINT svp1;\nmysql> INSERT INTO T2 VALUES(200);\nmysql> ROLLBACK TO SAVEPOINT svp1;\nmysql> RELEASE SAVEPOINT svp1;\nmysql> COMMIT;\nmysql> SELECT * FROM T2;\n+------+\n|  ID   |\n+------+\n|  100 |\n+------+\n```\n\n----------------------------------------\n\nTITLE: Creating Temporary Tables in TiDB\nDESCRIPTION: Demonstrates the syntax for creating global or local temporary tables in TiDB. Global temporary tables are visible to all sessions with persistent schema, while local temporary tables are session-specific with non-persistent schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.0.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE [GLOBAL] TEMPORARY TABLE\n```\n\n----------------------------------------\n\nTITLE: Querying TiKV Store Status Across Regions\nDESCRIPTION: SQL query to display TiKV node distribution across regions, zones and hosts, showing store IDs, addresses and topology labels.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSELECT store_id,address,label from INFORMATION_SCHEMA.TIKV_STORE_STATUS;\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Primary Key and Auto Increment\nDESCRIPTION: Shows how to create a table with an auto-incrementing primary key column, defining integer column constraints\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\n```\n\n----------------------------------------\n\nTITLE: TiCDC Debezium Message Value Format in JSON\nDESCRIPTION: This JSON structure represents the value format of a TiCDC Debezium message. It includes payload and schema information, with details about the source, operation type, timestamp, and field definitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-debezium.md#2025-04-18_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"payload\": {\n        \"source\": {\n            \"version\": \"2.4.0.Final\",\n            \"connector\": \"TiCDC\",\n            \"name\": \"test_cluster\",\n            \"ts_ms\": 0,\n            \"snapshot\": \"false\",\n            \"db\": \"\",\n            \"table\": \"\",\n            \"server_id\": 0,\n            \"gtid\": null,\n            \"file\": \"\",\n            \"pos\": 0,\n            \"row\": 0,\n            \"thread\": 0,\n            \"query\": null,\n            \"commit_ts\": 3,\n            \"cluster_id\": \"test_cluster\"\n        },\n        \"op\": \"m\",\n        \"ts_ms\": 1701326309000,\n        \"transaction\": null\n    },\n    \"schema\": {\n        \"type\": \"struct\",\n        \"optional\": false,\n        \"name\": \"test_cluster.watermark.Envelope\",\n        \"version\": 1,\n        \"fields\": [\n            {\n                \"type\": \"struct\",\n                \"fields\": [\n                    {\n                        \"type\": \"string\",\n                        \"optional\": false,\n                        \"field\": \"version\"\n                    },\n                    {\n                        \"type\": \"string\",\n                        \"optional\": false,\n                        \"field\": \"connector\"\n                    },\n                    {\n                        \"type\": \"string\",\n                        \"optional\": false,\n                        \"field\": \"name\"\n                    },\n                    {\n                        \"type\": \"int64\",\n                        \"optional\": false,\n                        \"field\": \"ts_ms\"\n                    },\n                    {\n                        \"type\": \"string\",\n                        \"optional\": true,\n                        \"name\": \"io.debezium.data.Enum\",\n                        \"version\": 1,\n                        \"parameters\": {\n                            \"allowed\": \"true,last,false,incremental\"\n                        },\n                        \"default\": \"false\",\n                        \"field\": \"snapshot\"\n                    },\n                    {\n                        \"type\": \"string\",\n                        \"optional\": false,\n                        \"field\": \"db\"\n                    },\n                    {\n                        \"type\": \"string\",\n                        \"optional\": true,\n                        \"field\": \"sequence\"\n                    },\n                    {\n                        \"type\": \"string\",\n                        \"optional\": true,\n                        \"field\": \"table\"\n                    },\n                    {\n                        \"type\": \"int64\",\n                        \"optional\": false,\n                        \"field\": \"server_id\"\n                    },\n                    {\n                        \"type\": \"string\",\n                        \"optional\": true,\n                        \"field\": \"gtid\"\n                    },\n                    {\n                        \"type\": \"string\",\n                        \"optional\": false,\n                        \"field\": \"file\"\n                    },\n                    {\n                        \"type\": \"int64\",\n                        \"optional\": false,\n                        \"field\": \"pos\"\n                    },\n                    {\n                        \"type\": \"int32\",\n                        \"optional\": false,\n                        \"field\": \"row\"\n                    },\n                    {\n                        \"type\": \"int64\",\n                        \"optional\": true,\n                        \"field\": \"thread\"\n                    },\n                    {\n                        \"type\": \"string\",\n                        \"optional\": true,\n                        \"field\": \"query\"\n                    }\n                ],\n                \"optional\": false,\n                \"name\": \"io.debezium.connector.mysql.Source\",\n                \"field\": \"source\"\n            },\n            {\n                \"type\": \"string\",\n                \"optional\": false,\n                \"field\": \"op\"\n            },\n            {\n                \"type\": \"int64\",\n                \"optional\": true,\n                \"field\": \"ts_ms\"\n            },\n            {\n                \"type\": \"struct\",\n                \"fields\": [\n                    {\n                        \"type\": \"string\",\n                        \"optional\": false,\n                        \"field\": \"id\"\n                    },\n                    {\n                        \"type\": \"int64\",\n                        \"optional\": false,\n                        \"field\": \"total_order\"\n                    },\n                    {\n                        \"type\": \"int64\",\n                        \"optional\": false,\n                        \"field\": \"data_collection_order\"\n                    }\n                ],\n                \"optional\": true,\n                \"name\": \"event.block\",\n                \"version\": 1,\n                \"field\": \"transaction\"\n            }\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Monotonous Function Partition Pruning\nDESCRIPTION: Demonstrates partition pruning with monotonous function TO_DAYS() in the partition expression, showing how date-based partitioning can be optimized.\nSOURCE: https://github.com/pingcap/docs/blob/master/partition-pruning.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (id datetime) partition by range (to_days(id)) (\n    partition p0 values less than (to_days('2020-04-01')),\n    partition p1 values less than (to_days('2020-05-01')));\nexplain select * from t where id > '2020-04-18';\n```\n\n----------------------------------------\n\nTITLE: Configuring Key-Value Entry Size Limit in TiDB\nDESCRIPTION: Adds the 'txn-entry-size-limit' configuration option to make the size limit of key-value entries in transactions configurable in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.10.md#2025-04-18_snippet_0\n\nLANGUAGE: Go\nCODE:\n```\n// GitHub PR: https://github.com/pingcap/tidb/pull/21843\n// Implementation details not provided in the release notes\n```\n\n----------------------------------------\n\nTITLE: Data Definition Example\nDESCRIPTION: Creates example tables for detail and daily data with TiFlash replicas and inserts sample data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-results-materialization.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE detail_data (\n    ts DATETIME,                -- Fee generation time\n    customer_id VARCHAR(20),    -- Customer ID\n    detail_fee DECIMAL(20,2));  -- Amount of fee\n\nCREATE TABLE daily_data (\n    rec_date DATE,              -- Date when data is collected\n    customer_id VARCHAR(20),    -- Customer ID\n    daily_fee DECIMAL(20,2));   -- Amount of fee for per day\n\nALTER TABLE detail_data SET TIFLASH REPLICA 2;\nALTER TABLE daily_data SET TIFLASH REPLICA 2;\n\n-- ... (detail_data table continues updating)\nINSERT INTO detail_data(ts,customer_id,detail_fee) VALUES\n('2023-1-1 12:2:3', 'cus001', 200.86),\n('2023-1-2 12:2:3', 'cus002', 100.86),\n('2023-1-3 12:2:3', 'cus002', 2200.86),\n('2023-1-4 12:2:3', 'cus003', 2020.86),\n('2023-1-5 12:2:3', 'cus003', 1200.86),\n('2023-1-6 12:2:3', 'cus002', 20.86),\n('2023-1-7 12:2:3', 'cus004', 120.56),\n('2023-1-8 12:2:3', 'cus005', 320.16);\n```\n\n----------------------------------------\n\nTITLE: Setting Up TiDB Clusters Using TiUP Playground\nDESCRIPTION: This snippet demonstrates how to create an upstream and a downstream TiDB cluster using TiUP Playground. The commands configure the clusters on two specified nodes. Dependencies include TiUP and an appropriate environment setup.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n# Create an upstream cluster on Node A\n    tiup --tag upstream playground --host 0.0.0.0 --db 1 --pd 1 --kv 1 --tiflash 0 --ticdc 1\n    # Create a downstream cluster on Node B\n    tiup --tag downstream playground --host 0.0.0.0 --db 1 --pd 1 --kv 1 --tiflash 0 --ticdc 0\n    # View cluster status\n    tiup status\n```\n\n----------------------------------------\n\nTITLE: Setting and Using a Granted Role\nDESCRIPTION: SQL commands showing how a user needs to explicitly set a role before using its privileges, and the difference in grants and permissions before and after setting the role.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-grant-role.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS;\n+---------------------------------------------+\n| Grants for User                             |\n+---------------------------------------------+\n| GRANT USAGE ON *.* TO 'jennifer'@'%'        |\n| GRANT 'analyticsteam'@'%' TO 'jennifer'@'%' |\n+---------------------------------------------+\n2 rows in set (0.00 sec)\n\nSHOW TABLES in test;\nERROR 1044 (42000): Access denied for user 'jennifer'@'%' to database 'test'\nSET ROLE analyticsteam;\nQuery OK, 0 rows affected (0.00 sec)\n\nSHOW GRANTS;\n+---------------------------------------------+\n| Grants for User                             |\n+---------------------------------------------+\n| GRANT USAGE ON *.* TO 'jennifer'@'%'        |\n| GRANT SELECT ON test.* TO 'jennifer'@'%'    |\n| GRANT 'analyticsteam'@'%' TO 'jennifer'@'%' |\n+---------------------------------------------+\n3 rows in set (0.00 sec)\n\nSHOW TABLES IN test;\n+----------------+\n| Tables_in_test |\n+----------------+\n| t1             |\n+----------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Using Default Role After Reconnecting\nDESCRIPTION: SQL commands showing how a user with a default role automatically has access to the role's privileges without explicitly setting the role.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-grant-role.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS;\n+---------------------------------------------+\n| Grants for User                             |\n+---------------------------------------------+\n| GRANT USAGE ON *.* TO 'jennifer'@'%'        |\n| GRANT SELECT ON test.* TO 'jennifer'@'%'    |\n| GRANT 'analyticsteam'@'%' TO 'jennifer'@'%' |\n+---------------------------------------------+\n3 rows in set (0.00 sec)\n\nSHOW TABLES IN test;\n+----------------+\n| Tables_in_test |\n+----------------+\n| t1             |\n+----------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Altering a user and binding to a resource group\nDESCRIPTION: This SQL statement modifies the user `usr2` to bind them to the resource group `rg2`. After this statement is executed, new sessions created by `usr2` will have their resource consumption controlled by the resource group `rg2`. Existing sessions of `usr2` are not affected.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-ru-groups.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n\"ALTER USER usr2 RESOURCE GROUP rg2;\"\n```\n\n----------------------------------------\n\nTITLE: Creating MySQL Data Source Configuration in YAML\nDESCRIPTION: Configures a MySQL data source for TiDB Data Migration with connection details and GTID settings\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nsource-id: \"mysql-01\"\nenable-gtid: false\n\nfrom:\n  host: \"${host}\"\n  user: \"root\"\n  password: \"${password}\"\n  port: 3306\n```\n\n----------------------------------------\n\nTITLE: Preventing Region Merging for a Table in SQL\nDESCRIPTION: Demonstrates how to prevent Regions of a table from merging by setting the merge_option attribute to 'deny'.\nSOURCE: https://github.com/pingcap/docs/blob/master/table-attributes.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t ATTRIBUTES 'merge_option=deny';\n```\n\n----------------------------------------\n\nTITLE: Modifying DDL Job Parameters in TiDB SQL\nDESCRIPTION: Example of using ADMIN ALTER DDL JOBS to modify the thread count of a running DDL job. The statement takes a job ID and allows setting parameters like THREAD, BATCH_SIZE, and MAX_WRITE_SPEED.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-alter-ddl.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nADMIN ALTER DDL JOBS 101 THREAD = 8;\n```\n\n----------------------------------------\n\nTITLE: Configuring Common Table Expression Recursion Depth in TiDB SQL\nDESCRIPTION: Sets the maximum recursion depth for Common Table Expressions in TiDB. This is a newly added system variable in TiDB 5.1.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.0.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET cte_max_recursion_depth = <value>;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Cluster Topology\nDESCRIPTION: TOML configuration file that defines the topology for a TiDB cluster with 5 replicas across 3 regions, including PD servers, TiDB servers, TiKV servers, and monitoring components\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-multi-replica.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nglobal:\n  user: \"root\"\n  ssh_port: 22\n  deploy_dir: \"/data/tidb_cluster/tidb-deploy\"\n  data_dir: \"/data/tidb_cluster/tidb-data\"\n\nserver_configs:\n  tikv:\n    server.grpc-compression-type: gzip\n  pd:\n    replication.location-labels:  [\"Region\",\"AZ\"]\n\npd_servers:\n  - host: tidb-dr-test1\n    name: \"pd-1\"\n  - host: tidb-dr-test2\n    name: \"pd-2\"\n  - host: tidb-dr-test3\n    name: \"pd-3\"\n  - host: tidb-dr-test4\n    name: \"pd-4\"\n  - host: tidb-dr-test5\n    name: \"pd-5\"\n\ntidb_servers:\n  - host: tidb-dr-test1\n  - host: tidb-dr-test3\n\ntikv_servers:\n  - host: tidb-dr-test1\n    config:\n      server.labels: { Region: \"Region1\", AZ: \"AZ1\" }\n  - host: tidb-dr-test2\n    config:\n      server.labels: { Region: \"Region1\", AZ: \"AZ2\" }\n  - host: tidb-dr-test3\n    config:\n      server.labels: { Region: \"Region2\", AZ: \"AZ3\" }\n  - host: tidb-dr-test4\n    config:\n      server.labels: { Region: \"Region2\", AZ: \"AZ4\" }\n  - host: tidb-dr-test5\n    config:\n      server.labels: { Region: \"Region3\", AZ: \"AZ5\" }\n      raftstore.raft-min-election-timeout-ticks: 50\n      raftstore.raft-max-election-timeout-ticks: 60\n\nmonitoring_servers:\n  - host: tidb-dr-test2\n\ngrafana_servers:\n  - host: tidb-dr-test2\n\nalertmanager_servers:\n  - host: tidb-dr-test2\n```\n\n----------------------------------------\n\nTITLE: Explaining Point Get Query Execution in TiDB\nDESCRIPTION: This SQL query demonstrates the execution plan for a Point Get operation, which uses a primary key lookup to efficiently retrieve data from a table named 'emp'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT id, name FROM emp WHERE id = 901;\n```\n\n----------------------------------------\n\nTITLE: Basic Window Function with ROW_NUMBER Example\nDESCRIPTION: Example showing a typical window function query using ROW_NUMBER() with filtering that can be optimized.\nSOURCE: https://github.com/pingcap/docs/blob/master/derive-topn-from-window.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM (SELECT ROW_NUMBER() OVER (ORDER BY a) AS rownumber FROM t) dt WHERE rownumber <= 3\n```\n\n----------------------------------------\n\nTITLE: Revoking Multiple Roles from a User in TiDB\nDESCRIPTION: This snippet shows how to revoke multiple roles from a single user in TiDB using the `REVOKE` statement. The operation is atomic, meaning if any part of the revocation fails, the entire operation rolls back. To execute this statement, the user needs the `SUPER` privilege.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE 'app_read', 'app_write' FROM 'rw_user1'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Querying Statistics Buckets with SQL in TiDB\nDESCRIPTION: This SQL snippet demonstrates how to use the SHOW STATS_BUCKETS statement to filter and display statistics buckets for a specific table in the TiDB database system. It requires a running instance of TiDB. The snippet outputs a table with details such as database name, table name, and bucket boundaries.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-buckets.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\n\"SHOW STATS_BUCKETS WHERE Table_name='t';\"\n```\n\n----------------------------------------\n\nTITLE: Starting Read-Only Transaction with Historical Timestamp in SQL\nDESCRIPTION: Demonstrates how to start a read-only transaction that reads data from a specific historical timestamp using SQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-stale-read.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSTART TRANSACTION READ ONLY AS OF TIMESTAMP NOW() - INTERVAL 5 SECOND;\n```\n\n----------------------------------------\n\nTITLE: Creating Published Date Index in TiDB\nDESCRIPTION: SQL statement showing how to create an index on the published_at column for timestamp-based queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-index-best-practice.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX published_at_idx ON books (published_at);\n```\n\n----------------------------------------\n\nTITLE: JDBC Connection Setup\nDESCRIPTION: Java code example showing how to create a JDBC connection to TiDB using MysqlDataSource.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connect-to-tidb.md#2025-04-18_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nMysqlDataSource mysqlDataSource = new MysqlDataSource();\nmysqlDataSource.setURL(\"jdbc:mysql://{host}:{port}/{database}?user={username}&password={password}\");\n```\n\n----------------------------------------\n\nTITLE: Troubleshooting SQL Bindings with EXPLAIN in TiDB\nDESCRIPTION: Example of using EXPLAIN with verbose format and SHOW WARNINGS to identify which binding is used for a particular SQL statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a global binding\n\nCREATE GLOBAL BINDING for\n    SELECT * FROM t\nUSING\n    SELECT /*+ USE_INDEX(t, idx_a) */ * FROM t;\n\n-- Use explain format = 'verbose' to view the execution plan of a SQL statement\n\nexplain format = 'verbose' SELECT * FROM t;\n\n-- Run `show warnings` to view the binding used in the query.\n\nshow warnings;\n```\n\n----------------------------------------\n\nTITLE: Checking IAM Role Policy Permissions\nDESCRIPTION: This JSON snippet exemplifies an IAM role policy that specifies permissions connected to accessing S3 resources and decrypting with KMS key. It is crucial to verify the correctness of Resource fields in policies to avoid authorization errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/troubleshoot-import-access-denied-error.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:GetObjectVersion\"\n            ],\n            \"Resource\": \"arn:aws:s3:::tidb-cloud-source-data/mydata/*\"\n        },\n        {\n            \"Sid\": \"VisualEditor1\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:ListBucket\",\n                \"s3:GetBucketLocation\"\n            ],\n            \"Resource\": \"arn:aws:s3:::tidb-cloud-source-data\"\n        },\n        {\n            \"Sid\": \"AllowKMSkey\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"kms:Decrypt\"\n            ],\n            \"Resource\": \"arn:aws:kms:ap-northeast-1:105880447796:key/c3046e91-fdfc-4f3a-acff-00597dd3801f\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Sources in cluster.json\nDESCRIPTION: This code snippet demonstrates the configuration of data sources in the `cluster.json` file for a Data App in TiDB Cloud.  It shows how to link multiple TiDB clusters to a Data App by specifying the `cluster_id` for each cluster. This configuration is used to define the data sources that the Data App can access.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-app-config-files.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n\n[\n  {\n    \"cluster_id\": <Cluster ID1>\n  },\n  {\n    \"cluster_id\": <Cluster ID2>\n  }\n]\n\n```\n\n----------------------------------------\n\nTITLE: Querying the tidb_query_duration Monitoring Table\nDESCRIPTION: This SQL snippet retrieves all information related to the `tidb_query_duration` monitoring table from `information_schema.metrics_tables`. It allows understanding of its structure and purpose in monitoring TiDB performance metrics.\nSOURCE: https://github.com/pingcap/docs/blob/master/metrics-schema.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.metrics_tables WHERE table_name='tidb_query_duration';\n```\n\n----------------------------------------\n\nTITLE: Creating a basic SQL binding in TiDB\nDESCRIPTION: This statement is used to create a SQL binding at either the GLOBAL or SESSION level. The binding associates a specified SQL statement with a particular execution plan. The bound SQL statement (BindableStmt) can be a `SELECT`, `DELETE`, `UPDATE`, or `INSERT` / `REPLACE` statement with `SELECT` subqueries.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE [GLOBAL | SESSION] BINDING [FOR BindableStmt] USING BindableStmt;\n```\n\n----------------------------------------\n\nTITLE: Querying Data from TiDB with Go-MySQL-Driver\nDESCRIPTION: Example of querying data from a 'player' table using Go-MySQL-Driver. It demonstrates executing a SELECT SQL statement with a parameterized WHERE clause and processing the result set.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-golang-sql-driver.md#2025-04-18_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nopenDB(\"mysql\", func(db *sql.DB) {\n    selectSQL = \"SELECT id, coins, goods FROM player WHERE id = ?\"\n    rows, err := db.Query(selectSQL, \"id\")\n    if err != nil {\n        panic(err)\n    }\n\n    // This line is extremely important!\n    defer rows.Close()\n\n    id, coins, goods := \"\", 0, 0\n    if rows.Next() {\n        err = rows.Scan(&id, &coins, &goods)\n        if err == nil {\n            fmt.Printf(\"player id: %s, coins: %d, goods: %d\\n\", id, coins, goods)\n        }\n    }\n})\n```\n\n----------------------------------------\n\nTITLE: Setting Client Connection Character Set\nDESCRIPTION: Example of setting character set and collation for client connections.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSET character_set_client = charset_name;\nSET character_set_results = charset_name;\nSET character_set_connection = charset_name;\n```\n\n----------------------------------------\n\nTITLE: Implementing CRUD Operations with Prisma Client in TypeScript\nDESCRIPTION: Main logic of the sample code demonstrating how to use Prisma Client to perform CRUD operations on a TiDB database.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// Step 1. Import the auto-generated `@prisma/client` package.\nimport {Player, PrismaClient} from '@prisma/client';\n\nasync function main(): Promise<void> {\n  // Step 2. Create a new `PrismaClient` instance.\n  const prisma = new PrismaClient();\n  try {\n\n    // Step 3. Perform some CRUD operations with Prisma Client ...\n\n  } finally {\n    // Step 4. Disconnect Prisma Client.\n    await prisma.$disconnect();\n  }\n}\n\nvoid main();\n```\n\n----------------------------------------\n\nTITLE: Restoring Specific MySQL Schema Table with BR in Shell\nDESCRIPTION: This command demonstrates how to restore a specific user-created table (mysql.usertable) from the mysql schema using BR. It uses table filters to include only the desired table while excluding other mysql schema tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nbr restore full -f '*.*' -f '!mysql.*' -f 'mysql.usertable' -s $external_storage_url --with-sys-table\n```\n\n----------------------------------------\n\nTITLE: Explaining and Analyzing Query Execution in TiDB\nDESCRIPTION: This SQL statement uses `EXPLAIN ANALYZE` to display the execution plan for a given query and also executes the query, providing actual execution statistics. The output includes the time spent in each operator, the number of rows processed, and memory usage, allowing for a detailed performance analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n\"EXPLAIN ANALYZE SELECT count(*) FROM trips WHERE start_date BETWEEN '2017-07-01 00:00:00' AND '2017-07-01 23:59:59';\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Maven Dependencies for Java JDBC Application\nDESCRIPTION: This XML snippet shows the Maven configuration (pom.xml) for a Java application using JDBC to connect to TiDB. It includes dependencies for MySQL Connector/J and HikariCP, and configures the build process.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>com.pingcap</groupId>\n  <artifactId>plain-java-txn</artifactId>\n  <version>0.0.1</version>\n\n  <name>plain-java-jdbc</name>\n\n  <properties>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <maven.compiler.source>17</maven.compiler.source>\n    <maven.compiler.target>17</maven.compiler.target>\n  </properties>\n\n  <dependencies>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>4.13.2</version>\n      <scope>test</scope>\n    </dependency>\n\n    <!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java -->\n    <dependency>\n      <groupId>mysql</groupId>\n      <artifactId>mysql-connector-java</artifactId>\n      <version>8.0.28</version>\n    </dependency>\n\n    <dependency>\n      <groupId>com.zaxxer</groupId>\n      <artifactId>HikariCP</artifactId>\n      <version>5.0.1</version>\n    </dependency>\n  </dependencies>\n\n  <build>\n    <plugins>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-assembly-plugin</artifactId>\n        <version>3.3.0</version>\n        <configuration>\n          <descriptorRefs>\n            <descriptorRef>jar-with-dependencies</descriptorRef>\n          </descriptorRefs>\n          <archive>\n            <manifest>\n              <mainClass>com.pingcap.txn.TxnExample</mainClass>\n            </manifest>\n          </archive>\n\n        </configuration>\n        <executions>\n          <execution>\n            <id>make-assembly</id>\n            <phase>package</phase>\n            <goals>\n              <goal>single</goal>\n            </goals>\n          </execution>\n        </executions>\n      </plugin>\n    </plugins>\n  </build>\n\n</project>\n```\n\n----------------------------------------\n\nTITLE: Setting Placement Policy for a Table in TiDB\nDESCRIPTION: Demonstrates how to create and attach a placement policy to a table, and how to reset it back to the default policy.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY five_replicas FOLLOWERS=4;\n\nCREATE TABLE t (a INT) PLACEMENT POLICY=five_replicas;  -- Creates a table t and attaches the 'five_replicas' placement policy to it.\n\nALTER TABLE t PLACEMENT POLICY=default; -- Removes the placement policy 'five_replicas' from the table t and resets the placement policy to the default one.\n```\n\n----------------------------------------\n\nTITLE: Configuring Zone Labels for TiKV and TiDB Nodes\nDESCRIPTION: Configuration example for setting the zone label in TiKV and TiDB nodes to ensure proper data center identification. This configuration ensures nodes in the same data center share the same zone label value.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/three-dc-local-read.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n[labels]\nzone=dc-1\n```\n\n----------------------------------------\n\nTITLE: Merge Join Query Example in SQL\nDESCRIPTION: This SQL query demonstrates how to force a merge join between tables t1 and t2 using the `MERGE_JOIN` hint. The `EXPLAIN` statement provides insight into how TiDB plans and executes the query, specifically showing the use of the MergeJoin operator.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ MERGE_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Manipulating Data in TiDB with DML\nDESCRIPTION: Commands for inserting, updating, and deleting data in tables, including inserting complete and partial records, updating specific fields, and deleting records with conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/basic-sql-operations.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO person VALUES(1,'tom','20170912');\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO person(id,name) VALUES('2','bob');\n```\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE person SET birthday='20180808' WHERE id=2;\n```\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM person WHERE id=2;\n```\n\n----------------------------------------\n\nTITLE: Retrieving Recent Slow Queries Example - SQL in TiDB\nDESCRIPTION: This SQL command retrieves the 10 most recent slow query records. It allows users to quickly assess the performance of their most recent queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW SLOW recent 10\n```\n\n----------------------------------------\n\nTITLE: Initializing TiDB Vector Store for Document Embeddings\nDESCRIPTION: Creates a vector store in TiDB with the specified configuration including table name, distance strategy, and vector dimension settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntidbvec = TiDBVectorStore(\n   connection_string=tidb_connection_url,\n   table_name=\"paul_graham_test\",\n   distance_strategy=\"cosine\",\n   vector_dimension=1536,\n   drop_existing_table=False,\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_parallel_hashagg_spill in TiDB\nDESCRIPTION: Controls the disk spill support for parallel HashAgg, balancing performance and data throughput. It is default ON, with faults reported if set OFF after v8.2.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_36\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): No\n- Type: Boolean\n- Default value: `ON`\n- This variable controls whether TiDB supports disk spill for the parallel HashAgg algorithm.\n```\n\n----------------------------------------\n\nTITLE: Efficient Multi-Row SQL Statements\nDESCRIPTION: Examples of recommended multi-row operations versus inefficient single-row operations for INSERT and DELETE statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql-best-practices.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES (1, 'a'), (2, 'b'), (3, 'c');\n\nDELETE FROM t WHERE id IN (1, 2, 3);\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES (1, 'a');\nINSERT INTO t VALUES (2, 'b');\nINSERT INTO t VALUES (3, 'c');\n\nDELETE FROM t WHERE id = 1;\nDELETE FROM t WHERE id = 2;\nDELETE FROM t WHERE id = 3;\n```\n\n----------------------------------------\n\nTITLE: Optimizing DISTINCT in Aggregate Functions with Push Down in TiDB\nDESCRIPTION: This example demonstrates how the tidb_opt_distinct_agg_push_down configuration affects DISTINCT aggregate function execution. When enabled, the distinct operation can be pushed down to the TiKV or TiFlash Coprocessor, potentially reducing computation overhead in the TiDB layer.\nSOURCE: https://github.com/pingcap/docs/blob/master/agg-distinct-optimization.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> desc select count(distinct a) from test.t;\n+-------------------------+----------+-----------+---------------+------------------------------------------+\n| id                      | estRows  | task      | access object | operator info                            |\n+-------------------------+----------+-----------+---------------+------------------------------------------+\n| StreamAgg_6             | 1.00     | root      |               | funcs:count(distinct test.t.a)->Column#4 |\n| └─TableReader_10        | 10000.00 | root      |               | data:TableFullScan_9                     |\n|   └─TableFullScan_9     | 10000.00 | cop[tikv] | table:t       | keep order:false, stats:pseudo           |\n+-------------------------+----------+-----------+---------------+------------------------------------------+\n3 rows in set (0.01 sec)\n\nmysql> set session tidb_opt_distinct_agg_push_down = 1;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> desc select count(distinct a) from test.t;\n+---------------------------+----------+-----------+---------------+------------------------------------------+\n| id                        | estRows  | task      | access object | operator info                            |\n+---------------------------+----------+-----------+---------------+------------------------------------------+\n| HashAgg_8                 | 1.00     | root      |               | funcs:count(distinct test.t.a)->Column#3 |\n| └─TableReader_9           | 1.00     | root      |               | data:HashAgg_5                           |\n|   └─HashAgg_5             | 1.00     | cop[tikv] |               | group by:test.t.a,                       |\n|     └─TableFullScan_7     | 10000.00 | cop[tikv] | table:t       | keep order:false, stats:pseudo           |\n+---------------------------+----------+-----------+---------------+------------------------------------------+\n4 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Showing and Setting FastScan Variable in TiFlash\nDESCRIPTION: This SQL snippet illustrates how to show the current state of the FastScan variable in TiFlash for both session and global scopes, and how to enable and disable the FastScan feature. It emphasizes the importance of understanding the current configuration to manipulate query performance effectively.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-fastscan.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nshow variables like 'tiflash_fastscan';\n\n+------------------+-------+\n| Variable_name    | Value |\n+------------------+-------+\n| tiflash_fastscan | OFF   |\n+------------------+-------+\n\nshow global variables like 'tiflash_fastscan';\n\n+------------------+-------+\n| Variable_name    | Value |\n+------------------+-------+\n| tiflash_fastscan | OFF   |\n+------------------+-------+\n\nset session tiflash_fastscan=ON;\nset global tiflash_fastscan=ON;\n\nset session tiflash_fastscan=OFF;\nset global tiflash_fastscan=OFF;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Optimized Query Execution Plan in TiDB\nDESCRIPTION: Uses EXPLAIN to view the execution plan after adding a secondary index, showing improved performance with index lookup.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM books WHERE title = 'Marian Yost';\n```\n\n----------------------------------------\n\nTITLE: Creating Changefeed for Reverse Replication - Shell\nDESCRIPTION: Shell command to create a Changefeed for reverse replication from new to old cluster. Involves configuring a sink URI and ensuring no loopback writes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:${cluster_version} cdc changefeed create --server http://${cdc_host}:${cdc_port} --sink-uri=\"mysql://${username}:${password}@${tidb_endpoint}:${port}\" --config config.toml --start-ts ${tso}\n```\n\n----------------------------------------\n\nTITLE: Using TiDB Cloud Serverless Driver with Deno\nDESCRIPTION: Example showing how to use the TiDB Cloud Serverless Driver in a Deno runtime environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_6\n\nLANGUAGE: ts\nCODE:\n```\nimport { connect } from \"npm:@tidbcloud/serverless-js\"\n\nconst conn = connect({url: Deno.env.get('DATABASE_URL')})\nconst result = await conn.execute('show tables')\n```\n\n----------------------------------------\n\nTITLE: Optimizing LIMIT Queries with IndexLookup in TiDB\nDESCRIPTION: Example demonstrating how TiDB efficiently handles LIMIT clauses with ordered index scans, limiting the number of rows processed at the index level before fetching the full rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-indexes.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t1 ORDER BY intkey DESC LIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration\nDESCRIPTION: YAML frontmatter defining title and summary for the release notes document.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.0.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: TiDB 5.3 Release Notes\nsummary: TiDB 5.3.0 introduces temporary tables, table attributes, and user privileges on TiDB Dashboard for improved performance and security. It also enhances TiDB Data Migration, supports parallel import using multiple TiDB Lightning instances, and continuous profiling for better observability. Compatibility changes and configuration file parameters have been modified. The release also includes new SQL features, security enhancements, stability improvements, and diagnostic efficiency. Additionally, bug fixes and improvements have been made to TiDB, TiKV, PD, TiFlash, and TiCDC. The cyclic replication feature between TiDB clusters has been removed. Telemetry now includes information about the usage of the TEMPORARY TABLE feature.\n---\n```\n\n----------------------------------------\n\nTITLE: Loading CSV data into TiDB Cloud with dbt seed command\nDESCRIPTION: Command to load seed data from CSV files into TiDB Cloud tables. This materializes the CSV files in the seeds directory as tables in the target database specified in the configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ndbt seed\n```\n\n----------------------------------------\n\nTITLE: Querying Player Data with Prisma in JavaScript\nDESCRIPTION: This snippet shows how to retrieve a single Player object by its ID using Prisma's findUnique method. It returns the Player object if found, or null if no matching record exists.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\nconst player: Player | null = prisma.player.findUnique({\n   where: {\n      id: 101,\n   }\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Write Skew Prevention in Java\nDESCRIPTION: This Java code demonstrates how to use SELECT FOR UPDATE to prevent write skew in a concurrent environment. It manages doctor leave requests while ensuring at least one doctor remains on call.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-restraints.md#2025-04-18_snippet_3\n\nLANGUAGE: java\nCODE:\n```\npublic static void askForLeave(HikariDataSource ds, Semaphore txn1Pass, Integer txnID, Integer doctorID) {\n    try(Connection connection = ds.getConnection()) {\n        try {\n            connection.setAutoCommit(false);\n\n            String comment = txnID == 2 ? \"    \" : \"\" + \"/* txn #{txn_id} */ \";\n            connection.createStatement().executeUpdate(comment + \"BEGIN\");\n\n            // Txn 1 should be waiting for txn 2 done\n            if (txnID == 1) {\n                txn1Pass.acquire();\n            }\n\n            PreparedStatement currentOnCallQuery = connection.prepareStatement(comment +\n                    \"SELECT COUNT(*) AS `count` FROM `doctors` WHERE `on_call` = ? AND `shift_id` = ? FOR UPDATE\");\n            currentOnCallQuery.setBoolean(1, true);\n            currentOnCallQuery.setInt(2, 123);\n            ResultSet res = currentOnCallQuery.executeQuery();\n\n            if (!res.next()) {\n                throw new RuntimeException(\"error query\");\n            } else {\n                int count = res.getInt(\"count\");\n                if (count >= 2) {\n                    // If current on-call doctor has 2 or more, this doctor can leave\n                    PreparedStatement insert = connection.prepareStatement( comment +\n                            \"UPDATE `doctors` SET `on_call` = ? WHERE `id` = ? AND `shift_id` = ?\");\n                    insert.setBoolean(1, false);\n                    insert.setInt(2, doctorID);\n                    insert.setInt(3, 123);\n                    insert.executeUpdate();\n\n                    connection.commit();\n                } else {\n                    throw new RuntimeException(\"At least one doctor is on call\");\n                }\n            }\n\n            // Txn 2 done, let txn 1 run again\n            if (txnID == 2) {\n                txn1Pass.release();\n            }\n        } catch (Exception e) {\n            // If got any error, you should roll back, data is priceless\n            connection.rollback();\n            e.printStackTrace();\n        }\n    } catch (SQLException e) {\n        e.printStackTrace();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing SQL Query Execution Plan\nDESCRIPTION: This SQL snippet shows an EXPLAIN ANALYZE statement to examine the execution plan of a SELECT query with filtering and sorting conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT  \ntest.*\nFROM\n  test\nWHERE\n  test.snapshot_id = 459840\n  AND test.id > 998464\nORDER BY\n  test.id ASC\nLIMIT\n  1000\n```\n\n----------------------------------------\n\nTITLE: ROLLBACK Usage Example in TiDB\nDESCRIPTION: Example demonstrating the use of ROLLBACK statement in TiDB, showing table creation, transaction initiation, data insertion, and rollback operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-rollback.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (a INT NOT NULL PRIMARY KEY);\nQuery OK, 0 rows affected (0.12 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> INSERT INTO t1 VALUES (1);\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> ROLLBACK;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> SELECT * FROM t1;\nEmpty set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Enabling Compaction Filter for All TiKV Instances\nDESCRIPTION: SQL commands to enable the Compaction Filter for all TiKV instances and verify the change.\nSOURCE: https://github.com/pingcap/docs/blob/master/garbage-collection-configuration.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nset config tikv gc.enable-compaction-filter = true;\nshow config where type = 'tikv' and name like '%enable-compaction-filter%';\n```\n\n----------------------------------------\n\nTITLE: Show Backups in TiDB\nDESCRIPTION: This SQL statement retrieves a list of all backup tasks that have been queued, are currently running, or have recently completed on the TiDB instance. The output includes information such as destination, state, progress, and timestamps.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-backups.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW BACKUPS;\n```\n\n----------------------------------------\n\nTITLE: Creating Employees Table\nDESCRIPTION: This SQL statement creates a table named `employees` with columns for employee ID, first name, last name, hire date, separation date, job code, and store ID. This table serves as the base for demonstrating various partitioning strategies in subsequent examples.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT NOT NULL\n);\n```\n\n----------------------------------------\n\nTITLE: TiFlash Storage Format Version Configuration Parameter (Modified)\nDESCRIPTION: TiFlash parameter that controls the data validation feature. The default value has been changed from 2 to 3, enabling consistency checks on read operations to avoid incorrect reads due to hardware failures.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_12\n\nLANGUAGE: toml\nCODE:\n```\nstorage.format_version\n```\n\n----------------------------------------\n\nTITLE: Analyzing Hot Leader Region Distribution by Store in SQL\nDESCRIPTION: This SQL query counts hot leader regions grouped by store_id for a specific table and time range. It focuses on regions where is_leader is true.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-hot-regions-history.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT count(region_id) cnt, store_id FROM INFORMATION_SCHEMA.TIDB_HOT_REGIONS_HISTORY WHERE update_time >'2021-08-18 21:40:00' and update_time <'2021-09-19 00:00:00' and table_name = 'table_name' and is_leader=1 GROUP BY STORE_ID ORDER BY cnt DESC;\n```\n\n----------------------------------------\n\nTITLE: Output of SHOW COLUMNS Statement\nDESCRIPTION: This shows the output of the SHOW COLUMNS statement for the test.t1 table, displaying basic column information in a tabular format.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-columns.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n+-------+---------+------+------+---------+-------+\n| Field | Type    | Null | Key  | Default | Extra |\n+-------+---------+------+------+---------+-------+\n| a     | int(11) | YES  |      | NULL    |       |\n+-------+---------+------+------+---------+-------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Decoding TiDB-encoded Keys with TIDB_DECODE_KEY in SQL\nDESCRIPTION: This example shows how to use the TIDB_DECODE_KEY function to decode TiDB-encoded keys from the tikv_region_status table. It demonstrates decoding for both hidden rowid and compound clustered primary key scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT START_KEY, TIDB_DECODE_KEY(START_KEY) FROM information_schema.tikv_region_status WHERE table_name='t1' AND REGION_ID=2\\G\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT tidb_decode_key('7480000000000000FF3E5F720400000000FF0000000601633430FF3338646232FF2D64FF3531632D3131FF65FF622D386337352DFFFF3830653635303138FFFF61396265000000FF00FB000000000000F9');\n```\n\n----------------------------------------\n\nTITLE: Viewing Table's Placement Policy SQL\nDESCRIPTION: This SQL statement shows how to query the placement policy attached to a specific table, essential for monitoring table configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE t1\\G\n*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `a` int DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin /*T![placement] PLACEMENT POLICY=`myplacementpolicy` */\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Adjusting Scheduling Parameters with pd-ctl in TiDB\nDESCRIPTION: This snippet shows pd-ctl commands for checking and adjusting scheduling configuration in TiDB, including various limits and enablement options.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/pd-scheduling-best-practices.md#2025-04-18_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n- `leader-schedule-limit`: Controls the concurrency of transferring leader scheduling\n- `region-schedule-limit`: Controls the concurrency of adding/deleting peer scheduling\n- `enable-replace-offline-replica`: Determines whether to enable the scheduling to take nodes offline\n- `enable-location-replacement`: Determines whether to enable the scheduling that handles the isolation level of regions\n- `max-snapshot-count`: Controls the maximum concurrency of sending/receiving snapshots for each store\n```\n\n----------------------------------------\n\nTITLE: Querying FOREIGN KEY Constraints from TABLE_CONSTRAINTS in SQL\nDESCRIPTION: This example demonstrates querying the INFORMATION_SCHEMA.TABLE_CONSTRAINTS system table to retrieve all foreign key constraints, providing each constraint's catalog, schema, table, and type. Requires access to the INFORMATION_SCHEMA.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT * FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS WHERE CONSTRAINT_TYPE='FOREIGN KEY'\\G\n***************************[ 1. row ]***************************\nCONSTRAINT_CATALOG | def\nCONSTRAINT_SCHEMA  | test\nCONSTRAINT_NAME    | fk_1\nTABLE_SCHEMA       | test\nTABLE_NAME         | child\nCONSTRAINT_TYPE    | FOREIGN KEY\n\n```\n\n----------------------------------------\n\nTITLE: JSON Creation Functions\nDESCRIPTION: Functions for creating JSON values including JSON_ARRAY(), JSON_OBJECT(), and JSON_QUOTE() for generating arrays, objects, and quoted strings respectively.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nJSON_ARRAY()\nJSON_OBJECT()\nJSON_QUOTE()\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning for Import\nDESCRIPTION: This snippet shows the configuration of a `tidb-lightning.toml` file. TiDB Lightning is used for bulk data import into TiDB. Dependencies include the target TiDB server and the path to data exported by Dumpling. Key parameters are the log level, backend, and storage configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-to-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\n# log.\nlevel = \"info\"\nfile = \"tidb-lightning.log\"\n\n[tikv-importer]\n# Default backend. Recommended for large data import (1 TiB or more).\nbackend = \"local\"\nsorted-kv-dir = \"${sorted-kv-dir}\"\n\n[mydumper]\ndata-source-dir = \"${data-path}\"\n\n[tidb]\nhost = ${host}\nport = ${port}\nuser = \"${user_name}\"\npassword = \"${password}\"\nstatus-port = ${status-port}\npd-addr = \"${ip}:${port}\"\n```\n\n----------------------------------------\n\nTITLE: Deploying New TiDB Primary Cluster with TiUP\nDESCRIPTION: Command to deploy a new TiDB v5.4.0 cluster on Node A as the new primary cluster using TiUP playground. The command sets up a minimal cluster with one TiDB, one PD, one TiKV, and one TiCDC node without TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup --tag upstream playground v5.4.0 --host 0.0.0.0 --db 1 --pd 1 --kv 1 --tiflash 0 --ticdc 1\n```\n\n----------------------------------------\n\nTITLE: Example of PREPARE Statement with Cursor in TiDB\nDESCRIPTION: An example of using PREPARE and EXECUTE statements with variables that previously had issues with slow query logs. This syntax prepares a statement with a placeholder and executes it using a variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.4.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nPREPARE stmt1 FROM SELECT * FROM t WHERE a > ?;\nEXECUTE stmt1 USING @variable\n```\n\n----------------------------------------\n\nTITLE: Creating Merged Table Schema in TiDB\nDESCRIPTION: This SQL snippet defines the schema for the merged `sale` table in the downstream TiDB database. The auto-increment attribute is removed from the `id` column. An index is created on `id`, and a unique key constraint is applied to `sid`, which acts as the sharding key. The table contains columns for `id`, `sid`, `pid`, and `comment`.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-shards-to-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE TABLE `sale` (\n  `id` bigint NOT NULL,\n  `sid` bigint NOT NULL,\n  `pid` bigint NOT NULL,\n  `comment` varchar(255) DEFAULT NULL,\n  INDEX (`id`),\n  UNIQUE KEY `sid` (`sid`)\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\"\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_pipelined_window_function in TiDB\nDESCRIPTION: Specifies whether to utilize pipeline execution for window functions, improving processing efficiency. Default value is ON.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_37\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): No\n- Type: Boolean\n- Default value: `ON`\n- This variable specifies whether to use the pipeline execution algorithm for [window functions](/functions-and-operators/window-functions.md).\n```\n\n----------------------------------------\n\nTITLE: Even Split Syntax for Partitioned Tables\nDESCRIPTION: This SQL syntax describes how to perform an even split operation on partitioned tables by specifying the partition name and index name.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT [PARTITION] TABLE t [PARTITION] [(partition_name_list...)] [INDEX index_name] BETWEEN (lower_value) AND (upper_value) REGIONS region_num;\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Cloud Prisma Adapter and Serverless Driver\nDESCRIPTION: Install the required packages @tidbcloud/prisma-adapter and @tidbcloud/serverless using npm.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-prisma-example.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm install @tidbcloud/prisma-adapter\nnpm install @tidbcloud/serverless\n```\n\n----------------------------------------\n\nTITLE: Specifying Leader and Follower Distribution\nDESCRIPTION: SQL commands for creating placement policies that control the distribution of Raft Leaders and Followers across different regions.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY deploy221_primary_east1 LEADER_CONSTRAINTS=\"[+region=us-east-1]\" FOLLOWER_CONSTRAINTS='{\"region=us-east-1\": 1, \"+region=us-east-2\": 2, \"+region=us-west-1\": 1}';\n\nCREATE PLACEMENT POLICY eastandwest PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-east-2,us-west-1\" SCHEDULE=\"MAJORITY_IN_PRIMARY\" FOLLOWERS=4;\n```\n\n----------------------------------------\n\nTITLE: Querying TTL Job History\nDESCRIPTION: This SQL snippet retrieves the execution history of TTL jobs which have been performed on tables. It provides details including job ID, table name, creation time, finish time, and summary of the job results.\nSOURCE: https://github.com/pingcap/docs/blob/master/time-to-live.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nTABLE mysql.tidb_ttl_job_history LIMIT 1\\G\n\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV and PD Encryption Settings\nDESCRIPTION: This code snippet illustrates how to configure encryption settings for TiKV and PD to enable data encryption at rest. The snippet specifies the data encryption method and key rotation period. Encryption is essential for protecting sensitive storage data.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n[security.encryption]\n  data-encryption-method = \"aes128-ctr\"\n  data-key-rotation-period = \"168h\" # 7 days\n```\n\n----------------------------------------\n\nTITLE: Attempting to Create a Clustered Global Index in TiDB (Error Example)\nDESCRIPTION: This SQL snippet shows an attempt to create a clustered global index, which is not supported in TiDB. It demonstrates the error message received when trying to create such an index.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_63\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t2 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    PRIMARY KEY (col2) CLUSTERED GLOBAL\n) PARTITION BY HASH(col1) PARTITIONS 5;\n```\n\n----------------------------------------\n\nTITLE: Complex Query with HashAgg for Memory Analysis\nDESCRIPTION: SQL query demonstrating memory-intensive operation using multiple table joins with hash aggregation.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-memory-usage.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nexplain analyze select /*+ HASH_AGG() */ count(*) from t t1 join t t2 join t t3 group by t1.a, t2.a, t3.a;\n```\n\n----------------------------------------\n\nTITLE: Using MERGE_JOIN Hint for View Query Block\nDESCRIPTION: Examples showing how to specify MERGE_JOIN hint for different query blocks of a view using QB_NAME notation.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_41\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ QB_NAME(v2_1, v2) merge_join(t@v2_1) */ * FROM v2;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ QB_NAME(v2_2, v2.@SEL_2) merge_join(t1@v2_2) stream_agg(@v2_2) */ * FROM v2;\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Document for Vector Search Testing\nDESCRIPTION: Creates a directory structure and downloads a sample document from the LangChain GitHub repository to be used for testing vector search functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n!mkdir -p 'data/how_to/'\n!wget 'https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/how_to/state_of_the_union.txt' -O 'data/how_to/state_of_the_union.txt'\n```\n\n----------------------------------------\n\nTITLE: Configuring Spark for TiSpark\nDESCRIPTION: This snippet demonstrates the configuration needed to set up Spark for using TiSpark. It includes modifications to the spark-defaults.conf file to integrate TiSpark extensions and catalog information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: scala\nCODE:\n```\n```\nspark.sql.extensions  org.apache.spark.sql.TiExtensions\nspark.tispark.pd.addresses  ${your_pd_address}\nspark.sql.catalog.tidb_catalog  org.apache.spark.sql.catalyst.catalog.TiCatalog\nspark.sql.catalog.tidb_catalog.pd.addresses  ${your_pd_address}\n```\n```\n\n----------------------------------------\n\nTITLE: TiDB ADMIN BINDINGS Management\nDESCRIPTION: SQL statements for managing SQL Plan bindings including flushing, capturing, evolving and reloading bindings.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nADMIN FLUSH BINDINGS;\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN CAPTURE BINDINGS;\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN EVOLVE BINDINGS;\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN RELOAD BINDINGS;\n```\n\n----------------------------------------\n\nTITLE: Performing TiDB Backup with IAM Role-based S3 Access\nDESCRIPTION: This command uses BR to perform a full backup of a TiDB cluster to Amazon S3 using IAM role-based authentication. It connects to the PD endpoint and specifies the S3 storage location.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd \"${PD_IP}:2379\" \\\n--storage \"s3://${host}/${path}\"\n```\n\n----------------------------------------\n\nTITLE: DM's DDL Recording for pt-osc\nDESCRIPTION: SQL statement used by DM to record DDL operations in its metadata table for later execution. This stores the DDL that will eventually be applied to the original table.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nREPLACE INTO dm_meta.{task_name}_onlineddl (id, ghost_schema , ghost_table , ddls) VALUES (...);\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring Sample Data for MPP Mode in TiDB\nDESCRIPTION: This code creates a sample table 't1', inserts test data, configures a TiFlash replica, and enables the MPP mode for query execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-mpp.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id int, value int);\nINSERT INTO t1 values(1,2),(2,3),(1,3);\nALTER TABLE t1 set tiflash replica 1;\nANALYZE TABLE t1;\nSET tidb_allow_mpp = 1;\n```\n\n----------------------------------------\n\nTITLE: Implementing Data Isolation Between Applications\nDESCRIPTION: SQL statements demonstrating how to create placement policies for isolating data between different applications using label constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY app_order CONSTRAINTS=\"[+app=order]\";\nCREATE PLACEMENT POLICY app_list CONSTRAINTS=\"[+app=list_collection]\";\nCREATE TABLE order (id INT, name VARCHAR(50), purchased DATE)\nPLACEMENT POLICY=app_order\nCREATE TABLE list (id INT, name VARCHAR(50), purchased DATE)\nPLACEMENT POLICY=app_list\n```\n\n----------------------------------------\n\nTITLE: ALTER USER Syntax in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the ALTER USER statement in TiDB. It includes options for modifying user specifications, authentication, connection limits, password policies, and account locking.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nAlterUserStmt ::=\n    'ALTER' 'USER' IfExists (UserSpecList RequireClauseOpt ConnectionOptions PasswordOption LockOption AttributeOption | 'USER' '(' ')' 'IDENTIFIED' 'BY' AuthString) ResourceGroupNameOption\n\nUserSpecList ::=\n    UserSpec ( ',' UserSpec )*\n\nUserSpec ::=\n    Username AuthOption\n\nRequireClauseOpt ::=\n    ( 'REQUIRE' 'NONE' | 'REQUIRE' 'SSL' | 'REQUIRE' 'X509' | 'REQUIRE' RequireList )?\n\nRequireList ::=\n    ( \"ISSUER\" stringLit | \"SUBJECT\" stringLit | \"CIPHER\" stringLit | \"SAN\" stringLit | \"TOKEN_ISSUER\" stringLit )*\n\nUsername ::=\n    StringName ('@' StringName | singleAtIdentifier)? | 'CURRENT_USER' OptionalBraces\n\nAuthOption ::=\n    ( 'IDENTIFIED' ( 'BY' ( AuthString | 'PASSWORD' HashString ) | 'WITH' StringName ( 'BY' AuthString | 'AS' HashString )? ) )?\n\nConnectionOptions ::=\n    ( 'WITH' 'MAX_USER_CONNECTIONS' N )?\n\nPasswordOption ::= ( 'PASSWORD' 'EXPIRE' ( 'DEFAULT' | 'NEVER' | 'INTERVAL' N 'DAY' )? | 'PASSWORD' 'HISTORY' ( 'DEFAULT' | N ) | 'PASSWORD' 'REUSE' 'INTERVAL' ( 'DEFAULT' | N 'DAY' ) | 'FAILED_LOGIN_ATTEMPTS' N | 'PASSWORD_LOCK_TIME' ( N | 'UNBOUNDED' ) )*\n\nLockOption ::= ( 'ACCOUNT' 'LOCK' | 'ACCOUNT' 'UNLOCK' )?\n\nAttributeOption ::= ( 'COMMENT' CommentString | 'ATTRIBUTE' AttributeString )?\n\nResourceGroupNameOption::= ( 'RESOURCE' 'GROUP' Identifier)?\n\nRequireClauseOpt ::= ('REQUIRE' ('NONE' | 'SSL' | 'X509' | RequireListElement ('AND'? RequireListElement)*))?\n\nRequireListElement ::= 'ISSUER' Issuer | 'SUBJECT' Subject | 'CIPHER' Cipher | 'SAN' SAN | 'TOKEN_ISSUER' TokenIssuer\n```\n\n----------------------------------------\n\nTITLE: Configuring Default Authentication Plugin in TiDB\nDESCRIPTION: Defines the authentication method used during server-client connection establishment, with multiple authentication plugin options including native password, SHA2, SM3, and LDAP methods\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ndefault_authentication_plugin = 'mysql_native_password'\n```\n\n----------------------------------------\n\nTITLE: Setting Default Roles for a User in TiDB\nDESCRIPTION: This snippet demonstrates how to set default roles for a user in TiDB using the `SET DEFAULT ROLE` statement. When the user logs in, the default roles are automatically enabled.  You need to grant the role to the user before setting the default role. To execute this statement, the user needs the `SUPER` privilege.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSET DEFAULT ROLE\n    {NONE | ALL | role [, role ] ...}\n    TO user [, user ]\n```\n\n----------------------------------------\n\nTITLE: Using CURL to Obtain MVCC Data - Shell\nDESCRIPTION: Demonstrates using a CURL command to retrieve MVCC data from the TiDB HTTP API. The data includes transaction identifiers and base64-encoded values representing the row content.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-control.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ curl \"http://$IP:10080/mvcc/index/test/t/a/1?a=1\"\n```\n\nLANGUAGE: shell\nCODE:\n```\n$ curl \"http://$IP:10080/mvcc/key/test/t/1\"\n```\n\n----------------------------------------\n\nTITLE: Modifying Configuration of a Single TiKV Instance - SQL\nDESCRIPTION: This SQL command modifies the configuration of a specific TiKV instance identified by its address (127.0.0.1:20180). The command sets the 'split.qps-threshold' parameter to 1000, ensuring correct syntax by using backticks.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nset config \"127.0.0.1:20180\" `split.qps-threshold`=1000;\n```\n\n----------------------------------------\n\nTITLE: Configuring Auto Increment with Offset and Increment\nDESCRIPTION: Demonstrates how to set auto_increment_offset and auto_increment_increment to control ID generation in a table, showing step-based ID allocation\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (a int not null primary key auto_increment);\nset auto_increment_offset=1;\nset auto_increment_increment=3;\nINSERT INTO t1 VALUES (),(),(),();\nSELECT * FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Configuring Prisma Schema for TiDB Cloud Serverless Connection\nDESCRIPTION: Example Prisma schema configuration for connecting to a TiDB Cloud Serverless cluster using environment variables. The datasource is configured to use MySQL provider with the connection URL stored in the DATABASE_URL environment variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-vercel.md#2025-04-18_snippet_5\n\nLANGUAGE: prisma\nCODE:\n```\ndatasource db {\n    provider = \"mysql\"\n    url      = env(\"DATABASE_URL\")\n}\n```\n\n----------------------------------------\n\nTITLE: Modifying Configuration of All TiKV Instances - SQL\nDESCRIPTION: This SQL command modifies the configuration setting for all TiKV instances simultaneously, specifically setting the 'split.qps-threshold' to 1000. It is crucial to wrap variable names in backticks to avoid syntax errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nset config tikv `split.qps-threshold`=1000;\n```\n\n----------------------------------------\n\nTITLE: Creating and Analyzing a Table Before Locking Statistics in TiDB\nDESCRIPTION: This SQL snippet demonstrates creating a table, inserting data, and analyzing it before locking statistics. The ANALYZE statement succeeds when the table statistics are not locked.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t(a INT, b INT);\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> INSERT INTO t VALUES (1,2), (3,4), (5,6), (7,8);\nQuery OK, 4 rows affected (0.00 sec)\nRecords: 4  Duplicates: 0  Warnings: 0\n\nmysql> ANALYZE TABLE t;\nQuery OK, 0 rows affected, 1 warning (0.02 sec)\n\nmysql> SHOW WARNINGS;\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Level | Code | Message                                                                                                                                                                                                               |\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Note  | 1105 | Analyze use auto adjusted sample rate 1.000000 for table test.t, reason to use this rate is \"Row count in stats_meta is much smaller compared with the row count got by PD, use min(1, 15000/4) as the sample-rate=1\" |\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Run YCSB Workload against TiDB (Bash)\nDESCRIPTION: This command runs the YCSB workload against a TiDB instance. It uses the `run` subcommand of the TiUP bench ycsb component, specifying the TiDB instance and the operation count. The `-p` flag is used to set properties for the YCSB benchmark.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench ycsb run tidb -p tidb.instances=\"127.0.0.1:4000\" -p operationcount=10000\n```\n\n----------------------------------------\n\nTITLE: Querying Metrics Summary Table Structure\nDESCRIPTION: Shows the structure of the metrics_summary table including field names, types, and properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-metrics-summary.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC metrics_summary;\n```\n\n----------------------------------------\n\nTITLE: Describing MEMORY_USAGE_OPS_HISTORY Table Structure in TiDB\nDESCRIPTION: SQL command to view the structure of the MEMORY_USAGE_OPS_HISTORY table in the information_schema database, showing all columns and their data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-memory-usage-ops-history.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC memory_usage_ops_history;\n```\n\n----------------------------------------\n\nTITLE: Executing a Prepared Statement in SQL\nDESCRIPTION: Shows how to set a parameter value and execute the previously created prepared statement to query a book by ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-prepared-statement.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET @id = 1;\nEXECUTE `books_query` USING @id;\n```\n\n----------------------------------------\n\nTITLE: Importing Data using MyLoader in Shell\nDESCRIPTION: This command uses MyLoader to import the data exported by Dumpling into the downstream MySQL instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-mysql.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nmyloader -h 127.0.0.1 -P 3306 -d ./dumpling_output/\n```\n\n----------------------------------------\n\nTITLE: TiCDC Simple Protocol - DML Message (INSERT)\nDESCRIPTION: This snippet shows an example of an INSERT event message in JSON format using the TiCDC Simple protocol. It includes fields like version, database, table, table ID, event type, commit timestamp, build timestamp, schema version, and the inserted data.  This demonstrates how row insertions are captured and formatted for downstream consumption.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-simple-protocol.md#2025-04-18_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"version\":1,\n   \"database\":\"simple\",\n   \"table\":\"user\",\n   \"tableID\":148,\n   \"type\":\"INSERT\",\n   \"commitTs\":447984084414103554,\n   \"buildTs\":1708923662983,\n   \"schemaVersion\":447984074911121426,\n   \"data\":{\n      \"age\":\"25\",\n      \"id\":\"1\",\n      \"name\":\"John Doe\",\n      \"score\":\"90.5\"\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Starting a Log Backup Task\nDESCRIPTION: This command initiates a new log backup task. It is often used after stopping an existing task or if a task cannot be resumed. A full backup should be performed to ensure PITR consistency after starting the new task.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n\"br log start\"\n```\n\n----------------------------------------\n\nTITLE: Setting TiDB Lightning's send-kv-size Parameter in Physical Import Mode\nDESCRIPTION: Specifies the maximum size of one request when sending data to TiKV in physical import mode. The default value is \"16K\". This parameter was introduced in v7.2.0 to replace the deprecated send-kv-pairs parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\ntikv-importer:\n  send-kv-size: \"16K\"\n```\n\n----------------------------------------\n\nTITLE: Setting TiDB Distributed Execution Framework Variable\nDESCRIPTION: Sets the tidb_enable_dist_task variable to control the TiDB Distributed eXecution Framework (DXF). This variable enables distributed execution of DDL and import tasks across multiple TiDB nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_20\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_enable_dist_task = ON;\n```\n\n----------------------------------------\n\nTITLE: Querying User Privileges in MySQL User Table\nDESCRIPTION: This SQL query selects specific privilege columns from the mysql.user table, demonstrating the structure of global privilege storage. It shows how user, host, and privilege information are stored.\nSOURCE: https://github.com/pingcap/docs/blob/master/privilege-management.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT User,Host,Select_priv,Insert_priv FROM mysql.user LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Using ADD INDEX Statements in TiDB\nDESCRIPTION: Examples of ADD INDEX statements that can now be executed in parallel in TiDB 7.5.0. This feature significantly reduces the execution time of DDL operations, especially for wide tables, with performance improvements of up to 94% according to internal tests.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.5.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nADD INDEX\n```\n\n----------------------------------------\n\nTITLE: Configuring Foreign Key Constraints in TypeORM with TypeScript\nDESCRIPTION: This code shows how to control the creation of foreign key constraints when defining entity relationships in TypeORM. It demonstrates disabling foreign key constraint creation for performance reasons.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\n@Entity()\nexport class ActionLog {\n    @PrimaryColumn()\n    id: number\n\n    @ManyToOne((type) => Person, {\n        createForeignKeyConstraints: false,\n    })\n    person: Person\n}\n```\n\n----------------------------------------\n\nTITLE: Setting tidb_replica_read Variable in TiDB\nDESCRIPTION: This SQL statement demonstrates how to modify the `tidb_replica_read` variable to enable and configure the Follower Read feature in TiDB. The variable can be set at the SESSION or GLOBAL level to control how TiDB handles read requests, allowing reads from the leader, follower, or any replica based on the specified value.\nSOURCE: https://github.com/pingcap/docs/blob/master/follower-read.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nset [session | global] tidb_replica_read = '<target value>';\n```\n\n----------------------------------------\n\nTITLE: TiFlash TableFullScan Execution Performance Metrics\nDESCRIPTION: Performance metrics for TiFlash table scan operations, including DTFile scanning, pack processing, and snapshot creation times\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n\"tiflash_scan\": {\n  \"dtfile\": {\n    \"total_scanned_packs\": 2,\n    \"total_skipped_packs\": 1,\n    \"total_scanned_rows\": 16000,\n    \"total_skipped_rows\": 8192,\n    \"total_rough_set_index_load_time\": \"2ms\",\n    \"total_read_time\": \"20ms\"\n  },\n  \"total_create_snapshot_time\": \"1ms\"\n}\n```\n\n----------------------------------------\n\nTITLE: Querying with json_contains using IndexMerge\nDESCRIPTION: Examples showing how IndexMerge works with json_contains when conditions are connected with AND/OR. Shows that IndexMerge works with AND semantics for json_contains.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1, mvi2) */ * FROM t4 WHERE json_contains(j->'$.a', '[1]') AND json_contains(j->'$.b', '[2, 3]');\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1, mvi2) */ * FROM t4 WHERE json_contains(j->'$.a', '[1]') OR json_contains(j->'$.b', '[2, 3]');\n```\n\n----------------------------------------\n\nTITLE: Setting src-tolerance-ratio for balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command sets the source tolerance ratio for the expectation scheduler. A smaller value makes scheduling easier, while a larger value can reduce redundant scheduling.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_39\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-hot-region-scheduler set src-tolerance-ratio 1.1\n```\n\n----------------------------------------\n\nTITLE: Describing METRICS_TABLES Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the METRICS_TABLES system table, showing its fields, data types, and other properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-metrics-tables.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC METRICS_TABLES;\n```\n\n----------------------------------------\n\nTITLE: Consuming Data from Kafka Topic - Shell\nDESCRIPTION: Runs the Kafka console consumer to read data from a specified topic, allowing validation of data replication from TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-data-to-kafka.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n./bin/kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --from-beginning --topic `${topic-name}`\n```\n\n----------------------------------------\n\nTITLE: Configuring SSH Key-Based Authentication\nDESCRIPTION: Commands to generate an SSH key pair and copy the public key to a target machine for passwordless authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_35\n\nLANGUAGE: bash\nCODE:\n```\nssh-keygen -t rsa\nssh-copy-id -i ~/.ssh/id_rsa.pub 10.0.1.1\n```\n\n----------------------------------------\n\nTITLE: AWS S3 Bucket Policy Configuration for Audit Logging\nDESCRIPTION: JSON policy template defining write-only permissions for TiDB Cloud to access an S3 bucket for storing audit logs\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-auditing.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"s3:PutObject\",\n            \"Resource\": \"<Your S3 bucket ARN>/*\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Modifying Database Character Set in TiDB SQL\nDESCRIPTION: An SQL example demonstrating how to alter the default character set of a database named 'test' to utf8mb4 using the ALTER DATABASE statement in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-database.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER DATABASE test DEFAULT CHARACTER SET = utf8mb4;\n```\n\n----------------------------------------\n\nTITLE: Configuring Snapshot Write Speed in TiDB\nDESCRIPTION: Steps to temporarily adjust snapshot write speed for TiKV and TiFlash instances to accelerate replication. No external dependencies are required beyond access to the TiDB environment and the dynamic configuration SQL interface. The configuration changes are applied immediately upon execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n-- The default value for both configurations are 100MiB, i.e. the maximum disk bandwidth used for writing snapshots is no more than 100MiB/s.\nSET CONFIG tikv `server.snap-io-max-bytes-per-sec` = '300MiB';\nSET CONFIG tiflash `raftstore-proxy.server.snap-io-max-bytes-per-sec` = '300MiB';\n```\n\n----------------------------------------\n\nTITLE: Disabling Resource Control in SQL - TiDB\nDESCRIPTION: This snippet shows how to disable the resource control feature globally in TiDB using the respective SQL statement. It is important to understand the implications of disabling resource control in terms of resource management.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-ru-groups.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_resource_control = 'OFF';\n```\n\n----------------------------------------\n\nTITLE: Using Manual Hint for TiFlash in TiDB SQL\nDESCRIPTION: This SQL query demonstrates how to use a manual hint to force TiDB to read from TiFlash replicas for a specific table.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tidb-to-read-tiflash.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nselect /*+ read_from_storage(tiflash[table_name]) */ ... from table_name;\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up TiDB Cluster\nDESCRIPTION: Removes all TiDB cluster components and cleans up the environment\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup clean --all\n```\n\n----------------------------------------\n\nTITLE: Deleting a Branch Using the Alias Command in Shell\nDESCRIPTION: An alternative alias command that can be used to delete a branch from a TiDB Cloud Serverless cluster. This provides the same functionality as the primary command but with a shorter syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-delete.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch rm [flags]\n```\n\n----------------------------------------\n\nTITLE: Enabling Garbage Collection in TiDB\nDESCRIPTION: This SQL snippet is used to re-enable garbage collection (GC) in the primary TiDB cluster after creating changefeeds to ensure data is periodically cleaned as needed.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_enable=TRUE;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@global.tidb_gc_enable;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------+\n| @@global.tidb_gc_enable |\n+-------------------------+\n|                       1 |\n+-------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting Execution Time Limit with MAX_EXECUTION_TIME\nDESCRIPTION: Example showing how to limit query execution time to 1000 milliseconds using MAX_EXECUTION_TIME hint.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_45\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ MAX_EXECUTION_TIME(1000) */ * from t1 inner join t2 where t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Starting TiDB Cluster with Safe Start\nDESCRIPTION: Initializes and starts a TiDB cluster named 'tidb-test' using TiUP's safe start method, which automatically generates a root password for enhanced security.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster start tidb-test --init\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Servers with Location Labels for Three AZs\nDESCRIPTION: YAML configuration for TiKV servers with location labels reflecting their physical deployment across three availability zones. This setup enables PD to perform global management and scheduling based on the physical topology.\nSOURCE: https://github.com/pingcap/docs/blob/master/three-data-centers-in-two-cities-deployment.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ntikv_servers:\n  - host: 10.63.10.30\n    config:\n      server.labels: { az: \"1\", replication zone: \"1\", rack: \"1\", host: \"30\" }\n  - host: 10.63.10.31\n    config:\n      server.labels: { az: \"1\", replication zone: \"2\", rack: \"2\", host: \"31\" }\n  - host: 10.63.10.32\n    config:\n      server.labels: { az: \"2\", replication zone: \"3\", rack: \"3\", host: \"32\" }\n  - host: 10.63.10.33\n    config:\n      server.labels: { az: \"2\", replication zone: \"4\", rack: \"4\", host: \"33\" }\n  - host: 10.63.10.34\n    config:\n      server.labels: { az: \"3\", replication zone: \"5\", rack: \"5\", host: \"34\" }\n```\n\n----------------------------------------\n\nTITLE: Creating Migration Task Configuration in YAML\nDESCRIPTION: Defines a comprehensive migration task configuration for incremental data replication from MySQL to TiDB\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nname: \"test\"\ntask-mode: \"incremental\"\ntarget-database:\n  host: \"${host}\"\n  port: 4000\n  user: \"root\"\n  password: \"${password}\"\n\nblock-allow-list:\n  listA:\n    do-tables:\n    - db-name: \"test_db\"\n      tbl-name: \"test_table\"\n\nmysql-instances:\n  - source-id: \"mysql-01\"\n    block-allow-list: \"listA\"\n    meta:\n      binlog-name: \"mysql-bin.000004\"\n      binlog-pos: 109227\n```\n\n----------------------------------------\n\nTITLE: Using TiDB Cloud Serverless Driver in Cloudflare Workers\nDESCRIPTION: Implementation example showing how to use the TiDB Cloud Serverless Driver within a Cloudflare Workers environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_4\n\nLANGUAGE: ts\nCODE:\n```\nimport { connect } from '@tidbcloud/serverless'\nexport interface Env {\n  DATABASE_URL: string;\n}\nexport default {\n  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n    const conn = connect({url: env.DATABASE_URL})\n    const result = await conn.execute('show tables')\n    return new Response(JSON.stringify(result));\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Querying METRICS_TABLES Data in SQL\nDESCRIPTION: This SQL query retrieves the first 5 rows from the METRICS_TABLES system table, displaying all columns for each row in a vertical format.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-metrics-tables.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM metrics_tables LIMIT 5\\G\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Connection Environment Variables\nDESCRIPTION: This snippet shows the structure of the .env file used to configure the connection parameters for TiDB. It includes host, port, user, password, database name, and SSL settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-sequelize.md#2025-04-18_snippet_1\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_HOST='{host}'\nTIDB_PORT='4000'\nTIDB_USER='{user}'\nTIDB_PASSWORD='{password}'\nTIDB_DB_NAME='test'\nTIDB_ENABLE_SSL='true'\nTIDB_CA_PATH='{path/to/ca}'\n```\n\n----------------------------------------\n\nTITLE: Enabling Password Complexity Check in TiDB\nDESCRIPTION: This SQL command enables the password complexity check in TiDB by setting the 'validate_password.enable' variable to ON. This change affects only newly set passwords and requires that they meet defined complexity criteria.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL validate_password.enable = ON;\n```\n\n----------------------------------------\n\nTITLE: Multi-Instance Deployment\nDESCRIPTION: Command to start multiple instances of TiDB, TiKV, and PD components.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground --db 3 --pd 3 --kv 3\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Shared Block Cache in TiUP Configuration\nDESCRIPTION: YAML configuration for setting up a shared block cache in TiKV with 30GB capacity as an alternative to configuring separate block caches for different column families.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  tikv:\n    storage.block-cache.capacity: \"30GB\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Efficient Paging in Java\nDESCRIPTION: Demonstrates how to implement the efficient paging method in Java, including fetching page meta information and deleting books by page.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-paginate-results.md#2025-04-18_snippet_4\n\nLANGUAGE: java\nCODE:\n```\npublic class BookDAO {\n    public List<PageMeta<Long>> getPageMetaList() throws SQLException {\n        List<PageMeta<Long>> pageMetaList = new ArrayList<>();\n        try (Connection conn = ds.getConnection()) {\n            Statement stmt = conn.createStatement();\n            ResultSet rs = stmt.executeQuery(\"\"\"\n            SELECT\n                floor((t.row_num - 1) / 1000) + 1 AS page_num,\n                min(t.id) AS start_key,\n                max(t.id) AS end_key,\n                count(*) AS page_size\n            FROM (\n                SELECT id, row_number() OVER (ORDER BY id) AS row_num\n                FROM books\n            ) t\n            GROUP BY page_num\n            ORDER BY page_num;\n            \"\"\");\n            while (rs.next()) {\n                PageMeta<Long> pageMeta = new PageMeta<>();\n                pageMeta.setPageNum(rs.getLong(\"page_num\"));\n                pageMeta.setStartKey(rs.getLong(\"start_key\"));\n                pageMeta.setEndKey(rs.getLong(\"end_key\"));\n                pageMeta.setPageSize(rs.getLong(\"page_size\"));\n                pageMetaList.add(pageMeta);\n            }\n        }\n        return pageMetaList;\n    }\n\n    public void deleteBooksByPageMeta(PageMeta<Long> pageMeta) throws SQLException {\n        try (Connection conn = ds.getConnection()) {\n            PreparedStatement stmt = conn.prepareStatement(\"DELETE FROM books WHERE id >= ? AND id <= ?\");\n            stmt.setLong(1, pageMeta.getStartKey());\n            stmt.setLong(2, pageMeta.getEndKey());\n            stmt.executeUpdate();\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding MyBatis Gradle Dependencies\nDESCRIPTION: Gradle configuration for adding MyBatis and MySQL connector dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-choose-driver-or-orm.md#2025-04-18_snippet_6\n\nLANGUAGE: gradle\nCODE:\n```\nimplementation 'org.mybatis:mybatis:3.5.13'\nimplementation 'mysql:mysql-connector-java:8.0.33'\n```\n\n----------------------------------------\n\nTITLE: Starting Minio for External Storage Simulation\nDESCRIPTION: This snippet sets up Minio as a simulated S3-compatible external storage service for backups. It starts the Minio server on a specified port and configures access credentials. Dependencies include Minio binary and a compatible environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nwget https://dl.min.io/server/minio/release/linux-amd64/minio\n    chmod +x minio\n    # Configure access-key access-screct-id to access minio\n    export HOST_IP='172.16.6.123' # Replace it with the IP address of your upstream cluster\n    export MINIO_ROOT_USER='minio'\n    export MINIO_ROOT_PASSWORD='miniostorage'\n    # Create the redo and backup directories. `backup` and `redo` are bucket names.\n    mkdir -p data/redo\n    mkdir -p data/backup\n    # Start minio at port 6060\n    nohup ./minio server ./data --address :6060 &\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Table in TiDB\nDESCRIPTION: SQL statements to create a table with a vector column for storing document embeddings. The table includes an ID, document text, and a 3-dimensional vector embedding.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-sql.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nUSE test;\nCREATE TABLE embedded_documents (\n    id        INT       PRIMARY KEY,\n    -- Column to store the original content of the document.\n    document  TEXT,\n    -- Column to store the vector representation of the document.\n    embedding VECTOR(3)\n);\n```\n\n----------------------------------------\n\nTITLE: Using the TRUNCATE Statement in TiDB SQL\nDESCRIPTION: Demonstrates how to use the TRUNCATE statement to remove all data from an existing table in TiDB. The examples show creating a table, inserting data, truncating it, and ensuring the table is empty afterwards. This operation requires TiDB SQL environment set up with appropriate permissions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-truncate.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (a INT NOT NULL PRIMARY KEY);\\nQuery OK, 0 rows affected (0.11 sec)\\n\\nmysql> INSERT INTO t1 VALUES (1),(2),(3),(4),(5);\\nQuery OK, 5 rows affected (0.01 sec)\\nRecords: 5  Duplicates: 0  Warnings: 0\\n\\nmysql> SELECT * FROM t1;\\n+---+\\n| a |\\n+---+\\n| 1 |\\n| 2 |\\n| 3 |\\n| 4 |\\n| 5 |\\n+---+\\n5 rows in set (0.00 sec)\\n\\nmysql> TRUNCATE t1;\\nQuery OK, 0 rows affected (0.11 sec)\\n\\nmysql> SELECT * FROM t1;\\nEmpty set (0.00 sec)\\n\\nmysql> INSERT INTO t1 VALUES (1),(2),(3),(4),(5);\\nQuery OK, 5 rows affected (0.01 sec)\\nRecords: 5  Duplicates: 0  Warnings: 0\\n\\nmysql> TRUNCATE TABLE t1;\\nQuery OK, 0 rows affected (0.11 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_point_get_cache in TiDB\nDESCRIPTION: When the lock type is set to READ, enables caching of point query results for reduced overhead and improved performance in executing point queries. Default is OFF.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_42\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): YES\n- Type: Boolean\n- Default value: `OFF`\n- When you set the table lock type of [`LOCK TABLES`](/sql-statements/sql-statement-lock-tables-and-unlock-tables.md) to `READ`, setting this variable to `ON` enables caching of point query results, reducing the overhead of repeated queries and improving point query performance.\n```\n\n----------------------------------------\n\nTITLE: Java Author Class Definition\nDESCRIPTION: Java class definition for representing author data with appropriate data types mapped to database columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_1\n\nLANGUAGE: java\nCODE:\n```\npublic class Author {\n    private Long id;\n    private String name;\n    private Short gender;\n    private Short birthYear;\n    private Short deathYear;\n\n    public Author() {}\n\n     // Skip the getters and setters.\n}\n```\n\n----------------------------------------\n\nTITLE: Convert Primary Timestamp to Readable Time - SQL\nDESCRIPTION: Shows how to convert a specific TSO value into a human-readable date and time using TiDB SQL functions. This is critical for comparing replication completion against source data.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_PARSE_TSO(453880027545600000);\n```\n\n----------------------------------------\n\nTITLE: Network Layer TCP Configuration\nDESCRIPTION: Configures TCP keepalive and Nagle algorithm settings to optimize network communication for TiDB server connections.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-configuration-file.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ntcp-keep-alive: true\ntcp-no-delay: true\n```\n\n----------------------------------------\n\nTITLE: Creating Table with UUID Binary Default\nDESCRIPTION: Example demonstrating how to create a table with a binary column that uses UUID_TO_BIN(UUID()) as its default value for storing UUIDs.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-default-values.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t3 (\n  uuid BINARY(16) DEFAULT (UUID_TO_BIN(UUID())),\n  name VARCHAR(255)\n);\n```\n\n----------------------------------------\n\nTITLE: Using INL_JOIN Hint with Join Order in SQL - SQL\nDESCRIPTION: This SQL snippet explains how to structure a join using the INL_JOIN hint along with a predefined order to optimize performance with an IndexJoin operator. It demonstrates proper use of hinting in SQL joins.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_59\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ leading(t1, t3), inl_join(t3) */ * FROM t1, t2, t3 WHERE t1.id = t2.id AND t2.id = t3.id AND t1.id = t3.id;\n```\n\n----------------------------------------\n\nTITLE: Using PLAN REPLAYER to Export SQL Execution Information in TiDB\nDESCRIPTION: This SQL command demonstrates how to use the PLAN REPLAYER feature to capture and save SQL execution information from a TiDB cluster. This tool helps recreate the execution environment for further analysis of performance issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nPLAN REPLAYER DUMP EXPLAIN [ANALYZE] [WITH STATS AS OF TIMESTAMP expression] sql-statement;\n```\n\n----------------------------------------\n\nTITLE: Running TiDB Lightning Import\nDESCRIPTION: Instructions for starting TiDB Lightning to import data configured in a `.toml` file. The procedure requires setting AWS credentials for S3 data sources. The command uses `nohup` to handle potential SIGHUP signals.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-to-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nexport AWS_ACCESS_KEY_ID=${access_key}\nexport AWS_SECRET_ACCESS_KEY=${secret_key}\nnohup tiup tidb-lightning -config tidb-lightning.toml > nohup.out 2>&1 &\n```\n\n----------------------------------------\n\nTITLE: Recommending Indexes for a Single Query in TiDB\nDESCRIPTION: Demonstrates how to use the RECOMMEND INDEX statement to analyze a specific query and get index recommendations for optimizing its performance. The output includes the suggested index name, columns, and creation statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nRECOMMEND INDEX RUN for \"SELECT a, b FROM t WHERE a = 1 AND b = 1\"\\G\n```\n\n----------------------------------------\n\nTITLE: Creating a Key Partitioned Table by Multiple Columns in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Key partitioned table divided into 4 partitions based on multiple columns: fname and store_id.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_30\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT\n)\n\nPARTITION BY KEY(fname, store_id)\nPARTITIONS 4;\n```\n\n----------------------------------------\n\nTITLE: Configuring Raft Log Parameters\nDESCRIPTION: This snippet covers various parameters related to Raft logs, including tick intervals, heartbeats, and size limits, which guide the behavior of the Raft consensus algorithm.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\n+ The time interval at which the Raft state machine ticks\n+ Default value: `\"1s\"`\n+ Minimum value: greater than `0`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n+ The number of passed ticks when the heartbeat is sent. This means that a heartbeat is sent at the time interval of `raft-base-tick-interval` * `raft-heartbeat-ticks`.\n+ Default value: `2`\n+ Minimum value: greater than `0`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n+ The number of passed ticks when Raft election is initiated. This means that if Raft group is missing the leader, a leader election is initiated approximately after the time interval of `raft-base-tick-interval` * `raft-election-timeout-ticks`.\n+ Default value: `10`\n+ Minimum value: `raft-heartbeat-ticks`\n```\n\n----------------------------------------\n\nTITLE: Creating and Modifying Tables with Indexes in SQL\nDESCRIPTION: This SQL snippet demonstrates creating a table, inserting data, and adding an index to a column. The script also includes using the EXPLAIN command to show the execution plan before and after adding an index, highlighting improvements in query performance. Prerequisites include a running TiDB cluster and basic knowledge of SQL commands.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-add-index.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5);\nQuery OK, 5 rows affected (0.03 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\nmysql> EXPLAIN SELECT * FROM t1 WHERE c1 = 3;\n+-------------------------+----------+-----------+---------------+--------------------------------+\n| id                      | estRows  | task      | access object | operator info                  |\n+-------------------------+----------+-----------+---------------+--------------------------------+\n| TableReader_7           | 10.00    | root      |               | data:Selection_6               |\n| └─Selection_6           | 10.00    | cop[tikv] |               | eq(test.t1.c1, 3)              |\n|   └─TableFullScan_5     | 10000.00 | cop[tikv] | table:t1      | keep order:false, stats:pseudo |\n+-------------------------+----------+-----------+---------------+--------------------------------+\n3 rows in set (0.00 sec)\n\nmysql> ALTER TABLE t1 ADD INDEX (c1);\nQuery OK, 0 rows affected (0.30 sec)\n\nmysql> EXPLAIN SELECT * FROM t1 WHERE c1 = 3;\n+------------------------+---------+-----------+------------------------+---------------------------------------------+\n| id                     | estRows | task      | access object          | operator info                               |\n+------------------------+---------+-----------+------------------------+---------------------------------------------+\n| IndexReader_6          | 0.01    | root      |                        | index:IndexRangeScan_5                      |\n| └─IndexRangeScan_5     | 0.01    | cop[tikv] | table:t1, index:c1(c1) | range:[3,3], keep order:false, stats:pseudo |\n+------------------------+---------+-----------+------------------------+---------------------------------------------+\n2 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: GCS Restore Command\nDESCRIPTION: Command for restoring snapshot data from Google Cloud Storage using BR with credentials file authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full --pd \"${PD_IP}:2379\" \\\n--storage \"gcs://external/backup-20220915?credentials-file=${credentials-file-path}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring cert_allowed_cn for TiFlash\nDESCRIPTION: This code configures the `cert_allowed_cn` parameter for TiFlash, specifying the Common Names that are allowed to connect to TiFlash in `tiflash.toml` and `tiflash-learner.toml` files.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\n    ```toml\n    [security]\n    cert_allowed_cn = [\"tidb\", \"tikv\", \"prometheus\"]\n    ```\n```\n\nLANGUAGE: toml\nCODE:\n```\n    ```toml\n    [security]\n    cert-allowed-cn = [\"tidb\", \"tikv\", \"tiflash\", \"prometheus\"]\n    ```\n```\n\n----------------------------------------\n\nTITLE: Optimized JDBC Connection String with Recommended Parameters\nDESCRIPTION: A comprehensive JDBC connection string that includes recommended parameters for optimal TiDB performance, including prepared statement caching, batch rewrites, and performance configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_7\n\nLANGUAGE: java\nCODE:\n```\njdbc:mysql://<IP_ADDRESS>:<PORT_NUMBER>/<DATABASE_NAME>?characterEncoding=UTF-8&useSSL=false&useServerPrepStmts=true&cachePrepStmts=true&prepStmtCacheSqlLimit=10000&prepStmtCacheSize=1000&useConfigs=maxPerformance&rewriteBatchedStatements=true\n```\n\n----------------------------------------\n\nTITLE: Querying INSPECTION_RESULT Table in SQL\nDESCRIPTION: SQL query to select all columns from the information_schema.inspection_result table, which triggers internal diagnostics and returns results.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-result.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.inspection_result\\G\n```\n\n----------------------------------------\n\nTITLE: Using EXPLAIN ANALYZE for RU Consumption\nDESCRIPTION: SQL command reference showing how to analyze Request Unit consumption for SQL statements using the EXPLAIN ANALYZE feature\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-faqs.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE\n```\n\n----------------------------------------\n\nTITLE: Handling Role Password Expiration in TiDB\nDESCRIPTION: This SQL example demonstrates using the password_expired attribute to prevent roles without passwords from being unlocked and accessed without setting a new, compliant password.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_12\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> CREATE ROLE testrole;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> SELECT user,password_expired,Account_locked FROM mysql.user WHERE user = 'testrole';\n+----------+------------------+----------------+\n| user     | password_expired | Account_locked |\n+----------+------------------+----------------+\n| testrole | Y                | Y              |\n+----------+------------------+----------------+\n1 row in set (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: SQL Query Result Showing Doctor Records\nDESCRIPTION: This SQL query result displays the contents of the doctors table after the transactions, showing three doctors (Alice, Bob, and Carol) with their on-call status and shift assignments.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-restraints.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT * FROM doctors;\n+----+-------+---------+----------+\n| id | name  | on_call | shift_id |\n+----+-------+---------+----------+\n|  1 | Alice |       1 |      123 |\n|  2 | Bob   |       0 |      123 |\n|  3 | Carol |       0 |      123 |\n+----+-------+---------+----------+\n```\n\n----------------------------------------\n\nTITLE: Verifying Cross-database Binding Usage in TiDB\nDESCRIPTION: Executes queries across different databases and checks if the cross-database binding is being used by examining the LAST_PLAN_FROM_BINDING variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_26\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM db1.t1, db1.t2;\nSELECT @@LAST_PLAN_FROM_BINDING;\n\nSELECT * FROM db2.t1, db2.t2;\nSELECT @@LAST_PLAN_FROM_BINDING;\n\nSELECT * FROM db1.t1, db2.t2;\nSELECT @@LAST_PLAN_FROM_BINDING;\n\nUSE db1;\nSELECT * FROM t1, db2.t2;\nSELECT @@LAST_PLAN_FROM_BINDING;\n```\n\n----------------------------------------\n\nTITLE: Attaching Placement Policy to Tables SQL\nDESCRIPTION: SQL statements attach a previously created placement policy to tables, modulating data storage strategies without additional privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (a INT) PLACEMENT POLICY=myplacementpolicy;\nCREATE TABLE t2 (a INT);\nALTER TABLE t2 PLACEMENT POLICY=myplacementpolicy;\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS for TiCDC\nDESCRIPTION: This code snippet presents two methods for configuring TLS in TiCDC: using a configuration file to specify the paths to the CA certificate, server certificate, and server key, or using command-line arguments with the https protocol. Both approaches enable secure communication for TiCDC.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n\t\t```toml\n        [security]\n        ca-path = \"/path/to/ca.pem\"\n        cert-path = \"/path/to/cdc-server.pem\"\n        key-path = \"/path/to/cdc-server-key.pem\"\n        ```\n```\n\n----------------------------------------\n\nTITLE: Disabling Auto Analyze for Batch Operations in TiDB\nDESCRIPTION: This SQL command disables auto-analyze in TiDB to optimize performance during large data imports or updates, allowing for greater control over the timing of statistics collection.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_auto_analyze = OFF;\n```\n\n----------------------------------------\n\nTITLE: Encrypted Traffic Capture Example\nDESCRIPTION: SQL example showing how to capture traffic with encryption enabled but compression disabled for one hour.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-traffic-capture.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nTRAFFIC CAPTURE TO \"/tmp/traffic\" DURATION=\"1h\" COMPRESS=false ENCRYPTION_METHOD=\"aes256-ctr\";\n```\n\n----------------------------------------\n\nTITLE: Listing All Export Tasks in Interactive Mode - Shell\nDESCRIPTION: This snippet illustrates how to list all export tasks in interactive mode, requiring no additional flags. It simplifies the user experience by allowing the user to follow prompts.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-list.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export list\n```\n\n----------------------------------------\n\nTITLE: Incorrect BATCH Column Specification\nDESCRIPTION: Example demonstrating an incorrect way of specifying the column in BATCH statement that results in an error due to ambiguity.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-batch.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nBATCH ON id LIMIT 1 INSERT INTO t SELECT t2.id, t2.v, t3.v FROM t2 JOIN t3 ON t2.k = t3.k;\n```\n\n----------------------------------------\n\nTITLE: Creating Dashboard Access Role\nDESCRIPTION: SQL commands to create a role with dashboard access privileges and assign it to a user using RBAC.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-user.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE ROLE 'dashboard_access';\nGRANT PROCESS, CONFIG ON *.* TO 'dashboard_access'@'%';\nGRANT SHOW DATABASES ON *.* TO 'dashboard_access'@'%';\nGRANT DASHBOARD_CLIENT ON *.* TO 'dashboard_access'@'%';\nGRANT SYSTEM_VARIABLES_ADMIN ON *.* TO 'dashboard_access'@'%';\nGRANT SUPER ON *.* TO 'dashboardAdmin'@'%';\n```\n\n----------------------------------------\n\nTITLE: Sqoop Export Command with Statement Limit Adjustment - Bash\nDESCRIPTION: This bash command is an example of how to use Sqoop to export data into TiDB while adjusting the number of records per statement to avoid exceeding the maximum statement limit of 5000 in a transaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/sql-faq.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsqoop export \\\n    -Dsqoop.export.records.per.statement=10 \\\n    --connect jdbc:mysql://mysql.example.com/sqoop \\\n    --username sqoop ${user} \\\n    --password ${passwd} \\\n    --table ${tab_name} \\\n    --export-dir ${dir} \\\n    --batch\n```\n\n----------------------------------------\n\nTITLE: Using FOR UPDATE OF TABLES Syntax in TiDB\nDESCRIPTION: Shows the syntax for acquiring pessimistic locks on specific tables in a join query using the FOR UPDATE OF TABLES clause, allowing more granular control over locking behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.0.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nFOR UPDATE OF TABLES\n```\n\n----------------------------------------\n\nTITLE: Setting Session-Level TiDB System Variables in SQL\nDESCRIPTION: Example of using SQL to set a session-level system variable in TiDB Cloud. This changes the variable only for the current session and is not persistent across restarts.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/release-notes-2022.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET [GLOBAL|SESSION] <variable>\n```\n\n----------------------------------------\n\nTITLE: Creating global binding - Cartesian product\nDESCRIPTION: This example demonstrates a case where creating a global binding fails due to syntax conflicts with statements that use the `JOIN` keyword without specifying associated columns with the `USING` keyword.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Type one: Statements that get the Cartesian product by using the `JOIN` keyword and not specifying the associated columns with the `USING` keyword.\nCREATE GLOBAL BINDING for\n    SELECT * FROM orders o1 JOIN orders o2\nUSING\n    SELECT * FROM orders o1 JOIN orders o2;\n```\n\n----------------------------------------\n\nTITLE: SQL Alter Table Compact Statement\nDESCRIPTION: New SQL statement introduced in TiFlash v6.1.0 to manually compact physical data. This helps update data in earlier formats and improve read/write performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE ... COMPACT\n```\n\n----------------------------------------\n\nTITLE: Generating Client Key and Certificate Request for TiDB Authentication\nDESCRIPTION: Command to create a new 2048-bit RSA key and certificate signing request for a TiDB client. This step creates both a private key and a certificate request file for client authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/certificate-authentication.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nsudo openssl req -newkey rsa:2048 -days 365000 -nodes -keyout client-key.pem -out client-req.pem\n```\n\n----------------------------------------\n\nTITLE: Compacting All TiFlash Replicas in a Table\nDESCRIPTION: SQL statement to manually trigger compaction for all TiFlash replicas across all partitions in the 'employees' table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table-compact.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE employees COMPACT TIFLASH REPLICA;\n```\n\n----------------------------------------\n\nTITLE: Querying Data with MyBatis in XML\nDESCRIPTION: This XML configuration defines a mapper for querying player data from a TiDB database using MyBatis. It includes a result map and a select statement to retrieve player information by primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-mybatis.md#2025-04-18_snippet_4\n\nLANGUAGE: XML\nCODE:\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.pingcap.model.PlayerMapper\">\n    <resultMap id=\"BaseResultMap\" type=\"com.pingcap.model.Player\">\n        <constructor>\n            <idArg column=\"id\" javaType=\"java.lang.String\" jdbcType=\"VARCHAR\" />\n            <arg column=\"coins\" javaType=\"java.lang.Integer\" jdbcType=\"INTEGER\" />\n            <arg column=\"goods\" javaType=\"java.lang.Integer\" jdbcType=\"INTEGER\" />\n        </constructor>\n    </resultMap>\n\n    <select id=\"selectByPrimaryKey\" parameterType=\"java.lang.String\" resultMap=\"BaseResultMap\">\n    select id, coins, goods\n    from player\n    where id = #{id,jdbcType=VARCHAR}\n    </select>\n</mapper>\n```\n\n----------------------------------------\n\nTITLE: Creating GHC Table in MySQL with gh-ost\nDESCRIPTION: SQL statement to create a ghost control (_ghc) table used by gh-ost to store online-schema-change related information. DM ignores this operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCreate /* gh-ost */ table `test`.`_test4_ghc` (\n                            id bigint auto_increment,\n                            last_update timestamp not null DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n                            hint varchar(64) charset ascii not null,\n                            value varchar(4096) charset ascii not null,\n                            primary key(id),\n                            unique key hint_uidx(hint)\n                    ) auto_increment=256 ;\n```\n\n----------------------------------------\n\nTITLE: Checking a User's Privileges using a Specific Role in TiDB\nDESCRIPTION: This snippet shows how to check the privileges a user has through a specific role using the `SHOW GRANTS ... USING` statement in TiDB. This statement displays the privileges associated with the specified role for the given user. To check privilege-related information of another user, you need the `SELECT` privilege on the `mysql` database.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS FOR 'dev1'@'localhost' USING 'app_developer';\n```\n\n----------------------------------------\n\nTITLE: Configuring SASL/GSSAPI Keytab Authentication in Kafka\nDESCRIPTION: This snippet shows how to configure SASL/GSSAPI authentication using a keytab file for authentication. It includes necessary parameters like the keytab path and other GSSAPI credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"kafka://127.0.0.1:9092/topic-name?kafka-version=2.4.0&sasl-mechanism=gssapi&sasl-gssapi-auth-type=keytab&sasl-gssapi-kerberos-config-path=/etc/krb5.conf&sasl-gssapi-service-name=kafka&sasl-gssapi-user=alice/for-kafka&sasl-gssapi-keytab-path=/var/lib/secret/alice.key&sasl-gssapi-realm=example.com\"\n```\n\n----------------------------------------\n\nTITLE: Key-Value pairs in TiKV with MVCC\nDESCRIPTION: This code snippet shows how MVCC is implemented in TiKV by appending a version number to the key. This allows for multiple versions of the same key to coexist, enabling concurrent reads and writes without conflicts.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-storage.md#2025-04-18_snippet_1\n\nLANGUAGE: none\nCODE:\n```\n\"Key1_Version3 -> Value\nKey1_Version2 -> Value\nKey1_Version1 -> Value\n……\nKey2_Version4 -> Value\nKey2_Version3 -> Value\nKey2_Version2 -> Value\nKey2_Version1 -> Value\n……\nKeyN_Version2 -> Value\nKeyN_Version1 -> Value\n……\"\n```\n\n----------------------------------------\n\nTITLE: Remove Replication Task API Call\nDESCRIPTION: cURL command to remove an existing replication task by ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X DELETE http://127.0.0.1:8300/api/v1/changefeeds/test1\n```\n\n----------------------------------------\n\nTITLE: Enabling Extended Statistics in TiDB\nDESCRIPTION: Sets the system variable to enable extended statistics functionality across the database. This is a global setting that applies to all extended statistics objects.\nSOURCE: https://github.com/pingcap/docs/blob/master/extended-statistics.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_extended_stats = ON;\n```\n\n----------------------------------------\n\nTITLE: Checking TiDB Cluster Status and Details\nDESCRIPTION: Displays detailed information about a specific TiDB cluster, including component status, addresses, ports, and directory locations. This command helps verify the deployment and monitor the cluster state.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster display tidb-test\n```\n\n----------------------------------------\n\nTITLE: Alter Character Set for Sharded Tables\nDESCRIPTION: The SQL statement modifies the character set and collation of all upstream sharded tables in MySQL to LATIN1 and LATIN1_DANISH_CI, which is necessary for consistent data schema during migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE `shard_db_*`.`shard_table_*` CHARACTER SET LATIN1 COLLATE LATIN1_DANISH_CI;\n```\n\n----------------------------------------\n\nTITLE: Filtering Vector Search Results with Inclusion Criteria in Python\nDESCRIPTION: Demonstrates how to perform a vector search with metadata filters to include only specific documents. This example filters for documents where the book metadata field equals 'paul_graham'.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.core.vector_stores.types import (\n   MetadataFilter,\n   MetadataFilters,\n)\n\nquery_engine = index.as_query_engine(\n   filters=MetadataFilters(\n      filters=[\n         MetadataFilter(key=\"book\", value=\"paul_graham\", operator=\"==\"),\n      ]\n   ),\n   similarity_top_k=2,\n)\nresponse = query_engine.query(\"What did the author learn?\")\nprint(textwrap.fill(str(response), 100))\n```\n\n----------------------------------------\n\nTITLE: Generating PNG Diagram from Execution Plan in Bash\nDESCRIPTION: Uses the dot program to convert a .dot file generated from an EXPLAIN statement into a PNG image visualization of the execution plan. The xx.dot file is the result returned by the EXPLAIN statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ndot xx.dot -T png -O\n\nThe xx.dot is the result returned by the above statement.\n```\n\n----------------------------------------\n\nTITLE: Manually Analyzing Tables in TiDB SQL\nDESCRIPTION: This SQL snippet manually collects statistics for a specified table after batch operations. This is crucial for performance tuning, ensuring the query optimizer has up-to-date statistics to work with.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\n-- Manually collect statistics\nANALYZE TABLE your_table;\n\n-- Re-enable auto analyze\nSET GLOBAL tidb_enable_auto_analyze = ON;\n```\n\n----------------------------------------\n\nTITLE: Implementing Kysely with TiDB Cloud in Vercel Edge Function\nDESCRIPTION: TypeScript code for using Kysely with TiDB Cloud serverless driver in a Vercel Edge Function, including request handling and database querying.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-kysely-example.md#2025-04-18_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\nimport { Kysely,GeneratedAlways,Selectable } from 'kysely'\nimport { TiDBServerlessDialect } from '@tidbcloud/kysely'\n\nexport const runtime = 'edge';\n\n// Types\ninterface Database {\n  person: PersonTable\n}\n\ninterface PersonTable {\n  id: GeneratedAlways<number>\n  name: string\n  gender: \"male\" | \"female\" | \"other\"\n}\n\n// Dialect\nconst db = new Kysely<Database>({\n  dialect: new TiDBServerlessDialect({\n    url: process.env.DATABASE_URL\n  }),\n})\n\n// Query\ntype Person = Selectable<PersonTable>\nasync function findPeople(criteria: Partial<Person> = {}) {\n  let query = db.selectFrom('person')\n\n  if (criteria.name){\n    query = query.where('name', '=', criteria.name)\n  }\n\n  return await query.selectAll().execute()\n}\n\nexport async function GET(request: NextRequest) {\n\n  const searchParams = request.nextUrl.searchParams\n  const query = searchParams.get('query')\n\n  let response = null;\n  if (query) {\n    response = await findPeople({name: query})\n  } else {\n    response = await findPeople()\n  }\n\n  return NextResponse.json(response);\n}\n```\n\n----------------------------------------\n\nTITLE: Checking GC Status after Enabling\nDESCRIPTION: This SQL command queries the GC status to ensure that it has been re-enabled after the changefeed creation, allowing for proper data management in the TiDB environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nMySQL [test]> SELECT @@global.tidb_gc_enable;\n\n```\n+-------------------------+\n| @@global.tidb_gc_enable |\n+-------------------------+\n|                       1 |\n+-------------------------+\n1 row in set (0.00 sec)\n```\n```\n\n----------------------------------------\n\nTITLE: Executing Sysbench Performance Tests\nDESCRIPTION: This shell command runs Sysbench tests against different OLTP workloads on the 'sbtest' database. It sets a range of concurrent threads and logs performance over 20 minutes, requiring configurations such as host, port, and defined workloads.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.1-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nsysbench ${WORKLOAD} run \\\n  --mysql-host=${HOST} \\\n  --mysql-port=${PORT} \\\n  --mysql-user=root \\\n  --db-driver=mysql \\\n  --mysql-db=sbtest \\\n  --threads=${THREAD} \\\n  --time=1200 \\\n  --report-interval=10 \\\n  --tables=32 \\\n  --table-size=10000000 \\\n  --mysql-ignore-errors=1062,2013,8028,9007 \\\n  --auto-inc=false \\\n  --mysql-password=${PASSWORD}\n```\n\n----------------------------------------\n\nTITLE: Explain Query with Visible Index\nDESCRIPTION: Example showing query execution plan with a visible index for comparison.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-index.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT c2 FROM t1 ORDER BY c2;\n```\n\n----------------------------------------\n\nTITLE: Utilizing GROUPING function for advanced aggregation identification in SQL\nDESCRIPTION: This SQL query demonstrates the use of the GROUPING function to distinguish between aggregated groups and native NULL values in the results of a GROUP BY query using WITH ROLLUP. It shows how to identify the level of aggregation for each row.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/group-by-modifier.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT year, month, SUM(profit) AS profit, grouping(year) as grp_year, grouping(month) as grp_month FROM bank GROUP BY year, month WITH ROLLUP ORDER BY year DESC, month DESC;\n```\n\n----------------------------------------\n\nTITLE: Scaling Out TiDB Cluster Using TiUP and YAML Configuration\nDESCRIPTION: This command scales out the 'tidb-test' cluster by adding new nodes specified in the 'scale.yaml' file. It demonstrates how to expand a cluster with additional PD and TiKV nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster scale-out tidb-test scale.yaml\n```\n\n----------------------------------------\n\nTITLE: Querying TiKV Addresses for Top Regions by Written Bytes in SQL\nDESCRIPTION: This SQL query retrieves the specific TiKV addresses for the top 3 Regions with the maximum value of WRITTEN_BYTES, joining information from multiple tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tikv-region-peers.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n  address,\n  tikv.address,\n  region.region_id\nFROM\n  TIKV_STORE_STATUS tikv,\n  TIKV_REGION_PEERS peer,\n  (SELECT * FROM tikv_region_status ORDER BY written_bytes DESC LIMIT 3) region\nWHERE\n  region.region_id = peer.region_id\n  AND peer.is_leader = 1\n  AND peer.store_id = tikv.store_id;\n```\n\n----------------------------------------\n\nTITLE: KMS Key Permission Configuration for S3 Bucket with SSE-KMS\nDESCRIPTION: This JSON snippet shows the additional policy statement needed when the S3 bucket uses AWS KMS encryption with a customer-managed key. It grants the Decrypt permission for the specified KMS key.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-external-storage.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Sid\": \"AllowKMSkey\",\n    \"Effect\": \"Allow\",\n    \"Action\": [\n        \"kms:Decrypt\"\n    ],\n    \"Resource\": \"arn:aws:kms:ap-northeast-1:105880447796:key/c3046e91-fdfc-4f3a-acff-00597dd3801f\"\n}\n```\n\n----------------------------------------\n\nTITLE: Modifying TiDB Cluster Configuration\nDESCRIPTION: Command to edit and reload cluster configuration. Supports both global and node-specific configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/maintain-tidb-using-tiup.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster edit-config ${cluster-name}\ntiup cluster reload ${cluster-name} [-N <nodes>] [-R <roles>]\n```\n\n----------------------------------------\n\nTITLE: Configuring Snapshot Information (TOML)\nDESCRIPTION: This TOML snippet illustrates how to configure the datasource for the upstream and downstream TiDB databases using the timestamps obtained from the ts-map. This configuration allows for consistent queries across different databases.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-upstream-downstream-check.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n######################### Datasource config ########################\n[data-sources.uptidb]\n    host = \"172.16.0.1\"\n    port = 4000\n    user = \"root\"\n    password = \"\"\n    snapshot = \"435953225454059520\"\n\n[data-sources.downtidb]\n    host = \"172.16.0.2\"\n    port = 4000\n    user = \"root\"\n    snapshot = \"435953235516456963\"\n```\n\n----------------------------------------\n\nTITLE: Paging for Composite Primary Key Tables in SQL\nDESCRIPTION: Shows how to use the internal _tidb_rowid field for pagination in non-clustered index tables with composite primary keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-paginate-results.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    floor((t.row_num - 1) / 1000) + 1 AS page_num,\n    min(t._tidb_rowid) AS start_key,\n    max(t._tidb_rowid) AS end_key,\n    count(*) AS page_size\nFROM (\n    SELECT _tidb_rowid, row_number () OVER (ORDER BY _tidb_rowid) AS row_num\n    FROM users\n) t\nGROUP BY page_num\nORDER BY page_num;\n```\n\n----------------------------------------\n\nTITLE: Analyzing MPP Query Execution Plan Output\nDESCRIPTION: This code snippet shows the output of an EXPLAIN statement for an MPP query, detailing the execution plan with various operators and their properties across TiDB and TiFlash nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-mintso-scheduler.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------------------------+----------+--------------+---------------+----------------------------------------------------------+\n| id                                         | estRows  | task         | access object | operator info                                            |\n+--------------------------------------------+----------+--------------+---------------+----------------------------------------------------------+\n| HashAgg_44                                 | 1.00     | root         |               | funcs:count(Column#8)->Column#7                          |\n| └─TableReader_46                           | 1.00     | root         |               | MppVersion: 2, data:ExchangeSender_45                    |\n|   └─ExchangeSender_45                      | 1.00     | mpp[tiflash] |               | ExchangeType: PassThrough                                |\n|     └─HashAgg_13                           | 1.00     | mpp[tiflash] |               | funcs:count(1)->Column#8                                 |\n|       └─Projection_43                      | 12487.50 | mpp[tiflash] |               | test.t0.id                                               |\n|         └─HashJoin_42                      | 12487.50 | mpp[tiflash] |               | inner join, equal:[eq(test.t0.id, test.t0.id)]           |\n|           ├─ExchangeReceiver_22(Build)     | 9990.00  | mpp[tiflash] |               |                                                          |\n|           │ └─ExchangeSender_21            | 9990.00  | mpp[tiflash] |               | ExchangeType: Broadcast, Compression: FAST               |\n|           │   └─Selection_20               | 9990.00  | mpp[tiflash] |               | not(isnull(test.t0.id))                                  |\n|           │     └─TableFullScan_19         | 10000.00 | mpp[tiflash] | table:a       | pushed down filter:empty, keep order:false, stats:pseudo |\n|           └─Selection_24(Probe)            | 9990.00  | mpp[tiflash] |               | not(isnull(test.t0.id))                                  |\n|             └─TableFullScan_23             | 10000.00 | mpp[tiflash] | table:b       | pushed down filter:empty, keep order:false, stats:pseudo |\n+--------------------------------------------+----------+--------------+---------------+----------------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Creating Foreign Key Constraints with ALTER TABLE\nDESCRIPTION: This SQL snippet demonstrates how to add a foreign key constraint to an existing table using the ALTER TABLE statement, including optional constraint naming.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name\n    ADD [CONSTRAINT [identifier]] FOREIGN KEY\n    [identifier] (col_name, ...)\n    REFERENCES tbl_name (col_name,...)\n    [ON DELETE reference_option]\n    [ON UPDATE reference_option];\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with mysql.js\nDESCRIPTION: JavaScript code snippet demonstrating how to establish a connection to TiDB using mysql.js with options defined in environment variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysqljs.md#2025-04-18_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n// Step 1. Import the 'mysql' and 'dotenv' packages.\nimport { createConnection } from \"mysql\";\nimport dotenv from \"dotenv\";\nimport * as fs from \"fs\";\n\n// Step 2. Load environment variables from .env file to process.env.\ndotenv.config();\n\n// Step 3. Create a connection to the TiDB cluster.\nconst options = {\n    host: process.env.TIDB_HOST || '127.0.0.1',\n    port: process.env.TIDB_PORT || 4000,\n    user: process.env.TIDB_USER || 'root',\n    password: process.env.TIDB_PASSWORD || '',\n    database: process.env.TIDB_DATABASE || 'test',\n    ssl: process.env.TIDB_ENABLE_SSL === 'true' ? {\n        minVersion: 'TLSv1.2',\n        ca: process.env.TIDB_CA_PATH ? fs.readFileSync(process.env.TIDB_CA_PATH) : undefined\n    } : null,\n}\nconst conn = createConnection(options);\n\n// Step 4. Perform some SQL operations...\n\n// Step 5. Close the connection.\nconn.end();\n```\n\n----------------------------------------\n\nTITLE: Viewing DDL Job Parameters in TiDB SQL\nDESCRIPTION: Example of using ADMIN SHOW DDL JOBS to view the current parameter values for a specific DDL job. The results are displayed in the COMMENTS column of the output.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-alter-ddl.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW DDL JOBS 1;\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Server Using MySQL Client with Full Syntax\nDESCRIPTION: Connect to the TiDB server using the MySQL client with the full command line syntax, specifying port, username, and prompting for password.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nmysql --port 4000 --user xxx --password\n```\n\n----------------------------------------\n\nTITLE: Dropping a Resource Group Example\nDESCRIPTION: Example showing how to drop a resource group named 'rg1' with IF EXISTS clause to prevent errors if the group doesn't exist.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-resource-group.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP RESOURCE GROUP IF EXISTS rg1;\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for TiDB Cloud Serverless\nDESCRIPTION: Example .env file configuration for connecting to a TiDB Cloud Serverless cluster. Contains connection parameters including host, port, credentials, and SSL certificate path.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-peewee.md#2025-04-18_snippet_3\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_HOST=gateway01.****.prod.aws.tidbcloud.com\nTIDB_PORT=4000\nTIDB_USERNAME=********.root\nTIDB_PASSWORD=********\nTIDB_DATABASE=test\nTIDB_CA_PATH=/etc/ssl/cert.pem\n```\n\n----------------------------------------\n\nTITLE: Partitioning an Existing Table with Range in SQL\nDESCRIPTION: This SQL snippet shows how to convert an existing table to a Range partitioned table with multiple partitions based on a 'level' column.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_47\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE member_level PARTITION BY RANGE(level)\n(PARTITION pLow VALUES LESS THAN (1),\n PARTITION pMid VALUES LESS THAN (3),\n PARTITION pHigh VALUES LESS THAN (7)\n PARTITION pMax VALUES LESS THAN (MAXVALUE));\n```\n\n----------------------------------------\n\nTITLE: Output of CLUSTER_SLOW_QUERY Table Schema - SQL\nDESCRIPTION: This snippet demonstrates the expected output from the DESC command executed on the CLUSTER_SLOW_QUERY table, listing all the fields, their data types, nullability, and additional metadata relevant to slow query analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-slow-query.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------------------------+-----------------+------+------+---------+-------+\n| Field                                      | Type            | Null | Key  | Default | Extra |\n+--------------------------------------------+-----------------+------+------+---------+-------+\n| INSTANCE                                   | varchar(64)     | YES  |      | NULL    |       |\n| Time                                       | timestamp(6)    | NO   | PRI  | NULL    |       |\n| Txn_start_ts                               | bigint unsigned | YES  |      | NULL    |       |\n| User                                       | varchar(64)     | YES  |      | NULL    |       |\n| Host                                       | varchar(64)     | YES  |      | NULL    |       |\n| Conn_ID                                    | bigint unsigned | YES  |      | NULL    |       |\n| Session_alias                              | varchar(64)     | YES  |      | NULL    |       |\n| Exec_retry_count                           | bigint unsigned | YES  |      | NULL    |       |\n| Exec_retry_time                            | double          | YES  |      | NULL    |       |\n| Query_time                                 | double          | YES  |      | NULL    |       |\n| Parse_time                                 | double          | YES  |      | NULL    |       |\n| Compile_time                               | double          | YES  |      | NULL    |       |\n| Rewrite_time                               | double          | YES  |      | NULL    |       |\n| Preproc_subqueries                         | bigint unsigned | YES  |      | NULL    |       |\n| Preproc_subqueries_time                    | double          | YES  |      | NULL    |       |\n| Optimize_time                              | double          | YES  |      | NULL    |       |\n| Wait_TS                                    | double          | YES  |      | NULL    |       |\n| Prewrite_time                              | double          | YES  |      | NULL    |       |\n| Wait_prewrite_binlog_time                  | double          | YES  |      | NULL    |       |\n| Commit_time                                | double          | YES  |      | NULL    |       |\n| Get_commit_ts_time                         | double          | YES  |      | NULL    |       |\n| Commit_backoff_time                        | double          | YES  |      | NULL    |       |\n| Backoff_types                              | varchar(64)     | YES  |      | NULL    |       |\n| Resolve_lock_time                          | double          | YES  |      | NULL    |       |\n| Local_latch_wait_time                      | double          | YES  |      | NULL    |       |\n| Write_keys                                 | bigint          | YES  |      | NULL    |       |\n| Write_size                                 | bigint          | YES  |      | NULL    |       |\n| Prewrite_region                            | bigint          | YES  |      | NULL    |       |\n| Txn_retry                                  | bigint          | YES  |      | NULL    |       |\n| Cop_time                                   | double          | YES  |      | NULL    |       |\n| Process_time                               | double          | YES  |      | NULL    |       |\n| Wait_time                                  | double          | YES  |      | NULL    |       |\n| Backoff_time                               | double          | YES  |      | NULL    |       |\n| LockKeys_time                              | double          | YES  |      | NULL    |       |\n| Request_count                              | bigint unsigned | YES  |      | NULL    |       |\n| Total_keys                                 | bigint unsigned | YES  |      | NULL    |       |\n| Process_keys                               | bigint unsigned | YES  |      | NULL    |       |\n| Rocksdb_delete_skipped_count               | bigint unsigned | YES  |      | NULL    |       |\n| Rocksdb_key_skipped_count                  | bigint unsigned | YES  |      | NULL    |       |\n| Rocksdb_block_cache_hit_count              | bigint unsigned | YES  |      | NULL    |       |\n| Rocksdb_block_read_count                   | bigint unsigned | YES  |      | NULL    |       |\n| Rocksdb_block_read_byte                    | bigint unsigned | YES  |      | NULL    |       |\n| DB                                         | varchar(64)     | YES  |      | NULL    |       |\n| Index_names                                | varchar(100)    | YES  |      | NULL    |       |\n| Is_internal                                | tinyint(1)      | YES  |      | NULL    |       |\n| Digest                                     | varchar(64)     | YES  |      | NULL    |       |\n| Stats                                      | varchar(512)    | YES  |      | NULL    |       |\n| Cop_proc_avg                               | double          | YES  |      | NULL    |       |\n| Cop_proc_p90                               | double          | YES  |      | NULL    |       |\n| Cop_proc_max                               | double          | YES  |      | NULL    |       |\n| Cop_proc_addr                              | varchar(64)     | YES  |      | NULL    |       |\n| Cop_wait_avg                               | double          | YES  |      | NULL    |       |\n| Cop_wait_p90                               | double          | YES  |      | NULL    |       |\n| Cop_wait_max                               | double          | YES  |      | NULL    |       |\n| Cop_wait_addr                              | varchar(64)     | YES  |      | NULL    |       |\n| Mem_max                                    | bigint          | YES  |      | NULL    |       |\n| Disk_max                                   | bigint          | YES  |      | NULL    |       |\n| KV_total                                   | double          | YES  |      | NULL    |       |\n| PD_total                                   | double          | YES  |      | NULL    |       |\n| Backoff_total                              | double          | YES  |      | NULL    |       |\n| Unpacked_bytes_sent_tikv_total             | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_received_tikv_total         | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_sent_tikv_cross_zone        | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_received_tikv_cross_zone    | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_sent_tiflash_total          | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_received_tiflash_total      | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_sent_tiflash_cross_zone     | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_received_tiflash_cross_zone | bigint          | YES  |      | NULL    |       |\n| Write_sql_response_total                   | double          | YES  |      | NULL    |       |\n| Result_rows                                | bigint          | YES  |      | NULL    |       |\n| Warnings                                   | longtext        | YES  |      | NULL    |       |\n| Backoff_Detail                             | varchar(4096)   | YES  |      | NULL    |       |\n| Prepared                                   | tinyint(1)      | YES  |      | NULL    |       |\n| Succ                                       | tinyint(1)      | YES  |      | NULL    |       |\n| IsExplicitTxn                              | tinyint(1)      | YES  |      | NULL    |       |\n| IsWriteCacheTable                          | tinyint(1)      | YES  |      | NULL    |       |\n| Plan_from_cache                            | tinyint(1)      | YES  |      | NULL    |       |\n| Plan_from_binding                          | tinyint(1)      | YES  |      | NULL    |       |\n| Has_more_results                           | tinyint(1)      | YES  |      | NULL    |       |\n| Resource_group                             | varchar(64)     | YES  |      | NULL    |       |\n| Request_unit_read                          | double          | YES  |      | NULL    |       |\n| Request_unit_write                         | double          | YES  |      | NULL    |       |\n| Time_queued_by_rc                          | double          | YES  |      | NULL    |       |\n| Tidb_cpu_time                              | double          | YES  |      | NULL    |       |\n| Tikv_cpu_time                              | double          | YES  |      | NULL    |       |\n| Plan                                       | longtext        | YES  |      | NULL    |       |\n| Plan_digest                                | varchar(128)    | YES  |      | NULL    |       |\n| Binary_plan                                | longtext        | YES  |      | NULL    |       |\n| Prev_stmt                                  | longtext        | YES  |      | NULL    |       |\n| Query                                      | longtext        | YES  |      | NULL    |       |\n+--------------------------------------------+-----------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Handling NULLIF Logic in SQL\nDESCRIPTION: The NULLIF function compares two expressions and returns NULL if they are identical; otherwise, it returns the first expression. It's useful in preventing specific values from being treated the same by a query and relies on compatible SQL databases. The function returns NULL if both arguments are the same or if the first argument is NULL.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/control-flow-functions.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nWITH RECURSIVE d AS (SELECT 1 AS n UNION ALL SELECT n+1 FROM d WHERE n<10)\nSELECT n, NULLIF(n+n, n+2) FROM d;\n```\n\n----------------------------------------\n\nTITLE: Update Query Execution Plan\nDESCRIPTION: Shows the detailed execution plan for an UPDATE statement, revealing the query's operator stages and access methods\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN UPDATE t1 SET c1=5 WHERE c1=3;\n```\n\n----------------------------------------\n\nTITLE: Auto-Timestamp Table Creation\nDESCRIPTION: Example of creating a table with TIMESTAMP and DATETIME columns that automatically initialize and update to current timestamp.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    dt DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP\n);\n```\n\n----------------------------------------\n\nTITLE: NON-FULL GROUP BY Syntax Example Causing Unstable Results\nDESCRIPTION: A SQL query with NON-FULL GROUP BY syntax that causes unstable results. The SELECT clause includes a non-aggregated column (stuname) that is not in the GROUP BY clause, leading to ambiguity in which student name to show for each class.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-unstable-result-set.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    `a`.`class`,\n    `a`.`stuname`,\n    max( `b`.`courscore` )\nFROM\n    `stu_info` `a`\n    JOIN `stu_score` `b` ON `a`.`stuno` = `b`.`stuno`\nGROUP BY\n    `a`.`class`\nORDER BY\n    `a`.`class`,\n    `a`.`stuname`;\n```\n\n----------------------------------------\n\nTITLE: Configuring dbt global profile for TiDB Cloud\nDESCRIPTION: YAML configuration for the global dbt profile that specifies connection details for TiDB Cloud. This configuration is stored in ~/.dbt/profiles.yml and includes server endpoint, port, database schema, and authentication details.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\njaffle_shop_tidb:                                                 # Project name\n  target: dev                                                     # Target\n  outputs:\n    dev:\n      type: tidb                                                  # The specific adapter to use\n      server: gateway01.ap-southeast-1.prod.aws.tidbcloud.com     # The TiDB Cloud clusters' endpoint to connect to\n      port: 4000                                                  # The port to use\n      schema: analytics                                           # Specify the schema (database) to normalize data into\n      username: xxxxxxxxxxx.root                                  # The username to use to connect to the TiDB Cloud clusters\n      password: \"your_password\"                                   # The password to use for authenticating to the TiDB Cloud clusters\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning for TSV Import in TOML\nDESCRIPTION: This TOML configuration snippet adjusts the CSV section of TiDB Lightning's configuration to handle Tab-Separated Value (TSV) files. It sets the appropriate separator, delimiter, and other format-specific options.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-csv-files-to-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[mydumper.csv]\nseparator = \"\\t\"\ndelimiter = ''\nheader = true\nnot-null = false\nnull = 'NULL'\nbackslash-escape = false\ntrim-last-separator = false\n```\n\n----------------------------------------\n\nTITLE: Modifying Resource Control Controller Configuration in TiDB\nDESCRIPTION: This command demonstrates how to modify the 'ltb-max-wait-duration' configuration of the Resource Control controller using PD Control.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_29\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl resource-manager config controller set ltb-max-wait-duration 30m\n```\n\n----------------------------------------\n\nTITLE: Character Set String Examples\nDESCRIPTION: Demonstrates using character set introducers and collation clauses with string literals.\nSOURCE: https://github.com/pingcap/docs/blob/master/literal-values.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT _latin1'string';\nSELECT _binary'string';\nSELECT _utf8'string' COLLATE utf8_bin;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Cloud Serverless Connection String\nDESCRIPTION: Environment variable configuration for connecting to TiDB Cloud Serverless with TLS enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_4\n\nLANGUAGE: dotenv\nCODE:\n```\nDATABASE_URL='mysql2://{user}:{password}@{host}:{port}/{database_name}?ssl_mode=verify_identity'\n```\n\n----------------------------------------\n\nTITLE: Enabling gRPC Compression for TiKV to Reduce Cross-AZ Traffic\nDESCRIPTION: This configuration enables gzip compression for TiKV's gRPC communication to reduce cross-AZ network traffic. Compressing data before transmission helps lower data transfer costs between availability zones.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices-on-public-cloud.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  tikv:\n    server.grpc-compression-type: gzip\n```\n\n----------------------------------------\n\nTITLE: Setting Operator-level Spilling Thresholds for Hash Aggregation Example in SQL\nDESCRIPTION: These SQL statements demonstrate disabling operator-level spilling for Hash Aggregation operators by setting the threshold to 0, then executing a memory-intensive GROUP BY query that consumes approximately 29.55 GiB of memory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-spill-disk.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_max_bytes_before_tiflash_external_group_by = 0;\nSELECT\n  l_orderkey,\n  MAX(L_COMMENT),\n  MAX(L_SHIPMODE),\n  MAX(L_SHIPINSTRUCT),\n  MAX(L_SHIPDATE),\n  MAX(L_EXTENDEDPRICE)\nFROM lineitem\nGROUP BY l_orderkey\nHAVING SUM(l_quantity) > 314;\n```\n\n----------------------------------------\n\nTITLE: Setting TiFlash Replica Labels for Tables\nDESCRIPTION: SQL command to define the location labels for TiFlash replicas, allowing for strategic distribution across zones. This example specifies a label at the table level.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name SET TIFLASH REPLICA count LOCATION LABELS location_labels;\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t SET TIFLASH REPLICA 2 LOCATION LABELS \"zone\";\n```\n\n----------------------------------------\n\nTITLE: Performing Bitwise Inversion in SQL\nDESCRIPTION: The '~' operator is used to perform a bitwise inversion, flipping each bit of the input value. The expected input is a binary number, and the output will be its bitwise NOT representation, inverted from 0 to 1 and vice versa.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/bit-functions-and-operators.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONV(~ b'1111000011110000',10,2);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONV(~ b'1111111111111111111111111111111111111111111111110000111100001111',10,2);\n```\n\n----------------------------------------\n\nTITLE: Setting gRPC Rate Limit for GetRegion API in PD\nDESCRIPTION: Sets the maximum rate (QPS) for GetRegion gRPC API requests to 100.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nconfig set service-middleware grpc-rate-limit GetRegion qps 100\n```\n\n----------------------------------------\n\nTITLE: Building Checksum Bytes for Update - Go\nDESCRIPTION: The `buildChecksumBytes` function generates a byte slice for checksum updating, based on column values and their processed MySQL types. It handles unique type encodings, such as integral types, floats, ENUM, and SET. Dependencies include standard libraries for string manipulation and error handling.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-checksum-verification.md#2025-04-18_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\n// buildChecksumBytes generates a byte slice used to update the checksum, refer to https://github.com/pingcap/tidb/blob/e3417913f58cdd5a136259b902bf177eaf3aa637/util/rowcodec/common.go#L308\nfunc buildChecksumBytes(buf []byte, value interface{}, mysqlType byte) ([]byte, error) {\n    if value == nil {\n        return buf, nil\n    }\n\n    switch mysqlType {\n    // TypeTiny, TypeShort, and TypeInt32 are encoded as int32.\n    // TypeLong is encoded as int32 if signed, otherwise, it is encoded as int64.\n    // TypeLongLong is encoded as int64 if signed, otherwise, it is encoded as uint64.\n    // When the checksum feature is enabled, bigintUnsignedHandlingMode must be set to string, which is encoded as string.\n    case mysql.TypeTiny, mysql.TypeShort, mysql.TypeLong, mysql.TypeLonglong, mysql.TypeInt24, mysql.TypeYear:\n        switch a := value.(type) {\n        case int32:\n            buf = binary.LittleEndian.AppendUint64(buf, uint64(a))\n        case uint32:\n            buf = binary.LittleEndian.AppendUint64(buf, uint64(a))\n        case int64:\n            buf = binary.LittleEndian.AppendUint64(buf, uint64(a))\n        case uint64:\n            buf = binary.LittleEndian.AppendUint64(buf, a)\n        case string:\n            v, err := strconv.ParseUint(a, 10, 64)\n            if err != nil {\n                return nil, errors.Trace(err)\n            }\n            buf = binary.LittleEndian.AppendUint64(buf, v)\n        default:\n            log.Panic(\"unknown golang type for the integral value\",\n                zap.Any(\"value\", value), zap.Any(\"mysqlType\", mysqlType))\n        }\n    // Encode float type as float64 and encode double type as float64.\n    case mysql.TypeFloat, mysql.TypeDouble:\n        var v float64\n        switch a := value.(type) {\n        case float32:\n            v = float64(a)\n        case float64:\n            v = a\n        }\n        if math.IsInf(v, 0) || math.IsNaN(v) {\n            v = 0\n        }\n        buf = binary.LittleEndian.AppendUint64(buf, math.Float64bits(v))\n    // getColumnValue encodes Enum and Set to uint64 type.\n    case mysql.TypeEnum, mysql.TypeSet:\n        buf = binary.LittleEndian.AppendUint64(buf, value.(uint64))\n    case mysql.TypeBit:\n        // Encode bit type as []byte and convert it to uint64.\n        v, err := binaryLiteralToInt(value.([]byte))\n        if err != nil {\n            return nil, errors.Trace(err)\n        }\n        buf = binary.LittleEndian.AppendUint64(buf, v)\n    // Non-binary types are encoded as string, and binary types are encoded as []byte.\n    case mysql.TypeVarchar, mysql.TypeVarString, mysql.TypeString, mysql.TypeTinyBlob, mysql.TypeMediumBlob, mysql.TypeLongBlob, mysql.TypeBlob:\n        switch a := value.(type) {\n        case string:\n            buf = appendLengthValue(buf, []byte(a))\n        case []byte:\n            buf = appendLengthValue(buf, a)\n        default:\n            log.Panic(\"unknown golang type for the string value\",\n                zap.Any(\"value\", value), zap.Any(\"mysqlType\", mysqlType))\n    }\n    return buf, nil\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Collations Used in MariaDB Tables\nDESCRIPTION: SQL query to identify the collations used in MariaDB tables, helping to plan for any necessary collation changes during migration to TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-mariadb.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n  TABLE_SCHEMA,\n  COLLATION_NAME,\n  COUNT(*)\nFROM\n  information_schema.columns\nGROUP BY\n  TABLE_SCHEMA, COLLATION_NAME\nORDER BY\n  COLLATION_NAME;\n```\n\n----------------------------------------\n\nTITLE: Defining TEXT Column in TiDB\nDESCRIPTION: Syntax for creating a TEXT column for variable-length strings up to 65,535 bytes with optional character set and collation specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nTEXT[(M)] [CHARACTER SET charset_name] [COLLATE collation_name]\n```\n\n----------------------------------------\n\nTITLE: Enabling Consistent Replica Reads\nDESCRIPTION: Example showing how to enable reading consistent data from TiKV follower nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_47\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ READ_CONSISTENT_REPLICA() */ * from t;\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS Security for TiDB Lightning\nDESCRIPTION: Defines security settings for TLS connections, including CA, certificate, and key paths for secure communication\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[security]\nca-path = \"/path/to/ca.pem\"\ncert-path = \"/path/to/lightning.pem\"\nkey-path = \"/path/to/lightning.key\"\n```\n\n----------------------------------------\n\nTITLE: Viewing DDL Job Information in TiDB\nDESCRIPTION: The basic ADMIN SHOW DDL JOBS command displays information about database schema changes, including job ID, database name, table name, job type, schema state, and timing information.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW DDL JOBS;\n```\n\n----------------------------------------\n\nTITLE: Creating AUTO_RANDOM Columns with Comment Syntax in TiDB\nDESCRIPTION: Using TiDB specific comment syntax to create AUTO_RANDOM columns, which can help with compatibility with other database systems.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-random.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a bigint /*T![auto_rand] AUTO_RANDOM */, b VARCHAR(255), PRIMARY KEY (a));\nCREATE TABLE t (a bigint PRIMARY KEY /*T![auto_rand] AUTO_RANDOM */, b VARCHAR(255));\nCREATE TABLE t (a BIGINT /*T![auto_rand] AUTO_RANDOM(6) */, b VARCHAR(255), PRIMARY KEY (a));\nCREATE TABLE t (a BIGINT  /*T![auto_rand] AUTO_RANDOM(5, 54) */, b VARCHAR(255), PRIMARY KEY (a));\n```\n\n----------------------------------------\n\nTITLE: Running TiUP Cluster Command\nDESCRIPTION: This snippet demonstrates how to run the TiUP cluster command which provides commands for deploying and managing TiDB clusters. It outlines the available commands and usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster\n```\n\nLANGUAGE: bash\nCODE:\n```\nStarting component `cluster`: /home/tidb/.tiup/components/cluster/v1.12.3/cluster\nDeploy a TiDB cluster for production\n\nUsage:\n  tiup cluster [command]\n\nAvailable Commands:\n  check       Precheck a cluster\n  deploy      Deploy a cluster for production\n  start       Start a TiDB cluster\n  stop        Stop a TiDB cluster\n  restart     Restart a TiDB cluster\n  scale-in    Scale in a TiDB cluster\n  scale-out   Scale out a TiDB cluster\n  destroy     Destroy a specified cluster\n  clean       (Experimental) Clean up a specified cluster\n  upgrade     Upgrade a specified TiDB cluster\n  display     Display information of a TiDB cluster\n  list        List all clusters\n  audit       Show audit log of cluster operation\n  import      Import an existing TiDB cluster from TiDB-Ansible\n  edit-config Edit TiDB cluster config\n  reload      Reload a TiDB cluster's config and restart if needed\n  patch       Replace the remote package with a specified package and restart the service\n  help        Help about any command\n\nFlags:\n  -c, --concurrency int     Maximum number of concurrent tasks allowed (defaults to `5`)\n      --format string       (EXPERIMENTAL) The format of output, available values are [default, json] (default \"default\")\n  -h, --help                help for tiup\n      --ssh string          (Experimental) The executor type. Optional values are 'builtin', 'system', and 'none'.\n      --ssh-timeout uint    Timeout in seconds to connect a host via SSH. Operations that don't need an SSH connection are ignored. (default 5)\n  -v, --version            TiUP version\n      --wait-timeout uint   Timeout in seconds to wait for an operation to complete. Inapplicable operations are ignored. (defaults to `120`)\n  -y, --yes                 Skip all confirmations and assumes 'yes'\n```\n\n----------------------------------------\n\nTITLE: Configuring JDBC Connection Timeouts\nDESCRIPTION: Set session-level variables in the JDBC connection string to avoid idle connections and indefinitely executing SQL statements. This example sets a 1-hour wait timeout and a 5-minute execution timeout.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-timeouts-in-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\njdbc:mysql://localhost:4000/test?sessionVariables=wait_timeout=3600&sessionVariables=max_execution_time=300000\n```\n\n----------------------------------------\n\nTITLE: Optimized INSERT Statement With Batch Rewriting\nDESCRIPTION: Demonstrates the SQL statement sent to TiDB when rewriteBatchedStatements=true is configured. Multiple rows are inserted in a single SQL statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ninsert into t(a) values(10),(11),(12);\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB with Distributed PD Servers\nDESCRIPTION: Example of configuring the --path parameter with multiple PD server addresses for a distributed TiKV storage engine setup.\nSOURCE: https://github.com/pingcap/docs/blob/master/command-line-flags-for-tidb-configuration.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntidb-server --store=tikv --path=\"192.168.100.113:2379, 192.168.100.114:2379, 192.168.100.115:2379\"\n```\n\n----------------------------------------\n\nTITLE: Querying data using SQL\nDESCRIPTION: This SQL query selects data from a table named `usertable`, filters it based on `tenantId` and `objectTypeId`, limits the results, and then combines a limited set of results with a count of all matching records.  The query is designed to retrieve specific fields from the filtered data and also provide a total count of records matching the criteria. The `WITH` clause defines common table expressions (`results` and `limited_results`) to improve readability and maintainability.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nWITH `results` AS (\n  SELECT field1, field2, field3, field4\n  FROM usertable\n  where tenantId = 1234 and objectTypeId = 6789\n),\n`limited_results` AS (\n  SELECT field1, field2, field3, field4\n  FROM `results` LIMIT 100\n)\nSELECT field1, field2, field3, field4\nFROM\n  (\n    SELECT 100 `__total__`, field1, field2, field3, field4\n    FROM `limited_results`\n    UNION ALL\n    SELECT count(*) `__total__`, field1, field2, field3, field4\n    FROM `results`\n  ) `result_and_count`;\n```\n\n----------------------------------------\n\nTITLE: Querying Data from TiDB with PyMySQL in Python\nDESCRIPTION: This code snippet shows how to query data from a TiDB database using PyMySQL. It executes a SELECT SQL statement to count the number of rows in the 'players' table and prints the result.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-pymysql.md#2025-04-18_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nwith get_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT count(*) FROM players\")\n        print(cursor.fetchone()[\"count(*)\"])\n```\n\n----------------------------------------\n\nTITLE: Reformatting TiDB Error Logs - Shell\nDESCRIPTION: Demonstrates the use of the 'log' command in TiDB Control to transform single-line stack traces in error logs into a more readable multi-line format.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-control.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntidb-ctl log\n```\n\n----------------------------------------\n\nTITLE: Enabling low-precision TSO in TiDB for reduced wait time\nDESCRIPTION: This SQL command enables the low-precision TSO feature in TiDB to help reduce TSO wait times during read operations, at the risk of potentially stale reads. It's particularly useful for read-heavy workloads where slight staleness can be tolerated.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_low_resolution_tso=ON;\n```\n\n----------------------------------------\n\nTITLE: Inserting Encoded Unicode Value\nDESCRIPTION: Inserting a 4-byte Unicode character using unhex function before UTF-8 check implementation\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/upgrade-faq.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\ninsert t values (unhex('f09f8c80'));\n```\n\n----------------------------------------\n\nTITLE: Verifying Partial Pushdown\nDESCRIPTION: SQL query to verify that only the non-blocklisted operator (>) is pushed down to TiKV while the blocklisted operator (<) remains at root.\nSOURCE: https://github.com/pingcap/docs/blob/master/blocklist-control-plan.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t WHERE a < 2 AND a > 2;\n```\n\n----------------------------------------\n\nTITLE: Querying utf8mb4 Collations in TiDB\nDESCRIPTION: This SQL query retrieves all available collations for the utf8mb4 character set, displaying their names, IDs, default status, compilation status, and sort length information.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-collations.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM collations WHERE character_set_name='utf8mb4';\n```\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------+--------------------+------+------------+-------------+---------+\n| COLLATION_NAME     | CHARACTER_SET_NAME | ID   | IS_DEFAULT | IS_COMPILED | SORTLEN |\n+--------------------+--------------------+------+------------+-------------+---------+\n| utf8mb4_bin        | utf8mb4            |   46 | Yes        | Yes         |       1 |\n| utf8mb4_general_ci | utf8mb4            |   45 |            | Yes         |       1 |\n| utf8mb4_unicode_ci | utf8mb4            |  224 |            | Yes         |       1 |\n+--------------------+--------------------+------+------------+-------------+---------+\n3 rows in set (0.001 sec)\n```\n\n----------------------------------------\n\nTITLE: Enabling Fast Table Creation\nDESCRIPTION: Configures the tidb_enable_fast_create_table variable to enable or disable TiDB Accelerated Table Creation. This feature can significantly speed up the process of creating new tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_28\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_enable_fast_create_table = ON;\n```\n\n----------------------------------------\n\nTITLE: Setting Transaction Modes in TiDB\nDESCRIPTION: These SQL commands set the transaction mode for sessions in TiDB, allowing for optimization based on expected workload behavior, with options for pessimistic and optimistic modes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSET SESSION tidb_txn_mode = \"pessimistic\";\n\nSET SESSION tidb_txn_mode = \"optimistic\";\n```\n\n----------------------------------------\n\nTITLE: Java Helper Methods for Session-Level Stale Read\nDESCRIPTION: Implements helper methods to manage session-level stale read settings in Java.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-stale-read.md#2025-04-18_snippet_10\n\nLANGUAGE: java\nCODE:\n```\npublic static class StaleReadHelper{\n\n    public static void enableStaleReadOnSession(Connection conn, Integer seconds) throws SQLException {\n        PreparedStatement stmt = conn.prepareStatement(\n            \"SET @@tidb_read_staleness= ?;\"\n        );\n        stmt.setString(1, String.format(\"-%d\", seconds));\n        stmt.execute();\n    }\n\n    public static void disableStaleReadOnSession(Connection conn) throws SQLException {\n        PreparedStatement stmt = conn.prepareStatement(\n            \"SET @@tidb_read_staleness=\\\"\\\";\"\n        );\n        stmt.execute();\n    }\n\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Initial Pushdown Behavior\nDESCRIPTION: SQL query to demonstrate the default behavior where both < and > operators are pushed down to TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/blocklist-control-plan.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t WHERE a < 2 AND a > 2;\n```\n\n----------------------------------------\n\nTITLE: Transforming SELECT DISTINCT to GROUP BY in TiDB\nDESCRIPTION: This example shows how TiDB transforms a SELECT DISTINCT query into a GROUP BY operation internally. The execution plan reveals that a HashAgg operator is used to handle the distinct operation on column 'a'.\nSOURCE: https://github.com/pingcap/docs/blob/master/agg-distinct-optimization.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain SELECT DISTINCT a from t;\n+--------------------------+---------+-----------+---------------+-------------------------------------------------------+\n| id                       | estRows | task      | access object | operator info                                         |\n+--------------------------+---------+-----------+---------------+-------------------------------------------------------+\n| HashAgg_6                | 2.40    | root      |               | group by:test.t.a, funcs:firstrow(test.t.a)->test.t.a |\n| └─TableReader_11         | 3.00    | root      |               | data:TableFullScan_10                                 |\n|   └─TableFullScan_10     | 3.00    | cop[tikv] | table:t       | keep order:false, stats:pseudo                        |\n+--------------------------+---------+-----------+---------------+-------------------------------------------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Table in TiDB\nDESCRIPTION: Example of creating a simple table with a single integer column, viewing its structure, and inserting data. This demonstrates the basic CREATE TABLE syntax and validation.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-table.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (a int);\nDESC t1;\nSHOW CREATE TABLE t1\\G\nINSERT INTO t1 (a) VALUES (1);\nSELECT * FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Accessing TiDB Statistics API Endpoint\nDESCRIPTION: HTTP endpoint to access the JSON format statistics of a specific table in a specified database.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\nhttp://${tidb-server-ip}:${tidb-server-status-port}/stats/dump/${db_name}/${table_name}\n```\n\n----------------------------------------\n\nTITLE: Table Row Key Example in TiDB\nDESCRIPTION: Concrete example of an encoded row key in TiDB storage, with table_id 22 and row_id 11.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\nt22_r11\n```\n\n----------------------------------------\n\nTITLE: Defining TiDB Schema Loading Failure Alert Rule in Prometheus\nDESCRIPTION: Alert rule to detect failures in reloading the latest schema information in TiDB. Triggers when failures exceed 10 times in 10 minutes.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_2\n\nLANGUAGE: prometheus\nCODE:\n```\nincrease(tidb_domain_load_schema_total{type=\"failed\"}[10m]) > 10\n```\n\n----------------------------------------\n\nTITLE: Checking TiDB Cloud Restore Task Status\nDESCRIPTION: Terminal output showing how to check the status of a TiDB Cloud restore task using the Terraform state show command. The output displays detailed information about the restore task including its current status.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-restore-resource.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform state show tidbcloud_restore.example_restore\n\n# tidbcloud_restore.example_restore:\nresource \"tidbcloud_restore\" \"example_restore\" {\n    backup_id        = \"1350048\"\n    cluster          = {\n        id     = \"1379661944630264072\"\n        name   = \"restoreCluster\"\n        status = \"INITIALIZING\"\n    }\n    cluster_id       = \"1379661944630234067\"\n    config           = {\n        components    = {\n            tidb    = {\n                node_quantity = 2\n                node_size     = \"8C16G\"\n            }\n            tiflash = {\n                node_quantity    = 2\n                node_size        = \"8C64G\"\n                storage_size_gib = 500\n            }\n            tikv    = {\n                node_quantity    = 6\n                node_size        = \"8C32G\"\n                storage_size_gib = 500\n            }\n        }\n        port          = 4000\n        root_password = \"Your_root_password1.\"\n    }\n    create_timestamp = \"2022-08-26T08:16:33Z\"\n    id               = \"780114\"\n    name             = \"restoreCluster\"\n    project_id       = \"1372813089189561287\"\n    status           = \"PENDING\"\n}\n```\n\n----------------------------------------\n\nTITLE: Getting Vector Dimensions in TiDB SQL\nDESCRIPTION: VEC_DIMS function returns the dimension of a vector. Works with vectors of any size including empty vectors.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-functions-and-operators.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VEC_DIMS('[1,2,3]');\n\nSELECT VEC_DIMS('[]');\n```\n\n----------------------------------------\n\nTITLE: Executing SQL Queries with TiDB Cloud Serverless Driver\nDESCRIPTION: Code snippet demonstrating how to create a connection to a TiDB Cloud Serverless cluster and execute a parameterized SQL query.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_1\n\nLANGUAGE: ts\nCODE:\n```\nimport { connect } from '@tidbcloud/serverless'\n\nconst conn = connect({url: 'mysql://[username]:[password]@[host]/[database]'})\nconst results = await conn.execute('select * from test where id = ?',[1])\n```\n\n----------------------------------------\n\nTITLE: Using INSERT Prepared Statements in Java JDBC\nDESCRIPTION: Illustrates how to use prepared statements with Java JDBC to insert data into the 'books' table, including setting various data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-prepared-statement.md#2025-04-18_snippet_5\n\nLANGUAGE: java\nCODE:\n```\ntry (Connection connection = ds.getConnection()) {\n    String sql = \"INSERT INTO `books` (`title`, `type`, `stock`, `price`, `published_at`) VALUES (?, ?, ?, ?, ?);\";\n    PreparedStatement preparedStatement = connection.prepareStatement(sql);\n\n    preparedStatement.setString(1, \"TiDB Developer Guide\");\n    preparedStatement.setString(2, \"Science & Technology\");\n    preparedStatement.setInt(3, 100);\n    preparedStatement.setBigDecimal(4, new BigDecimal(\"0.0\"));\n    preparedStatement.setTimestamp(5, new Timestamp(Calendar.getInstance().getTimeInMillis()));\n\n    preparedStatement.executeUpdate();\n} catch (SQLException e) {\n    e.printStackTrace();\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering SQL Plan Baseline by Database and Table Wildcards\nDESCRIPTION: Use wildcard patterns to filter plan baseline capturing across multiple databases and tables with flexible matching rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_30\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO mysql.capture_plan_baselines_blacklist(filter_type, filter_value) VALUES('table', 'test.table_*');\nINSERT INTO mysql.capture_plan_baselines_blacklist(filter_type, filter_value) VALUES('table', 'db_*.table_*');\n```\n\n----------------------------------------\n\nTITLE: Removing Session-Level SQL Plan Binding\nDESCRIPTION: Demonstrates how to remove a previously created session-level binding for a specific SQL statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nDROP SESSION BINDING for SELECT * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Executing start-task Command in TiDB Data Migration (Bash)\nDESCRIPTION: This command executes the `start-task` command with a configuration file. It demonstrates how to start a data migration task and shows the expected JSON output indicating the success or failure of the operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-create-task.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nstart-task task.yaml\n```\n\n----------------------------------------\n\nTITLE: Comparing Query Execution Plans Without and With Recommended Index\nDESCRIPTION: Uses EXPLAIN FORMAT='VERBOSE' to compare the execution plan of a query without indexes to the same query using a hypothetical index recommended by the Index Advisor. Shows the significant performance improvement from using the recommended index.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN FORMAT='VERBOSE' SELECT a, b FROM t WHERE a=1 AND b=1;\n```\n\n----------------------------------------\n\nTITLE: Querying All Records in TiDB with SQL\nDESCRIPTION: This SQL statement selects all columns and rows from the 'person' table. It demonstrates how to retrieve all data from a table.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-tidb-crud-sql.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM person;\n```\n\n----------------------------------------\n\nTITLE: Altering User with Combined Password Reuse Policy in SQL\nDESCRIPTION: SQL command to modify an existing user with a combined password reuse policy that prohibits both the last 5 passwords and any passwords used within the last 365 days.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_27\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER 'test'@'localhost'\n  PASSWORD HISTORY 5\n  PASSWORD REUSE INTERVAL 365 DAY;\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB as Root\nDESCRIPTION: Shell command to connect to TiDB database as the root user on localhost port 4000.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-revoke-role.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 127.0.0.1 -P 4000 -u root\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW PLACEMENT FOR Commands in SQL\nDESCRIPTION: These SQL commands illustrate how to create and alter placement policies, as well as query the placement status for specific tables and databases. The expected input includes policy definitions and database/table identifiers, while the output is a summary of the current scheduling state for each target.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-placement-for.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY p1 PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\" FOLLOWERS=4;\nALTER DATABASE test PLACEMENT POLICY=p1;\nCREATE TABLE t1 (a INT);\nSHOW PLACEMENT FOR DATABASE test;\nSHOW PLACEMENT FOR TABLE t1;\nSHOW CREATE TABLE t1\\G\nCREATE TABLE t3 (a INT) PARTITION BY RANGE (a) (PARTITION p1 VALUES LESS THAN (10), PARTITION p2 VALUES LESS THAN (20));\nSHOW PLACEMENT FOR TABLE t3 PARTITION p1\\G\n```\n\n----------------------------------------\n\nTITLE: Displaying Log Backup Task Status\nDESCRIPTION: This command retrieves the status of a log backup task. The command provides information such as the task name, status (NORMAL, ERROR, etc.), start and end times, storage location, backup speed, checkpoint details, and error messages, allowing you to monitor and troubleshoot log backup tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n\"br log status --pd x.x.x.x:2379\"\n```\n\n----------------------------------------\n\nTITLE: Querying Trip Records with Filter in TiDB Cloud\nDESCRIPTION: SQL query to retrieve trip records from the trips table where the start station name is '12th & U St NW', limited to 10 results.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-sample-data.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nselect * from `trips` where start_station_name='12th & U St NW' limit 10;\n```\n\n----------------------------------------\n\nTITLE: Querying Global Checkpoint Information in TiDB\nDESCRIPTION: This SQL query retrieves the global checkpoint information for all upstream database sources corresponding to the data migration task from the checkpoint table in the downstream TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/manually-upgrade-dm-1.0-to-2.0.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT `id`, `binlog_name`, `binlog_pos` FROM `dm_meta`.`task_v1_syncer_checkpoint` WHERE `is_global`=1;\n```\n\n----------------------------------------\n\nTITLE: Inserting Values with Division by Zero in TiDB\nDESCRIPTION: Shows an SQL statement that attempts to insert a result of division by zero into a table, used to demonstrate different behaviors based on SQL mode settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/precision-math.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO t SET i = 1/0;\n```\n\n----------------------------------------\n\nTITLE: Querying CPU Load Information from CLUSTER_LOAD\nDESCRIPTION: Demonstrates how to query CPU load metrics for all instances in the TiDB cluster using the CLUSTER_LOAD table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-load.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM cluster_load WHERE device_type='cpu' AND device_name='cpu';\n```\n\n----------------------------------------\n\nTITLE: Splitting Table Index Data with SQL\nDESCRIPTION: This SQL snippet demonstrates how to use the SPLIT TABLE command to divide index data into multiple Regions based on a specified range, from \"a\" to \"z\", in TiDB. No additional dependencies are required, and it primarily functions to improve data distribution. Expected input includes a table name and the index's range, while the output shows the number of Regions created and the scatter finish ratio.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-regions.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\ntest> SPLIT TABLE t INDEX name BETWEEN (\"a\") AND (\"z\") REGIONS 2;\n+--------------------+----------------------+\n| TOTAL_SPLIT_REGION | SCATTER_FINISH_RATIO |\n+--------------------+----------------------+\n| 2                  | 1.0                  |\n+--------------------+----------------------+\n```\n\n----------------------------------------\n\nTITLE: Status Code 429 SQL Endpoint Response Example\nDESCRIPTION: This code snippet illustrates a Data Service response from a SQL endpoint with an HTTP status code of 429. The response indicates that the request exceeded the rate limit for the API key (100 requests per minute). The `result.code` is 49900007, and the `message` field provides details about the rate limit and a link to request more quota.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"\",\n  \"data\": {\n    \"columns\": [],\n    \"rows\": [],\n    \"result\": {\n      \"code\": 49900007,\n      \"message\": \"The request exceeded the limit of 100 times per apikey per minute. For more quota, please contact us: https://tidb.support.pingcap.com/\",\n      \"start_ms\": \"\",\n      \"end_ms\": \"\",\n      \"latency\": \"\",\n      \"row_count\": 0,\n      \"row_affect\": 0,\n      \"limit\": 0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Pushing Predicates Below Join Operator\nDESCRIPTION: Illustrates how predicates can be pushed below join operators to reduce computational overhead by filtering data before join\nSOURCE: https://github.com/pingcap/docs/blob/master/predicate-push-down.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id int primary key, a int not null);\ncreate table s(id int primary key, a int not null);\nexplain select * from t join s on t.a = s.a where t.a < 1;\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed with Kafka Sink\nDESCRIPTION: Command example showing how to create a TiCDC changefeed that replicates data to Kafka, including configuration for table matching and topic naming. The command specifies Kafka connection details, partition settings, and message size limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-architecture.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=\"http://127.0.0.1:8300\" --sink-uri=\"kafka://127.0.0.1:9092/cdc-test?kafka-version=2.4.0&partition-num=6&max-message-bytes=67108864&replication-factor=1\"\ncat changefeed.toml\n......\n[sink]\ndispatchers = [\n    {matcher = ['test1.tab1', 'test2.tab2'], topic = \"{schema}_{table}\"},\n    {matcher = ['test3.tab3', 'test4.tab4'], topic = \"{schema}_{table}\"},\n]\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into a Table with AUTO_RANDOM Primary Key (Invalid Approach)\nDESCRIPTION: This SQL snippet demonstrates an invalid approach for inserting data into a table with an AUTO_RANDOM primary key. This will result in an error as explicit insertion on AUTO_RANDOM columns is disabled by default.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-insert-data.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO `bookshop`.`users` (`id`, `balance`, `nickname`) VALUES (1, 0.00, 'nicky');\n```\n\n----------------------------------------\n\nTITLE: Prepared statement with JSON_CONTAINS and no plan cache\nDESCRIPTION: This SQL code prepares and executes a statement that selects from table `t5` using `JSON_CONTAINS`. Because `JSON_CONTAINS` with immutable parameters can affect index selection, the query plan cannot be cached, as indicated by the warning message.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\nmysql> PREPARE st2 FROM 'SELECT /*+ use_index(t5, idx1) */ * FROM t5 WHERE JSON_CONTAINS(j1, ?)';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SET @a='[1,2]';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> EXECUTE st2 USING @a;\nEmpty set, 1 warning (0.00 sec)\n\nmysql> SHOW WARNINGS;  -- cannot hit plan cache since the JSON_CONTAINS predicate might affect index selection\n+---------+------+-------------------------------------------------------------------------------------------------------+\n| Level   | Code | Message                                                                                               |\n+---------+------+-------------------------------------------------------------------------------------------------------+\n| Warning | 1105 | skip prepared plan-cache: json_contains function with immutable parameters can affect index selection |\n+---------+------+-------------------------------------------------------------------------------------------------------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP using Shell\nDESCRIPTION: This shell command is used to install TiUP, a package manager for managing different components within the TiDB ecosystem. Users need to execute this command in their terminal, and it requires access to the internet to fetch the installation script securely.\nSOURCE: https://github.com/pingcap/docs/blob/master/migration-tools.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Setting Default Resource Group\nDESCRIPTION: SQL commands to set the current session to use the default resource group and verify the change.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-resource-group.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSET RESOURCE GROUP `default`;\nSELECT CURRENT_RESOURCE_GROUP();\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB Row ID Sharding Information\nDESCRIPTION: Shows how to query the TIDB_ROW_ID_SHARDING_INFO column in the information_schema.tables table to get RowID scattering information.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-beta.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT TIDB_ROW_ID_SHARDING_INFO FROM information_schema.tables WHERE table_name = 'A';\n```\n\n----------------------------------------\n\nTITLE: Example GCS URI for IMPORT INTO Statement\nDESCRIPTION: Shows how to format a Google Cloud Storage URI for the IMPORT INTO SQL statement, specifying a CSV file and credentials file.\nSOURCE: https://github.com/pingcap/docs/blob/master/external-storage-uri.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ngcs://external/test.csv?credentials-file=${credentials-file-path}\n```\n\n----------------------------------------\n\nTITLE: Granting SELECT Privilege to a Role in TiDB\nDESCRIPTION: This snippet shows how to grant the `SELECT` privilege on the `app_db` database to the `app_read` role. The `GRANT` statement is used to assign privileges to roles, similar to how privileges are granted to users. The user executing this statement needs appropriate grant privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nGRANT SELECT ON app_db.* TO 'app_read'@'%';\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS for TiFlash\nDESCRIPTION: This code configures TLS for TiFlash by specifying the paths to the CA certificate, server certificate, and server key in `tiflash.toml` and `tiflash-learner.toml` files, thus enabling encrypted communication.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n\t\t```toml\n        [security]\n        ## The path for certificates. An empty string means that secure connections are disabled.\n        # Path of the file that contains a list of trusted SSL CAs. If it is set, the following settings `cert_path` and `key_path` are also needed.\n        ca_path = \"/path/to/ca.pem\"\n        # Path of the file that contains X509 certificate in PEM format.\n        cert_path = \"/path/to/tiflash-server.pem\"\n        # Path of the file that contains X509 key in PEM format.\n        key_path = \"/path/to/tiflash-server-key.pem\"\n        ```\n```\n\nLANGUAGE: toml\nCODE:\n```\n        ```toml\n        [security]\n        # Path of the file that contains a list of trusted SSL CAs. If it is set, the following settings `cert_path` and `key_path` are also needed.\n        ca-path = \"/path/to/ca.pem\"\n        # Path of the file that contains X509 certificate in PEM format.\n        cert-path = \"/path/to/tiflash-server.pem\"\n        # Path of the file that contains X509 key in PEM format.\n        key-path = \"/path/to/tiflash-server-key.pem\"\n        ```\n```\n\n----------------------------------------\n\nTITLE: Starting Data Migration Task\nDESCRIPTION: Command to start a data migration task using dmctl and the task configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-task.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n./dmctl --master-addr 127.0.0.1:8261 start-task conf/task.yaml\n```\n\n----------------------------------------\n\nTITLE: FLASHBACK CLUSTER Failure Example in TiDB\nDESCRIPTION: Example demonstrating a scenario where FLASHBACK CLUSTER fails due to an incomplete DDL statement at the specified time.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-cluster.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t ADD INDEX k(a);\n\nADMIN SHOW DDL JOBS 1;\n\nFLASHBACK CLUSTER TO TIMESTAMP '2023-01-29 14:33:12';\n```\n\n----------------------------------------\n\nTITLE: Restoring Default Snapshot Write Speed in TiDB\nDESCRIPTION: SQL statements to return to the default snapshot write speeds for TiDB after completing replication tasks, ensuring the cluster operates within its usual limits post-acceleration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSET CONFIG tikv `server.snap-io-max-bytes-per-sec` = '100MiB';\nSET CONFIG tiflash `raftstore-proxy.server.snap-io-max-bytes-per-sec` = '100MiB';\n```\n\n----------------------------------------\n\nTITLE: Switching to parallel mode for TSO requests in TiDB\nDESCRIPTION: These SQL commands allow you to switch the mode in which TiDB sends TSO RPC requests to PD, potentially improving performance for workloads suffering from high TSO wait times. Options are 'PARALLEL' and 'PARALLEL-FAST'.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n-- Use the PARALLEL mode\nSET GLOBAL tidb_tso_client_rpc_mode=PARALLEL;\n\n-- Use the PARALLEL-FAST mode\nSET GLOBAL tidb_tso_client_rpc_mode=PARALLEL-FAST;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiFlash Storage Paths in TOML\nDESCRIPTION: Example of configuring storage paths for TiFlash data in the tiflash.toml file. This shows how to set multiple directories for storing data and specifying capacity limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[storage.main]\ndir = [\"/tidb-data/tiflash-9000\", \"/ssd0/tidb-data/tiflash\", \"/ssd1/tidb-data/tiflash\"]\ncapacity = [10737418240, 10737418240, 10737418240]\n\n[storage.latest]\ndir = [\"/nvme0/tidb-data/tiflash\", \"/nvme1/tidb-data/tiflash\"]\ncapacity = [10737418240, 10737418240]\n```\n\n----------------------------------------\n\nTITLE: Identifying Tables Without TiFlash Replicas in TiDB\nDESCRIPTION: This SQL query identifies tables in a specific database that do not have TiFlash replicas. It compares tables in the database against those with TiFlash replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT TABLE_NAME FROM information_schema.tables where TABLE_SCHEMA = \"<db_name>\" and TABLE_NAME not in (SELECT TABLE_NAME FROM information_schema.tiflash_replica where TABLE_SCHEMA = \"<db_name>\");\n```\n\n----------------------------------------\n\nTITLE: Setting External Timestamp in TiDB\nDESCRIPTION: This SQL snippet sets the global system variable 'tidb_external_ts' to the current timestamp. It is prepared for reading historical data based on the specified timestamp.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-external-ts.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSTART TRANSACTION;\nSET GLOBAL tidb_external_ts=@@tidb_current_ts;\nCOMMIT;\n```\n\n----------------------------------------\n\nTITLE: SQL Encryption Function Fix\nDESCRIPTION: Fixed runtime error when using AES_DECRYPT expression in SQL statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.7.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nAES_DECRYPT\n```\n\n----------------------------------------\n\nTITLE: Creating a Python Virtual Environment for TiDB Vector Project\nDESCRIPTION: Commands to set up a Python virtual environment for the TiDB Vector project, which isolates the project dependencies from other Python projects.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-peewee.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd tidb-vector-python/examples/orm-peewee-quickstart\npython3 -m venv .venv\nsource .venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Creating Sharded Table Schema in MySQL\nDESCRIPTION: This SQL snippet defines the schema for sharded tables (sale_01, sale_02) in the upstream MySQL instances. The table includes an auto-incrementing primary key (`id`) and a unique key (`sid`) used for sharding. The example table contains columns for `id`, `sid`, `pid`, and `comment`.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-shards-to-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE TABLE `sale_01` (\n  `id` bigint NOT NULL AUTO_INCREMENT,\n  `sid` bigint NOT NULL,\n  `pid` bigint NOT NULL,\n  `comment` varchar(255) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `sid` (`sid`)\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Master Key in TiKV - INI\nDESCRIPTION: This configuration snippet shows how to specify the master key in the TiKV configuration file after creating it using AWS KMS. It includes key information such as key-id, region, and endpoint.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_2\n\nLANGUAGE: ini\nCODE:\n```\n[security.encryption.master-key]\ntype = \"kms\"\nkey-id = \"0987dcba-09fe-87dc-65ba-ab0987654321\"\nregion = \"us-west-2\"\nendpoint = \"https://kms.us-west-2.amazonaws.com\"\n```\n\n----------------------------------------\n\nTITLE: Using S3 Wildcard Pattern for Multiple Character Matching\nDESCRIPTION: Demonstrates how to use the asterisk wildcard in S3 URIs to match any number of characters in filenames during import.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-parquet-files.md#2025-04-18_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\ns3://[bucket_name]/[data_source_folder]/my-data*.parquet\n```\n\n----------------------------------------\n\nTITLE: JWT Token Generation Command\nDESCRIPTION: Generates a JWT token using a Go-based tool, specifying key ID, subject, email, and issuer\nSOURCE: https://github.com/pingcap/docs/blob/master/security-compatibility-with-mysql.md#2025-04-18_snippet_5\n\nLANGUAGE: text\nCODE:\n```\ngenerate_jwt --kid \"the-key-id-0\" --sub \"user@pingcap.com\" --email \"user@pingcap.com\" --iss \"issuer-abc\"\n```\n\n----------------------------------------\n\nTITLE: Selecting Data from a Local Temporary Table in a Different Session\nDESCRIPTION: Retrieves all rows from the local temporary table of a different session, highlighting its independent data storage and functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/temporary-tables.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM users;\n```\n\n----------------------------------------\n\nTITLE: Using TIDB_IS_DDL_OWNER to Check if Connected to DDL Owner\nDESCRIPTION: Demonstrates using TIDB_IS_DDL_OWNER function to check if the current TiDB instance is the DDL owner. Returns 1 if true, 0 if false.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_IS_DDL_OWNER();\n```\n\n----------------------------------------\n\nTITLE: Viewing Placement Rules with pd-ctl\nDESCRIPTION: Basic commands to view placement rules in the system using pd-ctl, including showing all rules, group-specific rules, and region-specific rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-placement-rules.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules show\n```\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules show --group=pd\n```\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules show --group=pd --id=default\n```\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules show --region=2\n```\n\n----------------------------------------\n\nTITLE: Revoking Database Privileges in TiDB\nDESCRIPTION: SQL command to revoke INSERT, UPDATE, and DELETE privileges on app_db database from the app_write role.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE INSERT, UPDATE, DELETE ON app_db.* FROM 'app_write';\n```\n\n----------------------------------------\n\nTITLE: Checking Firewall Status on TiDB Host\nDESCRIPTION: Commands to check the current status of the firewalld service on CentOS 7, which is important to ensure proper network communication between TiDB cluster components.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nsudo firewall-cmd --state\nsudo systemctl status firewalld.service\n```\n\n----------------------------------------\n\nTITLE: Manual SSH Connection Testing\nDESCRIPTION: Command to manually test SSH connection with private key\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-troubleshooting-guide.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nssh -i identity_file user@remote\n```\n\n----------------------------------------\n\nTITLE: Creating a Kafka Changefeed - Shell\nDESCRIPTION: Creates a changefeed in TiCDC to replicate incremental data from TiDB to Kafka. The provided URI configuration includes options for additional Kafka brokers for production environments.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-data-to-kafka.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc:v<CLUSTER_VERSION> cli changefeed create --server=\"http://127.0.0.1:8300\" --sink-uri=\"kafka://127.0.0.1:9092/kafka-topic-name?protocol=canal-json\" --changefeed-id=\"kafka-changefeed\" --config=\"changefeed.conf\"\n\n# If successful, the output will include changefeed information.\nCreate changefeed successfully!\nID: kafka-changefeed\nInfo: {... changfeed info json struct ...}\n```\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc:v<CLUSTER_VERSION> cli changefeed create --server=\"http://127.0.0.1:8300\" --sink-uri=\"kafka://127.0.0.1:9092,127.0.0.2:9092,127.0.0.3:9092/kafka-topic-name?protocol=canal-json&partition-num=3&replication-factor=1&max-message-bytes=1048576\" --config=\"changefeed.conf\"\n```\n\n----------------------------------------\n\nTITLE: Viewing Load Base Split Configuration with SQL in TiDB\nDESCRIPTION: Shows how to view the Load Base Split configuration using SQL statements in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-load-base-split.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nshow config where type='tikv' and name like '%split.qps-threshold%';\n```\n\n----------------------------------------\n\nTITLE: Connecting to a TiDB Cloud Serverless branch in interactive mode\nDESCRIPTION: Example showing how to connect to a TiDB Cloud Serverless branch using interactive mode, which will prompt for required information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-shell.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch shell\n```\n\n----------------------------------------\n\nTITLE: Immediate Unique Constraint Violation Detection\nDESCRIPTION: This example shows the immediate error when attempting to insert a duplicate value with in-place constraint checking enabled in an optimistic transaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO users (username) VALUES ('jane'), ('chris'), ('bill');\n```\n\n----------------------------------------\n\nTITLE: Installing Dumpling using TiUP\nDESCRIPTION: Command to install Dumpling, a data export tool for MySQL and TiDB, using the TiUP package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/get-started-with-tidb-lightning.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup install dumpling\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Cloud Serverless Connection with Database URL in TypeScript\nDESCRIPTION: This snippet shows how to configure a connection to TiDB Cloud Serverless using a database URL. It uses an environment variable 'DATABASE_URL' or a fallback URL string. The arrayMode option is also set to true for better performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst config = {\n  url: process.env['DATABASE_URL'] || 'mysql://[username]:[password]@[host]/[database]',\n  arrayMode: true\n}\n\nconst conn = connect(config)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Right Shift Operation in SQL using Recursive CTE\nDESCRIPTION: This SQL query uses a recursive CTE to demonstrate the right shift operation on the value 1024 for different shift amounts. It shows the decimal result and the binary representation of the shifted value.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/bit-functions-and-operators.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nWITH RECURSIVE cte(n) AS (\n    SELECT 0 AS n\n    UNION ALL\n    SELECT n+1 FROM cte WHERE n<11\n)\nSELECT n,1024>>n,LPAD(CONV(1024>>n,10,2),11,0) FROM cte;\n```\n\n----------------------------------------\n\nTITLE: Specifying Global Configuration in YAML\nDESCRIPTION: This YAML snippet demonstrates how to set up the global configuration for a TiUP cluster. It specifies the user as 'tidb' and enforces a memory limit of 2 GB for resource control. The 'global' section generally configures cluster-wide defaults such as SSH ports, TLS settings, and directories for deployment, data, and logs.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nglobal:\n  user: \"tidb\"\n  resource_control:\n    memory_limit: \"2G\"\n\n```\n\n----------------------------------------\n\nTITLE: Create Invisible Index\nDESCRIPTION: This SQL code demonstrates how to create an invisible index in TiDB.  Invisible indexes are ignored by the query optimizer by default, allowing for testing index changes without affecting query performance. Starting from TiDB v8.0.0, the behavior can be changed by modifying the system variable tidb_opt_use_invisible_indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (c1 INT, c2 INT, UNIQUE(c2));\nCREATE UNIQUE INDEX c1 ON t1 (c1) INVISIBLE;\n\n```\n\n----------------------------------------\n\nTITLE: Explaining Query for MPP Mode\nDESCRIPTION: This SQL statement, combined with `show warnings`, helps identify reasons why TiDB might not select the MPP mode for a specific query. The `EXPLAIN` statement provides a plan for the query execution, and `show warnings` displays messages indicating unsupported functions or operators that prevent MPP execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\n```sql\ncreate table t(a datetime);\nalter table t set tiflash replica 1;\ninsert into t values('2022-01-13');\nset @@session.tidb_enforce_mpp=1;\nexplain select count(*) from t where subtime(a, '12:00:00') > '2022-01-01' group by a;\nshow warnings;\n```\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed with Specific Start Timestamp\nDESCRIPTION: Shell command to create a new TiCDC replication task (changefeed) with a specific start timestamp. This is used after data restoration to begin incremental replication from a particular point in time.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create -c \"upstream-to-downstream-some-tables\" --start-ts=431434047157698561 --sink-uri=\"mysql://root@127.0.0.1:4000? time-zone=\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Memory Profiling in TiKV\nDESCRIPTION: These YAML configuration options enable heap profiling and set the sampling rate for tracking memory usage in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_36\n\nLANGUAGE: yaml\nCODE:\n```\nmemory:\n  enable-heap-profiling: true\n  profiling-sample-per-bytes: \"512KiB\"\n```\n\n----------------------------------------\n\nTITLE: Using NO_DECORRELATE Hint in TiDB Query\nDESCRIPTION: Demonstrates how to use the NO_DECORRELATE optimizer hint to prevent subquery decorrelation optimization.\nSOURCE: https://github.com/pingcap/docs/blob/master/correlated-subquery-optimization.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nexplain select * from t1 where t1.a < (select /*+ NO_DECORRELATE() */ sum(t2.a) from t2 where t2.b = t1.b);\n```\n\n----------------------------------------\n\nTITLE: Configuring Large Table Distribution Across TiCDC Nodes\nDESCRIPTION: Configuration for scaling out the replication of a single large table across multiple TiCDC nodes. This distributes the load based on Region count and write volume thresholds.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_14\n\nLANGUAGE: toml\nCODE:\n```\n[scheduler]\n# The default value is \"false\". You can set it to \"true\" to enable this feature.\nenable-table-across-nodes = true\n# When you enable this feature, it only takes effect for tables with the number of regions greater than the `region-threshold` value.\nregion-threshold = 100000\n# When you enable this feature, it takes effect for tables with the number of rows modified per minute greater than the `write-key-threshold` value.\n# Note:\n# * The default value of `write-key-threshold` is 0, which means that the feature does not split the table replication range according to the number of rows modified in a table by default.\n# * You can configure this parameter according to your cluster workload. For example, if it is configured as 30000, it means that the feature will split the replication range of a table when the number of modified rows per minute in the table exceeds 30000.\n# * When `region-threshold` and `write-key-threshold` are configured at the same time:\n#   TiCDC will check whether the number of modified rows is greater than `write-key-threshold` first.\n#   If not, next check whether the number of Regions is greater than `region-threshold`.\nwrite-key-threshold = 30000\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning Import Settings in TOML\nDESCRIPTION: TOML configuration for TiDB Lightning to control import speed and reduce impact on cluster performance, including bandwidth limit and concurrency settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-physical-import-mode-usage.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[tikv-importer]\n# Limits the bandwidth in which TiDB Lightning writes data into each TiKV node in the physical import mode.\nstore-write-bwlimit = \"128MiB\"\n\n[tidb]\n# Use smaller concurrency to reduce the impact of Checksum and Analyze on the transaction latency.\ndistsql-scan-concurrency = 3\n```\n\n----------------------------------------\n\nTITLE: Configuring Load Processing Unit - YAML\nDESCRIPTION: This snippet outlines configuration parameters for the load processing unit, including pool size for concurrent executions and the directory for storing dumped data. It also defines import modes and conflict resolution strategies during data loading.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/task-configuration-file-full.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nloaders:\n  global:                            # The configuration name of the processing unit.\n    pool-size: 16                    # The number of threads that concurrently execute dumped SQL files in the load processing unit (16 by default). When multiple instances are migrating data to TiDB at the same time, slightly reduce the value according to the load.\n    dir: \"./dumped_data\"\n    import-mode: \"logical\"\n    on-duplicate-logical: \"replace\"\n    on-duplicate-physical: \"none\"\n    sorting-dir-physical: \"./dumped_data\"\n    disk-quota-physical: \"0\"\n    checksum-physical: \"required\"\n    analyze: \"off\"\n```\n\n----------------------------------------\n\nTITLE: Adding TiDB-JDBC Gradle Dependencies\nDESCRIPTION: Gradle configuration for adding TiDB-JDBC and related dependencies to a Java project.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-choose-driver-or-orm.md#2025-04-18_snippet_2\n\nLANGUAGE: gradle\nCODE:\n```\nimplementation group: 'io.github.lastincisor', name: 'mysql-connector-java', version: '8.0.29-tidb-1.0.0'\nimplementation group: 'org.bouncycastle', name: 'bcprov-jdk15on', version: '1.67'\nimplementation group: 'org.bouncycastle', name: 'bcpkix-jdk15on', version: '1.67'\n```\n\n----------------------------------------\n\nTITLE: Importing Sample Data Using TiUP\nDESCRIPTION: This snippet provides a command to quickly generate and import sample data for the Bookshop application using TiUP. By default, it configures the connection to a local TiDB server.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-bookshop-schema-design.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup demo bookshop prepare\n```\n\n----------------------------------------\n\nTITLE: Viewing Store Limit settings with PD Control\nDESCRIPTION: Commands to view the current store limit settings for all stores, including specific commands for viewing add-peer and remove-peer limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-store-limit.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd store limit                         // Shows the speed limit of adding and deleting peers in all stores.\ntiup ctl:v<CLUSTER_VERSION> pd store limit add-peer                // Shows the speed limit of adding peers in all stores.\ntiup ctl:v<CLUSTER_VERSION> pd store limit remove-peer             // Shows the speed limit of deleting peers in all stores.\n```\n\n----------------------------------------\n\nTITLE: Configuring Memory Usage Alarm Ratio in TiDB\nDESCRIPTION: Example of setting the memory usage alarm ratio that triggers warnings when memory usage exceeds a threshold percentage.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-memory-usage.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_memory_usage_alarm_ratio = 0.85;\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW CREATE SEQUENCE Syntax in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the SHOW CREATE SEQUENCE statement in TiDB. It shows the structure of the statement, including optional schema name and required table name.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-sequence.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowCreateSequenceStmt ::=\n    \"SHOW\" \"CREATE\" \"SEQUENCE\" ( SchemaName \".\" )? TableName\n```\n\n----------------------------------------\n\nTITLE: Adding Hibernate Timeout Configuration in TiKV\nDESCRIPTION: Adds a new hibernate-timeout configuration to delay region hibernation, improving rolling update performance in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.17.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\n-- Example of setting hibernate-timeout (actual syntax may vary)\nSET GLOBAL tikv_hibernate_timeout = 'value';\n```\n\n----------------------------------------\n\nTITLE: Displaying Current RECOMMEND INDEX Option Settings\nDESCRIPTION: This query retrieves the current settings for the RECOMMEND INDEX options, including maximum indices and timeout settings. It is useful for verifying configuration before running index recommendations.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nRECOMMEND INDEX SHOW OPTION;\n+-------------------+-------+---------------------------------------------------------+\n| option            | value | description                                             |\n+-------------------+-------+---------------------------------------------------------+\n| max_num_index     | 5     | The maximum number of indexes to recommend.             |\n| max_index_columns | 3     | The maximum number of columns in an index.              |\n| max_num_query     | 1000  | The maximum number of queries to recommend indexes.     |\n| timeout           | 30s   | The timeout of index advisor.                           |\n+-------------------+-------+---------------------------------------------------------+\n4 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Using Database Selection SQL Statement\nDESCRIPTION: SQL statement used to select a target database in endpoints other than predefined system endpoints. This statement is required to specify which database the subsequent queries will operate on.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-manage-endpoint.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nUSE database_name;\n```\n\n----------------------------------------\n\nTITLE: Checking TiDB Cluster for Potential Risks\nDESCRIPTION: This command checks the TiDB cluster for potential risks before scaling out. It identifies issues related to the cluster setup and configuration that may hinder the scaling process.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster check <cluster-name> scale-out.yml --cluster --user root [-p] [-i /home/root/.ssh/gcp_rsa]\"\n```\n\n----------------------------------------\n\nTITLE: Querying Table Storage Info - Bash/JSON\nDESCRIPTION: Examples of querying storage information for specific tables and databases in TiDB. Shows how to retrieve details like table rows, data length, and index information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-monitoring-api.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:10080/schema_storage/mysql/stats_histograms\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"table_schema\": \"mysql\",\n    \"table_name\": \"stats_histograms\",\n    \"table_rows\": 0,\n    \"avg_row_length\": 0,\n    \"data_length\": 0,\n    \"max_data_length\": 0,\n    \"index_length\": 0,\n    \"data_free\": 0\n}\n```\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:10080/schema_storage/test\n```\n\nLANGUAGE: json\nCODE:\n```\n[\n    {\n        \"table_schema\": \"test\",\n        \"table_name\": \"test\",\n        \"table_rows\": 0,\n        \"avg_row_length\": 0,\n        \"data_length\": 0,\n        \"max_data_length\": 0,\n        \"index_length\": 0,\n        \"data_free\": 0\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Running ANALYZE and Re-explaining Query\nDESCRIPTION: SQL commands to run ANALYZE on table 't1' and then re-explain the query, showing updated and accurate statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-analyze-table.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nANALYZE TABLE t1;\n```\n\nLANGUAGE: SQL\nCODE:\n```\nEXPLAIN SELECT * FROM t1 WHERE c1 = 3;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiCDC Syncpoint and Consistent Replication in TOML\nDESCRIPTION: This TOML configuration snippet enables the Syncpoint feature for TiCDC, sets up consistent replication, and configures redo log storage. It specifies intervals for syncing and retaining data, as well as settings for eventual consistency and redo log management.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_12\n\nLANGUAGE: toml\nCODE:\n```\nenable-sync-point = true\n\nsync-point-interval = \"10m\"\n\nsync-point-retention = \"1h\"\n\n[consistent]\nlevel = \"eventual\"\nmax-log-size = 64\nflush-interval = 2000\nstorage = \"s3://redo?access-key=minio&secret-access-key=miniostorage&endpoint=http://10.0.1.10:6060&force-path-style=true\"\n```\n\n----------------------------------------\n\nTITLE: Setting Broadcast Join Threshold in TiDB\nDESCRIPTION: Sets the broadcast join threshold size parameter to control when broadcast joins are used instead of hash joins. This configuration affects join strategy selection.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_broadcast_join_threshold_size = 10000000;\n```\n\n----------------------------------------\n\nTITLE: Creating Table and Data Population Example in TiDB\nDESCRIPTION: Example showing table creation with an index and population with random data through multiple INSERT statements using JOIN operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-binding.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n     id INT NOT NULL PRIMARY KEY auto_increment,\n     b INT NOT NULL,\n     pad VARBINARY(255),\n     INDEX(b)\n    );\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM dual;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\n```\n\n----------------------------------------\n\nTITLE: Enabling Titan with ZSTD Compression for RocksDB in TiKV\nDESCRIPTION: Configuration snippet for enabling Titan in RocksDB to reduce write amplification when large values are used. This sets the minimum blob size to 1KB and uses ZSTD compression for blob files.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices-on-public-cloud.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[rocksdb.titan]\nenabled = true\n[rocksdb.defaultcf.titan]\nmin-blob-size = \"1KB\"\nblob-file-compression = \"zstd\"\n```\n\n----------------------------------------\n\nTITLE: Upgrading TiDB Cluster to v8.5.0\nDESCRIPTION: Example command for upgrading a TiDB cluster named 'tidb-test' to version 8.5.0 using TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster upgrade tidb-test v8.5.0\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV with Dedicated Storage for Raft Engine on Google Cloud\nDESCRIPTION: TiKV configuration example for attaching an additional 512 GB pd-ssd disk on Google Cloud using TiDB Operator. This configuration directs Raft Engine logs to the dedicated storage volume for improved performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices-on-public-cloud.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ntikv:\n    config: |\n      [raft-engine]\n        dir = \"/var/lib/raft-pv-ssd/raft-engine\"\n        enable = true\n        enable-log-recycle = true\n    requests:\n      storage: 4Ti\n    storageClassName: pd-ssd\n    storageVolumes:\n    - mountPath: /var/lib/raft-pv-ssd\n      name: raft-pv-ssd\n      storageSize: 512Gi\n```\n\n----------------------------------------\n\nTITLE: Identifying Largest Tables in MySQL Database\nDESCRIPTION: This SQL query identifies the 5 largest tables across all schemas in a MySQL database, calculating their data, index, and total sizes. It's useful for prioritizing data migration efforts.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-hardware-and-software-requirements.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT \n  TABLE_NAME,\n  TABLE_SCHEMA,\n  FORMAT_BYTES(SUM(data_length)) AS 'Data Size',\n  FORMAT_BYTES(SUM(index_length)) AS 'Index Size',\n  FORMAT_BYTES(SUM(data_length+index_length)) AS 'Total Size'\nFROM\n  information_schema.tables\nGROUP BY\n  TABLE_NAME,\n  TABLE_SCHEMA\nORDER BY\n  SUM(DATA_LENGTH+INDEX_LENGTH) DESC\nLIMIT\n  5;\n```\n\n----------------------------------------\n\nTITLE: Explaining Query Execution Plan with Limited tidb_opt_range_max_size in TiDB\nDESCRIPTION: This SQL query explains the execution plan for a SELECT statement after setting tidb_opt_range_max_size to 1500 bytes. It shows how the optimizer builds more relaxed scan ranges due to the memory limitation.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_71\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t USE INDEX (idx) WHERE a IN (10,20,30) AND b IN (40,50,60);\n```\n\n----------------------------------------\n\nTITLE: Checking Query Warnings for Vector Index Usage Issues\nDESCRIPTION: These examples show how to check warnings that explain why a vector index is not being used. Warnings are shown for using an incorrect distance function or incorrect sort order.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-index.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n-- Using a wrong distance function:\nEXPLAIN SELECT * FROM vector_table_with_index\nORDER BY VEC_L2_DISTANCE(embedding, '[1, 2, 3]')\nLIMIT 10;\n\nSHOW WARNINGS;\n\n-- Using a wrong order:\nEXPLAIN SELECT * FROM vector_table_with_index\nORDER BY VEC_COSINE_DISTANCE(embedding, '[1, 2, 3]') DESC\nLIMIT 10;\n\nSHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: Starting Custom TiDB Cluster Configuration\nDESCRIPTION: Starts a TiDB cluster with specific version and component instance counts\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground v8.5.0 --db 2 --pd 3 --kv 3\n```\n\n----------------------------------------\n\nTITLE: Joining Temporary Table in SQL\nDESCRIPTION: SQL query demonstrating how to join a temporary table with another table and perform aggregations.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT ANY_VALUE(ta.id) AS author_id, ANY_VALUE(ta.age), ANY_VALUE(ta.name), COUNT(*) AS books\nFROM top_50_eldest_authors ta\nLEFT JOIN book_authors ba ON ta.id = ba.author_id\nGROUP BY ta.id;\n```\n\n----------------------------------------\n\nTITLE: Show Backups with LIKE Clause in TiDB\nDESCRIPTION: This SQL statement filters the output of SHOW BACKUPS to only include tasks with a destination URL matching the specified wildcard pattern. In this case, it displays backups where the destination URL starts with 's3://'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-backups.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW BACKUPS LIKE 's3://%';\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Labels for Smart Scheduling in YAML\nDESCRIPTION: YAML configuration for setting host-level labels on TiKV instances. This enables PD to perform smart scheduling and ensure high availability in hybrid deployments.\nSOURCE: https://github.com/pingcap/docs/blob/master/hybrid-deployment-topology.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nconfig:\n  server.labels:\n    host: tikv1\n```\n\n----------------------------------------\n\nTITLE: Setting Global TiDB System Variables in SQL\nDESCRIPTION: Example of using SQL to set a global system variable in TiDB Cloud. This allows dynamically changing and persisting certain system variables, which will be applied cluster-wide and remain effective after restarts.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/release-notes-2022.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_committer_concurrency = 127;\n```\n\n----------------------------------------\n\nTITLE: Starting Migration Task\nDESCRIPTION: Initiates the data migration task using tiup dmctl\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} start-task task.yaml\n```\n\n----------------------------------------\n\nTITLE: Loading Data Source Configuration using dmctl\nDESCRIPTION: This shell command uses `tiup dmctl` to load the data source configuration from `source1.yaml` into the DM cluster. It specifies the master address of the DM cluster and the `operate-source create` command to add the data source.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-shards-to-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup dmctl --master-addr ${advertise-addr} operate-source create source1.yaml\"\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for USE Statement in TiDB\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the USE statement in TiDB. It shows that the USE statement requires a database name as an identifier.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-use.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nUseStmt ::=\n    \"USE\" DBName\n\nDBName ::=\n    Identifier\n```\n\n----------------------------------------\n\nTITLE: Creating a user and binding to a resource group\nDESCRIPTION: This SQL statement creates a user `usr1` with the password `123` and binds the user to the resource group `rg1`. Any sessions created by this user will be automatically associated with the `rg1` resource group, and their resource consumption will be controlled by the quota defined for that group.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-ru-groups.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE USER 'usr1'@'%' IDENTIFIED BY '123' RESOURCE GROUP rg1;\"\n```\n\n----------------------------------------\n\nTITLE: Transaction Commit Execution Information\nDESCRIPTION: Detailed timing metrics for transaction commit phases, including prewrite, commit, and key write operations\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n\"commit_txn\": {\"prewrite\":\"48.564544ms\", \"wait_prewrite_binlog\":\"47.821579\", \"get_commit_ts\":\"4.277455ms\", \"commit\":\"50.431774ms\", \"region_num\":7, \"write_keys\":16, \"write_byte\":536}\n```\n\n----------------------------------------\n\nTITLE: Creating Database with Character Set and Collation\nDESCRIPTION: SQL syntax for creating or altering a database with specific character set and collation settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE db_name\n    [[DEFAULT] CHARACTER SET charset_name]\n    [[DEFAULT] COLLATE collation_name]\n\nALTER DATABASE db_name\n    [[DEFAULT] CHARACTER SET charset_name]\n    [[DEFAULT] COLLATE collation_name]\n```\n\n----------------------------------------\n\nTITLE: Mounting Data Disk with Required Options for TiKV\nDESCRIPTION: Commands to create a mount point directory, reload systemd configuration, and mount all filesystems defined in fstab. This applies the nodelalloc and noatime options required for optimal TiKV performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmkdir /data1 && \\\nsystemctl daemon-reload && \\\nmount -a\n```\n\n----------------------------------------\n\nTITLE: Configuring Statement Summary Maximum SQL Length\nDESCRIPTION: The Query column length is controlled by the tidb_stmt_summary_max_sql_length system variable, which allows configuring the maximum length of SQL statements stored in the statement summary.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-slow-query.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n| Query                                      | longtext        | YES  |      | NULL    |       |\n+--------------------------------------------+-----------------+------+------+---------+-------+\n89 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying TiCDC Replication Task List\nDESCRIPTION: Command to list all existing replication tasks and their status.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed list --server=http://10.0.10.25:8300\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Default Host and Empty Password in TiDB\nDESCRIPTION: Explicit form of creating a user that can connect from any host (%) with an empty password, equivalent to the shorter CREATE USER 'test' syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'test'@'%' IDENTIFIED BY '';\n```\n\n----------------------------------------\n\nTITLE: Finding Similar Slow Queries by SQL Fingerprint in SQL\nDESCRIPTION: Two SQL queries to first find a slow query and its fingerprint, then use that fingerprint to find similar slow queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nselect query_time, query, digest\nfrom information_schema.slow_query\nwhere is_internal = false\norder by query_time desc\nlimit 1;\n```\n\nLANGUAGE: sql\nCODE:\n```\nselect query, query_time\nfrom information_schema.slow_query\nwhere digest = \"4751cb6008fda383e22dacb601fde85425dc8f8cf669338d55d944bafb46a6fa\";\n```\n\n----------------------------------------\n\nTITLE: Creating Sample Tables for Optimizer Hint Examples in SQL\nDESCRIPTION: Creates two sample tables t1 and t2 for demonstrating optimizer hints. Table t2 includes an index on column b that will be used in subsequent examples.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t1(a int, b int);\ncreate table t2(a int, b int, index idx(b));\n```\n\n----------------------------------------\n\nTITLE: Checking NTP Service Status\nDESCRIPTION: Command to check the status of the NTP service daemon.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl status ntpd.service\n```\n\n----------------------------------------\n\nTITLE: Attempting to Use Invisible Index\nDESCRIPTION: Example showing that forced use of invisible index via USE INDEX hint results in error.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-index.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 USE INDEX(c1);\n```\n\n----------------------------------------\n\nTITLE: Checking Data Source Configuration in TiDB Data Migration\nDESCRIPTION: This snippet demonstrates how to retrieve the configuration of a specific data source using its source-id. It uses the config source command to display the configuration details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-manage-source.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nconfig source mysql-replica-01\n```\n\n----------------------------------------\n\nTITLE: Verifying Hotfix Application\nDESCRIPTION: Command to verify that the hotfix has been successfully applied by checking the version information of the DM component after patching.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-patch.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n/home/tidb/dm/deploy/dm-master-8261/bin/dm-master/dm-master -V\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Resource Group in TiDB SQL\nDESCRIPTION: SQL statements to create a new user 'newuser11' that uses the resource group 'rg1' and verify the resource group assignment in the mysql.user table in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser11'@'%' RESOURCE GROUP rg1;\nSELECT USER, HOST, USER_ATTRIBUTES FROM MYSQL.USER WHERE USER='newuser11';\n```\n\n----------------------------------------\n\nTITLE: Viewing Result from TIDB_PARSE_TSO_LOGICAL for Another TSO\nDESCRIPTION: Shows the output of TIDB_PARSE_TSO_LOGICAL for a TSO value that has the same physical timestamp but a different logical counter (2) than the previous example.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------------------------+\n| TIDB_PARSE_TSO_LOGICAL(450456244814610434) |\n+--------------------------------------------+\n|                                          2 |\n+--------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating Session Binding with Query Plan Analysis\nDESCRIPTION: Example demonstrating how to create a session binding that forces the query optimizer to ignore an index, including EXPLAIN ANALYZE output before and after binding creation.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-binding.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT * FROM t1 WHERE b = 123;\nCREATE SESSION BINDING FOR\n         SELECT * FROM t1 WHERE b = 123\n        USING\n         SELECT * FROM t1 IGNORE INDEX (b) WHERE b = 123;\nEXPLAIN ANALYZE SELECT * FROM t1 WHERE b = 123;\n```\n\n----------------------------------------\n\nTITLE: Querying Data from a Cached Table in SQL\nDESCRIPTION: SQL statement to select all records from the cached 'users' table.\nSOURCE: https://github.com/pingcap/docs/blob/master/cached-tables.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM users;\n```\n\n----------------------------------------\n\nTITLE: Checking Unsafe Recovery Progress\nDESCRIPTION: Command to check the progress of store removal and recovery using PD Control\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl -u <pd_addr> unsafe remove-failed-stores show\n```\n\n----------------------------------------\n\nTITLE: Check TiFlash Replication Progress in TiDB\nDESCRIPTION: This SQL query checks the replication progress of a specific table to TiFlash using the `information_schema.tiflash_replica` table. It requires specifying the database and table names to retrieve the replication status.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-htap-cluster.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = '<db_name>' and TABLE_NAME = '<table_name>';\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed for Storage Replication\nDESCRIPTION: Command to create a changefeed task for replicating data to a storage service, specifically Amazon S3 in this example. Configures server address, sink URI, and changefeed ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create \\\n    --server=http://10.0.10.25:8300 \\\n    --sink-uri=\"s3://logbucket/storage_test?protocol=canal-json\" \\\n    --changefeed-id=\"simple-replication-task\"\n```\n\n----------------------------------------\n\nTITLE: Schema File Definition for Table DDL Event - Shell\nDESCRIPTION: This shell snippet shows the format for generating a schema file when a DDL event changes the table version. It ensures the table schema is recorded accurately.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n{scheme}://{prefix}/{schema}/{table}/meta/schema_{table-version}_{hash}.json\n```\n\n----------------------------------------\n\nTITLE: Creating a Normal Table in SQL\nDESCRIPTION: SQL statement to create a normal table named 'users' with 'id' and 'name' columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/cached-tables.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE users (\n    id BIGINT,\n    name VARCHAR(100),\n    PRIMARY KEY(id)\n);\n```\n\n----------------------------------------\n\nTITLE: JSON_LENGTH Nested Path Query\nDESCRIPTION: Demonstrates using JSON_LENGTH() with a path argument to count items at a specific nested location.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-return.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_LENGTH('{\"weather\": {\"current\": \"sunny\", \"tomorrow\": \"cloudy\"}}','$.weather');\n```\n\n----------------------------------------\n\nTITLE: Configuring TiFlash Topology for Disaggregated Architecture in YAML\nDESCRIPTION: This YAML configuration defines the topology for TiFlash servers in a disaggregated storage and compute architecture. It specifies Write Nodes and Compute Nodes with their respective configurations, including S3 storage settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-disaggregated-and-s3.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ntiflash_servers:\n  - host: 172.31.8.1\n    config:\n      flash.disaggregated_mode: tiflash_write\n      storage.s3.endpoint: http://s3.{region}.amazonaws.com\n      storage.s3.bucket: mybucket\n      storage.s3.root: /cluster1_data\n      storage.s3.access_key_id: {ACCESS_KEY_ID}\n      storage.s3.secret_access_key: {SECRET_ACCESS_KEY}\n      storage.main.dir: [\"/data1/tiflash/data\"]\n  - host: 172.31.8.2\n    config:\n      flash.disaggregated_mode: tiflash_write\n      storage.s3.endpoint: http://s3.{region}.amazonaws.com\n      storage.s3.bucket: mybucket\n      storage.s3.root: /cluster1_data\n      storage.s3.access_key_id: {ACCESS_KEY_ID}\n      storage.s3.secret_access_key: {SECRET_ACCESS_KEY}\n      storage.main.dir: [\"/data1/tiflash/data\"]\n  - host: 172.31.9.1\n    config:\n      flash.disaggregated_mode: tiflash_compute\n      storage.s3.endpoint: http://s3.{region}.amazonaws.com\n      storage.s3.bucket: mybucket\n      storage.s3.root: /cluster1_data\n      storage.s3.access_key_id: {ACCESS_KEY_ID}\n      storage.s3.secret_access_key: {SECRET_ACCESS_KEY}\n      storage.main.dir: [\"/data1/tiflash/data\"]\n      storage.remote.cache.dir: /data1/tiflash/cache\n      storage.remote.cache.capacity: 858993459200\n  - host: 172.31.9.2\n    config:\n      flash.disaggregated_mode: tiflash_compute\n      storage.s3.endpoint: http://s3.{region}.amazonaws.com\n      storage.s3.bucket: mybucket\n      storage.s3.root: /cluster1_data\n      storage.s3.access_key_id: {ACCESS_KEY_ID}\n      storage.s3.secret_access_key: {SECRET_ACCESS_KEY}\n      storage.main.dir: [\"/data1/tiflash/data\"]\n      storage.remote.cache.dir: /data1/tiflash/cache\n      storage.remote.cache.capacity: 858993459200\n```\n\n----------------------------------------\n\nTITLE: Modifying User Password in TiDB\nDESCRIPTION: Example of changing the password for the user 'newuser' using the ALTER USER statement. This demonstrates how to update user authentication in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'newuser' IDENTIFIED BY 'newnewpassword';\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql> SHOW CREATE USER 'newuser';\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| CREATE USER for newuser@%                                                                                                                                            |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| CREATE USER 'newuser'@'%' IDENTIFIED WITH 'mysql_native_password' AS '*FB8A1EA1353E8775CA836233E367FBDFCB37BE73' REQUIRE NONE PASSWORD EXPIRE DEFAULT ACCOUNT UNLOCK |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying Conflict Error Table using SQL\nDESCRIPTION: Connects to the MySQL server using the command-line client and executes a `SELECT` statement to retrieve all rows from the `lightning_task_info.conflict_error_v3` table. This table contains information about unique/primary key conflicts encountered during the import process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\n\"$ mysql -u root -h 127.0.0.1 -P 4000 -e 'select * from lightning_task_info.conflict_error_v3;' --binary-as-hex -E\\n\\n*************************** 1. row ***************************\\n       task_id: 1635888701843303564\\n   create_time: 2021-11-02 21:31:42.669601\\n    table_name: `example`.`t`\\n    index_name: PRIMARY\\n      key_data: 40\\n      row_data: (40, \\\"forty\\\")\\n       raw_key: 0x7480000000000000C15F728000000000000028\\n     raw_value: 0x800001000000020500666F727479\\n    raw_handle: 0x7480000000000000C15F728000000000000028\\n       raw_row: 0x800001000000020500666F727479\\n\\n*************************** 2. row ***************************\\n       task_id: 1635888701843303564\\n   create_time: 2021-11-02 21:31:42.674798\\n    table_name: `example`.`t`\\n    index_name: PRIMARY\\n      key_data: 40\\n      row_data: (40, \\\"forty\\\")\\n       raw_key: 0x7480000000000000C15F728000000000000028\\n     raw_value: 0x800001000000020600666F75727479\\n    raw_handle: 0x7480000000000000C15F728000000000000028\\n       raw_row: 0x800001000000020600666F75727479\\n\\n*************************** 3. row ***************************\\n       task_id: 1635888701843303564\\n   create_time: 2021-11-02 21:31:42.680332\\n    table_name: `example`.`t`\\n    index_name: b\\n      key_data: 54\\n      row_data: (54, \\\"fifty-four\\\")\\n       raw_key: 0x7480000000000000C15F6980000000000000010166696674792D666FFF7572000000000000F9\\n     raw_value: 0x0000000000000036\\n    raw_handle: 0x7480000000000000C15F728000000000000036\\n       raw_row: 0x800001000000020A0066696674792D666F7572\\n\\n*************************** 4. row ***************************\\n       task_id: 1635888701843303564\\n   create_time: 2021-11-02 21:31:42.681073\\n    table_name: `example`.`t`\\n    index_name: b\\n      key_data: 42\\n      row_data: (42, \\\"fifty-four\\\")\\n       raw_key: 0x7480000000000000C15F6980000000000000010166696674792D666FFF7572000000000000F9\\n     raw_value: 0x000000000000002A\\n    raw_handle: 0x7480000000000000C15F72800000000000002A\\n       raw_row: 0x800001000000020A0066696674792D666F7572\"\n```\n\n----------------------------------------\n\nTITLE: Compacting Specific Partitions in TiFlash\nDESCRIPTION: SQL statement to compact specific partitions (pNorth and pEast) of a table's TiFlash replica. This allows for targeted optimization of particular partitions rather than the entire table.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE employees COMPACT PARTITION pNorth, pEast TIFLASH REPLICA;\n```\n\n----------------------------------------\n\nTITLE: Executing ticloud serverless export create Command\nDESCRIPTION: This command is used to export data from a TiDB Cloud Serverless cluster. It can be run in interactive or non-interactive mode, with various options for specifying the export destination and format.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-create.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export create [flags]\n```\n\n----------------------------------------\n\nTITLE: Creating Extended Statistics Object for Column Correlation\nDESCRIPTION: SQL statement to create an extended statistics object that captures correlation between columns. This defines which columns should be analyzed together during statistics collection.\nSOURCE: https://github.com/pingcap/docs/blob/master/extended-statistics.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name ADD STATS_EXTENDED IF NOT EXISTS stats_name stats_type(column_name, column_name...);\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic User in TiDB SQL\nDESCRIPTION: SQL statement to create a new user 'newuser' with a password 'newuserpassword' in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser' IDENTIFIED BY 'newuserpassword';\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Password History Constraint in TiDB SQL\nDESCRIPTION: SQL statement to create a new user 'newuser8' who is not allowed to reuse the last 5 passwords in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser8'@'%' PASSWORD HISTORY 5;\n```\n\n----------------------------------------\n\nTITLE: Configuring Bulk DML for Large Transactions in TiDB\nDESCRIPTION: This code shows how to enable the Bulk DML feature using the tidb_dml_type system variable, which helps handle large batch DML tasks more efficiently while providing transaction guarantees and mitigating OOM issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ntidb_dml_type = \"bulk\"\n```\n\n----------------------------------------\n\nTITLE: Defining TiCDC Configuration Parameters\nDESCRIPTION: This JSON snippet defines the structure and available options for configuring a TiCDC replication task. It includes parameters for identifying the changefeed, configuring replication behavior, specifying the sink URI, and setting start and target timestamps.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"changefeed_id\": \"string\",\n  \"replica_config\": {\n    \"bdr_mode\": true,\n    \"case_sensitive\": false,\n    \"check_gc_safe_point\": true,\n    \"consistent\": {\n      \"flush_interval\": 0,\n      \"level\": \"string\",\n      \"max_log_size\": 0,\n      \"storage\": \"string\"\n    },\n    \"enable_old_value\": true,\n    \"enable_sync_point\": true,\n    \"filter\": {\n      \"event_filters\": [\n        {\n          \"ignore_delete_value_expr\": \"string\",\n          \"ignore_event\": [\n            \"string\"\n          ],\n          \"ignore_insert_value_expr\": \"string\",\n          \"ignore_sql\": [\n            \"string\"\n          ],\n          \"ignore_update_new_value_expr\": \"string\",\n          \"ignore_update_old_value_expr\": \"string\",\n          \"matcher\": [\n            \"string\"\n          ]\n        }\n      ],\n      \"ignore_txn_start_ts\": [\n        0\n      ],\n      \"rules\": [\n        \"string\"\n      ]\n    },\n    \"force_replicate\": true,\n    \"ignore_ineligible_table\": true,\n    \"memory_quota\": 0,\n    \"mounter\": {\n      \"worker_num\": 0\n    },\n    \"sink\": {\n      \"column_selectors\": [\n        {\n          \"columns\": [\n            \"string\"\n          ],\n          \"matcher\": [\n            \"string\"\n          ]\n        }\n      ],\n      \"csv\": {\n        \"delimiter\": \"string\",\n        \"include_commit_ts\": true,\n        \"null\": \"string\",\n        \"quote\": \"string\"\n      },\n      \"date_separator\": \"string\",\n      \"dispatchers\": [\n        {\n          \"matcher\": [\n            \"string\"\n          ],\n          \"partition\": \"string\",\n          \"topic\": \"string\"\n        }\n      ],\n      \"enable_partition_separator\": true,\n      \"encoder_concurrency\": 0,\n      \"protocol\": \"string\",\n      \"schema_registry\": \"string\",\n      \"terminator\": \"string\",\n      \"transaction_atomicity\": \"string\"\n    },\n    \"sync_point_interval\": \"string\",\n    \"sync_point_retention\": \"string\"\n  },\n  \"sink_uri\": \"string\",\n  \"start_ts\": 0,\n  \"target_ts\": 0\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a List Partitioned Table with Default Partition in SQL\nDESCRIPTION: Example of creating an employees table with List partitioning including a default partition. The default partition handles any store_id values that don't match the specific regions defined in the other partitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    store_id INT\n)\nPARTITION BY LIST (store_id) (\n    PARTITION pNorth VALUES IN (1, 2, 3, 4, 5),\n    PARTITION pEast VALUES IN (6, 7, 8, 9, 10),\n    PARTITION pWest VALUES IN (11, 12, 13, 14, 15),\n    PARTITION pCentral VALUES IN (16, 17, 18, 19, 20),\n    PARTITION pDefault DEFAULT\n);\n```\n\n----------------------------------------\n\nTITLE: Viewing Existing Placement Policy SQL\nDESCRIPTION: The SQL statement displays details of an existing placement policy, helping verify policy configurations in TiKV clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE PLACEMENT POLICY myplacementpolicy\\G\n*************************** 1. row ***************************\n       Policy: myplacementpolicy\nCreate Policy: CREATE PLACEMENT POLICY myplacementpolicy PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\"\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Terraform Provider for TiDB Cloud Backup\nDESCRIPTION: Basic Terraform configuration that sets up the TiDB Cloud provider and defines a backup resource with project ID, cluster ID, name, and description.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-backup-resource.md#2025-04-18_snippet_0\n\nLANGUAGE: hcl\nCODE:\n```\nterraform {\n required_providers {\n   tidbcloud = {\n     source = \"tidbcloud/tidbcloud\"\n   }\n }\n}\n\nprovider \"tidbcloud\" {\n public_key = \"your_public_key\"\n private_key = \"your_private_key\"\n}\nresource \"tidbcloud_backup\" \"example_backup\" {\n  project_id  = \"1372813089189561287\"\n  cluster_id  = \"1379661944630234067\"\n  name        = \"firstBackup\"\n  description = \"create by terraform\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Hosts for Kafka\nDESCRIPTION: This example demonstrates how to configure the sink URI when the downstream Kafka consists of multiple hosts or ports. It uses a comma-separated list to specify multiple host and port combinations within the URI, ensuring flexibility and redundancy in the connection configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n[scheme]://[host]:[port],[host]:[port],[host]:[port][/path]?[query_parameters]\n```\n\n----------------------------------------\n\nTITLE: Data Type Conversion Fix - FLOAT to DOUBLE\nDESCRIPTION: Fix for incorrect query results when changing column type from FLOAT to DOUBLE\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.1.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE table_name MODIFY COLUMN column_name DOUBLE\n```\n\n----------------------------------------\n\nTITLE: Creating a Sequence with Default Parameters\nDESCRIPTION: Example of creating a simple sequence object named 'seq' using default parameters in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-sequence.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SEQUENCE seq;\n```\n\n----------------------------------------\n\nTITLE: Modifying TiDB slow-threshold Variable\nDESCRIPTION: This SQL statement modifies the `tidb_slow_log_threshold` system variable, which controls the slow query log threshold in TiDB. The example sets the threshold to 200 milliseconds. It demonstrates the use of system variables to dynamically adjust TiDB configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nset tidb_slow_log_threshold = 200;\n```\n\n----------------------------------------\n\nTITLE: Query Execution Plan After Distinct Optimization\nDESCRIPTION: Demonstrates the improved execution plan after enabling distinct optimization, showing how distinct operations are pushed down to TiFlash for better performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain analyze select count(distinct a) from test.t;\n```\n\n----------------------------------------\n\nTITLE: Limiting DDL Reorganization Write Speed\nDESCRIPTION: Configures the tidb_ddl_reorg_max_write_speed variable to limit the write bandwidth for each TiKV node during index creation. This helps reduce the impact on application workloads when creating indexes on large datasets.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_26\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_ddl_reorg_max_write_speed = '256MiB';\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Encryption Method\nDESCRIPTION: Specifies the encryption method for data files with various options including AES and plaintext, crucial for secure data handling.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_10\n\nLANGUAGE: TOML\nCODE:\n```\n\"security.encryption.data-encryption-method = \\\"aes256-ctr\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Aggregating Key-Value Pairs into a JSON Object in SQL - TiDB\nDESCRIPTION: This snippet illustrates the use of the JSON_OBJECTAGG function to aggregate key-value pairs from related tables into a JSON object. It shows how to create two tables, populate them with data, and retrieve aggregated JSON objects based on grouping, which is particularly useful for reconstructing structured data from relational formats.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-aggregate.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE plants (\n    id INT PRIMARY KEY,\n    name VARCHAR(255)\n);\n\nCREATE TABLE plant_attributes (\n    id INT PRIMARY KEY AUTO_INCREMENT,\n    plant_id INT, attribute VARCHAR(255),\n    value VARCHAR(255),\n    FOREIGN KEY (plant_id) REFERENCES plants(id)\n);\n\nINSERT INTO plants\nVALUES\n(1,\"rose\"),\n(2,\"tulip\"),\n(3,\"orchid\");\n\nINSERT INTO plant_attributes(plant_id,attribute,value)\nVALUES\n(1,\"color\",\"red\"),\n(1,\"thorns\",\"yes\"),\n(2,\"color\",\"orange\"),\n(2,\"thorns\",\"no\"),\n(2,\"grows_from\",\"bulb\"),\n(3,\"color\",\"white\"),\n(3, \"thorns\",\"no\");\n\nSELECT\n    p.name,\n    JSON_OBJECTAGG(attribute,value)\nFROM\n    plant_attributes pa\n    LEFT JOIN plants p ON pa.plant_id=p.id\nGROUP BY\n    plant_id;\n```\n\n----------------------------------------\n\nTITLE: Restoring Full Cluster Snapshot from Local Storage\nDESCRIPTION: Command to restore a full TiDB cluster snapshot from local storage. This command automatically restores table statistics if they were included in the backup.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full \\\n--storage local:///br_data/ --pd \"${PD_IP}:2379\" --log-file restore.log\n```\n\n----------------------------------------\n\nTITLE: Collecting Table Statistics\nDESCRIPTION: SQL commands to collect statistics for all tables to optimize query execution plans. Includes setting analysis options and analyzing individual tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-ch.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nset global tidb_analyze_column_options='ALL';\nanalyze table customer;\nanalyze table district;\nanalyze table history;\nanalyze table item;\nanalyze table new_order;\nanalyze table order_line;\nanalyze table orders;\nanalyze table stock;\nanalyze table warehouse;\nanalyze table nation;\nanalyze table region;\nanalyze table supplier;\n```\n\n----------------------------------------\n\nTITLE: Querying Slow Logs in Abnormal Time Periods in SQL\nDESCRIPTION: Complex SQL query to find slow logs that occur only during an abnormal time period, excluding those that also occur during a normal time period.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM\n    (SELECT /*+ AGG_TO_COP(), HASH_AGG() */ count(*),\n         min(time),\n         sum(query_time) AS sum_query_time,\n         sum(Process_time) AS sum_process_time,\n         sum(Wait_time) AS sum_wait_time,\n         sum(Commit_time),\n         sum(Request_count),\n         sum(process_keys),\n         sum(Write_keys),\n         max(Cop_proc_max),\n         min(query),min(prev_stmt),\n         digest\n    FROM information_schema.CLUSTER_SLOW_QUERY\n    WHERE time >= '2020-03-10 13:24:00'\n            AND time < '2020-03-10 13:27:00'\n            AND Is_internal = false\n    GROUP BY  digest) AS t1\nWHERE t1.digest NOT IN\n    (SELECT /*+ AGG_TO_COP(), HASH_AGG() */ digest\n    FROM information_schema.CLUSTER_SLOW_QUERY\n    WHERE time >= '2020-03-10 13:20:00'\n            AND time < '2020-03-10 13:23:00'\n    GROUP BY  digest)\nORDER BY  t1.sum_query_time DESC limit 10\\G\n```\n\n----------------------------------------\n\nTITLE: Defining PD Cluster Down Store Alert Rule in Prometheus\nDESCRIPTION: Alert rule to detect when PD has not received a TiKV/TiFlash heartbeat for a long time. Triggers when any store is down.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_6\n\nLANGUAGE: prometheus\nCODE:\n```\n(sum(pd_cluster_status{type=\"store_down_count\"}) by (instance) > 0) and (sum(etcd_server_is_leader) by (instance) > 0)\n```\n\n----------------------------------------\n\nTITLE: Viewing available commands in TiDB Cloud CLI\nDESCRIPTION: This snippet shows the command to view all available commands and options in the TiDB Cloud CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nticloud --help\n```\n\n----------------------------------------\n\nTITLE: Accessing TiDB Cloud CLI with OAuth 2.0 Device Code Grant Type\nDESCRIPTION: This snippet demonstrates the commands for authenticating with TiDB Cloud and logging out using the OAuth 2.0 Device Code grant type in the TiDB Cloud CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/oauth2.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- [ticloud auth login](/tidb-cloud/ticloud-auth-login.md): Authenticate with TiDB Cloud\n- [ticloud auth logout](/tidb-cloud/ticloud-auth-logout.md): Log out of TiDB Cloud\n```\n\n----------------------------------------\n\nTITLE: Creating a User with X.509 Certificate Requirement in TiDB SQL\nDESCRIPTION: SQL statement to create a new user 'newuser4' that is required to use an X.509 certificate for login in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser4'@'%' IDENTIFIED BY 'newuserpassword' REQUIRE ISSUER '/C=US/ST=California/L=San Francisco/O=PingCAP';\n```\n\n----------------------------------------\n\nTITLE: Viewing All Instance Configurations in TiDB Cluster\nDESCRIPTION: This SQL query displays the configuration of all instances in the TiDB cluster, including the type, instance address, configuration name, and value.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nshow config;\n```\n\n----------------------------------------\n\nTITLE: Set Operations with ORDER BY and LIMIT\nDESCRIPTION: Demonstrates using ORDER BY and LIMIT clauses with set operations to sort and limit the final result set.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/set-operators.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n(SELECT * FROM t1 UNION ALL SELECT * FROM t1 INTERSECT SELECT * FROM t2) ORDER BY a LIMIT 2;\n```\n\n----------------------------------------\n\nTITLE: Starting a Pessimistic Transaction with Compatibility Comment - SQL\nDESCRIPTION: This snippet shows how to start a pessimistic transaction using a SQL command that includes a special comment. This is useful in scenarios where command compatibility with certain SQL client tools is required.\nSOURCE: https://github.com/pingcap/docs/blob/master/pessimistic-transaction.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN /*T! PESSIMISTIC */;\n```\n\n----------------------------------------\n\nTITLE: Invalid Composite Multi-Valued Index Creation\nDESCRIPTION: This snippet demonstrates an attempt to create a composite index with multiple multi-valued parts, which is not supported. This results in an error. The error message indicates the limitation of only one multi-valued key part per index.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE customers (\n    id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    name CHAR(10),\n    custinfo JSON,\n    INDEX zips(name, (CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)), (CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)))\n);\nERROR 1235 (42000): This version of TiDB doesn't yet support 'more than one multi-valued key part per index'.\n\n```\n\n----------------------------------------\n\nTITLE: Creating schema_unused_indexes View in SQL\nDESCRIPTION: SQL commands to manually create the schema_unused_indexes view for clusters upgraded from versions before v8.0.0. Creates the sys database if needed and defines the view to track unused indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sys-schema/sys-schema-unused-indexes.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE IF NOT EXISTS sys;\nCREATE OR REPLACE VIEW sys.schema_unused_indexes AS\n  SELECT\n    table_schema as object_schema,\n    table_name as object_name,\n    index_name\n  FROM information_schema.cluster_tidb_index_usage\n  WHERE\n    table_schema not in ('sys', 'mysql', 'INFORMATION_SCHEMA', 'PERFORMANCE_SCHEMA') and\n    index_name != 'PRIMARY'\n  GROUP BY table_schema, table_name, index_name\n  HAVING\n    sum(last_access_time) is null;\n```\n\n----------------------------------------\n\nTITLE: Querying Data Source Configuration\nDESCRIPTION: Command to retrieve configuration details for a specific data source using its source-id.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-source.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup dmctl --master-addr <master-addr> config source mysql-01\n```\n\n----------------------------------------\n\nTITLE: Clear Error Rows Command in DM\nDESCRIPTION: Command syntax for clearing error rows from validation status. Allows clearing specific error IDs or all errors using the --all flag.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-continuous-data-validation.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nUsage:\n  dmctl validation clear-error <task-name> <error-id|--all> [flags]\n\nFlags:\n      --all    all errors\n      -h, --help   help for clear-error\n```\n\n----------------------------------------\n\nTITLE: Setting min-hot-byte-rate for balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command sets the minimum number of bytes to be counted as a hot region. The default value is usually 100.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_33\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-hot-region-scheduler set min-hot-byte-rate 100\n```\n\n----------------------------------------\n\nTITLE: Setting Password Reuse Policy in TiDB\nDESCRIPTION: Example of setting a password reuse policy for 'newuser' to disallow reuse of any password used within the last 90 days. This demonstrates how to enhance password security in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'newuser' PASSWORD REUSE INTERVAL 90 DAY;\nQuery OK, 0 rows affected (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Executing Sysbench Tests on TiDB Cloud in Bash\nDESCRIPTION: A command in bash for executing Sysbench benchmark tests on various workloads in a TiDB Cloud Dedicated cluster. Includes customizable parameters like host, port, and password. Tests various workloads with different thread counts.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v6.5-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsysbench ${WORKLOAD} run \\\n   --mysql-host=${HOST} \\\n   --mysql-port=${PORT} \\\n   --mysql-user=root \\\n   --db-driver=mysql \\\n   --mysql-db=sbtest \\\n   --threads=${THREAD} \\\n   --time=1200 \\\n   --report-interval=10 \\\n   --tables=32 \\\n   --table-size=10000000 \\\n   --mysql-ignore-errors=1062,2013,8028,9007 \\\n   --auto-inc=false \\\n   --mysql-password=${PASSWORD}\n```\n\n----------------------------------------\n\nTITLE: Querying MySQL GTID Sets\nDESCRIPTION: SQL commands for retrieving GTID sets from MySQL instances to verify compatibility before switching connections. These commands retrieve purged and executed transaction IDs.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/usage-scenario-master-slave-switch.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@GLOBAL.gtid_purged;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@GLOBAL.gtid_executed;\n```\n\n----------------------------------------\n\nTITLE: Configuring RocksDB Parameters for Write Stall Prevention\nDESCRIPTION: This YAML configuration snippet shows recommended settings for RocksDB parameters to prevent write stalls caused by level0 file limits. It increases the trigger thresholds for slowdown and stop writes across different column families.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-tikv-thread-performance.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nrocksdb.defaultcf.level0-slowdown-writes-trigger: 64\nrocksdb.writecf.level0-slowdown-writes-trigger: 64\nrocksdb.lockcf.level0-slowdown-writes-trigger: 64\nrocksdb.defaultcf.level0-stop-writes-trigger: 64\nrocksdb.writecf.level0-stop-writes-trigger: 64\nrocksdb.lockcf.level0-stop-writes-trigger: 64\n```\n\n----------------------------------------\n\nTITLE: Amazon S3 Data Import Command with TiDB Lightning\nDESCRIPTION: Command-line example for importing data from Amazon S3 using TiDB Lightning with specified backend, port, and external storage configuration\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-distributed-import.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup tidb-lightning --tidb-port=4000 --pd-urls=127.0.0.1:2379 --backend=local --sorted-kv-dir=/tmp/sorted-kvs \\\n    -d 's3://my-bucket/sql-backup'\n```\n\n----------------------------------------\n\nTITLE: Scale-Out Configuration for TiFlash Servers\nDESCRIPTION: This configuration adds the TiFlash node information to the `scale-out.yml` file. Currently, only IP addresses are supported and not domain names.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_12\n\nLANGUAGE: ini\nCODE:\n```\n\"tiflash_servers:\\n- host: 10.0.1.4\"\n```\n\n----------------------------------------\n\nTITLE: Modifying User Resource Group in TiDB\nDESCRIPTION: Example of changing the resource group for 'newuser' to 'rg1' and then verifying the change. This demonstrates how to manage resource allocation for users in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'newuser' RESOURCE GROUP rg1;\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql> SELECT USER, JSON_EXTRACT(User_attributes, \"$.resource_group\") FROM mysql.user WHERE user = \"newuser\";\n+---------+---------------------------------------------------+\n| USER    | JSON_EXTRACT(User_attributes, \"$.resource_group\") |\n+---------+---------------------------------------------------+\n| newuser | \"rg1\"                                             |\n+---------+---------------------------------------------------+\n1 row in set (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying with json_overlaps and json_contains in TiDB SQL\nDESCRIPTION: Shows how TiDB handles queries with json_overlaps and json_contains functions using index merge optimization for single-value conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1, mvi2) */ * FROM t4 WHERE json_overlaps(j->'$.a', '[1]') AND json_overlaps(j->'$.b', '[2]');\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1, mvi2) */ * FROM t4 WHERE json_contains(j->'$.a', '[1]') OR json_contains(j->'$.b', '[2]');\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings with Jina AI API\nDESCRIPTION: Helper function to generate embeddings from text using Jina AI embeddings API.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-jinaai-embedding.md#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport requests\nimport dotenv\n\ndotenv.load_dotenv()\n\nJINAAI_API_KEY = os.getenv('JINAAI_API_KEY')\n\ndef generate_embeddings(text: str):\n    JINAAI_API_URL = 'https://api.jina.ai/v1/embeddings'\n    JINAAI_HEADERS = {\n        'Content-Type': 'application/json',\n        'Authorization': f'Bearer {JINAAI_API_KEY}'\n    }\n    JINAAI_REQUEST_DATA = {\n        'input': [text],\n        'model': 'jina-embeddings-v2-base-en'  # with dimension 768.\n    }\n    response = requests.post(JINAAI_API_URL, headers=JINAAI_HEADERS, json=JINAAI_REQUEST_DATA)\n    return response.json()['data'][0]['embedding']\n```\n\n----------------------------------------\n\nTITLE: Pushing TopN into Join with Outer Table Columns\nDESCRIPTION: SQL example showing how TopN can be pushed down into a Join operation when the sorting rule only depends on columns in the outer table, reducing the calculation cost of the Join operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/topn-limit-push-down.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id int primary key, a int not null);\ncreate table s(id int primary key, a int not null);\nexplain select * from t left join s on t.a = s.a order by t.a limit 10;\n```\n\n----------------------------------------\n\nTITLE: Increasing Partition Count in SQL\nDESCRIPTION: This SQL snippet shows how to increase the number of partitions for a Hash partitioned table by one.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_41\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE example ADD PARTITION PARTITIONS 1;\n```\n\n----------------------------------------\n\nTITLE: Deploying Primary and Secondary Clusters with TiCDC - YAML\nDESCRIPTION: This YAML configuration template is used for deploying TiDB primary and secondary clusters along with TiCDC, specifying various server options and deployment parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nglobal:\n  user: \"tidb\"\n  ssh_port: 22\n  deploy_dir: \"/tidb-deploy\"\n  data_dir: \"/tidb-data\"\n  server_configs: {}\n  pd_servers:\n    - host: 10.0.1.1\n    - host: 10.0.1.2\n    - host: 10.0.1.3\n  tidb_servers:\n    - host: 10.0.1.4\n    - host: 10.0.1.5\n  tikv_servers:\n    - host: 10.0.1.6\n    - host: 10.0.1.7\n    - host: 10.0.1.8\n  monitoring_servers:\n    - host: 10.0.1.9\n  grafana_servers:\n    - host: 10.0.1.9\n  alertmanager_servers:\n    - host: 10.0.1.9\n  cdc_servers:\n    - host: 10.1.1.9\n      gc-ttl: 86400\n      data_dir: \"/cdc-data\"\n      ticdc_cluster_id: \"DR_TiCDC\"\n    - host: 10.1.1.10\n      gc-ttl: 86400\n      data_dir: \"/cdc-data\"\n      ticdc_cluster_id: \"DR_TiCDC\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning Physical Import Mode\nDESCRIPTION: Parameter configuration for TiDB Lightning to separate data import and index import processes. This improves import speed and stability by adding indexes via SQL statements after importing row data.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.0.0.md#2025-04-18_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nadd-index-by-sql: true\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_mem_quota_analyze for Statistics Update\nDESCRIPTION: Controls the maximum memory usage for TiDB when updating statistics, affecting both manual ANALYZE TABLE commands and background automatic analysis tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_52\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_mem_quota_analyze = <value>;\n```\n\n----------------------------------------\n\nTITLE: Index Naming Pattern Examples\nDESCRIPTION: Standard patterns for naming different types of indexes including primary key, unique, and common indexes\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-object-naming-guidelines.md#2025-04-18_snippet_2\n\nLANGUAGE: text\nCODE:\n```\npk_{table_name_abbreviation}_{field_name_abbreviation}\nuk_{table_name_abbreviation}_{field_name_abbreviation}\nidx_{table_name_abbreviation}_{field_name_abbreviation}\n```\n\n----------------------------------------\n\nTITLE: Performance Tuning BACKUP Operations in TiDB\nDESCRIPTION: Example of configuring performance-related options for backup operations, including rate limiting, concurrency control, and disabling checksum verification.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-backup.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP DATABASE `test` TO 's3://example-bucket-2020/backup-06/'\n    RATE_LIMIT = 120 MB/SECOND\n    CONCURRENCY = 8\n    CHECKSUM = FALSE;\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for S3 Access in Shell\nDESCRIPTION: These shell commands set environment variables for S3 access key and secret key. They should be added to the ~/.bash_profile of the user that starts the TiFlash process on all machines where TiFlash is deployed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-disaggregated-and-s3.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nexport S3_ACCESS_KEY_ID={ACCESS_KEY_ID}\nexport S3_SECRET_ACCESS_KEY={SECRET_ACCESS_KEY}\n```\n\n----------------------------------------\n\nTITLE: Listing Partitions with Attached Placement Policies SQL\nDESCRIPTION: This SQL query helps identify partitions attached with placement policies, essential for monitoring partition-level configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.partitions WHERE tidb_placement_policy_name IS NOT NULL;\n```\n\n----------------------------------------\n\nTITLE: Creating Merged Table Structure in SQL\nDESCRIPTION: SQL command to create the target merged table structure with columns for storing extracted source information from sharded tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-table-routing.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `test`.`t` (\n    a int PRIMARY KEY,\n    c_table varchar(10) DEFAULT NULL,\n    c_schema varchar(10) DEFAULT NULL,\n    c_source varchar(10) DEFAULT NULL\n);\n```\n\n----------------------------------------\n\nTITLE: Showing Processlist in SQL\nDESCRIPTION: This SQL snippet shows how to check the execution progress of a non-transactional DML statement using `SHOW PROCESSLIST`. The `Time` field in the returned result indicates the time consumption of the current batch execution. This allows monitoring the progress of each split statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n\"SHOW PROCESSLIST;\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"+------+------+--------------------+--------+---------+------+------------+----------------------------------------------------------------------------------------------------+\\n| Id   | User | Host               | db     | Command | Time | State      | Info                                                                                               |\\n+------+------+--------------------+--------+---------+------+------------+----------------------------------------------------------------------------------------------------+\\n| 1203 | root | 100.64.10.62:52711 | test   | Query   | 0    | autocommit | /* job 506/500000 */ DELETE FROM `test`.`t1` WHERE `test`.`t1`.`_tidb_rowid` BETWEEN 2271 AND 2273 |\\n| 1209 | root | 100.64.10.62:52735 | <null> | Query   | 0    | autocommit | show full processlist                                                                              |\\n+------+------+--------------------+--------+---------+------+------------+----------------------------------------------------------------------------------------------------+\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Roles in the Current Session in TiDB\nDESCRIPTION: This snippet demonstrates how to enable roles for the current session in TiDB using the `SET ROLE` statement. The enabled roles are valid only for the duration of the current session. The user must have been granted the role before it can be enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSET ROLE {\n    DEFAULT\n  | NONE\n  | ALL\n  | ALL EXCEPT role [, role ] ...\n  | role [, role ] ...\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for TiDB Cloud Dedicated\nDESCRIPTION: Environment variables configuration for connecting to a TiDB Cloud Dedicated cluster with TLS encryption and a custom CA certificate.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_5\n\nLANGUAGE: dotenv\nCODE:\n```\nDATABASE_HOST={host}\nDATABASE_PORT=4000\nDATABASE_USER={user}\nDATABASE_PASSWORD={password}\nDATABASE_NAME=test\nDATABASE_ENABLE_SSL=true\nDATABASE_SSL_CA={downloaded_ssl_ca_path}\n```\n\n----------------------------------------\n\nTITLE: Creating and Modifying a Resource Group in TiDB\nDESCRIPTION: SQL examples demonstrating how to create a resource group named 'rg1', check its properties, and then modify it using the ALTER RESOURCE GROUP statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-resource-group.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nDROP RESOURCE GROUP IF EXISTS rg1;\n\nCREATE RESOURCE GROUP IF NOT EXISTS rg1\n  RU_PER_SEC = 100\n  BURSTABLE;\n\nSELECT * FROM information_schema.resource_groups WHERE NAME ='rg1';\n\nALTER RESOURCE GROUP rg1\n  RU_PER_SEC = 200\n  PRIORITY = LOW\n  QUERY_LIMIT = (EXEC_ELAPSED='1s' ACTION=COOLDOWN WATCH=EXACT DURATION '30s');\n\nSELECT * FROM information_schema.resource_groups WHERE NAME ='rg1';\n```\n\n----------------------------------------\n\nTITLE: Setting Password Expiration Policy in TiDB\nDESCRIPTION: Example of setting the password expiration policy for 'newuser' to never expire. This demonstrates how to manage password lifecycle policies in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'newuser' PASSWORD EXPIRE NEVER;\nQuery OK, 0 rows affected (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Auto-Repairing Deployment Configuration Issues\nDESCRIPTION: Automatically fixes potential issues identified in the topology configuration using the --apply flag. This helps ensure a smoother deployment process by addressing common issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster check ./topology.yaml --apply --user root [-p] [-i /home/root/.ssh/gcp_rsa]\n```\n\n----------------------------------------\n\nTITLE: Modifying PD Configuration with SQL\nDESCRIPTION: This SQL statement demonstrates how to dynamically modify a PD configuration item, specifically the log level, using the `set config pd` command.  The change is persisted in etcd, taking precedence over the configuration file. The backticks `` ` `` are required to enclose the configuration items names in some cases.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nset config pd `log.level`='info';\n```\n\n----------------------------------------\n\nTITLE: Creating ITEM Table in TiDB Schema - SQL\nDESCRIPTION: Defines the structure of the `ITEM` table in TiDB. It includes primary key and data types for item-related fields. There are no dependencies for creating this table.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `item` (\n  `i_id` int NOT NULL,\n  `i_im_id` int DEFAULT NULL,\n  `i_name` varchar(24) DEFAULT NULL,\n  `i_price` decimal(5,2) DEFAULT NULL,\n  `i_data` varchar(50) DEFAULT NULL,\n  PRIMARY KEY (`i_id`)\n);\n```\n\n----------------------------------------\n\nTITLE: Using HASH_JOIN Hint in SQL Queries\nDESCRIPTION: The HASH_JOIN hint forces the optimizer to use the hash join algorithm for the specified tables. This algorithm enables concurrent execution with multiple threads for higher performance but requires more memory.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ HASH_JOIN(t1, t2) */ * from t1, t2 where t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Deleting Data from TiDB (TypeScript)\nDESCRIPTION: Deletes a Player record from the database by ID. Uses a prepared statement to ensure safe deletion based on user input.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nconst [rsh] = await pool.query('DELETE FROM players WHERE id = ?;', [1]);\nconsole.log(rsh.affectedRows);\n```\n\n----------------------------------------\n\nTITLE: Configuring Online DDL in TiDB DM v2.0.5+\nDESCRIPTION: Configuration setting for enabling online DDL support in TiDB Data Migration version 2.0.5 and later. Setting online-ddl to true enables support for both gh-ost and pt-osc tools.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-online-ddl-tool-support.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nonline-ddl: true\n```\n\n----------------------------------------\n\nTITLE: Setting TiDB System Variables using SQL\nDESCRIPTION: Examples of setting session and global system variables in TiDB using SQL SET statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n# These two identical statements change a session variable\nSET tidb_distsql_scan_concurrency = 10;\nSET SESSION tidb_distsql_scan_concurrency = 10;\n\n# These two identical statements change a global variable\nSET @@global.tidb_distsql_scan_concurrency = 10;\nSET GLOBAL tidb_distsql_scan_concurrency = 10;\n```\n\n----------------------------------------\n\nTITLE: Dropping Expression Index in SQL\nDESCRIPTION: Shows how to remove an expression index from a table. The syntax is the same as dropping a regular index.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nDROP INDEX idx1 ON t1;\n```\n\n----------------------------------------\n\nTITLE: Creating the 'books' Table in TiDB\nDESCRIPTION: SQL statement to create the 'books' table in the 'bookshop' database with various fields including id, title, type, published_at, stock, and price.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-secondary-indexes.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `bookshop`.`books` (\n  `id` bigint AUTO_RANDOM NOT NULL,\n  `title` varchar(100) NOT NULL,\n  `type` enum('Magazine', 'Novel', 'Life', 'Arts', 'Comics', 'Education & Reference', 'Humanities & Social Sciences', 'Science & Technology', 'Kids', 'Sports') NOT NULL,\n  `published_at` datetime NOT NULL,\n  `stock` int DEFAULT '0',\n  `price` decimal(15,2) DEFAULT '0.0',\n  PRIMARY KEY (`id`) CLUSTERED\n) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\n```\n\n----------------------------------------\n\nTITLE: Running Read-Only Test with Sysbench\nDESCRIPTION: Bash command for executing the read-only benchmark test with Sysbench, which evaluates the performance of read operations in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nsysbench --config-file=config oltp_read_only --tables=32 --table-size=10000000 --db-ps-mode=auto --rand-type=uniform run\n```\n\n----------------------------------------\n\nTITLE: TiDB JSON Implicit Conversion\nDESCRIPTION: Example showing TiDB's implicit conversion of values to JSON type when inserting into a JSON column.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-json.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(col JSON);\nINSERT INTO t VALUES (3);\n```\n\n----------------------------------------\n\nTITLE: Updating Data with GORM in Golang\nDESCRIPTION: Updates an existing Player record in the database using GORM's Save method.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-golang-gorm.md#2025-04-18_snippet_3\n\nLANGUAGE: Go\nCODE:\n```\ndb.Save(&Player{ID: \"id\", Coins: 100, Goods: 1})\n```\n\n----------------------------------------\n\nTITLE: Example Response for Data Source List in JSON\nDESCRIPTION: This JSON represents the response format when retrieving the list of data sources. It includes an array of data source configurations and a total count of available sources.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_15\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"data\": [\n    {\n      \"enable_gtid\": false,\n      \"host\": \"127.0.0.1\",\n      \"password\": \"******\",\n      \"port\": 3306,\n      \"purge\": {\n        \"expires\": 0,\n        \"interval\": 3600,\n        \"remain_space\": 15\n      },\n      \"security\": null,\n      \"source_name\": \"mysql-01\",\n      \"user\": \"root\"\n    },\n    {\n      \"enable_gtid\": false,\n      \"host\": \"127.0.0.1\",\n      \"password\": \"******\",\n      \"port\": 3307,\n      \"purge\": {\n        \"expires\": 0,\n        \"interval\": 3600,\n        \"remain_space\": 15\n      },\n      \"security\": null,\n      \"source_name\": \"mysql-02\",\n      \"user\": \"root\"\n    }\n  ],\n  \"total\": 2\n}\n```\n\n----------------------------------------\n\nTITLE: Executing SQL to Prepare Data for Base64 Decoding - SQL\nDESCRIPTION: Prepares the database by creating a table and inserting data, which is used later for base64 decoding operations in TiDB Control.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-control.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nuse test; create table t (a int, b varchar(20),c datetime default current_timestamp , d timestamp default current_timestamp, unique index(a)); insert into t (a,b,c) values(1,\"哈哈 hello\",NULL); alter table t add column e varchar(20);\n```\n\n----------------------------------------\n\nTITLE: Changing Column Names in TiDB SQL\nDESCRIPTION: SQL commands demonstrating how to change column names using the CHANGE COLUMN statement in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-change-column.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t1 CHANGE col1 col2 INT;\n\nALTER TABLE t1 CHANGE col2 col3 BIGINT, ALGORITHM=INSTANT;\n```\n\n----------------------------------------\n\nTITLE: Correctly Quoting Qualified Identifiers\nDESCRIPTION: Show the correct way to quote table and column names with qualified identifiers using separate backticks\nSOURCE: https://github.com/pingcap/docs/blob/master/schema-object-names.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n`table_name`.`col_name`\n```\n\n----------------------------------------\n\nTITLE: Sink URI Example for Google Cloud Storage\nDESCRIPTION: Basic sink URI configuration for Google Cloud Storage, specifying the bucket, prefix, and protocol for data replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"gcs://bucket/prefix?protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: Viewing TiDB Query Execution Plan Output\nDESCRIPTION: A partial display of a TiDB query execution plan showing a nested loop join operation with table scans on 'rates' and 'orders' tables. The output includes operator information, row counts, and execution time statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\n|   │     └─Selection_96(Probe)         | 1000.00  | 2458    | cop[tikv] |                                                                                        | time:444.4ms, ...| N/A      | N/A  |\n|   │       └─TableRowIDScan_94         | 6517.14  | 6481    | cop[tikv] | table:rates                                                                            | tikv_task:{pro...| N/A      | N/A  |\n|   └─TableReader_84(Probe)             | 984.56   | 1998    | root      |                                                                                        | time:207.6ms, ...| N/A      | N/A  |\n|     └─Selection_83                    | 984.56   | 1998    | cop[tikv] |                                                                                        | tikv_task:{pro...| N/A      | N/A  |\n|       └─TableRangeScan_82             | 1000.00  | 2048    | cop[tikv] | table:orders                                                                           | tikv_task:{pro...| N/A      | N/A  |\n+---------------------------------------+----------+---------+-----------+----------------------------------------------------------------------------------------+---------------...+----------+------+\n```\n\n----------------------------------------\n\nTITLE: Querying All Character Sets in TiDB\nDESCRIPTION: SQL example showing how to list all available character sets in TiDB using the SHOW CHARACTER SET statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-character-set.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CHARACTER SET;\n```\n\n----------------------------------------\n\nTITLE: Creating a resource group with RU limit and priority\nDESCRIPTION: This SQL statement creates a resource group named `rg3` with an RU limit of 100 RUs per second and sets the absolute priority to `HIGH`. The `IF NOT EXISTS` clause ensures that the statement does not fail if the resource group already exists. Priority can be LOW, MEDIUM or HIGH.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-ru-groups.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE RESOURCE GROUP IF NOT EXISTS rg3 RU_PER_SEC = 100 PRIORITY = HIGH;\"\n```\n\n----------------------------------------\n\nTITLE: Optimized Execution Plan with Accurate Estimations - SQL\nDESCRIPTION: This snippet illustrates an optimized execution plan where the estimated rows more accurately match the actual rows, leading to significant improvements in execution time and resource utilization.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n+---------------------------------------+----------+---------+-----------+----------------------------------------------------------------------------------------+---------------...+----------+------+(\\n| id                                    | estRows  | actRows | task      | access object                                                                          | execution info...| memory   | disk |\\n+---------------------------------------+----------+---------+-----------+----------------------------------------------------------------------------------------+---------------...+----------+------+(\\n| Limit_24                              | 1000.00  | 1000    | root      |                                                                                        | time:1.96s, lo...| N/A      | N/A  |\\n| └─IndexJoin_88                        | 1000.00  | 1000    | root      |                                                                                        | time:1.96s, lo...| 1.32 MB  | N/A  |\\n|   ├─IndexJoin_99(Build)               | 1000.00  | 2458    | root      |                                                                                        | time:1.96s, lo...| 77.7 MB  | N/A  |\\n|   │ ├─TableReader_109(Build)          | 6505.62  | 158728  | root      |                                                                                        | time:1.26s, lo...| 297.0 MB | N/A  |\\n|   │ │ └─Selection_108                 | 6505.62  | 171583  | cop[tikv] |                                                                                        | tikv_task:{pro...| N/A      | N/A  |\\n|   │ │   └─TableRangeScan_107          | 80396.43 | 179616  | cop[tikv] | table:labels                                                                           | tikv_task:{pro...| N/A      | N/A  |\\n|   │ └─Projection_98(Probe)            | 1000.00  | 2458    | root      |                                                                                        | time:2.13s, lo...| 59.2 KB  | N/A  |\\n|   │   └─IndexLookUp_97                | 1000.00  | 2458    | root      | partition:all                                                                          | time:2.13s, lo...| 1.20 MB  | N/A  |\\n|   │     ├─Selection_95(Build)         | 6517.14  | 6481    | cop[tikv] |                                                                                        | time:798.6ms, ...| N/A      | N/A  |\\n|   │     │ └─IndexRangeScan_93         | 6517.14  | 6481    | cop[tikv] | table:rates, index:index_rates_on_label_id(label_id)                                   | tikv_task:{pro...| N/A      | N/A  |\\n\n```\n\n----------------------------------------\n\nTITLE: Export to Amazon S3 Using TiDB Cloud CLI\nDESCRIPTION: Command to export data from TiDB Cloud Serverless to Amazon S3 bucket using access key credentials\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-export.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export create -c <cluster-id> --s3.bucket-uri <uri> --s3.access-key-id <access-key-id> --s3.secret-access-key <secret-access-key>\n```\n\n----------------------------------------\n\nTITLE: Selecting Data from Table with Predicate Column in SQL\nDESCRIPTION: Executes a SELECT query on table 't' to retrieve all records where column 'b' exceeds 1. This is to demonstrate the use of collected statistics for query optimization.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n-- The optimizer uses the statistics on column b in this query.\nSELECT * FROM t WHERE b > 1;\n```\n\n----------------------------------------\n\nTITLE: Explaining Query Execution Plan in TiDB\nDESCRIPTION: This EXPLAIN statement shows the execution plan for the previous query, revealing that TiDB uses an index lookup followed by a table scan due to the lack of a covering index.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT title, price FROM books WHERE title = 'Marian Yost';\n```\n\n----------------------------------------\n\nTITLE: Efficient Date Comparison in SQL WHERE Clause\nDESCRIPTION: Shows the recommended way to perform date comparison in a WHERE clause, avoiding function use on the indexed column.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sql-development-specification.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATE_FORMAT(gmt_create, '%Y%m%d %H:%i:%s')\nFROM ...\nWHERE gmt_create = str_to_date('20090101 00:00:00', '%Y%m%d %H:%i:%s')\n```\n\n----------------------------------------\n\nTITLE: Revoking Privileges Syntax in TiDB SQL\nDESCRIPTION: The provided EBNF diagram defines the syntax for the REVOKE statement in TiDB, detailing the structure required to remove privileges from a user. This syntax requires the GRANT OPTION privilege and involves specifying privilege elements, object types, privilege levels, and user specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-revoke-privileges.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\nRevokeStmt ::= \n    'REVOKE' PrivElemList 'ON' ObjectType PrivLevel 'FROM' UserSpecList\n\nPrivElemList ::= \n    PrivElem ( ',' PrivElem )*\n\nPrivElem ::= \n    PrivType ( '(' ColumnNameList ')' )?\n\nPrivType ::= \n    'ALL' 'PRIVILEGES'?\n|   'ALTER' 'ROUTINE'?\n|   'CREATE' ( 'USER' | 'TEMPORARY' 'TABLES' | 'VIEW' | 'ROLE' | 'ROUTINE' )?\n|    'TRIGGER'\n|   'DELETE'\n|    'DROP' 'ROLE'?\n|    'PROCESS'\n|    'EXECUTE'\n|   'INDEX'\n|   'INSERT'\n|   'SELECT'\n|   'SUPER'\n|    'SHOW' ( 'DATABASES' | 'VIEW' )\n|   'UPDATE'\n|   'GRANT' 'OPTION'\n|   'REFERENCES'\n|   'REPLICATION' ( 'SLAVE' | 'CLIENT' )\n|   'USAGE'\n|    'RELOAD'\n|   'FILE'\n|   'CONFIG'\n|   'LOCK' 'TABLES'\n|    'EVENT'\n|   'SHUTDOWN'\n\nObjectType ::= \n    'TABLE'?\n\nPrivLevel ::= \n    '*' ( '.' '*' )?\n|    Identifier ( '.' ( '*' | Identifier ) )?\n\nUserSpecList ::= \n    UserSpec ( ',' UserSpec )*\n```\n\n----------------------------------------\n\nTITLE: Filtering Character Sets with LIKE Clause in TiDB\nDESCRIPTION: SQL example demonstrating how to use the LIKE clause with SHOW CHARACTER SET to filter results for UTF-8 character sets.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-character-set.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CHARACTER SET LIKE 'utf8%';\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Using MySQL Client\nDESCRIPTION: Connects to the TiDB database using the MySQL client with default credentials\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nmysql --host 127.0.0.1 --port 4000 -u root\n```\n\n----------------------------------------\n\nTITLE: TiDB ADMIN Statement EBNF Syntax\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the ADMIN statement in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin.md#2025-04-18_snippet_5\n\nLANGUAGE: ebnf\nCODE:\n```\nAdminStmt ::=\n    'ADMIN' ( \n        'SHOW' ( \n            'DDL' ( \n                'JOBS' Int64Num? WhereClauseOptional \n                | 'JOB' 'QUERIES' (NumList | AdminStmtLimitOpt)\n            )? \n            | TableName 'NEXT_ROW_ID' \n            | 'SLOW' AdminShowSlow \n            | 'BDR' 'ROLE'\n        ) \n        | 'CHECK' ( \n            'TABLE' TableNameList \n            | 'INDEX' TableName Identifier ( HandleRange ( ',' HandleRange )* )? \n        ) \n        | 'RECOVER' 'INDEX' TableName Identifier \n        | 'CLEANUP' ( \n            'INDEX' TableName Identifier \n            | 'TABLE' 'LOCK' TableNameList ) \n        | 'CHECKSUM' 'TABLE' TableNameList | 'CANCEL' 'DDL' 'JOBS' NumList \n        | ( 'CANCEL' | 'PAUSE' | 'RESUME' ) 'DDL' 'JOBS' NumList\n        | 'RELOAD' (\n            'EXPR_PUSHDOWN_BLACKLIST' \n            | 'OPT_RULE_BLACKLIST' \n            | 'BINDINGS'\n            | 'STATS_EXTENDED'\n            | 'STATISTICS'\n        ) \n        | 'PLUGINS' ( 'ENABLE' | 'DISABLE' ) PluginNameList \n        | 'REPAIR' 'TABLE' TableName CreateTableStmt \n        | ( 'FLUSH' | 'CAPTURE' | 'EVOLVE' ) 'BINDINGS'\n        | 'FLUSH' ('SESSION' | 'INSTANCE') 'PLAN_CACHE'\n        | 'SET' 'BDR' 'ROLE' ( 'PRIMARY' | 'SECONDARY' )\n        | 'UNSET' 'BDR' 'ROLE'\n        | 'CREATE' 'WORKLOAD' 'SNAPSHOT'\n    )\n\nNumList ::=\n    Int64Num ( ',' Int64Num )*\n\nAdminStmtLimitOpt ::=\n    'LIMIT' LengthNum\n|    'LIMIT' LengthNum ',' LengthNum\n|    'LIMIT' LengthNum 'OFFSET' LengthNum\n\nTableNameList ::=\n    TableName ( ',' TableName )*\n```\n\n----------------------------------------\n\nTITLE: Enabling Titan through TiUP Configuration in TiKV\nDESCRIPTION: This snippet shows how to enable Titan by editing the TiKV configuration with TiUP. This is followed by a reload command to apply the configuration and restart TiKV instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/storage-engine/titan-configuration.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntikv:\n  rocksdb.titan.enabled: true\n```\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster reload ${cluster-name} -R tikv\n```\n\n----------------------------------------\n\nTITLE: Retrieving Database Version (SQL)\nDESCRIPTION: The `VERSION()` function returns the version of TiDB, formatted to indicate compatibility with MySQL, helping in version management and compatibility checks.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/information-functions.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VERSION();\n```\n+--------------------+\n| VERSION()          |\n+--------------------+\n| 8.0.11-TiDB-v7.5.1 |\n+--------------------+\n1 row in set (0.00 sec)\n\nSELECT TIDB_VERSION()\\G\n*************************** 1. row ***************************\nTIDB_VERSION(): Release Version: v7.5.1\nEdition: Community\nGit Commit Hash: 7d16cc79e81bbf573124df3fd9351c26963f3e70\nGit Branch: heads/refs/tags/v7.5.1\nUTC Build Time: 2024-02-27 14:28:32\nGoVersion: go1.21.6\nRace Enabled: false\nCheck Table Before Drop: false\nStore: tikv\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Using JSON_PRETTY for JSON Formatting in SQL\nDESCRIPTION: Demonstrates how to use JSON_PRETTY function to format a JSON document with proper indentation and line breaks. The function takes a JSON document as input and returns a formatted string.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-utility.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_PRETTY('{\"person\":{\"name\":{\"first\":\"John\",\"last\":\"Doe\"},\"age\":23}}')\\G\n```\n\n----------------------------------------\n\nTITLE: Identifying Deadlock Error in SQL\nDESCRIPTION: The SQL error message that indicates a deadlock has occurred in a transaction. This is shown to help developers recognize when a deadlock situation has happened.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-troubleshoot.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nERROR 1213: Deadlock found when trying to get lock; try restarting transaction\n```\n\n----------------------------------------\n\nTITLE: Cross-Database DDL Statement Example\nDESCRIPTION: Demonstrates the recommended approach for cross-database DDL statements to ensure correct replication, explicitly specifying database names.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-ddl.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE db1.t1 LIKE db2.t2\n```\n\n----------------------------------------\n\nTITLE: Checking Backup Directory Permissions using `ls -al` command in Linux\nDESCRIPTION: This snippet illustrates how to use the `ls -al` command in Linux to check the permissions of the backup directory. The output displays the file type, permissions, number of links, owner, group, size, and last modification time of the directory, enabling administrators to verify if the TiKV user has the necessary read or write permissions for backup and restore operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\n\n    ls -al backup\n    \n```\n\n----------------------------------------\n\nTITLE: Creating a Database in TiDB\nDESCRIPTION: This SQL snippet demonstrates how to create a 'tpcc' database in a TiDB cluster. It is used to prepare the database for the TPC-C benchmarks.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE tpcc;\n```\n\n----------------------------------------\n\nTITLE: Running Branch Describe in Interactive Mode\nDESCRIPTION: Example of running the branch describe command in interactive mode, where the CLI will prompt for required information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-describe.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch describe\n```\n\n----------------------------------------\n\nTITLE: Creating a Prepared Statement in SQL\nDESCRIPTION: Demonstrates how to create a prepared statement for selecting data from the 'books' table using a placeholder for the book ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-prepared-statement.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nPREPARE `books_query` FROM 'SELECT * FROM `books` WHERE `id` = ?';\n```\n\n----------------------------------------\n\nTITLE: Setting DDL Reorganization Priority\nDESCRIPTION: Sets the tidb_ddl_reorg_priority variable to control the priority of executing ADD INDEX operations during the re-organize phase. This can be used to balance DDL operations with other workloads.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_25\n\nLANGUAGE: SQL\nCODE:\n```\nSET SESSION tidb_ddl_reorg_priority = 'PRIORITY_LOW';\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with AUTO_RANDOM Primary Key in TiDB\nDESCRIPTION: Illustrates how to create a table using AUTO_RANDOM for the primary key to generate randomly distributed, non-repeated primary keys and scatter write hotspots.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-hot-spot-issues.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a BIGINT PRIMARY KEY AUTO_RANDOM, b varchar(255));\n```\n\n----------------------------------------\n\nTITLE: CREATE VIEW Syntax Definition in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the CREATE VIEW statement in TiDB, including options for replacement, algorithm, definer, SQL security, and check options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-view.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCreateViewStmt ::=\n    'CREATE' OrReplace ViewAlgorithm ViewDefiner ViewSQLSecurity 'VIEW' ViewName ViewFieldList 'AS' CreateViewSelectOpt ViewCheckOption\n\nOrReplace ::=\n    ( 'OR' 'REPLACE' )?\n\nViewAlgorithm ::=\n    ( 'ALGORITHM' '=' ( 'UNDEFINED' | 'MERGE' | 'TEMPTABLE' ) )?\n\nViewDefiner ::=\n    ( 'DEFINER' '=' Username )?\n\nViewSQLSecurity ::=\n    ( 'SQL' 'SECURITY' ( 'DEFINER' | 'INVOKER' ) )?\n\nViewName ::= TableName\n\nViewFieldList ::=\n    ( '(' Identifier ( ',' Identifier )* ')' )?\n\nViewCheckOption ::=\n    ( 'WITH' ( 'CASCADED' | 'LOCAL' ) 'CHECK' 'OPTION' )?\n```\n\n----------------------------------------\n\nTITLE: Physical Algorithms Supported by MPP Mode\nDESCRIPTION: This snippet shows an example of a query execution plan utilizing MPP algorithms. It elucidates the inclusion of operators like ExchangeSender and ExchangeReceiver in the execution plan.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tiflash-mpp-mode.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nexplain select count(*) from customer c join nation n on c.c_nationkey=n.n_nationkey;\n```\n\n----------------------------------------\n\nTITLE: Describing RESOURCE_GROUPS Table Structure\nDESCRIPTION: Shows the structure of the RESOURCE_GROUPS table including field names, data types, and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-resource-groups.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC resource_groups;\n```\n\n----------------------------------------\n\nTITLE: Using TIDB_DECODE_SQL_DIGESTS with Statement Truncation\nDESCRIPTION: Demonstrates using TIDB_DECODE_SQL_DIGESTS with a truncation parameter to limit the length of returned SQL statements. When statements exceed the specified length, they are truncated and appended with '...'.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_DECODE_SQL_DIGESTS(@digests, 10);\n```\n\n----------------------------------------\n\nTITLE: Uneven Split Syntax Example for TiDB Tables\nDESCRIPTION: SQL syntax example for manually splitting a table region at specific points, useful for unevenly distributed data in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSPLIT TABLE table_name [INDEX index_name] BY (value_list) [, (value_list)] ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Server-Level Memory Limit in TiDB\nDESCRIPTION: Example of setting the total memory usage threshold for a tidb-server instance using the tidb_server_memory_limit system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-memory-usage.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_server_memory_limit = \"32GB\";\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax for RecoverTableStmt\nDESCRIPTION: This snippet provides an Extended Backus-Naur Form (EBNF) representation of the syntax for the RECOVER TABLE statement, detailing its structure and allowable forms.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-recover-table.md#2025-04-18_snippet_2\n\nLANGUAGE: ebnf\nCODE:\n```\nRecoverTableStmt ::= 'RECOVER' 'TABLE' ( 'BY' 'JOB' Int64Num | TableName Int64Num? )\n\nTableName ::= Identifier ( '.' Identifier )?\n\nInt64Num ::= NUM\n\nNUM ::= intLit\n```\n\n----------------------------------------\n\nTITLE: Creating Test Table for TIDB_ROW_CHECKSUM Demo\nDESCRIPTION: Creates a test table and inserts a sample row to demonstrate the TIDB_ROW_CHECKSUM function. The table has a primary key and two other columns of integer and character types.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nUSE test;\nCREATE TABLE t (id INT PRIMARY KEY, k INT, c CHAR(1));\nINSERT INTO t VALUES (1, 10, 'a');\n```\n\n----------------------------------------\n\nTITLE: DOUBLE Type Declaration in SQL\nDESCRIPTION: Two equivalent syntaxes for declaring DOUBLE type with optional display width, decimal places, unsigned flag and zero-fill option\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-numeric.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nDOUBLE[(M,D)] [UNSIGNED] [ZEROFILL]\n```\n\nLANGUAGE: sql\nCODE:\n```\nDOUBLE PRECISION [(M,D)] [UNSIGNED] [ZEROFILL], REAL[(M,D)] [UNSIGNED] [ZEROFILL]\n```\n\n----------------------------------------\n\nTITLE: Create User and Set Password\nDESCRIPTION: This set of SQL statements creates a new user and then modifies the password. It illustrates creating a user named 'newuser' with an initial password and subsequently changing that password using the `SET PASSWORD` statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-password.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE USER 'newuser' IDENTIFIED BY 'test';\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW CREATE USER 'newuser';\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSET PASSWORD FOR newuser = 'test';\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW CREATE USER 'newuser';\n```\n\n----------------------------------------\n\nTITLE: Switching to the Created Database\nDESCRIPTION: This SQL command switches the context to the 'pingcap' database after its creation, allowing subsequent operations to be performed within that database.\nSOURCE: https://github.com/pingcap/docs/blob/master/post-installation-check.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nuse pingcap;\n```\n\n----------------------------------------\n\nTITLE: Querying with HAVING Clause in TiDB\nDESCRIPTION: Fixes the unknown column error for SQL statements that use a HAVING clause referencing a table column.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.17.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT a FROM t HAVING t.a > 0;\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP DM Destroy Command in Shell\nDESCRIPTION: The command to destroy a DM cluster using TiUP. It stops the cluster, deletes log, deployment, and data directories for each service, and removes parent directories created by tiup-dm. The cluster name is required, and optional flags can be used.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-destroy.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm destroy <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Cancelling Traffic Jobs in SQL\nDESCRIPTION: This SQL snippet demonstrates how to use the CANCEL TRAFFIC JOBS command to cancel all ongoing traffic capture or replay jobs in TiDB. This command requires specific privileges to execute.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-cancel-traffic-jobs.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCANCEL TRAFFIC JOBS;\n```\n\n----------------------------------------\n\nTITLE: Exporting Data from MySQL using Dumpling\nDESCRIPTION: Shell commands to export data from MySQL databases my_db1 and my_db2 using Dumpling. The commands specify various parameters for optimizing the export process.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\ntiup dumpling -h ${ip} -P 3306 -u root -t 16 -r 200000 -F 256MB -B my_db1 -f 'my_db1.table[12]' -o ${data-path}/my_db1\n```\n\nLANGUAGE: Shell\nCODE:\n```\ntiup dumpling -h ${ip} -P 3306 -u root -t 16 -r 200000 -F 256MB -B my_db2 -f 'my_db2.table[34]' -o ${data-path}/my_db2\n```\n\n----------------------------------------\n\nTITLE: Defining Insert Event Value Format in JSON\nDESCRIPTION: Describes the value format for Insert events in Row Changed Events. It contains the newly added row data with column details.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"u\":{\n        <Column Name>:{\n            \"t\":<Column Type>,\n            \"h\":<Where Handle>,\n            \"f\":<Flag>,\n            \"v\":<Column Value>\n        },\n        <Column Name>:{\n            \"t\":<Column Type>,\n            \"h\":<Where Handle>,\n            \"f\":<Flag>,\n            \"v\":<Column Value>\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing EXPLAIN Query in TiDB\nDESCRIPTION: This SQL snippet shows how to use the EXPLAIN command in TiDB to get detailed information about query execution plans, including memory and disk usage by operators.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-beta.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nEXPLAIN SELECT * FROM table_name WHERE condition;\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Subnet Access Pattern in TiDB\nDESCRIPTION: Create a 'test' user that can connect from any host in the 192.168.10.* subnet using wildcard pattern matching.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'test'@'192.168.10.%';\n```\n\n----------------------------------------\n\nTITLE: Allowing Region Merging for a Table in SQL\nDESCRIPTION: Shows how to allow merging of Regions belonging to a table by setting the merge_option attribute to 'allow'.\nSOURCE: https://github.com/pingcap/docs/blob/master/table-attributes.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t ATTRIBUTES 'merge_option=allow';\n```\n\n----------------------------------------\n\nTITLE: Filtered Output from SHOW STATS_HISTOGRAMS\nDESCRIPTION: Shows the filtered output when executing SHOW STATS_HISTOGRAMS with a WHERE condition. The example targets a specific table, displaying relevant statistics such as distinct counts and average column size for the filtered data set.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-histograms.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\n+---------+------------+----------------+-------------+----------+---------------------+----------------+------------+--------------+-------------+\\n| Db_name | Table_name | Partition_name | Column_name | Is_index | Update_time         | Distinct_count | Null_count | Avg_col_size | Correlation |\\n+---------+------------+----------------+-------------+----------+---------------------+----------------+------------+--------------+-------------+\\n| test    | t2         |                | b           |        0 | 2020-05-25 19:20:01 |              6 |          0 |         1.67 |           1 |\\n| test    | t2         |                | a           |        0 | 2020-05-25 19:20:01 |              6 |          0 |            8 |           0 |\\n+---------+------------+----------------+-------------+----------+---------------------+----------------+------------+--------------+-------------+\\n2 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Altering User to Disable Password Expiration in SQL\nDESCRIPTION: SQL command to modify an existing user to set their password to never expire, overriding any global expiration policy.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_17\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER 'test'@'localhost' PASSWORD EXPIRE NEVER;\n```\n\n----------------------------------------\n\nTITLE: Showing Table Creation Statement in TiDB\nDESCRIPTION: This SQL statement displays the `CREATE TABLE` statement for the `trips` table. This allows users to inspect the table schema, including column definitions, primary keys, and indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n\"SHOW CREATE TABLE trips\\G\"\n```\n\n----------------------------------------\n\nTITLE: Manually Splitting Table Regions in TiDB\nDESCRIPTION: Example of manually splitting a Region using the SPLIT TABLE REGION statement and verifying the results. The command splits a Region between specified key ranges into multiple Regions for better data distribution.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-regions.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SPLIT TABLE t1 BETWEEN (31717) AND (63434) REGIONS 2;\n+--------------------+----------------------+\n| TOTAL_SPLIT_REGION | SCATTER_FINISH_RATIO |\n+--------------------+----------------------+\n|                  1 |                    1 |\n+--------------------+----------------------+\n1 row in set (42.34 sec)\n\nmysql> SHOW TABLE t1 REGIONS;\n+-----------+--------------+--------------+-----------+-----------------+-------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n| REGION_ID | START_KEY    | END_KEY      | LEADER_ID | LEADER_STORE_ID | PEERS | SCATTERING | WRITTEN_BYTES | READ_BYTES | APPROXIMATE_SIZE(MB) | APPROXIMATE_KEYS | SCHEDULING_CONSTRAINTS | SCHEDULING_STATE |\n+-----------+--------------+--------------+-----------+-----------------+-------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n|        94 | t_75_        | t_75_r_31717 |        95 |               1 | 95    |          0 |             0 |          0 |                  112 |           207465 |                        |                  |\n|        98 | t_75_r_31717 | t_75_r_47575 |        99 |               1 | 99    |          0 |          1325 |          0 |                   53 |            12052 |                        |                  |\n|        96 | t_75_r_47575 | t_75_r_63434 |        97 |               1 | 97    |          0 |          1526 |          0 |                   48 |                0 |                        |                  |\n|         2 | t_75_r_63434 |              |         3 |               1 | 3     |          0 |             0 |   55752049 |                   60 |                0 |                        |                  |\n+-----------+--------------+--------------+-----------+-----------------+-------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n4 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a TiCDC Changefeed with TiDB Extension Field\nDESCRIPTION: CLI command to create a changefeed with the Canal-JSON protocol that includes TiDB extension fields. When enable-tidb-extension is set to true, TiCDC adds TiDB-specific data like CommitTS and sends WATERMARK events.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://127.0.0.1:8300 --changefeed-id=\"kafka-canal-json-enable-tidb-extension\" --sink-uri=\"kafka://127.0.0.1:9092/topic-name?kafka-version=2.4.0&protocol=canal-json&enable-tidb-extension=true\"\n```\n\n----------------------------------------\n\nTITLE: Scaling in the TiDB cluster using TiUP\nDESCRIPTION: This command scales in the TiDB cluster by removing the specified node. The `--node` parameter specifies the ID (host:port) of the node to be taken offline. This command is executed twice to remove two nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster scale-in <cluster-name> --node 10.0.1.8:3379\"\n```\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster scale-in <cluster-name> --node 10.0.1.9:3379\"\n```\n\n----------------------------------------\n\nTITLE: Converting TIME and DATETIME to Numeric Format in SQL\nDESCRIPTION: These examples demonstrate how to convert TIME and DATETIME values to numeric format in SQL. It shows the result of adding 0 to CURTIME() and NOW() functions, both with and without fractional seconds.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURTIME(), CURTIME()+0, CURTIME(3)+0;\n\nSELECT NOW(), NOW()+0, NOW(3)+0;\n```\n\n----------------------------------------\n\nTITLE: SQL Transaction Log Example with Doctor On-Call Status Check\nDESCRIPTION: This SQL log demonstrates two concurrent transactions: one checking the total number of on-call doctors, and another updating a specific doctor's on-call status. The first transaction rolls back after seeing at least one doctor is on call.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-restraints.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n/* txn 1 */ BEGIN\n    /* txn 2 */ BEGIN\n    /* txn 2 */ SELECT COUNT(*) AS `count` FROM `doctors` WHERE on_call = 1 AND `shift_id` = 123 FOR UPDATE\n    /* txn 2 */ UPDATE `doctors` SET on_call = 0 WHERE `id` = 2 AND `shift_id` = 123\n    /* txn 2 */ COMMIT\n/* txn 1 */ SELECT COUNT(*) AS `count` FROM `doctors` WHERE `on_call` = 1 FOR UPDATE\nAt least one doctor is on call\n/* txn 1 */ ROLLBACK\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Auto-Increment and Primary Key\nDESCRIPTION: This SQL snippet demonstrates creating a table with an auto-incrementing column that is part of the primary key. This is a new feature in TiDB v7.0.0, removing the previous constraint that auto-increment columns must be an index or index prefix. The example shows a table named 'test1' with an auto-incrementing 'id' column and a composite primary key consisting of 'k' and 'id'.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.0.0.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n    CREATE TABLE test1 (\n        `id` int(11) NOT NULL AUTO_INCREMENT,\n        `k` int(11) NOT NULL DEFAULT '0',\n        `c` char(120) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '',\n        PRIMARY KEY(`k`, `id`)\n    );\n\n```\n\n----------------------------------------\n\nTITLE: Creating a database in TiDB\nDESCRIPTION: This SQL statement creates a database named 'test' in the TiDB database. This is a prerequisite for the following examples that demonstrate how to show the create statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-database.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE test;\n```\n\n----------------------------------------\n\nTITLE: Creating YAML Configuration for Scaling Out TiDB Cluster\nDESCRIPTION: This YAML configuration file specifies new PD and TiKV nodes to be added to the cluster during a scale-out operation. It includes only the description of the new nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n---\n\npd_servers:\n  - host: 172.16.5.140\n\ntikv_servers:\n  - host: 172.16.5.140\n```\n\n----------------------------------------\n\nTITLE: Managing TiDB Etcd Keys - Shell\nDESCRIPTION: Includes examples of using the 'etcd' command to interact with Etcd keys related to TiDB's schema versions and DDL operations. Covers adding, retrieving, and deleting keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-control.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntidb-ctl etcd putkey \"foo\" \"bar\"\n```\n\nLANGUAGE: shell\nCODE:\n```\ntidb-ctl etcd delkey \"/tidb/ddl/fg/owner/foo\"\n```\n\nLANGUAGE: shell\nCODE:\n```\ntidb-ctl etcd delkey \"/tidb/ddl/all_schema_versions/bar\"\n```\n\n----------------------------------------\n\nTITLE: Replicating Tables to TiFlash in TiDB Cloud Using SQL\nDESCRIPTION: This SQL snippet demonstrates how to replicate a sample table named 'games' to TiFlash, a columnar storage engine in TiDB Cloud, using DDL statements. This step requires an active TiDB Cloud Serverless cluster with a dataset imported. Key parameters include the table to be replicated and the number of TiFlash replicas. The expected input is valid SQL commands executed in a MySQL client, and the output is the successful creation of table replicas in TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-htap-quickstart.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE game;\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE games SET TIFLASH REPLICA 2;\n```\n\n----------------------------------------\n\nTITLE: Viewing Global Bindings in TiDB\nDESCRIPTION: Displays all global bindings, including cross-database bindings, using the SHOW GLOBAL BINDINGS command in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_27\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW GLOBAL BINDINGS;\n```\n\n----------------------------------------\n\nTITLE: Importing a Data File in SQL Format\nDESCRIPTION: This SQL statement imports a data file in SQL format into a TiDB table.  The `FORMAT 'sql'` clause specifies that the input file contains SQL statements for data insertion.  The file should contain valid SQL `INSERT` statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t FROM '/path/to/file.sql' FORMAT 'sql';\n```\n\n----------------------------------------\n\nTITLE: Enabling Syncpoint in TiCDC Configuration (TOML)\nDESCRIPTION: This snippet provides the configuration needed to enable Syncpoint in TiCDC to align snapshots between upstream and downstream clusters. It ensures data consistency during replication by setting the sync-point configuration options.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-upstream-downstream-check.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n# Enables SyncPoint.\nenable-sync-point = true\n\n# Aligns the upstream and downstream snapshots every 5 minutes\nsync-point-interval = \"5m\"\n\n# Cleans up the ts-map data in the downstream tidb_cdc.syncpoint_v1 table every hour\nsync-point-retention = \"1h\"\n```\n\n----------------------------------------\n\nTITLE: Example of Using EXPLAIN Statement\nDESCRIPTION: This SQL example demonstrates how to use the 'EXPLAIN' statement to check the execution plan of a query. It shows how the MPP mode might be blocked due to the absence of TiFlash replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tiflash-mpp-mode.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nset @@session.tidb_enforce_mpp=1;\ncreate table t(a int);\nexplain select count(*) from t;\nshow warnings;\n```\n\n----------------------------------------\n\nTITLE: Listing Managed DM Clusters\nDESCRIPTION: This command lists all DM clusters currently managed by TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup-offline.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm list\n```\n\n----------------------------------------\n\nTITLE: Getting User Information (SQL)\nDESCRIPTION: The `USER()` function returns the user name and host name of the current session, which may differ from `CURRENT_USER()` by showing the actual IP address.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/information-functions.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT USER(), CURRENT_USER();\n```\n+----------------+----------------+\n| USER()         | CURRENT_USER() |\n+----------------+----------------+\n| root@127.0.0.1 | root@%         |\n+----------------+----------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Upgrading TiDB Cluster Online in Shell\nDESCRIPTION: This command upgrades the TiDB cluster to a specified version using the online method. It allows the cluster to continue providing services during the upgrade process.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster upgrade <cluster-name> <version>\n```\n\n----------------------------------------\n\nTITLE: Updating TiProxy Configuration using Bash and TOML\nDESCRIPTION: A multi-step process to update TiProxy configuration: retrieving current config, creating a TOML file with changes, and sending a PUT request to update the configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-api.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:3080/api/admin/config/\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ cat test.toml\n[log]\nlevel='warning'\n$ curl -X PUT --data-binary @test.toml http://127.0.0.1:3080/api/admin/config/\n```\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:3080/api/admin/config/\n```\n\n----------------------------------------\n\nTITLE: Autogenerate Endpoint in TiDB Cloud Data Service\nDESCRIPTION: Procedure for automatically generating web API endpoints for database operations, supporting various HTTP methods and vector search capabilities\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-manage-endpoint.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n1. Navigate to Data Service page\n2. Select Data App\n3. Click \"Autogenerate Endpoint\"\n4. Choose cluster, database, table\n5. Select HTTP operations\n6. Configure optional settings\n7. Click \"Generate\"\n```\n\n----------------------------------------\n\nTITLE: Restoring Only MySQL Schema User Table with BR in Shell\nDESCRIPTION: This command shows how to restore only the mysql.usertable from a backup using BR. It specifically targets the single table without including other tables from the mysql schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nbr restore full -f 'mysql.usertable' -s $external_storage_url --with-sys-table\n```\n\n----------------------------------------\n\nTITLE: Enforcing MPP Mode in TiDB Query Execution\nDESCRIPTION: Sets tidb_enforce_mpp to 1 to force the use of MPP (Massively Parallel Processing) mode, ignoring optimizer estimation. This can be used to ensure queries use MPP execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.4.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_enforce_mpp = 1;\n```\n\n----------------------------------------\n\nTITLE: Setting TiFlash MPP Mode System Variables\nDESCRIPTION: SQL statements to control the MPP (Massively Parallel Processing) mode of TiFlash. These system variables allow disabling MPP mode or forcibly enabling it for query execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/explore-htap.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_allow_mpp = 'OFF'; -- To disable MPP mode\nSET tidb_allow_mpp = 'ON'; -- Required for MPP mode\nSET tidb_enforce_mpp = 'ON'; -- To forcibly enable MPP mode\n```\n\n----------------------------------------\n\nTITLE: Successful Response Structure from Chat2Data Endpoint in JSON\nDESCRIPTION: This json snippet depicts a successful response from the Chat2Data v1 endpoint, demonstrating the return data's structure, including columns, rows, and the result metadata. It confirms successful execution with a '200' code and lists the executed SQL statement and its performance metrics.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"chat2data_endpoint\",\n  \"data\": {\n    \"columns\": [\n      {\n        \"col\": \"COUNT(`user_id`)\",\n        \"data_type\": \"BIGINT\",\n        \"nullable\": false\n      }\n    ],\n    \"rows\": [\n      {\n        \"COUNT(`user_id`)\": \"1\"\n      }\n    ],\n    \"result\": {\n      \"code\": 200,\n      \"message\": \"Query OK!\",\n      \"start_ms\": 1699529488292,\n      \"end_ms\": 1699529491901,\n      \"latency\": \"3.609656403s\",\n      \"row_count\": 1,\n      \"row_affect\": 0,\n      \"limit\": 1000,\n      \"sql\": \"SELECT COUNT(`user_id`) FROM `users`;\",\n      \"ai_latency\": \"3.054822491s\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using INSERT IGNORE with List Partitioning in SQL\nDESCRIPTION: Example demonstrating how to use the INSERT IGNORE syntax with a list partitioned table to skip rows that don't match any partition. This allows the statement to complete without error, inserting only valid rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\ntest> TRUNCATE t;\nQuery OK, 1 row affected (0.00 sec)\n\ntest> INSERT IGNORE INTO t VALUES (1, 1), (7, 7), (8, 8), (3, 3), (5, 5);\nQuery OK, 3 rows affected, 2 warnings (0.01 sec)\nRecords: 5  Duplicates: 2  Warnings: 2\n\ntest> select * from t;\n+------+------+\n| a    | b    |\n+------+------+\n|    5 |    5 |\n|    1 |    1 |\n|    3 |    3 |\n+------+------+\n3 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating TiFlash Replicas for Databases in TiDB\nDESCRIPTION: This SQL command creates a specified number of TiFlash replicas for all tables in a given database. The 'count' parameter determines the number of replicas, with 0 deleting existing replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nALTER DATABASE db_name SET TIFLASH REPLICA count;\n```\n\n----------------------------------------\n\nTITLE: Creating TiFlash Replicas for Tables in TiDB (SQL)\nDESCRIPTION: This SQL snippet demonstrates how to create TiFlash replicas for the `catalog_sales` and `date_dim` tables to prepare them for join operations leveraging the Runtime Filter feature.\nSOURCE: https://github.com/pingcap/docs/blob/master/runtime-filter.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE catalog_sales SET tiflash REPLICA 1;\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE date_dim SET tiflash REPLICA 1;\n```\n\n----------------------------------------\n\nTITLE: Complete DROP STATS Example Workflow\nDESCRIPTION: Complete example showing table creation, statistics verification, dropping stats, and verification of stats removal.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-stats.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a INT);\n\nSHOW STATS_META WHERE db_name='test' and table_name='t';\n\nDROP STATS t;\n\nSHOW STATS_META WHERE db_name='test' and table_name='t';\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Connection in Django Settings\nDESCRIPTION: Python code snippet for configuring the database connection to TiDB in the Django settings file.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nDATABASES = {\n    \"default\": {\n        \"ENGINE\": \"django_tidb\",\n        \"HOST\": ${tidb_host},\n        \"PORT\": ${tidb_port},\n        \"USER\": ${tidb_user},\n        \"PASSWORD\": ${tidb_password},\n        \"NAME\": ${tidb_db_name},\n        \"OPTIONS\": {\n            \"charset\": \"utf8mb4\",\n        },\n    }\n}\n\nTIDB_CA_PATH = ${ca_path}\nif TIDB_CA_PATH:\n    DATABASES[\"default\"][\"OPTIONS\"][\"ssl_mode\"] = \"VERIFY_IDENTITY\"\n    DATABASES[\"default\"][\"OPTIONS\"][\"ssl\"] = {\n        \"ca\": TIDB_CA_PATH,\n    }\n```\n\n----------------------------------------\n\nTITLE: Deploying MySQL using Docker in Shell\nDESCRIPTION: This command quickly deploys a MySQL instance using Docker. It sets the root password and maps port 3306 to the host.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-mysql.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -p 3306:3306 -d mysql\n```\n\n----------------------------------------\n\nTITLE: Configuring TiCDC CSV Protocol in TOML\nDESCRIPTION: This TOML configuration specifies the CSV protocol settings for TiCDC. It defines the sink protocol, terminator, delimiter, quote character, null representation, and options for including commit timestamps and old values.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-csv.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sink]\nprotocol = \"csv\"\nterminator = \"\\n\"\n\n[sink.csv]\ndelimiter = ',' # Before v7.6.0, you can only set the delimiter to a single character. Starting from v7.6.0, you can set it to 1-3 characters. For example, `$^` or `|@|`.\nquote = '\"'\nnull = '\\N'\ninclude-commit-ts = true\noutput-old-value = false\n```\n\n----------------------------------------\n\nTITLE: Checking DM Task Configuration with dmctl\nDESCRIPTION: Shell command for verifying a DM task configuration using the check-task command with tiup dmctl. This validates the task configuration before starting it.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\n[root@localhost ~]# tiup dmctl --master-addr 192.168.11.110:9261 check-task dm-task.yaml\n```\n\n----------------------------------------\n\nTITLE: Generating Private Key for Client Certificate\nDESCRIPTION: Command to generate a 2048-bit RSA private key for the client (dmctl) certificate.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nopenssl genrsa -out client-key.pem 2048\n```\n\n----------------------------------------\n\nTITLE: Connecting with custom user credentials to a TiDB Cloud Serverless branch\nDESCRIPTION: Example showing how to connect to a TiDB Cloud Serverless branch with custom username and password in non-interactive mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-shell.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch shell -c <cluster-id> -b <branch-id> -u <user-name> --password <password>\n```\n\n----------------------------------------\n\nTITLE: Pausing Changefeed Replication - Shell\nDESCRIPTION: A shell command to pause ongoing Changefeed replication in the cluster. This operation facilitates controlled transition phases like cluster swap or migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:${cluster_version} cdc changefeed pause --server http://${cdc_host}:${cdc_port} -c <changefeedid>\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into a Local Temporary Table in a New Session\nDESCRIPTION: Illustrates how to insert data into the local temporary table of a different session, maintaining data separation from other sessions.\nSOURCE: https://github.com/pingcap/docs/blob/master/temporary-tables.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO users(id, name, city) VALUES(1001, 'James', 'NewYork');\n```\n\n----------------------------------------\n\nTITLE: Checking THP Status\nDESCRIPTION: Command to check if Transparent Huge Pages (THP) is enabled or disabled in the system.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\ncat /sys/kernel/mm/transparent_hugepage/enabled\n```\n\n----------------------------------------\n\nTITLE: Insert Data into Unique Multi-Valued Index\nDESCRIPTION: These snippets demonstrate inserting data into a table with a unique multi-valued index. The first insert succeeds, while the second fails because it attempts to insert a duplicate value for the indexed field. Dependencies include a table with a unique multi-valued index.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nmysql> INSERT INTO customers VALUES (1, 'pingcap', '{\"zipcode\": [1,2]}');\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> INSERT INTO customers VALUES (1, 'pingcap', '{\"zipcode\": [2,3]}');\nERROR 1062 (23000): Duplicate entry '2' for key 'customers.zips'\n\n```\n\n----------------------------------------\n\nTITLE: Setting min-hot-query-rate for balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command sets the minimum number of queries to be counted as a hot region. The default value is usually 10.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_35\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-hot-region-scheduler set min-hot-query-rate 10\n```\n\n----------------------------------------\n\nTITLE: Exporting TiDB Table Statistics to a File\nDESCRIPTION: Example curl command to export statistics of table t1 in the test database to a JSON file.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\ncurl -s http://127.0.0.1:10080/stats/dump/test/t1 -o /tmp/t1.json\n```\n\n----------------------------------------\n\nTITLE: Comparing RANK() and DENSE_RANK() Window Functions in SQL\nDESCRIPTION: This snippet compares the RANK() and DENSE_RANK() functions, showing how RANK() leaves gaps in the ranking for ties while DENSE_RANK() provides consecutive ranks.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/window-functions.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    *,\n    RANK() OVER (ORDER BY n),\n    DENSE_RANK() OVER (ORDER BY n)\nFROM (\n    SELECT 5 AS 'n'\n    UNION ALL\n    SELECT 8\n    UNION ALL\n    SELECT 5\n    UNION ALL\n    SELECT 30\n    UNION ALL\n    SELECT 31\n    UNION ALL\n    SELECT 32) a;\n```\n\n----------------------------------------\n\nTITLE: Creating TiFlash Replicas for Tables in TiDB\nDESCRIPTION: This SQL command creates a specified number of TiFlash replicas for a given table. The 'count' parameter determines the number of replicas, with 0 deleting existing replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE table_name SET TIFLASH REPLICA count;\n```\n\n----------------------------------------\n\nTITLE: Example Block and Allow List Configuration for TiDB Data Migration\nDESCRIPTION: This YAML configuration demonstrates a practical example of using block and allow lists in TiDB Data Migration. It includes rules for filtering specific databases and tables using both wildcard patterns and regular expressions.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-block-allow-table-lists.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nblock-allow-list:  # Use black-white-list if the DM version is earlier than or equal to v2.0.0-beta.2.\n  bw-rule:\n    do-dbs: [\"forum_backup_2018\", \"forum\"]\n    ignore-dbs: [\"~^forum_backup_\"]\n    do-tables:\n    - db-name: \"logs\"\n      tbl-name: \"~_2018$\"\n    - db-name: \"~^forum.*\"\n      tbl-name: \"messages\"\n    ignore-tables:\n    - db-name: \"~.*\"\n      tbl-name: \"^messages.*\"\n```\n\n----------------------------------------\n\nTITLE: Setting Cost Model Version 2 in TiDB\nDESCRIPTION: SQL command to enable the Cost Model Version 2 in TiDB, which provides more accurate cost estimation for query optimization. This model helps the optimizer choose optimal execution plans, especially when TiFlash is deployed.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.5.0.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ntidb_cost_model_version = 2\n```\n\n----------------------------------------\n\nTITLE: Creating a Placement Policy SQL\nDESCRIPTION: The SQL statement creates a placement policy to configure data placement in TiDB. It specifies primary and secondary regions for Raft Leaders and Followers.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY myplacementpolicy PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\";\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_plan_cache_for_subquery in TiDB\nDESCRIPTION: Enables caching plans for queries that include subqueries, optimizing performance for complex query structures. Default is ON.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_39\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): No\n- Type: Boolean\n- Default value: `ON`\n- This variable controls whether Prepared Plan Cache caches queries that contain subqueries.\n```\n\n----------------------------------------\n\nTITLE: Publishing a Custom Component to TiUP Mirror\nDESCRIPTION: Publishes a previously packaged custom component to the configured TiUP mirror.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ntiup mirror publish hello v0.0.1 package/hello-v0.0.1-linux-amd64.tar.gz hello\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB for Disaggregated TiFlash in YAML\nDESCRIPTION: This YAML configuration enables querying TiFlash using the disaggregated storage and compute architecture. It should be added to the TiDB configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-disaggregated-and-s3.md#2025-04-18_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\ntidb:\ndisaggregated-tiflash: true\n```\n\n----------------------------------------\n\nTITLE: Using TIDB_SHARD for Index Hotspot Scattering in SQL\nDESCRIPTION: The `TIDB_SHARD()` function creates a shard index to scatter index hotspots, particularly useful for indexes with monotonically increasing or decreasing integer fields. It cannot be used in various query contexts such as inequality queries or composite indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_SHARD(12373743746);\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test(id INT PRIMARY KEY CLUSTERED, a INT, b INT, UNIQUE KEY uk((tidb_shard(a)), a));\n```\n\n----------------------------------------\n\nTITLE: UNION DISTINCT vs UNION ALL Operation\nDESCRIPTION: Shows the difference between UNION DISTINCT and UNION ALL operations, where DISTINCT removes duplicates while ALL keeps them.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/set-operators.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 UNION DISTINCT SELECT * FROM t2;\n\nSELECT * FROM t1 UNION ALL SELECT * FROM t2;\n```\n\n----------------------------------------\n\nTITLE: Defining PD etcd Write Latency Alert Rule in Prometheus\nDESCRIPTION: Alert rule to detect slow disk writes in etcd. Triggers when 99th percentile of fsync operations exceeds 1 second.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_7\n\nLANGUAGE: prometheus\nCODE:\n```\nhistogram_quantile(0.99, sum(rate(etcd_disk_wal_fsync_duration_seconds_bucket[1m])) by (instance, job, le)) > 1\n```\n\n----------------------------------------\n\nTITLE: Resuming TiCDC Replication Task\nDESCRIPTION: Command to resume a paused replication task.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed resume --server=http://10.0.10.25:8300 --changefeed-id simple-replication-task\n```\n\n----------------------------------------\n\nTITLE: Configuring Resource Control in TiKV\nDESCRIPTION: These YAML configuration options enable and control resource scheduling based on Request Units (RU) for user foreground read/write requests in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_34\n\nLANGUAGE: yaml\nCODE:\n```\nresource-control:\n  enabled: true\n  priority-ctl-strategy: \"moderate\"\n```\n\n----------------------------------------\n\nTITLE: Checksum Calculation Algorithm (Pseudocode)\nDESCRIPTION: Pseudocode representing the algorithm used for calculating checksums. It iterates through sorted columns, encodes each column value, and updates a CRC32 checksum.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-integrity-check.md#2025-04-18_snippet_4\n\nLANGUAGE: Pseudocode\nCODE:\n```\nfn checksum(columns) {\n    let result = 0\n    for column in sort_by_schema_order(columns) {\n        result = crc32.update(result, encode(column))\n    }\n    return result\n}\n```\n\n----------------------------------------\n\nTITLE: Loading TPC-C Test Data\nDESCRIPTION: Command to load test data into TiDB cluster with 1000 warehouses using 20 parallel threads. Connects to multiple TiDB servers for distributed loading.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-tpcc.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup bench tpcc -H 172.16.5.140,172.16.5.141 -P 4000 -D tpcc --warehouses 1000 --threads 20 prepare\n```\n\n----------------------------------------\n\nTITLE: SQL Mode Behavior with Warnings\nDESCRIPTION: Demonstrates how changing the SQL mode affects warning generation and handling of out-of-range values\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-warnings.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET sql_mode='';\nINSERT INTO t1 VALUES (-1);\nSHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: Displaying All Plugins in TiDB\nDESCRIPTION: This SQL example demonstrates how to use the `SHOW PLUGINS` statement without any filters to display all installed plugins in the TiDB instance. The output shows the plugin name, status, type, library path, license, and version.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-plugins.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"SHOW PLUGINS;\"\n```\n\n----------------------------------------\n\nTITLE: Running Sysbench Workload for Performance Testing\nDESCRIPTION: Bash command for running the sysbench read-only workload to benchmark TiDB performance with 200 concurrent threads against 1000 tables, used to compare baseline and optimized configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nsysbench oltp_read_only run --mysql-host={host} --mysql-port={port} --mysql-user=root --db-driver=mysql --mysql-db=test --threads=200 --time=900 --report-interval=10 --tables=1000 --table-size=10000\n```\n\n----------------------------------------\n\nTITLE: Creating Test Integer Table for Canal-JSON Update Event Example\nDESCRIPTION: SQL script to create a test table with multiple integer types to demonstrate TiCDC Canal-JSON update event behavior\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\ncreate table tp_int\\n(\\n    id          int auto_increment,\\n    c_tinyint   tinyint   null,\\n    c_smallint  smallint  null,\\n    c_mediumint mediumint null,\\n    c_int       int       null,\\n    c_bigint    bigint    null,\\n    constraint pk\\n        primary key (id)\\n);\\n\\ninsert into tp_int(c_tinyint, c_smallint, c_mediumint, c_int, c_bigint)\\nvalues (127, 32767, 8388607, 2147483647, 9223372036854775807);\\n\\nupdate tp_int set c_int = 0, c_tinyint = 0 where c_smallint = 32767;\n```\n\n----------------------------------------\n\nTITLE: Stop Log Backup Help Command\nDESCRIPTION: Shows help information for the log backup stop command including available flags and global options.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log stop --help\nstop a log backup task\n\nUsage:\n  br log stop [flags]\n\nFlags:\n  -h, --help           help for status\n  --task-name string   The task name for the backup log task.\n\nGlobal Flags:\n --ca string                  CA certificate path for TLS connection\n --cert string                Certificate path for TLS connection\n --key string                 Private key path for TLS connection\n -u, --pd strings             PD address (default [127.0.0.1:2379])\n```\n\n----------------------------------------\n\nTITLE: Describing VIEWS Table Structure in TiDB\nDESCRIPTION: This SQL snippet shows how to view the structure of the VIEWS table in the INFORMATION_SCHEMA database of TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-views.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC VIEWS;\n```\n\n----------------------------------------\n\nTITLE: Monitoring Software Interrupt Stats\nDESCRIPTION: Command to observe software interrupt statistics, helpful for determining if software interrupt handling is becoming a bottleneck.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n/proc/net/softnet_stat\n```\n\n----------------------------------------\n\nTITLE: Generating a New TiUP Key Pair\nDESCRIPTION: Creates a new private key for signing components in a TiUP mirror, stored in the default location.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ntiup mirror genkey\n```\n\n----------------------------------------\n\nTITLE: Database Restoration with Renaming in TiDB\nDESCRIPTION: Example demonstrating how to restore a dropped database with a new name using the FLASHBACK DATABASE statement with the TO clause, allowing recovery without name conflicts.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-database.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nDROP DATABASE test;\n```\n\nLANGUAGE: sql\nCODE:\n```\nFLASHBACK DATABASE test TO test1;\n```\n\n----------------------------------------\n\nTITLE: Sample Diagnostic Result Output\nDESCRIPTION: Example output showing cluster information, sampling details, and diagnostic results including configuration problems and rule violations. Shows how the tool identifies potential risks and provides links to knowledge base articles.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nStarting component `diag`: /root/.tiup/components/diag/v0.7.0/diag check diag-fNTnz5MGhr6\n\n# Diagnostic result\nlili 2022-01-24T09:33:57+08:00\n\n## 1. Cluster basic information\n- Cluster ID: 7047403704292855808\n- Cluster Name: lili\n- Cluster Version: v5.3.0\n\n## 2. Sampling information\n- Sample ID: fNTnz5MGhr6\n- Sampling Date: 2022-01-24T09:33:57+08:00\n- Sample Content:: [system monitor log config]\n\n## 3. Diagnostic result, including potential configuration problems\nIn this inspection, 22 rules were executed.\n\nThe results of **1** rules were abnormal and needed to be further discussed with support team.\n\nThe following is the details of the abnormalities.\n\n### Diagnostic result summary\nThe configuration rules are all derived from PingCAP's OnCall Service.\n\nIf the results of the configuration rules are found to be abnormal, they may cause the cluster to fail.\n\nThere were **1** abnormal results.\n\n#### Path to save the diagnostic result file\n\nRule Name: tidb-max-days\n- RuleID: 100\n- Variation: TidbConfig.log.file.max-days\n- For more information, please visit: https://s.tidb.io/msmo6awg\n- Check Result:\n  TidbConfig_172.16.7.87:4000   TidbConfig.log.file.max-days:0   warning\n  TidbConfig_172.16.7.86:4000   TidbConfig.log.file.max-days:0   warning\n  TidbConfig_172.16.7.179:4000   TidbConfig.log.file.max-days:0   warning\n\nResult report and record are saved at diag-fNTnz5MGhr6/report-220125153215\n```\n\n----------------------------------------\n\nTITLE: Error Example: Using Incompatible ALGORITHM Assertion\nDESCRIPTION: SQL statement showing an error that occurs when specifying ALGORITHM=INSTANT for an operation (adding an index) that requires the INPLACE algorithm in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t1 ADD INDEX (c1), ALGORITHM=INSTANT;\n```\n\n----------------------------------------\n\nTITLE: Comment Syntax Differences\nDESCRIPTION: This snippet describes how comment syntax differs between Oracle and TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_30\n\nLANGUAGE: sql\nCODE:\n```\n--Comment\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Comment\n```\n\n----------------------------------------\n\nTITLE: ALTER SEQUENCE SQL Syntax\nDESCRIPTION: SQL syntax for the ALTER SEQUENCE statement in TiDB, showing the complete command format with all available options for modifying sequence properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-sequence.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER SEQUENCE sequence_name\n    [ INCREMENT [ BY | = ] increment ]\n    [ MINVALUE [=] minvalue | NO MINVALUE | NOMINVALUE ]\n    [ MAXVALUE [=] maxvalue | NO MAXVALUE | NOMAXVALUE ]\n    [ START [ WITH | = ] start ]\n    [ CACHE [=] cache | NOCACHE | NO CACHE]\n    [ CYCLE | NOCYCLE | NO CYCLE]\n    [table_options]\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into a Table\nDESCRIPTION: SQL statement to insert three rows with different ID values into the example table t1.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-table.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t1 VALUES (1),(2),(3);\n```\n\n----------------------------------------\n\nTITLE: MyBatis Stream Reading Java Annotation Configuration\nDESCRIPTION: Java annotation-based configuration for enabling streaming result sets in MyBatis using Options annotation.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_11\n\nLANGUAGE: java\nCODE:\n```\n@Select(\"select * from post\")\n@Options(fetchSize = Integer.MIN_VALUE)\nCursor<Post> queryAllPost();\n```\n\n----------------------------------------\n\nTITLE: Disk Read Latency Alert Rule\nDESCRIPTION: PromQL query to monitor disk read latency, alerting when it exceeds 32ms\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_22\n\nLANGUAGE: promql\nCODE:\n```\n((rate(node_disk_read_time_seconds_total{device=~\".+\"}[5m]) / rate(node_disk_reads_completed_total{device=~\".+\"}[5m])) or (irate(node_disk_read_time_seconds_total{device=~\".+\"}[5m]) / irate(node_disk_reads_completed_total{device=~\".+\"}[5m])) ) * 1000 > 32\n```\n\n----------------------------------------\n\nTITLE: Explain Output for Merge Join in SQL\nDESCRIPTION: This shows the output from the `EXPLAIN` statement, illustrating the query plan when merge join is used. The output shows the MergeJoin operator, the tables involved (t1 and t2), and the join keys (t1.id and t2.id).\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\n+-----------------------------+-----------+-----------+---------------+-------------------------------------------------------+\n| id                          | estRows   | task      | access object | operator info                                         |\n+-----------------------------+-----------+-----------+---------------+-------------------------------------------------------+\n| MergeJoin_7                 | 142020.00 | root      |               | inner join, left key:test.t1.id, right key:test.t2.id |\n| ├─TableReader_12(Build)     | 180000.00 | root      |               | data:TableFullScan_11                                 |\n| │ └─TableFullScan_11        | 180000.00 | cop[tikv] | table:t2      | keep order:true                                       |\n| └─TableReader_10(Probe)     | 142020.00 | root      |               | data:TableFullScan_9                                  |\n|   └─TableFullScan_9         | 142020.00 | cop[tikv] | table:t1      | keep order:true                                       |\n+-----------------------------+-----------+-----------+---------------+-------------------------------------------------------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Task Info Schema Name in TiDB Lightning with TOML\nDESCRIPTION: TOML configuration for changing the default database name where TiDB Lightning stores error information. The default name is 'lightning_task_info'.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\ntask-info-schema-name = 'lightning_task_info'\n```\n\n----------------------------------------\n\nTITLE: Defining ShowEnginesStmt in EBNF\nDESCRIPTION: This EBNF diagram snippet defines the grammar for the 'SHOW ENGINES' SQL statement, used to list supported storage engines in TiDB. Optional LIKE and WHERE clauses can refine engine filtering. Compatible with MySQL's syntax for broader applicability.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-engines.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\nShowEnginesStmt ::= \n    \"SHOW\" \"ENGINES\" ShowLikeOrWhere?\n\nShowLikeOrWhere ::= \n    \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud Serverless Cluster in Interactive Mode\nDESCRIPTION: This snippet showcases connecting to a TiDB Cloud Serverless cluster in interactive mode. The command prompts the user for the necessary information, such as cluster ID, username, and password.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-shell.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless shell\n```\n\n----------------------------------------\n\nTITLE: tiup cluster audit cleanup Syntax\nDESCRIPTION: This code snippet shows the basic syntax for using the `tiup cluster audit cleanup` command. It accepts optional flags to customize its behavior. No specific dependencies are required beyond the TiUP cluster management tool.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-audit-cleanup.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster audit cleanup [flags]\"\n```\n\n----------------------------------------\n\nTITLE: Querying with AUTO_RANDOM Primary Key in TiDB\nDESCRIPTION: Example of creating a table with AUTO_RANDOM primary key and querying it with left shift operation to maintain order. This approach helps avoid write hotspots while preserving query order capabilities.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-best-practices.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a bigint PRIMARY KEY AUTO_RANDOM, b varchar(255));\nSelect a, a<<5 ,b from t order by a <<5 desc\n```\n\n----------------------------------------\n\nTITLE: Executing SQL Admin Checksum on Tables\nDESCRIPTION: This SQL command is used to calculate and verify checksum values for tables in the database. It helps in ensuring data integrity during the import process. No additional dependencies are needed apart from access to the required database. Input is specified table name, and output is the checksum values for the table. Note that this is only applicable to imported data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nADMIN CHECKSUM TABLE `schema`.`table`;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+---------+------------+---------------------+-----------+-------------+\n| Db_name | Table_name | Checksum_crc64_xor  | Total_kvs | Total_bytes |\n+---------+------------+---------------------+-----------+-------------+\n| schema  | table      | 5505282386844578743 |         3 |          96 |\n+---------+------------+---------------------+-----------+-------------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying Region Distribution with SHOW TABLE REGIONS in TiDB SQL\nDESCRIPTION: Added support for the SHOW TABLE REGIONS statement to query the Region distribution of a table through SQL statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.15.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW TABLE REGIONS\n```\n\n----------------------------------------\n\nTITLE: Viewing Capture Tasks Example\nDESCRIPTION: Shows how to view ongoing capture tasks and their results in the mysql.plan_replayer_task table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-replayer.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nmysql> PLAN REPLAYER CAPTURE 'example_sql' 'example_plan';\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> SELECT * FROM mysql.plan_replayer_task;\n+-------------+--------------+---------------------+\n| sql_digest  | plan_digest  | update_time         |\n+-------------+--------------+---------------------+\n| example_sql | example_plan | 2023-01-28 11:58:22 |\n+-------------+--------------+---------------------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with SHARD_ROW_ID_BITS in TiDB\nDESCRIPTION: Demonstrates how to create a table with SHARD_ROW_ID_BITS set to 4, which helps distribute row IDs across 16 shards to alleviate write hotspots.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-hot-spot-issues.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (c int) SHARD_ROW_ID_BITS = 4;\n```\n\n----------------------------------------\n\nTITLE: Resume Task Example Command\nDESCRIPTION: Example command showing how to resume a task with an optional source specification.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-resume-task.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nresume-task [-s \"mysql-replica-01\"] task-name\n```\n\n----------------------------------------\n\nTITLE: Configuring Snapshot Sampling Interval\nDESCRIPTION: SQL command to set the snapshot sampling interval to 15 minutes (900 seconds).\nSOURCE: https://github.com/pingcap/docs/blob/master/workload-repository.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_workload_repository_snapshot_interval = 900;\n```\n\n----------------------------------------\n\nTITLE: Adding table_storage_stats System Table in TiDB\nDESCRIPTION: Introduces a new system table called table_storage_stats, which provides storage statistics for tables in the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.8.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM table_storage_stats;\n```\n\n----------------------------------------\n\nTITLE: Setting Memory Quota Query in TiDB\nDESCRIPTION: SQL command to configure the memory quota of a SQL statement to 1GB using bit shift operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-memory-usage.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_mem_quota_query = 1 << 30;\n```\n\n----------------------------------------\n\nTITLE: Defining SQL Mode in TiDB Lightning TOML Configuration\nDESCRIPTION: This TOML configuration adjusts the SQL mode to enforce stricter data validation by TiDB Lightning. The specified 'STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION' mode prohibits invalid data from being imported. This setting should be defined in the [tidb] section of the tidb-lighting.toml configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[tidb]\nsql-mode = \"STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION\"\n```\n\n----------------------------------------\n\nTITLE: Listing Available TiUP Components\nDESCRIPTION: A TiUP command to list all available components that can be managed via TiUP in the TiDB ecosystem. This facilitates identifying the components available for installation or management.\nSOURCE: https://github.com/pingcap/docs/blob/master/migration-tools.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup list\n```\n\n----------------------------------------\n\nTITLE: Replication Configuration Parameters\nDESCRIPTION: Settings for managing replica counts and topology configurations in TiKV clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-configuration-file.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nreplication:\n  max-replicas: 3\n  location-labels: []\n  isolation-level: \"\"\n```\n\n----------------------------------------\n\nTITLE: Disabling GC in TiDB\nDESCRIPTION: This SQL command disables garbage collection (GC) in the upstream TiDB cluster to prevent deletion of newly written data during migration while maintaining access to historical data.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nMySQL [test]> SET GLOBAL tidb_gc_enable=FALSE;\n\n```\nQuery OK, 0 rows affected (0.01 sec)\n```\n```\n\n----------------------------------------\n\nTITLE: TiUP Cluster Restart Command Syntax\nDESCRIPTION: Basic syntax for the tiup cluster restart command. The command requires a cluster name parameter and accepts optional flags for customizing the restart operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-restart.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster restart <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Defining SET ROLE Statement Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the SET ROLE statement in TiDB SQL. It specifies the various options for setting roles, including DEFAULT, ALL, NONE, or specific role names.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-role.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nSetRoleStmt ::=\n    \"SET\" \"ROLE\" ( \"DEFAULT\" | \"ALL\" ( \"EXCEPT\" Rolename (\",\" Rolename)* )? | \"NONE\" | Rolename (\",\" Rolename)* )?\n```\n\n----------------------------------------\n\nTITLE: Listing Export Tasks in JSON Format - Shell\nDESCRIPTION: This snippet displays how to list export tasks for a specified cluster in JSON format. It utilizes both the `-c` flag for specifying the cluster ID and the `-o json` flag for output format.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-list.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export list -c <cluster-id> -o json\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Pre-Split Regions in TiDB SQL\nDESCRIPTION: Uses the pre_split_regions option in CREATE TABLE statements to pre-split Table Regions, avoiding write hot spots caused by intensive writes after table creation.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.0-rc.1.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t1 (id INT) pre_split_regions=4;\n```\n\n----------------------------------------\n\nTITLE: Explain Output with Disabled Subquery Pre-Execution\nDESCRIPTION: Output from EXPLAIN after disabling subquery pre-execution, showing the full execution plan including the scalar subquery operators.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\n+---------------------------+----------+-----------+---------------+---------------------------------+\n| id                        | estRows  | task      | access object | operator info                   |\n+---------------------------+----------+-----------+---------------+---------------------------------+\n| Selection_13              | 8000.00  | root      |               | eq(test.t2.a, ScalarQueryCol#5) |\n| └─TableReader_15          | 10000.00 | root      |               | data:TableFullScan_14           |\n|   └─TableFullScan_14      | 10000.00 | cop[tikv] | table:t2      | keep order:false, stats:pseudo  |\n| ScalarSubQuery_10         | N/A      | root      |               | Output: ScalarQueryCol#5        |\n| └─MaxOneRow_6             | 1.00     | root      |               |                                 |\n|   └─TableReader_9         | 1.00     | root      |               | data:TableFullScan_8            |\n|     └─TableFullScan_8     | 1.00     | cop[tikv] | table:t1      | keep order:false, stats:pseudo  |\n+---------------------------+----------+-----------+---------------+---------------------------------+\n7 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Running Sysbench Test for Result Set Performance Comparison (Bash)\nDESCRIPTION: This snippet executes a Sysbench test to evaluate the performance of TiProxy and HAProxy under varying row numbers in result sets. It uses a 100-thread configuration and aims to produce different QPS results based on the specified row sizes. Requires Sysbench and MySQL database access.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-performance-test.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsysbench oltp_read_only \\\n    --threads=100 \\\n    --time=1200 \\\n    --report-interval=10 \\\n    --rand-type=uniform \\\n    --db-driver=mysql \\\n    --mysql-db=sbtest \\\n    --mysql-host=$host \\\n    --mysql-port=$port \\\n    --skip_trx=true \\\n    --point_selects=0 \\\n    --sum_ranges=0 \\\n    --order_ranges=0 \\\n    --distinct_ranges=0 \\\n    --simple_ranges=1 \\\n    --range_size=$range_size\n    run --tables=32 --table-size=1000000\n```\n\n----------------------------------------\n\nTITLE: Data Preparation using TiUP Demo Command\nDESCRIPTION: Shell command to prepare sample data for the bookshop schema using TiUP demo tool. Creates tables with specified number of users, books, authors, ratings and orders.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-hybrid-oltp-and-olap-queries.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup demo bookshop prepare --users=200000 --books=500000 --authors=100000 --ratings=1000000 --orders=1000000 --host 127.0.0.1 --port 4000 --drop-tables\n```\n\n----------------------------------------\n\nTITLE: Modifying Account Locking Policy for Existing User in TiDB\nDESCRIPTION: This SQL command alters the account locking policy for an existing user 'test2'@'localhost'. The account will be locked indefinitely after 4 consecutive failed login attempts until manually unlocked.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_31\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER 'test2'@'localhost' FAILED_LOGIN_ATTEMPTS 4 PASSWORD_LOCK_TIME UNBOUNDED;\n```\n\n----------------------------------------\n\nTITLE: Create TiCDC Changefeed for Kafka Replication\nDESCRIPTION: This command creates a TiCDC changefeed to replicate data to Apache Kafka.  It configures the connection to the TiCDC server, specifies the Kafka sink URI (including brokers, topic, protocol, Kafka version, partitions, message size, and replication factor), and sets a unique ID for the replication task.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create \\\n    --server=http://10.0.10.25:8300 \\\n    --sink-uri=\"kafka://127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094/topic-name?protocol=canal-json&kafka-version=2.4.0&partition-num=6&max-message-bytes=67108864&replication-factor=1\" \\\n    --changefeed-id=\"simple-replication-task\"\n```\n\n----------------------------------------\n\nTITLE: TiCDC Simple Protocol - DDL Message (ALTER)\nDESCRIPTION: This snippet shows an example of a DDL message in JSON format using the TiCDC Simple protocol. It represents an ALTER TABLE statement, including details such as the protocol version, event type, SQL statement, commit timestamp, build timestamp, and before/after table schemas. This message structure provides comprehensive information about the schema change.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-simple-protocol.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"version\":1,\n   \"type\":\"ALTER\",\n   \"sql\":\"ALTER TABLE `user` ADD COLUMN `createTime` TIMESTAMP\",\n   \"commitTs\":447987408682614795,\n   \"buildTs\":1708936343598,\n   \"tableSchema\":{\n      \"schema\":\"simple\",\n      \"table\":\"user\",\n      \"tableID\":148,\n      \"version\":447987408682614791,\n      \"columns\":[\n         {\n            \"name\":\"id\",\n            \"dataType\":{\n               \"mysqlType\":\"int\",\n               \"charset\":\"binary\",\n               \"collate\":\"binary\",\n               \"length\":11\n            },\n            \"nullable\":false,\n            \"default\":null\n         },\n         {\n            \"name\":\"name\",\n            \"dataType\":{\n               \"mysqlType\":\"varchar\",\n               \"charset\":\"utf8mb4\",\n               \"collate\":\"utf8mb4_bin\",\n               \"length\":255\n            },\n            \"nullable\":true,\n            \"default\":null\n         },\n         {\n            \"name\":\"age\",\n            \"dataType\":{\n               \"mysqlType\":\"int\",\n               \"charset\":\"binary\",\n               \"collate\":\"binary\",\n               \"length\":11\n            },\n            \"nullable\":true,\n            \"default\":null\n         },\n         {\n            \"name\":\"score\",\n            \"dataType\":{\n               \"mysqlType\":\"float\",\n               \"charset\":\"binary\",\n               \"collate\":\"binary\",\n               \"length\":12\n            },\n            \"nullable\":true,\n            \"default\":null\n         },\n         {\n            \"name\":\"createTime\",\n            \"dataType\":{\n               \"mysqlType\":\"timestamp\",\n               \"charset\":\"binary\",\n               \"collate\":\"binary\",\n               \"length\":19\n            },\n            \"nullable\":true,\n            \"default\":null\n         }\n      ],\n      \"indexes\":[\n         {\n            \"name\":\"primary\",\n            \"unique\":true,\n            \"primary\":true,\n            \"nullable\":false,\n            \"columns\":[\n               \"id\"\n            ]\n         }\n      ]\n   },\n   \"preTableSchema\":{\n      \"schema\":\"simple\",\n      \"table\":\"user\",\n      \"tableID\":148,\n      \"version\":447984074911121426,\n      \"columns\":[\n         {\n            \"name\":\"id\",\n            \"dataType\":{\n               \"mysqlType\":\"int\",\n               \"charset\":\"binary\",\n               \"collate\":\"binary\",\n               \"length\":11\n            },\n            \"nullable\":false,\n            \"default\":null\n         },\n         {\n            \"name\":\"name\",\n            \"dataType\":{\n               \"mysqlType\":\"varchar\",\n               \"charset\":\"utf8mb4\",\n               \"collate\":\"utf8mb4_bin\",\n               \"length\":255\n            },\n            \"nullable\":true,\n            \"default\":null\n         },\n         {\n            \"name\":\"age\",\n            \"dataType\":{\n               \"mysqlType\":\"int\",\n               \"charset\":\"binary\",\n               \"collate\":\"binary\",\n               \"length\":11\n            },\n            \"nullable\":true,\n            \"default\":null\n         },\n         {\n            \"name\":\"score\",\n            \"dataType\":{\n               \"mysqlType\":\"float\",\n               \"charset\":\"binary\",\n               \"collate\":\"binary\",\n               \"length\":12\n            },\n            \"nullable\":true,\n            \"default\":null\n         }\n      ],\n      \"indexes\":[\n         {\n            \"name\":\"primary\",\n            \"unique\":true,\n            \"primary\":true,\n            \"nullable\":false,\n            \"columns\":[\n               \"id\"\n            ]\n         }\n      ]\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Even Split Example with Integer Range in TiDB\nDESCRIPTION: SQL example for splitting a table into 16 evenly distributed regions across the entire Int64 range in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nSPLIT TABLE t BETWEEN (-9223372036854775808) AND (9223372036854775807) REGIONS 16;\n```\n\n----------------------------------------\n\nTITLE: NGINX Reverse Proxy Configuration\nDESCRIPTION: NGINX configuration for reverse proxying TiDB Dashboard on port 8033\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_4\n\nLANGUAGE: nginx\nCODE:\n```\nserver {\n    listen 8033;\n    location /dashboard/ {\n    proxy_pass http://192.168.0.123:2379/dashboard/;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: DM Task Configuration\nDESCRIPTION: YAML configuration for defining a TiDB DM migration task with source and target details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nname: tiup-playground-task\ntask-mode: \"all\"\n\nmysql-instances:\n  - source-id: \"mysql-01\"\n\ntarget-database:\n  host: \"127.0.0.1\"\n  port: 4000\n  user: \"root\"\n  password: \"\"\n```\n\n----------------------------------------\n\nTITLE: SQL Normalization Example\nDESCRIPTION: This example illustrates how TiDB normalizes SQL statements before matching them against bound execution plans. Constants are converted to variable parameters, and database names are explicitly specified.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM users WHERE balance >    100\n-- After normalization, the above statement is as follows:\nSELECT * FROM bookshop . users WHERE balance > ?\n```\n\n----------------------------------------\n\nTITLE: Using IGNORE_INDEX Hint in TiDB SQL\nDESCRIPTION: Example of using the IGNORE_INDEX hint to tell the optimizer to avoid using specific indexes when querying a table. This is equivalent to the IGNORE INDEX syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_30\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ IGNORE_INDEX(t1, idx1, idx2) */ * from t t1;\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Password in TiDB\nDESCRIPTION: SQL syntax for creating a new user with a password. The CREATE USER statement establishes a new user account with optional IF NOT EXISTS clause and password authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER [IF NOT EXISTS] user [IDENTIFIED BY 'auth_string'];\n```\n\n----------------------------------------\n\nTITLE: Creating Dashboard Admin User with SEM\nDESCRIPTION: SQL commands to create a dashboard admin user with minimum required privileges when Security Enhanced Mode is enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-user.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'dashboardAdmin'@'%' IDENTIFIED BY '<YOUR_PASSWORD>';\nGRANT PROCESS, CONFIG ON *.* TO 'dashboardAdmin'@'%';\nGRANT SHOW DATABASES ON *.* TO 'dashboardAdmin'@'%';\nGRANT DASHBOARD_CLIENT ON *.* TO 'dashboardAdmin'@'%';\nGRANT RESTRICTED_STATUS_ADMIN ON *.* TO 'dashboardAdmin'@'%';\nGRANT RESTRICTED_TABLES_ADMIN ON *.* TO 'dashboardAdmin'@'%';\nGRANT RESTRICTED_VARIABLES_ADMIN ON *.* TO 'dashboardAdmin'@'%';\n\n-- To modify the configuration items on the interface after signing in to TiDB Dashboard, the user-defined SQL user must be granted with the following privilege.\nGRANT SYSTEM_VARIABLES_ADMIN ON *.* TO 'dashboardAdmin'@'%';\n\n-- To use the Fast Bind Executions Plan feature on the interface after signing in to TiDB Dashboard, the user-defined SQL user must be granted with the following privileges.\nGRANT SYSTEM_VARIABLES_ADMIN ON *.* TO 'dashboardAdmin'@'%';\nGRANT SUPER ON *.* TO 'dashboardAdmin'@'%';\n```\n\n----------------------------------------\n\nTITLE: Using RECOVER TABLE for Truncated Tables in TiDB 4.0 RC\nDESCRIPTION: TiDB 4.0 RC enhances the RECOVER TABLE syntax to support recovering truncated tables. This feature allows users to restore tables that have been accidentally truncated.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-rc.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\n-- Example of recovering a truncated table\nRECOVER TABLE truncated_table;\n```\n\n----------------------------------------\n\nTITLE: Verifying Default Role in TiDB\nDESCRIPTION: SQL commands to verify that the default role is active for the user jennifer without explicitly setting it.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-role.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS;\nSHOW TABLES IN test;\n```\n\n----------------------------------------\n\nTITLE: Checking TiFlash Replication Progress\nDESCRIPTION: This section explains how to monitor the data replication progress to TiFlash replicas after restoring a downstream cluster using PITR. The data replication to TiFlash replicas is not immediate; you need to wait and check the progress using the `INFORMATION_SCHEMA.tiflash_replica` table. This helps determine when TiFlash is ready to serve queries after a restore operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n\"ALTER TABLE table_name SET TIFLASH REPLICA ***\"\n```\n\n----------------------------------------\n\nTITLE: Calculating and Verifying Checksums - TiCDC - Go\nDESCRIPTION: The function `CalculateAndVerifyChecksum` calculates and verifies checksum values, ensuring data integrity for TiCDC. It uses predefined column types and their values to compute checksums and assess discrepancies against expected values. Prerequisites include obtaining `valueMap` and `valueSchema`. The function iterates columns, categorizes types, and computes checksums using the CRC32 algorithm. Note constraints like future support for additional TiDB types.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-checksum-verification.md#2025-04-18_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nfunc CalculateAndVerifyChecksum(valueMap, valueSchema map[string]interface{}) error {\n    // The fields variable stores the column type information for each data change event. The column IDs are used to sort the fields, which is the same as the order in which the checksum is calculated.\n    fields, ok := valueSchema[\"fields\"].([]interface{})\n    if !ok {\n        return errors.New(\"schema fields should be a map\")\n    }\n\n    // 1. Get the expected checksum value from valueMap, which is encoded as a string.\n    // If the expected checksum value is not found, it means that the checksum feature is not enabled when TiCDC sends the data. In this case, this function returns directly.\n    o, ok := valueMap[\"_tidb_row_level_checksum\"]\n    if !ok {\n        return nil\n    }\n    expected := o.(string)\n    if expected == \"\" {\n        return nil\n    }\n\n    // expectedChecksum is the expected checksum value passed from TiCDC.\n    expectedChecksum, err := strconv.ParseUint(expected, 10, 64)\n    if err != nil {\n        return errors.Trace(err)\n    }\n\n    // 2. Iterate over each field and calculate the checksum value.\n    var actualChecksum uint32\n    // buf stores the byte slice used to update the checksum value each time.\n    buf := make([]byte, 0)\n    for _, item := range fields {\n        field, ok := item.(map[string]interface{})\n        if !ok {\n            return errors.New(\"schema field should be a map\")\n        }\n\n        // The tidbOp and subsequent columns are not involved in the checksum calculation, because they are used to assist data consumption and not real TiDB column data.\n        colName := field[\"name\"].(string)\n        if colName == \"_tidb_op\" {\n            break\n        }\n\n        // The holder variable stores the type information of each column.\n        var holder map[string]interface{}\n        switch ty := field[\"type\"].(type) {\n        case []interface{}:\n            for _, item := range ty {\n                if m, ok := item.(map[string]interface{}); ok {\n                    holder = m[\"connect.parameters\"].(map[string]interface{})\n                    break\n                }\n            }\n        case map[string]interface{}:\n            holder = ty[\"connect.parameters\"].(map[string]interface{})\n        default:\n            log.Panic(\"type info is anything else\", zap.Any(\"typeInfo\", field[\"type\"]))\n        }\n        tidbType := holder[\"tidb_type\"].(string)\n\n        mysqlType := mysqlTypeFromTiDBType(tidbType)\n\n        // Get the value of each column from the decoded value map according to the name of each column.\n        value, ok := valueMap[colName]\n        if !ok {\n            return errors.New(\"value not found\")\n        }\n        value, err := getColumnValue(value, holder, mysqlType)\n        if err != nil {\n            return errors.Trace(err)\n        }\n\n        if len(buf) > 0 {\n            buf = buf[:0]\n        }\n\n        // Generate a byte slice used to update the checksum according to the value and mysqlType of each column, and then update the checksum value.\n        buf, err = buildChecksumBytes(buf, value, mysqlType)\n        if err != nil {\n            return errors.Trace(err)\n        }\n        actualChecksum = crc32.Update(actualChecksum, crc32.IEEETable, buf)\n    }\n\n    if uint64(actualChecksum) != expectedChecksum {\n        log.Error(\"checksum mismatch\",\n            zap.Uint64(\"expected\", expectedChecksum),\n            zap.Uint64(\"actual\", uint64(actualChecksum)))\n        return errors.New(\"checksum mismatch\")\n    }\n\n    log.Info(\"checksum verified\", zap.Uint64(\"checksum\", uint64(actualChecksum)))\n    return nil\n}\n```\n\n----------------------------------------\n\nTITLE: Querying KEY_COLUMN_USAGE Table Structure in SQL\nDESCRIPTION: This SQL snippet demonstrates how to examine the structure of the KEY_COLUMN_USAGE table in the information_schema database, showing all columns and their data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-key-column-usage.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC key_column_usage;\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP Bench Component\nDESCRIPTION: Command to install the bench component using TiUP package manager for running CH-benCHmark tests.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-ch.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup install bench\n```\n\n----------------------------------------\n\nTITLE: Markdown Table - Dumpling CLI Options\nDESCRIPTION: Detailed table listing all available command line options for the Dumpling tool, including their usage and default values. Covers functionality like database connection, export filtering, concurrent processing, logging, and output formatting.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_14\n\nLANGUAGE: markdown\nCODE:\n```\n| Options                      | Usage                                                                                                                                                                                                                                                                                                                              | Default value                              |\n| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------ |\n| `-V` or `--version`          | Output the Dumpling version and exit directly                                                                                                                                                                                                                                                                      |\n| `-B` or `--database`         | Export specified databases                                                                                                                                                                                                                                                                                         |\n| `-T` or `--tables-list`      | Export specified tables                                                                                                                                                                                                                                                                                            |\n| `-f` or `--filter`           | Export tables that match the filter pattern. For the filter syntax, see [table-filter](/table-filter.md).                                                                                                                                                                                                          |    `[\\*\\.\\*,!/^(mysql\\|sys\\|INFORMATION_SCHEMA\\|PERFORMANCE_SCHEMA\\|METRICS_SCHEMA\\|INSPECTION_SCHEMA)$/\\.\\*]` |\n| `--case-sensitive`           | whether table-filter is case-sensitive                                                                                                                                                                                                                                                                             | false (case-insensitive)                   |\n| `-h` or `--host`             | The IP address of the connected database host                                                                                                                                                                                                                                                                      | \"127.0.0.1\"                                |\n| `-t` or `--threads`          | The number of concurrent backup threads                                                                                                                                                                                                                                                                            | 4                                          |\n```\n\n----------------------------------------\n\nTITLE: Creating Table Structure in MySQL/TiDB\nDESCRIPTION: Demonstrates the table structure used in the cost model example, showing a table 't' with three integer columns and two indexes on columns 'b' and 'c'.\nSOURCE: https://github.com/pingcap/docs/blob/master/cost-model.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW CREATE TABLE t;\n+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Table | Create Table                                                                                                                                                                                        |\n+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| t     | CREATE TABLE `t` (\n  `a` int DEFAULT NULL,\n  `b` int DEFAULT NULL,\n  `c` int DEFAULT NULL,\n  KEY `b` (`b`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin |\n+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: DROP TABLE SQL Usage Examples\nDESCRIPTION: Examples demonstrating various DROP TABLE operations including dropping regular tables, handling non-existent tables, and showing warnings.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-table.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (a INT);\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> DROP TABLE t1;\nQuery OK, 0 rows affected (0.22 sec)\n\nmysql> DROP TABLE table_not_exists;\nERROR 1051 (42S02): Unknown table 'test.table_not_exists'\n\nmysql> DROP TABLE IF EXISTS table_not_exists;\nQuery OK, 0 rows affected, 1 warning (0.01 sec)\n\nmysql> SHOW WARNINGS;\n+-------+------+---------------------------------------+\n| Level | Code | Message                               |\n+-------+------+---------------------------------------+\n| Note  | 1051 | Unknown table 'test.table_not_exists' |\n+-------+------+---------------------------------------+\n1 row in set (0.01 sec)\n\nmysql> CREATE VIEW v1 AS SELECT 1;\nQuery OK, 0 rows affected (0.10 sec)\n\nmysql> DROP TABLE v1;\nQuery OK, 0 rows affected (0.23 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying Rounded Values in TiDB\nDESCRIPTION: Demonstrates the ROUND() function behavior with exact and approximate values in TiDB, showing differences from MySQL for approximate values.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/precision-math.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT ROUND(2.5), ROUND(25E-1);\n```\n\n----------------------------------------\n\nTITLE: Setting AUTO_ID_CACHE Size with Table Option\nDESCRIPTION: This snippet demonstrates how to set the cache size for allocating auto-increment IDs using the AUTO_ID_CACHE table option introduced in TiDB v3.0.14, v3.1.2, and v4.0.rc-2.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a int AUTO_INCREMENT key) AUTO_ID_CACHE 100;\nQuery OK, 0 rows affected (0.02 sec)\n\nINSERT INTO t values();\nQuery OK, 1 row affected (0.00 sec)\n\nSELECT * FROM t;\n+---+\n| a |\n+---+\n| 1 |\n+---+\n1 row in set (0.01 sec)\n\nSHOW CREATE TABLE t;\n+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Table | Create Table                                                                                                                                                                                                                             |\n+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| t     | CREATE TABLE `t` (\n  `a` int NOT NULL AUTO_INCREMENT,\n  PRIMARY KEY (`a`) /*T![clustered_index] CLUSTERED */\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin AUTO_INCREMENT=101 /*T![auto_id_cache] AUTO_ID_CACHE=100 */ |\n+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying Data from TiDB (TypeScript)\nDESCRIPTION: Retrieves a single Player record by ID from the database. Uses a prepared statement with a parameterized query for security.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst [rows] = await pool.query('SELECT id, coins, goods FROM players WHERE id = ?;', [1]);\nconsole.log(rows[0]);\n```\n\n----------------------------------------\n\nTITLE: Deleting Data with GORM in Golang\nDESCRIPTION: Deletes a Player record from the database using GORM's Delete method.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-golang-gorm.md#2025-04-18_snippet_4\n\nLANGUAGE: Go\nCODE:\n```\ndb.Delete(&Player{ID: \"id\"})\n```\n\n----------------------------------------\n\nTITLE: Using BR Restore with Table Filters\nDESCRIPTION: Example of using table filters with BR restore tool to restore schemas matching 'foo*' and 'bar*' patterns\nSOURCE: https://github.com/pingcap/docs/blob/master/table-filter.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full -f 'foo*.*' -f 'bar*.*' -s 'local:///tmp/backup'\n```\n\n----------------------------------------\n\nTITLE: Querying Available Prometheus Metric Prefixes\nDESCRIPTION: Command to retrieve available metric prefixes from the TiDB monitoring API using curl and jq.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl -s 'http://${prometheus-host}:${prometheus-port}/api/v1/label/__name__/values' | jq -r '.data[]' | cut -d\\_ -f1 | uniq -c | sort -rn\n```\n\n----------------------------------------\n\nTITLE: Force TiFlash Replica Usage with Hint in TiDB\nDESCRIPTION: This SQL query uses a manual hint to force TiDB to use TiFlash replicas for a specific table. The `read_from_storage(tiflash[table_name])` hint instructs the optimizer to utilize TiFlash for the specified table.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-htap-cluster.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ read_from_storage(tiflash[table_name]) */ ... from table_name;\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for TiDB and OpenAI\nDESCRIPTION: Sets up environment variables for TiDB connection string and OpenAI API key using secure input prompts to avoid exposing sensitive information.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Use getpass to securely prompt for environment variables in your terminal.\nimport getpass\nimport os\n\n# Copy your connection string from the TiDB Cloud console.\n# Connection string format: \"mysql+pymysql://<USER>:<PASSWORD>@<HOST>:4000/<DB>?ssl_ca=/etc/ssl/cert.pem&ssl_verify_cert=true&ssl_verify_identity=true\"\ntidb_connection_string = getpass.getpass(\"TiDB Connection String:\")\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n```\n\n----------------------------------------\n\nTITLE: Checking Foreign Key Invalidity in TiDB with SHOW CREATE TABLE\nDESCRIPTION: This snippet allows users to check for ineffective foreign keys in TiDB using the SHOW CREATE TABLE statement. It highlights the usage of a comment indicating the foreign key is invalid, especially relevant for TiDB versions before v6.6.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW CREATE TABLE child\\G\n***************************[ 1. row ]***************************\nTable        | child\nCreate Table | CREATE TABLE `child` (\n  `id` int DEFAULT NULL,\n  `pid` int DEFAULT NULL,\n  KEY `idx_pid` (`pid`),\n  CONSTRAINT `fk_1` FOREIGN KEY (`pid`) REFERENCES `test`.`parent` (`id`) ON DELETE CASCADE /* FOREIGN KEY INVALID */\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\n\n```\n\n----------------------------------------\n\nTITLE: Forcing MPP Mode in TiDB\nDESCRIPTION: This SQL snippet configures TiDB to ignore the optimizer's cost estimation and forcibly select the MPP mode for query executions by setting both 'tidb_allow_mpp' and 'tidb_enforce_mpp' to 1.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tiflash-mpp-mode.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nset @@session.tidb_allow_mpp=1;\nset @@session.tidb_enforce_mpp=1;\n```\n\n----------------------------------------\n\nTITLE: Setting and Using Roles in TiDB\nDESCRIPTION: SQL commands demonstrating how to set and use roles, including showing grants and accessing tables with different permissions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-role.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS;\nSHOW TABLES in test;\nSET ROLE analyticsteam;\nSHOW GRANTS;\nSHOW TABLES IN test;\n```\n\n----------------------------------------\n\nTITLE: Executing ticloud help Command in Shell\nDESCRIPTION: This command retrieves help information for any command in TiDB Cloud CLI. It takes an optional command argument and flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-help.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud help [command] [flags]\n```\n\n----------------------------------------\n\nTITLE: Adding Named Partitions in SQL\nDESCRIPTION: This SQL snippet demonstrates how to add named partitions with comments to a Hash partitioned table.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_42\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE example ADD PARTITION\n(PARTITION pExample4 COMMENT = 'not p3, but pExample4 instead',\n PARTITION pExample5 COMMENT = 'not p4, but pExample5 instead');\n```\n\n----------------------------------------\n\nTITLE: Creating Table with MySQL Compatible Auto-Increment\nDESCRIPTION: Creates a table with auto-increment primary key using MySQL compatibility mode (AUTO_ID_CACHE 1) for minimal gaps between IDs.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a int AUTO_INCREMENT key) AUTO_ID_CACHE 1;\n```\n\n----------------------------------------\n\nTITLE: Defining LONGTEXT Column in TiDB\nDESCRIPTION: Syntax for creating a LONGTEXT column supporting up to 4,294,967,295 bytes with character set options.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nLONGTEXT [CHARACTER SET charset_name] [COLLATE collation_name]\n```\n\n----------------------------------------\n\nTITLE: Configuring TiCDC Servers in TiUP Deployment File\nDESCRIPTION: Example YAML configuration for deploying TiCDC servers with a TiDB cluster using TiUP. Specifies host addresses, garbage collection TTL, and data directories for two TiCDC nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/deploy-ticdc.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc_servers:\n  - host: 10.0.1.20\n    gc-ttl: 86400\n    data_dir: \"/cdc-data\"\n  - host: 10.0.1.21\n    gc-ttl: 86400\n    data_dir: \"/cdc-data\"\n```\n\n----------------------------------------\n\nTITLE: Alter a resource group to cancel the runaway query check\nDESCRIPTION: This SQL statement alters the existing resource group 'rg1' to remove the runaway query check by setting QUERY_LIMIT to NULL. This disables the active monitoring and handling of runaway queries for the specified resource group.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\n\"ALTER RESOURCE GROUP rg1 QUERY_LIMIT=NULL;\"\n```\n\n----------------------------------------\n\nTITLE: Disabling Garbage Collection in TiDB using SQL\nDESCRIPTION: These SQL commands disable garbage collection in TiDB and verify the change. This is necessary before exporting full data to ensure newly written data is not deleted during incremental migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-mysql.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_enable=FALSE;\nSELECT @@global.tidb_gc_enable;\n```\n\n----------------------------------------\n\nTITLE: Changefeed Configuration Parameters for Pulsar\nDESCRIPTION: This code snippet illustrates a TOML configuration file (`changefeed config`) used to configure TiCDC's behavior when replicating data to Pulsar. It allows customization of various aspects such as dispatchers for routing messages, protocol selection (canal-json), and Pulsar-specific settings like authentication and producer cache size.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[sink]\n# `dispatchers` is used to specify matching rules.\n# Note: When the downstream MQ is Pulsar, if the routing rule for `partition` is not specified as any of `ts`, `index-value`, `table`, or `default`, each Pulsar message will be routed using the string you set as the key.\n# For example, if you specify the routing rule for a matcher as the string `code`, then all Pulsar messages that match that matcher will be routed with `code` as the key.\n# dispatchers = [\n#    {matcher = ['test1.*', 'test2.*'], topic = \"Topic expression 1\", partition = \"ts\" },\n#    {matcher = ['test3.*', 'test4.*'], topic = \"Topic expression 2\", partition = \"index-value\" },\n#    {matcher = ['test1.*', 'test5.*'], topic = \"Topic expression 3\", partition = \"table\"},\n#    {matcher = ['test6.*'], partition = \"default\"},\n#    {matcher = ['test7.*'], partition = \"test123\"}\n# ]\n\n# `protocol` is used to specify the protocol format for encoding messages.\n# When the downstream is Pulsar, the protocol can only be canal-json.\n# protocol = \"canal-json\"\n\n# The following parameters only take effect when the downstream is Pulsar.\n[sink.pulsar-config]\n# Authentication on the Pulsar server is done using a token. Specify the value of the token.\nauthentication-token = \"xxxxxxxxxxxxx\"\n# When you use a token for Pulsar server authentication, specify the path to the file where the token is located.\ntoken-from-file=\"/data/pulsar/token-file.txt\"\n# Pulsar uses the basic account and password to authenticate the identity. Specify the account.\nbasic-user-name=\"root\"\n# Pulsar uses the basic account and password to authenticate the identity. Specify the password.\nbasic-password=\"password\"\n# The certificate path on the client, which is required when Pulsar enables the mTLS authentication.\nauth-tls-certificate-path=\"/data/pulsar/certificate\"\n# The private key path on the client, which is required when Pulsar enables the mTLS authentication.\nauth-tls-private-key-path=\"/data/pulsar/certificate.key\"\n# The path to the trusted certificate file of the Pulsar TLS authentication, which is required when Pulsar enables the mTLS authentication or TLS encrypted transmission.\ntls-trust-certs-file-path=\"/data/pulsar/tls-trust-certs-file\"\n# The path to the encrypted private key on the client, which is required when Pulsar enables TLS encrypted transmission.\ntls-key-file-path=\"/data/pulsar/tls-key-file\"\n# The path to the encrypted certificate file on the client, which is required when Pulsar enables TLS encrypted transmission.\ntls-certificate-file=\"/data/pulsar/tls-certificate-file\"\n# Pulsar oauth2 issuer-url. For more information, see the Pulsar website: https://pulsar.apache.org/docs/2.10.x/client-libraries-go/#tls-encryption-and-authentication\noauth2.oauth2-issuer-url=\"https://xxxx.auth0.com\"\n# Pulsar oauth2 audience\noauth2.oauth2-audience=\"https://xxxx.auth0.com/api/v2/\"\n# Pulsar oauth2 private-key\noauth2.oauth2-private-key=\"/data/pulsar/privateKey\"\n# Pulsar oauth2 client-id\noauth2.oauth2-client-id=\"0Xx...Yyxeny\"\n# Pulsar oauth2 oauth2-scope\noauth2.oauth2-scope=\"xxxx\"\n# The number of cached Pulsar producers in TiCDC. The value is 10240 by default. Each Pulsar producer corresponds to one topic. If the number of topics you need to replicate is larger than the default value, you need to increase the number.\npulsar-producer-cache-size=10240\n# Pulsar data compression method. No compression is used by default. Optional values are \"lz4\", \"zlib\", and \"zstd\".\ncompression-type=\"\"\n# The timeout for the Pulsar client to establish a TCP connection with the server. The value is 5 seconds by default.\nconnection-timeout=5\n# The timeout for Pulsar clients to initiate operations such as creating and subscribing to a topic. The value is 30 seconds by default.\noperation-timeout=30\n# The maximum number of messages in a single batch for a Pulsar producer to send. The value is 1000 by default.\nbatching-max-messages=1000\n# The interval at which Pulsar producer messages are saved for batching. The value is 10 milliseconds by default.\nbatching-max-publish-delay=10\n# The timeout for a Pulsar producer to send a message. The value is 30 seconds by default.\nsend-timeout=30\n```\n\n----------------------------------------\n\nTITLE: Using MySQL-Compatible Comment Syntax with STRAIGHT_JOIN\nDESCRIPTION: Shows how to use MySQL-compatible comment syntax (/*!...*/) in TiDB to include executable SQL fragments within comments. This example uses STRAIGHT_JOIN to affect query execution plan.\nSOURCE: https://github.com/pingcap/docs/blob/master/comment-syntax.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*! STRAIGHT_JOIN */ col1 FROM table1,table2 WHERE ...\n```\n\n----------------------------------------\n\nTITLE: TIDB_CHECK_CONSTRAINTS Query Result Structure\nDESCRIPTION: Shows the output structure when querying the TIDB_CHECK_CONSTRAINTS table, displaying constraint details including catalog, schema, name, and check clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-check-constraints.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------+-------------+------+------+---------+-------+\n| Field              | Type        | Null | Key  | Default | Extra |\n+--------------------+-------------+------+------+---------+-------+\n| CONSTRAINT_CATALOG | varchar(64) | NO   |      | NULL    |       |\n| CONSTRAINT_SCHEMA  | varchar(64) | NO   |      | NULL    |       |\n| CONSTRAINT_NAME    | varchar(64) | NO   |      | NULL    |       |\n| CHECK_CLAUSE       | longtext    | NO   |      | NULL    |       |\n| TABLE_NAME         | varchar(64) | YES  |      | NULL    |       |\n| TABLE_ID           | bigint(21)  | YES  |      | NULL    |       |\n+--------------------+-------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Determining Action on Invalid Update Requests\nDESCRIPTION: This snippet explains how TiKV handles invalid `max-ts` update requests, detailing the configured actions like 'panic', 'error', or 'log' that can be triggered when the maximum timestamp rules are exceeded.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n+ Determines how TiKV handles invalid `max-ts` update requests. If a read or write request uses a timestamp that exceeds **the sum of the PD TSO cached in TiKV and [`max-drift`](#max-drift-new-in-v900)**, TiKV considers it an invalid `max-ts` update request. Invalid `max-ts` update requests might break the linearizability and transaction concurrency control semantics of the TiDB cluster.\n+ Value options:\n    + `\"panic\"`: TiKV panics. If the PD TSO cached in TiKV is not updated in time, TiKV uses an approximate method for validation, in which case invalid requests do not cause TiKV panic.\n    + `\"error\"`: TiKV returns an error and stops processing the request.\n    + `\"log\"`: TiKV prints an error log but still processes the request.\n+ Default value: `\"panic\"`\n```\n\n----------------------------------------\n\nTITLE: Query Specific Changefeed Status using CDC CLI\nDESCRIPTION: This command queries the status of a specific changefeed in a TiCDC cluster. It requires the address of the TiCDC server, the changefeed ID, and the capture ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli processor query --server=http://10.0.10.25:8300 --changefeed-id=simple-replication-task --capture-id=b293999a-4168-4988-a4f4-35d9589b226b\n```\n\n----------------------------------------\n\nTITLE: Creating Table Schema in TiDB\nDESCRIPTION: Creates a table with integer columns and defines primary key and secondary indexes\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (id int, a int, b int, c int, primary key(id), key(a), key(b, c))\n```\n\n----------------------------------------\n\nTITLE: Example Result Set for FULL GROUP BY Query\nDESCRIPTION: The result set from the FULL GROUP BY query showing student classes, names, and maximum course scores. This demonstrates a stable result set where the grouping is unambiguous, with one row per unique class and student name combination.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-unstable-result-set.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+------------+--------------+------------------+\n| class      | stuname      | max(b.courscore) |\n+------------+--------------+------------------+\n| 2018_CS_01 | MonkeyDLuffy |             95.5 |\n| 2018_CS_03 | PatrickStar  |             99.0 |\n| 2018_CS_03 | SpongeBob    |             95.0 |\n+------------+--------------+------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Killing a Blocking Transaction in TiDB\nDESCRIPTION: This SQL command uses the global KILL statement to terminate a transaction that is blocking a DDL operation. The session ID is obtained from the mysql.tidb_mdl_view.\nSOURCE: https://github.com/pingcap/docs/blob/master/metadata-lock.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nKILL 1547698182;\n```\n\n----------------------------------------\n\nTITLE: Retrieving Connection ID (SQL)\nDESCRIPTION: The `CONNECTION_ID()` function returns the unique ID of the current connection, facilitating the management of connections and queries in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/information-functions.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONNECTION_ID();\n```\n+-----------------+\n| CONNECTION_ID() |\n+-----------------+\n|       322961414 |\n+-----------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Using NO_ORDER_INDEX Hint in TiDB SQL\nDESCRIPTION: Example of using the NO_ORDER_INDEX hint to tell the optimizer to use a specific index but not to read it in order, resulting in a TopN execution plan.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_32\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a INT, b INT, key(a), key(b));\nEXPLAIN SELECT /*+ NO_ORDER_INDEX(t, a) */ a FROM t ORDER BY a LIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Using SHOW COLUMNS Statement as an Alternative\nDESCRIPTION: This SQL example demonstrates how to use the SHOW COLUMNS statement as an alternative to querying the INFORMATION_SCHEMA.COLUMNS table. This is a more concise way to view column information.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-columns.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLUMNS FROM t1 FROM test;\n```\n\n----------------------------------------\n\nTITLE: Using LASTVAL Function with Sequence\nDESCRIPTION: Shows how to use the LASTVAL() function to retrieve the last used value of a sequence in the current session.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-sequence.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LASTVAL(seq);\n```\n\n----------------------------------------\n\nTITLE: Creating a Local Temporary Table in TiDB\nDESCRIPTION: This snippet illustrates how to create a local temporary table in TiDB, which is session-specific and will not interfere with ordinary tables of the same name.\nSOURCE: https://github.com/pingcap/docs/blob/master/temporary-tables.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TEMPORARY TABLE users (\n    id BIGINT,\n    name VARCHAR(100),\n    city VARCHAR(50),\n    PRIMARY KEY(id)\n);\n```\n\n----------------------------------------\n\nTITLE: Verifying Current Version of TiUP Cluster - Shell\nDESCRIPTION: This command checks the current version of the TiUP cluster that is installed, which is useful for ensuring compatibility and functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup --binary cluster\n```\n\n----------------------------------------\n\nTITLE: Updating Data in TiDB with PyMySQL in Python\nDESCRIPTION: This code snippet demonstrates how to update data in a TiDB database using PyMySQL. It executes an UPDATE SQL statement to modify the 'goods' and 'coins' columns for a specific player.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-pymysql.md#2025-04-18_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nwith get_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        player_id, amount, price=\"1\", 10, 500\n        cursor.execute(\n            \"UPDATE players SET goods = goods + %s, coins = coins + %s WHERE id = %s\",\n            (-amount, price, player_id),\n        )\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating Airport Routes Table in SQL\nDESCRIPTION: Creates a table for storing airport route data and inserts sample data using SQL within a Python context.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# Create a table to store flight plan data.\nvector_store.tidb_vector_client.execute(\n    \"\"\"CREATE TABLE airplan_routes (\n        id INT AUTO_INCREMENT PRIMARY KEY,\n        airport_code VARCHAR(10),\n        airline_code VARCHAR(10),\n        destination_code VARCHAR(10),\n        route_details TEXT,\n        duration TIME,\n        frequency INT,\n        airplane_type VARCHAR(50),\n        price DECIMAL(10, 2),\n        layover TEXT\n    );\"\"\"\n)\n\n# Insert some sample data into airplan_routes and the vector table.\nvector_store.tidb_vector_client.execute(\n    \"\"\"INSERT INTO airplan_routes (\n        airport_code,\n        airline_code,\n        destination_code,\n        route_details,\n        duration,\n        frequency,\n        airplane_type,\n        price,\n        layover\n    ) VALUES\n    ('JFK', 'DL', 'LAX', 'Non-stop from JFK to LAX.', '06:00:00', 5, 'Boeing 777', 299.99, 'None'),\n    ('LAX', 'AA', 'ORD', 'Direct LAX to ORD route.', '04:00:00', 3, 'Airbus A320', 149.99, 'None'),\n    ('EFGH', 'UA', 'SEA', 'Daily flights from SFO to SEA.', '02:30:00', 7, 'Boeing 737', 129.99, 'None');\n    \"\"\"\n)\nvector_store.add_texts(\n    texts=[\n        \"Clean lounges and excellent vegetarian dining options. Highly recommended.\",\n        \"Comfortable seating in lounge areas and diverse food selections, including vegetarian.\",\n        \"Small airport with basic facilities.\",\n    ],\n    metadatas=[\n        {\"airport_code\": \"JFK\"},\n        {\"airport_code\": \"LAX\"},\n        {\"airport_code\": \"EFGH\"},\n    ],\n)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Detailed Airport Information Using SQL in Python\nDESCRIPTION: Extracts airport codes from search results and queries the database for detailed route information using SQL within a Python context.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n# Extracting airport codes from the metadata\nairport_codes = [review.metadata[\"airport_code\"] for review in reviews]\n\n# Executing a query to get the airport details\nsearch_query = \"SELECT * FROM airplan_routes WHERE airport_code IN :codes\"\nparams = {\"codes\": tuple(airport_codes)}\n\nairport_details = vector_store.tidb_vector_client.execute(search_query, params)\nairport_details.get(\"result\")\n```\n\n----------------------------------------\n\nTITLE: FLUSH STATUS Usage Example in TiDB\nDESCRIPTION: Example showing the usage of SHOW STATUS and FLUSH STATUS commands in TiDB, demonstrating that the flush operation has no effect on the status variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flush-status.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> show status;\n+--------------------+--------------------------------------+\n| Variable_name      | Value                                |\n+--------------------+--------------------------------------+\n| Ssl_cipher_list    |                                      |\n| server_id          | 93e2e07d-6bb4-4a1b-90b7-e035fae154fe |\n| ddl_schema_version | 141                                  |\n| Ssl_verify_mode    | 0                                    |\n| Ssl_version        |                                      |\n| Ssl_cipher         |                                      |\n+--------------------+--------------------------------------+\n6 rows in set (0.01 sec)\n\nmysql> show global status;\n+--------------------+--------------------------------------+\n| Variable_name      | Value                                |\n+--------------------+--------------------------------------+\n| Ssl_cipher         |                                      |\n| Ssl_cipher_list    |                                      |\n| Ssl_verify_mode    | 0                                    |\n| Ssl_version        |                                      |\n| server_id          | 93e2e07d-6bb4-4a1b-90b7-e035fae154fe |\n| ddl_schema_version | 141                                  |\n+--------------------+--------------------------------------+\n6 rows in set (0.00 sec)\n\nmysql> flush status;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> show status;\n+--------------------+--------------------------------------+\n| Variable_name      | Value                                |\n+--------------------+--------------------------------------+\n| Ssl_cipher         |                                      |\n| Ssl_cipher_list    |                                      |\n| Ssl_verify_mode    | 0                                    |\n| Ssl_version        |                                      |\n| ddl_schema_version | 141                                  |\n| server_id          | 93e2e07d-6bb4-4a1b-90b7-e035fae154fe |\n+--------------------+--------------------------------------+\n6 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Explaining Broadcast Join with MPP in SQL\nDESCRIPTION: This snippet provides an explanation of a Broadcast Join execution plan using the EXPLAIN statement in SQL. It highlights how data from a small table is distributed across multiple nodes in an MPP setting to perform join operations efficiently, utilizing the Broadcast exchange type.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-mpp.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT COUNT(*) FROM t1 a JOIN t1 b ON a.id = b.id;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------------------+---------+--------------+---------------+------------------------------------------------+\n| id                                     | estRows | task         | access object | operator info                                  |\n+----------------------------------------+---------+--------------+---------------+------------------------------------------------+\n| StreamAgg_15                           | 1.00    | root         |               | funcs:count(1)->Column#7                       |\n| └─TableReader_47                       | 9.00    | root         |               | data:ExchangeSender_46                         |\n|   └─ExchangeSender_46                  | 9.00    | cop[tiflash] |               | ExchangeType: PassThrough                      |\n|     └─HashJoin_43                      | 9.00    | cop[tiflash] |               | inner join, equal:[eq(test.t1.id, test.t1.id)] |\n|       ├─ExchangeReceiver_20(Build)     | 6.00    | cop[tiflash] |               |                                                |\n|       │ └─ExchangeSender_19            | 6.00    | cop[tiflash] |               | ExchangeType: Broadcast                        |\n|       │   └─Selection_18               | 6.00    | cop[tiflash] |               | not(isnull(test.t1.id))                        |\n|       │     └─TableFullScan_17         | 6.00    | cop[tiflash] | table:a       | keep order:false                               |\n|       └─Selection_22(Probe)            | 6.00    | cop[tiflash] |               | not(isnull(test.t1.id))                        |\n|         └─TableFullScan_21             | 6.00    | cop[tiflash] | table:b       | keep order:false                               |\n+----------------------------------------+---------+--------------+---------------+------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Configuring Import Settings in TiKV YAML\nDESCRIPTION: YAML configuration for TiKV import settings, including thread count, stream channel window, and memory usage ratio for PITR.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_28\n\nLANGUAGE: yaml\nCODE:\n```\nimport:\n  num-threads: 8\n  stream-channel-window: 128\n  memory-use-ratio: 0.3\n```\n\n----------------------------------------\n\nTITLE: Disabling Garbage Collection in TiDB\nDESCRIPTION: SQL commands to disable garbage collection in the upstream TiDB cluster and verify the setting.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_enable=FALSE;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@global.tidb_gc_enable;\n```\n\n----------------------------------------\n\nTITLE: Configuring Decoders for Custom Column Value Formatting in TypeScript\nDESCRIPTION: This snippet illustrates how to configure custom decoders for specific column types in the TiDB Cloud serverless driver. This allows for converting raw values to appropriate JavaScript types, facilitating easier data manipulation post-retrieval.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nimport { connect, ColumnType } from '@tidbcloud/serverless';\n\nconst conn = connect({\n  url: 'mysql://[username]:[password]@[host]/[database]',\n  decoders: {\n    // By default, TiDB Cloud serverless driver returns the BIGINT type as text value. This decoder converts BIGINT to the JavaScript built-in BigInt type.\n    [ColumnType.BIGINT]: (rawValue: string) => BigInt(rawValue),\n    \n    // By default, TiDB Cloud serverless driver returns the DATETIME type as the text value in the 'yyyy-MM-dd HH:mm:ss' format. This decoder converts the DATETIME text to the JavaScript native Date object.\n    [ColumnType.DATETIME]: (rawValue: string) => new Date(rawValue),\n  }\n});\n\n// You can also configure the decoder option at the SQL level to override the decoders with the same keys at the connection level.\nconn.execute(`select ...`, [], {\n  decoders: {\n    // ...\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Defining QUERY WATCH Statement in EBNF for TiDB\nDESCRIPTION: This snippet outlines the syntax for adding and removing queries from the watch list using the QUERY WATCH statement. It illustrates how to use options such as resource groups and actions to manage runaway queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-query-watch.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAddQueryWatchStmt ::=\n    \"QUERY\" \"WATCH\" \"ADD\" QueryWatchOptionList\n\nQueryWatchOptionList ::=\n    QueryWatchOption\n|   QueryWatchOptionList QueryWatchOption\n|   QueryWatchOptionList ',' QueryWatchOption\n\nQueryWatchOption ::=\n    \"RESOURCE\" \"GROUP\" ResourceGroupName\n|   \"RESOURCE\" \"GROUP\" UserVariable\n|   \"ACTION\" EqOpt ResourceGroupRunawayActionOption\n|   QueryWatchTextOption\n\nResourceGroupName ::=\n    Identifier\n|   \"DEFAULT\"\n\nResourceGroupRunawayActionOption ::=\n    DRYRUN\n|   COOLDOWN\n|   KILL\n|   \"SWITCH_GROUP\" '(' ResourceGroupName ')'\n\nQueryWatchTextOption ::=\n    \"SQL\" \"DIGEST\" SimpleExpr\n|   \"PLAN\" \"DIGEST\" SimpleExpr\n|   \"SQL\" \"TEXT\" ResourceGroupRunawayWatchOption \"TO\" SimpleExpr\n\nResourceGroupRunawayWatchOption ::=\n    \"EXACT\"\n|   \"SIMILAR\"\n|   \"PLAN\"\n\nDropQueryWatchStmt ::=\n    \"QUERY\" \"WATCH\" \"REMOVE\" NUM\n```\n\n----------------------------------------\n\nTITLE: Resuming TiCDC Changefeed\nDESCRIPTION: This command resumes a TiCDC replication task (changefeed) to retry executing a failed DDL statement in the downstream. It uses the cdc cli tool and requires specifying the changefeed ID and the address of the TiCDC server.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/troubleshoot-ticdc.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n\"cdc cli changefeed resume -c test-cf --server=http://127.0.0.1:8300\"\n```\n\n----------------------------------------\n\nTITLE: Defining TableConsumer Struct and Methods in Golang\nDESCRIPTION: This snippet introduces the `TableConsumer` struct which handles consumption from a particular table, including processing checkpoints and managing versions. The methods outlined manage file dispatch and DDL execution based on the consumer's state.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-storage-consumer-dev-guide.md#2025-04-18_snippet_2\n\nLANGUAGE: go\nCODE:\n```\ntype TableConsumer struct {\n  // This checkpoint indicates where this TableConsumer has consumed.\n  // Its initial value is ConsumerManager.Checkpoint.\n  // TableConsumer.Checkpoint is equal to TableVersionConsumer.Checkpoint.\n  Checkpoint int64\n\n  schema,table string\n  // Must be consumed sequentially according to the order of table versions.\n  verConsumers map[version int64]*TableVersionConsumer\n  currentVer, previousVer int64\n}\n\n// Send newly added files to the corresponding TableVersionConsumer.\n// For any DDL, assign a TableVersionConsumer for the new table version.\nfunc (tc *TableConsumer) Dispatch() {}\n\n// If DDL query is empty or its tableVersion is less than TableConsumer.Checkpoint,\n// - ignore this DDL, and consume the data under the table version.\n// Otherwise,\n// - execute the DDL first, and then consume the data under the table version.\n// - For tables that are dropped, auto-recycling is performed after the drop table DDL is executed.\nfunc (tc *TableConsumer) ExecuteDDL() {}\n```\n\n----------------------------------------\n\nTITLE: Viewing TiKV Store Status\nDESCRIPTION: This SQL command fetches the status of TiKV stores, providing insights into their capacity, available space, and uptime, which is essential for monitoring performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/post-installation-check.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nselect STORE_ID,ADDRESS,STORE_STATE,STORE_STATE_NAME,CAPACITY,AVAILABLE,UPTIME from INFORMATION_SCHEMA.TIKV_STORE_STATUS;\n```\n\n----------------------------------------\n\nTITLE: Using VEC_L2_DISTANCE Function in SQL\nDESCRIPTION: This SQL example demonstrates how to calculate the L2 distance (Euclidean distance) between two 2-dimensional vectors [0,3] and [4,0]. The function implements the formula √Σ(pi-qi)² and returns 5 as the distance between these vectors.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-functions-and-operators.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VEC_L2_DISTANCE('[0,3]', '[4,0]');\n```\n\n----------------------------------------\n\nTITLE: MySQL Mathematical Functions\nDESCRIPTION: Comprehensive set of mathematical functions for performing calculations including trigonometric, logarithmic, rounding, and other mathematical operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/numeric-functions-and-operators.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nABS()      # Absolute value\nACOS()     # Arc cosine\nASIN()     # Arc sine\nATAN()     # Arc tangent\nCEIL()     # Ceiling value\nCOS()      # Cosine\nEXP()      # Exponential\nFLOOR()    # Floor value\nLN()       # Natural logarithm\nLOG()      # Logarithm\nPI()       # Pi value\nPOW()      # Power\nRAND()     # Random value\nROUND()    # Round number\nSIGN()     # Sign of argument\nSQRT()     # Square root\nTRUNCATE() # Truncate decimal\n```\n\n----------------------------------------\n\nTITLE: Executing SQL Query with Runtime Filter in TiDB\nDESCRIPTION: This snippet executes a SQL query in TiDB that retrieves the cs_ship_date_sk from catalog_sales and date_dim tables, applying a runtime filter based on date matching. It directly illustrates the application of runtime filters in execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/runtime-filter.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT cs_ship_date_sk FROM catalog_sales, date_dim\nWHERE d_date = '2002-2-01' AND\n     cs_ship_date_sk = d_date_sk;\n```\n\n----------------------------------------\n\nTITLE: Encoding Key-Value Pairs for Non-Unique Index Data in TiDB\nDESCRIPTION: Illustrates the encoding method for non-unique index data in TiDB, which includes rowID in the key to ensure uniqueness.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-hot-spot-issues.md#2025-04-18_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nKey: tablePrefix{tableID}_indexPrefixSep{indexID}_indexedColumnsValue_rowID\nValue: null\n```\n\n----------------------------------------\n\nTITLE: Configuring AWS Glue Schema Registry in TiCDC with TOML\nDESCRIPTION: This TOML configuration snippet demonstrates how to configure TiCDC to use Avro as the protocol and integrate with AWS Glue Schema Registry. It requires specifying the region, registry name, access key, secret access key, and token.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-changefeed-config.md#2025-04-18_snippet_2\n\nLANGUAGE: TOML\nCODE:\n```\n\"region=\\\"us-west-1\\\"\\nregistry-name=\\\"ticdc-test\\\"\\naccess-key=\\\"xxxx\\\"\\nsecret-access-key=\\\"xxxx\\\"\\ntoken=\\\"xxxx\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Table Routing for DM Task in YAML\nDESCRIPTION: This YAML snippet shows how to set up table routing rules for a DM task. It defines mappings between source and target schemas and tables, supporting wildcard patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-task-configuration-guide.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nroutes:                           # The routing mapping rule set between the data source tables and downstream TiDB tables. You can set multiple rules at the same time.\n  route-rule-1:                   # The name of the routing mapping rule.\n    schema-pattern: \"test_*\"      # The pattern of the upstream schema name. Wildcard characters (*?) are supported.\n    table-pattern: \"t_*\"          # The pattern of the upstream table name. Wildcard characters (*?) are supported.\n    target-schema: \"test\"         # The name of the downstream TiDB schema.\n    target-table: \"t\"             # The name of the downstream TiDB table.\n  route-rule-2:\n    schema-pattern: \"test_*\"\n    target-schema: \"test\"\n```\n\n----------------------------------------\n\nTITLE: Altering User Password Expiration in SQL\nDESCRIPTION: SQL command to modify an existing user to set their password to expire every 90 days. This alters the account-level password expiration policy.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_15\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER 'test'@'localhost' PASSWORD EXPIRE INTERVAL 90 DAY;\n```\n\n----------------------------------------\n\nTITLE: Enabling Log Desensitization for TiDB\nDESCRIPTION: SQL command to enable log desensitization for TiDB by setting a variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0-rc.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_redact_log = 1;\n```\n\n----------------------------------------\n\nTITLE: Stream Aggregation with Index Optimization in TiDB\nDESCRIPTION: This SQL snippet adds an index to the `col1` column of table `t2` and then re-runs the `EXPLAIN` statement with `STREAM_AGG()`.  The output shows how the index eliminates the need for the `Sort` operator, thereby optimizing the stream aggregation.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-aggregation.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t2 ADD INDEX (col1);\nEXPLAIN SELECT /*+ STREAM_AGG() */ col1, count(*) FROM t2 GROUP BY col1;\n```\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.28 sec)\n\n+------------------------------+---------+-----------+----------------------------+----------------------------------------------------------------------------------------------------+\n| id                           | estRows | task      | access object              | operator info                                                                                      |\n+------------------------------+---------+-----------+----------------------------+----------------------------------------------------------------------------------------------------+\n| Projection_4                 | 4.00    | root      |                            | test.t2.col1, Column#3                                                                             |\n| └─StreamAgg_14               | 4.00    | root      |                            | group by:test.t2.col1, funcs:count(Column#4)->Column#3, funcs:firstrow(test.t2.col1)->test.t2.col1 |\n|   └─IndexReader_15           | 4.00    | root      |                            | index:StreamAgg_8                                                                                  |\n|     └─StreamAgg_8            | 4.00    | cop[tikv] |                            | group by:test.t2.col1, funcs:count(1)->Column#4                                                    |\n|       └─IndexFullScan_13     | 5.00    | cop[tikv] | table:t2, index:col1(col1) | keep order:true, stats:pseudo                                                                      |\n+------------------------------+---------+-----------+----------------------------+----------------------------------------------------------------------------------------------------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Checking Password Strength in TiDB SQL\nDESCRIPTION: These queries demonstrate the use of VALIDATE_PASSWORD_STRENGTH() function to check password strength. The function returns a value between 0 and 100, with higher values indicating stronger passwords.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_14\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT VALIDATE_PASSWORD_STRENGTH('');\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT VALIDATE_PASSWORD_STRENGTH('abcdef');\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT VALIDATE_PASSWORD_STRENGTH('abcdefghi');\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT VALIDATE_PASSWORD_STRENGTH('Abcdefghi');\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT VALIDATE_PASSWORD_STRENGTH('Abcdefghi123');\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT VALIDATE_PASSWORD_STRENGTH('Abcdefghi123%$#');\n```\n\n----------------------------------------\n\nTITLE: Displaying Help for start-task Command in TiDB Data Migration (Bash)\nDESCRIPTION: This command displays the help information for the `start-task` command, showing its usage, flags, and global flags. It's used to understand the options available when creating a data migration task.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-create-task.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhelp start-task\n```\n\n----------------------------------------\n\nTITLE: PD Initial Cluster Configuration Example\nDESCRIPTION: This snippet demonstrates the `initial-cluster` configuration parameter used for bootstrapping a PD cluster. It shows how to define the initial cluster configuration using the `name` and `advertise-peer-urls` parameters. This configuration is essential for setting up the initial cluster membership.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-configuration-file.md#2025-04-18_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n\"pd1=http://192.168.100.113:2380, pd2=http://192.168.100.114:2380, pd3=192.168.100.115:2380\"\n```\n\n----------------------------------------\n\nTITLE: Converting AUTO_INCREMENT to AUTO_RANDOM in TiDB SQL\nDESCRIPTION: SQL command to modify a BIGINT column from AUTO_INCREMENT to AUTO_RANDOM with a random bits value of 5. This helps avoid write hotspots in storage nodes by generating non-consecutive IDs.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-random.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t MODIFY COLUMN id BIGINT AUTO_RANDOM(5);\n```\n\n----------------------------------------\n\nTITLE: Enabling Password Complexity Check in TiDB SQL\nDESCRIPTION: This query enables the password complexity check by setting the validate_password.enable system variable to ON. This affects the behavior of the VALIDATE_PASSWORD_STRENGTH() function.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_12\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL validate_password.enable=ON;\n```\n\n----------------------------------------\n\nTITLE: Region Ranges After Table Creation with PRE_SPLIT_REGIONS\nDESCRIPTION: This snippet shows the ranges of the 4 table regions that are created after using PRE_SPLIT_REGIONS=2 with SHARD_ROW_ID_BITS=4. The regions are divided based on row ID boundaries to distribute data evenly.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_33\n\nLANGUAGE: text\nCODE:\n```\nregion1:   [ -inf      ,  1<<61 )\nregion2:   [ 1<<61     ,  2<<61 )\nregion3:   [ 2<<61     ,  3<<61 )\nregion4:   [ 3<<61     ,  +inf  )\n```\n\n----------------------------------------\n\nTITLE: Unlocking and Analyzing a Specific Partition in TiDB\nDESCRIPTION: This SQL snippet shows unlocking statistics for a specific partition (p1) with UNLOCK STATS PARTITION, allowing the ANALYZE statement to be successfully executed on that partition again.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nmysql> UNLOCK STATS t PARTITION p1;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> ANALYZE TABLE t PARTITION p1;\nQuery OK, 0 rows affected, 1 warning (0.01 sec)\n\nmysql> SHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: Atomic Table Swap Example\nDESCRIPTION: Example showing how to atomically swap tables without any downtime using RENAME TABLE.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-rename-table.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1(id int PRIMARY KEY);\nCREATE TABLE t1_new(id int PRIMARY KEY, n CHAR(0));\nRENAME TABLE t1 TO t1_old, t1_new TO t1;\n```\n\n----------------------------------------\n\nTITLE: Setting tidb_opt_range_max_size to 100 Bytes in TiDB\nDESCRIPTION: This SQL statement further reduces the tidb_opt_range_max_size to 100 bytes, severely limiting the memory available for building scan ranges.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_73\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_opt_range_max_size = 100;\n```\n\n----------------------------------------\n\nTITLE: Install Components via TiUP Shell Command\nDESCRIPTION: The provided shell commands allow the installation of specific TiDB platform components via TiUP. Users can install multiple components at once by listing them in the command. For example, 'tiup install dm' will only install the data migration manager component, whereas 'tiup install dm tidb-lightning' installs both the data migration manager and the TiDB Lightning tool used for data import.\nSOURCE: https://github.com/pingcap/docs/blob/master/migration-tools.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup install dm\n```\n\nLANGUAGE: shell\nCODE:\n```\ntiup install dm tidb-lightning\n```\n\n----------------------------------------\n\nTITLE: Splitting Table Regions in TiDB SQL\nDESCRIPTION: Improves the SPLIT TABLE syntax to generate N data regions and one index region when specifying the number of regions.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.17.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSPLIT TABLE ... REGIONS N\n```\n\n----------------------------------------\n\nTITLE: Getting Data Source Status with cURL in Shell\nDESCRIPTION: This example demonstrates how to retrieve the status of a specific data source by making a GET request to the DM API. The response includes information about relay logs and current stage.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/sources/mysql-replica-01/status' \\\n  -H 'accept: application/json'\n```\n\n----------------------------------------\n\nTITLE: Establishing password_reuse_interval in TiDB\nDESCRIPTION: This variable limits the reuse of passwords based on the time elapsed since their last usage, enforcing security protocols. Setting it to a positive integer defines the restriction period.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n-- Default value: `0`\n-- Range: `[0, 4294967295]`\nSET GLOBAL password_reuse_interval = 0;\n```\n\n----------------------------------------\n\nTITLE: Convert TSO to Human-Readable Time - SQL\nDESCRIPTION: Executes a query in TiDB to convert a TSO into a human-readable time format, aiding in comparing replication progress between upstream and downstream TiDB instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_PARSE_TSO(453880027545600000);\n```\n\n----------------------------------------\n\nTITLE: Listing Export Tasks for a Specified Cluster - Shell\nDESCRIPTION: This snippet shows how to list export tasks for a specified cluster in non-interactive mode using the `-c` flag. This command requires the cluster ID as an argument.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-list.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export list -c <cluster-id>\n```\n\n----------------------------------------\n\nTITLE: Creating Google Cloud Private Endpoint via Command Line\nDESCRIPTION: This command creates a Google Cloud Private Service Connect endpoint to connect to a TiDB Cloud Dedicated cluster. It uses parameters like project ID, VPC name, subnet name, and endpoint name provided by the user in the TiDB Cloud console.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-private-endpoint-connections-on-google-cloud.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngcloud compute addresses create [Private Service Connect Endpoint Name] \\\n    --global \\\n    --network=[Google Cloud VPC Name] \\\n    --prefix-length=16 \\\n    --purpose=PRIVATE_SERVICE_CONNECT\n```\n\n----------------------------------------\n\nTITLE: Querying ENGINES Table Data in SQL\nDESCRIPTION: This SQL query demonstrates how to retrieve all data from the ENGINES table in the information_schema database.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-engines.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM engines;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV to Reduce Stale Read Latency\nDESCRIPTION: TOML configuration for TiKV to modify the Resolved TS advancement interval, reducing Stale Read latency by making TiDB advance the timestamp more frequently. This may increase CPU usage and network traffic.\nSOURCE: https://github.com/pingcap/docs/blob/master/stale-read.md#2025-04-18_snippet_3\n\nLANGUAGE: TOML\nCODE:\n```\n[resolved-ts]\nadvance-ts-interval = \"20s\" # The default value is \"20s\". You can set it to a smaller value such as \"1s\" to advance the Resolved TS timestamp more frequently.\n```\n\n----------------------------------------\n\nTITLE: Configuring Gitpod Workspace with Custom Docker Image\nDESCRIPTION: This YAML configuration file sets up the Gitpod workspace using a custom Docker image defined in .gitpod.Dockerfile. It includes tasks for TiDB development and specifies port configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-playground-gitpod.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nimage:\n  file: .gitpod.Dockerfile\n\ntasks:\n  - name: Open Target File\n    command: |\n      if [ -n \"$targetFile\" ]; then code ${targetFile//[_]//};  fi\n  - name: TiUP init playground\n    command: |\n      $HOME/.tiup/bin/tiup playground\n  - name: Test Case\n    openMode: split-right\n    init: echo \"*** Waiting for TiUP Playground Ready! ***\"\n    command: |\n      gp await-port 3930\n      if [ \"$targetMode\" == \"plain-java-jdbc\" ]\n      then\n        cd plain-java-jdbc\n        code src/main/resources/dbinit.sql\n        code src/main/java/com/pingcap/JDBCExample.java\n        make mysql\n      elif [ \"$targetMode\" == \"plain-java-hibernate\" ]\n      then\n        cd plain-java-hibernate\n        make\n      elif [ \"$targetMode\" == \"spring-jpa-hibernate\" ]\n      then\n        cd spring-jpa-hibernate\n        make\n      fi\nports:\n  - port: 8080\n    visibility: public\n  - port: 4000\n    visibility: public\n  - port: 2379-36663\n    onOpen: ignore\n```\n\n----------------------------------------\n\nTITLE: Restoring TiDB Full Backup Data\nDESCRIPTION: This command restores a full backup from the specified S3 storage location to the TiDB cluster. This must be done before restoring any incremental backups that depend on this full backup.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-incremental-guide.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full --pd \"${PD_IP}:2379\" \\\n--storage \"s3://backup-101/snapshot-202209081330?access-key=${access-key}&secret-access-key=${secret-access-key}\"\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies from Requirements File\nDESCRIPTION: Command to install all the required Python packages for the demo project using a requirements file.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: SQL Backup Command with Disabled Credentials\nDESCRIPTION: SQL statement for backing up databases with disabled credential transfer to TiKV nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP DATABASE * TO 's3://bucket-name/prefix' SEND_CREDENTIALS_TO_TIKV = FALSE;\n```\n\n----------------------------------------\n\nTITLE: Stopping Services in TiDB DM Cluster using TiUP\nDESCRIPTION: This command stops services in a specified TiDB Data Migration (DM) cluster. It allows for stopping all services or targeting specific nodes and roles. The command outputs the log of the stopping process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-stop.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm stop <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Viewing Data Disk Information in Linux\nDESCRIPTION: Command to view the available data disks on the system using fdisk. This helps identify the NVMe disk that will be used for TiKV data storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nfdisk -l\n```\n\n----------------------------------------\n\nTITLE: Listing TiDB Cloud Serverless Clusters with CLI\nDESCRIPTION: Command to list all TiDB Cloud Serverless clusters in a project. It can be used with 'list' or its alias 'ls'. The command supports various flags for specifying project ID, output format, and other options.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-list.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless list [flags]\n```\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless ls [flags]\n```\n\n----------------------------------------\n\nTITLE: Revoking a Role from Multiple Users in TiDB\nDESCRIPTION: This snippet demonstrates how to revoke a role from multiple users in TiDB using the `REVOKE` statement. The operation is atomic, meaning if any part of the revocation fails, the entire operation rolls back. To execute this statement, the user needs the `SUPER` privilege.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE 'app_read' FROM 'read_user1'@'localhost', 'read_user2'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Configuring SASL/PLAIN Authentication in Kafka\nDESCRIPTION: This snippet shows how to configure Kafka SASL/PLAIN authentication by specifying the sink URI with the necessary parameters like Kafka version, user, password, and mechanism.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"kafka://127.0.0.1:9092/topic-name?kafka-version=2.4.0&sasl-user=alice-user&sasl-password=alice-secret&sasl-mechanism=plain\"\n```\n\n----------------------------------------\n\nTITLE: TiDB ADMIN RELOAD Statement\nDESCRIPTION: SQL statements for reloading expression pushdown blacklist and optimization rule blacklist.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nADMIN RELOAD expr_pushdown_blacklist;\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN RELOAD opt_rule_blacklist;\n```\n\n----------------------------------------\n\nTITLE: Setting PD Configuration Parameters\nDESCRIPTION: This snippet demonstrates how to use the 'config set' command to modify various configuration parameters such as snapshot count, pending peer count, and region merge settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nconfig set max-snapshot-count 64  // Set the maximum number of snapshots to 64\nconfig set max-pending-peer-count 64  // Set the maximum number of pending peers to 64\nconfig set max-merge-region-size 16 // Set the upper limit on the size of Region Merge to 16 MiB\nconfig set max-merge-region-keys 50000 // Set the upper limit on keyCount to 50000\nconfig set split-merge-interval 24h  // Set the interval between `split` and `merge` to one day\nconfig set enable-one-way-merge true  // Enables one-way merging.\nconfig set enable-cross-table-merge true  // Enable cross table merge.\nconfig set key-type raw  // Enable cross table merge.\nconfig set region-score-formula-version v2\nconfig set patrol-region-interval 10ms // Set the execution frequency of the checker to 10ms\nconfig set patrol-region-worker-count 2 // Set the checker concurrency to 2\nconfig set max-store-down-time 30m  // Set the time within which PD receives no heartbeats and after which PD starts to add replicas to 30 minutes\nconfig set max-store-preparing-time 4h\nconfig set leader-schedule-limit 4         // 4 tasks of leader scheduling at the same time at most\nconfig set region-schedule-limit 2         // 2 tasks of Region scheduling at the same time at most\nconfig set replica-schedule-limit 4        // 4 tasks of replica scheduling at the same time at most\nconfig set merge-schedule-limit 16       // 16 tasks of Merge scheduling at the same time at most\nconfig set hot-region-schedule-limit 4       // 4 tasks of hot Region scheduling at the same time at most\n```\n\n----------------------------------------\n\nTITLE: Configuring Topic Dispatcher for Kafka Sink\nDESCRIPTION: This TOML configuration snippet defines a topic dispatcher for the Kafka sink.  It configures how data is routed to different Kafka topics based on schema and table names, ensuring that each table's data resides in its dedicated topic when using the Avro protocol.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-protocol.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n[sink]\ndispatchers = [\n {matcher = ['*.*'], topic = \"tidb_{schema}_{table}\"},\n]\n```\n\n----------------------------------------\n\nTITLE: Creating a TiCDC Changefeed with Avro Protocol\nDESCRIPTION: This command creates a TiCDC changefeed using the Avro protocol for data replication. It specifies the Kafka broker address, topic name, schema registry URL, and a configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-protocol.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://127.0.0.1:8300 --changefeed-id=\"kafka-avro\" --sink-uri=\"kafka://127.0.0.1:9092/topic-name?protocol=avro\" --schema-registry=http://127.0.0.1:8081 --config changefeed_config.toml\n```\n\n----------------------------------------\n\nTITLE: Creating Another Local Temporary Table in a Different Session\nDESCRIPTION: Shows how a different session can also create a local temporary table with the same name as an ordinary table without conflict, allowing independent access within its session.\nSOURCE: https://github.com/pingcap/docs/blob/master/temporary-tables.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TEMPORARY TABLE users (\n    id BIGINT,\n    name VARCHAR(100),\n    city VARCHAR(50),\n    PRIMARY KEY(id)\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Incremental Replication Task in YAML\nDESCRIPTION: YAML configuration for creating an all mode (full + incremental) migration task in DM. It defines the target database, source details, and syncer settings for optimized incremental replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-performance-test.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n---\nname: test-all\ntask-mode: all\n\ntarget-database:\n  host: \"192.168.0.1\"\n  port: 4000\n  user: \"root\"\n  password: \"\"\n\nmysql-instances:\n  -\n    source-id: \"source-1\"\n    block-allow-list:  \"instance\"\n    syncer-config-name: \"global\"\n\nblock-allow-list:\n  instance:\n    do-dbs: [\"dm_benchmark\"]\n\nsyncers:\n  global:\n    worker-count: 16\n    batch: 100\n```\n\n----------------------------------------\n\nTITLE: Deploying DM Cluster with TiUP\nDESCRIPTION: Command to deploy a DM cluster using TiUP. Requires specifying cluster name, version, topology file, and SSH user. Optionally accepts SSH key or password for authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm deploy ${name} ${version} ./topology.yaml -u ${ssh_user} [-p] [-i /home/root/.ssh/gcp_rsa]\n```\n\n----------------------------------------\n\nTITLE: Using := Assignment Operator for User-Defined Variables\nDESCRIPTION: Demonstrates using the := assignment operator as an alternative to = when setting user-defined variables in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET @favorite_db := 'TiDB';\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed in Shell\nDESCRIPTION: This command creates a TiCDC changefeed to replicate incremental data from the upstream TiDB cluster to the downstream MySQL instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-mysql.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc:v<CLUSTER_VERSION> cli changefeed create --server=http://127.0.0.1:8300 --sink-uri=\"mysql://root:@127.0.0.1:3306\" --changefeed-id=\"upstream-to-downstream\" --start-ts=\"434217889191428107\"\n```\n\n----------------------------------------\n\nTITLE: Running go-tpc tpcc command to conduct stress tests using Shell\nDESCRIPTION: This shell command runs the `go-tpc tpcc` command to conduct stress tests on the TiDB Cloud Dedicated cluster.  It configures parameters like host, port, warehouse count, database, thread count, and test duration. This command measures the performance of the TiDB cluster under stress.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n\"go-tpc tpcc --host ${HOST} -P 4000 --warehouses 1000 run -D tpcc -T ${THREAD} --time 2h0m0s -p ${PASSWORD} --ignore-error\"\n```\n\n----------------------------------------\n\nTITLE: Creating and Modifying Table Structures in SQL\nDESCRIPTION: This SQL snippet demonstrates creating a table named t1, inserting data, and then modifying the column type using the ALTER TABLE statement in TiDB. It provides a practical example of applying the MODIFY COLUMN statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-modify-column.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id int not null primary key AUTO_INCREMENT, col1 INT);\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t1 (col1) VALUES (1),(2),(3),(4),(5);\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t1 MODIFY col1 BIGINT;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE t1\\G\n```\n\n----------------------------------------\n\nTITLE: Converting TopN to Limit with Primary Key Order\nDESCRIPTION: SQL example demonstrating how TopN can be simplified to a Limit operation when sorting by a primary key that can be read in order without extra sorting.\nSOURCE: https://github.com/pingcap/docs/blob/master/topn-limit-push-down.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id int primary key, a int not null);\ncreate table s(id int primary key, a int not null);\nexplain select * from t left join s on t.a = s.a order by t.id limit 10;\n```\n\n----------------------------------------\n\nTITLE: Detailed Region Information with Row and Index Data in TiDB\nDESCRIPTION: Advanced example showing Region information for a table, including both row data Regions and index data Regions. The output demonstrates how data is distributed across multiple Regions with different key ranges.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-regions.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW TABLE t REGIONS;\n+-----------+--------------+--------------+-----------+-----------------+---------------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n| REGION_ID | START_KEY    | END_KEY      | LEADER_ID | LEADER_STORE_ID | PEERS         | SCATTERING | WRITTEN_BYTES | READ_BYTES | APPROXIMATE_SIZE(MB) | APPROXIMATE_KEYS | SCHEDULING_CONSTRAINTS | SCHEDULING_STATE |\n+-----------+--------------+--------------+-----------+-----------------+---------------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n| 102       | t_43_r       | t_43_r_20000 | 118       | 7               | 105, 118, 119 | 0          | 0             | 0          | 1                    | 0                |                        |                  |\n| 106       | t_43_r_20000 | t_43_r_40000 | 120       | 7               | 107, 108, 120 | 0          | 23            | 0          | 1                    | 0                |                        |                  |\n| 110       | t_43_r_40000 | t_43_r_60000 | 112       | 9               | 112, 113, 121 | 0          | 0             | 0          | 1                    | 0                |                        |                  |\n| 114       | t_43_r_60000 | t_43_r_80000 | 122       | 7               | 115, 122, 123 | 0          | 35            | 0          | 1                    | 0                |                        |                  |\n| 3         | t_43_r_80000 |              | 93        | 8               | 5, 73, 93     | 0          | 0             | 0          | 1                    | 0                |                        |                  |\n| 98        | t_43_        | t_43_r       | 99        | 1               | 99, 100, 101  | 0          | 0             | 0          | 1                    | 0                |                        |                  |\n+-----------+--------------+--------------+-----------+-----------------+---------------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n6 rows in set\n```\n\n----------------------------------------\n\nTITLE: SQL Subquery to Join and Aggregation Conversion Example\nDESCRIPTION: Example demonstrating how the tidb_opt_insubq_to_join_and_agg optimizer rule converts a subquery into a join operation with aggregation, and a simpler form when the subquery column has unique and not null constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_55\n\nLANGUAGE: sql\nCODE:\n```\nselect * from t where t.a in (select aa from t1);\n```\n\nLANGUAGE: sql\nCODE:\n```\nselect t.* from t, (select aa from t1 group by aa) tmp_t where t.a = tmp_t.aa;\n```\n\nLANGUAGE: sql\nCODE:\n```\nselect t.* from t, t1 where t.a=t1.aa;\n```\n\n----------------------------------------\n\nTITLE: Enabling Marker Mode for Log Redaction in TiDB\nDESCRIPTION: This SQL command sets the global variable tidb_redact_log to MARKER, enabling marker mode for log redaction. In this mode, sensitive data is enclosed in '‹›' markers instead of being replaced.\nSOURCE: https://github.com/pingcap/docs/blob/master/log-redaction.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nset @@global.tidb_redact_log = MARKER;\n```\n\n----------------------------------------\n\nTITLE: TiDB ADMIN REPAIR Table Statement\nDESCRIPTION: SQL statement for repairing table metadata in untrusted mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nADMIN REPAIR TABLE tbl_name CREATE TABLE STATEMENT;\n```\n\n----------------------------------------\n\nTITLE: Example JSON Output Structure for Query Status\nDESCRIPTION: The JSON output provides detailed status information about the replication tasks associated with the DM cluster. It includes fields for result status, message, source statuses, and detailed sync information for each task.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_13\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"result\": true,\n   \"msg\": \"\",\n   \"sources\": [\n       {\n           \"result\": true,\n           \"msg\": \"\",\n           \"sourceStatus\": {\n               \"source\": \"mysql-replica-01\",\n               \"worker\": \"dm-192.168.11.111-9262\",\n               \"result\": null,\n               \"relayStatus\": null\n           },\n\n           \"subTaskStatus\": [\n               {\n                   \"name\": \"test-task1\",\n                   \"stage\": \"Running\",\n                   \"unit\": \"Sync\",\n                   \"result\": null,\n                   \"unresolvedDDLLockID\": \"\",\n                   \"sync\": {\n                       \"totalEvents\": \"4048\",\n                       \"totalTps\": \"3\",\n                       \"recentTps\": \"3\",\n                       \"masterBinlog\": \"(mysql-bin.000002, 246550002)\",\n                       \"masterBinlogGtid\": \"b631bcad-bb10-11ec-9eee-fec83cf2b903:1-194813\",\n                       \"syncerBinlog\": \"(mysql-bin.000002, 246550002)\",\n                       \"syncerBinlogGtid\": \"b631bcad-bb10-11ec-9eee-fec83cf2b903:1-194813\",\n                       \"blockingDDLs\": [\n                       ],\n                       \"unresolvedGroups\": [\n                       ],\n                       \"synced\": true,\n                       \"binlogType\": \"remote\",\n                       \"secondsBehindMaster\": \"0\",\n                       \"blockDDLOwner\": \"\",\n                       \"conflictMsg\": \"\"\n                   }\n               }\n           ]\n       },\n       {\n           \"result\": true,\n           \"msg\": \"\",\n           \"sourceStatus\": {\n               \"source\": \"mysql-replica-02\",\n               \"worker\": \"dm-192.168.11.112-9262\",\n               \"result\": null,\n               \"relayStatus\": null\n           },\n           \"subTaskStatus\": [\n               {\n                   \"name\": \"test-task1\",\n                   \"stage\": \"Running\",\n                   \"unit\": \"Sync\",\n                   \"result\": null,\n                   \"unresolvedDDLLockID\": \"\",\n                   \"sync\": {\n                       \"totalEvents\": \"33\",\n                       \"totalTps\": \"0\",\n                       \"recentTps\": \"0\",\n                       \"masterBinlog\": \"(mysql-bin.000001, 1316487)\",\n                       \"masterBinlogGtid\": \"cd21245e-bb10-11ec-ae16-fec83cf2b903:1-4048\",\n                       \"syncerBinlog\": \"(mysql-bin.000001, 1316487)\",\n                       \"syncerBinlogGtid\": \"cd21245e-bb10-11ec-ae16-fec83cf2b903:1-4048\",\n                       \"blockingDDLs\": [\n                       ],\n                       \"unresolvedGroups\": [\n                       ],\n                       \"synced\": true,\n                       \"binlogType\": \"remote\",\n                       \"secondsBehindMaster\": \"0\",\n                       \"blockDDLOwner\": \"\",\n                       \"conflictMsg\": \"\"\n                   }\n               }\n           ]\n       }\n   ]\n}\n```\n\n----------------------------------------\n\nTITLE: Example of SHOW GLOBAL STATUS Query in SQL\nDESCRIPTION: This SQL snippet illustrates the execution of the SHOW GLOBAL STATUS command, which retrieves the global status variables and their values in TiDB, maintaining compatibility with MySQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-status.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW GLOBAL STATUS;\n+-----------------------+--------------------------------------+ \n| Variable_name         | Value                                | \n+-----------------------+--------------------------------------+ \n| Ssl_cipher            |                                      | \n| Ssl_cipher_list       |                                      | \n| Ssl_server_not_after  |                                      | \n| Ssl_server_not_before |                                      | \n| Ssl_verify_mode       | 0                                    | \n| Ssl_version           |                                      | \n| Uptime                | 1413                                 | \n| ddl_schema_version    | 116                                  | \n| server_id             | 61160e73-ab80-40ff-8f33-27d55d475fd1 | \n+-----------------------+--------------------------------------+ \n9 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Updating Book Price in SQL\nDESCRIPTION: This SQL statement updates the price of a specific book in the 'books' table. It demonstrates how data can be modified, which is relevant to the Stale Read concept.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-stale-read.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nUPDATE books SET price = 150 WHERE id = 3181093216;\n```\n\n----------------------------------------\n\nTITLE: Check TiCDC Replication Progress - SQL\nDESCRIPTION: This SQL code runs on TiDB to check the TiCDC replication progress by converting the TSO to a human-readable format. It helps verify if replication is complete after upstream changes have stopped. Requires TiDB and a functioning TiCDC setup.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN;\nSELECT TIDB_PARSE_TSO(TIDB_CURRENT_TSO());\nROLLBACK;\n```\n\n----------------------------------------\n\nTITLE: Handle DDL Command Errors with Binlog Skip\nDESCRIPTION: This bash command is used to skip currently failed DDL statements in MySQL during migration, enabling the task to continue without interruption in the case of unsupported operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n» binlog skip test\n```\n\n----------------------------------------\n\nTITLE: Setting access token in Diag configuration\nDESCRIPTION: Command to configure the authentication token in Diag client for uploading diagnostic data to Clinic Server. The token ensures secure data isolation.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/quick-start-with-clinic.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag config clinic.token ${token-value}\n```\n\n----------------------------------------\n\nTITLE: Describing INSPECTION_RESULT Table Structure in SQL\nDESCRIPTION: SQL query to describe the structure of the information_schema.inspection_result table, showing the field names, types, and other metadata.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-result.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC inspection_result;\n```\n\n----------------------------------------\n\nTITLE: Querying runaway watches information schema\nDESCRIPTION: This SQL statement retrieves all rows from the `information_schema.runaway_watches` table, ordered by the `id` column. This allows the user to examine existing runaway query watch rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT * from information_schema.runaway_watches ORDER BY id\\G\"\n```\n\n----------------------------------------\n\nTITLE: TiProxy Cluster Configuration Example\nDESCRIPTION: This YAML configuration demonstrates how to configure TiProxy and TiDB servers with zone labels for location-based load balancing. It specifies the component versions, server configurations, and labels for each TiProxy, TiDB, TiKV, and PD instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-load-balance.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n\"component_versions:\n  tiproxy: \\\"v1.1.0\\\"\nserver_configs:\n  tidb:\n    graceful-wait-before-shutdown: 15\ntiproxy_servers:\n  - host: tiproxy-host-1\n    config:\n      labels:\n        zone: east\n  - host: tiproxy-host-2\n    config:\n      labels:\n        zone: west\ntidb_servers:\n  - host: tidb-host-1\n    config:\n      labels:\n        zone: east\n  - host: tidb-host-2\n    config:\n      labels:\n        zone: west\ntikv_servers:\n  - host: tikv-host-1\n  - host: tikv-host-2\n  - host: tikv-host-3\npd_servers:\n  - host: pd-host-1\n  - host: pd-host-2\n  - host: pd-host-3\n\"\n```\n\n----------------------------------------\n\nTITLE: Column Definition in TiCDC Simple Protocol\nDESCRIPTION: JSON representation of a Column object in TiCDC Simple Protocol. It includes the column name, data type information, nullability, and default value.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-simple-protocol.md#2025-04-18_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n        \"name\":\"id\",\n        \"dataType\":{\n            \"mysqlType\":\"int\",\n            \"charset\":\"binary\",\n            \"collate\":\"binary\",\n            \"length\":11\n        },\n        \"nullable\":false,\n        \"default\":null\n}\n```\n\n----------------------------------------\n\nTITLE: Querying DDL_JOBS Table Sample Data\nDESCRIPTION: Demonstrates querying the DDL_JOBS table to view sample DDL operations with limit 3 and using \\G for vertical output format.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-ddl-jobs.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM ddl_jobs LIMIT 3\\G\n```\n\n----------------------------------------\n\nTITLE: Updating Author Name in Java\nDESCRIPTION: Java code example using JDBC to execute an UPDATE statement for changing an author's name, with prepared statement for parameterization.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-update-data.md#2025-04-18_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n// ds is an entity of com.mysql.cj.jdbc.MysqlDataSource\ntry (Connection connection = ds.getConnection()) {\n    PreparedStatement pstmt = connection.prepareStatement(\"UPDATE `authors` SET `name` = ? WHERE `id` = ?\");\n    pstmt.setString(1, \"Helen Haruki\");\n    pstmt.setInt(2, 1);\n    pstmt.executeUpdate();\n} catch (SQLException e) {\n    e.printStackTrace();\n}\n```\n\n----------------------------------------\n\nTITLE: Output Format for Available Components\nDESCRIPTION: The command output in bash format, detailing the available TiUP components, their owners, and descriptions, providing insights into what each component manages or facilitates within the TiDB ecosystem.\nSOURCE: https://github.com/pingcap/docs/blob/master/migration-tools.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nAvailable components:\nName            Owner      Description\n----            -----      -----------\nPCC             community  A tool used to capture plan changes among different versions of TiDB\nbench           pingcap    Benchmark database with different workloads\nbr              pingcap    TiDB/TiKV cluster backup restore tool.\ncdc             pingcap    CDC is a change data capture tool for TiDB\nchaosd          community  An easy-to-use Chaos Engineering tool used to inject failures to a physical node\nclient          pingcap    Client to connect playground\ncloud           pingcap    CLI tool to manage TiDB Cloud\ncluster         pingcap    Deploy a TiDB cluster for production\nctl             pingcap    TiDB controller suite\ndm              pingcap    Data Migration Platform manager\ndmctl           pingcap    dmctl component of Data Migration Platform.\nerrdoc          pingcap    Document about TiDB errors\npd-recover      pingcap    PD Recover is a disaster recovery tool of PD, used to recover the PD cluster which cannot start or provide services normally.\nplayground      pingcap    Bootstrap a local TiDB cluster for fun\ntidb            pingcap    TiDB is an open source distributed HTAP database compatible with the MySQL protocol.\ntidb-dashboard  pingcap    TiDB Dashboard is a Web UI for monitoring, diagnosing, and managing the TiDB cluster\ntidb-lightning  pingcap    TiDB Lightning is a tool used for fast full import of large amounts of data into a TiDB cluster\ntikv-br         pingcap    TiKV cluster backup restore tool\ntikv-cdc        pingcap    TiKV-CDC is a change data capture tool for TiKV\ntiproxy         pingcap    TiProxy is a database proxy that is based on TiDB.\ntiup            pingcap    TiUP is a command-line component management tool that can help to download and install TiDB platform components to the local system\n```\n\n----------------------------------------\n\nTITLE: Querying Hot Regions Within a Specific Time Period in SQL\nDESCRIPTION: This SQL query selects all data from the TIDB_HOT_REGIONS_HISTORY table for a specific time range. It demonstrates how to filter results based on the update_time field.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-hot-regions-history.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.TIDB_HOT_REGIONS_HISTORY WHERE update_time >'2021-08-18 21:40:00' and update_time <'2021-09-19 00:00:00';\n```\n\n----------------------------------------\n\nTITLE: ALTER SEQUENCE EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax diagram for the ALTER SEQUENCE statement in TiDB, showing the complete grammar definition including all available options for sequence modification.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-sequence.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCreateSequenceStmt ::=\n    'ALTER' 'SEQUENCE' TableName CreateSequenceOptionListOpt\n\nTableName ::=\n    Identifier ('.' Identifier)?\n\nCreateSequenceOptionListOpt ::=\n    SequenceOption*\n\nSequenceOptionList ::=\n    SequenceOption\n\nSequenceOption ::=\n    ( 'INCREMENT' ( '='? | 'BY' ) | 'START' ( '='? | 'WITH' ) | ( 'MINVALUE' | 'MAXVALUE' | 'CACHE' ) '='? ) SignedNum\n|   'COMMENT' '='? stringLit\n|   'NOMINVALUE'\n|   'NO' ( 'MINVALUE' | 'MAXVALUE' | 'CACHE' | 'CYCLE' )\n|   'NOMAXVALUE'\n|   'NOCACHE'\n|   'CYCLE'\n|   'NOCYCLE'\n|   'RESTART' ( ( '='? | 'WITH' ) SignedNum )?\n```\n\n----------------------------------------\n\nTITLE: Adding a watch list item with exact SQL matching\nDESCRIPTION: This code snippet adds a watch item to the default resource group. The `ACTION` is set to `KILL` when the SQL exactly matches 'select * from test.t2'. It requires `QUERY LIMIT` to be set for the default resource group in advance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n\"QUERY WATCH ADD ACTION KILL SQL TEXT EXACT TO 'select * from test.t2';\"\n```\n\n----------------------------------------\n\nTITLE: Simple Database Restoration with FLASHBACK DATABASE in TiDB\nDESCRIPTION: Example showing how to restore a dropped database using FLASHBACK DATABASE with its original name. This requires execution within the GC lifetime period.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-database.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nDROP DATABASE test;\n```\n\nLANGUAGE: sql\nCODE:\n```\nFLASHBACK DATABASE test;\n```\n\n----------------------------------------\n\nTITLE: Enabling Specific Roles with SET ROLE in TiDB SQL\nDESCRIPTION: SQL commands to enable specific roles 'r2' and 'r3' for the current session, followed by a query to check the current roles.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-role.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET ROLE 'r2', 'r3';\nSELECT CURRENT_ROLE();\n```\n\n----------------------------------------\n\nTITLE: Defining Critical Alert Rule for CDC ResolvedTS High Delay in YAML\nDESCRIPTION: YAML configuration for a critical alert rule that triggers when the TiCDC owner resolved timestamp lag exceeds 300 seconds (5 minutes).\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-alert-rules.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nticdc_owner_resolved_ts_lag > 300\n```\n\n----------------------------------------\n\nTITLE: DATETIME Default Values Example\nDESCRIPTION: Shows how to create DATETIME columns with different default value behaviors based on NULL constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n    dt1 DATETIME ON UPDATE CURRENT_TIMESTAMP,         -- default NULL\n    dt2 DATETIME NOT NULL ON UPDATE CURRENT_TIMESTAMP -- default 0\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring PD for Label-based Scheduling in YAML\nDESCRIPTION: YAML configuration for PD to recognize and use host labels for Region scheduling. This ensures proper distribution of Raft Group replicas in hybrid deployments.\nSOURCE: https://github.com/pingcap/docs/blob/master/hybrid-deployment-topology.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\npd:\n  replication.location-labels: [\"host\"]\n```\n\n----------------------------------------\n\nTITLE: Collecting TiDB Cluster Configuration Data with Diag\nDESCRIPTION: Command to collect configuration data from a TiDB cluster using the tiup diag tool. This collects only configuration files, resulting in relatively small data size (less than 10KB for an 18-node cluster).\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag collect ${cluster-name} --include=\"config\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Foreign Key Constraints from REFERENTIAL_CONSTRAINTS\nDESCRIPTION: Fetches complete details of foreign key constraints from the INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS system table. It includes metadata like schema, constraint names, match options, and update/delete rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT * FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS\\G\n***************************[ 1. row ]***************************\nCONSTRAINT_CATALOG        | def\nCONSTRAINT_SCHEMA         | test\nCONSTRAINT_NAME           | fk_1\nUNIQUE_CONSTRAINT_CATALOG | def\nUNIQUE_CONSTRAINT_SCHEMA  | test\nUNIQUE_CONSTRAINT_NAME    | PRIMARY\nMATCH_OPTION              | NONE\nUPDATE_RULE               | NO ACTION\nDELETE_RULE               | CASCADE\nTABLE_NAME                | child\nREFERENCED_TABLE_NAME     | parent\n\n```\n\n----------------------------------------\n\nTITLE: Describing TIKV_REGION_STATUS Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the TIKV_REGION_STATUS table, showing all columns, their data types, and other attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tikv-region-status.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC TIKV_REGION_STATUS;\n```\n\n----------------------------------------\n\nTITLE: Running Sysbench Tests for Performance Metrics - Shell\nDESCRIPTION: This shell command runs Sysbench performance tests on the specified workload with variable threading. It measures transaction per second (TPS) and latency for each workload scenario, essential for analyzing database performance under load.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nsysbench ${WORKLOAD} run \\\n      --mysql-host=${HOST} \\\n      --mysql-port=${PORT} \\\n      --mysql-user=root \\\n      --db-driver=mysql \\\n      --mysql-db=sbtest \\\n      --threads=${THREAD} \\\n      --time=1200 \\\n      --report-interval=10 \\\n      --tables=32 \\\n      --table-size=10000000 \\\n      --mysql-ignore-errors=1062,2013,8028,9007 \\\n      --auto-inc=false \\\n      --mysql-password=${PASSWORD}\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB Version in SQL\nDESCRIPTION: These SQL queries can be used to check the version of TiDB running in your TiDB Cloud Serverless cluster. They provide information about the current TiDB version installed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-faqs.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT version()\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT tidb_version()\n```\n\n----------------------------------------\n\nTITLE: Listing Changefeeds in TiCDC - Shell Command\nDESCRIPTION: This shell command uses the TiCDC command-line interface to list all changefeeds, providing details about each replication task's state. The command assumes a server address of http://127.0.0.1:8300 but should be replaced with the actual PD address for proper execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed list --server=http://127.0.0.1:8300\n```\n\n----------------------------------------\n\nTITLE: Modifying User Comment in TiDB\nDESCRIPTION: Example of adding a comment to the user 'newuser' using ALTER USER and then querying the user_attributes table to verify the change. This demonstrates how to add descriptive metadata to user accounts in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'newuser' COMMENT 'Here is the comment';\nmysql> SELECT * FROM information_schema.user_attributes;\n+-----------+------+--------------------------------------------------------+\n| USER      | HOST | ATTRIBUTE                                              |\n+-----------+------+--------------------------------------------------------+\n| newuser   | %    | {\"comment\": \"Here is the comment\", \"newAttr\": \"value\"} |\n+-----------+------+--------------------------------------------------------+\n1 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Pause Log Backup Example\nDESCRIPTION: Example command to pause a running log backup task with specified task name and PD address.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log pause --task-name=pitr --pd=\"${PD_IP}:2379\"\n```\n\n----------------------------------------\n\nTITLE: Canceling Export Task in Interactive Mode\nDESCRIPTION: Example of canceling an export task in interactive mode. In this mode, the CLI will prompt for necessary information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-cancel.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export cancel\n```\n\n----------------------------------------\n\nTITLE: Using DO Statement with SLEEP Function in SQL\nDESCRIPTION: SQL examples showing the use of the DO statement with the SLEEP function. These statements pause execution without producing a result set.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-do.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nDO SLEEP(5);\n```\n\nLANGUAGE: SQL\nCODE:\n```\nDO SLEEP(1), SLEEP(1.5);\n```\n\n----------------------------------------\n\nTITLE: Static Partition Pruning Mode Explanation\nDESCRIPTION: Demonstrates query execution in static partition pruning mode, showing individual partition scans for count operation\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tiflash-mpp-mode.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_partition_prune_mode=static;\nexplain SELECT count(*) FROM test.employees;\n```\n\n----------------------------------------\n\nTITLE: Starting DM Migration Task\nDESCRIPTION: Shell command for starting a DM migration task using tiup dmctl. Initiates the migration process using the specified configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-shards-to-tidb.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} start-task task.yaml\n```\n\n----------------------------------------\n\nTITLE: Scaling Out TiFlash Cluster\nDESCRIPTION: This command initiates the scale-out process for the TiFlash cluster, adding a new TiFlash node to the existing cluster. It relies on the assumption of mutual trust or requires the `-p` or `-i` options.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster scale-out <cluster-name> scale-out.yml\"\n```\n\n----------------------------------------\n\nTITLE: Performing Environment Checks on Target Machines\nDESCRIPTION: Commands for checking target machine environments before deployment or on existing clusters. Includes options for CPU, memory, and disk checks.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster check topology.yml --user tidb -p\ntiup cluster check <cluster-name> --cluster\n```\n\n----------------------------------------\n\nTITLE: Exporting historical data snapshots in TiDB\nDESCRIPTION: Commands to export data as it existed at a specific point in time using Dumpling's --snapshot option with either TSO or datetime format.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ntiup dumpling --snapshot 417773951312461825\ntiup dumpling --snapshot \"2020-07-02 17:12:45\"\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB Query Duration Metrics - SQL\nDESCRIPTION: This SQL snippet queries the 'tidb_query_duration' monitoring item, filtering for non-null values within a specified 3-minute time range. It retrieves detailed metrics for different SQL types and quantiles.\nSOURCE: https://github.com/pingcap/docs/blob/master/metrics-schema.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nselect * from metrics_schema.tidb_query_duration where value is not null and time>='2020-03-25 23:40:00' and time <= '2020-03-25 23:42:00' and quantile=0.99;\n```\n\n----------------------------------------\n\nTITLE: Illustrating Dynamic User Variable Behavior in TiDB SQL Query\nDESCRIPTION: This SQL snippet demonstrates why predicates with user variables are not pushed down. It creates a table, inserts data, sets a user variable, and executes a query where the variable's value changes during execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/predicate-push-down.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id int primary key, a int);\ninsert into t values(1, 1), (2,2);\nset @a = 1;\nselect id, a, @a:=@a+1 from t where a = @a;\n```\n\n----------------------------------------\n\nTITLE: Displaying Password Complexity Variables in TiDB\nDESCRIPTION: This SQL query displays all system variables related to the password complexity policy in TiDB, showing current settings for password length, mixed case count, and other parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> SHOW VARIABLES LIKE 'validate_password.%';\n\n+--------------------------------------+--------+\n| Variable_name                        | Value  |\n+--------------------------------------+--------+\n| validate_password.check_user_name    | ON     |\n| validate_password.dictionary         |        |\n| validate_password.enable             | OFF    |\n| validate_password.length             | 8      |\n| validate_password.mixed_case_count   | 1      |\n| validate_password.number_count       | 1      |\n| validate_password.policy             | MEDIUM |\n| validate_password.special_char_count | 1      |\n+--------------------------------------+--------+\n8 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Deleting Roles in TiDB\nDESCRIPTION: SQL command to drop multiple roles (app_read and app_write) from the database system.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nDROP ROLE 'app_read', 'app_write';\n```\n\n----------------------------------------\n\nTITLE: Configuring DM-worker Using TOML File\nDESCRIPTION: Example TOML configuration file for DM-worker, including settings for logging, network addresses, and joining the DM-master cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-binary.md#2025-04-18_snippet_4\n\nLANGUAGE: TOML\nCODE:\n```\n# Worker Configuration.\nname = \"worker1\"\n\n# Log configuration.\nlog-level = \"info\"\nlog-file = \"dm-worker.log\"\n\n# DM-worker address.\nworker-addr = \":8262\"\n\n# The master-addr configuration of the DM-master nodes in the cluster.\njoin = \"192.168.0.4:8261,192.168.0.5:8261,192.168.0.6:8261\"\n```\n\n----------------------------------------\n\nTITLE: Importing a File Asynchronously in DETACHED Mode\nDESCRIPTION: This SQL statement imports a CSV file into a TiDB table in detached mode, meaning the import process runs in the background.  The `WITH DETACHED` option allows the client to disconnect without interrupting the import. This returns job information immediately, indicating the job is pending.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t FROM '/path/to/file.csv' WITH DETACHED;\n```\n\n----------------------------------------\n\nTITLE: Column Data Format for BIT(64)\nDESCRIPTION: Demonstrates the structure for a BIT(64) column. It includes the `length` parameter in the connect parameters. The Avro type is `bytes`.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-protocol.md#2025-04-18_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\":\"{{ColumnName}}\",\n    \"type\":{\n        \"connect.parameters\":{\n            \"tidb_type\":\"BIT\",\n            \"length\":\"64\"\n        },\n        \"type\":\"bytes\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Generate ANALYZE TABLE Statements for Partitioned Tables\nDESCRIPTION: This SQL query dynamically generates `ANALYZE TABLE` statements for all partitioned tables, excluding system schemas.  It concatenates the string 'ANALYZE TABLE' with the schema, table name, and 'ALL COLUMNS;' to create a complete SQL statement for updating table statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_81\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DISTINCT CONCAT('ANALYZE TABLE ',TABLE_SCHEMA,'.',TABLE_NAME,' ALL COLUMNS;')\n    FROM information_schema.PARTITIONS\n    WHERE TIDB_PARTITION_ID IS NOT NULL\n    AND TABLE_SCHEMA NOT IN ('INFORMATION_SCHEMA','mysql','sys','PERFORMANCE_SCHEMA','METRICS_SCHEMA');\n```\n\nLANGUAGE: sql\nCODE:\n```\n+\n| concat('ANALYZE TABLE ',TABLE_SCHEMA,'.',TABLE_NAME,' ALL COLUMNS;') |\n+\n| ANALYZE TABLE test.t ALL COLUMNS;                                    |\n+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Importing TiDB Ansible Cluster from Specific Path\nDESCRIPTION: Example command to import a TiDB cluster by specifying the path to the TiDB-Ansible directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster import --dir=/path/to/tidb-ansible\n```\n\n----------------------------------------\n\nTITLE: Deploying TiUP and Dumpling using curl\nDESCRIPTION: Commands to install TiUP and Dumpling tools on a Linux server. This installs TiUP first, then uses it to deploy and update Dumpling to the latest version.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n## Deploy TiUP\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\nsource /root/.bash_profile\n## Deploy Dumpling and update to the latest version\ntiup install dumpling\ntiup update --self && tiup update dumpling\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning for CSV Import in TOML\nDESCRIPTION: This TOML configuration file sets up TiDB Lightning for importing CSV data into TiDB. It specifies logging, backend settings, data source directory, CSV format details, and target TiDB cluster information.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-csv-files-to-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[lightning]\nlevel = \"info\"\nfile = \"tidb-lightning.log\"\n\n[tikv-importer]\nbackend = \"local\"\nsorted-kv-dir = \"/mnt/ssd/sorted-kv-dir\"\n\n[mydumper]\ndata-source-dir = \"${data-path}\"\n\n[mydumper.csv]\nseparator = ','\ndelimiter = '\"'\nheader = true\nnot-null = false\nnull = '\\N'\nbackslash-escape = true\ntrim-last-separator = false\n\n[tidb]\nhost = ${host}\nport = ${port}\nuser = \"${user_name}\"\npassword = \"${password}\"\nstatus-port = ${status-port}\npd-addr = \"${ip}:${port}\"\n```\n\n----------------------------------------\n\nTITLE: Boolean Literal Query Example\nDESCRIPTION: Demonstrates boolean literal values and case insensitivity.\nSOURCE: https://github.com/pingcap/docs/blob/master/literal-values.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TRUE, true, tRuE, FALSE, FaLsE, false;\n```\n\n----------------------------------------\n\nTITLE: Comparing Characters with Different Collations in TiDB\nDESCRIPTION: SQL examples demonstrating character comparison behavior with different collations (utf8mb4_bin vs utf8mb4_general_ci) in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET NAMES utf8mb4 COLLATE utf8mb4_bin;\nSELECT 'A' = 'a';\nSET NAMES utf8mb4 COLLATE utf8mb4_general_ci;\nSELECT 'A' = 'a';\n```\n\n----------------------------------------\n\nTITLE: Syntax of SHOW STATS_HISTOGRAMS Statement in TiDB SQL\nDESCRIPTION: Provides the syntax structure of the SHOW STATS_HISTOGRAMS statement for use in TiDB, allowing for optional LIKE or WHERE conditions to filter results. This helps in retrieving statistical histogram data collected by the ANALYZE statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-histograms.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nShowStatsHistogramsStmt ::=\\n    \"SHOW\" \"STATS_HISTOGRAMS\" ShowLikeOrWhere?\\n\\nShowLikeOrWhere ::=\\n    \"LIKE\" SimpleExpr\\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Generating Root CA Key\nDESCRIPTION: Command to generate a 4096-bit RSA private key for the root Certificate Authority (CA).\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nopenssl genrsa -out root.key 4096\n```\n\n----------------------------------------\n\nTITLE: Naming Columns with Column Aliases in SQL\nDESCRIPTION: This example shows the recommended approach to naming columns using the AS keyword for aliasing, rather than using the NAME_CONST() function.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 'value' AS 'column name' UNION ALL SELECT 'another value';\n```\n\n----------------------------------------\n\nTITLE: RaftDB Configuration Settings\nDESCRIPTION: Core configuration parameters for RaftDB including background jobs, file limits, and WAL settings. Controls database performance and resource utilization.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_20\n\nLANGUAGE: yaml\nCODE:\n```\nraftdb:\n  max-background-jobs: 4\n  max-sub-compactions: 2\n  max-open-files: 40960\n  max-manifest-file-size: \"20MiB\"\n  create-if-missing: true\n  stats-dump-period: \"10m\"\n  wal-dir: \"\"\n  wal-ttl-seconds: 0\n  wal-size-limit: 0\n```\n\n----------------------------------------\n\nTITLE: Encoding WATERMARK Event in TiCDC - JSON\nDESCRIPTION: This snippet defines the JSON structure for a WATERMARK event in TiCDC, which marks the replication progress. It captures fields like version and commit timestamp. This event helps in managing the data consistency during data replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-simple-protocol.md#2025-04-18_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"version\":1,\n   \"type\":\"WATERMARK\",\n   \"commitTs\":447984124732375041,\n   \"buildTs\":1708923816911\n}\n```\n\n----------------------------------------\n\nTITLE: MPP Query Execution Plan\nDESCRIPTION: Detailed execution plan showing a distributed query processing flow with TiFlash MPP engine. The plan includes table scanning, data exchange operations, sorting, and window function calculation for processing 600 million rows. Notable operations include hash partitioning, row number window function, and table full scan with TiFlash-specific metrics.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\n| TableReader_24                   | 600000000.00 | 600000000 | root         |               | time:2m55s, loops:585941, cop_task: {num: 9163, max: 0s, min: 0s, avg: 0s, p95: 0s, copr_cache_hit_ratio: 0.00}                                                                                                                                                                                                                                   | data:ExchangeSender_23                                                                                                | N/A    | N/A  |\n| └─ExchangeSender_23              | 600000000.00 | 600000000 | mpp[tiflash] |               | tiflash_task:{proc max:2m55s, min:1m37s, avg: 2m28.7s, p80:2m55s, p95:2m55s, iters:9160, tasks:3, threads:60}                                                                                                                                                                                                                                     | ExchangeType: PassThrough                                                                                             | N/A    | N/A  |\n|   └─Window_22                    | 600000000.00 | 600000000 | mpp[tiflash] |               | tiflash_task:{proc max:2m12.9s, min:1m17s, avg: 1m54.2s, p80:2m12.9s, p95:2m12.9s, iters:9160, tasks:3, threads:60}                                                                                                                                                                                                                               | row_number()->Column#23 over(partition by test.t.a rows between current row and current row), stream_count: 20        | N/A    | N/A  |\n|     └─Sort_13                    | 600000000.00 | 600000000 | mpp[tiflash] |               | tiflash_task:{proc max:2m10.9s, min:1m16s, avg: 1m52.5s, p80:2m10.9s, p95:2m10.9s, iters:9160, tasks:3, threads:60}                                                                                                                                                                                                                               | test.t.a, stream_count: 20                                                                                            | N/A    | N/A  |\n|       └─ExchangeReceiver_12      | 600000000.00 | 600000000 | mpp[tiflash] |               | tiflash_task:{proc max:27.2s, min:25.5s, avg: 26.6s, p80:27.2s, p95:27.2s, iters:49602, tasks:3, threads:60}                                                                                                                                                                                                                                      | stream_count: 20                                                                                                      | N/A    | N/A  |\n|         └─ExchangeSender_11      | 600000000.00 | 600000000 | mpp[tiflash] |               | tiflash_task:{proc max:25.5s, min:0s, avg: 8.51s, p80:25.5s, p95:25.5s, iters:9388, tasks:3, threads:60}                                                                                                                                                                                                                                          | ExchangeType: HashPartition, Hash Cols: [name: test.t.a, collate: binary], stream_count: 20                           | N/A    | N/A  |\n|           └─TableFullScan_10     | 600000000.00 | 600000000 | mpp[tiflash] | table:t       | tiflash_task:{proc max:167.3ms, min:0s, avg: 55.8ms, p80:167.3ms, p95:167.3ms, iters:9388, tasks:3, threads:60}, tiflash_scan:{dtfile:{total_scanned_packs:73834, total_skipped_packs:408, total_scanned_rows:600002896, total_skipped_rows:3307316, total_rs_index_load_time: 20ms, total_read_time: 179431ms}, total_create_snapshot_time: 0ms} | keep order:false                                                                                                      | N/A    | N/A  |\n```\n\n----------------------------------------\n\nTITLE: Defining Password Character Requirements in TiDB\nDESCRIPTION: These SQL statements set requirements for TiDB passwords, specifying minimum counts for numbers, mixed case letters, and special characters to enforce complexity.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL validate_password.number_count = 2;\nSET GLOBAL validate_password.mixed_case_count = 1;\nSET GLOBAL validate_password.special_char_count = 1;\n```\n\n----------------------------------------\n\nTITLE: Setting TiDB Lightning's logical-import-batch-size Parameter\nDESCRIPTION: Controls the size of each SQL statement executed on the downstream TiDB server in Logical Import Mode. It specifies the expected size of the VALUES part in INSERT or REPLACE statements. Default is \"96KiB\".\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\ntikv-importer:\n  logical-import-batch-size: \"96KiB\"\n```\n\n----------------------------------------\n\nTITLE: Performing Bitwise OR Operation in SQL\nDESCRIPTION: The '|' operator conducts a bitwise OR operation, yielding 1 for a bit position if at least one of the corresponding bits in the two operands is 1. The input comprises two binary numbers, with the output being their bitwise OR result.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/bit-functions-and-operators.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONV(b'1010' | b'1100',10,2);\n```\n\n----------------------------------------\n\nTITLE: Create DM Data Source Configuration\nDESCRIPTION: This YAML configuration defines a data source for TiDB Data Migration (DM). It specifies the connection details for the source MySQL database, including the host, user, password, and port.  It also configures whether DM-worker uses GTID to pull binlogs.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-to-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n\"# The ID must be unique.\nsource-id: \\\"mysql-01\\\"\\n\n# Configures whether DM-worker uses the global transaction identifier (GTID) to pull binlogs. To enable GTID, the upstream MySQL must have enabled GTID. If the upstream MySQL has automatic source-replica switching, the GTID mode is required.\nenable-gtid: true\n\nfrom:\n  host: \\\"${host}\\\"         # For example: 172.16.10.81\n  user: \\\"root\\\"\n  password: \\\"${password}\\\" # Plaintext password is supported but not recommended. It is recommended to use dmctl encrypt to encrypt the plaintext password before using the password.\n  port: 3306\"\n```\n\n----------------------------------------\n\nTITLE: Analyzing Tables in SQL\nDESCRIPTION: These SQL statements are executed to collect statistics for various tables in the `tpcc` database. Collecting statistics allows the TiDB optimizer to generate the optimal execution plan for queries. It is important to collect table statistics before running the actual tests.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n\"ANALYZE TABLE customer;\\nANALYZE TABLE district;\\nANALYZE TABLE history;\\nANALYZE TABLE item;\\nANALYZE TABLE new_order;\\nANALYZE TABLE order_line;\\nANALYZE TABLE orders;\\nANALYZE TABLE stock;\\nANALYZE TABLE warehouse;\"\n```\n\n----------------------------------------\n\nTITLE: Rewritten Batch INSERT with ON DUPLICATE KEY UPDATE\nDESCRIPTION: Shows how multiple INSERT statements with ON DUPLICATE KEY UPDATE clauses are rewritten into a single statement when rewriteBatchedStatements=true is configured.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\ninsert into t (a) values (10), (11), (12) on duplicate key update a = values(a);\n```\n\n----------------------------------------\n\nTITLE: Previous Master Key During Key Rotation\nDESCRIPTION: Defines the previous master key for cases when a new key is being rotated, maintaining data security continuity.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_13\n\nLANGUAGE: TOML\nCODE:\n```\n\"security.encryption.previous-master-key = \\\"old_master_key\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Changing Password for an Existing User in TiDB\nDESCRIPTION: Change the password for an existing user using SET PASSWORD FOR, which is one method to update user credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSET PASSWORD FOR 'root'@'%' = 'xxx';\n```\n\n----------------------------------------\n\nTITLE: Deploying TiDB Cluster using TiUP Playground in Shell\nDESCRIPTION: These commands create a TiDB cluster using TiUP Playground and view the cluster status. It sets up 1 TiDB, 1 PD, 1 TiKV, 0 TiFlash, and 1 TiCDC node.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-mysql.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n# Create a TiDB cluster\ntiup playground --db 1 --pd 1 --kv 1 --tiflash 0 --ticdc 1\n# View cluster status\ntiup status\n```\n\n----------------------------------------\n\nTITLE: Downloading and Preparing TiDB Lightning Binaries\nDESCRIPTION: Downloads TiDB Lightning binaries from the official repository, extracts them, and sets executable permissions. Requires wget or curl for downloading. Outputs an executable `tidb-lightning` binary ready for use.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/deploy-tidb-lightning.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntar -zxvf tidb-lightning-${version}-linux-amd64.tar.gz\nchmod +x tidb-lightning\n```\n\n----------------------------------------\n\nTITLE: Testing Network Connectivity with iperf3 - Shell\nDESCRIPTION: This shell script uses iperf3 to test network connectivity between server-side and client-side nodes to diagnose network issues causing retries and EOF errors during data import/export operations. It assumes iperf3 is already installed on both nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/migration-tidb-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\niperf3 -s\n```\n\nLANGUAGE: shell\nCODE:\n```\niperf3 -c <server-IP>\n```\n\nLANGUAGE: shell\nCODE:\n```\n$ iperf3 -c 192.168.196.58\nConnecting to host 192.168.196.58, port 5201\n[  5] local 192.168.196.150 port 55397 connected to 192.168.196.58 port 5201\n[ ID] Interval           Transfer     Bitrate\n[  5]   0.00-1.00   sec  18.0 MBytes   150 Mbits/sec\n[  5]   1.00-2.00   sec  20.8 MBytes   175 Mbits/sec\n[  5]   2.00-3.00   sec  18.2 MBytes   153 Mbits/sec\n[  5]   3.00-4.00   sec  22.5 MBytes   188 Mbits/sec\n[  5]   4.00-5.00   sec  22.4 MBytes   188 Mbits/sec\n[  5]   5.00-6.00   sec  22.8 MBytes   191 Mbits/sec\n[  5]   6.00-7.00   sec  20.8 MBytes   174 Mbits/sec\n[  5]   7.00-8.00   sec  20.1 MBytes   168 Mbits/sec\n[  5]   8.00-9.00   sec  20.8 MBytes   175 Mbits/sec\n[  5]   9.00-10.00  sec  21.8 MBytes   183 Mbits/sec\n- - - - - - - - - - - - - - - - - - - - - - - - -\n[ ID] Interval           Transfer     Bitrate\n[  5]   0.00-10.00  sec   208 MBytes   175 Mbits/sec                  sender\n[  5]   0.00-10.00  sec   208 MBytes   174 Mbits/sec                  receiver\n\niperf Done.\n```\n\n----------------------------------------\n\nTITLE: Defining MEDIUMTEXT Column in TiDB\nDESCRIPTION: Syntax for creating a MEDIUMTEXT column supporting up to 16,777,215 bytes with character set options.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nMEDIUMTEXT [CHARACTER SET charset_name] [COLLATE collation_name]\n```\n\n----------------------------------------\n\nTITLE: Querying Slow Query Count with Execution Plan\nDESCRIPTION: Shows how to query the count of slow queries for a specific user and displays the execution plan demonstrating how TiDB pushes down calculations to other nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-slow-query.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nDESC SELECT COUNT(*) FROM CLUSTER_SLOW_QUERY WHERE user = 'u1';\n```\n\n----------------------------------------\n\nTITLE: Creating User with Combined Password Reuse Policy in SQL\nDESCRIPTION: SQL command to create a new user with a combined password reuse policy that prohibits both the last 5 passwords and any passwords used within the last 365 days.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_26\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE USER 'test'@'localhost'\n  PASSWORD HISTORY 5\n  PASSWORD REUSE INTERVAL 365 DAY;\n```\n\n----------------------------------------\n\nTITLE: Managing Rule Groups with pd-ctl\nDESCRIPTION: Commands for viewing and managing placement rule groups, including showing all groups, specific groups, and setting group attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-placement-rules.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules rule-group show\n```\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules rule-group show pd\n```\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules rule-group set pd 100 true\n```\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules rule-group delete pd\n```\n\n----------------------------------------\n\nTITLE: Adjusting GC Lifetime in TiDB\nDESCRIPTION: Configure the garbage collection lifetime to ensure data replication stability during migration and upgrade process\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n-- Check the current GC lifetime setting.\nSHOW VARIABLES LIKE '%tidb_gc_life_time%';\n-- Set GC lifetime.\nSET GLOBAL tidb_gc_life_time=60h;\n```\n\n----------------------------------------\n\nTITLE: FLASHBACK TABLE Basic Syntax\nDESCRIPTION: The basic syntax for the FLASHBACK TABLE statement to restore dropped tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-table.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nFLASHBACK TABLE table_name [TO other_table_name]\n```\n\n----------------------------------------\n\nTITLE: Configuring External Storage for BR Checkpoint Data\nDESCRIPTION: Example command showing how to specify an external storage location for BR checkpoint data using the --checkpoint-storage parameter when performing a full restore.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-checkpoint-restore.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n./br restore full -s \"s3://backup-bucket/backup-prefix\" --checkpoint-storage \"s3://temp-bucket/checkpoints\"\n```\n\n----------------------------------------\n\nTITLE: Setting Session SQL Mode in TiDB\nDESCRIPTION: SQL command to set the session SQL mode in TiDB, followed by a query to verify the immediate effect on the session level.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-variable.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET SESSION sql_mode = 'STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER';\nSHOW SESSION VARIABLES LIKE 'sql_mode';\n```\n\n----------------------------------------\n\nTITLE: Assigning Binary Expression Results to User-Defined Variables\nDESCRIPTION: Demonstrates assigning the result of a binary expression to a user-defined variable in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSET @c = b'1000001' + b'1000001';\n```\n\n----------------------------------------\n\nTITLE: Basic TiUP Cluster Display Command\nDESCRIPTION: Command syntax for displaying cluster component status. The command requires a cluster name parameter and supports various optional flags for customizing the output.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-display.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster display <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: BR Azure Blob Storage Encryption Commands\nDESCRIPTION: Commands for backing up data to Azure Blob Storage with encryption scope configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd <pd-address> --storage \"azure://<bucket>/<prefix>\" --azblob.encryption-scope scope1\n```\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd <pd-address> --storage \"azure://<bucket>/<prefix>?encryption-scope=scope1\"\n```\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full --pd <pd-address> --storage \"azure://<bucket>/<prefix>\"\n```\n\n----------------------------------------\n\nTITLE: Starting a Data Migration Task in TiDB Data Migration (Bash)\nDESCRIPTION: This command starts a data migration task using a specified configuration file. It optionally allows specifying a MySQL source to execute the task on.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-create-task.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nstart-task [ -s \"mysql-replica-01\"] ./task.yaml\n```\n\n----------------------------------------\n\nTITLE: Cloning the TiDB Vector Python Repository\nDESCRIPTION: Command to clone the tidb-vector-python repository to your local machine, which contains example code for integrating TiDB Vector Search with Python.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-peewee.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/pingcap/tidb-vector-python.git\n```\n\n----------------------------------------\n\nTITLE: Listing User Profiles with ticloud config list\nDESCRIPTION: This command lists all user profiles in the TiDB Cloud CLI. It can be used with or without flags to display available user profiles.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-list.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud config list [flags]\n```\n\n----------------------------------------\n\nTITLE: Filtering Table Statistics with WHERE Clause\nDESCRIPTION: Demonstrates how to filter statistical metadata for a specific table using the WHERE clause, allowing targeted retrieval of statistics for a single table\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-meta.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW STATS_META WHERE table_name = 't2';\n```\n\n----------------------------------------\n\nTITLE: Analyzing Query Execution Plan in TiDB before MPP Mode\nDESCRIPTION: This SQL query demonstrates the execution plan for a complex query involving joins and aggregations before MPP mode is enabled. It shows that TiDB needs to read data from TiKV and execute Join and Aggregation operations in TiDB itself.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain analyze select o_orderpriority, count(*) as order_count from orders where o_orderdate >= '1995-01-01' and o_orderdate < date_add('1995-01-01', interval '3' month) and exists (select * from lineitem where l_orderkey = o_orderkey and l_commitdate < l_receiptdate) group by o_orderpriority;\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Global Access in TiDB\nDESCRIPTION: Create a user 'finley' that can connect from any host with a password, similar to the localhost user but with broader access.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'finley'@'%' IDENTIFIED BY 'some_pass';\n```\n\n----------------------------------------\n\nTITLE: Checking Cluster Health in PD\nDESCRIPTION: Displays the health information of the PD cluster, including member IDs, client URLs, and health status for each PD node.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nhealth\n```\n\n----------------------------------------\n\nTITLE: Defining StorageReader Type and Methods in Golang\nDESCRIPTION: This snippet defines the `StorageReader` struct and its associated methods for reading files from storage and querying newly added files. The `ReadFiles` method manages file operations while `ExposeNewFiles` returns the latest checkpoint and new file names.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-storage-consumer-dev-guide.md#2025-04-18_snippet_0\n\nLANGUAGE: go\nCODE:\n```\ntype StorageReader struct {\n}\n// Read the files from storage.\n// Add new files and delete files that do not exist in storage.\nfunc (c *StorageReader) ReadFiles() {}\n\n// Query newly added files and the latest checkpoint from storage. One file can only be returned once.\nfunc (c *StorageReader) ExposeNewFiles() (int64, []string) {}\n```\n\n----------------------------------------\n\nTITLE: Using IMPORT INTO for Data Import in TiDB\nDESCRIPTION: The IMPORT INTO statement allows importing data from files without needing to install additional tools like TiDB Lightning. It supports the Distributed eXecution Framework (DXF) for parallel import, improving efficiency during large-scale data imports.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.5.0.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Replication Task\nDESCRIPTION: Example command to create a TiCDC replication task that copies data to MySQL using default configuration. The command specifies the server address, sink URI for MySQL connection, and a unique changefeed ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/monitor-ticdc.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://10.0.10.25:8300 --sink-uri=\"mysql://root:123456@127.0.0.1:3306/\" --changefeed-id=\"simple-replication-task\"\n```\n\n----------------------------------------\n\nTITLE: Integer Range Validation\nDESCRIPTION: SQL queries validating integer values within specified ranges\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-validate.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SCHEMA_VALID('{\"type\": \"integer\", \"minimum\": 40, \"maximum\": 45}', '42')\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SCHEMA_VALID('{\"type\": \"integer\", \"minimum\": 40, \"maximum\": 45}', '123')\n```\n\n----------------------------------------\n\nTITLE: Checking the Currently Enabled Role After Setting a Specific Role\nDESCRIPTION: This snippet shows how to check the currently enabled role after setting a specific role using `SET ROLE 'app_read'` followed by `SELECT CURRENT_ROLE()`. This demonstrates the effect of `SET ROLE` on the output of `CURRENT_ROLE()`.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nSET ROLE 'app_read'; SELECT CURRENT_ROLE();\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed to Skip DDL\nDESCRIPTION: These commands remove an existing TiCDC changefeed and create a new one, effectively skipping a problematic DDL statement. The `start-ts` is set to a value greater than the checkpoint-ts to avoid re-executing the failed DDL.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/troubleshoot-ticdc.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n\"cdc cli changefeed remove --server=http://127.0.0.1:8300 --changefeed-id simple-replication-task\\ncdc cli changefeed create --server=http://127.0.0.1:8300 --sink-uri=\\\"mysql://root:123456@127.0.0.1:3306/\\\" --changefeed-id=\\\"simple-replication-task\\\" --sort-engine=\\\"unified\\\" --start-ts 415241823337054210\"\n```\n\n----------------------------------------\n\nTITLE: Verifying TiDB Server and Client Certificates\nDESCRIPTION: Command to verify that both the server and client certificates were properly signed by the Certificate Authority. This ensures the certificates are valid for TiDB's certificate-based authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/certificate-authentication.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nopenssl verify -CAfile ca-cert.pem server-cert.pem client-cert.pem\n```\n\n----------------------------------------\n\nTITLE: CREATE SEQUENCE Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) representation of the CREATE SEQUENCE statement syntax in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-sequence.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCreateSequenceStmt ::=\n    'CREATE' 'SEQUENCE' IfNotExists TableName CreateSequenceOptionListOpt\n\nIfNotExists ::=\n    ('IF' 'NOT' 'EXISTS')?\n\nTableName ::=\n    Identifier ('.' Identifier)?\n\nCreateSequenceOptionListOpt ::=\n    SequenceOption*\n\nSequenceOptionList ::=\n    SequenceOption\n\nSequenceOption ::=\n    ( 'INCREMENT' ( '='? | 'BY' ) | 'START' ( '='? | 'WITH' ) | ( 'MINVALUE' | 'MAXVALUE' | 'CACHE' ) '='? ) SignedNum\n|   'COMMENT' '='? stringLit\n|   'NOMINVALUE'\n|   'NO' ( 'MINVALUE' | 'MAXVALUE' | 'CACHE' | 'CYCLE' )\n|   'NOMAXVALUE'\n|   'NOCACHE'\n|   'CYCLE'\n|   'NOCYCLE'\n```\n\n----------------------------------------\n\nTITLE: BR S3 Backup with Server-Side Encryption\nDESCRIPTION: Command for backing up data to S3 with server-side encryption using AWS KMS.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd <pd-address> --storage \"s3://<bucket>/<prefix>\" --s3.sse aws:kms\n```\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd <pd-address> --storage \"s3://<bucket>/<prefix>\" --s3.sse aws:kms --s3.sse-kms-key-id 0987dcba-09fe-87dc-65ba-ab0987654321\n```\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full --pd <pd-address> --storage \"s3://<bucket>/<prefix>\"\n```\n\n----------------------------------------\n\nTITLE: Filtering SQL Plan Baseline by Table Name\nDESCRIPTION: Insert filtering conditions into the system table to exclude specific tables from plan baseline capturing. Supports exact table names and wildcard patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO mysql.capture_plan_baselines_blacklist(filter_type, filter_value) VALUES('table', 'test.t');\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies Manually\nDESCRIPTION: Alternative command to manually install the necessary Python packages for working with TiDB Vector Search and SQLAlchemy.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install pymysql python-dotenv sqlalchemy tidb-vector\n```\n\n----------------------------------------\n\nTITLE: Command Mode dmctl Examples\nDESCRIPTION: Examples of using dmctl in command mode to perform specific operations like starting/stopping tasks and querying status. Includes environment variable usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dmctl-introduction.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./dmctl --master-addr 172.16.30.14:8261 start-task task.yaml\n./dmctl --master-addr 172.16.30.14:8261 stop-task task\n./dmctl --master-addr 172.16.30.14:8261 query-status\n\nexport DM_MASTER_ADDR=\"172.16.30.14:8261\"\n./dmctl query-status\n```\n\n----------------------------------------\n\nTITLE: Importing UNION Query Results into a Table with Concurrency Control in SQL\nDESCRIPTION: This example demonstrates how to import the results of a UNION query into a target table in TiDB. It specifies a concurrency level of 8 threads and disables prechecks for non-critical items to optimize the import process.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t FROM SELECT * FROM src UNION SELECT * FROM src2 WITH THREAD = 8, DISABLE_PRECHECK;\n```\n\n----------------------------------------\n\nTITLE: Rewriting Store Labels in TiKV\nDESCRIPTION: This command allows users to overwrite all labels of a specified store by using the --rewrite option. It's critical to note that this will remove all existing labels.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_54\n\nLANGUAGE: bash\nCODE:\n```\nstore label 1 region=us-est-1 disk=ssd --rewrite\n```\n\n----------------------------------------\n\nTITLE: Casting Between Vector and String in SQL\nDESCRIPTION: Shows how to cast between Vector and String data types using various functions and methods.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-data-types.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT VEC_DIMS('[0.3, 0.5, -0.1]');\n\nSELECT VEC_DIMS(VEC_FROM_TEXT('[0.3, 0.5, -0.1]'));\n\nSELECT VEC_DIMS(CAST('[0.3, 0.5, -0.1]' AS VECTOR));\n\nSELECT VEC_AS_TEXT('[0.3,     0.5,  -0.1]');\n```\n\n----------------------------------------\n\nTITLE: Querying Binlog Help Command\nDESCRIPTION: Command to display help information for the binlog command in dmctl\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nbinlog -h\n```\n\n----------------------------------------\n\nTITLE: Querying Test Database Tables - SQL\nDESCRIPTION: Executes a SQL query to retrieve data from the 'test' schema, summarizing row counts and data sizes for each table. The stats help verify data equivalency and formatting across multiple tables after generation.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-htap.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  CONCAT(table_schema,'.',table_name) AS 'Table Name',\n  table_rows AS 'Number of Rows',\n  FORMAT_BYTES(data_length) AS 'Data Size',\n  FORMAT_BYTES(index_length) AS 'Index Size',\n  FORMAT_BYTES(data_length+index_length) AS'Total'\nFROM\n  information_schema.TABLES\nWHERE\n  table_schema='test';\n```\n\nLANGUAGE: sql\nCODE:\n```\n+---------------+----------------+-----------+------------+-----------+\n|  Table Name   | Number of Rows | Data Size | Index Size |   Total   |\n+---------------+----------------+-----------+------------+-----------+\n| test.nation   |             25 | 2.44 KiB  | 0 bytes    | 2.44 KiB  |\n| test.region   |              5 | 416 bytes | 0 bytes    | 416 bytes |\n| test.part     |         200000 | 25.07 MiB | 0 bytes    | 25.07 MiB |\n| test.supplier |          10000 | 1.45 MiB  | 0 bytes    | 1.45 MiB  |\n| test.partsupp |         800000 | 120.17 MiB| 12.21 MiB  | 132.38 MiB|\n| test.customer |         150000 | 24.77 MiB | 0 bytes    | 24.77 MiB |\n| test.orders   |        1527648 | 174.40 MiB| 0 bytes    | 174.40 MiB|\n| test.lineitem |        6491711 | 849.07 MiB| 99.06 MiB  | 948.13 MiB|\n+---------------+----------------+-----------+------------+-----------+\n8 rows in set (0.06 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting Flow Round By Digit in PD\nDESCRIPTION: Sets the number of lowest digits to round for Region flow information to 4. This reduces statistics updates caused by minor changes in Region flow.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nconfig set flow-round-by-digit 4\n```\n\n----------------------------------------\n\nTITLE: Canceling DDL Jobs in TiDB\nDESCRIPTION: The ADMIN CANCEL DDL JOBS command is used to cancel DDL tasks that have been submitted but not completed. It returns an error if the job is already completed.\nSOURCE: https://github.com/pingcap/docs/blob/master/ddl-introduction.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN CANCEL DDL JOBS job_id, [, job_id]\n```\n\n----------------------------------------\n\nTITLE: Fetching Cluster ID from TiKV Log in Bash\nDESCRIPTION: Obtains cluster ID from TiKV log by searching for relevant log entries with grep. File paths must be specified correctly.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-recover.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngrep \"connect to PD cluster\" {{/path/to}}/tikv.log\n```\n\n----------------------------------------\n\nTITLE: JDBC Connection URL Parameter for Batch Rewrites\nDESCRIPTION: Enable batch network transfer for multiple SQL statements by setting rewriteBatchedStatements parameter in JDBC connection URL.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nrewriteBatchedStatements=true\n```\n\n----------------------------------------\n\nTITLE: Managing max_connections in TiDB\nDESCRIPTION: Defines the maximum number of concurrent connections allowed for a single TiDB instance. When set, it acts as a control on resource allocation for user connections.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\n-- Default value: `0`\n-- Range: `[0, 100000]`\nSET GLOBAL max_connections = 0;\n```\n\n----------------------------------------\n\nTITLE: Setting tidb_max_bytes_before_tiflash_external_sort Variable\nDESCRIPTION: This variable specifies the maximum memory usage for TopN and Sort operators in TiFlash before spilling to disk. It affects a single TiFlash node when multiple nodes are present. When set to -1, TiFlash uses its own configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_45\n\nLANGUAGE: SQL\nCODE:\n```\nSET [GLOBAL] tidb_max_bytes_before_tiflash_external_sort = <value>;\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating Temporary Table in Java\nDESCRIPTION: Java method to create a temporary table, insert data, and retrieve the top 50 eldest authors using JDBC.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_3\n\nLANGUAGE: java\nCODE:\n```\npublic List<Author> getTop50EldestAuthorInfo() throws SQLException {\n    List<Author> authors = new ArrayList<>();\n    try (Connection conn = ds.getConnection()) {\n        Statement stmt = conn.createStatement();\n        stmt.executeUpdate(\"\"\"\n            CREATE TEMPORARY TABLE top_50_eldest_authors (\n                id BIGINT,\n                name VARCHAR(255),\n                age INT,\n                PRIMARY KEY(id)\n            );\n        \"\"\");\n\n        stmt.executeUpdate(\"\"\"\n            INSERT INTO top_50_eldest_authors\n            SELECT a.id, a.name, (IFNULL(a.death_year, YEAR(NOW())) - a.birth_year) AS age\n            FROM authors a\n            ORDER BY age DESC\n            LIMIT 50;\n        \"\"\");\n\n        ResultSet rs = stmt.executeQuery(\"\"\"\n            SELECT id, name FROM top_50_eldest_authors;\n        \"\"\");\n\n        while (rs.next()) {\n            Author author = new Author();\n            author.setId(rs.getLong(\"id\"));\n            author.setName(rs.getString(\"name\"));\n            authors.add(author);\n        }\n    }\n    return authors;\n}\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Replication Task\nDESCRIPTION: Command to create a new TiCDC replication task with specified server, sink URI and changefeed ID parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://10.0.10.25:8300 --sink-uri=\"mysql://root:123456@127.0.0.1:3306/\" --changefeed-id=\"simple-replication-task\"\n```\n\n----------------------------------------\n\nTITLE: BookDAO Implementation with Stale Read Support\nDESCRIPTION: Implements a DAO class with methods to query books using stale read functionality, including error handling for specific TiDB scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-stale-read.md#2025-04-18_snippet_8\n\nLANGUAGE: java\nCODE:\n```\npublic class BookDAO {\n\n    public List<Book> getTop5LatestBooksWithTxnStaleRead(Integer seconds) throws SQLException {\n        List<Book> books = new ArrayList<>();\n        try (Connection conn = ds.getConnection()) {\n            TxnHelper.startTxnWithStaleRead(conn, seconds);\n\n            Statement stmt = conn.createStatement();\n            ResultSet rs = stmt.executeQuery(\"\"\"\n            SELECT id, title, type, price FROM books ORDER BY published_at DESC LIMIT 5;\n            \"\"\");\n            while (rs.next()) {\n                Book book = new Book();\n                book.setId(rs.getLong(\"id\"));\n                book.setTitle(rs.getString(\"title\"));\n                book.setType(rs.getString(\"type\"));\n                book.setPrice(rs.getDouble(\"price\"));\n                books.add(book);\n            }\n\n            conn.commit();\n        } catch (SQLException e) {\n            if (\"HY000\".equals(e.getSQLState()) && e.getErrorCode() == 1105) {\n                System.out.println(\"WARN: cannot set read timestamp to a future time.\");\n            } else if (\"HY000\".equals(e.getSQLState()) && e.getErrorCode() == 9006) {\n                System.out.println(\"WARN: GC life time is shorter than transaction duration.\");\n            } else {\n                throw e;\n            }\n        }\n        return books;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting TiFlash Replica in SQL\nDESCRIPTION: This SQL command sets the number of TiFlash replicas for a specific table to 1. It should be executed after scaling out the TiFlash cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-disaggregated-and-s3.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name SET TIFLASH REPLICA 1;\n```\n\n----------------------------------------\n\nTITLE: Query Active Connections in TiDB Cluster\nDESCRIPTION: SQL query to list all active connections in the cluster showing connection ID, user, instance, and query information.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-kill.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ID, USER, INSTANCE, INFO FROM INFORMATION_SCHEMA.CLUSTER_PROCESSLIST;\n```\n\n----------------------------------------\n\nTITLE: Efficiently Filtering Aggregate Results in SQL using GROUPING\nDESCRIPTION: This SQL snippet illustrates filtering aggregate results at multiple dimensions using the GROUPING function, allowing for selective display of summarized data per specified criteria.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/group-by-modifier.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT year, month, SUM(profit) AS profit, grouping(year) as grp_year, grouping(month) as grp_month FROM bank GROUP BY year, month WITH ROLLUP HAVING GROUPING(year, month) <> 0 ORDER BY year DESC, month DESC;\n```\n\n----------------------------------------\n\nTITLE: Configure PD Leader Priority\nDESCRIPTION: This code snippet configures the leader priority for PD nodes. It increases the priority of local PD nodes (in Seattle) and decreases the priority of PD nodes in the remote region (San Francisco) to ensure the PD leader is located in the preferred region.\nSOURCE: https://github.com/pingcap/docs/blob/master/three-data-centers-in-two-cities-deployment.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n\"member leader_priority PD-10 5\\nmember leader_priority PD-11 5\\nmember leader_priority PD-12 5\\nmember leader_priority PD-13 5\\nmember leader_priority PD-14 1\"\n```\n\n----------------------------------------\n\nTITLE: Configuring DR Auto-Sync Mode in PD Configuration File (TOML)\nDESCRIPTION: TOML configuration for enabling DR Auto-Sync mode in the PD configuration file before cluster deployment. Defines primary and DR availability zones, replica counts, and timeout settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/two-data-centers-in-one-city-deployment.md#2025-04-18_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[replication-mode]\nreplication-mode = \"dr-auto-sync\"\n[replication-mode.dr-auto-sync]\nlabel-key = \"az\"\nprimary = \"east\"\ndr = \"west\"\nprimary-replicas = 3\ndr-replicas = 2\nwait-store-timeout = \"1m\"\nwait-recover-timeout = \"0s\"\npause-region-split = false\n```\n\n----------------------------------------\n\nTITLE: Creating Plan Binding from Historical Execution Plan\nDESCRIPTION: Example of creating a binding using a historical execution plan's digest value to fix the query plan for specific SQL statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nCREATE BINDING FROM HISTORY USING PLAN DIGEST '4e3159169cc63c14b139a4e7d72eae1759875c9a9581f94bb2079aae961189cb';\n```\n\n----------------------------------------\n\nTITLE: Basic INSERT INTO SELECT Example\nDESCRIPTION: Simple example demonstrating how to save query results from table t1 into table t2 using INSERT INTO SELECT.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-results-materialization.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t2 (name, country)\nSELECT app_name, country FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Limiting Write Speed to TiKV during Import\nDESCRIPTION: This SQL statement limits the write speed to a TiKV node to 10 MiB/s during the import process.  The `MAX_WRITE_SPEED='10MiB'` option throttles the write speed, preventing overload of TiKV nodes.  This is useful for large imports.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t FROM 's3://bucket/path/to/file.parquet?access-key=XXX&secret-access-key=XXX' FORMAT 'parquet' WITH MAX_WRITE_SPEED='10MiB';\n```\n\n----------------------------------------\n\nTITLE: Configuring compression-per-level for Default CF in TiKV\nDESCRIPTION: This snippet shows how to change the `compression-per-level` parameter for the default CF in TiKV to improve disk I/O performance when the default CF compaction experiences high pressure.  This can be achieved by using a compression algorithm with a higher compression ratio.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_6\n\nLANGUAGE: TOML\nCODE:\n```\n\"[rocksdb.defaultcf] compression-per-level = [\\\"no\\\", \\\"no\\\", \\\"zstd\\\", \\\"zstd\\\", \\\"zstd\\\", \\\"zstd\\\", \\\"zstd\\\"]\"\n```\n\n----------------------------------------\n\nTITLE: MySQL connection string example for TiDB Cloud Dedicated\nDESCRIPTION: This is an example of the connection string to be used for TiDB Cloud Dedicated when using the LOAD DATA statement to load data from local data files. It includes options for user, host, port, database, SSL mode, TLS version, and enables local file loading.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-load-data.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nmysql --connect-timeout 15 --ssl-mode=VERIFY_IDENTITY --ssl-ca=<CA_path> --tls-version=\"TLSv1.2\" -u root -h <host_name> -P 4000 -D test -p<your_password> --local-infile\n```\n\n----------------------------------------\n\nTITLE: Viewing MVCC with tikv-ctl Shell\nDESCRIPTION: This shell command uses tikv-ctl to view the MVCC of a specified key in a TiKV database. The command requires the key as the escaped form of the raw key. The tool displays write CF values along with the start and commit timestamps, and a short value representation. Dependencies include a valid data directory path and the tikv-ctl executable.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir /path/to/tikv mvcc -k \"zmDB:29\\000\\000\\377\\000\\374\\000\\000\\000\\000\\000\\000\\377\\000H\\000\\000\\000\\000\\000\\000\\371\" --show-cf=lock,write,default\n```\n\nLANGUAGE: shell\nCODE:\n```\nkey: zmDB:29\\000\\000\\377\\000\\374\\000\\000\\000\\000\\000\\000\\377\\000H\\000\\000\\000\\000\\000\\000\\371\n         write cf value: start_ts: 399650105239273474 commit_ts: 399650105239273475 short_value: \"\\000\\000\\000\\000\\000\\000\\000\\002\"\n         write cf value: start_ts: 399650105199951882 commit_ts: 399650105213059076 short_value: \"\\000\\000\\000\\000\\000\\000\\000\\001\"\n```\n\n----------------------------------------\n\nTITLE: Executing Terraform Commands for Import Task Management\nDESCRIPTION: Terminal commands for applying Terraform configurations, checking import task status, and refreshing state information for TiDB Cloud import tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-import-resource.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform apply\n...\nPlan: 1 to add, 0 to change, 0 to destroy.\n\nDo you want to perform these actions?\nTerraform will perform the actions described above.\nOnly 'yes' will be accepted to approve.\n\nEnter a value: yes\n\ntidbcloud_import.example_local: Creating...\ntidbcloud_import.example_local: Creation complete after 6s [id=781074]\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform state show tidbcloud_import.example_local\n# tidbcloud_import.example_local:\nresource \"tidbcloud_import\" \"example_local\" {\n    all_completed_tables          = [\n        {\n            message    = \"\"\n            result     = \"SUCCESS\"\n            table_name = \"`test`.`import_test`\"\n        },\n    ]\n    cluster_id                    = \"1379661944641274168\"\n    completed_percent             = 100\n    completed_tables              = 1\n    created_at                    = \"2023-02-06T05:39:46.000Z\"\n    csv_format                    = {\n        separator = \";\"\n    }\n    data_format                   = \"CSV\"\n    elapsed_time_seconds          = 48\n    file_name                     = \"./t.csv\"\n    id                            = \"781074\"\n    new_file_name                 = \"2023-02-06T05:39:42Z-t.csv\"\n    pending_tables                = 0\n    post_import_completed_percent = 100\n    processed_source_data_size    = \"31\"\n    project_id                    = \"1372813089191151295\"\n    status                        = \"IMPORTING\"\n    target_table                  = {\n        database = \"test\"\n        table  = \"import_test\"\n    }\n    total_files                   = 0\n    total_size                    = \"31\"\n    total_tables_count            = 1\n    type                          = \"LOCAL\"\n}\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform refresh && terraform state show tidbcloud_import.example_local\ntidbcloud_import.example_local: Refreshing state... [id=781074]\n# tidbcloud_import.example_local:\nresource \"tidbcloud_import\" \"example_local\" {\n    all_completed_tables          = [\n        {\n            message    = \"\"\n            result     = \"SUCCESS\"\n            table_name = \"`test`.`import_test`\"\n        },\n    ]\n    cluster_id                    = \"1379661944641274168\"\n    completed_percent             = 100\n    completed_tables              = 1\n    created_at                    = \"2023-02-06T05:39:46.000Z\"\n    csv_format                    = {\n        separator = \";\"\n    }\n    data_format                   = \"CSV\"\n    elapsed_time_seconds          = 49\n    file_name                     = \"./t.csv\"\n    id                            = \"781074\"\n    new_file_name                 = \"2023-02-06T05:39:42Z-t.csv\"\n    pending_tables                = 0\n    post_import_completed_percent = 100\n    processed_source_data_size    = \"31\"\n    project_id                    = \"1372813089191151295\"\n    status                        = \"COMPLETED\"\n    target_table                  = {\n        database = \"test\"\n        table  = \"import_test\"\n    }\n    total_files                   = 0\n    total_size                    = \"31\"\n    total_tables_count            = 1\n    type                          = \"LOCAL\"\n}\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform apply\n...\nPlan: 2 to add, 0 to change, 0 to destroy.\n\nDo you want to perform these actions?\nTerraform will perform the actions described above.\nOnly 'yes' will be accepted to approve.\n\nEnter a value: yes\n\ntidbcloud_import.example_s3_csv: Creating...\ntidbcloud_import.example_s3_csv: Creation complete after 3s [id=781075]\ntidbcloud_import.example_s3_parquet: Creating...\ntidbcloud_import.example_s3_parquet: Creation complete after 4s [id=781076]\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform destroy\n...\nPlan: 0 to add, 0 to change, 1 to destroy.\n\nDo you really want to destroy all resources?\n  Terraform will destroy all your managed infrastructure, as shown above.\n  There is no undo. Only 'yes' will be accepted to confirm.\n\n  Enter a value: yes\n\ntidbcloud_import.example_local: Destroying... [id=781074]\n╷\n│ Error: Delete Error\n│\n│ Unable to call CancelImport, got error: [DELETE /api/internal/projects/{project_id}/clusters/{cluster_id}/imports/{id}][500] CancelImport default  &{Code:59900104 Details:[] Message:failed to cancel\n│ import}\n╵\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform destroy\n...\nPlan: 0 to add, 0 to change, 1 to destroy.\n\nDo you really want to destroy all resources?\n  Terraform will destroy all your managed infrastructure, as shown above.\n  There is no undo. Only 'yes' will be accepted to confirm.\n\n  Enter a value: yes\n\ntidbcloud_import.example_local: Destroying... [id=781074]\ntidbcloud_import.example_local: Destruction complete after 0s\n\nDestroy complete! Resources: 1 destroyed.\n```\n\n----------------------------------------\n\nTITLE: Using Global Temporary Table in Java\nDESCRIPTION: Java method to create a global temporary table, insert data, and retrieve the top 50 eldest authors using JDBC with transaction management.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_5\n\nLANGUAGE: java\nCODE:\n```\npublic List<Author> getTop50EldestAuthorInfo() throws SQLException {\n    List<Author> authors = new ArrayList<>();\n    try (Connection conn = ds.getConnection()) {\n        conn.setAutoCommit(false);\n\n        Statement stmt = conn.createStatement();\n        stmt.executeUpdate(\"\"\"\n            CREATE GLOBAL TEMPORARY TABLE IF NOT EXISTS top_50_eldest_authors (\n                id BIGINT,\n                name VARCHAR(255),\n                age INT,\n                PRIMARY KEY(id)\n            ) ON COMMIT DELETE ROWS;\n        \"\"\");\n\n        stmt.executeUpdate(\"\"\"\n            INSERT INTO top_50_eldest_authors\n            SELECT a.id, a.name, (IFNULL(a.death_year, YEAR(NOW())) - a.birth_year) AS age\n            FROM authors a\n            ORDER BY age DESC\n            LIMIT 50;\n        \"\"\");\n\n        ResultSet rs = stmt.executeQuery(\"\"\"\n            SELECT id, name FROM top_50_eldest_authors;\n        \"\"\");\n\n        conn.commit();\n        while (rs.next()) {\n            Author author = new Author();\n            author.setId(rs.getLong(\"id\"));\n            author.setName(rs.getString(\"name\"));\n            authors.add(author);\n        }\n    }\n    return authors;\n}\n```\n\n----------------------------------------\n\nTITLE: Sample Endpoint Call with curl\nDESCRIPTION: Demonstrates how to call a Data Service endpoint using curl command, showing basic HTTP request interaction with TiDB Cloud Data Service\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-get-started.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \"https://<region>.data.tidbcloud.com/api/v1beta/app/<App ID>/endpoint/my_endpoint/get_id\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Region Bucket in TiKV\nDESCRIPTION: Enable the Region bucket feature to improve query concurrency when using larger Region sizes. Set 'coprocessor.enable-region-bucket' to true and control bucket size with 'coprocessor.region-bucket-size'.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-region-performance.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ncoprocessor:\n  enable-region-bucket: true\n  region-bucket-size: 96MiB\n```\n\n----------------------------------------\n\nTITLE: Creating a View in TiDB SQL\nDESCRIPTION: This snippet demonstrates how to create a view in TiDB using the CREATE VIEW statement. It defines a view that joins the books and ratings tables to get a list of books with average ratings.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-views.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE VIEW book_with_ratings AS\nSELECT b.id AS book_id, ANY_VALUE(b.title) AS book_title, AVG(r.score) AS average_score\nFROM books b\nLEFT JOIN ratings r ON b.id = r.book_id\nGROUP BY b.id;\n```\n\n----------------------------------------\n\nTITLE: Defining ALTER TABLE MODIFY COLUMN Syntax in SQL\nDESCRIPTION: This snippet details the EBNF syntax for the ALTER TABLE MODIFY COLUMN statement in TiDB. It showcases the diverse column options that can be applied during alteration, such as changing column types and attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-modify-column.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\nAlterTableStmt\n         ::= 'ALTER' 'IGNORE'? 'TABLE' TableName ModifyColumnSpec ( ',' ModifyColumnSpec )*\n\nModifyColumnSpec\n         ::= 'MODIFY' ColumnKeywordOpt 'IF EXISTS' ColumnName ColumnType ColumnOption* ( 'FIRST' | 'AFTER' ColumnName )?\n\nColumnType\n         ::= NumericType\n           | StringType\n           | DateAndTimeType\n           | 'SERIAL'\n\nColumnOption\n         ::= 'NOT'? 'NULL'\n           | 'AUTO_INCREMENT'\n           | 'PRIMARY'? 'KEY' ( 'CLUSTERED' | 'NONCLUSTERED' )?\n           | 'UNIQUE' 'KEY'?\n           | 'DEFAULT' ( NowSymOptionFraction | SignedLiteral | NextValueForSequence )\n           | 'SERIAL' 'DEFAULT' 'VALUE'\n           | 'ON' 'UPDATE' NowSymOptionFraction\n           | 'COMMENT' stringLit\n           | ( 'CONSTRAINT' Identifier? )? 'CHECK' '(' Expression ')' ( 'NOT'? ( 'ENFORCED' | 'NULL' ) )?\n           | 'GENERATED' 'ALWAYS' 'AS' '(' Expression ')' ( 'VIRTUAL' | 'STORED' )?\n           | 'REFERENCES' TableName ( '(' IndexPartSpecificationList ')' )? Match? OnDeleteUpdateOpt\n           | 'COLLATE' CollationName\n           | 'COLUMN_FORMAT' ColumnFormat\n           | 'STORAGE' StorageMedia\n           | 'AUTO_RANDOM' ( '(' LengthNum ')' )?\n\nColumnName ::= Identifier ( '.' Identifier ( '.' Identifier )? )?\n```\n\n----------------------------------------\n\nTITLE: Error Example for Multiple Table Joins in Non-Transactional DML\nDESCRIPTION: Example showing an error that occurs when executing a non-transactional DML statement with a WHERE clause that involves tables other than the one where the shard column is defined.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nBATCH ON test.t2.id LIMIT 1 \nINSERT INTO t \nSELECT t2.id, t2.v, t3.id FROM t2, t3 WHERE t2.id = t3.id\n```\n\n----------------------------------------\n\nTITLE: Logging into TiDB Database via MySQL Client\nDESCRIPTION: This snippet provides the command to log into the TiDB database using the MySQL client. It requires the server IP address and port where TiDB is running, and it assumes the root user credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/post-installation-check.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmysql -u root -h ${tidb_server_host_IP_address} -P 4000\n```\n\n----------------------------------------\n\nTITLE: Inserting Vector Embeddings\nDESCRIPTION: SQL statement to insert sample documents with their corresponding vector embeddings into the table.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-sql.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO embedded_documents\nVALUES\n    (1, 'dog', '[1,2,1]'),\n    (2, 'fish', '[1,2,4]'),\n    (3, 'tree', '[1,0,0]');\n```\n\n----------------------------------------\n\nTITLE: Using SHOW ANALYZE STATUS in TiDB\nDESCRIPTION: Example SQL commands demonstrating the usage of SHOW ANALYZE STATUS, including table creation, analyzing, and viewing the status of analyze tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-analyze-status.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> create table t(x int, index idx(x)) partition by hash(x) partitions 2;\nQuery OK, 0 rows affected (0.69 sec)\n\nmysql> set @@tidb_analyze_version = 1;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> analyze table t;\nQuery OK, 0 rows affected (0.20 sec)\n\nmysql> show analyze status;\n+--------------+------------+----------------+-------------------+----------------+---------------------+---------------------+----------+-------------+----------------+------------+------------------+----------+---------------------+\n| Table_schema | Table_name | Partition_name | Job_info          | Processed_rows | Start_time          | End_time            | State    | Fail_reason | Instance       | Process_ID | Remaining_seconds| Progress | Estimated_total_rows|\n+--------------+------------+----------------+-------------------+----------------+---------------------+---------------------+----------+-------------+----------------+------------+------------------+----------+---------------------+\n| test         | t          | p1             | analyze index idx |              0 | 2022-05-27 11:29:46 | 2022-05-27 11:29:46 | finished | NULL        | 127.0.0.1:4000 | NULL       | NULL             | NULL     | NULL                |\n| test         | t          | p0             | analyze index idx |              0 | 2022-05-27 11:29:46 | 2022-05-27 11:29:46 | finished | NULL        | 127.0.0.1:4000 | NULL       | NULL             | NULL     | NULL                |\n| test         | t          | p1             | analyze columns   |              0 | 2022-05-27 11:29:46 | 2022-05-27 11:29:46 | finished | NULL        | 127.0.0.1:4000 | NULL       | NULL             | NULL     | NULL                |\n| test         | t          | p0             | analyze columns   |              0 | 2022-05-27 11:29:46 | 2022-05-27 11:29:46 | finished | NULL        | 127.0.0.1:4000 | NULL       | NULL             | NULL     | NULL                |\n| test         | t1         | p0             | analyze columns   |       28523259 | 2022-05-27 11:29:46 | 2022-05-27 11:29:46 | running  | NULL        | 127.0.0.1:4000 | 690208308  | 0s               | 0.9843   | 28978290            |\n+--------------+------------+----------------+-------------------+----------------+---------------------+---------------------+----------+-------------+----------------+------------+------------------+----------+---------------------+\n4 rows in set (0.01 sec)\n\nmysql> set @@tidb_analyze_version = 2;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> analyze table t;\nQuery OK, 0 rows affected, 2 warnings (0.03 sec)\n\nmysql> show analyze status;\n+--------------+------------+----------------+--------------------------------------------------------------------+----------------+---------------------+---------------------+----------+-------------+----------------+------------+--------------------+----------+----------------------+\n| Table_schema | Table_name | Partition_name | Job_info                                                           | Processed_rows | Start_time          | End_time            | State    | Fail_reason | Instance       | Process_ID | Remaining_seconds  | Progress | Estimated_total_rows |\n+--------------+------------+----------------+--------------------------------------------------------------------+----------------+---------------------+---------------------+----------+-------------+----------------+------------+--------------------+----------+----------------------+\n| test         | t          | p1             | analyze table all columns with 256 buckets, 500 topn, 1 samplerate |              0 | 2022-05-27 11:30:12 | 2022-05-27 11:30:12 | finished | NULL        | 127.0.0.1:4000 | NULL       | NULL               | NULL     | NULL                 |\n| test         | t          | p0             | analyze table all columns with 256 buckets, 500 topn, 1 samplerate |              0 | 2022-05-27 11:30:12 | 2022-05-27 11:30:12 | finished | NULL        | 127.0.0.1:4000 | NULL       | NULL               | NULL     | NULL                 |\n| test         | t          | p1             | analyze index idx                                                  |              0 | 2022-05-27 11:29:46 | 2022-05-27 11:29:46 | finished | NULL        | 127.0.0.1:4000 | NULL       | NULL               | NULL     | NULL                 |\n| test         | t          | p0             | analyze index idx                                                  |              0 | 2022-05-27 11:29:46 | 2022-05-27 11:29:46 | finished | NULL        | 127.0.0.1:4000 | NULL       | NULL               | NULL     | NULL                 |\n| test         | t          | p1             | analyze columns                                                    |              0 | 2022-05-27 11:29:46 | 2022-05-27 11:29:46 | finished | NULL        | 127.0.0.1:4000 | NULL       | NULL               | NULL     | NULL                 |\n| test         | t          | p0             | analyze columns                                                    |              0 | 2022-05-27 11:29:46 | 2022-05-27 11:29:46 | finished | NULL        | 127.0.0.1:4000 | NULL       | NULL               | NULL     | NULL                 |\n+--------------+------------+----------------+--------------------------------------------------------------------+----------------+---------------------+---------------------+----------+-------------+----------------+------------+--------------------+----------+----------------------+\n6 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Selecting Data from a Local Temporary Table\nDESCRIPTION: This code snippet retrieves all rows from the session-specific local temporary table, showing the inserted values.\nSOURCE: https://github.com/pingcap/docs/blob/master/temporary-tables.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM users;\n```\n\n----------------------------------------\n\nTITLE: Enabling Dictionary Check in TiDB Passwords\nDESCRIPTION: This SQL command activates a dictionary check for passwords in TiDB, preventing the use of certain words like 'mysql' or 'abcd' by setting 'validate_password.dictionary' with a semicolon-separated list.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL validate_password.dictionary = 'mysql;abcd';\n```\n\n----------------------------------------\n\nTITLE: SQL commands for verifying loaded data in TiDB Cloud\nDESCRIPTION: SQL commands to verify the database and tables created by dbt in TiDB Cloud, including listing databases, viewing tables in the analytics database, and querying sample data from the raw_customers table.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| INFORMATION_SCHEMA |\n| METRICS_SCHEMA     |\n| PERFORMANCE_SCHEMA |\n| analytics          |\n| io_replicate       |\n| mysql              |\n| test               |\n+--------------------+\n7 rows in set (0.00 sec)\n\nmysql> USE ANALYTICS;\nmysql> SHOW TABLES;\n+---------------------+\n| Tables_in_analytics |\n+---------------------+\n| raw_customers       |\n| raw_orders          |\n| raw_payments        |\n+---------------------+\n3 rows in set (0.00 sec)\n\nmysql> SELECT * FROM raw_customers LIMIT 10;\n+------+------------+-----------+\n| id   | first_name | last_name |\n+------+------------+-----------+\n|    1 | Michael    | P.        |\n|    2 | Shawn      | M.        |\n|    3 | Kathleen   | P.        |\n|    4 | Jimmy      | C.        |\n|    5 | Katherine  | R.        |\n|    6 | Sarah      | R.        |\n|    7 | Martin     | M.        |\n|    8 | Frank      | R.        |\n|    9 | Jennifer   | F.        |\n|   10 | Henry      | W.        |\n+------+------------+-----------+\n10 rows in set (0.10 sec)\n```\n\n----------------------------------------\n\nTITLE: TTL with Default Timestamp\nDESCRIPTION: Creates a table with TTL using CURRENT_TIMESTAMP as default value for tracking creation time.\nSOURCE: https://github.com/pingcap/docs/blob/master/time-to-live.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n    id int PRIMARY KEY,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n) TTL = `created_at` + INTERVAL 3 MONTH;\n```\n\n----------------------------------------\n\nTITLE: Configuring Sysbench for TiDB\nDESCRIPTION: This configuration file sets up Sysbench for testing TiDB. It specifies connection details such as host, port, and user, alongside benchmark parameters like time duration and thread count. It also includes error codes to ignore and settings for auto-increment. This setup requires access to a TiDB instance and appropriate credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-performance-reference.md#2025-04-18_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\nmysql-host={TIDB_HOST}\nmysql-port=4000\nmysql-user=root\nmysql-password=password\nmysql-db=sbtest\ntime=1200\nthreads={100}\nreport-interval=10\ndb-driver=mysql\nmysql-ignore-errors=1062,2013,8028,9002,9007\nauto-inc=false\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Test Table and Querying Its Column Information\nDESCRIPTION: This SQL example shows how to create a test table and then query the COLUMNS table to retrieve metadata about the columns in that table. The \\G modifier formats the output vertically for better readability.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-columns.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test.t1 (a int);\nSELECT * FROM COLUMNS WHERE table_schema='test' AND TABLE_NAME='t1'\\G\n```\n\n----------------------------------------\n\nTITLE: Inserting Values into MySQL Table in SQL\nDESCRIPTION: This SQL snippet performs an insertion of data into the previously defined table 't', explicitly specifying all columns except for the auto-incremented 'id'. It uses various types of values including decimal, strings, binary, and enum.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\ninsert into t (c_decimal, c_char, c_varchar, c_binary, c_varbinary, c_enum, c_set, c_bit)\nvalues (123.456, \"abc\", \"abc\", \"abc\", \"abc\", 'a', 'a,b', b'1000001');\n```\n\n----------------------------------------\n\nTITLE: Initializing Embedding Model in Python\nDESCRIPTION: Sets up the SentenceTransformer model for text embedding and defines a function to convert text to vector embeddings.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-python.md#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom sentence_transformers import SentenceTransformer\n\nprint(\"Downloading and loading the embedding model...\")\nembed_model = SentenceTransformer(\"sentence-transformers/msmarco-MiniLM-L12-cos-v5\", trust_remote_code=True)\nembed_model_dims = embed_model.get_sentence_embedding_dimension()\n\ndef text_to_embedding(text):\n    \"\"\"Generates vector embeddings for the given text.\"\"\"\n    embedding = embed_model.encode(text)\n    return embedding.tolist()\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Resources by Dropping Table in SQL\nDESCRIPTION: Demonstrates how to clean up resources by dropping the created table using SQL within a Python context.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nvector_store.tidb_vector_client.execute(\"DROP TABLE airplan_routes\")\n```\n\n----------------------------------------\n\nTITLE: Counting Bits Using BIT_COUNT in SQL\nDESCRIPTION: The BIT_COUNT(expr) function counts the number of bits that are set to 1 in the given expression. It requires the input to be a binary number prefixed with 'b'. The expected input is a binary literal, and it outputs an integer representing the count of 1s.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/bit-functions-and-operators.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT BIT_COUNT(b'00101001');\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT BIT_COUNT(0x29), CONV(0x29,16,2);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT BIT_COUNT(INET_ATON('255.255.255.0'));\n```\n\n----------------------------------------\n\nTITLE: Truncating Outdated Log Backup Data in TiDB\nDESCRIPTION: Command to truncate log backup data older than a specified time (May 14, 2022), used for cleaning up outdated backup data.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-use-cases.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log truncate --until='2022-05-14 00:00:00 +0800' --storage='s3://tidb-pitr-bucket/backup-data/log-backup'\n```\n\n----------------------------------------\n\nTITLE: Using NEXTVAL Function with Sequence\nDESCRIPTION: Demonstrates how to use the NEXTVAL() function to get the next value of a sequence object.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-sequence.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT NEXTVAL(seq);\n```\n\n----------------------------------------\n\nTITLE: Configuring RocksDB Default Column Family in TiKV\nDESCRIPTION: Configuration settings for the default column family in RocksDB, including compression settings, memtable size, and write buffer parameters. These settings control how data is stored, compressed, and flushed to disk.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-tikv-memory-performance.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\ncompression-per-level = [\"no\", \"no\", \"lz4\", \"lz4\", \"lz4\", \"zstd\", \"zstd\"]\n\n# The RocksDB memtable size\nwrite-buffer-size = \"128MiB\"\n\n# The maximum number of the memtables. The data written into RocksDB is first recorded in the WAL log, and then inserted\n# into memtables. When the memtable reaches the size limit of `write-buffer-size`, it turns into read only and generates\n# a new memtable receiving new write operations. The flush threads of RocksDB will flush the read only memtable to the\n# disks to become an sst file of level0. `max-background-flushes` controls the maximum number of flush threads. When the\n# flush threads are busy, resulting in the number of the memtables waiting to be flushed to the disks reaching the limit\n# of `max-write-buffer-number`, RocksDB stalls the new operation.\n# \"Stall\" is a flow control mechanism of RocksDB. When importing data, you can set the `max-write-buffer-number` value\n# higher, like 10.\nmax-write-buffer-number = 5\n\n# When the number of sst files of level0 reaches the limit of `level0-slowdown-writes-trigger`, RocksDB\n# tries to slow down the write operation, because too many sst files of level0 can cause higher read pressure of\n# RocksDB. `level0-slowdown-writes-trigger` and `level0-stop-writes-trigger` are for the flow control of RocksDB.\n# When the number of sst files of level0 reaches 4 (the default value), the sst files of level0 and the sst files\n# of level1 which overlap those of level0 implement compaction to relieve the read pressure.\nlevel0-slowdown-writes-trigger = 20\n\n# When the number of sst files of level0 reaches the limit of `level0-stop-writes-trigger`, RocksDB stalls the new\n# write operation.\nlevel0-stop-writes-trigger = 36\n\n# When the level1 data size reaches the limit value of `max-bytes-for-level-base`, the sst files of level1\n# and their overlap sst files of level2 implement compaction. The golden rule: the first reference principle\n# of setting `max-bytes-for-level-base` is guaranteeing that the `max-bytes-for-level-base` value is roughly equal to the\n# data volume of level0. Thus unnecessary compaction is reduced. For example, if the compaction mode is\n# \"no:no:lz4:lz4:lz4:lz4:lz4\", the `max-bytes-for-level-base` value is write-buffer-size * 4, because there is no\n# compaction of level0 and level1 and the trigger condition of compaction for level0 is that the number of the\n# sst files reaches 4 (the default value). When both level0 and level1 adopt compaction, it is necessary to analyze\n# RocksDB logs to know the size of an sst file compressed from an mentable. For example, if the file size is 32MB,\n# the proposed value of `max-bytes-for-level-base` is 32MiB * 4 = 128MiB.\nmax-bytes-for-level-base = \"512MiB\"\n\n# The sst file size. The sst file size of level0 is influenced by the compaction algorithm of `write-buffer-size`\n# and level0. `target-file-size-base` is used to control the size of a single sst file of level1-level6.\ntarget-file-size-base = \"32MiB\"\n```\n\n----------------------------------------\n\nTITLE: GRANT Statement EBNF Syntax Definition for TiDB\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the GRANT statement in TiDB, which follows MySQL's privilege model where credentials are assigned based on database/table patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-grant-privileges.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nGrantStmt ::=\n    'GRANT' PrivElemList 'ON' ObjectType PrivLevel 'TO' UserSpecList RequireClauseOpt WithGrantOptionOpt\n\nPrivElemList ::=\n    PrivElem ( ',' PrivElem )*\n\nPrivElem ::=\n    PrivType ( '(' ColumnNameList ')' )?\n\nPrivType ::=\n    'ALL' 'PRIVILEGES'?\n|    'ALTER' 'ROUTINE'?\n|   'CREATE' ( 'USER' | 'TEMPORARY' 'TABLES' | 'VIEW' | 'ROLE' | 'ROUTINE' )?\n|   'TRIGGER'\n|   'DELETE'\n|   'DROP' 'ROLE'?\n|    'PROCESS'\n|   'EXECUTE'\n|   'INDEX'\n|   'INSERT'\n|   'SELECT'\n|   'SUPER'\n|   'SHOW' ( 'DATABASES' | 'VIEW' )\n|   'UPDATE'\n|    'GRANT' 'OPTION'\n|    'REFERENCES'\n|    'REPLICATION' ( 'SLAVE' | 'CLIENT' )\n|    'USAGE'\n|   'RELOAD'\n|   'FILE'\n|   'CONFIG'\n|   'LOCK' 'TABLES'\n|   'EVENT'\n|   'SHUTDOWN'\n\nObjectType ::=\n    'TABLE'?\n\nPrivLevel ::=\n    '*' ( '.' '*' )?\n|    Identifier ( '.' ( '*' | Identifier ) )?\n\nUserSpecList ::=\n    UserSpec ( ',' UserSpec )*\n\nRequireClauseOpt ::= ('REQUIRE' ('NONE' | 'SSL' | 'X509' | RequireListElement ('AND'? RequireListElement)*))?\n\nRequireListElement ::= 'ISSUER' Issuer | 'SUBJECT' Subject | 'CIPHER' Cipher | 'SAN' SAN | 'TOKEN_ISSUER' TokenIssuer\n```\n\n----------------------------------------\n\nTITLE: Updating Data in TiDB SQL\nDESCRIPTION: Updates the value in table 't' where c=2, changing it to 22. This modification demonstrates a change that can later be observed through historical data access.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-read-staleness.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nupdate t set c=22 where c=2;\n```\n\n----------------------------------------\n\nTITLE: Comparing Query Plans with tidb_opt_distinct_agg_push_down in SQL\nDESCRIPTION: This snippet demonstrates the effect of enabling tidb_opt_distinct_agg_push_down on a query plan. It shows how the aggregate function with distinct is pushed down to Coprocessor after enabling the variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_54\n\nLANGUAGE: sql\nCODE:\n```\nmysql> desc select count(distinct a) from test.t;\n+-------------------------+----------+-----------+---------------+------------------------------------------+\n| id                      | estRows  | task      | access object | operator info                            |\n+-------------------------+----------+-----------+---------------+------------------------------------------+\n| StreamAgg_6             | 1.00     | root      |               | funcs:count(distinct test.t.a)->Column#4 |\n| └─TableReader_10        | 10000.00 | root      |               | data:TableFullScan_9                     |\n|   └─TableFullScan_9     | 10000.00 | cop[tikv] | table:t       | keep order:false, stats:pseudo           |\n+-------------------------+----------+-----------+---------------+------------------------------------------+\n3 rows in set (0.01 sec)\n\nmysql> set session tidb_opt_distinct_agg_push_down = 1;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> desc select count(distinct a) from test.t;\n+---------------------------+----------+-----------+---------------+------------------------------------------+\n| id                        | estRows  | task      | access object | operator info                            |\n+---------------------------+----------+-----------+---------------+------------------------------------------+\n| HashAgg_8                 | 1.00     | root      |               | funcs:count(distinct test.t.a)->Column#3 |\n| └─TableReader_9           | 1.00     | root      |               | data:HashAgg_5                           |\n|   └─HashAgg_5             | 1.00     | cop[tikv] |               | group by:test.t.a,                       |\n|     └─TableFullScan_7     | 10000.00 | cop[tikv] | table:t       | keep order:false, stats:pseudo           |\n+---------------------------+----------+-----------+---------------+------------------------------------------+\n4 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining TRACE Statement Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the TRACE statement in TiDB. It specifies the structure of the TRACE command, including optional FORMAT specification and traceable statement types.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-trace.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nTraceStmt ::=\n    \"TRACE\" ( \"FORMAT\" \"=\" stringLit )? TracableStmt\n\nTracableStmt ::=\n    ( SelectStmt | DeleteFromStmt | UpdateStmt | InsertIntoStmt | ReplaceIntoStmt | UnionStmt | LoadDataStmt | BeginTransactionStmt | CommitStmt | RollbackStmt | SetStmt )\n```\n\n----------------------------------------\n\nTITLE: Creating Table and Demonstrating Warning Scenarios\nDESCRIPTION: Illustrates how warnings are generated and displayed when performing operations like division by zero and integer overflow\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-warnings.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (a INT UNSIGNED);\nINSERT INTO t1 VALUES (0);\nSELECT 1/a FROM t1;\nSHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: Importing Data from CSV File to TiDB Cloud using MySQL CLI\nDESCRIPTION: Command for importing data from a CSV file into TiDB Cloud using MySQL CLI with the LOAD DATA LOCAL INFILE statement. The command specifies field and line terminators and ignores the header row.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-with-mysql-cli.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmysql --comments --connect-timeout 150 -u '<your_username>' -h <your_host> -P 4000 -D test --ssl-mode=VERIFY_IDENTITY --ssl-ca=<your_ca_path> -p<your_password> -e \"LOAD DATA LOCAL INFILE '<your_csv_path>' INTO TABLE products\nFIELDS TERMINATED BY ','\nLINES TERMINATED BY '\\n'\nIGNORE 1 LINES (product_id, product_name, price);\"\n```\n\n----------------------------------------\n\nTITLE: Creating a resource group with RU limit and burstable option\nDESCRIPTION: This SQL statement creates a resource group named `rg1` with a resource limit of 500 RUs per second, allowing applications in this resource group to overrun resources. The `IF NOT EXISTS` clause ensures that the statement does not fail if the resource group already exists.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-ru-groups.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE RESOURCE GROUP IF NOT EXISTS rg1 RU_PER_SEC = 500 BURSTABLE;\"\n```\n\n----------------------------------------\n\nTITLE: Executing FLASHBACK CLUSTER with TSO in TiDB\nDESCRIPTION: Syntax for executing FLASHBACK CLUSTER using a TSO (Timestamp Oracle) value to restore a cluster to a precise point in time.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-cluster.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nFLASHBACK CLUSTER TO TSO 445494839813079041;\n```\n\n----------------------------------------\n\nTITLE: Executing stop-task Command and Viewing Results in DM\nDESCRIPTION: This snippet shows the execution of the 'stop-task' command for a task named 'test' and displays the returned results, including the operation status and details for each source.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-stop-task.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nstop-task test\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"op\": \"Stop\",\n    \"result\": true,\n    \"msg\": \"\",\n    \"sources\": [\n        {\n            \"result\": true,\n            \"msg\": \"\",\n            \"source\": \"mysql-replica-01\",\n            \"worker\": \"worker1\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with mysqlclient in Python\nDESCRIPTION: This function establishes a connection to TiDB using mysqlclient. It configures the connection parameters and optionally sets up SSL for secure connections.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-mysqlclient.md#2025-04-18_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef get_mysqlclient_connection(autocommit:bool=True) -> MySQLdb.Connection:\n    db_conf = {\n        \"host\": ${tidb_host},\n        \"port\": ${tidb_port},\n        \"user\": ${tidb_user},\n        \"password\": ${tidb_password},\n        \"database\": ${tidb_db_name},\n        \"autocommit\": autocommit\n    }\n\n    if ${ca_path}:\n        db_conf[\"ssl_mode\"] = \"VERIFY_IDENTITY\"\n        db_conf[\"ssl\"] = {\"ca\": ${ca_path}}\n\n    return MySQLdb.connect(**db_conf)\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Hash Partitioning by Year Function in SQL\nDESCRIPTION: This example demonstrates creating a Hash partitioned table 't1' with 4 partitions based on the year extracted from the 'col3' column of DATE type.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_27\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t1 (col1 INT, col2 CHAR(5), col3 DATE)\n    PARTITION BY HASH( YEAR(col3) )\n    PARTITIONS 4;\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up TiUP Installation\nDESCRIPTION: Removes all TiUP components and cleaning up the installation.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\ntiup clean --all\n```\n\n----------------------------------------\n\nTITLE: Creating a Cross-database Binding in TiDB\nDESCRIPTION: Creates a global cross-database binding using wildcards for table names across all databases in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_25\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE GLOBAL BINDING USING SELECT /*+ use_index(t1, idx_a), use_index(t2, idx_a) */ * FROM *.t1, *.t2;\n```\n\n----------------------------------------\n\nTITLE: Task Configuration JSON Structure\nDESCRIPTION: This JSON structure defines a DM replication task with its configuration details including task mode, filtering rules, and migration settings. It represents the complete configuration for a data migration task.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_31\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"task-1\",\n  \"task_mode\": \"all\",\n  \"shard_mode\": \"pessimistic\",\n  \"meta_schema\": \"dm-meta\",\n  \"enhance_online_schema_change\": true,\n  \"on_duplicate\": \"overwrite\",\n  \"target_config\": {\n    \"host\": \"127.0.0.1\",\n    \"port\": 3306,\n    \"user\": \"root\",\n    \"password\": \"123456\",\n    \"security\": {\n      \"ssl_ca_content\": \"\",\n      \"ssl_cert_content\": \"\",\n      \"ssl_key_content\": \"\",\n      \"cert_allowed_cn\": [\n        \"string\"\n      ]\n    }\n  },\n  \"binlog_filter_rule\": {\n    \"rule-1\": {\n      \"ignore_event\": [\n        \"all dml\"\n      ],\n      \"ignore_sql\": [\n        \"^Drop\"\n      ]\n    },\n    \"rule-2\": {\n      \"ignore_event\": [\n        \"all dml\"\n      ],\n      \"ignore_sql\": [\n        \"^Drop\"\n      ]\n    },\n    \"rule-3\": {\n      \"ignore_event\": [\n        \"all dml\"\n      ],\n      \"ignore_sql\": [\n        \"^Drop\"\n      ]\n    }\n  },\n  \"table_migrate_rule\": [\n    {\n      \"source\": {\n        \"source_name\": \"source-name\",\n        \"schema\": \"db-*\",\n        \"table\": \"tb-*\"\n      },\n      \"target\": {\n        \"schema\": \"db1\",\n        \"table\": \"tb1\"\n      },\n      \"binlog_filter_rule\": [\n        \"rule-1\",\n        \"rule-2\",\n        \"rule-3\",\n      ]\n    }\n  ],\n  \"source_config\": {\n    \"full_migrate_conf\": {\n      \"export_threads\": 4,\n      \"import_threads\": 16,\n      \"data_dir\": \"./exported_data\",\n      \"consistency\": \"auto\"\n      \"import_mode\": \"physical\",\n      \"sorting_dir\": \"./sort_dir\",\n      \"disk_quota\": \"80G\",\n      \"checksum\": \"required\",\n      \"analyze\": \"optional\",\n      \"range_concurrency\": 0,\n      \"compress-kv-pairs\": \"\",\n      \"pd_addr\": \"\",\n      \"on_duplicate_logical\": \"error\",\n      \"on_duplicate_physical\": \"none\"\n    },\n    \"incr_migrate_conf\": {\n      \"repl_threads\": 16,\n      \"repl_batch\": 100\n    },\n    \"source_conf\": [\n      {\n        \"source_name\": \"mysql-replica-01\",\n        \"binlog_name\": \"binlog.000001\",\n        \"binlog_pos\": 4,\n        \"binlog_gtid\": \"03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170\"\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating TiCDC Task Configuration\nDESCRIPTION: Series of commands to update the configuration of a replication task by pausing, updating, and resuming the task.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed pause -c test-cf --server=http://10.0.10.25:8300\ncdc cli changefeed update -c test-cf --server=http://10.0.10.25:8300 --sink-uri=\"mysql://127.0.0.1:3306/?max-txn-row=20&worker-count=8\" --config=changefeed.toml\ncdc cli changefeed resume -c test-cf --server=http://10.0.10.25:8300\n```\n\n----------------------------------------\n\nTITLE: Executing Multi-Table Join with BATCH\nDESCRIPTION: Example showing how to properly specify the full column path when using BATCH with multi-table joins to avoid ambiguity.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-batch.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nBATCH ON test.t2.id LIMIT 1 INSERT INTO t SELECT t2.id, t2.v, t3.v FROM t2 JOIN t3 ON t2.k = t3.k;\n```\n\n----------------------------------------\n\nTITLE: Monitoring Metrics Documentation in Markdown\nDESCRIPTION: Structured documentation of TiKV monitoring metrics covering various components including Coprocessor processing, thread management, RocksDB operations, Raft Engine metrics, Titan blob storage, and In-Memory Engine performance indicators.\nSOURCE: https://github.com/pingcap/docs/blob/master/grafana-tikv-dashboard.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### Coprocessor Detail\n\n- Handle duration: The histogram of time spent actually processing coprocessor requests per minute\n- 95% Handle duration by store: The time consumed to handle coprocessor requests per TiKV instance per second (P95)\n- Wait duration: The time consumed when coprocessor requests are waiting to be handled. It should be less than `10s` (P99.99).\n- 95% Wait duration by store: The time consumed when coprocessor requests are waiting to be handled per TiKV instance per second (P95)\n- Total DAG Requests: The total number of DAG requests per second\n- Total DAG Executors: The total number of DAG executors per second\n- Total Ops Details (Table Scan): The number of RocksDB internal operations per second when executing select scan in coprocessor\n- Total Ops Details (Index Scan): The number of RocksDB internal operations per second when executing index scan in coprocessor\n- Total Ops Details by CF (Table Scan): The number of RocksDB internal operations for each CF per second when executing select scan in coprocessor\n- Total Ops Details by CF (Index Scan): The number of RocksDB internal operations for each CF per second when executing index scan in coprocessor\n```\n\n----------------------------------------\n\nTITLE: Community Support Channel Links - TiDB Cloud Platform\nDESCRIPTION: Markdown content block specific to TiDB Cloud platform that provides links to Discord, Slack communities and cloud support ticket system.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_11\n\nLANGUAGE: markdown\nCODE:\n```\n<CustomContent platform=\"tidb-cloud\">\n\nAsk the community on [Discord](https://discord.gg/DQZ2dy3cuc?utm_source=doc) or [Slack](https://slack.tidb.io/invite?team=tidb-community&channel=everyone&ref=pingcap-docs), or [submit a support ticket](https://tidb.support.pingcap.com/).\n\n</CustomContent>\n```\n\n----------------------------------------\n\nTITLE: System Tables Documentation in Markdown\nDESCRIPTION: Markdown list describing new system tables and schemas added to TiDB for tracking index usage statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\n* Add new system tables [`INFORMATION_SCHEMA.TIDB_INDEX_USAGE`](/information-schema/information-schema-tidb-index-usage.md) and [`INFORMATION_SCHEMA.CLUSTER_TIDB_INDEX_USAGE`](/information-schema/information-schema-tidb-index-usage.md#cluster_tidb_index_usage) to record index usage statistics on TiDB nodes.\n* Add a new system schema [`sys`](/sys-schema/sys-schema.md) and a new view [`sys.schema_unused_indexes`](/sys-schema/sys-schema-unused-indexes.md), which records indexes that have not been used since the last start of TiDB.\n```\n\n----------------------------------------\n\nTITLE: Retrieving Cluster Specifications from TiDB Cloud\nDESCRIPTION: Configuration to obtain cluster specification information from TiDB Cloud using the tidbcloud_cluster_specs data source. This shows how to query available configurations like cloud providers, regions, and node sizes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_1\n\nLANGUAGE: terraform\nCODE:\n```\nterraform {\n  required_providers {\n    tidbcloud = {\n      source = \"tidbcloud/tidbcloud\"\n    }\n  }\n}\nprovider \"tidbcloud\" {\n  public_key = \"your_public_key\"\n  private_key = \"your_private_key\"\n  sync = true\n}\ndata \"tidbcloud_cluster_specs\" \"example_cluster_spec\" {\n}\noutput \"cluster_spec\" {\n  value = data.tidbcloud_cluster_specs.example_cluster_spec.items\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Block and Allow Lists in YAML for TiDB Data Migration\nDESCRIPTION: This YAML configuration demonstrates how to set up block and allow lists for database and table filtering in TiDB Data Migration. It includes rules for wildcard matching and regular expressions to specify which databases and tables to include or exclude from migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-block-allow-table-lists.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nblock-allow-list:             # Use black-white-list if the DM version is earlier than or equal to v2.0.0-beta.2.\n  rule-1:\n    do-dbs: [\"test*\"]         # Starting with characters other than \"~\" indicates that it is a wildcard;\n                              # v1.0.5 or later versions support the regular expression rules.\n    do-tables:\n    - db-name: \"test[123]\"    # Matches test1, test2, and test3.\n      tbl-name: \"t[1-5]\"      # Matches t1, t2, t3, t4, and t5.\n    - db-name: \"test\"\n      tbl-name: \"t\"\n  rule-2:\n    do-dbs: [\"~^test.*\"]      # Starting with \"~\" indicates that it is a regular expression.\n    ignore-dbs: [\"mysql\"]\n    do-tables:\n    - db-name: \"~^test.*\"\n      tbl-name: \"~^t.*\"\n    - db-name: \"test\"\n      tbl-name: \"t*\"\n    ignore-tables:\n    - db-name: \"test\"\n      tbl-name: \"log\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Query-level Spilling in SQL\nDESCRIPTION: These SQL statements demonstrate enabling query-level spilling by setting a 5 GiB memory quota per node with a 70% spill ratio threshold, reducing the memory usage of the query to 3.94 GiB.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-spill-disk.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET tiflash_mem_quota_query_per_node = 5368709120;\nSET tiflash_query_spill_ratio = 0.7;\nSELECT\n  l_orderkey,\n  MAX(L_COMMENT),\n  MAX(L_SHIPMODE),\n  MAX(L_SHIPINSTRUCT),\n  MAX(L_SHIPDATE),\n  MAX(L_EXTENDEDPRICE)\nFROM lineitem\nGROUP BY l_orderkey\nHAVING SUM(l_quantity) > 314;\n```\n\n----------------------------------------\n\nTITLE: Setting Maximum Size for Temporary Tables in TiDB - SQL\nDESCRIPTION: This snippet demonstrates how to set a global configuration to limit the size of temporary tables in TiDB, ensuring that their memory consumption does not exceed specified thresholds.\nSOURCE: https://github.com/pingcap/docs/blob/master/temporary-tables.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_tmp_table_max_size=268435456;\n```\n\n----------------------------------------\n\nTITLE: Using NEXTVAL() Function in TiDB\nDESCRIPTION: This snippet shows how to use the NEXTVAL() function to get the next value from a sequence 's1'.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/sequence-functions.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT NEXTVAL(s1);\n```\n\n----------------------------------------\n\nTITLE: Setting Spending Limit in Interactive Mode - TiDB Cloud CLI - Shell\nDESCRIPTION: This code snippet shows the usage of the command to set the spending limit for a TiDB Cloud Serverless cluster in interactive mode, allowing the user to enter values as prompted.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-spending-limit.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless spending-limit\n```\n\n----------------------------------------\n\nTITLE: Defining Rename Index Syntax in EBNF\nDESCRIPTION: Defines the syntax for the RENAME INDEX statement in EBNF format used in TiDB SQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-rename-index.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\nAlterTableStmt\n         ::= 'ALTER' 'IGNORE'? 'TABLE' TableName RenameIndexSpec ( ',' RenameIndexSpec )*\n\nRenameIndexSpec\n         ::= 'RENAME' ( 'KEY' | 'INDEX' ) Identifier 'TO' Identifier\n```\n\n----------------------------------------\n\nTITLE: Installing Diag client using TiUP\nDESCRIPTION: Command to install the Diag diagnostic client tool using TiUP package manager, which is required before using PingCAP Clinic services.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/quick-start-with-clinic.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup install diag\n```\n\n----------------------------------------\n\nTITLE: Creating and Showing Tables in TiDB\nDESCRIPTION: Example SQL statements that create tables and views, followed by the SHOW TABLES query. This illustrates the command's functionality and expected output.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-tables.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (a int);\\nQuery OK, 0 rows affected (0.12 sec)\\n\\nmysql> CREATE VIEW v1 AS SELECT 1;\\nQuery OK, 0 rows affected (0.10 sec)\\n\\nmysql> SHOW TABLES;\\n+----------------+\\n| Tables_in_test |\\n+----------------+\\n| t1             |\\n| v1             |\\n+----------------+\\n2 rows in set (0.00 sec)\\n\\nmysql> SHOW FULL TABLES;\\n+----------------+------------+\\n| Tables_in_test | Table_type |\\n+----------------+------------+\\n| t1             | BASE TABLE |\\n| v1             | VIEW       |\\n+----------------+------------+\\n2 rows in set (0.00 sec)\\n\\nmysql> SHOW TABLES IN mysql;\\n+-------------------------+\\n| Tables_in_mysql         |\\n+-------------------------+\\n| GLOBAL_VARIABLES        |\\n| bind_info               |\\n| columns_priv            |\\n| db                      |\\n| default_roles           |\\n| expr_pushdown_blacklist |\\n| gc_delete_range         |\\n| gc_delete_range_done    |\\n| global_priv             |\\n| help_topic              |\\n| opt_rule_blacklist      |\\n| role_edges              |\\n| stats_buckets           |\\n| stats_feedback          |\\n| stats_histograms        |\\n| stats_meta              |\\n| stats_top_n             |\\n| tables_priv             |\\n| tidb                    |\\n| user                    |\\n+-------------------------+\\n20 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Performing Full Snapshot Backup for TiDB\nDESCRIPTION: Command to back up a complete snapshot of the TiDB cluster to the specified storage, typically scheduled at regular intervals.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-use-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup br backup full\n```\n\n----------------------------------------\n\nTITLE: User-Defined Variables Containing Column Names\nDESCRIPTION: Shows that even when a user-defined variable contains what appears to be a column reference with backticks, TiDB treats it as a string value rather than a column identifier.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSET @col = \"`a`\";\nSELECT @col FROM t;\n```\n\n----------------------------------------\n\nTITLE: Adding a watch list item with PLAN DIGEST matching and action\nDESCRIPTION: This code snippet adds a watch item to the `rg1` resource group using `PLAN DIGEST` for matching. The `ACTION` is set to `KILL`. The PLAN DIGEST value is provided as a string.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n\"QUERY WATCH ADD RESOURCE GROUP rg1 ACTION KILL PLAN DIGEST 'd08bc323a934c39dc41948b0a073725be3398479b6fa4f6dd1db2a9b115f7f57';\"\n```\n\n----------------------------------------\n\nTITLE: Start DM Migration Task\nDESCRIPTION: This shell command uses `tiup dmctl` to start the DM migration task defined in `task.yaml`. It connects to the DM-master at the specified address and executes the `start-task` command.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-to-tidb.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup dmctl --master-addr ${advertise-addr} start-task task.yaml\"\n```\n\n----------------------------------------\n\nTITLE: Executing sync-diff-inspector Command\nDESCRIPTION: Runs the sync-diff-inspector using the provided configuration file to compare and synchronize data. Requires the configuration file to be properly set up and path accessible.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/sync-diff-inspector-overview.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n\"./sync_diff_inspector --config=./config.toml\"\n```\n\n----------------------------------------\n\nTITLE: Example: Setting 'test' Profile as Active in TiDB Cloud CLI (Shell)\nDESCRIPTION: This example demonstrates how to set the 'test' profile as the active user profile in the TiDB Cloud CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-use.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud config use test\n```\n\n----------------------------------------\n\nTITLE: Executing TiKV Control via TiUP\nDESCRIPTION: Commands to run tikv-ctl through the TiUP package manager with specific cluster version.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> tikv\n```\n\n----------------------------------------\n\nTITLE: Creating a User with No Password in TiDB\nDESCRIPTION: Create a user 'dummy' that can only connect from localhost with no password, typically used for local testing or development.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'dummy'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Fixing Audit Plugin Port Probing Panic in TiDB\nDESCRIPTION: Resolves a potential panic caused by port probing when the audit plugin is enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_19\n\nLANGUAGE: SQL\nCODE:\n```\n-- Enable audit plugin\nSET GLOBAL audit_plugin = 'audit'\n```\n\n----------------------------------------\n\nTITLE: Compressing Data in SQL\nDESCRIPTION: The `COMPRESS(expr)` function compresses the input data and returns it as a binary string. If the input is NULL or empty, it returns NULL or a zero-length value respectively.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT COMPRESS(0x414243);\n```\n\nLANGUAGE: sql\nCODE:\n```\nWITH x AS (SELECT REPEAT('a',100) 'a') SELECT LENGTH(a),LENGTH(COMPRESS(a)) FROM x;\n```\n\n----------------------------------------\n\nTITLE: Configuring HAProxy Global and Default Settings\nDESCRIPTION: Comprehensive HAProxy configuration defining global parameters, thread settings, logging, and default connection behaviors\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-performance-test.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nglobal:\n    log         127.0.0.1 local2\n    pidfile     /var/run/haproxy.pid\n    maxconn     4096\n    nbthread    4\n    user        haproxy\n    group       haproxy\n    daemon\n    stats socket /var/lib/haproxy/stats\n```\n\n----------------------------------------\n\nTITLE: Creating Replication Task in DM\nDESCRIPTION: This YAML snippet demonstrates how to create a replication task targeting incremental data replication. It sets the task name, operation mode, target database configurations, as well as table filtering rules to control the data migration process.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nname: task-test               # The name of the task. Should be globally unique.\ntask-mode: incremental        # The mode of the task. \"incremental\" means full data migration is skipped and only incremental replication is performed.\n# Required for incremental replication from sharded tables. By default, the \"pessimistic\" mode is used.\n# If you have a deep understanding of the principles and usage limitations of the optimistic mode, you can also use the \"optimistic\" mode.\n# For more information, see [Merge and Migrate Data from Sharded Tables](https://docs.pingcap.com/tidb/dev/feature-shard-merge/).\n\nshard-mode: \"pessimistic\"\n\n# Configure the access information of the target TiDB database instance:\ntarget-database:              # The target database instance\n  host: \"${host}\"             # For example: 127.0.0.1\n  port: 4000\n  user: \"root\"\n  password: \"${password}\"     # It is recommended to use a dmctl encrypted password.\n\n# Use block-allow-list to configure tables that require sync:\nblock-allow-list:             # The set of filter rules on matching tables in the data sources, to decide which tables need to migrate and which not. Use the black-white-list if the DM version is earlier than or equal to v2.0.0-beta.2.\n  bw-rule-1:                  # The ID of the block and allow list rule.\n    do-dbs: [\"my_db1\"]        # The databases to be migrated. Here, my_db1 of instance 1 and my_db2 of instance 2 are configured as two separate rules to demonstrate how to prevent my_db2 of instance 1 from being replicated.\n  bw-rule-2:\n    do-dbs: [\"my_db2\"]\nroutes:                               # Table renaming rules ('routes') from upstream to downstream tables, in order to support merging different sharded table into a single target table.\n  route-rule-1:                       # Rule name. Migrate and merge table1 and table2 from my_db1 to the downstream my_db.table5.\n    schema-pattern: \"my_db1\"          # Rule for matching upstream schema names. It supports the wildcards \"*\" and \"?\".\n    table-pattern: \"table[1-2]\"       # Rule for matching upstream table names. It supports the wildcards \"*\" and \"?\".\n    target-schema: \"my_db\"            # Name of the target schema.\n    target-table: \"table5\"            # Name of the target table.\n  route-rule-2:                       # Rule name. Migrate and merge table3 and table4 from my_db2 to the downstream my_db.table5.\n    schema-pattern: \"my_db2\"\n    table-pattern: \"table[3-4]\"\n    target-schema: \"my_db\"\n    target-table: \"table5\"\n\n# Configure data sources. The following uses two data sources as an example.\nmysql-instances:\n  - source-id: \"mysql-01\"             # Data source ID. It is the source-id in source1.yaml.\n    block-allow-list: \"bw-rule-1\"     # Use the block and allow list configuration above. Replicate `my_db1` in instance 1.\n    route-rules: [\"route-rule-1\"]     # Use the configured routing rule above to merge upstream tables.\n```\n\n----------------------------------------\n\nTITLE: Implementing TiDB Cloud Connection in Netlify Edge Function (TypeScript)\nDESCRIPTION: This TypeScript code creates a Netlify edge function that connects to a TiDB Cloud database using the serverless driver. It executes a simple 'show databases' query and returns the result as a JSON response. The function is configured to be accessible at the '/api/hello' path.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport { connect } from 'https://esm.sh/@tidbcloud/serverless'\n\nexport default async () => {\n  const conn = connect({url: Netlify.env.get('DATABASE_URL')})\n  const result = await conn.execute('show databases')\n  return new Response(JSON.stringify(result));\n}\n\nexport const config = { path: \"/api/hello\" };\n```\n\n----------------------------------------\n\nTITLE: Running TPC-C Stress Tests\nDESCRIPTION: This shell command initiates stress tests on the TiDB Cloud Dedicated cluster for 2 hours using the TPC-C benchmark. It captures performance metrics under various thread configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ngo-tpc tpcc --host ${HOST} -P 4000 --warehouses 1000 run -D tpcc -T ${THREAD} --time 2h0m0s -p ${PASSWORD} --ignore-error\n```\n\n----------------------------------------\n\nTITLE: Stopping TiDB Cluster for Offline Upgrade in Shell\nDESCRIPTION: This command stops the entire TiDB cluster before performing an offline upgrade. It is the first step in the offline upgrade process.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster stop <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Connecting to a TiDB Cloud Serverless branch with password\nDESCRIPTION: Example showing how to connect to a TiDB Cloud Serverless branch with cluster ID, branch ID, and password in non-interactive mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-shell.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch shell -c <cluster-id> -b <branch-id> --password <password>\n```\n\n----------------------------------------\n\nTITLE: Removing Checkpoints in TiDB Lightning with Shell\nDESCRIPTION: This command provides a method to remove all checkpoint records for one or multiple tables in TiDB Lightning, allowing users to manage import data states effectively.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-checkpoints.md#2025-04-18_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ntidb-lightning-ctl --checkpoint-remove='`schema`.`table`'\ntidb-lightning-ctl --checkpoint-remove=all\n```\n\n----------------------------------------\n\nTITLE: Enabling and Disabling TiDB General Log Collection\nDESCRIPTION: These commands show how to enable and disable general log collection in TiDB for troubleshooting duplicate entry errors in DM replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Enable general log collection\ncurl -X POST -d \"tidb_general_log=1\" http://{TiDBIP}:10080/settings\n# Disable general log collection\ncurl -X POST -d \"tidb_general_log=0\" http://{TiDBIP}:10080/settings\n```\n\n----------------------------------------\n\nTITLE: Saving Modified Placement Rules with pd-ctl\nDESCRIPTION: This shell command writes the modified Placement Rules configuration to PD. After this command, PD will begin scheduling data to read-only nodes as learners according to the rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/readonly-nodes.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules rule-bundle save --in=\"rules.json\"\n```\n\n----------------------------------------\n\nTITLE: Installing Required Python Packages for LangChain and TiDB Integration\nDESCRIPTION: Installs all necessary Python packages including LangChain, LangChain Community, OpenAI integration, PyMySQL for database connectivity, and TiDB Vector for vector operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n!pip install langchain langchain-community\n!pip install langchain-openai\n!pip install pymysql\n!pip install tidb-vector\n```\n\n----------------------------------------\n\nTITLE: Encrypting Data Source Password using dmctl\nDESCRIPTION: Command to encrypt a database password using the dmctl encryption tool. Returns an encrypted password string that can be used in configuration files.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-source.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup dmctl encrypt 'abc!@#123'\n```\n\n----------------------------------------\n\nTITLE: Setting gRPC Concurrency Limit for GetRegion API in PD\nDESCRIPTION: Sets the maximum concurrency for GetRegion gRPC API requests to 10.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nconfig set service-middleware grpc-rate-limit GetRegion concurrency 10\n```\n\n----------------------------------------\n\nTITLE: Setting Default Role for a User\nDESCRIPTION: SQL command showing how to set a default role for a user so they automatically have role privileges without needing to run SET ROLE.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-grant-role.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSET DEFAULT ROLE analyticsteam TO jennifer;\nQuery OK, 0 rows affected (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a List Partitioned Table Without Default Partition in SQL\nDESCRIPTION: Example showing how to create a simple list partitioned table without a default partition, and demonstrating the error that occurs when inserting a value that doesn't match any defined partition.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (\n  a INT,\n  b INT\n)\nPARTITION BY LIST (a) (\n  PARTITION p0 VALUES IN (1, 2, 3),\n  PARTITION p1 VALUES IN (4, 5, 6)\n);\nQuery OK, 0 rows affected (0.11 sec)\n\nINSERT INTO t VALUES (7, 7);\nERROR 1525 (HY000): Table has no partition for value 7\n```\n\n----------------------------------------\n\nTITLE: Correcting Fast Analyze on Indices in TiDB\nDESCRIPTION: Fixes a panic that occurred when fast analyze was performed on indices only.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_20\n\nLANGUAGE: SQL\nCODE:\n```\nANALYZE TABLE table_name INDEX index_name\n```\n\n----------------------------------------\n\nTITLE: Modifying User Attributes in TiDB\nDESCRIPTION: Example of modifying user attributes for 'newuser' and then querying the user_attributes table to verify the changes. This demonstrates how to add custom metadata to user accounts in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'newuser' ATTRIBUTE '{\"newAttr\": \"value\", \"deprecatedAttr\": null}';\nmysql> SELECT * FROM information_schema.user_attributes;\n+-----------+------+--------------------------+\n| USER      | HOST | ATTRIBUTE                |\n+-----------+------+--------------------------+\n| newuser   | %    | {\"newAttr\": \"value\"}     |\n+-----------+------+--------------------------+\n1 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying GROUP_CONCAT Without ORDER BY in SQL\nDESCRIPTION: This snippet demonstrates how GROUP_CONCAT() without ORDER BY can produce unstable results in TiDB due to parallel data reading from the storage layer.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-unstable-result-set.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nselect GROUP_CONCAT( customer_id SEPARATOR ',' ) FROM customer where customer_id like '200002%';\n```\n\n----------------------------------------\n\nTITLE: Identifying Unused Indexes with INFORMATION_SCHEMA.CLUSTER_TIDB_INDEX_USAGE\nDESCRIPTION: These SQL queries find unused indexes from the INFORMATION_SCHEMA.CLUSTER_TIDB_INDEX_USAGE table based on access time and usage percentage, helping to optimize database performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\n-- Find indexes that have not been accessed in the last 30 days.\nSELECT table_schema, table_name, index_name, last_access_time\nFROM information_schema.cluster_tidb_index_usage\nWHERE last_access_time IS NULL\n  OR last_access_time < NOW() - INTERVAL 30 DAY;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Find indexes that are consistently scanned with over 50% of total records.\nSELECT table_schema, table_name, index_name,\n       query_total, rows_access_total,\n       percentage_access_0 as full_table_scans\nFROM information_schema.cluster_tidb_index_usage\nWHERE last_access_time IS NOT NULL AND percentage_access_0 + percentage_access_0_1 + percentage_access_1_10 + percentage_access_10_20 + percentage_access_20_50 = 0;\n```\n\n----------------------------------------\n\nTITLE: Recovering a Table by DDL Job ID in TiDB SQL\nDESCRIPTION: This snippet outlines the SQL command needed to recover a deleted table using the DDL Job ID associated with its creation. This method is particularly useful when there are multiple tables with the same name and recovery of a specific instance is needed.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-recover-table.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nRECOVER TABLE BY JOB JOB_ID;\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Lightning via TiUP\nDESCRIPTION: Installs TiDB Lightning using the TiUP package manager. This is part of the online deployment process. Requires TiUP to be installed and set in the PATH. Outputs a ready-to-use TiDB Lightning binary.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/deploy-tidb-lightning.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup install tidb-lightning\n```\n\n----------------------------------------\n\nTITLE: REPLACE Statement Example in SQL\nDESCRIPTION: SQL example demonstrating the usage of the REPLACE statement in TiDB. It shows how to create a table, insert initial data, and then use REPLACE to update an existing row, effectively deleting and re-inserting the data.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-replace.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\n\nINSERT INTO t1 (c1) VALUES (1), (2), (3);\n\nSELECT * FROM t1;\n\nREPLACE INTO t1 (id, c1) VALUES(3, 99);\n\nSELECT * FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Configuring Password Expiration Policy\nDESCRIPTION: Sets global policy for automatic password expiration, allowing administrators to enforce periodic password changes\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\ndefault_password_lifetime = 90\n```\n\n----------------------------------------\n\nTITLE: Dropping Lightning Metadata Database in SQL\nDESCRIPTION: This SQL command removes the 'lightning_metadata' database, preventing any residual metadata from affecting future imports. Its use is crucial when checkpoint files are deleted manually or during versions of TiDB Lightning (v5.1.x and v5.2.x) where automatic cleanup is not performed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-faq.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nDROP DATABASE IF EXISTS `lightning_metadata`;\n```\n\n----------------------------------------\n\nTITLE: Querying Top 3 Regions by Write Volume in SQL\nDESCRIPTION: This SQL query selects all columns from the TIKV_REGION_STATUS table, ordering the results by the amount of data written (in descending order) and limiting the output to the top 3 regions.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tikv-region-status.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM tikv_region_status ORDER BY written_bytes DESC LIMIT 3;\n```\n\n----------------------------------------\n\nTITLE: Empty Table Creation Example in TiDB\nDESCRIPTION: Example of creating an empty table structure in the bookshop database without any columns defined.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `bookshop`.`users` (\n);\n```\n\n----------------------------------------\n\nTITLE: Querying with Enabled tidb_opt_prefix_index_single_scan in TiDB\nDESCRIPTION: This SQL query demonstrates the execution plan when tidb_opt_prefix_index_single_scan is enabled, showing that no table lookup is required.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_67\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN FORMAT='brief' SELECT COUNT(1) FROM t WHERE a = 1 AND b IS NOT NULL;\n```\n\n----------------------------------------\n\nTITLE: Starting TiDB Cluster Components\nDESCRIPTION: Commands to start a TiDB cluster or specific components using TiUP. Supports starting individual components or nodes using -R and -N parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/maintain-tidb-using-tiup.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster start ${cluster-name}\ntiup cluster start ${cluster-name} -R pd\ntiup cluster start ${cluster-name} -N 1.2.3.4:2379,1.2.3.5:2379\n```\n\n----------------------------------------\n\nTITLE: Creating Table and Inserting Initial Data in SQL\nDESCRIPTION: This SQL snippet creates a table 't' with an integer primary key and a value column, then inserts two rows of initial data.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-deadlocks.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (id int primary key, v int);\nINSERT INTO t VALUES (1, 10), (2, 20);\n```\n\n----------------------------------------\n\nTITLE: AWS IAM Policy for S3 Bucket Access (JSON)\nDESCRIPTION: This code snippet defines an AWS IAM policy in JSON format that grants TiDB Cloud access to an Amazon S3 bucket. It allows `GetObject` and `GetObjectVersion` actions on the specified directory within the bucket, and `ListBucket` and `GetBucketLocation` actions on the bucket itself. The policy should be customized with the correct bucket ARN and directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/config-s3-and-gcs-access.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n        {\n            \"Version\": \"2012-10-17\",\n            \"Statement\": [\n                {\n                    \"Sid\": \"VisualEditor0\",\n                    \"Effect\": \"Allow\",\n                    \"Action\": [\n                        \"s3:GetObject\",\n                        \"s3:GetObjectVersion\"\n                    ],\n                    \"Resource\": \"<Your S3 bucket ARN>/<Directory of your source data>/*\"\n                },\n                {\n                    \"Sid\": \"VisualEditor1\",\n                    \"Effect\": \"Allow\",\n                    \"Action\": [\n                        \"s3:ListBucket\",\n                        \"s3:GetBucketLocation\"\n                    ],\n                    \"Resource\": \"<Your S3 bucket ARN>\"\n                }\n            ]\n        }\n```\n\n----------------------------------------\n\nTITLE: Chat2Data Response Format in JavaScript\nDESCRIPTION: Example response from the /v3/chat2data endpoint. It includes a job ID and session ID that can be used to check the status of the SQL generation and execution job.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"code\": 200,\n  \"msg\": \"\",\n  \"result\": {\n    \"cluster_id\": \"10140100115280519574\",\n    \"database\": \"sp500insight\",\n    \"job_id\": \"20f7577088154d7889964f1a5b12cb26\",\n    \"session_id\": 304832\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring TiProxy Servers in YAML\nDESCRIPTION: Example YAML configuration for tiproxy_servers specifying two TiProxy instances with different zone labels. This configuration defines hosts, ports, and labels for TiProxy services in a TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\ntiproxy_servers:\n  - host: 10.0.1.21\n    port: 6000\n    status_port: 3080\n    config:\n      labels: { zone: \"zone1\" }\n  - host: 10.0.1.22\n    port: 6000\n    status_port: 3080\n    config:\n      labels: { zone: \"zone2\" }\n```\n\n----------------------------------------\n\nTITLE: Resetting HTTP Rate and Concurrency Limits in PD\nDESCRIPTION: Resets the rate (QPS) and concurrency limits for GetRegion HTTP API requests to 0, effectively removing the limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nconfig set service-middleware rate-limit GetRegion qps 0\nconfig set service-middleware rate-limit GetRegion concurrency 0\n```\n\n----------------------------------------\n\nTITLE: Setting min-hot-key-rate for balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command sets the minimum number of keys to be counted as a hot region. The default value is usually 10.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_34\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-hot-region-scheduler set min-hot-key-rate 10\n```\n\n----------------------------------------\n\nTITLE: Displaying User Attributes in TiDB\nDESCRIPTION: This SQL snippet shows how to query user attributes stored in the INFORMATION_SCHEMA.USER_ATTRIBUTES table in TiDB v6.4.0. It reveals the comments and structured attributes of users, facilitating easier management and documentation.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.4.0.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n+-----------+------+---------------------------------------------------+\n| USER      | HOST | ATTRIBUTE                                         |\n+-----------+------+---------------------------------------------------+\n| newuser1  | %    | {\"comment\": \"This user is created only for test\"} |\n| newuser1  | %    | {\"email\": \"user@pingcap.com\"}                     |\n+-----------+------+---------------------------------------------------+\n2 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting Memory Quota for SQL Queries in TiDB\nDESCRIPTION: Examples of setting different memory quota thresholds for individual SQL queries using the tidb_mem_quota_query system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-memory-usage.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n-- Set the threshold value of memory quota for a single SQL query to 8GB:\nSET tidb_mem_quota_query = 8 << 30;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Set the threshold value of memory quota for a single SQL query to 8MB:\nSET tidb_mem_quota_query = 8 << 20;\n```\n\nLANGUAGE: sql\nCODE:\n```\n-- Set the threshold value of memory quota for a single SQL query to 8KB:\nSET tidb_mem_quota_query = 8 << 10;\n```\n\n----------------------------------------\n\nTITLE: Exporting Data to CSV Files with Dumpling\nDESCRIPTION: Command to export filtered data to CSV files using SQL query with custom filename template and file size limit.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup dumpling -u root -P 4000 -h 127.0.0.1 -o /tmp/test --filetype csv --sql 'select * from `test`.`sbtest1` where id < 100' -F 100MiB --output-filename-template 'test.sbtest1.{{.Index}}'\n```\n\n----------------------------------------\n\nTITLE: Dropping Covering Index in SQL\nDESCRIPTION: This SQL statement drops the 'title_price_idx' index to revert the table schema for subsequent examples.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE books DROP INDEX title_price_idx;\n```\n\n----------------------------------------\n\nTITLE: Querying DM Migration Task Status with TiUP dmctl\nDESCRIPTION: Command to check the status of an ongoing migration task in a DM cluster. Uses tiup dmctl with master address and task name parameters to query the current status.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-to-tidb.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} query-status ${task-name}\n```\n\n----------------------------------------\n\nTITLE: Custom Path Prefix Configuration\nDESCRIPTION: YAML configuration for customizing TiDB Dashboard path prefix in PD configuration\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  pd:\n    dashboard.public-path-prefix: /foo\n```\n\n----------------------------------------\n\nTITLE: Create User with JWT Authentication in SQL\nDESCRIPTION: Creates a TiDB user with JWT authentication, specifying token issuer and email attributes\nSOURCE: https://github.com/pingcap/docs/blob/master/security-compatibility-with-mysql.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'user@pingcap.com' IDENTIFIED WITH 'tidb_auth_token' REQUIRE TOKEN_ISSUER 'issuer-abc' ATTRIBUTE '{\"email\": \"user@pingcap.com\"}'\n```\n\n----------------------------------------\n\nTITLE: Enabling In-Place Constraint Checking for Optimistic Transactions\nDESCRIPTION: This snippet demonstrates enabling immediate constraint checking for optimistic transactions by setting the tidb_constraint_check_in_place system variable to ON.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_constraint_check_in_place = ON;\n```\n\n----------------------------------------\n\nTITLE: Configuring Table Filters in TiCDC (TOML)\nDESCRIPTION: Demonstrates how to configure table filters in TiCDC using TOML syntax. Table filters allow specifying which databases and tables to replicate or exclude from replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-filter.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[filter]\n# Filter rules\nrules = ['*.*', '!test.*']\n```\n\n----------------------------------------\n\nTITLE: Get Substring in TiDB\nDESCRIPTION: Compares extracting a substring using SUBSTR in Oracle and SUBSTRING in TiDB, highlighting starting position differences.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSUBSTR('abcdefg',0,2) = 'ab'\nSUBSTR('abcdefg',1,2) = 'ab'\n```\n\nLANGUAGE: sql\nCODE:\n```\nSUBSTRING('abcdefg',0,2) = ''\nSUBSTRING('abcdefg',1,2) = 'ab'\n```\n\n----------------------------------------\n\nTITLE: Reading Execution Plan: Time-Based Query\nDESCRIPTION: SQL query demonstrating execution plan for filtering trips by date range and performing count aggregation across multiple operators in TiKV\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT COUNT(*) FROM trips WHERE start_date BETWEEN '2017-07-01 00:00:00' AND '2017-07-01 23:59:59';\n```\n\n----------------------------------------\n\nTITLE: Backing up TiDB data with encryption key as environment variable\nDESCRIPTION: These commands demonstrate setting the AZURE_ENCRYPTION_KEY environment variable before running the backup command. This method allows specifying the encryption key without including it in the command line.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\nexport AZURE_ENCRYPTION_KEY=<aes256-key>\ntiup br backup full --pd <pd-address> --storage \"azure://<bucket>/<prefix>\"\n```\n\n----------------------------------------\n\nTITLE: Encoding UPDATE Event in TiCDC - JSON\nDESCRIPTION: This snippet shows the JSON structure for an UPDATE event in TiCDC, which captures the new and old data of a database record. The required fields include version, database name, table name, and the data before and after the update. It serves to track changes made to records in a table efficiently.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-simple-protocol.md#2025-04-18_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"version\":1,\n   \"database\":\"simple\",\n   \"table\":\"user\",\n   \"tableID\":148,\n   \"type\":\"UPDATE\",\n   \"commitTs\":447984099186180098,\n   \"buildTs\":1708923719184,\n   \"schemaVersion\":447984074911121426,\n   \"data\":{\n      \"age\":\"25\",\n      \"id\":\"1\",\n      \"name\":\"John Doe\",\n      \"score\":\"95\"\n   },\n   \"old\":{\n      \"age\":\"25\",\n      \"id\":\"1\",\n      \"name\":\"John Doe\",\n      \"score\":\"90.5\"\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating UUIDs with UUID() in SQL\nDESCRIPTION: This function returns a universally unique identifier (UUID) version 1 as defined in RFC 4122. Each call generates a new unique UUID.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT UUID();\n```\n\n----------------------------------------\n\nTITLE: PREPARE Statement Syntax\nDESCRIPTION: Defines the syntax of the PREPARE statement using EBNF notation. It shows how to prepare a statement using an identifier and SQL from either a string literal or a user variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-prepare.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\n\"PreparedStmt ::= \\\n    'PREPARE' Identifier 'FROM' PrepareSQL\\\n\\\nPrepareSQL ::= \\\n    stringLit\\\n|   UserVariable\"\n```\n\n----------------------------------------\n\nTITLE: Configuring MyBatis Mapper for Data Insertion\nDESCRIPTION: XML configuration for MyBatis mapper to define an insert operation for the 'player' table in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-mybatis.md#2025-04-18_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.pingcap.model.PlayerMapper\">\n    <insert id=\"insert\" parameterType=\"com.pingcap.model.Player\">\n    insert into player (id, coins, goods)\n    values (#{id,jdbcType=VARCHAR}, #{coins,jdbcType=INTEGER}, #{goods,jdbcType=INTEGER})\n    </insert>\n</mapper>\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB DM Task for Incremental Replication\nDESCRIPTION: Complete YAML configuration for a TiDB DM replication task. This configuration specifies incremental mode, source databases with their binlog positions, target database connection, routing rules, filtering rules, and block-allow lists.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\n## ********* Task Configuration *********\nname: test-task1\nshard-mode: \"pessimistic\"\n# Task mode. The \"incremental\" mode only performs incremental data migration.\ntask-mode: incremental\n# timezone: \"UTC\"\n\n## ******** Data Source Configuration **********\n## (Optional) If you need to incrementally replicate data that has already been migrated in the full data migration, you need to enable the safe mode to avoid the incremental data migration error.\n##  This scenario is common in the following case: the full migration data does not belong to the data source's consistency snapshot, and after that, DM starts to replicate incremental data from a position earlier than the full migration.\nsyncers:           # The running configurations of the sync processing unit.\n global:           # Configuration name.\n   safe-mode: false # # If this field is set to true, DM changes INSERT of the data source to REPLACE for the target database,\n                    # # and changes UPDATE of the data source to DELETE and REPLACE for the target database.\n                    # # This is to ensure that when the table schema contains a primary key or unique index, DML statements can be imported repeatedly.\n                    # # In the first minute of starting or resuming an incremental migration task, DM automatically enables the safe mode.\nmysql-instances:\n- source-id: \"mysql-replica-01\"\n   block-allow-list:  \"bw-rule-1\"\n   route-rules: [\"store-route-rule\", \"sale-route-rule\"]\n   filter-rules: [\"store-filter-rule\", \"sale-filter-rule\"]\n   syncer-config-name: \"global\"\n   meta:\n     binlog-name: \"mysql-bin.000002\"\n     binlog-pos: 246546174\n     binlog-gtid: \"b631bcad-bb10-11ec-9eee-fec83cf2b903:1-194801\"\n- source-id: \"mysql-replica-02\"\n   block-allow-list:  \"bw-rule-1\"\n   route-rules: [\"store-route-rule\", \"sale-route-rule\"]\n   filter-rules: [\"store-filter-rule\", \"sale-filter-rule\"]\n   syncer-config-name: \"global\"\n   meta:\n     binlog-name: \"mysql-bin.000001\"\n     binlog-pos: 1312659\n     binlog-gtid: \"cd21245e-bb10-11ec-ae16-fec83cf2b903:1-4036\"\n\n## ******** Configuration of the target TiDB cluster on TiDB Cloud **********\ntarget-database:       # The target TiDB cluster on TiDB Cloud\n host: \"tidb.xxxxxxx.xxxxxxxxx.ap-northeast-1.prod.aws.tidbcloud.com\"\n port: 4000\n user: \"root\"\n password: \"${password}\"  # If the password is not empty, it is recommended to use a dmctl-encrypted cipher.\n\n## ******** Function Configuration **********\nroutes:\n store-route-rule:\n   schema-pattern: \"store_*\"\n   target-schema: \"store\"\n sale-route-rule:\n   schema-pattern: \"store_*\"\n   table-pattern: \"sale_*\"\n   target-schema: \"store\"\n   target-table:  \"sales\"\nfilters:\n sale-filter-rule:\n   schema-pattern: \"store_*\"\n   table-pattern: \"sale_*\"\n   events: [\"truncate table\", \"drop table\", \"delete\"]\n   action: Ignore\n store-filter-rule:\n   schema-pattern: \"store_*\"\n   events: [\"drop database\"]\n   action: Ignore\nblock-allow-list:\n bw-rule-1:\n   do-dbs: [\"store_*\"]\n\n## ******** Ignore check items **********\nignore-checking-items: [\"table_schema\",\"auto_increment_ID\"]\n```\n\n----------------------------------------\n\nTITLE: Defining VARBINARY Column in TiDB\nDESCRIPTION: Syntax for creating a VARBINARY column for variable-length binary strings.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nVARBINARY(M)\n```\n\n----------------------------------------\n\nTITLE: String Concatenation Examples\nDESCRIPTION: Shows how quoted strings placed next to each other are concatenated into a single string.\nSOURCE: https://github.com/pingcap/docs/blob/master/literal-values.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n'a string'\n'a' ' ' 'string'\n\"a\" ' ' \"string\"\n```\n\n----------------------------------------\n\nTITLE: Explaining Shuffle Hash Join with MPP in SQL\nDESCRIPTION: This snippet showcases the EXPLAIN command to illustrate a Shuffle Hash Join execution plan in SQL. It details the multi-stage distribution and joining of data between nodes in an MPP environment, with specific focus on hash partitioning to achieve parallelism in join operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-mpp.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_broadcast_join_threshold_count=0;\nSET tidb_broadcast_join_threshold_size=0;\nEXPLAIN SELECT COUNT(*) FROM t1 a JOIN t1 b ON a.id = b.id;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------------------+---------+--------------+---------------+----------------------------------------------------+\n| id                                     | estRows | task         | access object | operator info                                      |\n+----------------------------------------+---------+--------------+---------------+----------------------------------------------------+\n| StreamAgg_14                           | 1.00    | root         |               | funcs:count(1)->Column#7                           |\n| └─TableReader_48                       | 9.00    | root         |               | data:ExchangeSender_47                             |\n|   └─ExchangeSender_47                  | 9.00    | cop[tiflash] |               | ExchangeType: PassThrough                          |\n|     └─HashJoin_44                      | 9.00    | cop[tiflash] |               | inner join, equal:[eq(test.t1.id, test.t1.id)]     |\n|       ├─ExchangeReceiver_19(Build)     | 6.00    | cop[tiflash] |               |                                                    |\n|       │ └─ExchangeSender_18            | 6.00    | cop[tiflash] |               | ExchangeType: HashPartition, Hash Cols: test.t1.id |\n|       │   └─Selection_17               | 6.00    | cop[tiflash] |               | not(isnull(test.t1.id))                            |\n|       │     └─TableFullScan_16         | 6.00    | cop[tiflash] | table:a       | keep order:false                                   |\n|       └─ExchangeReceiver_23(Probe)     | 6.00    | cop[tiflash] |               |                                                    |\n|         └─ExchangeSender_22            | 6.00    | cop[tiflash] |               | ExchangeType: HashPartition, Hash Cols: test.t1.id |\n|           └─Selection_21               | 6.00    | cop[tiflash] |               | not(isnull(test.t1.id))                            |\n|             └─TableFullScan_20         | 6.00    | cop[tiflash] | table:b       | keep order:false                                   |\n+----------------------------------------+---------+--------------+---------------+----------------------------------------------------+\n12 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Generating Server Key and Certificate Request for TiDB\nDESCRIPTION: Command to create a new 2048-bit RSA key and certificate signing request (CSR) for the TiDB server. This step creates both a private key and a certificate request file.\nSOURCE: https://github.com/pingcap/docs/blob/master/certificate-authentication.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo openssl req -newkey rsa:2048 -days 365000 -nodes -keyout server-key.pem -out server-req.pem\n```\n\n----------------------------------------\n\nTITLE: Setting Certificate Paths in TiFlash Configuration\nDESCRIPTION: Defines the paths for the X509 certificate and key files in PEM format for secure communication.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_2\n\nLANGUAGE: TOML\nCODE:\n```\n\"cert_path = \\\"/path/to/tiflash-server.pem\\\"\"\n```\n\nLANGUAGE: TOML\nCODE:\n```\n\"key_path = \\\"/path/to/tiflash-server-key.pem\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Cloud Serverless Connection in .env File\nDESCRIPTION: Example of a .env file configuration for connecting to a TiDB Cloud Serverless cluster with SSL verification.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_4\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_DATABASE_URL=\"mysql+pymysql://<prefix>.root:<password>@gateway01.<region>.prod.aws.tidbcloud.com:4000/test?ssl_ca=/etc/ssl/cert.pem&ssl_verify_cert=true&ssl_verify_identity=true\"\n```\n\n----------------------------------------\n\nTITLE: Running Sysbench Short Connection Test (Bash)\nDESCRIPTION: This snippet performs a Sysbench test aimed at evaluating the effect of frequently created and disconnected short connections on query performance. Various rates of new connections are assessed against average latency and CPU usage metrics. Requires Sysbench and MySQL database access.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-performance-test.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nsysbench oltp_point_select \\\n    --threads=50 \\\n    --time=1200 \\\n    --report-interval=10 \\\n    --rand-type=uniform \\\n    --db-driver=mysql \\\n    --mysql-db=sbtest \\\n    --mysql-host=$host \\\n    --mysql-port=$port \\\n    run --tables=32 --table-size=1000000\n```\n\n----------------------------------------\n\nTITLE: TiDB SELECT Statement EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the SELECT statement in TiDB, including basic select, dual table select, and table select with various clauses like WHERE, GROUP BY, HAVING, and window functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-select.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nSelectStmt ::=\n    ( SelectStmtBasic | SelectStmtFromDualTable | SelectStmtFromTable )\n    OrderBy? SelectStmtLimit? SelectLockOpt? SelectStmtIntoOption\n\nSelectStmtBasic ::=\n    \"SELECT\" SelectStmtOpts Field (\",\" Field)* ( \"HAVING\" Expression)?\n\nSelectStmtFromDualTable ::=\n    \"SELECT\" SelectStmtOpts Field (\",\" Field)* \"FROM\" \"DUAL\" WhereClause?\n\nSelectStmtFromTable ::=\n    \"SELECT\" SelectStmtOpts Field (\",\" Field)* \"FROM\" TableRefsClause\n    WhereClause? GroupByClause? ( \"HAVING\" Expression)? WindowClause?\n```\n\n----------------------------------------\n\nTITLE: Creating Partitioned Table Example\nDESCRIPTION: Creates a partitioned table and demonstrates execution plan differences between static and dynamic modes using a simple query.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_75\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t1(id int, age int, key(id)) partition by range(id) (\n        partition p0 values less than (100),\n        partition p1 values less than (200),\n        partition p2 values less than (300),\n        partition p3 values less than (400));\nexplain select * from t1 where id < 150;\n```\n\n----------------------------------------\n\nTITLE: Executing EXPLAIN ANALYZE with HASH_JOIN hint and memory quota\nDESCRIPTION: This code snippet demonstrates how to use the `EXPLAIN ANALYZE` command in TiDB to analyze the execution plan and runtime statistics of a query with a hash join hint. It first executes the query with the default memory quota, then sets a lower memory quota using `SET tidb_mem_quota_query` and reruns the query to observe the effect on disk usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT /*+ HASH_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\nSET tidb_mem_quota_query=500 * 1024 * 1024;\nEXPLAIN ANALYZE SELECT /*+ HASH_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Forbid Raft Leader Scheduling to a Specific AZ\nDESCRIPTION: This code snippet configures the scheduler to prevent the Raft leader from being scheduled to a specific availability zone (AZ3). This avoids unnecessary network overhead and latency associated with cross-region communication.\nSOURCE: https://github.com/pingcap/docs/blob/master/three-data-centers-in-two-cities-deployment.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n\"config set label-property reject-leader dc 3\"\n```\n\n----------------------------------------\n\nTITLE: Revoking Analytics Role\nDESCRIPTION: SQL command to revoke the analytics team role from user jennifer.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-revoke-role.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE analyticsteam FROM jennifer;\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Inserting and Updating Tables with SQL in TiDB\nDESCRIPTION: Demonstrates SQL statements executed in an upstream TiDB instance to create a table and perform insertions and updates. The example highlights how data changes are translated into effective SQL operations for downstream systems by TiCDC. Dependencies include the presence of a TiDB-compatible SQL environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCreate Table t1 (A int Primary Key, B int);\\n\\nBEGIN;\\nInsert Into t1 values(1,2);\\nInsert Into t1 values(2,2);\\nInsert Into t1 values(3,3);\\nCommit;\\n\\nUpdate t1 set b = 4 where b = 2;\n```\n\n----------------------------------------\n\nTITLE: Unbinding User from Resource Group in TiDB\nDESCRIPTION: Example of unbinding 'newuser' from a specific resource group, effectively setting it back to the 'default' group. This demonstrates how to reset resource allocation for users in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_11\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'newuser' RESOURCE GROUP `default`;\nmysql> SELECT USER, JSON_EXTRACT(User_attributes, \"$.resource_group\") FROM mysql.user WHERE user = \"newuser\";\n+---------+---------------------------------------------------+\n| USER    | JSON_EXTRACT(User_attributes, \"$.resource_group\") |\n+---------+---------------------------------------------------+\n| newuser | \"default\"                                         |\n+---------+---------------------------------------------------+\n1 row in set (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring cluster-verify-cn for TiDB\nDESCRIPTION: This code snippet shows how to configure `cluster-verify-cn` in the TiDB configuration file to verify the caller's identity. It specifies a list of allowed Common Names (CNs) for secure communication.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\n    ```toml\n    [security]\n    cluster-verify-cn = [\"tidb\", \"tiproxy\", \"test-client\", \"prometheus\"]\n    ```\n```\n\n----------------------------------------\n\nTITLE: Table Renaming in pt-osc to Complete Schema Change\nDESCRIPTION: SQL statement used by pt-osc to swap the original table with the '_new' table, completing the online DDL operation. DM splits this into two operations and only processes the second one.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nRENAME TABLE `test`.`test4` TO `test`.`_test4_old`, `test`.`_test4_new` TO `test`.`test4`\n```\n\n----------------------------------------\n\nTITLE: Expression Pushdown References\nDESCRIPTION: Provides information about expressions that can be pushed down to TiKV and TiFlash for optimized processing. Includes links to detailed documentation on supported pushdown expressions.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/functions-and-operators-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- For expressions pushed down to TiKV: [List of expressions for pushdown](/functions-and-operators/expressions-pushed-down.md)\n- For expressions pushed down to TiFlash: [Push-down expressions](/tiflash/tiflash-supported-pushdown-calculations.md#push-down-expressions)\n```\n\n----------------------------------------\n\nTITLE: Disabling Transparent Huge Pages in Linux\nDESCRIPTION: Shell commands to disable Transparent Huge Pages (THP) which can cause performance issues for database applications due to memory fragmentation and CPU spikes during direct compaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\necho never > /sys/kernel/mm/transparent_hugepage/enabled\necho never > /sys/kernel/mm/transparent_hugepage/defrag\ngrubby --update-kernel=\"$KERNEL\" --args='transparent_hugepage=never'\n```\n\n----------------------------------------\n\nTITLE: Querying P99 Time for tidb_query_duration\nDESCRIPTION: This SQL snippet queries execution times for `tidb_query_duration`, filtering records where the `value` is not null and within a specified time range. It helps in analyzing query performance at the 99th percentile for specific timestamps.\nSOURCE: https://github.com/pingcap/docs/blob/master/metrics-schema.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM metrics_schema.tidb_query_duration WHERE value is not null AND time>='2020-03-25 23:40:00' AND time <= '2020-03-25 23:42:00' AND quantile=0.99;\n```\n\n----------------------------------------\n\nTITLE: SHOW STATS_META Grammar Definition\nDESCRIPTION: EBNF syntax definition for the SHOW STATS_META statement, showing the optional LIKE or WHERE clauses for filtering results\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-meta.md#2025-04-18_snippet_2\n\nLANGUAGE: ebnf\nCODE:\n```\nShowStatsMetaStmt ::=\n    \"SHOW\" \"STATS_META\" ShowLikeOrWhere?\n\nShowLikeOrWhere ::=\n    \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Checking a User's Privileges using Multiple Roles in TiDB\nDESCRIPTION: This snippet demonstrates how to check the privileges a user has through multiple roles using the `SHOW GRANTS ... USING` statement in TiDB. This statement displays the combined privileges associated with the specified roles for the given user. To check privilege-related information of another user, you need the `SELECT` privilege on the `mysql` database.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS FOR 'rw_user1'@'localhost' USING 'app_read', 'app_write';\n```\n\n----------------------------------------\n\nTITLE: Transaction Size and Entry Limits\nDESCRIPTION: Configures maximum transaction size, entry size, and statement count limitations to control transaction behaviors and prevent oversized transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-configuration-file.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ntxn-entry-size-limit: 6291456\ntxn-total-size-limit: 104857600\nstmt-count-limit: 5000\n```\n\n----------------------------------------\n\nTITLE: Correcting IndexLookupJoin Inner Table Range in TiDB\nDESCRIPTION: Fixes incorrect range of the inner table built by IndexLookupJoin plans.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_30\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM outer_table JOIN inner_table ON outer_table.key = inner_table.key\n```\n\n----------------------------------------\n\nTITLE: Using TiDB Cloud Serverless Driver with Bun\nDESCRIPTION: Code snippet showing how to use the TiDB Cloud Serverless Driver in a Bun JavaScript runtime.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_7\n\nLANGUAGE: ts\nCODE:\n```\nimport { connect } from \"@tidbcloud/serverless-js\"\n\nconst conn = connect({url: Bun.env.DATABASE_URL})\nconst result = await conn.execute('show tables')\n```\n\n----------------------------------------\n\nTITLE: Configuring HAProxy for TiDB Load Balancing in YAML\nDESCRIPTION: A complete HAProxy configuration template with detailed comments explaining each parameter. This configuration sets up global settings, default parameters, an admin statistics page, and TiDB cluster load balancing.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/haproxy-best-practices.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nglobal                                     # Global configuration.\n   log         127.0.0.1 local2            # Global syslog servers (up to two).\n   chroot      /var/lib/haproxy            # Changes the current directory and sets superuser privileges for the startup process to improve security.\n   pidfile     /var/run/haproxy.pid        # Writes the PIDs of HAProxy processes into this file.\n   maxconn     4096                        # The maximum number of concurrent connections for a single HAProxy process. It is equivalent to the command-line argument \"-n\".\n   nbthread    48                          # The maximum number of threads. (The upper limit is equal to the number of CPUs)\n   user        haproxy                     # Same with the UID parameter.\n   group       haproxy                     # Same with the GID parameter. A dedicated user group is recommended.\n   daemon                                  # Makes the process fork into background. It is equivalent to the command line \"-D\" argument. It can be disabled by the command line \"-db\" argument.\n   stats socket /var/lib/haproxy/stats     # The directory where statistics output is saved.\n\ndefaults                                   # Default configuration.\n   log global                              # Inherits the settings of the global configuration.\n   retries 2                               # The maximum number of retries to connect to an upstream server. If the number of connection attempts exceeds the value, the backend server is considered unavailable.\n   timeout connect  2s                     # The maximum time to wait for a connection attempt to a backend server to succeed. It should be set to a shorter time if the server is located on the same LAN as HAProxy.\n   timeout client 30000s                   # The maximum inactivity time on the client side.\n   timeout server 30000s                   # The maximum inactivity time on the server side.\n\nlisten admin_stats                         # The name of the Stats page reporting information from frontend and backend. You can customize the name according to your needs.\n   bind 0.0.0.0:8080                       # The listening port.\n   mode http                               # The monitoring mode.\n   option httplog                          # Enables HTTP logging.\n   maxconn 10                              # The maximum number of concurrent connections.\n   stats refresh 30s                       # Automatically refreshes the Stats page every 30 seconds.\n   stats uri /haproxy                      # The URL of the Stats page.\n   stats realm HAProxy                     # The authentication realm of the Stats page.\n   stats auth admin:pingcap123             # User name and password in the Stats page. You can have multiple user names.\n   stats hide-version                      # Hides the version information of HAProxy on the Stats page.\n   stats admin if TRUE                     # Manually enables or disables the backend server (supported in HAProxy 1.4.9 or later versions).\n\nlisten tidb-cluster                        # Database load balancing.\n   bind 0.0.0.0:3390                       # The Floating IP address and listening port.\n   mode tcp                                # HAProxy uses layer 4, the transport layer.\n   balance leastconn                       # The server with the smallest number of connections receives the connection. \"leastconn\" is recommended where long sessions are expected, such as LDAP, SQL and TSE, rather than protocols using short sessions, such as HTTP. The algorithm is dynamic, which means that server weights might be adjusted on the fly for slow starts for instance.\n   server tidb-1 10.9.18.229:4000 check inter 2000 rise 2 fall 3       # Detects port 4000 at a frequency of once every 2000 milliseconds. If it is detected as successful twice, the server is considered available; if it is detected as failed three times, the server is considered unavailable.\n   server tidb-2 10.9.39.208:4000 check inter 2000 rise 2 fall 3\n   server tidb-3 10.9.64.166:4000 check inter 2000 rise 2 fall 3\n```\n\n----------------------------------------\n\nTITLE: Sharding DML Migration Configuration\nDESCRIPTION: Configuration example for exclusively migrating DML statements and necessary CREATE operations in sharded environments.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-binlog-event-filter.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nfilters:\n  do-table-rule:\n    schema-pattern: \"test_*\"\n    table-pattern: \"t_*\"\n    events: [\"create table\", \"all dml\"]\n    action: Do\n  do-schema-rule:\n    schema-pattern: \"test_*\"\n    events: [\"create database\"]\n    action: Do\n```\n\n----------------------------------------\n\nTITLE: Querying DDL Statement Execution Process\nDESCRIPTION: Example query showing how to track a specific DDL job execution across cluster nodes using the CLUSTER_LOG table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-log.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT time,instance,left(message,150) FROM cluster_log WHERE message LIKE '%ddl%job%ID.80%' AND type='tidb' AND time > '2020-05-18 20:40:00' AND time < '2020-05-18 21:40:00'\n```\n\n----------------------------------------\n\nTITLE: Configuring Prometheus\nDESCRIPTION: Prometheus configuration file setup including scrape configs for TiDB cluster components and global settings\nSOURCE: https://github.com/pingcap/docs/blob/master/deploy-monitoring-services.md#2025-04-18_snippet_2\n\nLANGUAGE: ini\nCODE:\n```\nglobal:\n  scrape_interval:     15s  # By default, scrape targets every 15 seconds.\n  evaluation_interval: 15s  # By default, scrape targets every 15 seconds.\n  # scrape_timeout is set to the global default value (10s).\n  external_labels:\n    cluster: 'test-cluster'\n    monitor: \"prometheus\"\n\nscrape_configs:\n  - job_name: 'overwritten-nodes'\n    honor_labels: true  # Do not overwrite job & instance labels.\n    static_configs:\n    - targets:\n      - '192.168.199.113:9100'\n      - '192.168.199.114:9100'\n      - '192.168.199.115:9100'\n      - '192.168.199.116:9100'\n      - '192.168.199.117:9100'\n      - '192.168.199.118:9100'\n\n  - job_name: 'tidb'\n    honor_labels: true  # Do not overwrite job & instance labels.\n    static_configs:\n    - targets:\n      - '192.168.199.113:10080'\n\n  - job_name: 'pd'\n    honor_labels: true  # Do not overwrite job & instance labels.\n    static_configs:\n    - targets:\n      - '192.168.199.113:2379'\n      - '192.168.199.114:2379'\n      - '192.168.199.115:2379'\n\n  - job_name: 'tikv'\n    honor_labels: true  # Do not overwrite job & instance labels.\n    static_configs:\n    - targets:\n      - '192.168.199.116:20180'\n      - '192.168.199.117:20180'\n      - '192.168.199.118:20180'\n```\n\n----------------------------------------\n\nTITLE: TiDB Lightning Configuration for Schema Import\nDESCRIPTION: This TOML configuration file is used by TiDB Lightning to import the schema file exported from Aurora into TiDB. It specifies connection details and import settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[tidb]\nhost = ${host}\nport = ${port}\nuser = \"${user_name}\"\npassword = \"${password}\"\nstatus-port = ${status-port}\npd-addr = \"${ip}:${port}\"\n\n[tikv-importer]\nbackend = \"local\"\nsorted-kv-dir = \"${path}\"\n\n[mydumper]\ndata-source-dir = \"s3://my-bucket/schema-backup\"\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP Cluster List Command\nDESCRIPTION: This command is used to display a list of all TiDB clusters currently managed by TiUP. It helps users identify the target cluster for scaling operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster list\"\n```\n\n----------------------------------------\n\nTITLE: Defining DROP ROLE Syntax in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the DROP ROLE statement in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-role.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDropRoleStmt ::=\n    'DROP' 'ROLE' ( 'IF' 'EXISTS' )? RolenameList\n\nRolenameList ::=\n    Rolename ( ',' Rolename )*\n```\n\n----------------------------------------\n\nTITLE: Configuring Token Authentication Parameter for Pulsar in TiCDC\nDESCRIPTION: This TOML snippet demonstrates configuring the authentication token directly in the TiCDC configuration file. It is important to handle token storage securely.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\n[sink.pulsar-config]\nauthentication-token = \"xxxxxxxxxxxxx\"\n```\n\n----------------------------------------\n\nTITLE: Checking TLS Connection Encryption Status in TiDB\nDESCRIPTION: SQL command to check whether the current connection uses encryption by showing SSL-related status variables. This displays encryption protocol, TLS version, and certificate details.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-clients-and-servers.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW STATUS LIKE \"Ssl%\";\n```\n\n----------------------------------------\n\nTITLE: Get String Length in TiDB\nDESCRIPTION: This snippet compares how to get the length of a string using LENGTH function in Oracle and CHAR_LENGTH in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nLENGTH(str)\n```\n\nLANGUAGE: sql\nCODE:\n```\nCHAR_LENGTH(str)\n```\n\n----------------------------------------\n\nTITLE: Querying REFERENTIAL_CONSTRAINTS Table in SQL\nDESCRIPTION: This SQL query selects all columns from the REFERENTIAL_CONSTRAINTS table, displaying information about foreign key relationships between tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-referential-constraints.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM REFERENTIAL_CONSTRAINTS\\G\n```\n\n----------------------------------------\n\nTITLE: Checking Table Consistency in TiDB SQL\nDESCRIPTION: TiDB does not support the CHECK TABLE statement. Instead, use the ADMIN CHECK [TABLE|INDEX] statement to check the consistency of data and corresponding indexes in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-third-party-tools-compatibility.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN CHECK [TABLE|INDEX]\n```\n\n----------------------------------------\n\nTITLE: Running DM Task Precheck Manually with TiUP\nDESCRIPTION: This command demonstrates how to manually trigger a precheck for a DM migration task using the TiUP dmctl tool. It specifies the path to the task configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-precheck.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup dmctl check-task ./task.yaml\n```\n\n----------------------------------------\n\nTITLE: Dropping an Index in TiDB\nDESCRIPTION: This SQL command removes an existing index from a table. This is done after creating a new index to replace a potentially corrupted or inconsistent one.\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name DROP INDEX index_name_lame_duck;\n```\n\n----------------------------------------\n\nTITLE: Querying TIDB_TRX Table in SQL\nDESCRIPTION: This system table displays executing transactions on a TiDB node, now distinguishing between 'Running' and 'Idle' states for transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.2.0.md#2025-04-18_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.TIDB_TRX;\n```\n\n----------------------------------------\n\nTITLE: Simple Update Command for TiDB Cloud CLI\nDESCRIPTION: This shell snippet shows a direct command for updating the TiDB Cloud CLI without any additional flags or parameters. It serves as the simplest form of the update command.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-update.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud update\n```\n\n----------------------------------------\n\nTITLE: Querying Remaining Space of Nodes in TiKV\nDESCRIPTION: Use this command to query the remaining disk space for each node, formatted for easier consumption using Jq.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_62\n\nLANGUAGE: bash\nCODE:\n```\nstore --jq=\".stores[] | {id: .store.id, available: .status.available}\"\n```\n\n----------------------------------------\n\nTITLE: Evicting an Owner Node - TiCDC - Shell\nDESCRIPTION: This example demonstrates how to evict the current owner node of TiCDC, triggering a new leader election, using a POST request.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://127.0.0.1:8300/api/v1/owner/resign\n```\n\n----------------------------------------\n\nTITLE: Pausing a Replication Task - TiCDC - Shell\nDESCRIPTION: This example shows how to pause a replication task using a POST request. The `changefeed_id` is used as a path parameter to specify the replication task to be paused.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://127.0.0.1:8300/api/v1/changefeeds/test1/pause\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Specific Host and Password in TiDB\nDESCRIPTION: Create a user 'test' that can only connect from the IP address 127.0.0.1 with a specified password 'xxx'.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'test'@'127.0.0.1' IDENTIFIED BY 'xxx';\n```\n\n----------------------------------------\n\nTITLE: Executing PD Control command using TLS encryption\nDESCRIPTION: This snippet demonstrates how to use TLS to encrypt communication with the PD server.  It specifies the path to the CA certificate, SSL certificate, and key file using the `--cacert`, `--cert`, and `--key` flags, respectively.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd -u https://127.0.0.1:2379 --cacert=\"path/to/ca\" --cert=\"path/to/cert\" --key=\"path/to/key\"\n```\n\n----------------------------------------\n\nTITLE: Querying data with AS OF TIMESTAMP in TiDB\nDESCRIPTION: Demonstrates how to query data from a specific point in time using the AS OF TIMESTAMP clause in TiDB. This feature allows users to perform stale reads for historical data analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.0.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t AS OF TIMESTAMP  '2020-09-06 00:00:00';\nSTART TRANSACTION READ ONLY AS OF TIMESTAMP '2020-09-06 00:00:00';\nSET TRANSACTION READ ONLY as of timestamp '2020-09-06 00:00:00';\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Cloud Serverless Connection String\nDESCRIPTION: Creates a .env file with the connection string for a TiDB Cloud Serverless cluster, including necessary SSL configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-python.md#2025-04-18_snippet_1\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_DATABASE_URL=\"mysql+pymysql://<prefix>.root:<password>@gateway01.<region>.prod.aws.tidbcloud.com:4000/test?ssl_ca=/etc/ssl/cert.pem&ssl_verify_cert=true&ssl_verify_identity=true\"\n```\n\n----------------------------------------\n\nTITLE: Starting an Optimistic Transaction with In-Place Constraint Checking\nDESCRIPTION: This example begins an optimistic transaction after enabling in-place constraint checking, which will cause unique constraint violations to be detected immediately.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN OPTIMISTIC;\n```\n\n----------------------------------------\n\nTITLE: Rewriting SQL for binding compatibility\nDESCRIPTION: This snippet shows how to rewrite problematic SQL statements to avoid syntax conflicts when creating bindings. The `JOIN` keyword is replaced with a comma for Cartesian products, and the `USING` keyword is removed from the `DELETE` statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n-- Rewrite of type one statements: Delete the `JOIN` keyword. Replace it with a comma.\nCREATE GLOBAL BINDING for\n    SELECT * FROM orders o1, orders o2\nUSING\n    SELECT * FROM orders o1, orders o2;\n\n-- Rewrite of type two statements: Remove the `USING` keyword from the `DELETE` statement.\nCREATE GLOBAL BINDING for\n    DELETE users FROM users JOIN orders ON users.id = orders.user_id\nUSING\n    DELETE users FROM users JOIN orders ON users.id = orders.user_id;\n```\n\n----------------------------------------\n\nTITLE: Querying DM Task Status in Bash\nDESCRIPTION: This snippet shows the command to query the status of a DM task named 'test' using the query-status command.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-query-status.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n» query-status test\n```\n\n----------------------------------------\n\nTITLE: Pausing a TiDB Cloud Cluster with Terraform\nDESCRIPTION: This snippet demonstrates how to configure a TiDB Cloud cluster to be paused within the Terraform configuration. It shows how to set the 'paused' attribute to true in the configuration file and highlights the expected status change after applying the changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_10\n\nLANGUAGE: hcl\nCODE:\n```\nconfig = {\n    paused = true\n    root_password = \"Your_root_password1.\"\n    port          = 4000\n    ...\n  }\n```\n\n----------------------------------------\n\nTITLE: Querying Time Zone Variables\nDESCRIPTION: SQL example demonstrating how to query time zone related variables using SHOW GLOBAL VARIABLES with a LIKE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-variables.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW GLOBAL VARIABLES LIKE 'time_zone%';\n```\n\n----------------------------------------\n\nTITLE: Using AS OF TIMESTAMP Clause with SELECT Statement in SQL\nDESCRIPTION: SQL query using the AS OF TIMESTAMP clause to read historical data from a specific point in time, retrieving the original data before the update.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nselect * from t as of timestamp '2021-05-26 16:45:26';\n```\n\n----------------------------------------\n\nTITLE: Displaying PD Configuration Information\nDESCRIPTION: This snippet shows how to use the 'config show' command to display various levels of configuration information, including scheduling, replication, and cluster version.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n>> config show                                // Display the config information of the scheduling\n>> config show all                            // Display all config information\n>> config show replication                    // Display the config information of replication\n>> config show cluster-version                // Display the current version of the cluster\n```\n\n----------------------------------------\n\nTITLE: Configuring CSV File Settings - TOML\nDESCRIPTION: This snippet provides configuration settings for importing CSV files into TiDB using TOML. It specifies various options such as the field separator, quoting delimiter, line terminator, and NULL handling.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[mydumper.csv]\n# The field separator. Can be one or multiple characters. The default is ','.\n# If the data might contain commas, it is recommended to use '|+|' or other uncommon\n# character combinations as a separator.\nseparator = ','\n# Quoting delimiter. Empty value means no quoting.\ndelimiter = '\"'\n# Line terminator. Can be one or multiple characters. Empty value (default) means\n# both \"\\n\" (LF) and \"\\r\\n\" (CRLF) are line terminators.\nterminator = ''\n# Whether the CSV file contains a header.\n# If `header` is true, the first line is skipped and mapped\nto the table columns.\nheader = true\n# Whether the CSV file contains any NULL value.\n# If `not-null` is true, all columns from CSV cannot be parsed as NULL.\nnot-null = false\n# When `not-null` is false (that is, CSV can contain NULL),\n# fields equal to this value will be treated as NULL.\null = '\\N'\n# Whether to parse backslash as escape character.\nbackslash-escape = true\n# Whether to treat `separator` as the line terminator and trim all trailing separators.\ntrim-last-separator = false\n```\n\n----------------------------------------\n\nTITLE: Configuring Leader Scheduling Policy in Multi-AZ Deployment\nDESCRIPTION: Shell commands to configure leader transfer and priority settings for PD and TiKV nodes across different availability zones, optimizing read performance and leadership distribution\nSOURCE: https://github.com/pingcap/docs/blob/master/multi-data-centers-in-one-city-deployment.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n-- Evicts all leaders of other AZs to the AZ that provides services to the application.\nconfig set label-property reject-leader LabelName labelValue\n\n-- Migrates PD leaders and sets priority.\nmember leader transfer pdName1\nmember leader_priority pdName1 5\nmember leader_priority pdName2 4\nmember leader_priority pdName3 3\n```\n\n----------------------------------------\n\nTITLE: Running Sysbench Long Connection Test (Bash)\nDESCRIPTION: This snippet initiates a Sysbench test to examine the impact of idle long connections on QPS. It creates various counts of idle connections to test how they affect performance metrics such as average latency and CPU usage. Requires Sysbench and MySQL database access.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-performance-test.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nsysbench oltp_point_select \\\n    --threads=50 \\\n    --time=1200 \\\n    --report-interval=10 \\\n    --rand-type=uniform \\\n    --db-driver=mysql \\\n    --mysql-db=sbtest \\\n    --mysql-host=$host \\\n    --mysql-port=$port \\\n    run --tables=32 --table-size=1000000\n```\n\n----------------------------------------\n\nTITLE: Querying Data with ActiveRecord ORM in Rails\nDESCRIPTION: Ruby code that retrieves a Player record by ID using ActiveRecord's find_by method.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_12\n\nLANGUAGE: ruby\nCODE:\n```\nplayer = Player.find_by(id: new_player.id)\n```\n\n----------------------------------------\n\nTITLE: Monitoring TiFlash Raft Read Index Duration using PromQL\nDESCRIPTION: This PromQL query alerts when the 99th percentile of Raft read index duration exceeds 3 seconds in the last minute. It helps detect slow read operations in TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-alert-rules.md#2025-04-18_snippet_2\n\nLANGUAGE: promql\nCODE:\n```\nhistogram_quantile(0.99, sum(rate(tiflash_raft_read_index_duration_seconds_bucket[1m])) BY (le, instance)) > 3\n```\n\n----------------------------------------\n\nTITLE: Describing REFERENTIAL_CONSTRAINTS Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the REFERENTIAL_CONSTRAINTS table in the INFORMATION_SCHEMA database, showing all columns and their properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-referential-constraints.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC REFERENTIAL_CONSTRAINTS;\n```\n\n----------------------------------------\n\nTITLE: SHOW PROFILES Example\nDESCRIPTION: This SQL code demonstrates a simple `SHOW PROFILES` statement. It shows the basic syntax for retrieving profile information, but in TiDB, it returns an empty result set.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-profiles.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW PROFILES;\n```\n\n----------------------------------------\n\nTITLE: Example of AWS VPC Peering Environment Variables\nDESCRIPTION: A concrete example showing how to set the necessary environment variables for AWS VPC peering, including an actual peering ID, region, VPC ID, and CIDR range.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-vpc-peering-connections.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Sets up the related variables\npcx_tidb_to_app_id=\"pcx-069f41efddcff66c8\"\napp_region=\"us-west-2\"\napp_vpc_id=\"vpc-0039fb90bb5cf8698\"\ntidbcloud_project_cidr=\"10.250.0.0/16\"\n```\n\n----------------------------------------\n\nTITLE: Setting max_prepared_stmt_count in TiDB\nDESCRIPTION: Specifies the maximum number of prepared statements allowed in a TiDB instance. A value of `-1` allows unlimited prepared statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\n-- Default value: `-1`\n-- Range: `[-1, 1048576]`\nSET GLOBAL max_prepared_stmt_count = -1;\n```\n\n----------------------------------------\n\nTITLE: Describing SEQUENCES Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the SEQUENCES table in the INFORMATION_SCHEMA database, showing the fields, their types, and other properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-sequences.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC SEQUENCES;\n```\n\n----------------------------------------\n\nTITLE: Deleting PersistentVolumeClaim for TiKV with kubectl\nDESCRIPTION: This command deletes the PersistentVolumeClaim (PVC) associated with a failed TiKV instance in a Kubernetes environment managed by TiDB Operator. Requires the namespace and PVC name.\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nkubectl delete -n ${namespace} pvc ${pvc_name} --wait=false\n```\n\n----------------------------------------\n\nTITLE: Key-Value Mapping: Primary/Unique Index\nDESCRIPTION: This code snippet shows the encoding for primary keys and unique indexes in TiDB, focusing on how to quickly locate the corresponding `RowID` based on the key-value pair. The key is composed of the table ID, index ID, and indexed column values, while the value stores the `RowID`.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-computing.md#2025-04-18_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n\"Key:   tablePrefix{tableID}_indexPrefixSep{indexID}_indexedColumnsValue\\nValue: RowID\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Store Limit Version in PD\nDESCRIPTION: Sets the store limit version to v2, enabling dynamic adjustment of store limits based on TiKV snapshot capabilities without manual intervention.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nconfig set store-limit-version v2\n```\n\n----------------------------------------\n\nTITLE: HTTP Listening Port Configuration in TiDB\nDESCRIPTION: Code reference to TiDB's feature that stops TiDB startup if the HTTP listening port is unavailable when 'report-status' is enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.1.0-ga.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- Support directly stopping starting TiDB if the HTTP listening port is unavailable when the `report-status` configuration item is enabled [#16291](https://github.com/pingcap/tidb/pull/16291)\n```\n\n----------------------------------------\n\nTITLE: Collecting Statistics on Specific Columns in TiDB\nDESCRIPTION: SQL syntax for collecting statistics on specific columns in a table. The ColumnNameList specifies the target columns separated by commas. This command also collects statistics on indexed columns and all indexes in the table.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE TableName COLUMNS ColumnNameList [WITH NUM BUCKETS|TOPN|CMSKETCH DEPTH|CMSKETCH WIDTH]|[WITH NUM SAMPLES|WITH FLOATNUM SAMPLERATE];\n```\n\n----------------------------------------\n\nTITLE: Auto-Detect Store Removal for Unsafe Recovery\nDESCRIPTION: Command to automatically remove replicas from unregistered or forcibly deleted TiKV nodes when store IDs are unknown\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl -u <pd_addr> unsafe remove-failed-stores --auto-detect\n```\n\n----------------------------------------\n\nTITLE: Using EXPLAIN to Analyze Index Lookups in TiDB\nDESCRIPTION: Examples of SQL queries that use the IndexLookup operator on the 'intkey' index with various conditions, demonstrating how TiDB handles equality, range, BETWEEN, IN, and compound comparison operators.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-indexes.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t1 WHERE intkey = 123;\nEXPLAIN SELECT * FROM t1 WHERE intkey < 10;\nEXPLAIN SELECT * FROM t1 WHERE intkey BETWEEN 300 AND 310;\nEXPLAIN SELECT * FROM t1 WHERE intkey IN (123,29,98);\nEXPLAIN SELECT * FROM t1 WHERE intkey >= 99 AND intkey <= 103;\n```\n\n----------------------------------------\n\nTITLE: Performing Bitwise AND Operation in SQL\nDESCRIPTION: The '&' operator executes a bitwise AND operation between two numbers. The operator gives 1 for each bit position where both operands have 1, otherwise returns 0. Inputs are two binary numbers, and outputs are their bitwise AND result.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/bit-functions-and-operators.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONV(b'1010' & b'1000',10,2);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT INET_NTOA(INET_ATON('192.168.1.1') & INET_ATON('255.255.255.0'));\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT INET_NTOA(INET_ATON('192.168.1.2') & INET_ATON('255.255.255.0'));\n```\n\n----------------------------------------\n\nTITLE: Specifying mpp_version in TiDB\nDESCRIPTION: This variable specifies different MPP execution plan versions. Based on its setting, TiDB can select the corresponding execution plan for better efficiency or compatibility.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n-- Default value: `UNSPECIFIED`\nSET SESSION mpp_version = 'UNSPECIFIED';\n```\n\n----------------------------------------\n\nTITLE: Demonstrating DROP COLUMN Usage in TiDB\nDESCRIPTION: This SQL example demonstrates creating a table, inserting data, and then dropping columns using the ALTER TABLE DROP COLUMN statement in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-column.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, col1 INT NOT NULL, col2 INT NOT NULL);\nQuery OK, 0 rows affected (0.12 sec)\n\nmysql> INSERT INTO t1 (col1,col2) VALUES (1,1),(2,2),(3,3),(4,4),(5,5);\nQuery OK, 5 rows affected (0.02 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\nmysql> SELECT * FROM t1;\n+----+------+------+\n| id | col1 | col2 |\n+----+------+------+\n|  1 |    1 |    1 |\n|  2 |    2 |    2 |\n|  3 |    3 |    3 |\n|  4 |    4 |    4 |\n|  5 |    5 |    5 |\n+----+------+------+\n5 rows in set (0.01 sec)\n\nmysql> ALTER TABLE t1 DROP COLUMN col1, DROP COLUMN col2;\nERROR 1105 (HY000): can't run multi schema change\nmysql> SELECT * FROM t1;\n+----+------+------+\n| id | col1 | col2 |\n+----+------+------+\n|  1 |    1 |    1 |\n|  2 |    2 |    2 |\n|  3 |    3 |    3 |\n|  4 |    4 |    4 |\n|  5 |    5 |    5 |\n+----+------+------+\n5 rows in set (0.00 sec)\n\nmysql> ALTER TABLE t1 DROP COLUMN col1;\nQuery OK, 0 rows affected (0.27 sec)\n\nmysql> SELECT * FROM t1;\n+----+------+\n| id | col2 |\n+----+------+\n|  1 |    1 |\n|  2 |    2 |\n|  3 |    3 |\n|  4 |    4 |\n|  5 |    5 |\n+----+------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting global Store Limit for all stores\nDESCRIPTION: Commands to set store limits globally for all stores, with options to configure combined limits or separate limits for add-peer and remove-peer operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-store-limit.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd store limit all 5                   // All stores can at most add and delete 5 peers per minute.\ntiup ctl:v<CLUSTER_VERSION> pd store limit all 5 add-peer          // All stores can at most add 5 peers per minute.\ntiup ctl:v<CLUSTER_VERSION> pd store limit all 5 remove-peer       // All stores can at most delete 5 peers per minute.\n```\n\n----------------------------------------\n\nTITLE: Restoring TiDB data with encryption key as environment variable\nDESCRIPTION: These commands show setting the AZURE_ENCRYPTION_KEY environment variable before running the restore command, allowing the encryption key to be specified without including it in the command line.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\nexport AZURE_ENCRYPTION_KEY=<aes256-key>\ntiup br restore full --pd <pd-address> --storage \"azure://<bucket>/<prefix>\"\n```\n\n----------------------------------------\n\nTITLE: Initial Account Lock with Password Complexity in TiDB\nDESCRIPTION: This SQL example shows that creating a locked account without setting a compliant password results in an error, enforcing the importance of adhering to password policies from the onset.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> CREATE USER 'user02'@'localhost' ACCOUNT LOCK;\nERROR 1819 (HY000): Require Password Length: 8\n```\n\n----------------------------------------\n\nTITLE: Querying mysql.tidb_runaway_queries table\nDESCRIPTION: This SQL statement retrieves a sample record from the `mysql.tidb_runaway_queries` table. This table contains history records of runaway queries identified within the past 7 days.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n\"MySQL [(none)]> SELECT * FROM mysql.tidb_runaway_queries LIMIT 1\\G\"\n```\n\n----------------------------------------\n\nTITLE: Configuring List Partitioning in TiDB 5.0\nDESCRIPTION: SQL syntax for enabling and configuring list partitioning in TiDB 5.0. This feature allows partitioning tables based on a list of values using PARTITION BY LIST expression. Supports up to 1024 distinct integer values.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nPARTITION BY LIST(expr) PARTITION part_name VALUES IN (...)\n```\n\n----------------------------------------\n\nTITLE: Configuring Maximum Type Errors in TiDB Lightning\nDESCRIPTION: Configures the maximum number of type conversion errors that can be tolerated during data import. Setting this to 0 means no errors are allowed, while a positive number allows skipping that many type-related errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\nmax-error = 0\n```\n\n----------------------------------------\n\nTITLE: Sample Kafka Sink URI Configuration\nDESCRIPTION: A sample configuration of sink URI aimed at a Kafka topic. The URI includes details such as the protocol for message output, Kafka version, number of partitions, maximum message bytes, and replication factor. This configuration facilitates the connection setup with detailed option settings for an optimal and compliant Kafka interaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\\\"kafka://127.0.0.1:9092/topic-name?protocol=canal-json&kafka-version=2.4.0&partition-num=6&max-message-bytes=67108864&replication-factor=1\\\"\n```\n\n----------------------------------------\n\nTITLE: Job Status Response Format in JavaScript\nDESCRIPTION: Example response from the /v2/jobs/{job_id} endpoint. It includes the status of the job, timestamps, and if completed, the full data summary generated from the database analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"code\": 200,\n  \"msg\": \"\",\n  \"result\": {\n    \"ended_at\": 1699518950, // A UNIX timestamp indicating when the job is finished\n    \"job_id\": \"fb99ef785da640ab87bf69afed60903d\", // ID of current job\n    \"result\": DataSummaryObject, // AI exploration information of the given database\n    \"status\": \"done\" // Status of the current job\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Collecting Statistics on Table Partitions in TiDB\nDESCRIPTION: SQL syntax for collecting statistics on specific partitions of a table. The PartitionNameList specifies which partitions to analyze.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE TableName PARTITION PartitionNameList [WITH NUM BUCKETS|TOPN|CMSKETCH DEPTH|CMSKETCH WIDTH]|[WITH NUM SAMPLES|WITH FLOATNUM SAMPLERATE];\n```\n\n----------------------------------------\n\nTITLE: Executing FLASHBACK CLUSTER with Timestamp in TiDB\nDESCRIPTION: Syntax for executing FLASHBACK CLUSTER using a timestamp to restore a cluster to a specific point in time.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-cluster.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nFLASHBACK CLUSTER TO TIMESTAMP '2022-09-21 16:02:50';\n```\n\n----------------------------------------\n\nTITLE: Window Function with ORDER BY and TopN Optimization in SQL (TiDB)\nDESCRIPTION: This example demonstrates a window function with ORDER BY clause where TiDB's optimizer derives a TopN operator and pushes it down to TiKV. The PARTITION BY column is a prefix of the primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/derive-topn-from-window.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id1 int, id2 int, value1 int, value2 int, primary key(id1,id2) clustered);\nSET tidb_opt_derive_topn=on;\nEXPLAIN SELECT * FROM (SELECT ROW_NUMBER() OVER (PARTITION BY id1 ORDER BY value1) AS rownumber FROM t) dt WHERE rownumber <= 3;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiFlash Servers with YAML\nDESCRIPTION: Example YAML configuration for TiFlash servers showing how to set up multiple hosts. This simple configuration specifies two TiFlash instances using their IP addresses.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\ntiflash_servers:\n  - host: 10.0.1.21\n  - host: 10.0.1.22\n```\n\n----------------------------------------\n\nTITLE: Configuring sync-diff-inspector with Patterned Table Names\nDESCRIPTION: This TOML configuration example for sync-diff-inspector is utilized when there are many sharded tables, and the table naming follows a consistent pattern. It highlights the configuration of data source connections, routing rules for patterned table names, and task settings necessary for data comparison. It also includes parameters like \"check-thread-count\" and \"export-fix-sql\", similar to the configuration for specific table names.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/shard-diff.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n# Diff Configuration.\n######################### Global config #########################\n\n# The number of goroutines created to check data. The number of connections between upstream and downstream databases are slightly greater than this value.\ncheck-thread-count = 4\n\n# If enabled, SQL statements is exported to fix inconsistent tables.\nexport-fix-sql = true\n\n# Only compares the table structure instead of the data.\ncheck-struct-only = false\n\n######################### Datasource config #########################\n[data-sources.mysql1]\n    host = \"127.0.0.1\"\n    port = 3306\n    user = \"root\"\n    password = \"\"\n\n[data-sources.mysql2]\n    host = \"127.0.0.1\"\n    port = 3306\n    user = \"root\"\n    password = \"\"\n\n[data-sources.tidb0]\n    host = \"127.0.0.1\"\n    port = 4000\n    user = \"root\"\n    password = \"\"\n\n########################### Routes ###########################\n[routes.rule1]\nschema-pattern = \"test\"      # Matches the schema name of the data source. Supports the wildcards \"*\" and \"?\"\ntable-pattern = \"table-*\"    # Matches the table name of the data source. Supports the wildcards \"*\" and \"?\"\ntarget-schema = \"test\"       # The name of the schema in the target database\ntarget-table = \"table-0\"     # The name of the target table\n\n######################### Task config #########################\n[task]\n    output-dir = \"./output\"\n    source-instances = [\"mysql1\", \"mysql2\"]\n\n    target-instance = \"tidb0\"\n\n    # The tables of downstream databases to be compared. Each table needs to contain the schema name and the table name, separated by '.'\n    target-check-tables = [\"test.table-0\"]\n```\n\n----------------------------------------\n\nTITLE: Listing Available Regions - Shell\nDESCRIPTION: This command lists all available regions for TiDB Cloud Serverless. It can be executed in the command line to retrieve region data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-region.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless region [flags]\n```\n\n----------------------------------------\n\nTITLE: Adding tidb-loadbalance Gradle Dependencies\nDESCRIPTION: Gradle configuration for adding tidb-loadbalance and required MySQL connector dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-choose-driver-or-orm.md#2025-04-18_snippet_8\n\nLANGUAGE: gradle\nCODE:\n```\nimplementation group: 'io.github.lastincisor', name: 'mysql-connector-java', version: '8.0.29-tidb-1.0.0'\nimplementation group: 'io.github.lastincisor', name: 'tidb-loadbalance', version: '0.0.5'\n```\n\n----------------------------------------\n\nTITLE: Loading TPC-C Test Data\nDESCRIPTION: Command to load TPC-C test data with 1000 warehouses using 32 threads. The command connects to TiDB server at specified host and port.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-ch.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup bench tpcc -H 172.16.5.140 -P 4000 -D tpcc --warehouses 1000 prepare -T 32\n```\n\n----------------------------------------\n\nTITLE: Configuring DM-master Command-line Flags\nDESCRIPTION: These flags are used to configure various aspects of DM-master, such as network addresses, cluster initialization, data storage, and logging.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-command-line-flags.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### `--advertise-addr`\n\n- The external address of DM-master used to receive client requests\n- The default value is `\"{master-addr}\"`\n- Optional flag. It can be in the form of `\"domain-name:port\"`\n\n### `--advertise-peer-urls`\n\n- The external address for communication between DM-master nodes\n- The default value is `\"{peer-urls}\"`\n- Optional flag. It can be in the form of `\"http(s)://domain-name:port\"`\n\n### `--config`\n\n- The configuration file path of DM-master\n- The default value is `\"\"`\n- Optional flag\n\n### `--data-dir`\n\n- The directory used to store data of DM-master\n- The default value is `\"default.{name}\"`\n- Optional flag\n\n### `--initial-cluster`\n\n- The `\"{node name}={external address}\"` list used to bootstrap DM-master cluster\n- The default value is `\"{name}={advertise-peer-urls}\"`\n- This flag needs to be specified if the `join` flag is not specified. A configuration example of a 3-node cluster is `\"dm-master-1=http://172.16.15.11:8291,dm-master-2=http://172.16.15.12:8291,dm-master-3=http://172.16.15.13:8291\"`\n\n### `--join`\n\n- The existing cluster's `advertise-addr` list when a DM-master node joins this cluster\n- The default value is `\"\"`\n- This flag needs to be specified if the `initial-cluster` flag is not specified. Suppose a new node joins a cluster that has 2 nodes, a configuration example is `\"172.16.15.11:8261,172.16.15.12:8261\"`\n\n### `--log-file`\n\n- The output file name of the log\n- The default value is `\"\"`\n- Optional flag\n\n### `-L`\n\n- The log level\n- The default value is `\"info\"`\n- Optional flag\n\n### `--master-addr`\n\n- The address on which DM-master listens to the client's requests\n- The default value is `\"\"`\n- Required flag\n\n### `--name`\n\n- The name of a DM-master node\n- The default value is `\"dm-master-{hostname}\"`\n- Required flag\n\n### `--peer-urls`\n\n- The listening address for communications between DM-master nodes\n- The default value is `\"http://127.0.0.1:8291\"`\n- Required flag\n\n### `--secret-key-path`\n\n- The path of the customized secret key for encryption and decryption\n- The default value is `\"\"`\n- Optional flag\n```\n\n----------------------------------------\n\nTITLE: Describing CLUSTER_LOG Table Schema in SQL\nDESCRIPTION: Shows the structure of the CLUSTER_LOG table including field names, data types, and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-log.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC cluster_log;\n```\n\n----------------------------------------\n\nTITLE: TTL with Generated Columns\nDESCRIPTION: Creates a table with TTL using a generated column to implement different expiration rules based on content type.\nSOURCE: https://github.com/pingcap/docs/blob/master/time-to-live.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE message (\n    id int PRIMARY KEY,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    image bool,\n    expire_at TIMESTAMP AS (IF(image,\n            created_at + INTERVAL 5 DAY,\n            created_at + INTERVAL 30 DAY\n    ))\n) TTL = `expire_at` + INTERVAL 0 DAY;\n```\n\n----------------------------------------\n\nTITLE: Displaying Foreign Key Constraints\nDESCRIPTION: This SQL command retrieves the foreign key constraints of a specified table, useful for analyzing relationships and ensuring integrity in the schema design.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE child;\n```\n\n----------------------------------------\n\nTITLE: Complex Queries in Hash Partitioned Tables: Inapplicable Partition Pruning in SQL\nDESCRIPTION: This SQL example highlights the limitation of partition pruning when filter conditions are determined during execution, as demonstrated in a query involving a subquery. Partition pruning cannot predict which partition to access during the query plan generation phase.\nSOURCE: https://github.com/pingcap/docs/blob/master/partition-pruning.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (x int) partition by hash(x) partitions 4;\nexplain select * from t2 where x = (select * from t1 where t2.x = t1.x and t2.x < 2);\n```\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------------------+----------+-----------+------------------------+----------------------------------------------+\n| id                                   | estRows  | task      | access object          | operator info                                |\n+--------------------------------------+----------+-----------+------------------------+----------------------------------------------+\n| Projection_13                        | 9990.00  | root      |                        | test.t2.x                                    |\n| └─Apply_15                           | 9990.00  | root      |                        | inner join, equal:[eq(test.t2.x, test.t1.x)] |\n|   ├─TableReader_18(Build)            | 9990.00  | root      |                        | data:Selection_17                            |\n|   │ └─Selection_17                   | 9990.00  | cop[tikv] |                        | not(isnull(test.t2.x))                       |\n|   │   └─TableFullScan_16             | 10000.00 | cop[tikv] | table:t2               | keep order:false, stats:pseudo               |\n|   └─Selection_19(Probe)              | 0.80     | root      |                        | not(isnull(test.t1.x))                       |\n|     └─MaxOneRow_20                   | 1.00     | root      |                        |                                              |\n|       └─Union_21                     | 2.00     | root      |                        |                                              |\n|         ├─TableReader_24             | 2.00     | root      |                        | data:Selection_23                            |\n|         │ └─Selection_23             | 2.00     | cop[tikv] |                        | eq(test.t2.x, test.t1.x), lt(test.t2.x, 2)   |\n|         │   └─TableFullScan_22       | 2500.00  | cop[tikv] | table:t1, partition:p0 | keep order:false, stats:pseudo               |\n|         └─TableReader_27             | 2.00     | root      |                        | data:Selection_26                            |\n|           └─Selection_26             | 2.00     | cop[tikv] |                        | eq(test.t2.x, test.t1.x), lt(test.t2.x, 2)   |\n|             └─TableFullScan_25       | 2500.00  | cop[tikv] | table:t1, partition:p1 | keep order:false, stats:pseudo               |\n+--------------------------------------+----------+-----------+------------------------+----------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Remove All Regions from Failed Stores\nDESCRIPTION: This command removes failed machines from all regions in the specified stores. Precautions must be considered to avoid inconsistencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir /path/to/tikv unsafe-recover remove-fail-stores -s 4,5 --all-regions\n```\n\n----------------------------------------\n\nTITLE: Using INL_JOIN Optimizer Hint - SQL\nDESCRIPTION: This snippet illustrates the usage of the INL_JOIN optimizer hint to optimize query performance by specifying the index nested loop join algorithm for the provided tables, potentially reducing resource consumption during execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ INL_JOIN(t1, t2) */ * FROM t1, t2, t3 WHERE t1.id = t2.id AND t2.id = t3.id;\n```\n\n----------------------------------------\n\nTITLE: Showing ANALYZE Status in SQL\nDESCRIPTION: SQL query to show the status of running ANALYZE tasks, including the TiDB instance and task ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_28\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW ANALYZE STATUS\n```\n\n----------------------------------------\n\nTITLE: Importing Statistics with LOAD STATS SQL Statement\nDESCRIPTION: SQL statement to import statistics from a previously exported file. Requires starting the MySQL client with --local-infile=1 option.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nLOAD STATS 'file_name';\n```\n\n----------------------------------------\n\nTITLE: DELETE Statement EBNF Syntax in TiDB\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax diagram for the DELETE statement in TiDB. It shows the various optional clauses and components that can be used with DELETE, including table hints, priority options, and WHERE clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-delete.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDeleteFromStmt ::=\n    'DELETE' TableOptimizerHints PriorityOpt QuickOptional IgnoreOptional ( 'FROM' ( TableName TableAsNameOpt IndexHintListOpt WhereClauseOptional OrderByOptional LimitClause | TableAliasRefList 'USING' TableRefs WhereClauseOptional ) | TableAliasRefList 'FROM' TableRefs WhereClauseOptional )\n```\n\n----------------------------------------\n\nTITLE: Non-Transactional Update with Join in SQL\nDESCRIPTION: This SQL snippet demonstrates a non-transactional UPDATE statement in TiDB that joins two tables, 't' and 't2'. It updates the 'id' column of table 't2' based on a join condition. The batching is done on the '_tidb_rowid' column of table 't', with a limit of 1. Note the use of the complete database.table.column name for the shard column.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n\"BATCH ON test.t._tidb_rowid LIMIT 1 UPDATE t JOIN t2 ON t.id = t2.id SET t2.id = t2.id+1;\"\n```\n\n----------------------------------------\n\nTITLE: Explain SUM/AVG queries with IndexFullScan in TiDB\nDESCRIPTION: These SQL statements demonstrate how `IndexFullScan` is used to efficiently calculate the sum and average of an indexed column (`intkey`) in a TiDB table (`t1`). The `EXPLAIN` statement reveals the execution plan, showing that `IndexFullScan` scans every row in the index, making it more efficient than `TableFullScan` due to the smaller width of the index compared to the full row.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-indexes.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT SUM(intkey) FROM t1;\nEXPLAIN SELECT AVG(intkey) FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Developing Cloudflare Worker Function with TiDB Cloud\nDESCRIPTION: TypeScript code for a Cloudflare Worker function that connects to TiDB Cloud using the serverless driver and executes a 'show databases' query.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-cloudflare.md#2025-04-18_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { connect } from '@tidbcloud/serverless'\n\n\nexport interface Env {\n   DATABASE_URL: string;\n}\n\nexport default {\n   async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n      const conn = connect({url:env.DATABASE_URL})\n      const resp = await conn.execute(\"show databases\")\n      return new Response(JSON.stringify(resp));\n   },\n};\n```\n\n----------------------------------------\n\nTITLE: Displaying TiDB Supported Built-in Functions Using SHOW BUILTINS\nDESCRIPTION: This SQL command displays a complete list of all built-in functions supported by TiDB. The query returns a single column listing all available functions, which include mathematical, string, date/time, JSON, and TiDB-specific functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-builtins.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW BUILTINS;\n```\n\n----------------------------------------\n\nTITLE: Querying Unique Constraints from TABLE_CONSTRAINTS in TiDB (SQL)\nDESCRIPTION: This SQL query selects all rows from the TABLE_CONSTRAINTS table where the constraint type is 'UNIQUE'. It demonstrates how to retrieve specific constraint information from the table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-table-constraints.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM table_constraints WHERE constraint_type='UNIQUE';\n```\n\n----------------------------------------\n\nTITLE: Configuring Double Type Check in TiDB\nDESCRIPTION: Example showing how to disable strict double type checking to allow creation of tables with invalid DOUBLE precision specifications. This is useful for compatibility with older TiDB versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_43\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id int, c double(10));\nERROR 1149 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use\n\nmysql> SET tidb_enable_strict_double_type_check = 'OFF';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> CREATE TABLE t1 (id int, c double(10));\nQuery OK, 0 rows affected (0.09 sec)\n```\n\n----------------------------------------\n\nTITLE: Invalid Range Columns Partitioning Example\nDESCRIPTION: This example demonstrates an incorrect implementation of RANGE COLUMNS partitioning where the `VALUES LESS THAN` values are not strictly increasing for each partition.  This will result in an error because the partition ranges must be ordered from lowest to highest.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(\n    a int,\n    b datetime,\n    c varchar(8)\n) PARTITION BY RANGE COLUMNS(`c`,`b`)\n(PARTITION `p20240520A` VALUES LESS THAN ('A','2024-05-20 00:00:00'),\n PARTITION `p20240520Z` VALUES LESS THAN ('Z','2024-05-20 00:00:00'),\n PARTITION `p20240521A` VALUES LESS THAN ('A','2024-05-21 00:00:00'));\n```\n\n----------------------------------------\n\nTITLE: Enabling Aggregate Push Down Optimization in TiDB\nDESCRIPTION: Configures the system variable to allow pushing down aggregate functions before Join or Union operations, which can significantly improve query performance by reducing data processing\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_opt_agg_push_down = ON;\n```\n\n----------------------------------------\n\nTITLE: Logging into TiDB via MySQL Client\nDESCRIPTION: This snippet demonstrates how to log into a TiDB instance using the MySQL client. It specifies the host, user, and port to connect to the TiDB server.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/manage-cluster-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmysql -h 127.0.0.1 -uroot -P4000\n```\n\n----------------------------------------\n\nTITLE: Creating Session-Level SQL Plan Binding\nDESCRIPTION: Creates a session-level binding that specifies using hash join instead of the default sort merge join for a SELECT query joining t1 and t2 tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE BINDING for\n    SELECT * FROM t1, t2 WHERE t1.id = t2.id\nUSING\n    SELECT /*+ hash_join(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Creating a Replication Task with TiCDC Shell Command\nDESCRIPTION: This shell command creates a replication task with a specified ID and sink URI using a POST request to the TiCDC API. It requires curl and details of the changefeed configuration in JSON format. A successful request returns a 200 OK status.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST -H \"'Content-type':'application/json'\" http://127.0.0.1:8300/api/v2/changefeeds -d '{\"changefeed_id\":\"test5\",\"sink_uri\":\"blackhole://\"}'\n```\n\n----------------------------------------\n\nTITLE: Filtering Instance Configurations in TiDB Cluster\nDESCRIPTION: These SQL queries demonstrate how to filter the configuration results by various criteria such as component type, instance, or configuration name.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nshow config where type='tidb'\nshow config where instance in (...)\nshow config where name like '%log%'\nshow config where type='tikv' and name='log.level'\n```\n\n----------------------------------------\n\nTITLE: Creating Table with NOT NULL Generated Column\nDESCRIPTION: Shows how to create a table with a NOT NULL constraint on the generated column to enforce data integrity.\nSOURCE: https://github.com/pingcap/docs/blob/master/generated-columns.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE person (\n    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    name VARCHAR(255) NOT NULL,\n    address_info JSON,\n    city VARCHAR(64) AS (JSON_UNQUOTE(JSON_EXTRACT(address_info, '$.city'))) NOT NULL,\n    KEY (city)\n);\n```\n\n----------------------------------------\n\nTITLE: Recursive CTE SQL Example\nDESCRIPTION: Example of a recursive Common Table Expression that generates a sequence of numbers from 1 to 5 using recursion.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-with.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nWITH RECURSIVE cte(a) AS (SELECT 1 UNION SELECT a+1 FROM cte WHERE a < 5) SELECT * FROM cte;\n```\n\n----------------------------------------\n\nTITLE: Connecting as User Jennifer\nDESCRIPTION: Shell command to connect to TiDB database as the user jennifer.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-revoke-role.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 127.0.0.1 -P 4000 -u jennifer\n```\n\n----------------------------------------\n\nTITLE: Retrieving the Current Database (SQL)\nDESCRIPTION: The `DATABASE()` function returns the name of the currently selected database, which is essential for context in SQL operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/information-functions.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DATABASE();\n```\n+------------+\n| DATABASE() |\n+------------+\n| test       |\n+------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Handling Warnings During Configuration Modification - SQL\nDESCRIPTION: This command sets the log level of TiKV to 'warn' and depicts a scenario where a modification is successful but generates a warning, which provides feedback on any issues that may arise.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nset config tikv `log-level`='warn';\n```\n\n----------------------------------------\n\nTITLE: Example DDL Status Query\nDESCRIPTION: SQL command to show the current status of DDL jobs, including schema version, owner information, and running jobs.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW DDL\\G;\n```\n\n----------------------------------------\n\nTITLE: Example of SHOW SESSION STATUS Query in SQL\nDESCRIPTION: This SQL snippet demonstrates how to execute the SHOW SESSION STATUS command, which retrieves the current session status variables and their values in TiDB, mirroring MySQL behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-status.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW SESSION STATUS;\n+-------------------------------+--------------------------------------+\n| Variable_name                 | Value                                |\n+-------------------------------+--------------------------------------+\n| Compression                   | OFF                                  |\n| Compression_algorithm         |                                      |\n| Compression_level             | 0                                    |\n| Ssl_cipher                    |                                      |\n| Ssl_cipher_list               |                                      |\n| Ssl_server_not_after          |                                      |\n| Ssl_server_not_before         |                                      |\n| Ssl_verify_mode               | 0                                    |\n| Ssl_version                   |                                      |\n| Uptime                        | 1409                                 |\n| ddl_schema_version            | 116                                  |\n| last_plan_binding_update_time | 0000-00-00 00:00:00                  |\n| server_id                     | 61160e73-ab80-40ff-8f33-27d55d475fd1 |\n+-------------------------------+--------------------------------------+\n13 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Dropping an Invisible Index\nDESCRIPTION: Example showing how to drop an invisible index from a table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-index.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t1 DROP INDEX c1;\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Attribute in TiDB SQL\nDESCRIPTION: SQL statements to create a new user 'newuser7' with an email attribute and verify the attribute in the information_schema in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser7'@'%' ATTRIBUTE '{\"email\": \"user@pingcap.com\"}';\nSELECT * FROM information_schema.user_attributes;\n```\n\n----------------------------------------\n\nTITLE: Rewritten Batch INSERT with rewriteBatchedStatements=true\nDESCRIPTION: Optimized SQL statement sent to TiDB when using batch operations with rewriteBatchedStatements=true. Multiple inserts are combined into a single statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO `t` (`a`) values(10),(11),(12);\n```\n\n----------------------------------------\n\nTITLE: Calculating TiKV Node Number Based on Data Volume\nDESCRIPTION: Formula to estimate the number of TiKV nodes needed based on data volume, compression ratio, number of replicas, storage usage ratio, and individual node capacity. It ensures even distribution across availability zones.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/size-your-cluster.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n`node num = ceil(size of your data * TiKV compression ratio * the number of replicas ÷ TiKV storage usage ratio ÷ one TiKV capacity ÷ 3) * 3`\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Default Access Rights in TiDB\nDESCRIPTION: Create a 'test' user with default settings that can connect from any host with an empty password.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'test';\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_outer_join_reorder in TiDB\nDESCRIPTION: This variable controls whether TiDB enables the Join Reorder's support for Outer Join. It is applicable globally or at session level, with a default state of ON since v6.1.0. This variable's configuration is important for optimizing query execution after upgrading from earlier versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_30\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): Yes\n- Type: Boolean\n- Default value: `ON`\n- Since v6.1.0, the [Join Reorder](/join-reorder.md) algorithm of TiDB supports Outer Join. This variable controls whether TiDB enables the Join Reorder's support for Outer Join.\n- If your cluster is upgraded from an earlier version of TiDB, note the following:\n\n    - If the TiDB version before the upgrade is earlier than v6.1.0, the default value of this variable after the upgrade is `ON`.\n    - If the TiDB version before the upgrade is v6.1.0 or later, the default value of the variable after the upgrade follows the value before the upgrade.\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with TypeORM in TypeScript\nDESCRIPTION: This code establishes a connection to TiDB using TypeORM. It uses environment variables for connection details and includes options for SSL configuration. The code also sets up entity relationships and migration paths.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n// src/dataSource.ts\n\n// Load environment variables from .env file to process.env.\nrequire('dotenv').config();\n\nexport const AppDataSource = new DataSource({\n  type: \"mysql\",\n  host: process.env.TIDB_HOST || '127.0.0.1',\n  port: process.env.TIDB_PORT ? Number(process.env.TIDB_PORT) : 4000,\n  username: process.env.TIDB_USER || 'root',\n  password: process.env.TIDB_PASSWORD || '',\n  database: process.env.TIDB_DATABASE || 'test',\n  ssl: process.env.TIDB_ENABLE_SSL === 'true' ? {\n    minVersion: 'TLSv1.2',\n    ca: process.env.TIDB_CA_PATH ? fs.readFileSync(process.env.TIDB_CA_PATH) : undefined\n  } : null,\n  synchronize: process.env.NODE_ENV === 'development',\n  logging: false,\n  entities: [Player, Profile],\n  migrations: [__dirname + \"/migrations/**/*{.ts,.js}\"],\n});\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with Concurrent Updates - SQL\nDESCRIPTION: This code snippet illustrates how TiDB handles concurrent DML operations using pessimistic transactions, specifically focusing on the non-blocking nature of range queries during updates.\nSOURCE: https://github.com/pingcap/docs/blob/master/pessimistic-transaction.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id INT NOT NULL PRIMARY KEY, pad1 VARCHAR(100));\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t1 (id) VALUES (1),(5),(10);\n```\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN /*T! PESSIMISTIC */;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 WHERE id BETWEEN 1 AND 10 FOR UPDATE;\n```\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN /*T! PESSIMISTIC */;\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t1 (id) VALUES (6);\n```\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE t1 SET pad1='new value' WHERE id = 5;\n```\n\n----------------------------------------\n\nTITLE: Using tikv-ctl to Get Region Read Progress\nDESCRIPTION: Command-line example showing how to use tikv-ctl to retrieve the state of a Region's RegionReadProgress, including safe-ts and resolver information.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-stale-read.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./tikv-ctl --host 127.0.0.1:20160 get-region-read-progress -r 14 --log --min-start-ts 0\n```\n\n----------------------------------------\n\nTITLE: GitHub Repository Configuration for Data App\nDESCRIPTION: Specifies the configuration for connecting a Data App to a GitHub repository, including repository path and deployment settings\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-get-started.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- Repository: [Your GitHub Repository]\n- Branch: [Target Branch]\n- Directory: /mydata\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for ADMIN RESUME DDL\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition showing the grammar rules for the ADMIN RESUME DDL JOBS statement and NumList component.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-resume-ddl.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAdminResumeDDLStmt ::=\n    'ADMIN' 'RESUME' 'DDL' 'JOBS' NumList \n\nNumList ::=\n    Int64Num ( ',' Int64Num )*\n```\n\n----------------------------------------\n\nTITLE: Querying Specific Table Attributes in SQL\nDESCRIPTION: Demonstrates how to view attributes configured for a specific table or partition using a SELECT statement with a WHERE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/table-attributes.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.attributes WHERE id='schema/t[/p]';\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a table named 't' with two integer columns, 'id' and 'v', and defines a key on the 'id' column. The table is used in subsequent examples to demonstrate non-transactional DML operations. The successful execution of this query will result in the \"Query OK\" output.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE TABLE t (id INT, v INT, KEY(id));\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"Query OK, 0 rows affected\"\n```\n\n----------------------------------------\n\nTITLE: Canceling Import Task in Non-Interactive Mode\nDESCRIPTION: This example shows how to cancel an import task using the TiDB Cloud CLI in non-interactive mode. It requires specifying the cluster ID and import task ID as flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-cancel.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import cancel --cluster-id <cluster-id> --import-id <import-id>\n```\n\n----------------------------------------\n\nTITLE: GitHub Issue References\nDESCRIPTION: List of GitHub pull request and issue references documenting various fixes and improvements in TiDB 2.1.10\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.10.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[#10359](https://github.com/pingcap/tidb/pull/10359)\n[#10363](https://github.com/pingcap/tidb/pull/10363)\n[#10385](https://github.com/pingcap/tidb/pull/10385)\n[#10407](https://github.com/pingcap/tidb/pull/10407)\n[#10412](https://github.com/pingcap/tidb/pull/10412)\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for TiDB Self-Managed\nDESCRIPTION: Environment variables configuration for connecting to a self-managed TiDB cluster without TLS encryption.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_6\n\nLANGUAGE: dotenv\nCODE:\n```\nDATABASE_HOST={host}\nDATABASE_PORT=4000\nDATABASE_USER={user}\nDATABASE_PASSWORD={password}\nDATABASE_NAME=test\n```\n\n----------------------------------------\n\nTITLE: RocksDB Compaction Configuration Parameters\nDESCRIPTION: Compaction-related settings including triggers, limits, and optimization parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_17\n\nLANGUAGE: yaml\nCODE:\n```\ncompaction-pri:\n  defaultcf: \"min-overlapping-ratio\"\n  writecf: \"min-overlapping-ratio\"\n  lockcf: \"by-compensated-size\"\n\ncompaction-style: \"level\"\nenable-compaction-guard: true\ncompaction-guard-min-output-file-size: \"8MiB\"\ncompaction-guard-max-output-file-size: \"128MiB\"\n```\n\n----------------------------------------\n\nTITLE: TiCDC Changefeed Configuration (Simple Protocol)\nDESCRIPTION: This snippet shows the TiCDC changefeed configuration in TOML format when using the Simple protocol.  It includes settings for the protocol, bootstrap message intervals (time and count), sending bootstrap to all partitions, and the encoding format (JSON).  These settings control how TiCDC encodes and sends data changes to the downstream Kafka broker.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-simple-protocol.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sink]\nprotocol = \"simple\"\n\n# The following configuration parameters control the sending behavior of bootstrap messages.\n# send-bootstrap-interval-in-sec controls the time interval for sending bootstrap messages, in seconds.\n# The default value is 120 seconds, which means that a bootstrap message is sent every 120 seconds for each table.\nsend-bootstrap-interval-in-sec = 120\n\n# send-bootstrap-in-msg-count controls the message interval for sending bootstrap, in message count.\n# The default value is 10000, which means that a bootstrap message is sent every 10000 row changed messages for each table.\nsend-bootstrap-in-msg-count = 10000\n# Note: If you want to disable the sending of bootstrap messages, set both send-bootstrap-interval-in-sec and send-bootstrap-in-msg-count to 0.\n\n# send-bootstrap-to-all-partition controls whether to send bootstrap messages to all partitions.\n# The default value is true, which means that bootstrap messages are sent to all partitions of the corresponding table topic.\n# Setting it to false means bootstrap messages are sent to only the first partition of the corresponding table topic.\nsend-bootstrap-to-all-partition = true\n\n[sink.kafka-config.codec-config]\n# encoding-format controls the encoding format of the Simple protocol messages. Currently, the Simple protocol message supports \"json\" and \"avro\" encoding formats.\n# The default value is \"json\".\nencoding-format = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Upstream Database for TiDB Data Migration in YAML\nDESCRIPTION: This YAML configuration template specifies settings for connecting to an upstream MySQL database in TiDB Data Migration. It includes options for GTID, relay logs, connection details, security, and binlog event filtering.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-source-configuration-file.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsource-id: \"mysql-replica-01\"\n\nenable-gtid: false\n\nenable-relay: false\nrelay-binlog-name: \"\"     \nrelay-binlog-gtid: \"\"     \n\nfrom:\n  host: \"127.0.0.1\"\n  port: 3306\n  user: \"root\"\n  password: \"ZqMLjZ2j5khNelDEfDoUhkD5aV5fIJOe0fiog9w=\" \n  security:                       \n    ssl-ca: \"/path/to/ca.pem\"\n    ssl-cert: \"/path/to/cert.pem\"\n    ssl-key: \"/path/to/key.pem\"\n\n# purge:\n#   interval: 3600\n#   expires: 0\n#   remain-space: 15\n\n# checker:\n#   check-enable: true\n#   backoff-rollback: 5m0s\n#   backoff-max: 5m0s       \n\n# case-sensitive: false\n# filters:\n# - schema-pattern: dmctl\n#   table-pattern: t_1\n#   events: []\n#   sql-pattern:\n#   - alter table .* add column `aaa` int\n#   action: Ignore\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Security Settings for TLS Connections\nDESCRIPTION: TOML configuration section for enabling TLS in TiDB's configuration file. This specifies the paths to the server certificate, server key, and CA certificate required for secure connections.\nSOURCE: https://github.com/pingcap/docs/blob/master/certificate-authentication.md#2025-04-18_snippet_9\n\nLANGUAGE: toml\nCODE:\n```\n[security]\nssl-cert =\"path/to/server-cert.pem\"\nssl-key =\"path/to/server-key.pem\"\nssl-ca=\"path/to/ca-cert.pem\"\n```\n\n----------------------------------------\n\nTITLE: Label Management Commands\nDESCRIPTION: Commands to view and manage cluster label information including displaying all labels and filtering stores by label values.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\n>> label\n>> label store zone cn\n```\n\n----------------------------------------\n\nTITLE: Traffic Replay Jobs Output Example\nDESCRIPTION: Example output showing two TiProxy instances with manually canceled traffic replay jobs. Illustrates the columns and information returned for replay jobs that have been stopped.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-traffic-jobs.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------+----------------------------+----------------+--------+----------+----------+------------------+--------------------------------------------------------------------+\n| START_TIME                 | END_TIME                   | INSTANCE       | TYPE   | PROGRESS | STATUS   | FAIL_REASON      | PARAMS                                                             |\n+----------------------------+----------------------------+----------------+--------+----------+----------+------------------+--------------------------------------------------------------------+\n| 2024-12-17 10:54:41.000000 | 2024-12-17 11:34:42.000000 | 10.1.0.10:3080 | replay | 70%      | canceled | manually stopped | INPUT=\"/tmp/traffic\", USER=\"root\", SPEED=0.000000, READ_ONLY=false |\n| 2024-12-17 10:54:41.000000 | 2024-12-17 11:34:43.000000 | 10.1.0.11:3080 | replay | 69%      | canceled | manually stopped | INPUT=\"/tmp/traffic\", USER=\"root\", SPEED=0.000000, READ_ONLY=false |\n+----------------------------+----------------------------+----------------+--------+----------+----------+------------------+--------------------------------------------------------------------+\n2 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Sync-Diff-Inspector Configuration\nDESCRIPTION: YAML configuration for sync-diff-inspector tool to validate data consistency between clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ncheck-thread-count = 4\nexport-fix-sql = true\ncheck-struct-only = false\n\n[data-sources]\n[data-sources.upstream]\n        host = \"172.16.6.123\"\n        port = 4000\n        user = \"root\"\n        password = \"\"\n        snapshot = \"431434047157698561\"\n[data-sources.downstream]\n        host = \"172.16.6.124\"\n        port = 4000\n        user = \"root\"\n        password = \"\"\n        snapshot = \"431434141450371074\"\n\n[task]\n        output-dir = \"./output\"\n        source-instances = [\"upstream\"]\n        target-instance = \"downstream\"\n        target-check-tables = [\"*.*\"]\n```\n\n----------------------------------------\n\nTITLE: Verifying TiDB Connection through ProxySQL\nDESCRIPTION: SQL query to verify the successful connection to TiDB by displaying the version information.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VERSION();\n```\n\n----------------------------------------\n\nTITLE: Enabling TiKV Auto-Tune via tikv-ctl\nDESCRIPTION: This snippet shows how to enable the auto-tune feature in TiKV using the `tikv-ctl` command. Auto-tune, introduced in TiDB v5.4.0, limits backup task resource usage when the cluster workload is heavy. Enabling auto-tune can reduce the impact of backup tasks on the online cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n\"backup.enable-auto-tune\"\n```\n\n----------------------------------------\n\nTITLE: Checking TiFlash Replica Status for Databases in TiDB\nDESCRIPTION: This SQL query retrieves the status of TiFlash replicas for all tables in a specific database. It shows availability and replication progress for each table.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = '<db_name>';\n```\n\n----------------------------------------\n\nTITLE: Setting Permissions for TiDB Temporary Directory\nDESCRIPTION: Command to grant full read, write, and execute permissions to the TiDB temporary directory. This ensures that the TiDB process can properly use the directory for DDL operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nsudo chmod -R 777 /data/tidb-deploy/tempdir\n```\n\n----------------------------------------\n\nTITLE: Case-Sensitive REGEXP BINARY Function (SQL)\nDESCRIPTION: Updates the REGEXP BINARY function to be case-sensitive, aligning with MySQL's behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.16.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT 'a' REGEXP BINARY 'A';\n```\n\n----------------------------------------\n\nTITLE: Extending GC-safepoint Retention with BR Backup Command\nDESCRIPTION: Example shell command that uses the BR tool to perform a full backup with an extended gcttl parameter (15 hours) to ensure the gc-safepoint is retained longer, preventing data from being garbage collected before a backup retry can be attempted.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-checkpoint-backup.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full \\\n--storage local:///br_data/ --pd \"${PD_IP}:2379\" \\\n--gcttl 54000\n```\n\n----------------------------------------\n\nTITLE: Markdown Navigation Structure\nDESCRIPTION: Hierarchical documentation structure using markdown formatting to organize TiDB documentation topics and subtopics\nSOURCE: https://github.com/pingcap/docs/blob/master/TOC.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- Stream Data\n  - [TiCDC Overview](/ticdc/ticdc-overview.md)\n  - [Deploy and Maintain](/ticdc/deploy-ticdc.md)\n  - Changefeed\n    - [Overview](/ticdc/ticdc-changefeed-overview.md)\n    - Create Changefeeds\n      - [Replicate Data to MySQL-compatible Databases](/ticdc/ticdc-sink-to-mysql.md)\n      - [Replicate Data to Kafka](/ticdc/ticdc-sink-to-kafka.md)\n...\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Server Using MySQL Client with Abbreviated Syntax\nDESCRIPTION: Connect to the TiDB server using the MySQL client with abbreviated command line parameters for port, username, and password.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmysql -P 4000 -u xxx -p\n```\n\n----------------------------------------\n\nTITLE: Naming Columns with NAME_CONST() in SQL\nDESCRIPTION: This function is used to name columns, though using column aliases is recommended instead. It takes a name and value as arguments.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT NAME_CONST('column name', 'value') UNION ALL SELECT 'another value';\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB as root\nDESCRIPTION: Shell command to connect to TiDB as the root user.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-role.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 127.0.0.1 -P 4000 -u root\n```\n\n----------------------------------------\n\nTITLE: Testing ProxySQL Query Rules\nDESCRIPTION: SQL commands to test different query routing scenarios in ProxySQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM test.tidb_server;\nSELECT * FROM test.tidb_server FOR UPDATE;\nBEGIN;\nINSERT INTO test.tidb_server (server_name) VALUES ('insert this and rollback later');\nSELECT * FROM test.tidb_server;\nROLLBACK;\n```\n\n----------------------------------------\n\nTITLE: Replaying Traffic at Double Speed in SQL\nDESCRIPTION: SQL example demonstrating how to use the SPEED option in TRAFFIC REPLAY syntax to replay traffic at twice the original speed.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-traffic-replay.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nTRAFFIC REPLAY FROM \"/tmp/traffic\" USER=\"u1\" PASSWORD=\"123456\" SPEED=2;\n```\n\n----------------------------------------\n\nTITLE: Defining Dispatcher Rules for Pulsar Sink in TiCDC\nDESCRIPTION: This TOML snippet demonstrates how to define dispatcher rules for the Pulsar sink in TiCDC, allowing you to customize the topic and partition to which data change events are sent.  The `dispatchers` array defines rules based on matching table names and specifying topic and partition policies.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_16\n\nLANGUAGE: toml\nCODE:\n```\n[sink]\ndispatchers = [\n  {matcher = ['test1.*', 'test2.*'], topic = \"Topic expression 1\", partition = \"ts\" },\n  {matcher = ['test3.*', 'test4.*'], topic = \"Topic expression 2\", partition = \"index-value\" },\n  {matcher = ['test1.*', 'test5.*'], topic = \"Topic expression 3\", partition = \"table\"},\n  {matcher = ['test6.*'], partition = \"default\"},\n  {matcher = ['test7.*'], partition = \"test123\"}\n]\n```\n\n----------------------------------------\n\nTITLE: DM Sharding Modes Comparison Table (Markdown)\nDESCRIPTION: Markdown table comparing key differences between pessimistic and optimistic sharding modes in DM, including DML migration behavior, DDL execution requirements, and error handling characteristics.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-shard-merge.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Pessimistic mode   | Optimistic mode   |\n| :----------- | :----------- |\n| Sharded tables that executes DDL suspend DML migration | Sharded tables that executes DDL continue DML migration |\n| The DDL execution order and statements of each sharded table must be the same | Each sharded table only needs to keep the table schema compatible with each other  |\n| The DDL is migrated to the downstream after the entire shard group is consistent | The DDL of each sharded table immediately affects the downstream |\n| Wrong DDL operations can be intercepted after the detection | Wrong DDL operations will be migrated to the downstream, which may cause inconsistency between the upstream and downstream data before the detection  |\n```\n\n----------------------------------------\n\nTITLE: Cloning the dbt demo project 'jaffle_shop'\nDESCRIPTION: Commands to clone a demo project from GitHub provided by dbt-labs for testing and learning purposes. This creates a local copy of the jaffle_shop project.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/dbt-labs/jaffle_shop && \\\ncd jaffle_shop\n```\n\n----------------------------------------\n\nTITLE: Configuring MyDumper Data Source Directory - TOML\nDESCRIPTION: This snippet configures the data source directory for MyDumper in TiDB Lightning using TOML. The 'data-source-dir' parameter specifies the local directory or URI for your data files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[mydumper]\n# Local source data directory or the URI of the external storage such as S3. For more information about the URI of the external storage, see https://docs.pingcap.com/tidb/dev/backup-and-restore-storages#uri-format.\ndata-source-dir = \"/data/my_database\"\n```\n\n----------------------------------------\n\nTITLE: DML Event Format in Canal-JSON\nDESCRIPTION: Sample of a DML Event encoded in Canal-JSON format. This shows the structure of a row data change event (INSERT) including column data types, values, and the TiDB extension field with CommitTS.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"id\": 0,\n    \"database\": \"test\",\n    \"table\": \"tp_int\",\n    \"pkNames\": [\n        \"id\"\n    ],\n    \"isDdl\": false,\n    \"type\": \"INSERT\",\n    \"es\": 1639633141221,\n    \"ts\": 1639633142960,\n    \"sql\": \"\",\n    \"sqlType\": {\n        \"c_bigint\": -5,\n        \"c_int\": 4,\n        \"c_mediumint\": 4,\n        \"c_smallint\": 5,\n        \"c_tinyint\": -6,\n        \"id\": 4\n    },\n    \"mysqlType\": {\n        \"c_bigint\": \"bigint\",\n        \"c_int\": \"int\",\n        \"c_mediumint\": \"mediumint\",\n        \"c_smallint\": \"smallint\",\n        \"c_tinyint\": \"tinyint\",\n        \"id\": \"int\"\n    },\n    \"data\": [\n        {\n            \"c_bigint\": \"9223372036854775807\",\n            \"c_int\": \"2147483647\",\n            \"c_mediumint\": \"8388607\",\n            \"c_smallint\": \"32767\",\n            \"c_tinyint\": \"127\",\n            \"id\": \"2\"\n        }\n    ],\n    \"old\": null,\n    \"_tidb\": {     // TiDB extension field\n        \"commitTs\": 429918007904436226  // A TiDB TSO timestamp\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Statement Summary Parameters in TiDB SQL\nDESCRIPTION: SQL commands to configure global TiDB statement summary parameters, including the maximum statement count, enabling/disabling the feature, refresh interval, and history size. These settings control how SQL statement statistics are collected and stored.\nSOURCE: https://github.com/pingcap/docs/blob/master/statement-summary-tables.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nset global tidb_stmt_summary_max_stmt_count = 3000;\nset global tidb_enable_stmt_summary = true;\nset global tidb_stmt_summary_refresh_interval = 1800;\nset global tidb_stmt_summary_history_size = 24;\n```\n\n----------------------------------------\n\nTITLE: DROP RESOURCE GROUP Syntax Definition in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the DROP RESOURCE GROUP statement, including optional IF EXISTS clause and resource group name specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-resource-group.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDropResourceGroupStmt ::=\n    \"DROP\" \"RESOURCE\" \"GROUP\" IfExists ResourceGroupName\n\nIfExists ::=\n    ('IF' 'EXISTS')?\n\nResourceGroupName ::=\n    Identifier\n|   \"DEFAULT\"\n```\n\n----------------------------------------\n\nTITLE: Loading MySQL Time Zone Info shell\nDESCRIPTION: This shell command loads the system time zone information into MySQL to resolve errors related to time zones during data replication. It uses `mysql_tzinfo_to_sql` to convert and import time zones into MySQL. Successful output messages indicate missing but non-essential files.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/troubleshoot-ticdc.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmysql_tzinfo_to_sql /usr/share/zoneinfo | mysql -u root mysql -p\n```\n\n----------------------------------------\n\nTITLE: Example of RENAME INDEX Statement in SQL\nDESCRIPTION: Demonstrates the use of the RENAME INDEX statement with a complete example including creation of a table, renaming an index, and displaying the table structure before and after the operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-rename-index.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL, INDEX col1 (c1));\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> SHOW CREATE TABLE t1\\G\n*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `id` int NOT NULL AUTO_INCREMENT,\n  `c1` int NOT NULL,\n  PRIMARY KEY (`id`),\n  KEY `col1` (`c1`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\n1 row in set (0.00 sec)\n\nmysql> ALTER TABLE t1 RENAME INDEX col1 TO c1;\nQuery OK, 0 rows affected (0.09 sec)\n\nmysql> SHOW CREATE TABLE t1\\G\n*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `id` int NOT NULL AUTO_INCREMENT,\n  `c1` int NOT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c1` (`c1`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating MySQL-Compatible TTL Table\nDESCRIPTION: Creates a table with TTL using comment syntax for MySQL compatibility.\nSOURCE: https://github.com/pingcap/docs/blob/master/time-to-live.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n    id int PRIMARY KEY,\n    created_at TIMESTAMP\n) /*T![ttl] TTL = `created_at` + INTERVAL 3 MONTH TTL_ENABLE = 'OFF'*/;\n```\n\n----------------------------------------\n\nTITLE: Checking Storage Space with JSON_STORAGE_FREE\nDESCRIPTION: Shows the usage of JSON_STORAGE_FREE function which returns the freed storage space after in-place updates. In TiDB, this always returns 0 for compatibility with MySQL 8.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-utility.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_STORAGE_FREE('{}');\n```\n\n----------------------------------------\n\nTITLE: Checking GBK Collations with New Framework\nDESCRIPTION: SQL queries to verify GBK character set details after enabling the new collations framework, showing gbk_chinese_ci as default collation.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-gbk.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CHARACTER SET WHERE CHARSET = 'gbk';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLLATION WHERE CHARSET = 'gbk';\n```\n\n----------------------------------------\n\nTITLE: Creating Table with UUID Primary Key - With Swap Flag\nDESCRIPTION: Alternative table creation example that demonstrates the structure when using swap_flag. This approach may lead to hotspots in TiDB and should be avoided.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/uuid.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `uuid_demo_2` (\n  `uuid` varbinary(16) NOT NULL,\n  `c1` varchar(255) NOT NULL,\n  PRIMARY KEY (`uuid`) CLUSTERED\n)\n```\n\n----------------------------------------\n\nTITLE: Updating a Replication Task Configuration with TiCDC\nDESCRIPTION: This JSON snippet is used in a PUT request to update a replication task's configuration. It includes parameters like 'replica_config', 'sink_uri', and 'target_ts'. Updating involves pausing, modifying, and resuming the task.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"replica_config\": {\n    \"bdr_mode\": true,\n    \"case_sensitive\": false,\n    \"check_gc_safe_point\": true,\n    \"consistent\": {\n      \"flush_interval\": 0,\n      \"level\": \"string\",\n      \"max_log_size\": 0,\n      \"storage\": \"string\"\n    },\n    \"enable_old_value\": true,\n    \"enable_sync_point\": true,\n    \"filter\": {\n      \"event_filters\": [\n        {\n          \"ignore_delete_value_expr\": \"string\",\n          \"ignore_event\": [\n            \"string\"\n          ],\n          \"ignore_insert_value_expr\": \"string\",\n          \"ignore_sql\": [\n            \"string\"\n          ],\n          \"ignore_update_new_value_expr\": \"string\",\n          \"ignore_update_old_value_expr\": \"string\",\n          \"matcher\": [\n            \"string\"\n          ]\n        }\n      ],\n      \"ignore_txn_start_ts\": [\n        0\n      ],\n      \"rules\": [\n        \"string\"\n      ]\n    },\n    \"force_replicate\": true,\n    \"ignore_ineligible_table\": true,\n    \"memory_quota\": 0,\n    \"mounter\": {\n      \"worker_num\": 0\n    },\n    \"sink\": {\n      \"column_selectors\": [\n        {\n          \"columns\": [\n            \"string\"\n          ],\n          \"matcher\": [\n            \"string\"\n          ]\n        }\n      ],\n      \"csv\": {\n        \"delimiter\": \"string\",\n        \"include_commit_ts\": true,\n        \"null\": \"string\",\n        \"quote\": \"string\"\n      },\n      \"date_separator\": \"string\",\n      \"dispatchers\": [\n        {\n          \"matcher\": [\n            \"string\"\n          ],\n          \"partition\": \"string\",\n          \"topic\": \"string\"\n        }\n      ],\n      \"enable_partition_separator\": true,\n      \"encoder_concurrency\": 0,\n      \"protocol\": \"string\",\n      \"schema_registry\": \"string\",\n      \"terminator\": \"string\",\n      \"transaction_atomicity\": \"string\"\n    },\n    \"sync_point_interval\": \"string\",\n    \"sync_point_retention\": \"string\"\n  },\n  \"sink_uri\": \"string\",\n  \"target_ts\": 0\n}\n```\n\n----------------------------------------\n\nTITLE: Performing TiDB Incremental Backup with BR\nDESCRIPTION: This command performs an incremental backup of TiDB data between the last backup timestamp and the current time. It includes rate limiting and specifies an S3 storage location for the backup data.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-incremental-guide.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd \"${PD_IP}:2379\" \\\n--storage \"s3://backup-101/snapshot-202209081330/incr?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n--lastbackupts ${LAST_BACKUP_TS} \\\n--ratelimit 128\n```\n\n----------------------------------------\n\nTITLE: Listing Components with Verbose Output\nDESCRIPTION: Command to display detailed component information, including installed versions and comprehensive component descriptions. Useful for getting an in-depth view of available TiUP components.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-list.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup list --verbose\n```\n\n----------------------------------------\n\nTITLE: Configuring MySQL Data Source\nDESCRIPTION: YAML configuration for a MySQL data source in DM, including connection details and GTID settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-task.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nsource-id: \"mysql-replica-01\"\n\nenable-gtid: true\n\nfrom:\n  host: \"127.0.0.1\"\n  user: \"root\"\n  password: \"fCxfQ9XKCezSzuCD0Wf5dUD+LsKegSg=\"\n  port: 3306\n```\n\n----------------------------------------\n\nTITLE: Defining Prisma Schema with User Model\nDESCRIPTION: Create a schema.prisma file with a user model definition for database table representation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-prisma-example.md#2025-04-18_snippet_3\n\nLANGUAGE: prisma\nCODE:\n```\n// schema.prisma\ngenerator client {\n  provider        = \"prisma-client-js\"\n  previewFeatures = [\"driverAdapters\"]\n}\n\ndatasource db {\n  provider     = \"mysql\"\n  url          = env(\"DATABASE_URL\")\n} \n\n// define a data model according to your database table\nmodel user {\n  id    Int     @id @default(autoincrement())\n  email String? @unique(map: \"uniq_email\") @db.VarChar(255)\n  name  String? @db.VarChar(255)\n}\n```\n\n----------------------------------------\n\nTITLE: Explaining Query Execution with Late Materialization in SQL\nDESCRIPTION: An example showing how to use the EXPLAIN statement to view the execution plan that demonstrates filter conditions pushed down to the TableScan operator in TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-late-materialization.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT a, b, c FROM t1 WHERE a < 1;\n```\n\n----------------------------------------\n\nTITLE: Running Terraform Apply Command to Pause Cluster\nDESCRIPTION: This command is used to apply the Terraform configuration changes made to pause a cluster. It details the output received from executing 'terraform apply', showing the planned update actions and the prompt for user confirmation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform apply\n\ntidbcloud_cluster.example_cluster: Refreshing state... [id=1379661944630234067]\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  ~ update in-place\n\nTerraform will perform the following actions:\n\n  # tidbcloud_cluster.example_cluster will be updated in-place\n  ~ resource \"tidbcloud_cluster\" \"example_cluster\" {\n      ~ config         = {\n          + paused         = true\n            # (4 unchanged attributes hidden)\n        }\n      id             = \"1379661944630234067\"\n      name           = \"firstCluster\"\n      ~ status         = \"AVAILABLE\" -> (known after apply)\n      # (4 unchanged attributes hidden)\n  }\n\nPlan: 0 to add, 1 to change, 0 to destroy.\n\nDo you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only 'yes' will be accepted to approve.\n\n  Enter a value: yes\n\ntidbcloud_cluster.example_cluster: Modifying... [id=1379661944630234067]\ntidbcloud_cluster.example_cluster: Modifications complete after 2s [id=1379661944630234067]\n\nApply complete! Resources: 0 added, 1 changed, 0 destroyed.\n```\n\n----------------------------------------\n\nTITLE: Restarting ProxySQL Service\nDESCRIPTION: This command restarts the ProxySQL service to apply configuration changes made in the configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\nsystemctl restart proxysql\n```\n\n----------------------------------------\n\nTITLE: Creating Table with BLOB Default Value Using RAND()\nDESCRIPTION: Example showing how to create a table with a BLOB column that uses the RAND() function as its default value.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-default-values.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t2 (\n  b BLOB DEFAULT (RAND())\n);\n```\n\n----------------------------------------\n\nTITLE: Removing a watch list item by ID\nDESCRIPTION: This SQL statement removes a watch item from the runaway query watch list based on its ID. In this example, the watch item with ID `1` is removed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n\"QUERY WATCH REMOVE 1;\"\n```\n\n----------------------------------------\n\nTITLE: Editing the scale-out topology file\nDESCRIPTION: This command opens the `scale-out.yml` file in a text editor (vi) to configure the new TSO and Scheduling nodes to be added to the cluster. The file specifies parameters such as host IP and port.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n\"vi scale-out.yml\"\n```\n\n----------------------------------------\n\nTITLE: Starting TiDB Cluster with Tag\nDESCRIPTION: Starts a TiDB cluster with data persistence using a tag parameter\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground --tag ${tag_name}\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable for TiDB Cloud Serverless Driver Connection in Vercel\nDESCRIPTION: This environment variable is automatically added to your Vercel project when using the TiDB Cloud Vercel integration with TiDB Cloud Serverless Driver.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-vercel.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nDATABASE_URL\n```\n\n----------------------------------------\n\nTITLE: Querying Results for Specific Rule from INSPECTION_RESULT in SQL\nDESCRIPTION: SQL query to select diagnostic results only for the 'critical-error' rule from the inspection_result table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-result.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nselect * from information_schema.inspection_result where rule='critical-error';\n```\n\n----------------------------------------\n\nTITLE: IMPORT INTO Options Configuration\nDESCRIPTION: Comprehensive list of configuration options for the IMPORT INTO statement, including character sets, field separators, and performance settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCHARACTER_SET='<string>'\nFIELDS_TERMINATED_BY='<string>'\nFIELDS_ENCLOSED_BY='<char>'\nFIELDS_ESCAPED_BY='<char>'\nFIELDS_DEFINED_NULL_BY='<string>'\nLINES_TERMINATED_BY='<string>'\nSKIP_ROWS=<number>\nSPLIT_FILE\nDISK_QUOTA='<string>'\nDISABLE_TIKV_IMPORT_MODE\nTHREAD=<number>\nMAX_WRITE_SPEED='<string>'\nCHECKSUM_TABLE='<string>'\nDETACHED\nCLOUD_STORAGE_URI\nDISABLE_PRECHECK\n```\n\n----------------------------------------\n\nTITLE: Comparing Read Link Metrics Between Time Periods\nDESCRIPTION: SQL query that compares monitoring metrics for read links between two different time periods, calculating the ratio of average values and joining the results\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-summary.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n  t1.avg_value / t2.avg_value AS ratio,\n  t1.*,\n  t2.*\nFROM\n  (\n    SELECT\n      /*+ time_range(\"2020-01-16 16:00:54.933\", \"2020-01-16 16:10:54.933\")*/ *\n    FROM information_schema.inspection_summary WHERE rule='read-link'\n  ) t1\n  JOIN\n  (\n    SELECT\n      /*+ time_range(\"2020-01-16 16:10:54.933\", \"2020-01-16 16:20:54.933\")*/ *\n    FROM information_schema.inspection_summary WHERE rule='read-link'\n  ) t2\n  ON t1.metrics_name = t2.metrics_name\n  and t1.instance = t2.instance\n  and t1.label = t2.label\nORDER BY\n  ratio DESC;\n```\n\n----------------------------------------\n\nTITLE: Configuring Binlog Event Filters for Data Migration - YAML\nDESCRIPTION: This snippet shows how to add a filter configuration to the task file in DM to ignore specific binlog events based on schema and table patterns, events, and SQL patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/filter-binlog-event.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nfilters:\n  rule-1:\n    schema-pattern: \"test_*\"\n    table-pattern: \"t_*\"\n    events: [\"truncate table\", \"drop table\"]\n    sql-pattern: [\"^DROP\\\\s+PROCEDURE\", \"^CREATE\\\\s+PROCEDURE\"]\n    action: Ignore\n```\n\n----------------------------------------\n\nTITLE: Disabling System Swap for TiDB Performance\nDESCRIPTION: Commands to disable system swap by setting vm.swappiness to 0 and turning off swap partitions. This helps maintain stable performance by preventing memory used by TiDB from being swapped to disk.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\necho \"vm.swappiness = 0\">> /etc/sysctl.conf\nsysctl -p\nswapoff -a && swapon -a\n```\n\n----------------------------------------\n\nTITLE: Patching All TiDB Nodes with Hotfix\nDESCRIPTION: Example command to patch all TiDB nodes in a cluster with a hotfix package. The -R flag specifies patching only the 'tidb' role components.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster patch test-cluster /tmp/tidb-hotfix.tar.gz -R tidb\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed with TiDB Extension Enabled\nDESCRIPTION: This command creates a TiCDC changefeed with TiDB extension enabled for Avro protocol. When enable-tidb-extension is set to true, TiCDC adds three fields: _tidb_op, _tidb_commit_ts, and _tidb_commit_physical_time, to the Avro messages during message generation.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-protocol.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://127.0.0.1:8300 --changefeed-id=\"kafka-avro-enable-extension\" --sink-uri=\"kafka://127.0.0.1:9092/topic-name?protocol=avro&enable-tidb-extension=true\" --schema-registry=http://127.0.0.1:8081 --config changefeed_config.toml\n```\n\n----------------------------------------\n\nTITLE: Configuring AWS Credentials\nDESCRIPTION: Optional command to configure AWS access credentials if not already set up.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-aws-appflow-integration.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\naws configure\n```\n\n----------------------------------------\n\nTITLE: Removing a Replication Task via TiCDC Shell Command\nDESCRIPTION: This shell command sends a DELETE request to remove a specified replication task using the task's ID. This command is idempotent, meaning it can be safely repeated. A successful execution returns a 200 OK response.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X DELETE http://127.0.0.1:8300/api/v2/changefeeds/test1\n```\n\n----------------------------------------\n\nTITLE: Generating Autocompletion Script for TiDB Cloud CLI\nDESCRIPTION: This snippet illustrates how to generate the autocompletion script for the TiDB Cloud CLI by specifying a command. The command takes a single argument representing the shell type (e.g., bash or zsh) for which the script is being generated. It is part of the TiDB Cloud CLI functionality which enhances user experience by providing command completion features.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-completion.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud completion [command]\n```\n\n----------------------------------------\n\nTITLE: Window Function without ORDER BY Example\nDESCRIPTION: Example demonstrating optimization of window function without ORDER BY clause, showing how Limit operator is derived.\nSOURCE: https://github.com/pingcap/docs/blob/master/derive-topn-from-window.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id int, value int);\nSET tidb_opt_derive_topn=on;\nEXPLAIN SELECT * FROM (SELECT ROW_NUMBER() OVER () AS rownumber FROM t) dt WHERE rownumber <= 3;\n```\n\n----------------------------------------\n\nTITLE: Setting Initial Chunk Size in TiDB SQL Execution Engine\nDESCRIPTION: Adds a variable to control the size of the initial Chunk used by the execution engine for query processing.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0-beta.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_init_chunk_size = 32;\n```\n\n----------------------------------------\n\nTITLE: HTTP API Endpoint Example\nDESCRIPTION: Example of TiDB HTTP API endpoint for accessing MVCC key information\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.2.md#2025-04-18_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nhttp://{TiDB_ADDRESS:TIDB_IP}/mvcc/key/{db}/{table}/{handle}\n```\n\n----------------------------------------\n\nTITLE: Embedding and Storing Document Vectors in TiDB\nDESCRIPTION: Creates a vector store in TiDB by generating embeddings for document chunks using OpenAI's embedding model, and stores them in a table optimized for vector search with specified distance strategy.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nembeddings = OpenAIEmbeddings()\nvector_store = TiDBVectorStore.from_documents(\n    documents=docs,\n    embedding=embeddings,\n    table_name=\"embedded_documents\",\n    connection_string=tidb_connection_string,\n    distance_strategy=\"cosine\",  # default, another option is \"l2\"\n)\n```\n\n----------------------------------------\n\nTITLE: Importing TiDB Ansible Cluster from Current Directory\nDESCRIPTION: Example command to import a TiDB cluster from the current directory which contains TiDB-Ansible files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\ncd tidb-ansible\ntiup cluster import\n```\n\n----------------------------------------\n\nTITLE: TiFlash Compression Level Configuration Parameter (New)\nDESCRIPTION: New TiFlash parameter that specifies the compression level. The default value is 1.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_17\n\nLANGUAGE: toml\nCODE:\n```\nprofiles.default.dt_compression_level\n```\n\n----------------------------------------\n\nTITLE: Starting DM Validation via Command Line\nDESCRIPTION: Example shell command for starting continuous validation using dmctl, specifying start time and validation mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-continuous-data-validation.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndmctl --master-addr=127.0.0.1:8261 validation start --start-time 2021-10-21T00:01:00 --mode full my_dm_task\n```\n\n----------------------------------------\n\nTITLE: Restarting TiCDC Cluster using TiUP\nDESCRIPTION: This code snippet showcases how to restart the TiCDC cluster using TiUP. This is a necessary step when a replication task gets stuck due to compatibility issues. Restarting the cluster can resolve the stuck state and allow for a clean re-creation of the changefeed.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-compatibility.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n\"tiup cluster restart <cluster_name> -R cdc\"\n```\n\n----------------------------------------\n\nTITLE: Checking TiCDC Changefeed Status\nDESCRIPTION: Command to list and check the status of TiCDC changefeeds after creation to verify successful configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc:v<CLUSTER_VERSION> cli changefeed list --server=\"http://127.0.0.1:8300\"\n```\n\n----------------------------------------\n\nTITLE: Example Query for RawSQL Test (SQL)\nDESCRIPTION: This SQL query is an example of a query that can be used for a RawSQL test.  It selects the `a` column from the `t` table, calls the `sleep(rand())` function, and filters the results based on a condition involving `rand()`. This particular query simulates a workload.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\n-- Save your query in a SQL file. For example, you can save the following query in `demo.sql`.\nSELECT a, sleep(rand()) FROM t WHERE a < 4*rand();\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Servers in YAML\nDESCRIPTION: This YAML snippet provides configuration for TiDB servers, defining host settings, service ports, and the instance configuration to be merged with the global `tidb` configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n\"tidb_servers:\\n  - host: 10.0.1.14\\n    config:\\n      log.level: warn\\n      log.slow-query-file: tidb-slow-overwrited.log\\n  - host: 10.0.1.15\"\n```\n\n----------------------------------------\n\nTITLE: Starting a Non-Interactive Local Import Task in TiDB Cloud CLI\nDESCRIPTION: Example of starting a local data import task in non-interactive mode. This command requires specifying all necessary parameters including file path, cluster ID, file type, target database, and target table.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-start.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import start --local.file-path <file-path> --cluster-id <cluster-id> --file-type <file-type> --local.target-database <target-database> --local.target-table <target-table>\n```\n\n----------------------------------------\n\nTITLE: Configuring Alertmanager Listening Address in TiUP\nDESCRIPTION: This YAML example outlines how to set the 'listen_host' for Alertmanager in the topology.yaml file. By doing so, it configures the listening address for Alertmanager, addressing access issues when using proxies. The recommended setting is '0.0.0.0'.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/customized-montior-in-tiup-environment.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nalertmanager_servers:\n  - host: 172.16.7.147\n    listen_host: 0.0.0.0\n    ssh_port: 22\n```\n\n----------------------------------------\n\nTITLE: Querying PROCESSLIST Contents\nDESCRIPTION: Demonstrates how to query the contents of the PROCESSLIST table with detailed column output format.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-processlist.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.processlist\\G\n```\n\n----------------------------------------\n\nTITLE: Constants for Key-Value Mapping\nDESCRIPTION: This code snippet defines the string constants used in TiDB's key-value encoding scheme, including `tablePrefix`, `recordPrefixSep`, and `indexPrefixSep`.  These constants are used to distinguish different types of data in the Key space. These are byte arrays.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-computing.md#2025-04-18_snippet_3\n\nLANGUAGE: go\nCODE:\n```\n\"tablePrefix     = []byte{'t'}\\nrecordPrefixSep = []byte{'r'}\\nindexPrefixSep  = []byte{'i'}\"\n```\n\n----------------------------------------\n\nTITLE: Specifying Global Replica Count in TiDB\nDESCRIPTION: Demonstrates how to increase the number of replicas globally for a cluster by creating a placement policy and applying it at the cluster level using ALTER RANGE.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY five_replicas FOLLOWERS=4;\nALTER RANGE global PLACEMENT POLICY five_replicas;\n```\n\n----------------------------------------\n\nTITLE: Node Memory Usage Alert Rule\nDESCRIPTION: PromQL query to monitor memory usage, alerting when memory utilization exceeds 80%\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_20\n\nLANGUAGE: promql\nCODE:\n```\n(((node_memory_MemTotal_bytes-node_memory_MemFree_bytes-node_memory_Cached_bytes)/(node_memory_MemTotal_bytes)*100)) >= 80\n```\n\n----------------------------------------\n\nTITLE: Listing Table Schema with binlog-schema\nDESCRIPTION: Example of using the binlog-schema list command to retrieve the schema for a specific table in a migration task.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-manage-schema.md#2025-04-18_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\nbinlog-schema list -s mysql-replica-01 task_single db_single t1\n```\n\n----------------------------------------\n\nTITLE: SQL Generation Job Status Response in JavaScript\nDESCRIPTION: Example response from the /v2/jobs/{job_id} endpoint when checking a SQL generation job. It includes the generated SQL, execution results, chart options, and other details about the completed data retrieval task.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"code\": 200,\n  \"msg\": \"\",\n  \"result\": {\n    \"ended_at\": 1718785006, // A UNIX timestamp indicating when the job is finished\n    \"job_id\": \"20f7577088154d7889964f1a5b12cb26\",\n    \"reason\": \"\", // The reason for the job failure if the job fails\n    \"result\": {\n      \"assumptions\": [],\n      \"chart_options\": { // The generated chart options for the result\n        \"chart_name\": \"Table\",\n        \"option\": {\n          \"columns\": [\n            \"total_users\"\n          ]\n        },\n        \"title\": \"Total Number of Users in the Database\"\n      },\n      \"clarified_task\": \"Count the total number of users in the database.\", // The clarified description of the task\n      \"data\": { // The data returned by the SQL statement\n        \"columns\": [\n          {\n            \"col\": \"total_users\"\n          }\n        ],\n        \"rows\": [\n          [\n            \"1\"\n          ]\n        ]\n      },\n      \"description\": \"\",\n      \"sql\": \"SELECT COUNT(`user_id`) AS total_users FROM `users`;\", // The generated SQL statement\n      \"sql_error\": null, // The error message of the SQL statement\n      \"status\": \"done\", // The status of the job\n      \"task_id\": \"0\",\n      \"type\": \"data_retrieval\" // The type of the job\n    },\n    \"status\": \"done\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Specific Data Files Using Wildcards\nDESCRIPTION: This SQL statement imports specific CSV files into a TiDB table using wildcards with character sets. The character set `[13]` is used to specify the files `file-01.csv` and `file-03.csv` for import.  Only those files matching the pattern will be imported.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t FROM '/path/to/file-0[13].csv';\n```\n\n----------------------------------------\n\nTITLE: Backing Up Query Bindings in TiDB\nDESCRIPTION: This SQL query retrieves all enabled query bindings from the mysql.bind_info table, formatting them as CREATE GLOBAL BINDING statements for backup purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DISTINCT(CONCAT('CREATE GLOBAL BINDING FOR ', original_sql,' USING ', bind_sql,';')) FROM mysql.bind_info WHERE status='enabled';\n```\n\n----------------------------------------\n\nTITLE: Locking Table Statistics and Using SHOW STATS_LOCKED in SQL\nDESCRIPTION: This snippet illustrates the usage of the LOCK STATS statement followed by SHOW STATS_LOCKED in TiDB's SQL. It locks the statistics of a table and confirms their locked status. This feature is unique to TiDB's extension of MySQL syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-locked.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nmysql> LOCK STATS t;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SHOW STATS_LOCKED;\n+---------+------------+----------------+--------+\n| Db_name | Table_name | Partition_name | Status |\n+---------+------------+----------------+--------+\n| test    | t          |                | locked |\n+---------+------------+----------------+--------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Query Analysis Before Thread Configuration\nDESCRIPTION: Shows the execution plan and performance metrics of a GROUP BY query before increasing thread concurrency. Default configuration shows 24 total threads (8 threads × 3 instances).\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain analyze select a, count(*) from t group by a;\n```\n\n----------------------------------------\n\nTITLE: Describing Query Execution Plan in TiDB SQL\nDESCRIPTION: This SQL command shows the execution plan for a COUNT query, demonstrating how to check if TiFlash is being used.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tidb-to-read-tiflash.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\ndesc select count(*) from test.t;\n```\n\n----------------------------------------\n\nTITLE: Enabling tidb_opt_prefix_index_single_scan in TiDB\nDESCRIPTION: This SQL command enables the tidb_opt_prefix_index_single_scan optimization feature in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_66\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_opt_prefix_index_single_scan = 'ON';\n```\n\n----------------------------------------\n\nTITLE: Decompressing Data with UNCOMPRESS in TiDB SQL\nDESCRIPTION: The UNCOMPRESS() function decompresses data that was previously compressed with the COMPRESS() function. It takes compressed data as input and returns the original uncompressed data.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT UNCOMPRESS(0x03000000789C72747206040000FFFF018D00C7);\n```\n\n----------------------------------------\n\nTITLE: DEADLOCKS Table Structure Output in TiDB\nDESCRIPTION: This SQL output shows the structure of the DEADLOCKS table, including column names, data types, and other metadata. It provides details on the information stored for each deadlock event.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-deadlocks.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------+---------------------+------+------+---------+-------+\n| Field                   | Type                | Null | Key  | Default | Extra |\n+-------------------------+---------------------+------+------+---------+-------+\n| DEADLOCK_ID             | bigint(21)          | NO   |      | NULL    |       |\n| OCCUR_TIME              | timestamp(6)        | YES  |      | NULL    |       |\n| RETRYABLE               | tinyint(1)          | NO   |      | NULL    |       |\n| TRY_LOCK_TRX_ID         | bigint(21) unsigned | NO   |      | NULL    |       |\n| CURRENT_SQL_DIGEST      | varchar(64)         | YES  |      | NULL    |       |\n| CURRENT_SQL_DIGEST_TEXT | text                | YES  |      | NULL    |       |\n| KEY                     | text                | YES  |      | NULL    |       |\n| KEY_INFO                | text                | YES  |      | NULL    |       |\n| TRX_HOLDING_LOCK        | bigint(21) unsigned | NO   |      | NULL    |       |\n+-------------------------+---------------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Editing User Profile Configuration - Markdown\nDESCRIPTION: This snippet describes how to open the configuration file for editing user profile settings. This command allows users to directly interact and modify their settings within the TiDB Cloud CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/cli-reference.md#2025-04-18_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\nUse [`ticloud config edit`](/tidb-cloud/ticloud-config-edit.md) to open the configuration file for editing.\n```\n\n----------------------------------------\n\nTITLE: Comparing EXPLAIN Results with Additional Predicates in TiDB\nDESCRIPTION: This snippet demonstrates how predicates from both the view definition and the query are pushed down to the base table. It compares querying the view with an additional filter on bike_number to querying the table directly with the same condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-views.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM long_trips WHERE bike_number = 'W00950';\nEXPLAIN SELECT * FROM trips WHERE bike_number = 'W00950';\n```\n\n----------------------------------------\n\nTITLE: SQL Query Bug Fix Examples\nDESCRIPTION: Examples of SQL operations and functions that were fixed including window functions, GREATEST/LEAST operations, JOIN operations, and type casting issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.5.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nconcat(ifnull(time(3)))\n```\n\nLANGUAGE: sql\nCODE:\n```\ncast(integer as char) union string\n```\n\nLANGUAGE: sql\nCODE:\n```\nINL_HASH_JOIN ... LIMIT\n```\n\nLANGUAGE: sql\nCODE:\n```\nANY_VALUE\n```\n\nLANGUAGE: sql\nCODE:\n```\nKILL TIDB\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER SEQUENCE\n```\n\nLANGUAGE: sql\nCODE:\n```\navg()\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLUMNS\n```\n\nLANGUAGE: sql\nCODE:\n```\nlock tables\n```\n\nLANGUAGE: sql\nCODE:\n```\nunlock tables\n```\n\n----------------------------------------\n\nTITLE: Creating Books Table with Multiple Data Types\nDESCRIPTION: Complex table creation example with various data types including bigint, varchar, enum, datetime, int, and decimal fields for a bookshop database.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `bookshop`.`books` (\n  `id` bigint NOT NULL,\n  `title` varchar(100),\n  `type` enum('Magazine', 'Novel', 'Life', 'Arts', 'Comics', 'Education & Reference', 'Humanities & Social Sciences', 'Science & Technology', 'Kids', 'Sports'),\n  `published_at` datetime,\n  `stock` int,\n  `price` decimal(15,2)\n);\n```\n\n----------------------------------------\n\nTITLE: Task List Response Structure\nDESCRIPTION: This JSON structure represents the response when listing all replication tasks. It includes the complete configuration details of each task in the DM cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_37\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"total\": 2,\n  \"data\": [\n    {\n      \"name\": \"task-1\",\n      \"task_mode\": \"all\",\n      \"shard_mode\": \"pessimistic\",\n      \"meta_schema\": \"dm-meta\",\n      \"enhance_online_schema_change\": true,\n      \"on_duplicate\": \"overwrite\",\n      \"target_config\": {\n        \"host\": \"127.0.0.1\",\n        \"port\": 3306,\n        \"user\": \"root\",\n        \"password\": \"123456\",\n        \"security\": {\n          \"ssl_ca_content\": \"\",\n          \"ssl_cert_content\": \"\",\n          \"ssl_key_content\": \"\",\n          \"cert_allowed_cn\": [\n            \"string\"\n          ]\n        }\n      },\n      \"binlog_filter_rule\": {\n        \"rule-1\": {\n          \"ignore_event\": [\n            \"all dml\"\n          ],\n          \"ignore_sql\": [\n            \"^Drop\"\n          ]\n        },\n        \"rule-2\": {\n          \"ignore_event\": [\n            \"all dml\"\n          ],\n          \"ignore_sql\": [\n            \"^Drop\"\n          ]\n        },\n        \"rule-3\": {\n          \"ignore_event\": [\n            \"all dml\"\n          ],\n          \"ignore_sql\": [\n            \"^Drop\"\n          ]\n        }\n      },\n      \"table_migrate_rule\": [\n        {\n          \"source\": {\n            \"source_name\": \"source-name\",\n            \"schema\": \"db-*\",\n            \"table\": \"tb-*\"\n          },\n          \"target\": {\n            \"schema\": \"db1\",\n            \"table\": \"tb1\"\n          },\n          \"binlog_filter_rule\": [\n            \"rule-1\",\n            \"rule-2\",\n            \"rule-3\",\n          ]\n        }\n      ],\n      \"source_config\": {\n        \"full_migrate_conf\": {\n          \"export_threads\": 4,\n          \"import_threads\": 16,\n          \"data_dir\": \"./exported_data\",\n          \"consistency\": \"auto\",\n          \"import_mode\": \"physical\",\n          \"sorting_dir\": \"./sort_dir\",\n          \"disk_quota\": \"80G\",\n          \"checksum\": \"required\",\n          \"analyze\": \"optional\",\n          \"range_concurrency\": 0,\n          \"compress-kv-pairs\": \"\",\n          \"pd_addr\": \"\",\n          \"on_duplicate_logical\": \"error\",\n          \"on_duplicate_physical\": \"none\"\n        },\n        \"incr_migrate_conf\": {\n          \"repl_threads\": 16,\n          \"repl_batch\": 100\n        },\n        \"source_conf\": [\n          {\n            \"source_name\": \"mysql-replica-01\",\n            \"binlog_name\": \"binlog.000001\",\n            \"binlog_pos\": 4,\n            \"binlog_gtid\": \"03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170\"\n          }\n        ]\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Using ALGORITHM Assertion with ALTER TABLE in TiDB\nDESCRIPTION: SQL statements demonstrating how to use the ALGORITHM option to assert the type of algorithm TiDB should use for an ALTER TABLE operation. This example shows dropping an index with ALGORITHM=INSTANT.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t1 DROP INDEX c1, ALGORITHM=INSTANT;\n```\n\n----------------------------------------\n\nTITLE: Describing DDL_JOBS Table Schema in TiDB\nDESCRIPTION: Shows the structure of the DDL_JOBS table with all columns and their data types using the DESC command.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-ddl-jobs.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC ddl_jobs;\n```\n\n----------------------------------------\n\nTITLE: DROP INDEX Syntax in EBNF Format for TiDB\nDESCRIPTION: The EBNF syntax diagram for the DROP INDEX statement in TiDB. It shows the statement structure including optional IF EXISTS clause and index lock and algorithm options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-index.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDropIndexStmt ::=\n    \"DROP\" \"INDEX\" IfExists Identifier \"ON\" TableName IndexLockAndAlgorithmOpt\n\nIfExists ::=\n    ( 'IF' 'EXISTS' )?\n\nIndexLockAndAlgorithmOpt ::=\n    ( LockClause AlgorithmClause? | AlgorithmClause LockClause? )?\n```\n\n----------------------------------------\n\nTITLE: Scaling-in Unrecoverable TiDB Nodes using TiUP\nDESCRIPTION: This bash command uses TiUP to remove unrecoverable nodes from the TiDB cluster. It requires the cluster name and the specific host(s) to be removed. The `--force` flag bypasses safety checks, use with caution.\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster scale-in <cluster-name> -N <host> --force\n```\n\n----------------------------------------\n\nTITLE: Creating Ghost Table in MySQL with gh-ost\nDESCRIPTION: SQL statement to create a ghost (_gho) table as a copy of the original table. DM cleans up related metadata when encountering this operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCreate /* gh-ost */ table `test`.`_test4_gho` like `test`.`test4` ;\n```\n\n----------------------------------------\n\nTITLE: JSON Watermark Event Key Format\nDESCRIPTION: This JSON snippet shows the key format used for WATERMARK events in TiCDC messages. It contains an empty payload and a schema with specific fields such as `fields`, `optional`, `name`, and `type`. The schema name follows the format `\"{cluster-name}.watermark.Key\"`.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-debezium.md#2025-04-18_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"payload\": {},\n    \"schema\": {\n        \"fields\": [],\n        \"optional\": false,\n        \"name\": \"test_cluster.watermark.Key\",\n        \"type\": \"struct\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Python Project and Installing Dependencies\nDESCRIPTION: Sets up a new Python project directory and installs required packages including SQLAlchemy, PyMySQL, sentence-transformers, and tidb-vector.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-python.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nmkdir python-client-quickstart\ncd python-client-quickstart\ntouch example.py\n\npip install sqlalchemy pymysql sentence-transformers tidb-vector python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Displaying Region Information for a Table in TiDB\nDESCRIPTION: This snippet shows how to use the SHOW TABLE REGIONS statement to get information about the different regions a table is split into. This is useful for understanding data distribution and performance characteristics in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-aggregation.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLE t1 REGIONS;\n```\n\n----------------------------------------\n\nTITLE: Adjusting Log Level - Shell\nDESCRIPTION: Example of how to dynamically adjust the log level using POST /api/v2/log. Supports various log levels provided by zap.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST -H \"'Content-type':'application/json'\" http://127.0.0.1:8300/api/v2/log -d '{\"log_level\":\"debug\"}'\n```\n\n----------------------------------------\n\nTITLE: Using wait-for-tidbcloud-branch GitHub Action\nDESCRIPTION: This snippet illustrates how to use the `wait-for-tidbcloud-branch` GitHub Action to wait for a TiDB Cloud Serverless branch to be ready and retrieve its connection information.  The action requires `GITHUB_TOKEN`, `TIDB_CLOUD_API_PUBLIC_KEY`, and `TIDB_CLOUD_API_PRIVATE_KEY` secrets to authenticate and interact with the TiDB Cloud API. The connection information includes the host, user, and password, which are available as outputs.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/branch-github-integration.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n\"steps:\\n  - name: Wait for TiDB Cloud Serverless branch to be ready\\n    uses: tidbcloud/wait-for-tidbcloud-branch@v0\\n    id: wait-for-branch\\n    with:\\n      token: ${{ secrets.GITHUB_TOKEN }}\\n      public-key: ${{ secrets.TIDB_CLOUD_API_PUBLIC_KEY }}\\n      private-key: ${{ secrets.TIDB_CLOUD_API_PRIVATE_KEY }}\\n\\n  - name: Test with TiDB Cloud Serverless branch\\n    run: |\\n      echo \\\"The host is ${{ steps.wait-for-branch.outputs.host }}\\\"\\n      echo \\\"The user is ${{ steps.wait-for-branch.outputs.user }}\\\"\\n      echo \\\"The password is ${{ steps.wait-for-branch.outputs.password }}\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Using Pattern Matching for AWS Aurora Parquet Files in TiDB Lightning\nDESCRIPTION: Configuration example showing regular expression pattern matching for AWS Aurora parquet files. This helps TiDB Lightning parse and identify schema, table names, and file types from the file path structure.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n'(?i)^(?:[^/]*/)*([a-z0-9_]+)\\.([a-z0-9_]+)/(?:[^/]*/)*(?:[a-z0-9\\-_.]+\\.(parquet))$'\n```\n\n----------------------------------------\n\nTITLE: Inserting Data Example in TiDB\nDESCRIPTION: SQL statement to insert sample data into table t1.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-checksum-table.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t1 VALUES (1),(2),(3);\n```\n\n----------------------------------------\n\nTITLE: Using gh-ost to add a column to a table\nDESCRIPTION: Complete gh-ost command to add a new column named 'age' to the 'test.person' table. Includes connection parameters, replication settings, and execution options.\nSOURCE: https://github.com/pingcap/docs/blob/master/styles/config/vocabularies/PingCAP/accept.txt#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngh-ost \\\n  --user=\"root\" \\\n  --password=\"123456\" \\\n  --host=\"127.0.0.1\" \\\n  --port=4000 \\\n  --database=\"test\" \\\n  --table=\"person\" \\\n  --alter=\"add column age int\" \\\n  --allow-on-master \\\n  --assume-rbr \\\n  --approve-renamed-columns \\\n  --execute\n```\n\n----------------------------------------\n\nTITLE: Flashback Table/Database Commands\nDESCRIPTION: SQL commands for recovering dropped tables and databases in TiDB Cloud Serverless\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-faqs.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nFLASHBACK TABLE\nFLASHBACK DATABASE\n```\n\n----------------------------------------\n\nTITLE: Creating a user profile in TiDB Cloud CLI\nDESCRIPTION: This snippet illustrates the command to create a user profile using the TiDB Cloud CLI with your TiDB Cloud API key.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nticloud config create\n```\n\n----------------------------------------\n\nTITLE: Stopping Firewall Service for TiDB Deployment\nDESCRIPTION: Command to stop the firewalld service on the target machine. This is recommended for TiDB deployments in secure networks to ensure unimpeded communication between nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl stop firewalld.service\n```\n\n----------------------------------------\n\nTITLE: Configuring Max Allowed Packet Size in TiDB\nDESCRIPTION: SQL command to set the global max_allowed_packet variable to 128MB (134217728 bytes) in TiDB server for handling large data packets.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-error-handling.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nset @@global.max_allowed_packet=134217728\n```\n\n----------------------------------------\n\nTITLE: Encrypting Backup Data with AES-128-CTR to S3\nDESCRIPTION: Command to back up a TiDB cluster snapshot to Amazon S3 with AES-128-CTR encryption. It specifies the encryption method and key for securing the backup data.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full\\\n    --pd ${PD_IP}:2379 \\\n    --storage \"s3://${backup_collection_addr}/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --crypter.method aes128-ctr \\\n    --crypter.key 0123456789abcdef0123456789abcdef\n```\n\n----------------------------------------\n\nTITLE: Editing TiDB Cluster Configuration with TiUP\nDESCRIPTION: This command opens the configuration file for a TiDB cluster using TiUP, allowing you to modify the cluster settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster edit-config <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Bit Value Storage and Display Example\nDESCRIPTION: Demonstrates storing and retrieving bit values with different display formats.\nSOURCE: https://github.com/pingcap/docs/blob/master/literal-values.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (b BIT(8));\nINSERT INTO t SET b = b'00010011';\nINSERT INTO t SET b = b'1110';\nINSERT INTO t SET b = b'100101';\n\nmysql> SELECT b+0, BIN(b), HEX(b) FROM t;\n+------+--------+--------+\n| b+0  | BIN(b) | HEX(b) |\n+------+--------+--------+\n|   19 | 10011  | 13     |\n|   14 | 1110   | E      |\n|   37 | 100101 | 25     |\n+------+--------+--------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Invalid GBK Character Set Usage Example\nDESCRIPTION: Example showing unsupported GBK character introducer usage in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-gbk.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a CHAR(10) CHARSET BINARY);\nINSERT INTO t VALUES (_gbk'啊');\n```\n\n----------------------------------------\n\nTITLE: Using tidb-ctl for Key Range Queries\nDESCRIPTION: Command to query table-related key ranges using tidb-ctl, useful for configuring metadata or specific table rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-placement-rules.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ntidb-ctl keyrange --database test --table ttt --encode\n```\n\n----------------------------------------\n\nTITLE: Example runaway watches information schema record\nDESCRIPTION: This is an example of a record returned by querying `information_schema.runaway_watches`. It shows the fields related to a specific watch item, such as ID, resource group, start and end times, the type of matching, the SQL text, the source IP, action, and rule.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n\"*************************** 1. row ***************************\\n                 ID: 1\\n    RESOURCE_GROUP_NAME: default\\n             START_TIME: 2024-09-09 03:35:31\\n               END_TIME: 2024-09-09 03:45:31\\n                  WATCH: Exact\\n            WATCH_TEXT: SELECT variable_name, variable_value FROM mysql.global_variables\\n                 SOURCE: 127.0.0.1:4000\\n                ACTION: Kill\\n                RULE: ProcessedKeys = 666(10)\\n1 row in set (0.00 sec)\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Backup Settings in TiKV YAML\nDESCRIPTION: YAML configuration for TiKV backup settings, including thread count, batch size, and SST file size threshold.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_30\n\nLANGUAGE: yaml\nCODE:\n```\nbackup:\n  num-threads: 8\n  batch-size: 8\n  sst-max-size: \"384MiB\"\n  enable-auto-tune: true\n```\n\n----------------------------------------\n\nTITLE: Scaling in a TiFlash Node using TiUP\nDESCRIPTION: This command removes a TiFlash node from the specified host in a TiDB cluster using TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster scale-in <cluster-name> --node 10.0.1.4:9000\n```\n\n----------------------------------------\n\nTITLE: Setting Default Placement Policy for a Database in TiDB\nDESCRIPTION: Shows how to specify default placement policies for a database, create tables with inherited or specific policies, and modify policies that affect existing tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY p1 PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-east-2\";  -- Creates a placement policy\n\nCREATE PLACEMENT POLICY p2 FOLLOWERS=4;\n\nCREATE PLACEMENT POLICY p3 FOLLOWERS=2;\n\nCREATE TABLE t1 (a INT);  -- Creates a table t1 without specifying any placement policy.\n\nALTER DATABASE test PLACEMENT POLICY=p2;  -- Changes the default placement policy of the database to p2, which does not apply to the existing table t1.\n\nCREATE TABLE t2 (a INT);  -- Creates a table t2. The default placement policy p2 applies to t2.\n\nCREATE TABLE t3 (a INT) PLACEMENT POLICY=p1;  -- Creates a table t3. Because this statement has specified another placement rule, the default placement policy p2 does not apply to table t3.\n\nALTER DATABASE test PLACEMENT POLICY=p3;  -- Changes the default policy of the database again, which does not apply to existing tables.\n\nCREATE TABLE t4 (a INT);  -- Creates a table t4. The default placement policy p3 applies to t4.\n\nALTER PLACEMENT POLICY p3 FOLLOWERS=3; -- `FOLLOWERS=3` applies to the table attached with policy p3 (that is, table t4).\n```\n\n----------------------------------------\n\nTITLE: Setting Maximum Monthly Spending Limit - TiDB Cloud CLI - Shell\nDESCRIPTION: This command is used to set the maximum monthly spending limit for a TiDB Cloud Serverless cluster. It can be utilized in both interactive mode, where users follow prompts, and non-interactive mode, requiring manual entry of flags. Required flags include 'cluster-id' and 'monthly' for non-interactive mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-spending-limit.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless spending-limit [flags]\n```\n\n----------------------------------------\n\nTITLE: Repartitioning a Table and Updating Index Types in TiDB\nDESCRIPTION: This SQL statement shows how to repartition a table and update index types (global or local) in a single ALTER TABLE operation in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_66\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t1 PARTITION BY HASH (col1) PARTITIONS 3 UPDATE INDEXES (uidx12 LOCAL, uidx3 GLOBAL, idx1 LOCAL);\n```\n\n----------------------------------------\n\nTITLE: Creating User with Default Password Reuse Policy in SQL\nDESCRIPTION: SQL command to create a new user that follows the global password reuse policy rather than having an account-level override.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_28\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE USER 'test'@'localhost'\n  PASSWORD HISTORY DEFAULT\n  PASSWORD REUSE INTERVAL DEFAULT;\n```\n\n----------------------------------------\n\nTITLE: Importing CSV Files from Amazon S3 to TiDB Cloud\nDESCRIPTION: Step-by-step instructions for importing CSV files from Amazon S3 buckets to TiDB Cloud clusters, including configuration of source file locations, bucket access methods, and destination mapping.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-csv-files.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n1. Open the **Import** page for your target cluster.\n\n    1. Log in to the [TiDB Cloud console](https://tidbcloud.com/) and navigate to the [**Clusters**](https://tidbcloud.com/console/clusters) page of your project.\n\n        > **Tip:**\n        >\n        > If you have multiple projects, you can click <MDSvgIcon name=\"icon-left-projects\" /> in the lower-left corner and switch to another project.\n\n    2. Click the name of your target cluster to go to its overview page, and then click **Import** in the left navigation pane.\n\n2. Select **Import data from S3**.\n\n    If this is your first time importing data into this cluster, select **Import From Amazon S3**.\n\n3. On the **Import Data from Amazon S3** page, provide the following information for the source CSV files:\n\n    - **Import File Count**: select **One file** or **Multiple files** as needed.\n    - **Included Schema Files**: this field is only visible when importing multiple files. If the source folder contains the target table schemas, select **Yes**. Otherwise, select **No**.\n    - **Data Format**: select **CSV**.\n    - **File URI** or **Folder URI**:\n        - When importing one file, enter the source file URI and name in the following format `s3://[bucket_name]/[data_source_folder]/[file_name].csv`. For example, `s3://sampledata/ingest/TableName.01.csv`.\n        - When importing multiple files, enter the source file URI and name in the following format `s3://[bucket_name]/[data_source_folder]/`. For example, `s3://sampledata/ingest/`.\n    - **Bucket Access**: you can use either an AWS Role ARN or an AWS access key to access your bucket. For more information, see [Configure Amazon S3 access](/tidb-cloud/config-s3-and-gcs-access.md#configure-amazon-s3-access).\n        - **AWS Role ARN**: enter the AWS Role ARN value.\n        - **AWS Access Key**: enter the AWS access key ID and AWS secret access key.\n\n4. Click **Connect**.\n\n5. In the **Destination** section, select the target database and table.\n\n    When importing multiple files, you can use **Advanced Settings** > **Mapping Settings** to define a custom mapping rule for each target table and its corresponding CSV file. After that, the data source files will be re-scanned using the provided custom mapping rule.\n\n    When you enter the source file URI and name in **Source File URIs and Names**, make sure it is in the following format `s3://[bucket_name]/[data_source_folder]/[file_name].csv`. For example, `s3://sampledata/ingest/TableName.01.csv`.\n\n    You can also use wildcards to match the source files. For example:\n\n    - `s3://[bucket_name]/[data_source_folder]/my-data?.csv`: all CSV files starting with `my-data` followed by one character (such as `my-data1.csv` and `my-data2.csv`) in that folder will be imported into the same target table.\n\n    - `s3://[bucket_name]/[data_source_folder]/my-data*.csv`: all CSV files in the folder starting with `my-data` will be imported into the same target table.\n\n    Note that only `?` and `*` are supported.\n\n    > **Note:**\n    >\n    > The URI must contain the data source folder.\n\n6. Click **Start Import**.\n\n7. When the import progress shows **Completed**, check the imported tables.\n```\n\n----------------------------------------\n\nTITLE: Restoring Multiple Tables with Filter\nDESCRIPTION: Command to restore multiple tables using pattern matching filters in BR.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full \\\n    --pd \"${PD_IP}:2379\" \\\n    --filter 'db*.tbl*' \\\n    --storage \"s3://${backup_collection_addr}/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --log-file restorefull.log\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed for Incremental Replication\nDESCRIPTION: Establish a forward data replication channel using TiCDC with a specified starting TSO\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:${cluster_version} cdc changefeed create --server http://${cdc_host}:${cdc_port} --sink-uri=\"mysql://${username}:${password}@${tidb_endpoint}:${port}\" --config config.toml --start-ts ${tso}\n```\n\n----------------------------------------\n\nTITLE: Setting enable-for-tiflash for balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command enables or disables hot region scheduling for TiFlash instances. When enabled, it allows hot region balancing between TiFlash nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_43\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-hot-region-scheduler set enable-for-tiflash true\n```\n\n----------------------------------------\n\nTITLE: Configuring Max Allowed Packet Size in TiDB\nDESCRIPTION: Sets the maximum packet size for SQL connections. Configuring it to 0 will dynamically retrieve the value from the server on every connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_14\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- Example: `67_108_864` -->\n```\n\n----------------------------------------\n\nTITLE: Basic Binlog Event Filter Configuration in YAML\nDESCRIPTION: Example configuration showing how to set up basic binlog event filtering rules to ignore specific table operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-binlog-event-filter.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nfilters:\n  rule-1:\n    schema-pattern: \"test_*\"\n    ​table-pattern: \"t_*\"\n    ​events: [\"truncate table\", \"drop table\"]\n    sql-pattern: [\"^DROP\\\\s+PROCEDURE\", \"^CREATE\\\\s+PROCEDURE\"]\n    ​action: Ignore\n```\n\n----------------------------------------\n\nTITLE: Creating a Spring Data JPA Repository for TiDB\nDESCRIPTION: This Java code defines a Spring Data JPA repository interface for the PlayerBean entity, extending JpaRepository to inherit CRUD operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-spring-boot.md#2025-04-18_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n@Repository\npublic interface PlayerRepository extends JpaRepository<PlayerBean, Long> {\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS for TiProxy\nDESCRIPTION: This code snippet illustrates configuring TLS settings for TiProxy in the configuration file. The `server-http-tls` section specifies paths to the CA certificate, server certificate, and server key, enabling secure HTTPS communication.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\n\t\t```toml\n        [security]\n            [server-http-tls]\n            ca = \"/path/to/ca.pem\"\n            cert = \"/path/to/tiproxy-server.pem\"\n            key = \"/path/to/tiproxy-server-key.pem\"\n        ```\n```\n\n----------------------------------------\n\nTITLE: Downloading and Installing HAProxy from Source\nDESCRIPTION: Series of commands to download, extract, compile and install HAProxy 2.6.2 from source code.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/haproxy-best-practices.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nwget https://www.haproxy.org/download/2.6/src/haproxy-2.6.2.tar.gz\n```\n\nLANGUAGE: bash\nCODE:\n```\ntar zxf haproxy-2.6.2.tar.gz\n```\n\nLANGUAGE: bash\nCODE:\n```\ncd haproxy-2.6.2\nmake clean\nmake -j 8 TARGET=linux-glibc USE_THREAD=1\nmake PREFIX=${/app/haproxy} SBINDIR=${/app/haproxy/bin} install\n```\n\n----------------------------------------\n\nTITLE: Binding INSERT/REPLACE with SELECT Subqueries\nDESCRIPTION: This example shows how to correctly bind execution plans for `INSERT` / `REPLACE` statements with `SELECT` subqueries. The optimizer hints should be specified within the `SELECT` subquery, not after the `INSERT` / `REPLACE` keyword.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n-- The hint takes effect in the following statement.\nCREATE GLOBAL BINDING for\n    INSERT INTO orders SELECT * FROM pre_orders WHERE status = 'VALID' AND created <= (NOW() - INTERVAL 1 HOUR)\nUSING\n    INSERT INTO orders SELECT /*+ use_index(@sel_1 pre_orders, idx_created) */ * FROM pre_orders WHERE status = 'VALID' AND created <= (NOW() - INTERVAL 1 HOUR);\n\n-- The hint cannot take effect in the following statement.\nCREATE GLOBAL BINDING for\n    INSERT INTO orders SELECT * FROM pre_orders WHERE status = 'VALID' AND created <= (NOW() - INTERVAL 1 HOUR)\nUSING\n    INSERT /*+ use_index(@sel_1 pre_orders, idx_created) */ INTO orders SELECT * FROM pre_orders WHERE status = 'VALID' AND created <= (NOW() - INTERVAL 1 HOUR);\n```\n\n----------------------------------------\n\nTITLE: Confirming TiDB Cloud Backup Creation\nDESCRIPTION: Terminal output showing the completion of the backup resource creation after confirming with \"yes\".\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-backup-resource.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n  Enter a value: yes\n\ntidbcloud_backup.example_backup: Creating...\ntidbcloud_backup.example_backup: Creation complete after 2s [id=1350048]\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n```\n\n----------------------------------------\n\nTITLE: Connecting to PD cluster with tiup ctl pd\nDESCRIPTION: This command-line example shows how to connect to a PD cluster using `tiup ctl pd` after enabling TLS. It provides the necessary parameters for secure authentication: the CA certificate, the client certificate, and the client key.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n    ```bash\n    tiup ctl:v<CLUSTER_VERSION> pd -u https://127.0.0.1:2379 --cacert /path/to/ca.pem --cert /path/to/client.pem --key /path/to/client-key.pem\n    ```\n```\n\n----------------------------------------\n\nTITLE: Viewing Second MySQL Instance Binlog Position in Dumpling Metadata\nDESCRIPTION: Example of a metadata file exported by Dumpling for MySQL instance2, showing the binlog position and GTID information for configuring replication starting point.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\nStarted dump at: 2022-05-25 10:20:32\nSHOW MASTER STATUS:\n       Log: mysql-bin.000001\n       Pos: 1312659\n       GTID:cd21245e-bb10-11ec-ae16-fec83cf2b903:1-4036\nFinished dump at: 2022-05-25 10:20:32\n```\n\n----------------------------------------\n\nTITLE: Configure branch.allowList in tidbcloud.yml\nDESCRIPTION: This snippet shows how to configure the `branch.allowList` property within the `tidbcloud.yml` file. The `branch.allowList` is an array of strings that specifies the GitHub branches that the TiDB Cloud Branching app is allowed to manage. The example shows allowing branches with names ending with \"_db\".\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/branch-github-integration.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n\"github:\\n    branch:\\n        allowList:\\n            - \".*_db\"\"\n```\n\n----------------------------------------\n\nTITLE: Executing MySQL client with local-infile option\nDESCRIPTION: This code snippet demonstrates how to start the MySQL client with the `--local-infile=1` option to allow executing the `LOAD DATA LOCAL` statement in TiDB. This is necessary when the client's default setting does not permit local file loading.\nSOURCE: https://github.com/pingcap/docs/blob/master/error-codes.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nmysql --local-infile=1 -u root -h 127.0.0.1 -P 4000\n```\n\n----------------------------------------\n\nTITLE: Creating Table with UUID Primary Key - No Swap Flag\nDESCRIPTION: SQL table creation with UUID stored as varbinary(16) and clustered primary key. This implementation avoids hotspots by not using the swap_flag.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/uuid.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `uuid_demo_1` (\n  `uuid` varbinary(16) NOT NULL,\n  `c1` varchar(255) NOT NULL,\n  PRIMARY KEY (`uuid`) CLUSTERED\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Table with SHARD_ROW_ID_BITS\nDESCRIPTION: Demonstrates creating a table with 16 shards using the SHARD_ROW_ID_BITS attribute. This helps distribute data writes across multiple Regions to prevent write hot spots for tables with non-clustered primary keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/shard-row-id-bits.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (\n    id INT PRIMARY KEY NONCLUSTERED\n) SHARD_ROW_ID_BITS = 4;\n```\n\n----------------------------------------\n\nTITLE: Creating Tables and Basic Query Execution in TiDB\nDESCRIPTION: Creates two tables t1 and t2, then executes a query with a correlated subquery to demonstrate default query optimization behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/correlated-subquery-optimization.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t1(a int, b int);\ncreate table t2(a int, b int, index idx(b));\nexplain select * from t1 where t1.a < (select sum(t2.a) from t2 where t2.b = t1.b);\n```\n\n----------------------------------------\n\nTITLE: RocksDB Cache Configuration Parameters\nDESCRIPTION: Core cache-related configuration parameters for RocksDB, including block cache size, filter blocks, and bloom filter settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\nblock-cache-size:\n  defaultcf: \"Total machine memory * 25%\"\n  writecf: \"Total machine memory * 15%\"\n  lockcf: \"Total machine memory * 2%\"\n\ndisable-block-cache: false\ncache-index-and-filter-blocks: true\npin-l0-filter-and-index-blocks: true\nuse-bloom-filter: true\n```\n\n----------------------------------------\n\nTITLE: Snowflake-like ID Structure\nDESCRIPTION: An example of the 64-bit ID structure used by Baidu's uid-generator implementation of the Snowflake algorithm. This structure divides the ID into segments for sign bit, delta seconds, worker node ID, and sequence number.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-unique-serial-number-generation.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| sign | delta seconds | worker node id | sequencs |\n|------|---------------|----------------|----------|\n| 1bit |     28bits    | 22bits         | 13bits   |\n```\n\n----------------------------------------\n\nTITLE: Example of Using CREATE TABLE LIKE in TiDB\nDESCRIPTION: A complete example demonstrating how to create a table, insert data, and then create a new table with the same structure using CREATE TABLE LIKE. The example shows that the new table structure is copied but no data is transferred.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-table-like.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (a INT NOT NULL);\nQuery OK, 0 rows affected (0.13 sec)\n\nmysql> INSERT INTO t1 VALUES (1),(2),(3),(4),(5);\nQuery OK, 5 rows affected (0.02 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\nmysql> SELECT * FROM t1;\n+---+\n| a |\n+---+\n| 1 |\n| 2 |\n| 3 |\n| 4 |\n| 5 |\n+---+\n5 rows in set (0.00 sec)\n\nmysql> CREATE TABLE t2 LIKE t1;\nQuery OK, 0 rows affected (0.10 sec)\n\nmysql> SELECT * FROM t2;\nEmpty set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Accessing TiDB Statistics API for a Specific Time\nDESCRIPTION: HTTP endpoint to access the JSON format statistics of a specific table in a database at a particular timestamp.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\nhttp://${tidb-server-ip}:${tidb-server-status-port}/stats/dump/${db_name}/${table_name}/${yyyyMMddHHmmss}\n```\n\n----------------------------------------\n\nTITLE: Refreshing TiDB Cluster Configuration\nDESCRIPTION: These commands refresh the cluster configuration and Prometheus configuration after scaling in PD nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster reload <cluster-name> --skip-restart\n```\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster reload <cluster-name> -R prometheus\n```\n\n----------------------------------------\n\nTITLE: Starting a Pessimistic Transaction - SQL\nDESCRIPTION: This snippet demonstrates how to explicitly start a pessimistic transaction using SQL. The command can be used to initiate a transaction in pessimistic mode regardless of the global setting.\nSOURCE: https://github.com/pingcap/docs/blob/master/pessimistic-transaction.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN PESSIMISTIC;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiFlash Late Materialization at Global Level in SQL\nDESCRIPTION: SQL commands to enable or disable the TiFlash late materialization feature globally, affecting all new sessions, using the tidb_opt_enable_late_materialization system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-late-materialization.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_opt_enable_late_materialization=OFF;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_opt_enable_late_materialization=ON;\n```\n\n----------------------------------------\n\nTITLE: Enabling online-ddl in DM Configuration YAML\nDESCRIPTION: This YAML snippet demonstrates how to configure the online-ddl parameter in a DM task configuration file. By setting `online-ddl` to `true`, DM can automatically handle DDL operations by gh-ost or pt-osc. It also includes basic task settings such as the task name, mode, and shard merge mode. Key dependencies include DM software configured to connect to MySQL and TiDB databases. The configuration ensures minimal downtime and optimization for DDL operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-with-pt-ghost.md#2025-04-18_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\n# ----------- Global configuration -----------\n## ********* Basic configuration *********\nname: test                      # The name of the task. Should be globally unique.\ntask-mode: all                  # The task mode. Can be set to `full`, `incremental`, or `all`.\nshard-mode: \"pessimistic\"       # The shard merge mode. Optional modes are `pessimistic` and `optimistic`. The `pessimistic` mode is used by default. After understanding the principles and restrictions of the \"optimistic\" mode, you can set it to the \"optimistic\" mode.\nmeta-schema: \"dm_meta\"          # The downstream database that stores the `meta` information.\nonline-ddl: true                # Enable online-ddl support on DM to support automatic processing of \"gh-ost\" and \"pt-osc\" for the upstream database.\n```\n\n----------------------------------------\n\nTITLE: Resuming DDL Jobs in TiDB\nDESCRIPTION: The ADMIN RESUME DDL JOBS command is used to resume DDL tasks that have been paused. It can only resume paused DDL tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/ddl-introduction.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN RESUME DDL JOBS job_id [, job_id]\n```\n\n----------------------------------------\n\nTITLE: Querying Affected Tables After Unsafe Recovery\nDESCRIPTION: SQL query to retrieve table names and schemas for tables affected by the unsafe recovery process\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TABLE_SCHEMA, TABLE_NAME, TIDB_TABLE_ID FROM INFORMATION_SCHEMA.TABLES WHERE TIDB_TABLE_ID IN (64, 27);\n```\n\n----------------------------------------\n\nTITLE: TiCDC Status Output Example\nDESCRIPTION: Example JSON output from the TiCDC status command showing two capture nodes with their IDs, owner status, addresses, and cluster ID information.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/deploy-ticdc.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n[\n  {\n    \"id\": \"806e3a1b-0e31-477f-9dd6-f3f2c570abdd\",\n    \"is-owner\": true,\n    \"address\": \"127.0.0.1:8300\",\n    \"cluster-id\": \"default\"\n  },\n  {\n    \"id\": \"ea2a4203-56fe-43a6-b442-7b295f458ebc\",\n    \"is-owner\": false,\n    \"address\": \"127.0.0.1:8301\",\n    \"cluster-id\": \"default\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Raft Engine Core Configuration\nDESCRIPTION: Essential Raft Engine settings including enable/disable toggle, directory paths, and compression thresholds for log storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_23\n\nLANGUAGE: yaml\nCODE:\n```\nenable: true\ndir: \"\"\nspill-dir: \"\"\nbatch-compression-threshold: \"8KiB\"\ntarget-file-size: \"128MiB\"\npurge-threshold: \"10GiB\"\n```\n\n----------------------------------------\n\nTITLE: Sorted SQL Query - Authors by Birth Year\nDESCRIPTION: SQL query demonstrating result sorting using ORDER BY clause to sort authors by birth year in descending order.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, name, birth_year\nFROM authors\nORDER BY birth_year DESC;\n```\n\n----------------------------------------\n\nTITLE: Executing MAX Window Function with TiDB SQL\nDESCRIPTION: This SQL example shows how to create a table, insert data, and use the EXPLAIN command to analyze a query plan involving the MAX window function. It highlights that the execution plan with 'root' as the task target indicates that the MAX function cannot utilize TiFlash for window operations due to its limitation to aggregate functionality push-down. Key factors include understanding the distinction between aggregate functions and their use cases.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-supported-pushdown-calculations.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id INT PRIMARY KEY, c1 VARCHAR(100));\nALTER TABLE t SET TIFLASH REPLICA 1;\nINSERT INTO t VALUES(1,\"foo\"),(2,\"bar\"),(3,\"bar foo\"),(10,\"foo\"),(20,\"bar\"),(30,\"bar foo\");\n\nEXPLAIN SELECT id, MAX(id) OVER (PARTITION BY id > 10) FROM t;\n+-----------------------------+----------+-----------+---------------+------------------------------------------------------------+\n| id                          | estRows  | task      | access object | operator info                                              |\n+-----------------------------+----------+-----------+---------------+------------------------------------------------------------+\n| Projection_6                | 10000.00 | root      |               | test.t1.id, Column#5                                       |\n| └─Shuffle_14                | 10000.00 | root      |               | execution info: concurrency:5, data sources:[Projection_8] |\n|   └─Window_7                | 10000.00 | root      |               | max(test.t1.id)->Column#5 over(partition by Column#4)      |\n|     └─Sort_13               | 10000.00 | root      |               | Column#4                                                   |\n|       └─Projection_8        | 10000.00 | root      |               | test.t1.id, gt(test.t1.id, 10)->Column#4                   |\n|         └─TableReader_10    | 10000.00 | root      |               | data:TableFullScan_9                                       |\n|           └─TableFullScan_9 | 10000.00 | cop[tikv] | table:t1      | keep order:false, stats:pseudo                             |\n+-----------------------------+----------+-----------+---------------+------------------------------------------------------------+\n7 rows in set (0.0010 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining Warning Alert Rule for TiKV CDC Scan Duration Exceeding 10 Minutes in YAML\nDESCRIPTION: YAML configuration for a warning alert rule that triggers when the TiKV CDC module has scanned for incremental replication for more than 10 minutes.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-alert-rules.md#2025-04-18_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nhistogram_quantile(0.9, rate(tikv_cdc_scan_duration_seconds_bucket{}[1m])) > 600\n```\n\n----------------------------------------\n\nTITLE: Remove Failed Stores from Regions (Deprecated)\nDESCRIPTION: This command removes failed TiKV stores from the peer list of specified regions. It requires stopping the stores service first and can be risky if misused.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir /path/to/tikv unsafe-recover remove-fail-stores -s 3 -r 1001,1002\n```\n\n----------------------------------------\n\nTITLE: Executing a Slow Query on Books Table in TiDB\nDESCRIPTION: Demonstrates a slow SQL query that performs a full table scan on the 'books' table when searching by title.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM books WHERE title = 'Marian Yost';\n```\n\n----------------------------------------\n\nTITLE: SQL Execution Error Response in JavaScript\nDESCRIPTION: Example error response when the data summary is not ready. This indicates that you need to wait for the data summary to be completed before proceeding with SQL generation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\n{\n    \"code\": 400,\n    \"msg\": \"Data summary is not ready, please wait for a while and retry\",\n    \"result\": {}\n}\n```\n\n----------------------------------------\n\nTITLE: Get Next Value in a Sequence in TiDB\nDESCRIPTION: This snippet illustrates how to obtain the next value from a sequence in TiDB using NEXTVAL, in contrast to Oracle's sequence access method.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nsequence_name.NEXTVAL\n```\n\nLANGUAGE: sql\nCODE:\n```\nNEXTVAL(sequence_name)\n```\n\n----------------------------------------\n\nTITLE: Analyzing Hot Index Leader Region Distribution in SQL\nDESCRIPTION: This SQL query counts hot index leader regions grouped by index_name and store_id for a specific table and time range. It focuses on index regions where is_leader is true.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-hot-regions-history.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT count(region_id) cnt, index_name, store_id FROM INFORMATION_SCHEMA.TIDB_HOT_REGIONS_HISTORY WHERE update_time >'2021-08-18 21:40:00' and update_time <'2022-09-19 00:00:00' and table_name = 'table_name' and is_leader=1 group by index_name, store_id order by index_name,cnt desc;\n```\n\n----------------------------------------\n\nTITLE: Modifying TiKV Configuration - Adjust Compaction Rate Limiter\nDESCRIPTION: This command disables the rate-limiter-auto-tuned mode for compaction to prevent accumulated pending bytes due to rate limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --host ip:port modify-tikv-config -n rocksdb.rate-limiter-auto-tuned -v false\n```\n\n----------------------------------------\n\nTITLE: Range COLUMNS Partitioning by Name and Date\nDESCRIPTION: This SQL statement creates a table `t` partitioned by RANGE COLUMNS using `name` (varchar) and `valid_until` (datetime) columns.  The partitions are defined based on combined ranges of name and date, enabling efficient querying and archival based on these criteria.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (\n  valid_until datetime,\n  name varchar(255) CHARACTER SET ascii,\n  notes text\n)\nPARTITION BY RANGE COLUMNS(name, valid_until)\n(PARTITION `p2022-g` VALUES LESS THAN ('G','2023-01-01 00:00:00'),\n PARTITION `p2023-g` VALUES LESS THAN ('G','2024-01-01 00:00:00'),\n PARTITION `p2022-m` VALUES LESS THAN ('M','2023-01-01 00:00:00'),\n PARTITION `p2023-m` VALUES LESS THAN ('M','2024-01-01 00:00:00'),\n PARTITION `p2022-s` VALUES LESS THAN ('S','2023-01-01 00:00:00'),\n PARTITION `p2023-s` VALUES LESS THAN ('S','2024-01-01 00:00:00'))\n```\n\n----------------------------------------\n\nTITLE: Configuring RECOMMEND INDEX Options in SQL\nDESCRIPTION: This SQL snippet demonstrates how to set and show options for the RECOMMEND INDEX command, allowing fine-tuning of index recommendations. It includes settings such as timeout and maximum indexes. Dependencies include a SQL database supporting the RECOMMEND INDEX functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nRECOMMEND INDEX SET <option> = <value>;\nRECOMMEND INDEX SHOW OPTION;\n```\n\n----------------------------------------\n\nTITLE: Creating and Inserting Data into t2 Table in SQL\nDESCRIPTION: This SQL snippet first creates a table named 't2' with two integer columns, 'id' and 'v', and defines a key on the 'id' column, then inserts data into table `t2`. The inserted values are sample data used in later examples to illustrate non-transactional DML usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE TABLE t2(id int, v int, key(id));\\nINSERT INTO t2 VALUES (1,1), (3,3), (5,5);\"\n```\n\n----------------------------------------\n\nTITLE: Specific Table Query Result in TiDB\nDESCRIPTION: Shows the output of querying specific table information, displaying all metadata for the mysql.user table including TiDB-specific fields like TIDB_TABLE_ID and TIDB_ROW_ID_SHARDING_INFO.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tables.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n*************************** 1. row ***************************\n            TABLE_CATALOG: def\n             TABLE_SCHEMA: mysql\n               TABLE_NAME: user\n               TABLE_TYPE: BASE TABLE\n                   ENGINE: InnoDB\n                  VERSION: 10\n               ROW_FORMAT: Compact\n               TABLE_ROWS: 0\n           AVG_ROW_LENGTH: 0\n              DATA_LENGTH: 0\n          MAX_DATA_LENGTH: 0\n             INDEX_LENGTH: 0\n                DATA_FREE: 0\n           AUTO_INCREMENT: NULL\n              CREATE_TIME: 2020-07-05 09:25:51\n              UPDATE_TIME: NULL\n               CHECK_TIME: NULL\n          TABLE_COLLATION: utf8mb4_bin\n                 CHECKSUM: NULL\n           CREATE_OPTIONS: \n            TABLE_COMMENT: \n            TIDB_TABLE_ID: 5\nTIDB_ROW_ID_SHARDING_INFO: NULL\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: JDBC Prepared Statement Cache Configuration\nDESCRIPTION: This snippet provides a recommended JDBC configuration for utilizing the prepared plan cache feature in TiDB, aiming to enhance throughput performance and reduce latency.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tune-performance-overview.md#2025-04-18_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nuseServerPrepStmts=true&cachePrepStmts=true& prepStmtCacheSize=1000&prepStmtCacheSqlLimit=20480&useConfigs=maxPerformance\n```\n\n----------------------------------------\n\nTITLE: Batched Delete Pattern for Large Data Deletion in TiDB\nDESCRIPTION: A pseudocode example demonstrating how to efficiently delete large amounts of data by breaking the task into hourly chunks and processing in batches of 5000 rows. This approach prevents earlier delete operations from slowing down later ones by avoiding scan performance degradation due to tombstone records.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/tidb-best-practices.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nfor i from 0 to 23:\n    while affected_rows > 0:\n        delete from t where insert_time >= i:00:00 and insert_time < (i+1):00:00 limit 5000;\n        affected_rows = select affected_rows()\n```\n\n----------------------------------------\n\nTITLE: Java Implementation - Sorted Authors Query\nDESCRIPTION: Java implementation for querying and sorting authors by birth year using SQL ORDER BY clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_6\n\nLANGUAGE: java\nCODE:\n```\npublic List<Author> getAuthorsSortByBirthYear() throws SQLException {\n    List<Author> authors = new ArrayList<>();\n    try (Connection conn = ds.getConnection()) {\n        Statement stmt = conn.createStatement();\n        ResultSet rs = stmt.executeQuery(\"\"\"\n            SELECT id, name, birth_year\n            FROM authors\n            ORDER BY birth_year DESC;\n            \"\"\");\n\n        while (rs.next()) {\n            Author author = new Author();\n            author.setId(rs.getLong(\"id\"));\n            author.setName(rs.getString(\"name\"));\n            author.setBirthYear(rs.getShort(\"birth_year\"));\n            authors.add(author);\n        }\n    }\n    return authors;\n}\n```\n\n----------------------------------------\n\nTITLE: Expanded Form of Range COLUMNS INTERVAL Partitioned Table in SQL\nDESCRIPTION: The expanded form of the monthly_report_status table with Range COLUMNS INTERVAL partitioning, showing how TiDB automatically creates monthly partitions based on the date range specified.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `monthly_report_status` (\n  `report_id` int NOT NULL,\n  `report_status` varchar(20) NOT NULL,\n  `report_date` date NOT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\nPARTITION BY RANGE COLUMNS(`report_date`)\n(PARTITION `P_LT_2000-01-01` VALUES LESS THAN ('2000-01-01'),\n PARTITION `P_LT_2000-02-01` VALUES LESS THAN ('2000-02-01'),\n...\n PARTITION `P_LT_2024-11-01` VALUES LESS THAN ('2024-11-01'),\n PARTITION `P_LT_2024-12-01` VALUES LESS THAN ('2024-12-01'),\n PARTITION `P_LT_2025-01-01` VALUES LESS THAN ('2025-01-01'))\n```\n\n----------------------------------------\n\nTITLE: Updating Data with TypeORM in TypeScript\nDESCRIPTION: This code demonstrates how to update a Player record using TypeORM. It first retrieves the Player by ID, modifies a property, and then saves the updated object back to the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nconst player = await this.dataSource.manager.findOneBy(Player, {\n  id: 101\n});\nplayer.goods += 50;\nawait this.dataSource.manager.save(player);\n```\n\n----------------------------------------\n\nTITLE: Time Zone Impact Demonstration on Data Types\nDESCRIPTION: SQL example showing how time zone settings affect TIMESTAMP and DATETIME data types differently.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-time-zone.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (ts timestamp, dt datetime);\nset @@time_zone = 'UTC';\ninsert into t values ('2017-09-30 11:11:11', '2017-09-30 11:11:11');\nset @@time_zone = '+8:00';\nselect * from t;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV MVCC In-Memory Engine with TOML\nDESCRIPTION: TOML configuration for enabling and tuning the TiKV MVCC in-memory engine. It includes settings for enabling the feature, allocating memory capacity, controlling GC intervals, and setting thresholds for MVCC amplification.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-in-memory-engine.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[in-memory-engine]\n# This parameter is the switch for the in-memory engine feature, which is disabled by default. You can set it to true to enable it.\n# It is recommended to configure at least 8 GiB of memory for the TiKV node, with 32 GiB or more for optimal performance.\n# If the available memory for the TiKV node is insufficient, the in-memory engine will not be enabled even if this configuration item is set to true. In such cases, check the TiKV log file for messages containing \"in-memory engine is disabled because\" to learn why the in-memory engine is not enabled.\nenable = false\n\n# This parameter controls the memory size available to the in-memory engine.\n# The default value is 10% of the system memory, and the maximum value is 5 GiB.\n# You can manually adjust this configuration to allocate more memory.\n# Note: When the in-memory engine is enabled, block-cache.capacity automatically decreases by 10%.\ncapacity = \"5GiB\"\n\n# This parameter controls the time interval for the in-memory engine to GC the cached MVCC versions.\n# The default value is 3 minutes, representing that GC is performed every 3 minutes on the cached MVCC versions.\n# Decreasing the value of this parameter can increase the GC frequency, reduce the number of MVCC versions, but will increase CPU consumption for GC and increase the probability of in-memory engine cache miss.\ngc-run-interval = \"3m\"\n\n# This parameter controls the threshold for the in-memory engine to select and load Regions based on MVCC read amplification.\n# The default value is 10, indicating that if reading a single row in a Region requires processing more than 10 MVCC versions, this Region might be loaded into the in-memory engine.\nmvcc-amplification-threshold = 10\n```\n\n----------------------------------------\n\nTITLE: Error Message for Ghost Table DDL Operation\nDESCRIPTION: Example error message that occurs when handling DDL operations related to gh-ost tables after setting online-ddl to true.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n[unit=Sync] [\"error information\"=\"{\\\"msg\\\":\\\"[code=36046:class=sync-unit:scope=internal:level=high] online ddls on ghost table `xxx`.`_xxxx_gho`\\\\ngithub.com/pingcap/tiflow/pkg/terror.(*Error).Generate ......\n```\n\n----------------------------------------\n\nTITLE: Modifying TiKV Configuration - Set Rate Limit for Compaction\nDESCRIPTION: This command sets the rate limit for compaction in TiKV to 1GB per second. It is important for controlling compaction performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --host ip:port modify-tikv-config -n rocksdb.rate-bytes-per-sec -v \"1GB\"\n```\n\n----------------------------------------\n\nTITLE: Installing AWS CLI on Linux\nDESCRIPTION: Commands to download, unzip, and install the AWS Command Line Interface on a Linux x86_64 system. This is required to configure VPC peering using the command line.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-vpc-peering-connections.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\nunzip awscliv2.zip\nsudo ./aws/install\n```\n\n----------------------------------------\n\nTITLE: Deploying DM Cluster\nDESCRIPTION: This command deploys a DM cluster named 'dm-test' using the specified version and topology configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup-offline.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm deploy dm-test ${version} ./topology.yaml --user root [-p] [-i /home/root/.ssh/gcp_rsa]\n```\n\n----------------------------------------\n\nTITLE: Running Combined TPC-C and CH-benCHmark Test Command\nDESCRIPTION: Command to execute a combined TPC-C and CH-benCHmark test with 50 OLTP workers and 1 OLAP worker for 1 hour duration on a TiDB instance with 1000 warehouses.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-ch.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup bench ch --host 172.16.5.140 -P4000 --warehouses 1000 run -D tpcc -T 50 -t 1 --time 1h\n```\n\n----------------------------------------\n\nTITLE: Demonstrating tidb_analyze_skip_column_types Variable Usage in MySQL\nDESCRIPTION: This example demonstrates how the tidb_analyze_skip_column_types variable affects which columns are included in statistics collection. The snippet shows that columns with types specified in this variable (json, blob, longblob) are skipped during ANALYZE operations, even when explicitly requested.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW CREATE TABLE t;\n+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Table | Create Table                                                                                                                                                                                                             |\n+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| t     | CREATE TABLE `t` (\n  `a` int DEFAULT NULL,\n  `b` varchar(10) DEFAULT NULL,\n  `c` json DEFAULT NULL,\n  `d` blob DEFAULT NULL,\n  `e` longblob DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin |\n+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n\nmysql> SELECT @@tidb_analyze_skip_column_types;\n+----------------------------------+\n| @@tidb_analyze_skip_column_types |\n+----------------------------------+\n| json,blob,mediumblob,longblob    |\n+----------------------------------+\n1 row in set (0.00 sec)\n\nmysql> ANALYZE TABLE t;\nQuery OK, 0 rows affected, 1 warning (0.05 sec)\n\nmysql> SELECT job_info FROM mysql.analyze_jobs ORDER BY end_time DESC LIMIT 1;\n+---------------------------------------------------------------------+\n| job_info                                                            |\n+---------------------------------------------------------------------+\n| analyze table columns a, b with 256 buckets, 500 topn, 1 samplerate |\n+---------------------------------------------------------------------+\n1 row in set (0.00 sec)\n\nmysql> ANALYZE TABLE t COLUMNS a, c;\nQuery OK, 0 rows affected, 1 warning (0.04 sec)\n\nmysql> SELECT job_info FROM mysql.analyze_jobs ORDER BY end_time DESC LIMIT 1;\n+------------------------------------------------------------------+\n| job_info                                                         |\n+------------------------------------------------------------------+\n| analyze table columns a with 256 buckets, 500 topn, 1 samplerate |\n+------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting Session-Level Stale Read in SQL\nDESCRIPTION: Shows how to enable and disable stale read at the session level using SQL commands.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-stale-read.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSET @@tidb_read_staleness=\"-5\";\n\nset @@tidb_read_staleness=\"\";\n```\n\n----------------------------------------\n\nTITLE: Querying User Privileges in TiDB\nDESCRIPTION: This SQL query retrieves all privileges assigned to the root user from the INFORMATION_SCHEMA.USER_PRIVILEGES table, displaying the grantee, table catalog, privilege type, and whether the privilege is grantable.\nSOURCE: https://github.com/pingcap/docs/blob/master/privilege-management.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.USER_PRIVILEGES WHERE grantee = \"'root'@'%'\";\n```\n\n----------------------------------------\n\nTITLE: Viewing TABLES Structure Output in TiDB\nDESCRIPTION: Shows the output of the DESC command, displaying all columns in the TABLES information schema table along with their data types and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tables.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+---------------------------+---------------+------+------+----------+-------+\n| Field                     | Type          | Null | Key  | Default  | Extra |\n+---------------------------+---------------+------+------+----------+-------+\n| TABLE_CATALOG             | varchar(512)  | YES  |      | NULL     |       |\n| TABLE_SCHEMA              | varchar(64)   | YES  |      | NULL     |       |\n| TABLE_NAME                | varchar(64)   | YES  |      | NULL     |       |\n| TABLE_TYPE                | varchar(64)   | YES  |      | NULL     |       |\n| ENGINE                    | varchar(64)   | YES  |      | NULL     |       |\n| VERSION                   | bigint(21)    | YES  |      | NULL     |       |\n| ROW_FORMAT                | varchar(10)   | YES  |      | NULL     |       |\n| TABLE_ROWS                | bigint(21)    | YES  |      | NULL     |       |\n| AVG_ROW_LENGTH            | bigint(21)    | YES  |      | NULL     |       |\n| DATA_LENGTH               | bigint(21)    | YES  |      | NULL     |       |\n| MAX_DATA_LENGTH           | bigint(21)    | YES  |      | NULL     |       |\n| INDEX_LENGTH              | bigint(21)    | YES  |      | NULL     |       |\n| DATA_FREE                 | bigint(21)    | YES  |      | NULL     |       |\n| AUTO_INCREMENT            | bigint(21)    | YES  |      | NULL     |       |\n| CREATE_TIME               | datetime      | YES  |      | NULL     |       |\n| UPDATE_TIME               | datetime      | YES  |      | NULL     |       |\n| CHECK_TIME                | datetime      | YES  |      | NULL     |       |\n| TABLE_COLLATION           | varchar(32)   | NO   |      | utf8_bin |       |\n| CHECKSUM                  | bigint(21)    | YES  |      | NULL     |       |\n| CREATE_OPTIONS            | varchar(255)  | YES  |      | NULL     |       |\n| TABLE_COMMENT             | varchar(2048) | YES  |      | NULL     |       |\n| TIDB_TABLE_ID             | bigint(21)    | YES  |      | NULL     |       |\n| TIDB_ROW_ID_SHARDING_INFO | varchar(255)  | YES  |      | NULL     |       |\n+---------------------------+---------------+------+------+----------+-------+\n23 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying Current Resource Group in TiDB SQL\nDESCRIPTION: This snippet shows how to query the current resource group bound to a user session using the CURRENT_RESOURCE_GROUP() function in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_RESOURCE_GROUP();\n```\n\n----------------------------------------\n\nTITLE: Combined JSON_UNQUOTE() and JSON_EXTRACT() Result Example\nDESCRIPTION: The output shows the result of first extracting the 'database' property and then unquoting it, resulting in the plain string value 'TiDB'.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-modify.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------------------------------------------+\n| JSON_UNQUOTE(JSON_EXTRACT('{\"database\": \"TiDB\"}', '$.database')) |\n+------------------------------------------------------------------+\n| TiDB                                                             |\n+------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining Multiple-Column Foreign Keys\nDESCRIPTION: This SQL example showcases the creation of a table with multiple foreign keys that link to other tables, demonstrating complex relationships within the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE product (\n    category INT NOT NULL,\n    id INT NOT NULL,\n    price DECIMAL(20,10),\n    PRIMARY KEY(category, id)\n);\n\nCREATE TABLE customer (\n    id INT KEY\n);\n\nCREATE TABLE product_order (\n    id INT NOT NULL AUTO_INCREMENT,\n    product_category INT NOT NULL,\n    product_id INT NOT NULL,\n    customer_id INT NOT NULL,\n\n    PRIMARY KEY(id),\n    INDEX (product_category, product_id),\n    INDEX (customer_id),\n\n    FOREIGN KEY (product_category, product_id)\n      REFERENCES product(category, id)\n      ON UPDATE CASCADE ON DELETE RESTRICT,\n\n    FOREIGN KEY (customer_id)\n      REFERENCES customer(id)\n);\n```\n\n----------------------------------------\n\nTITLE: Analyzing Subquery Execution with EXPLAIN ANALYZE\nDESCRIPTION: Example showing how subqueries are executed in advance, demonstrated through EXPLAIN ANALYZE output of a query with a subquery comparing against max value.\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain analyze select count(*) from t where a=(select max(t1.a) from t t1, t t2 where t1.a=t2.a);\n```\n\n----------------------------------------\n\nTITLE: Interpreting SHOW PLACEMENT FOR Results in SQL\nDESCRIPTION: This SQL output snippet shows the results from executing SHOW PLACEMENT FOR commands. It clearly outlines the structure of the result set, including the target, placement, and scheduling state of various objects. The output indicates the status of scheduling progress for both databases and tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-placement-for.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.02 sec)\n\nQuery OK, 0 rows affected (0.00 sec)\n\nQuery OK, 0 rows affected (0.01 sec)\n\n+---------------+----------------------------------------------------------------------+------------------+\n| Target        | Placement                                                            | Scheduling_State |\n+---------------+----------------------------------------------------------------------+------------------+\n| DATABASE test | PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\" FOLLOWERS=4 | INPROGRESS       |\n+---------------+----------------------------------------------------------------------+------------------+\n1 row in set (0.00 sec)\n\n+---------------+-------------+------------------+\n| Target        | Placement   | Scheduling_State |\n+---------------+-------------+------------------+\n| TABLE test.t1 | FOLLOWERS=4 | INPROGRESS       |\n+---------------+-------------+------------------+\n1 row in set (0.00 sec)\n\n***************************[ 1. row ]***************************\nTable        | t1\nCreate Table | CREATE TABLE `t1` (\n  `a` int DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin /*T![placement] PLACEMENT POLICY=`p1` */\n1 row in set (0.00 sec)\n\n***************************[ 1. row ]***************************\nTarget           | TABLE test.t3 PARTITION p1\nPlacement        | PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\" FOLLOWERS=4\nScheduling_State | PENDING\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: INSERT ON DUPLICATE KEY UPDATE Syntax in SQL\nDESCRIPTION: SQL syntax for inserting new data or updating existing data if there's a unique key conflict using INSERT ON DUPLICATE KEY UPDATE statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-update-data.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO {table} ({columns}) VALUES ({values})\n    ON DUPLICATE KEY UPDATE {update_column} = {update_value};\n```\n\n----------------------------------------\n\nTITLE: Updating and Inserting Data\nDESCRIPTION: These SQL statements demonstrate updating an existing row and inserting a new row into different tables (`tbl00` and `tbl02`). They illustrate the type of DML statements that are migrated to the downstream TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-shard-merge-optimistic.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nUPDATE `tbl00` SET `Level` = 9 WHERE `ID` = 1;\nINSERT INTO `tbl02` (`ID`, `Name`) VALUES (27, 'Tony');\n```\n```\n\n----------------------------------------\n\nTITLE: Setting API URL for TiDB Cloud\nDESCRIPTION: This example demonstrates how to set the API URL for TiDB Cloud. By default, it's set to 'https://api.tidbcloud.com' and usually doesn't need to be changed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-set.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud config set api-url https://api.tidbcloud.com\n```\n\n----------------------------------------\n\nTITLE: Performing Vector Similarity Search\nDESCRIPTION: SQL query to find the most similar documents using cosine distance calculation between vector embeddings.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-sql.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, document, vec_cosine_distance(embedding, '[1,2,3]') AS distance\nFROM embedded_documents\nORDER BY distance\nLIMIT 3;\n```\n\n----------------------------------------\n\nTITLE: Updating a Data Source with cURL in Shell\nDESCRIPTION: This example shows how to update an existing data source by making a PUT request to the DM API. The request body contains the updated configuration including connection details and relay settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'PUT' \\\n  'http://127.0.0.1:8261/api/v1/sources/mysql-01' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": {\n    \"source_name\": \"mysql-01\",\n    \"host\": \"127.0.0.1\",\n    \"port\": 3306,\n    \"user\": \"root\",\n    \"password\": \"123456\",\n    \"enable_gtid\": false,\n    \"enable\": false,\n    \"flavor\": \"mysql\",\n    \"task_name_list\": [\n      \"task1\"\n    ],\n    \"security\": {\n      \"ssl_ca_content\": \"\",\n      \"ssl_cert_content\": \"\",\n      \"ssl_key_content\": \"\",\n      \"cert_allowed_cn\": [\n        \"string\"\n      ]\n    },\n    \"purge\": {\n      \"interval\": 3600,\n      \"expires\": 0,\n      \"remain_space\": 15\n    },\n    \"relay_config\": {\n      \"enable_relay\": true,\n      \"relay_binlog_name\": \"mysql-bin.000002\",\n      \"relay_binlog_gtid\": \"e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849\",\n      \"relay_dir\": \"./relay_log\"\n    }\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Creating Tables with Collation for Join Compatibility - SQL\nDESCRIPTION: This SQL snippet creates two tables, 't1' and 't2', with different collations which prevents the use of IndexJoin hints. The purpose is to demonstrate how collation can affect join operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_56\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (k varchar(8), key(k)) COLLATE=utf8mb4_general_ci;\nCREATE TABLE t2 (k varchar(8), key(k)) COLLATE=utf8mb4_bin;\nEXPLAIN SELECT /*+ tidb_inlj(t1) */ * FROM t1, t2 WHERE t1.k=t2.k;\n```\n\n----------------------------------------\n\nTITLE: Defining Data Replication Constraints in TiCDC - Plaintext\nDESCRIPTION: The snippet provides a constraint sequence showing the order of data replication based on different types of timestamps in TiCDC: table ResolvedTS, global ResolvedTS, table CheckpointTS, and global CheckpointTS.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-architecture.md#2025-04-18_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\ntable ResolvedTS >= global ResolvedTS >= table CheckpointTS >= global CheckpointTS\n```\n\n----------------------------------------\n\nTITLE: Enabling Post-Restore Operations in TiDB\nDESCRIPTION: Configures TiDB Lightning to automatically perform checksum and ANALYZE operations after the physical import completes, ensuring data integrity and optimization.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_20\n\nLANGUAGE: markdown\nCODE:\n```\nDefault value: \"required\". Starting from v4.0.8, the default value is changed from \"true\" to \"required\".\n```\n\n----------------------------------------\n\nTITLE: Optimized Query with TopN Derivation\nDESCRIPTION: The optimized version of the query after TiDB applies the TopN derivation optimization rule.\nSOURCE: https://github.com/pingcap/docs/blob/master/derive-topn-from-window.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nWITH t_topN AS (SELECT a FROM t1 ORDER BY a LIMIT 3) SELECT * FROM (SELECT ROW_NUMBER() OVER (ORDER BY a) AS rownumber FROM t_topN) dt WHERE rownumber <= 3\n```\n\n----------------------------------------\n\nTITLE: Altering a Table by Adding a Column in TiDB\nDESCRIPTION: SQL command to add a non-null column to an existing table, which creates a new schema version that affects Stale Read with TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/stale-read.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nalter table t1 add column c1 int not null;\n```\n\n----------------------------------------\n\nTITLE: Executing Traffic Replay with Speed Adjustment - Shell\nDESCRIPTION: This shell command uses `tiproxyctl` to replay traffic from a specified input file at twice the normal rate. The `--speed` option allows for adjusting the replay rate.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-traffic-replay.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiproxyctl traffic replay --host 10.0.1.10 --port 3080 --username=\"u1\" --password=\"123456\" --input=\"/tmp/traffic\" --speed=2\n```\n\n----------------------------------------\n\nTITLE: Configuring Physical Import Mode in TiDB Lightning\nDESCRIPTION: TOML configuration to enable the physical import mode by setting the tikv-importer backend to 'local' in tidb-lightning.toml file.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-physical-import-mode.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[tikv-importer]\n# Set the import mode to \"local\" to use the physical import mode.\nbackend = \"local\"\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Using TiUP Client\nDESCRIPTION: Connects to the TiDB database using the TiUP client\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup client\n```\n\n----------------------------------------\n\nTITLE: Fetching MVCC Information with TIDB_MVCC_INFO\nDESCRIPTION: The `TIDB_MVCC_INFO` function returns MVCC information for a specified key, necessary for concurrency control and conflict resolution processes.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_32\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_PRETTY(TIDB_MVCC_INFO('74800000000000007f5f698000000000000001038000000000000001038000000000000001')) AS info\\G\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Region Size for High-QPS Clusters\nDESCRIPTION: This TiKV configuration increases the Region split size to reduce the total number of Regions in a large cluster. Larger Regions help decrease heartbeat overhead and reduce PD server load in high-QPS environments.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices-on-public-cloud.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n[coprocessor]\n  region-split-size = \"288MiB\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up Databases and Tables for Cross-database Binding Example\nDESCRIPTION: Creates two databases (db1 and db2) and two tables in each database to demonstrate cross-database binding functionality in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_23\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE DATABASE db1;\nCREATE TABLE db1.t1 (a INT, KEY(a));\nCREATE TABLE db1.t2 (a INT, KEY(a));\nCREATE DATABASE db2;\nCREATE TABLE db2.t1 (a INT, KEY(a));\nCREATE TABLE db2.t2 (a INT, KEY(a));\n```\n\n----------------------------------------\n\nTITLE: Setting Transaction Idle Timeout in TiDB v7.6.0+\nDESCRIPTION: Use tidb_idle_transaction_timeout to control the idle timeout for transactions in a user session. This provides finer-grained control over transaction timeouts.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-timeouts-in-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_idle_transaction_timeout = 3600;\n```\n\n----------------------------------------\n\nTITLE: Stopping TiCDC Changefeed in Shell\nDESCRIPTION: These commands stop the TiCDC changefeed and check its status. This is done when migrating write services to the downstream cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-mysql.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\n# Stop the changefeed from the upstream cluster to the downstream cluster\ntiup cdc cli changefeed pause -c \"upstream-to-downstream\" --pd=http://172.16.6.122:2379\n# View the changefeed status\ntiup cdc cli changefeed list\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Containers\nDESCRIPTION: Command to start TiDB and ProxySQL containers using Docker Compose.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Querying All Resource Groups\nDESCRIPTION: Demonstrates how to view all resource groups in the system, including the default resource group.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-resource-groups.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.resource_groups;\n```\n\n----------------------------------------\n\nTITLE: Auditing TiUP Cluster Operations in Shell\nDESCRIPTION: This command displays the operation records for the TiDB cluster, including upgrade attempts. It is used to find the ID of a failed upgrade operation for retry purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster audit\n```\n\n----------------------------------------\n\nTITLE: Creating Test Table Schema in SQL\nDESCRIPTION: SQL command to create the 'sbtest' table used for performance testing. The table includes columns for ID, a numeric key, and character fields.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-performance-test.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `sbtest` (\n  `id` int NOT NULL AUTO_INCREMENT,\n  `k` int NOT NULL DEFAULT '0',\n  `c` char(120) CHARSET utf8mb4 COLLATE utf8mb4_bin NOT NULL DEFAULT '',\n  `pad` char(60) CHARSET utf8mb4 COLLATE utf8mb4_bin NOT NULL DEFAULT '',\n  PRIMARY KEY (`id`),\n  KEY `k_1` (`k`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\n```\n\n----------------------------------------\n\nTITLE: Configuring Grafana servers in TiDB Cluster\nDESCRIPTION: Configuration example for setting up Grafana visualization services in a TiDB cluster. This demonstrates how to specify the host machine and custom dashboard directory for Grafana deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-dm-topology-reference.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\ngrafana_servers:\n  - host: 10.0.1.11\n    dashboard_dir: /local/dashboard/dir\n```\n\n----------------------------------------\n\nTITLE: Forcing TiDB Cluster Upgrade by Skipping Leader Eviction\nDESCRIPTION: This command upgrades a TiDB cluster to a specified version while bypassing the processes of transferring PD leader and evicting TiKV leader. The --force flag directly restarts the cluster for version update, which can significantly impact clusters running in production.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster upgrade <cluster-name> <version> --force\n```\n\n----------------------------------------\n\nTITLE: TiDB Session Variable for Backoff Time Control\nDESCRIPTION: Shows the session variable 'tidb_wait_split_region_finish_backoff' that controls the backoff time when splitting Regions in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.1.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n+ Add the `tidb_wait_split_region_finish_backoff` session variable to control the backoff time of splitting Regions [#11166](https://github.com/pingcap/tidb/pull/11166)\n```\n\n----------------------------------------\n\nTITLE: Altering User to Use Default Password Reuse Policy in SQL\nDESCRIPTION: SQL command to modify an existing user to follow the global password reuse policy rather than having an account-level override.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_29\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER 'test'@'localhost'\n  PASSWORD HISTORY DEFAULT\n  PASSWORD REUSE INTERVAL DEFAULT;\n```\n\n----------------------------------------\n\nTITLE: Successful TiFlash max_threads Modification\nDESCRIPTION: SQL confirmation that the TiFlash variable modification has been successful.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Task Success Response in JSON\nDESCRIPTION: Example JSON response indicating successful task startup across worker nodes\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/migrate-data-using-dm.md#2025-04-18_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"result\": true,\n    \"msg\": \"\",\n    \"workers\": [\n        {\n            \"result\": true,\n            \"worker\": \"172.16.10.72:8262\",\n            \"msg\": \"\"\n        },\n        {\n            \"result\": true,\n            \"worker\": \"172.16.10.73:8262\",\n            \"msg\": \"\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Alias Command for Describing TiDB Cloud Serverless Cluster\nDESCRIPTION: Alternative command syntax to get information about a TiDB Cloud Serverless cluster. Functions identically to 'ticloud serverless describe'.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-describe.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless get [flags]\n```\n\n----------------------------------------\n\nTITLE: Installing ProxySQL via YUM\nDESCRIPTION: This command installs ProxySQL using the YUM package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nyum install -y proxysql\n```\n\n----------------------------------------\n\nTITLE: Creating and Granting Roles in TiDB\nDESCRIPTION: SQL commands to create a new role 'analyticsteam', grant permissions, create a user 'jennifer', and assign the role to the user.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-role.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE ROLE analyticsteam;\nGRANT SELECT ON test.* TO analyticsteam;\nCREATE USER jennifer;\nGRANT analyticsteam TO jennifer;\n```\n\n----------------------------------------\n\nTITLE: Adjusting TiCDC Server Log Level\nDESCRIPTION: cURL command to dynamically change the log level of the TiCDC server. Sends a POST request to the log endpoint with a JSON payload specifying the desired log level.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_23\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST -H \"'Content-type':'application/json'\" http://127.0.0.1:8300/api/v1/log -d '{\"log_level\":\"debug\"}'\n```\n\n----------------------------------------\n\nTITLE: SSH Connection Limits Configuration\nDESCRIPTION: Configuration settings for SSH daemon to increase maximum concurrent sessions and startup connections to 1000.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nMaxSessions 1000\nMaxStartups 1000\n```\n\n----------------------------------------\n\nTITLE: Disabling All Default Roles for a User in TiDB\nDESCRIPTION: This snippet shows how to disable all default roles for a user using the `SET DEFAULT ROLE NONE` statement. When `dev1@localhost` logs in, no roles will be automatically enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSET DEFAULT ROLE NONE TO 'dev1'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Configuring Log Progress in TiDB Import\nDESCRIPTION: Defines the frequency of logging import progress messages, enhancing monitoring and debugging during data import operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_26\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- Example: `\"5m\"` -->\n```\n\n----------------------------------------\n\nTITLE: Setting Partition Prune Mode to Dynamic in TiDB\nDESCRIPTION: This SQL statement sets the `tidb_partition_prune_mode` to 'dynamic'. This configuration allows TiDB to use dynamic partition pruning, which can enable more efficient query execution plans, such as IndexJoin, on partitioned tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_78\n\nLANGUAGE: sql\nCODE:\n```\nmysql> set @@tidb_partition_prune_mode = 'dynamic';\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating Target Table Structure in TiDB\nDESCRIPTION: SQL command to create the target table structure (table5) in TiDB database mydb. The 'id' column is changed to a non-unique index to avoid conflicts during merging.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `table5` (\n  `id` bigint NOT NULL,\n  `sid` bigint NOT NULL,\n  `pid` bigint NOT NULL,\n  `comment` varchar(255) DEFAULT NULL,\n  INDEX (`id`),\n  UNIQUE KEY `sid` (`sid`)\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\n```\n\n----------------------------------------\n\nTITLE: Creating Table Schema in SQL\nDESCRIPTION: Example of a table schema creation file content used for data import. The file should be named following the pattern ${db_name}.${table_name}-schema.sql\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/naming-conventions-for-data-import.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test_table (\n    id INTEGER PRIMARY KEY,\n    val VARCHAR(255)\n);\n```\n\n----------------------------------------\n\nTITLE: Describing schema_unused_indexes Table Structure in SQL\nDESCRIPTION: SQL command to view the structure of the schema_unused_indexes table showing its field definitions including column names, types, and properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/sys-schema/sys-schema-unused-indexes.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE SYS;\nDESC SCHEMA_UNUSED_INDEXES;\n```\n\n----------------------------------------\n\nTITLE: SET NAMES/CHARACTER SET Usage Examples in SQL\nDESCRIPTION: Example SQL commands demonstrating how to view and modify character set variables, including showing current settings, setting character set to utf8, and changing to utf8mb4.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-names.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW VARIABLES LIKE 'character_set%';\n+--------------------------+--------------------------------------------------------+\n| Variable_name            | Value                                                  |\n+--------------------------+--------------------------------------------------------+\n| character_sets_dir       | /usr/local/mysql-5.6.25-osx10.8-x86_64/share/charsets/ |\n| character_set_connection | utf8mb4                                                |\n| character_set_system     | utf8                                                   |\n| character_set_results    | utf8mb4                                                |\n| character_set_client     | utf8mb4                                                |\n| character_set_database   | utf8mb4                                                |\n| character_set_filesystem | binary                                                 |\n| character_set_server     | utf8mb4                                                |\n+--------------------------+--------------------------------------------------------+\n8 rows in set (0.01 sec)\n\nmysql> SET NAMES utf8;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SHOW VARIABLES LIKE 'character_set%';\n+--------------------------+--------------------------------------------------------+\n| Variable_name            | Value                                                  |\n+--------------------------+--------------------------------------------------------+\n| character_sets_dir       | /usr/local/mysql-5.6.25-osx10.8-x86_64/share/charsets/ |\n| character_set_connection | utf8                                                   |\n| character_set_system     | utf8                                                   |\n| character_set_results    | utf8                                                   |\n| character_set_client     | utf8                                                   |\n| character_set_server     | utf8mb4                                                |\n| character_set_database   | utf8mb4                                                |\n| character_set_filesystem | binary                                                 |\n+--------------------------+--------------------------------------------------------+\n8 rows in set (0.00 sec)\n\nmysql> SET CHARACTER SET utf8mb4;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SHOW VARIABLES LIKE 'character_set%';\n+--------------------------+--------------------------------------------------------+\n| Variable_name            | Value                                                  |\n+--------------------------+--------------------------------------------------------+\n| character_set_connection | utf8mb4                                                |\n| character_set_system     | utf8                                                   |\n| character_set_results    | utf8mb4                                                |\n| character_set_client     | utf8mb4                                                |\n| character_sets_dir       | /usr/local/mysql-5.6.25-osx10.8-x86_64/share/charsets/ |\n| character_set_database   | utf8mb4                                                |\n| character_set_filesystem | binary                                                 |\n| character_set_server     | utf8mb4                                                |\n+--------------------------+--------------------------------------------------------+\n8 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Running Sysbench Tests using Shell Command\nDESCRIPTION: This shell command executes the Sysbench performance tests on various workloads. It uses the `sysbench run` command, configured with parameters for MySQL connection, database, threads, test duration, and other settings. Placeholders like `${WORKLOAD}`, `${HOST}`, `${PORT}`, `${THREAD}`, and `${PASSWORD}` need to be replaced with actual values.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.5-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_4\n\nLANGUAGE: Shell\nCODE:\n```\n\"sysbench ${WORKLOAD} run \\\n   --mysql-host=${HOST} \\\n   --mysql-port=${PORT} \\\n   --mysql-user=root \\\n   --db-driver=mysql \\\n   --mysql-db=sbtest \\\n   --threads=${THREAD} \\\n   --time=1200 \\\n   --report-interval=10 \\\n   --tables=32 \\\n   --table-size=10000000 \\\n   --mysql-ignore-errors=1062,2013,8028,9007 \\\n   --auto-inc=false \\\n   --mysql-password=${PASSWORD}\"\n```\n\n----------------------------------------\n\nTITLE: Example of Normal Status Output\nDESCRIPTION: This shows example output from `br log status` after resuming a task, indicating a `NORMAL` status. The output includes task details such as name, status, start/end times, storage location, speed, and checkpoint information, confirming the task is running as expected.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n\"br log status\\n\\n● Total 1 Tasks.\\n> #1 <\\n              name: task1\\n            status: ● NORMAL\\n             start: 2022-07-25 13:49:02.868 +0000\\n               end: 2090-11-18 14:07:45.624 +0000\\n           storage: s3://tmp/br-log-backup0ef49055-5198-4be3-beab-d382a2189efb/Log\\n       speed(est.): 15509.75 ops/s\\ncheckpoint[global]: 2022-07-25 14:46:50.118 +0000; gap=6m28s\"\n```\n\n----------------------------------------\n\nTITLE: Collecting DM Cluster Diagnostic Data with Diag\nDESCRIPTION: Command to collect diagnostic data from a DM cluster for a specified time range using the TiUP diag tool.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag collectdm ${dm-cluster-name} -f=\"-4h\" -t=\"-2h\"\n```\n\n----------------------------------------\n\nTITLE: Basic Calibrate Resource Commands\nDESCRIPTION: SQL examples showing basic CALIBRATE RESOURCE usage with default TPCC workload and OLTP_WRITE_ONLY workload specification.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-calibrate-resource.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCALIBRATE RESOURCE;\n\nCALIBRATE RESOURCE WORKLOAD OLTP_WRITE_ONLY;\n```\n\n----------------------------------------\n\nTITLE: Querying with TiKV using EXPLAIN ANALYZE\nDESCRIPTION: This SQL snippet uses the `EXPLAIN ANALYZE` statement with a hint to force the TiDB optimizer to use TiKV (row-based storage) for the query. This allows the user to examine the execution statistics specifically for TiKV and understand its performance characteristics for the given query. The `READ_FROM_STORAGE` hint forces the optimizer to use TiKV for the `games` table.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-htap-quickstart.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n    \"EXPLAIN ANALYZE SELECT /*+ READ_FROM_STORAGE(TIKV[games]) */\\n      YEAR(`release_date`) AS `release_year`,\\n      COUNT(*) AS `games_released`,\\n      AVG(`price`) AS `average_price`,\\n      AVG(`average_playtime_forever`) AS `average_playtime`\\n    FROM\\n      `games`\\n    GROUP BY\\n      `release_year`\\n    ORDER BY\\n      `release_year` DESC;\"\n```\n\n----------------------------------------\n\nTITLE: SQL Table Creation\nDESCRIPTION: This code snippet shows an example SQL statement for creating a table named `User` with columns `ID`, `Name`, `Role`, and `Age`, along with a primary key on `ID` and a secondary index on `Age`. The table definition includes data types for each column.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-computing.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE TABLE User (\\n     ID int,\\n     Name varchar(20),\\n     Role varchar(20),\\n     Age int,\\n     PRIMARY KEY (ID),\\n     KEY idxAge (Age)\\n);\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Primary and Unique Keys\nDESCRIPTION: SQL command to create a table with a primary key and a unique key constraint, which is used in the example to demonstrate potential unique key conflicts during replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE data_table (\n    id BIGINT(20) NOT NULL PRIMARY KEY,\n    value BINARY(16) NOT NULL,\n    UNIQUE KEY value_index (value)\n) CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\n```\n\n----------------------------------------\n\nTITLE: CHARACTER_SETS Table Schema Output\nDESCRIPTION: Shows the output of the DESC command, displaying the column structure of the CHARACTER_SETS table including field names, types, and properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-character-sets.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------+-------------+------+------+---------+-------+\n| Field                | Type        | Null | Key  | Default | Extra |\n+----------------------+-------------+------+------+---------+-------+\n| CHARACTER_SET_NAME   | varchar(32) | YES  |      | NULL    |       |\n| DEFAULT_COLLATE_NAME | varchar(32) | YES  |      | NULL    |       |\n| DESCRIPTION          | varchar(60) | YES  |      | NULL    |       |\n| MAXLEN               | bigint(3)   | YES  |      | NULL    |       |\n+----------------------+-------------+------+------+---------+-------+\n4 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring mpp_exchange_compression_mode in TiDB\nDESCRIPTION: Defines the data compression mode for the MPP Exchange operator within TiDB. This variable influences performance and data compression during MPP execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n-- Default value: `UNSPECIFIED`\nSET SESSION mpp_exchange_compression_mode = 'UNSPECIFIED';\n```\n\n----------------------------------------\n\nTITLE: Using BROADCAST_JOIN Hint for MPP Mode\nDESCRIPTION: The BROADCAST_JOIN hint forces the optimizer to use the Broadcast Join algorithm for specified tables. This hint only takes effect in the MPP mode with TiFlash and can be combined with other join hints.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ BROADCAST_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: DM's Split Rename Operations for pt-osc\nDESCRIPTION: SQL statements that DM splits the rename operation into. DM only executes the second statement after transforming the recorded DDL to apply to the original table name.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nrename test.test4 to test._test4_old;\nrename test._test4_new to test.test4;\n```\n\n----------------------------------------\n\nTITLE: Inserting a New Row and Confirming Data\nDESCRIPTION: This SQL snippet shows how to insert a new row into the table 't' and retrieves the data afterward to confirm the insertion. It illustrates inserting new data while managing existing data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-external-ts.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES (4);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t;\n```\n\n----------------------------------------\n\nTITLE: ADMIN CANCEL DDL Usage Example\nDESCRIPTION: Example showing how to use the ADMIN CANCEL DDL JOBS command with job IDs to cancel running DDL jobs.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-cancel-ddl.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nADMIN CANCEL DDL JOBS job_id [, job_id] ...;\n```\n\n----------------------------------------\n\nTITLE: Multi-Column Index Query in TiDB\nDESCRIPTION: Query demonstrating IndexFullScan when missing prefix condition in multi-column index\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nselect b from t where c=3\n```\n\n----------------------------------------\n\nTITLE: SQL TiFlash Date Functions\nDESCRIPTION: Additional date/time functions supported in TiFlash for enhanced date manipulation capabilities.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.0.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nFROM_DAYS\nTO_DAYS\nTO_SECONDS\nWEEKOFYEAR\n```\n\n----------------------------------------\n\nTITLE: Creating a New Git Branch for Vercel Preview Deployment\nDESCRIPTION: Shell commands to create a new Git branch for a Vercel project that will trigger a preview deployment with TiDB Cloud Serverless branching.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-vercel.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncd tidb-prisma-vercel-demo1\ngit checkout -b new-branch\n```\n\n----------------------------------------\n\nTITLE: EXPLAIN Statement Syntax in EBNF Format\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the EXPLAIN statement in TiDB, showing the various forms including aliases (DESCRIBE, DESC) and options for formatting and connection analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nExplainSym ::=\n    'EXPLAIN'\n|   'DESCRIBE'\n|   'DESC'\n\nExplainStmt ::=\n    ExplainSym ( TableName ColumnName? | 'ANALYZE'? ExplainableStmt | 'FOR' 'CONNECTION' NUM | 'FORMAT' '=' ( stringLit | ExplainFormatType ) ( 'FOR' 'CONNECTION' NUM | ExplainableStmt ) )\n\nExplainableStmt ::=\n    SelectStmt\n|   DeleteFromStmt\n|   UpdateStmt\n|   InsertIntoStmt\n|   ReplaceIntoStmt\n|   UnionStmt\n```\n\n----------------------------------------\n\nTITLE: Adjusting TiFlash Replica Speed Limit with PD Control\nDESCRIPTION: Commands to modify the new replica speed limit for TiFlash using PD Control, which involves progressively increasing the limit to allow faster replication. Key parameters include the cluster version and PD address, which must be replaced with actual values.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd -u http://<PD_ADDRESS>:2379 store limit all engine tiflash 60 add-peer\n```\n\n----------------------------------------\n\nTITLE: Analyzing Query Execution in TiDB SQL\nDESCRIPTION: This SQL command provides a detailed analysis of the query execution, including actual row counts and execution times.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tidb-to-read-tiflash.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nexplain analyze select count(*) from test.t;\n```\n\n----------------------------------------\n\nTITLE: Markdown Table - TiDB Node Status Definitions\nDESCRIPTION: A markdown table defining TiDB node status states and their descriptions for TiDB Cloud Dedicated clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/monitor-tidb-cluster.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| TiDB node status | Description |\n|:--|:--|\n| **Available** | The TiDB node is healthy and available. |\n| **Creating** | The TiDB node is being created. |\n| **Unavailable** | The TiDB node is not available. |\n| **Deleting** | The TiDB node is being deleted. |\n```\n\n----------------------------------------\n\nTITLE: Example Changefeed Status Output\nDESCRIPTION: This is an example output of the `cdc cli processor query` command. It shows the status of the tables being replicated, the operation being performed, the admin job type, and the current position of the processor.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\n{\n  \"status\": {\n    \"tables\": {\n      \"56\": {    # 56 ID of the replication table, corresponding to tidb_table_id of a table in TiDB\n        \"start-ts\": 417474117955485702\n      }\n    },\n    \"operation\": null,\n    \"admin-job-type\": 0\n  },\n  \"position\": {\n    \"checkpoint-ts\": 417474143881789441,\n    \"resolved-ts\": 417474143881789441,\n    \"count\": 0\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running dmctl with TLS Encryption\nDESCRIPTION: Command line example for running dmctl with TLS certificate configuration to connect to a DM cluster securely.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-enable-tls.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./dmctl --master-addr=127.0.0.1:8261 --ssl-ca /path/to/ca.pem --ssl-cert /path/to/client-cert.pem --ssl-key /path/to/client-key.pem\n```\n\n----------------------------------------\n\nTITLE: Setting Up Log Backup in TiKV YAML\nDESCRIPTION: YAML configuration for TiKV log backup, including file size limit, scan rate limit, and thread count.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_31\n\nLANGUAGE: yaml\nCODE:\n```\nlog-backup:\n  enable: true\n  file-size-limit: 256MiB\n  initial-scan-rate-limit: 60MiB\n  max-flush-interval: 3min\n  num-threads: 6\n  temp-path: \"${deploy-dir}/data/log-backup-temp\"\n```\n\n----------------------------------------\n\nTITLE: Using TiUP Help Command in Shell\nDESCRIPTION: This snippet demonstrates the syntax for using the TiUP command-line interface to access help information. By using 'tiup help [command]', users can receive help for specific commands, or for TiUP if no command is specified. There are no options associated with this command, and the output is the corresponding help information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-help.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup help [command]\n```\n\n----------------------------------------\n\nTITLE: Selecting Data from TiDB Table\nDESCRIPTION: This SQL snippet retrieves all rows from the table 't'. It shows how to select and display the data currently stored in the table.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-external-ts.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t;\n```\n\n----------------------------------------\n\nTITLE: Simple TiDB Cloud Login Example\nDESCRIPTION: Example showing how to log into TiDB Cloud using the basic command without any flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-auth-login.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud auth login\n```\n\n----------------------------------------\n\nTITLE: Generating and Executing SQL with TiDB Cloud Chat2Query API in Bash\nDESCRIPTION: Example of calling the /v3/chat2data endpoint to generate and execute SQL statements. This request requires the cluster ID, database name, natural language question, and SQL generation mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user ${PUBLIC_KEY}:${PRIVATE_KEY} --request POST 'https://<region>.data.tidbcloud.com/api/v1beta/app/chat2query-<ID>/endpoint/v3/chat2data'\\\n --header 'content-type: application/json'\\\n --data-raw '{\n    \"cluster_id\": \"10140100115280519574\",\n    \"database\": \"sp500insight\",\n    \"question\": \"<Your question to generate data>\",\n    \"sql_generate_mode\": \"direct\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Configuring TiCDC Servers in YAML\nDESCRIPTION: Example YAML configuration for cdc_servers specifying two TiCDC instances with custom gc-ttl and data directory settings. This configuration defines the hosts, garbage collection time-to-live, and data directories for TiCDC services.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\ncdc_servers:\n  - host: 10.0.1.20\n    gc-ttl: 86400\n    data_dir: \"/cdc-data\"\n  - host: 10.0.1.21\n    gc-ttl: 86400\n    data_dir: \"/cdc-data\"\n```\n\n----------------------------------------\n\nTITLE: Displaying SQL Execution Plan in TiDB\nDESCRIPTION: This snippet shows the complete execution plan of the SQL query, detailing the estimated rows, tasks, access objects, and operator information. The plan outlines how the runtime filter integrates within the query execution flow.\nSOURCE: https://github.com/pingcap/docs/blob/master/runtime-filter.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------------------+-------------+--------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+\n| id                                     | estRows     | task         | access object       | operator info                                                                                                                                 |\n+----------------------------------------+-------------+--------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+\n| TableReader_53                         | 37343.19    | root         |                     | MppVersion: 1, data:ExchangeSender_52                                                                                                         |\n| └─ExchangeSender_52                    | 37343.19    | mpp[tiflash] |                     | ExchangeType: PassThrough                                                                                                                     |\n|   └─Projection_51                      | 37343.19    | mpp[tiflash] |                     | tpcds50.catalog_sales.cs_ship_date_sk                                                                                                         |\n|     └─HashJoin_48                      | 37343.19    | mpp[tiflash] |                     | inner join, equal:[eq(tpcds50.date_dim.d_date_sk, tpcds50.catalog_sales.cs_ship_date_sk)], runtime filter:0[IN] <- tpcds50.date_dim.d_date_sk |\n|       ├─ExchangeReceiver_29(Build)     | 1.00        | mpp[tiflash] |                     |                                                                                                                                               |\n|       │ └─ExchangeSender_28            | 1.00        | mpp[tiflash] |                     | ExchangeType: Broadcast, Compression: FAST                                                                                                    |\n|       │   └─TableFullScan_26           | 1.00        | mpp[tiflash] | table:date_dim      | pushed down filter:eq(tpcds50.date_dim.d_date, 2002-02-01 00:00:00.000000), keep order:false                                                  |\n|       └─Selection_31(Probe)            | 71638034.00 | mpp[tiflash] |                     | not(isnull(tpcds50.catalog_sales.cs_ship_date_sk))                                                                                            |\n|         └─TableFullScan_30             | 71997669.00 | mpp[tiflash] | table:catalog_sales | pushed down filter:empty, keep order:false, runtime filter:0[IN] -> tpcds50.catalog_sales.cs_ship_date_sk                                     |\n+----------------------------------------+-------------+--------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+\n9 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying data from TiDB with mysql.js\nDESCRIPTION: JavaScript code snippet demonstrating how to query a single Player record from TiDB by ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysqljs.md#2025-04-18_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nconn.query('SELECT id, coins, goods FROM players WHERE id = ?;', [1], (err, rows) => {\n   if (err) {\n      console.error(err);\n   } else {\n      console.log(rows[0]);\n   }\n});\n```\n\n----------------------------------------\n\nTITLE: Status Code 500 Response Example - Generic Internal Error\nDESCRIPTION: This code snippet provides an example of a Data Service response with an HTTP status code of 500, signifying a generic internal server error. The `result.code` is 500, and the `message` field indicates \"internal error!\" along with a placeholder for detailed error information. This response implies a server-side issue that requires further investigation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"sql_endpoint\",\n    \"data\": {\n        \"columns\": [],\n        \"rows\": [],\n        \"result\": {\n            \"code\": 500,\n            \"message\": \"internal error! {detailed error}\",\n            \"start_ms\": \"\",\n            \"end_ms\": \"\",\n            \"latency\": \"\",\n            \"row_count\": 0,\n            \"row_affect\": 0,\n            \"limit\": 0\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Specific Table Information in TiDB\nDESCRIPTION: Demonstrates how to query the TABLES information schema to get details about a specific table (mysql.user) using the SELECT statement with a WHERE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tables.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM tables WHERE table_schema='mysql' AND table_name='user'\\G\n```\n\n----------------------------------------\n\nTITLE: Check TiCDC Cluster Health Example\nDESCRIPTION: Example curl request and JSON response for checking the health status of a TiCDC cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v2/health\n```\n\nLANGUAGE: json\nCODE:\n```\n{}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Column Values Based on Type - Go\nDESCRIPTION: The `getColumnValue` function retrieves and converts column values based on their type, providing correct formats for checksum computation. It handles NULL values and specially encoded types like ENUM and SET. This function relies on understanding TiDB schema encoding and requires no additional libraries.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-checksum-verification.md#2025-04-18_snippet_4\n\nLANGUAGE: Go\nCODE:\n```\n// The value is an interface type, which needs to be converted according to the type information provided by the holder.\nfunc getColumnValue(value interface{}, holder map[string]interface{}, mysqlType byte) (interface{}, error) {\n    switch t := value.(type) {\n    // The column with nullable is encoded as a map, and there is only one key-value pair. The key is the type, and the value is the real value. Only the real value is concerned here.\n    case map[string]interface{}:\n        for _, v := range t {\n            value = v\n        }\n    }\n\n    switch mysqlType {\n    case mysql.TypeEnum:\n        // Enum is encoded as a string, which is converted to the int value corresponding to the Enum definition here.\n        allowed := strings.Split(holder[\"allowed\"].(string), \",\")\n        switch t := value.(type) {\n        case string:\n            enum, err := types.ParseEnum(allowed, t, \"\")\n            if err != nil {\n                return nil, errors.Trace(err)\n            }\n            value = enum.Value\n        case nil:\n            value = nil\n        }\n    case mysql.TypeSet:\n        // Set is encoded as a string, which is converted to the int value corresponding to the Set definition here.\n        elems := strings.Split(holder[\"allowed\"].(string), \",\")\n        switch t := value.(type) {\n        case string:\n            s, err := types.ParseSet(elems, t, \"\")\n            if err != nil {\n                return nil, errors.Trace(err)\n            }\n            value = s.Value\n        case nil:\n            value = nil\n        }\n    }\n    return value, nil\n}\n```\n\n----------------------------------------\n\nTITLE: Correcting UNION SELECT FOR UPDATE Behavior in TiDB\nDESCRIPTION: This fix resolves a concurrent race condition that could occur when executing 'UNION SELECT FOR UPDATE' statements. It improves the handling of locking mechanisms in union queries with FOR UPDATE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.5.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nUNION SELECT FOR UPDATE\n```\n\n----------------------------------------\n\nTITLE: Showing Placement Labels in TiDB\nDESCRIPTION: This SQL query demonstrates how to list available placement labels and their values using the `SHOW PLACEMENT LABELS` statement.  The expected output is a table with the label keys and their associated values.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-placement-labels.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW PLACEMENT LABELS;\n```\n\n----------------------------------------\n\nTITLE: Creating Table with AUTO_INCREMENT in MySQL Compatibility Mode\nDESCRIPTION: This SQL statement demonstrates how to create a table with an `AUTO_INCREMENT` column in TiDB using the MySQL compatibility mode.  It sets the `AUTO_ID_CACHE` to `1` which enables the centralized auto-increment ID allocating service. This ensures that IDs monotonically increase on all TiDB instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.5.0.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE TABLE t(a int AUTO_INCREMENT key) AUTO_ID_CACHE 1;\"\n```\n\n----------------------------------------\n\nTITLE: Configuring DDL Flashback Concurrency\nDESCRIPTION: Sets the tidb_ddl_flashback_concurrency variable to control the concurrency of the FLASHBACK CLUSTER operation. This affects the performance of cluster-wide rollback operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_23\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_ddl_flashback_concurrency = 64;\n```\n\n----------------------------------------\n\nTITLE: Refreshing TiUP Component List\nDESCRIPTION: Commands to refresh the TiUP component list and view latest available components\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-troubleshooting-guide.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup list\n```\n\n----------------------------------------\n\nTITLE: Getting Table Schema in TiDB Control - Bash\nDESCRIPTION: Uses the 'schema' command with the 'in' subcommand to retrieve schema information for all tables in a specified database. Demonstrates the default output format and how to filter for specific tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-control.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntidb-ctl schema in <database name>\n```\n\n----------------------------------------\n\nTITLE: Creating a Partitioned Table in TiDB\nDESCRIPTION: SQL statement that creates a table with range partitioning based on the year component of a date column. The table is partitioned into yearly segments from 2016 to 2019, with an additional partition for all other years.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-partitions.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n id BIGINT NOT NULL auto_increment,\n d date NOT NULL,\n pad1 BLOB,\n pad2 BLOB,\n pad3 BLOB,\n PRIMARY KEY (id,d)\n) PARTITION BY RANGE (YEAR(d)) (\n PARTITION p2016 VALUES LESS THAN (2017),\n PARTITION p2017 VALUES LESS THAN (2018),\n PARTITION p2018 VALUES LESS THAN (2019),\n PARTITION p2019 VALUES LESS THAN (2020),\n PARTITION pmax VALUES LESS THAN MAXVALUE\n);\n```\n\n----------------------------------------\n\nTITLE: DOT Graph Execution Plan\nDESCRIPTION: Shows how to generate a DOT graph representation of a query's execution plan, useful for visualizing complex query structures\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN format = \"dot\" SELECT A.a, B.b FROM t A JOIN t B ON A.a > B.b WHERE A.a < 10;\n```\n\n----------------------------------------\n\nTITLE: Output of CLIENT_ERRORS_SUMMARY_BY_HOST table structure in TiDB\nDESCRIPTION: The result set showing the structure of the CLIENT_ERRORS_SUMMARY_BY_HOST table, including field names, data types, null constraints, and other properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/client-errors-summary-by-host.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+---------------+---------------+------+------+---------+-------+\n| Field         | Type          | Null | Key  | Default | Extra |\n+---------------+---------------+------+------+---------+-------+\n| HOST          | varchar(255)  | NO   |      | NULL    |       |\n| ERROR_NUMBER  | bigint(64)    | NO   |      | NULL    |       |\n| ERROR_MESSAGE | varchar(1024) | NO   |      | NULL    |       |\n| ERROR_COUNT   | bigint(64)    | NO   |      | NULL    |       |\n| WARNING_COUNT | bigint(64)    | NO   |      | NULL    |       |\n| FIRST_SEEN    | timestamp     | YES  |      | NULL    |       |\n| LAST_SEEN     | timestamp     | YES  |      | NULL    |       |\n+---------------+---------------+------+------+---------+-------+\n7 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting region to CN for Chinese mainland Clinic Server\nDESCRIPTION: Command to configure Diag to use the CN region for users in the Chinese mainland, which determines the encryption certificate and target service for data uploads.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/quick-start-with-clinic.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag config clinic.region CN\n```\n\n----------------------------------------\n\nTITLE: Generating Certificate Request for Client\nDESCRIPTION: Command to generate a certificate request file for the client (dmctl) certificate.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nopenssl req -new -key client-key.pem -out client-cert.pem\n```\n\n----------------------------------------\n\nTITLE: Using dmctl through TiUP\nDESCRIPTION: Commands to use the DM cluster controller (dmctl) integrated with TiUP. It shows how to run dmctl commands and specify versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ntiup dmctl [args]\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup dmctl:${version} [args]\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup dmctl --master-addr master1:8261 operate-source create /tmp/source1.yml\n```\n\n----------------------------------------\n\nTITLE: Querying MySQL User Table Structure in SQL\nDESCRIPTION: SQL command to describe the structure of the mysql.user table, revealing all columns and their properties in the TiDB system table\nSOURCE: https://github.com/pingcap/docs/blob/master/mysql-schema/mysql-schema-user.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDESC mysql.user;\n```\n\n----------------------------------------\n\nTITLE: Specifying Certificate Path for TLS in TiDB\nDESCRIPTION: Defines the public certificate for the TiDB service. By default, it mirrors the security.cert-path setting.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_17\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- Example: `\"/path/to/lightning.pem\"` -->\n```\n\n----------------------------------------\n\nTITLE: Setting Default UTF8MB4 Collation in TiDB\nDESCRIPTION: Configures the default collation for UTF8MB4 character set, affecting table and database creation, and string literal comparisons\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ndefault_collation_for_utf8mb4 = 'utf8mb4_bin'\n```\n\n----------------------------------------\n\nTITLE: TiDB Slow Query Log Example\nDESCRIPTION: Example of a TiDB slow query log entry showing detailed execution metrics for a slow-running INSERT statement. The log includes timing information, connection details, execution statistics, and query plan information for an insert operation that copies data within the same table.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n# Time: 2019-08-14T09:26:59.487776265+08:00\n# Txn_start_ts: 410450924122144769\n# User@Host: root[root] @ localhost [127.0.0.1]\n# Conn_ID: 3086\n# Exec_retry_time: 5.1 Exec_retry_count: 3\n# Query_time: 1.527627037\n# Parse_time: 0.000054933\n# Compile_time: 0.000129729\n# Rewrite_time: 0.000000003 Preproc_subqueries: 2 Preproc_subqueries_time: 0.000000002\n# Optimize_time: 0.00000001\n# Wait_TS: 0.00001078\n# Process_time: 0.07 Request_count: 1 Total_keys: 131073 Process_keys: 131072 Prewrite_time: 0.335415029 Commit_time: 0.032175429 Get_commit_ts_time: 0.000177098 Local_latch_wait_time: 0.106869448 Write_keys: 131072 Write_size: 3538944 Prewrite_region: 1\n# DB: test\n# Is_internal: false\n# Digest: 50a2e32d2abbd6c1764b1b7f2058d428ef2712b029282b776beb9506a365c0f1\n# Stats: t:pseudo\n# Num_cop_tasks: 1\n# Cop_proc_avg: 0.07 Cop_proc_p90: 0.07 Cop_proc_max: 0.07 Cop_proc_addr: 172.16.5.87:20171\n# Cop_wait_avg: 0 Cop_wait_p90: 0 Cop_wait_max: 0 Cop_wait_addr: 172.16.5.87:20171\n# Cop_backoff_regionMiss_total_times: 200 Cop_backoff_regionMiss_total_time: 0.2 Cop_backoff_regionMiss_max_time: 0.2 Cop_backoff_regionMiss_max_addr: 127.0.0.1 Cop_backoff_regionMiss_avg_time: 0.2 Cop_backoff_regionMiss_p90_time: 0.2\n# Cop_backoff_rpcPD_total_times: 200 Cop_backoff_rpcPD_total_time: 0.2 Cop_backoff_rpcPD_max_time: 0.2 Cop_backoff_rpcPD_max_addr: 127.0.0.1 Cop_backoff_rpcPD_avg_time: 0.2 Cop_backoff_rpcPD_p90_time: 0.2\n# Cop_backoff_rpcTiKV_total_times: 200 Cop_backoff_rpcTiKV_total_time: 0.2 Cop_backoff_rpcTiKV_max_time: 0.2 Cop_backoff_rpcTiKV_max_addr: 127.0.0.1 Cop_backoff_rpcTiKV_avg_time: 0.2 Cop_backoff_rpcTiKV_p90_time: 0.2\n# Mem_max: 525211\n# Disk_max: 65536\n# Prepared: false\n# Plan_from_cache: false\n# Succ: true\n# Plan: tidb_decode_plan('ZJAwCTMyXzcJMAkyMAlkYXRhOlRhYmxlU2Nhbl82CjEJMTBfNgkxAR0AdAEY1Dp0LCByYW5nZTpbLWluZiwraW5mXSwga2VlcCBvcmRlcjpmYWxzZSwgc3RhdHM6cHNldWRvCg==')\nuse test;\ninsert into t select * from t;\n```\n\n----------------------------------------\n\nTITLE: Querying Data with Conditions Using Sequelize ORM in TypeScript\nDESCRIPTION: This code demonstrates how to query the Players table with a condition to find records where coins are greater than 300. It uses Sequelize's findAll method with an operator condition and logs the results.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-sequelize.md#2025-04-18_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nlogger.info('Reading all players with coins > 300...');\nconst allPlayersWithCoinsGreaterThan300 = await playersModel.findAll({\n  where: {\n    coins: {\n      [Op.gt]: 300,\n    },\n  },\n});\nlogger.info('Read all players with coins > 300.');\nlogger.info(allPlayersWithCoinsGreaterThan300.map((p) => p.toJSON()));\n```\n\n----------------------------------------\n\nTITLE: Fix Inconsistent Data with SQL Commands\nDESCRIPTION: Illustrates SQL REPLACE statement to correct inconsistent data rows in a specified chunk range. No external dependencies, but requires database access and relevant privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/sync-diff-inspector-overview.md#2025-04-18_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\n\"-- table: sbtest.sbtest99\\n-- range in sequence: (3690708) < (id) <= (3720581)\\n/\\*\\n  DIFF COLUMNS ╏   `K`   ╏                `C`                 ╏               `PAD`\\n╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╋╍╍╍╍╍╍╍╍╍╋╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╋╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍\\n  source data  ╏ 2501808 ╏ 'hello'                            ╏ 'world'\\n╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╋╍╍╍╍╍╍╍╍╍╋╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╋╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍╍\\n*/\\nREPLACE INTO `sbtest`.`sbtest99`(`id`,`k`,`c`,`pad`) VALUES (3700000,2501808,'hello','world');\"\n```\n\n----------------------------------------\n\nTITLE: Adjusting Maximum Chunk Size in TiDB\nDESCRIPTION: This SQL command sets the maximum number of rows in a chunk during query execution, which can be adjusted based on the workload type for improved performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_max_chunk_size = 128;\n\nSET GLOBAL tidb_max_chunk_size = 4096;\n```\n\n----------------------------------------\n\nTITLE: Checking TiKV MVCC In-Memory Engine Status in SQL\nDESCRIPTION: This SQL snippet checks the TiKV configuration to determine if the MVCC in-memory engine is enabled. It queries the configuration for entries related to 'in-memory-engine' using the 'SHOW CONFIG' statement. The output shows the current configuration values, indicating whether the in-memory engine is active with additional configuration details.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-in-memory-engine.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW CONFIG WHERE Type='tikv' AND Name LIKE 'in-memory-engine\\.\\%';\n\n```\n+------+-----------------+-----------------------------------------------+---------+\n| Type | Instance        | Name                                          | Value   |\n+------+-----------------+-----------------------------------------------+---------+\n| tikv | 127.0.0.1:20160 | in-memory-engine.capacity                     | 5GiB    |\n| tikv | 127.0.0.1:20160 | in-memory-engine.cross-check-interval         | 0s      |\n| tikv | 127.0.0.1:20160 | in-memory-engine.enable                       | true    |\n| tikv | 127.0.0.1:20160 | in-memory-engine.evict-threshold              | 4920MiB |\n| tikv | 127.0.0.1:20160 | in-memory-engine.gc-run-interval              | 3m      |\n| tikv | 127.0.0.1:20160 | in-memory-engine.load-evict-interval          | 5m      |\n| tikv | 127.0.0.1:20160 | in-memory-engine.mvcc-amplification-threshold | 10      |\n| tikv | 127.0.0.1:20160 | in-memory-engine.stop-load-threshold          | 4208MiB |\n+------+-----------------+-----------------------------------------------+---------+\n8 rows in set (0.00 sec)\n```\n```\n\n----------------------------------------\n\nTITLE: Decrypting Data Using AES in SQL\nDESCRIPTION: The `AES_DECRYPT(data, key [,iv])` function decrypts previously encrypted data using the specified key. The optional initialization vector enhances security and is set to NULL by default.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT AES_DECRYPT(0x28409970815CD536428876175F1A4923, 'secret');\n```\n\n----------------------------------------\n\nTITLE: Using JSON_CONTAINS for Value Checking in SQL\nDESCRIPTION: Demonstrates using JSON_CONTAINS function to check if a JSON value exists within a JSON document. Returns 1 if found, 0 if not found.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-search.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_CONTAINS('[\"a\",\"b\",\"c\"]',\"\\\"a\\\"');\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_CONTAINS('[\"a\",\"b\",\"c\"]',\"\\\"e\\\"');\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_CONTAINS('{\"foo\": \"bar\", \"aaa\": 5}','{\"foo\": \"bar\"}');\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_CONTAINS('{\"foo\": \"bar\", \"aaa\": 5}',\"\\\"bar\\\"');\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_CONTAINS('{\"foo\": \"bar\", \"aaa\": 5}',\"\\\"bar\\\"\", '$.foo');\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with HNSW Vector Index in TiDB\nDESCRIPTION: Example of creating a new table with a vector column and defining an HNSW vector index using the VEC_COSINE_DISTANCE function.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-index.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE foo (\n    id       INT PRIMARY KEY,\n    embedding     VECTOR(5),\n    VECTOR INDEX idx_embedding ((VEC_COSINE_DISTANCE(embedding)))\n);\n```\n\n----------------------------------------\n\nTITLE: Setting Store Scheduling Speed in TiKV\nDESCRIPTION: This set of commands allows users to manage the scheduling speed of store operations, including showing current limits, and adjusting them for add and remove peer operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_57\n\nLANGUAGE: bash\nCODE:\n```\nstore limit\n```\n\nLANGUAGE: bash\nCODE:\n```\nstore limit add-peer\n```\n\nLANGUAGE: bash\nCODE:\n```\nstore limit remove-peer\n```\n\nLANGUAGE: bash\nCODE:\n```\nstore limit all 5\n```\n\nLANGUAGE: bash\nCODE:\n```\nstore limit 1 5\n```\n\nLANGUAGE: bash\nCODE:\n```\nstore limit all 5 add-peer\n```\n\nLANGUAGE: bash\nCODE:\n```\nstore limit 1 5 add-peer\n```\n\nLANGUAGE: bash\nCODE:\n```\nstore limit 1 5 remove-peer\n```\n\nLANGUAGE: bash\nCODE:\n```\nstore limit all 5 remove-peer\n```\n\n----------------------------------------\n\nTITLE: RENAME TABLE Syntax Definition in EBNF\nDESCRIPTION: The formal syntax definition for the RENAME TABLE statement using Extended Backus-Naur Form (EBNF) notation.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-rename-table.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nRenameTableStmt ::=\n    'RENAME' 'TABLE' TableToTable ( ',' TableToTable )*\n\nTableToTable ::=\n    TableName 'TO' TableName\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Session Variables\nDESCRIPTION: Specifies different TiDB session variables that control various database features and performance settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_19\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- tidb_enable_clustered_index = \"OFF\" -->\n```\n\n----------------------------------------\n\nTITLE: Cross-Database Table Rename Example\nDESCRIPTION: Example demonstrating how to rename multiple tables across different databases in a single statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-rename-table.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nRENAME TABLE db1.t1 To db2.t2, db3.t3 To db4.t4;\n```\n\n----------------------------------------\n\nTITLE: Configuring mTLS Authentication Parameters for Pulsar in TiCDC\nDESCRIPTION: This TOML snippet shows the configuration parameters required for mTLS authentication.  It includes the certificate path, private key path, and the TLS trust certificates file path.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\n[sink.pulsar-config]\n# Certificate path of the Pulsar mTLS authentication\nauth-tls-certificate-path=\"/data/pulsar/certificate\"\n# Private key path of the Pulsar mTLS authentication\nauth-tls-private-key-path=\"/data/pulsar/certificate.key\"\n# Path to the trusted certificate file of the Pulsar mTLS authentication\ntls-trust-certs-file-path=\"/data/pulsar/tls-trust-certs-file\"\n```\n\n----------------------------------------\n\nTITLE: Modifying RECOMMEND INDEX Option Values in SQL\nDESCRIPTION: This code snippet illustrates how to modify the timeout for the RECOMMEND INDEX options. It shows the command format and confirms an update has been made successfully.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nRECOMMEND INDEX SET timeout='20s';\nQuery OK, 1 row affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating Source Table Structure in MySQL\nDESCRIPTION: SQL command to create the table structure for source tables (table1, table2, table3, table4) in MySQL databases my_db1 and my_db2. The table has an auto-incremented primary key 'id' and a unique key 'sid'.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `table1` (\n  `id` bigint NOT NULL AUTO_INCREMENT,\n  `sid` bigint NOT NULL,\n  `pid` bigint NOT NULL,\n  `comment` varchar(255) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `sid` (`sid`)\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\n```\n\n----------------------------------------\n\nTITLE: Configuring TiSpark to Read from TiFlash in Spark Shell\nDESCRIPTION: This Scala code snippet sets the configuration for TiSpark to read from TiFlash replicas in real-time within a Spark shell session.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tispark-to-read-tiflash.md#2025-04-18_snippet_2\n\nLANGUAGE: scala\nCODE:\n```\nspark.conf.set(\"spark.tispark.isolation_read_engines\", \"tiflash\")\n```\n\n----------------------------------------\n\nTITLE: Generating Test Data with Sysbench\nDESCRIPTION: Bash command using Sysbench to generate test data for full import benchmark. It creates tables and populates them with 50 million rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-performance-test.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsysbench --test=oltp_insert --tables=4 --mysql-host=172.16.4.40 --mysql-port=3306 --mysql-user=root --mysql-db=dm_benchmark --db-driver=mysql --table-size=50000000 prepare\n```\n\n----------------------------------------\n\nTITLE: Viewing DM-master Command-line Parameters\nDESCRIPTION: Shows how to display the available command-line parameters for DM-master using the --help flag.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-binary.md#2025-04-18_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\n./dm-master --help\n```\n\n----------------------------------------\n\nTITLE: Customizing Gitpod Docker Image for TiDB Development\nDESCRIPTION: This Dockerfile extends the Gitpod Java 17 workspace image by installing MySQL client and TiUP, which are necessary for TiDB development.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-playground-gitpod.md#2025-04-18_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM gitpod/workspace-java-17\n\nRUN sudo apt install mysql-client -y\nRUN curl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP DM Help Command in Shell\nDESCRIPTION: Shows the syntax for accessing help information in TiUP DM. The command accepts an optional command parameter to view specific command help, and supports the -h or --help flag to print help information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-help.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm help [command] [flags]\n```\n\n----------------------------------------\n\nTITLE: Complete Titan Configuration Example for TiKV\nDESCRIPTION: A comprehensive example of Titan configuration showing various parameters including rate limiting, GC settings, blob size threshold, compression settings, and other performance-related options.\nSOURCE: https://github.com/pingcap/docs/blob/master/storage-engine/titan-configuration.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[rocksdb]\nrate-bytes-per-sec = 0\n\n[rocksdb.titan]\nenabled = true\nmax-background-gc = 1\n\n[rocksdb.defaultcf.titan]\nmin-blob-size = \"32KB\"\nblob-file-compression = \"zstd\"\nzstd-dict-size = \"16KB\"\ndiscardable-ratio = 0.5\nblob-run-mode = \"normal\"\nlevel-merge = false\n```\n\n----------------------------------------\n\nTITLE: Creating a Global Binding and Checking Its Usage in TiDB\nDESCRIPTION: Example of creating a global binding with an index hint and then checking if it was used by querying the system variable last_plan_from_binding.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a global binding\nCREATE GLOBAL BINDING for\n    SELECT * FROM t\nUSING\n    SELECT /*+ USE_INDEX(t, idx_a) */ * FROM t;\n\nSELECT * FROM t;\nSELECT @@[SESSION.]last_plan_from_binding;\n```\n\n----------------------------------------\n\nTITLE: Custom Configuration for Online Schema Change Tools\nDESCRIPTION: YAML configuration example for customizing DM's handling of online schema changes with modified naming patterns for temporary tables. This allows for the use of customized or alternative schema change tools.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\nonline-ddl: true\nshadow-table-rules: [\"^_(.+)_(?:pcnew)$\"]\ntrash-table-rules: [\"^_(.+)_(?:pcold)$\"]\n```\n\n----------------------------------------\n\nTITLE: Simulating Service Workload with Sysbench\nDESCRIPTION: Command to simulate continuous write workload to three tables using sysbench, with 10 workers and a maximum TPS of 100.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nsysbench oltp_write_only --config-file=./tidb-config --tables=3 run\n```\n\n----------------------------------------\n\nTITLE: Split Statement Result Example in TiDB\nDESCRIPTION: Example output of a successful SPLIT statement in TiDB, showing the number of newly split regions and the scatter completion ratio.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\n+--------------------+----------------------+\n| TOTAL_SPLIT_REGION | SCATTER_FINISH_RATIO |\n+--------------------+----------------------+\n| 4                  | 1.0                  |\n+--------------------+----------------------+\n```\n\n----------------------------------------\n\nTITLE: Master Key Encrypted PITR Restore Command\nDESCRIPTION: Demonstrates how to restore log backup data that was encrypted using a master key.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_23\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore point --pd=\"${PD_IP}:2379\" \n--storage='s3://backup-101/logbackup?access-key=${ACCESS-KEY}&secret-access-key=${SECRET-ACCESS-KEY}' \n--full-backup-storage='s3://backup-101/snapshot-202205120000?access-key=${ACCESS-KEY}&secret-access-key=${SECRET-ACCESS-KEY}' \n--crypter.method aes128-ctr \n--crypter.key 0123456789abcdef0123456789abcdef \n--master-key-crypter-method aes128-ctr \n--master-key \"local:///path/to/master.key\"\n```\n\n----------------------------------------\n\nTITLE: Importing DM Cluster Configuration\nDESCRIPTION: This snippet shows how to use the 'config import' command to import data source and task configurations from a specified directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-export-import-config.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nconfig import -d /tmp/configs\n```\n\n----------------------------------------\n\nTITLE: Describing PROCESSLIST Table Schema\nDESCRIPTION: Shows the structure and column definitions of the PROCESSLIST table in the information_schema database.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-processlist.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC processlist;\n```\n\n----------------------------------------\n\nTITLE: Starting WordPress Docker Container\nDESCRIPTION: Docker Compose command to launch WordPress and its associated services in detached mode, using the configured TiDB Cloud Serverless connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/dev-guide-wordpress.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Configuring Region Merge Settings in TiDB\nDESCRIPTION: Commands to enable and configure Region Merge by setting parameters for maximum merge region size, keys, and scheduling limit.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/massive-regions-best-practices.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconfig set max-merge-region-size 54\nconfig set max-merge-region-keys 540000\nconfig set merge-schedule-limit 8\n```\n\n----------------------------------------\n\nTITLE: Killing TiDB Connection\nDESCRIPTION: Improves the execution speed of the kill tidb conn_id command to terminate a specific TiDB connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.17.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nKILL TIDB [CONNECTION | QUERY] connection_id;\n```\n\n----------------------------------------\n\nTITLE: Setting max-zombie-rounds for balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command sets the maximum number of heartbeats for an operator to be considered as pending influence. It affects how many operators are included in pending influence calculations.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_36\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-hot-region-scheduler set max-zombie-rounds 3\n```\n\n----------------------------------------\n\nTITLE: Filtering SQL Plan Baseline by Execution Frequency\nDESCRIPTION: Configure frequency-based filtering to control which SQL statements are captured based on their execution count.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_31\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO mysql.capture_plan_baselines_blacklist(filter_type, filter_value) VALUES('frequency', '2');\n```\n\n----------------------------------------\n\nTITLE: Sample Confluent Platform Sink Configuration with Avro Protocol\nDESCRIPTION: This code snippet illustrates how to configure a sink URI for the Confluent Platform using the Avro protocol. It includes relevant parameters such as the schema registry and replication factor.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"kafka://127.0.0.1:9092/topic-name?&protocol=avro&replication-factor=3\" --schema-registry=\"http://127.0.0.1:8081\" --config changefeed_config.toml\n```\n\n----------------------------------------\n\nTITLE: Defining Table-Level and Global Constraints for Checkpoints in TiCDC - Plaintext\nDESCRIPTION: This code establishes relationships between different checkpoint timestamps in TiCDC, namely table CheckpointTS and global CheckpointTS. It shows how data replication constraints are defined, ensuring that data smaller than global ResolvedTS is replicated.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-architecture.md#2025-04-18_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\ntable CheckpointTS >= global CheckpointTS\n```\n\n----------------------------------------\n\nTITLE: Deleting a store in TiDB PD\nDESCRIPTION: This command marks a store for deletion in the TiDB cluster, identified by its store ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_49\n\nLANGUAGE: bash\nCODE:\n```\nstore delete 1\n```\n\n----------------------------------------\n\nTITLE: Creating Valid Partitioned Table After Modifications - SQL\nDESCRIPTION: This SQL snippet presents a corrected table creation statement for 't3', where the unique keys now satisfy the partitioning requirement by including all necessary columns, making the DDL valid.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_56\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCREATE TABLE t3 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    UNIQUE KEY (col1, col2, col3),\n    UNIQUE KEY (col1, col3)\n)\nPARTITION BY HASH(col1 + col3)\n    PARTITIONS 4;\n```\n```\n\n----------------------------------------\n\nTITLE: Granting Specific Administrative Privileges in TiDB\nDESCRIPTION: Grant only RELOAD and PROCESS privileges to the admin user, restricting their access to specific administrative tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nGRANT RELOAD,PROCESS ON *.* TO 'admin'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: TiCDC Sink Dispatcher Configuration\nDESCRIPTION: Defines the dispatcher rules for the sink. This configuration example shows how to route all tables from all schemas to a topic named \"tidb_{schema}_{table}\" in Kafka.  This is usually part of `changefeed_config.toml`.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-protocol.md#2025-04-18_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n[sink]\ndispatchers = [\n {matcher = ['*.*'], topic = \"tidb_{schema}_{table}\"},\n]\n```\n\n----------------------------------------\n\nTITLE: Starting a Replication Task with cURL (DM API)\nDESCRIPTION: This example shows how to start a previously created replication task using the DM API. The POST request initiates the replication process for the specified task.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_32\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'POST' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1/start' \\\n  -H 'accept: */*'\n```\n\n----------------------------------------\n\nTITLE: Setting max_allowed_packet in TiDB\nDESCRIPTION: This variable defines the maximum packet size allowed for transmission between server and client in TiDB. Its integer value must be a multiple of 1024 and falls within the defined range.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n-- Default value: `67108864`\n-- Range: `[1024, 1073741824]`\nSET GLOBAL max_allowed_packet = 67108864;\n```\n\n----------------------------------------\n\nTITLE: Getting Task Status with cURL (DM API)\nDESCRIPTION: This example shows how to retrieve the status information of a specific replication task. The GET request returns detailed information about the task's current state and progress.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_34\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1/status?stage=running' \\\n  -H 'accept: application/json'\n```\n\n----------------------------------------\n\nTITLE: Configuring NGINX Path-Specific Reverse Proxy for TiDB Dashboard\nDESCRIPTION: NGINX configuration for proxying TiDB Dashboard under a specific path (/foo/). Includes server block with location-based routing.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_9\n\nLANGUAGE: nginx\nCODE:\n```\nserver {\n  listen 8033;\n  location /foo/ {\n    proxy_pass http://192.168.0.123:2379/dashboard/;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating User with Password Reuse Interval in SQL\nDESCRIPTION: SQL command to create a new user with a password reuse policy that prohibits reusing passwords used within the last 365 days.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_24\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE USER 'test'@'localhost' PASSWORD REUSE INTERVAL 365 DAY;\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB Cloud using Python\nDESCRIPTION: This code snippet demonstrates how to execute a query against a TiDB Cloud Dedicated cluster using Python's `mysqlclient` library. It establishes a connection with TLS configured, executes a SELECT DATABASE() query, and prints the database name.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tls-connect-to-dedicated.md#2025-04-18_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport MySQLdb\n\nconnection = MySQLdb.connect(host=\"tidb.srgnqxji5bc.clusters.staging.tidb-cloud.com\", port=4000, user=\"root\", password=\"<your_password>\", database=\"test\", ssl_mode=\"VERIFY_IDENTITY\", ssl={\"ca\": \"ca.pem\"})\n\nwith connection:\n    with connection.cursor() as cursor:\n        cursor.execute(\"SELECT DATABASE();\")\n        m = cursor.fetchone()\n        print(m[0])\n```\n\n----------------------------------------\n\nTITLE: Column Data Format for ENUM/SET\nDESCRIPTION: Shows the format for ENUM/SET columns. It adds the `allowed` parameter in the connect parameters to specify the allowed values for the ENUM/SET.  The Avro type is `string`.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-protocol.md#2025-04-18_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\":\"{{ColumnName}}\",\n    \"type\":{\n        \"connect.parameters\":{\n            \"tidb_type\":\"ENUM/SET\",\n            \"allowed\":\"a,b,c\"\n        },\n        \"type\":\"string\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Repairing Metadata with pd-recover in Shell\nDESCRIPTION: Utilizes pd-recover to modify metadata on a minority PD node to correct allocation IDs and TSO services. This step ensures successful recovery by managing rollback prevention.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-recover.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n./bin/pd-recover --from-old-member --endpoints=http://127.0.0.1:2379 # Specify the corresponding PD address\n```\n\n----------------------------------------\n\nTITLE: JSON_LENGTH Root Level Query\nDESCRIPTION: Shows how to use JSON_LENGTH() to count items at the root level of a JSON document.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-return.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_LENGTH('{\"weather\": {\"current\": \"sunny\", \"tomorrow\": \"cloudy\"}}','$');\n```\n\n----------------------------------------\n\nTITLE: Running TPC-C Stress Test with go-tpc\nDESCRIPTION: This shell command conducts a stress test on the TiDB Cloud Dedicated cluster using the `go-tpc tpcc` tool. It specifies parameters such as host, port, warehouses, threads, test duration, database name, and password. `${HOST}`, `${THREAD}`, and `${PASSWORD}` need to be replaced by actual values.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ngo-tpc tpcc --host ${HOST} -P 4000 --warehouses 1000 run -D tpcc -T ${THREAD} --time 2h0m0s -p ${PASSWORD} --ignore-error\n```\n\n----------------------------------------\n\nTITLE: Using JSON_DEPTH to Find Maximum Depth\nDESCRIPTION: Demonstrates how to use JSON_DEPTH() function to determine the maximum depth of a JSON document structure.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-return.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_DEPTH('{\"weather\": {\"current\": \"sunny\"}}');\n```\n\n----------------------------------------\n\nTITLE: Examining Large Transaction Details in TiDB Log\nDESCRIPTION: These log entries provide information about a large transaction, including its size, number of keys affected, and the SQL statement that caused it. This information is vital for identifying the root cause of stale read issues related to long-running transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-stale-read.md#2025-04-18_snippet_5\n\nLANGUAGE: log\nCODE:\n```\n[2023/07/17 21:16:18.287 +08:00] [INFO] [2pc.go:685] [\"[BIG_TXN]\"] [session=2826881778407440457] [\"key sample\"=74800000000000006a5f728000000000000000] [size=319967171] [keys=10000000] [puts=10000000] [dels=0] [locks=0] [checks=0] [txnStartTS=442918429687808001]\n\n[2023/07/17 21:16:22.703 +08:00] [WARN] [expensivequery.go:145] [expensive_query] [cost_time=60.047172498s] [cop_time=0.004575113s] [process_time=15.356963423s] [wait_time=0.017093811s] [request_count=397] [total_keys=20000398] [process_keys=10000000] [num_cop_tasks=397] [process_avg_time=0.038682527s] [process_p90_time=0.082608262s] [process_max_time=0.116321331s] [process_max_addr=192.168.31.244:20160] [wait_avg_time=0.000043057s] [wait_p90_time=0.00004007s] [wait_max_time=0.00075014s] [wait_max_addr=192.168.31.244:20160] [stats=t:442918428521267201] [conn=2826881778407440457] [user=root] [database=test] [table_ids=\"[106]\"] [txn_start_ts=442918429687808001] [mem_max=\"2513773983 Bytes (2.34 GB)\"] [sql=\"update t set b = b + 1\"]\n```\n\n----------------------------------------\n\nTITLE: Left Join Predicate Push Down Limitation\nDESCRIPTION: Shows how predicates on inner tables in outer joins cannot be pushed down due to potential result modification\nSOURCE: https://github.com/pingcap/docs/blob/master/predicate-push-down.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id int primary key, a int not null);\ncreate table s(id int primary key, a int not null);\nexplain select * from t left join s on t.a = s.a where s.a is null;\n```\n\n----------------------------------------\n\nTITLE: Time-based Splitting of Index Data in SQL\nDESCRIPTION: This SQL statement splits the index 'idx2' in table 't' into 10 Regions by year, specifying the time range from January 1, 2010 to January 1, 2020.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT TABLE t INDEX idx2 BETWEEN (\"2010-01-01 00:00:00\") AND (\"2020-01-01 00:00:00\") REGIONS 10;\n```\n\n----------------------------------------\n\nTITLE: Configuring Load Base Split with TiKV HTTP API\nDESCRIPTION: Shows how to modify Load Base Split parameters including QPS threshold, byte threshold, and CPU usage threshold using TiKV's HTTP API.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-load-base-split.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST \"http://ip:status_port/config\" -H \"accept: application/json\" -d '{\"split.qps-threshold\":\"1500\"}'\ncurl -X POST \"http://ip:status_port/config\" -H \"accept: application/json\" -d '{\"split.byte-threshold\":\"15728640\"}'\ncurl -X POST \"http://ip:status_port/config\" -H \"accept: application/json\" -d '{\"split.region-cpu-overload-threshold-ratio\":\"0.5\"}'\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning Metrics Port in TOML\nDESCRIPTION: Configure the HTTP port for debugging and Prometheus metrics collection in the TiDB Lightning configuration file\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/monitor-tidb-lightning.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\\n# HTTP port for debugging and Prometheus metrics pulling (0 to disable)\\npprof-port = 8289\n```\n\n----------------------------------------\n\nTITLE: Inserting Rows into the TiDB Table\nDESCRIPTION: This SQL snippet inserts three rows of integer values into the table 't'. It demonstrates how to add data to the table structure defined previously.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-external-ts.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES (1), (2), (3);\n```\n\n----------------------------------------\n\nTITLE: Starting TiUP Playground Environment\nDESCRIPTION: Command to launch a local TiDB environment with DM components for testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground --dm-master 1 --dm-worker 1 --tiflash 0 --without-monitor\n```\n\n----------------------------------------\n\nTITLE: Creating Products Table and Inserting Sample Data in TiDB\nDESCRIPTION: SQL script that creates a sample 'products' table with three columns and inserts three sample product records with their IDs, names, and prices.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-with-mysql-cli.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a table in your TiDB database\nCREATE TABLE products (\n    product_id INT PRIMARY KEY,\n    product_name VARCHAR(255),\n    price DECIMAL(10, 2)\n);\n\n-- Insert sample data into the table\nINSERT INTO products (product_id, product_name, price) VALUES\n    (1, 'Laptop', 999.99),\n    (2, 'Smartphone', 499.99),\n    (3, 'Tablet', 299.99);\n```\n\n----------------------------------------\n\nTITLE: Describing the CLIENT_ERRORS_SUMMARY_BY_HOST table structure in TiDB\nDESCRIPTION: This SQL command describes the structure of the CLIENT_ERRORS_SUMMARY_BY_HOST table in the INFORMATION_SCHEMA database, showing all available fields and their data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/client-errors-summary-by-host.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC CLIENT_ERRORS_SUMMARY_BY_HOST;\n```\n\n----------------------------------------\n\nTITLE: S3 Storage Traffic Capture Example\nDESCRIPTION: SQL example demonstrating how to capture traffic for 10 minutes and save it to an S3 storage bucket.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-traffic-capture.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nTRAFFIC CAPTURE TO \"s3://external/traffic?access-key=${access-key}&secret-access-key=${secret-access-key}\" DURATION=\"10m\";\n```\n\n----------------------------------------\n\nTITLE: Displaying S3 File URI Format for Parquet Import\nDESCRIPTION: Shows the expected format for Amazon S3 URIs when importing Parquet files, with examples for both single files and folders.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-parquet-files.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\ns3://[bucket_name]/[data_source_folder]/[file_name].parquet\n```\n\n----------------------------------------\n\nTITLE: Executing SQL Explain Plan for Join with Collation Incompatibility - SQL\nDESCRIPTION: This SQL snippet provides the execution plan of a join operation that fails to utilize the INL_JOIN hint due to collation mismatch. It aims to illustrate how the optimizer handles such scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_57\n\nLANGUAGE: sql\nCODE:\n```\n+-----------------------------+----------+-----------+----------------------+----------------------------------------------+\n| id                          | estRows  | task      | access object        | operator info                                |\n+-----------------------------+----------+-----------+----------------------+----------------------------------------------+\n| HashJoin_19                 | 12487.50 | root      |                      | inner join, equal:[eq(test.t1.k, test.t2.k)] |\n| ├─IndexReader_24(Build)     | 9990.00  | root      |                      | index:IndexFullScan_23                       |\n| │ └─IndexFullScan_23        | 9990.00  | cop[tikv] | table:t2, index:k(k) | keep order:false, stats:pseudo               |\n| └─IndexReader_22(Probe)     | 9990.00  | root      |                      | index:IndexFullScan_21                       |\n|   └─IndexFullScan_21        | 9990.00  | cop[tikv] | table:t1, index:k(k) | keep order:false, stats:pseudo               |\n+-----------------------------+----------+-----------+----------------------+----------------------------------------------+\n5 rows in set, 1 warning (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW ANALYZE STATUS Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the SHOW ANALYZE STATUS statement in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-analyze-status.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nShowAnalyzeStatusStmt ::= 'SHOW' 'ANALYZE' 'STATUS' ShowLikeOrWhereOpt\n\nShowLikeOrWhereOpt ::= 'LIKE' SimpleExpr | 'WHERE' Expression\n```\n\n----------------------------------------\n\nTITLE: Checking PD Replication Configuration\nDESCRIPTION: This command checks the PD (Placement Driver) configuration to determine if the Placement Rules feature is enabled. The Placement Rules feature is essential for managing data placement in TiDB, including the replication of data to TiFlash nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n```shell\necho 'config show replication' | /path/to/pd-ctl -u http://${pd-ip}:${pd-port}\n```\n```\n\n----------------------------------------\n\nTITLE: SQL Statement Types Supported in Fast Plan Binding\nDESCRIPTION: List of SQL statement types that are supported for fast plan binding functionality in TiDB Dashboard. These include basic DML operations but exclude certain complex query patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-statement-details.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\nDELETE\nUPDATE\nINSERT\nREPLACE\n```\n\n----------------------------------------\n\nTITLE: Altering Table to Add Unique Column in SQL\nDESCRIPTION: Attempts to add a new column with a UNIQUE constraint to an existing table in the upstream database using ALTER TABLE. TiDB does not support this DDL operation directly, interrupting the migration task. It requires a connection to the database and permissions to modify the table schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE `db1`.`tbl1` ADD COLUMN new_col INT UNIQUE;\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for General TiDB Cloud Connection in Vercel\nDESCRIPTION: These environment variables are automatically added to your Vercel project when using the TiDB Cloud Vercel integration for a general connection to a TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-vercel.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nTIDB_HOST\nTIDB_PORT\nTIDB_USER\nTIDB_PASSWORD\nTIDB_DATABASE\n```\n\n----------------------------------------\n\nTITLE: Environment Configuration\nDESCRIPTION: Example environment variables configuration for API key and database connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-jinaai-embedding.md#2025-04-18_snippet_1\n\nLANGUAGE: dotenv\nCODE:\n```\nJINAAI_API_KEY=\"****\"\nTIDB_DATABASE_URL=\"mysql+pymysql://<prefix>.root:<password>@gateway01.<region>.prod.aws.tidbcloud.com:4000/test?ssl_ca=/etc/ssl/cert.pem&ssl_verify_cert=true&ssl_verify_identity=true\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating AUTO_INCREMENT Monotonicity in TiDB\nDESCRIPTION: Example showing how AUTO_INCREMENT values are monotonically increasing when inserting multiple rows in a single statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a int PRIMARY KEY AUTO_INCREMENT, b timestamp NOT NULL DEFAULT NOW());\nINSERT INTO t (a) VALUES (NULL), (NULL), (NULL);\nSELECT * FROM t;\n```\n\n----------------------------------------\n\nTITLE: Viewing Background Task Configuration in SQL\nDESCRIPTION: This SQL query fetches the configuration details of the `default` resource group and displays its background task settings. It outputs data including task types and utilization limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-background-tasks.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.resource_groups WHERE NAME=\"default\";\n```\n\n----------------------------------------\n\nTITLE: Running YCSB Workload for Titan Storage Engine Testing\nDESCRIPTION: Bash command for running the YCSB workloada benchmark to test Titan storage engine performance with large record values, comparing baseline and optimized configurations with min-blob-size adjustments.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngo-ycsb run mysql -P /ycsb/workloads/workloada -p {host} -p mysql.port={port} -p mysql.db=test -p threadcount=100 -p recordcount=5000000 -p operationcount=5000000 -p workload=core -prequestdistribution=uniform -p fieldcount=31 -p fieldlength=1024\n```\n\n----------------------------------------\n\nTITLE: Enabling Default Roles in the Current Session in TiDB\nDESCRIPTION: This snippet demonstrates how to enable the default roles for the current session using the `SET ROLE DEFAULT` statement. This activates the roles that were previously set as default for the user.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nSET ROLE DEFAULT\n```\n\n----------------------------------------\n\nTITLE: Querying Global Index Information in TiDB\nDESCRIPTION: This SQL query demonstrates how to retrieve information about global indexes from the INFORMATION_SCHEMA.TIDB_INDEXES system table in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_65\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.TIDB_INDEXES WHERE table_name='t1';\n```\n\n----------------------------------------\n\nTITLE: Bug Fix - TiDB Schema Operations\nDESCRIPTION: Fixes for schema-related operations including DDL handling, view creation and usage, and partition management with IN expressions.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.12.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE VIEW /* Fixed view usage after creation */\nPARTITION /* Fixed IN expression handling */\nYEAR /* Fixed NULL comparison */\nauto_random /* Fixed connection handling */\n```\n\n----------------------------------------\n\nTITLE: Defining Decimal Type in JSON Schema\nDESCRIPTION: This JSON snippet illustrates the schema structure for decimal data types in TiDB, including the column name, type, precision, and scale.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_13\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"ColumnName\":\"COL1\",\n    \"ColumnType\":\"{DT} [UNSIGNED]\",\n    \"ColumnPrecision\":\"{M}\",\n    \"ColumnScale\":\"{D}\"\n}\n```\n\n----------------------------------------\n\nTITLE: Show Table Creation with Invisible Index\nDESCRIPTION: SQL command and output showing the table structure with an invisible index after modification.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-index.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE t1;\n```\n\n----------------------------------------\n\nTITLE: DECIMAL Type Declaration in SQL\nDESCRIPTION: Two equivalent syntaxes for declaring DECIMAL/NUMERIC type with optional precision, scale, unsigned flag and zero-fill option\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-numeric.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nDECIMAL[(M[,D])] [UNSIGNED] [ZEROFILL]\n```\n\nLANGUAGE: sql\nCODE:\n```\nNUMERIC[(M[,D])] [UNSIGNED] [ZEROFILL]\n```\n\n----------------------------------------\n\nTITLE: Describing RUNAWAY_WATCHES Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the RUNAWAY_WATCHES table, showing its columns and their properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-runaway-watches.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC RUNAWAY_WATCHES;\n```\n\n----------------------------------------\n\nTITLE: Auto-Increment Insert Sequence with Default Cache\nDESCRIPTION: Example showing ID generation with default AUTO_ID_CACHE 0, demonstrating larger gaps between sequences across instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES (); -- Returns ID 1\nINSERT INTO t VALUES (); -- Returns ID 2\n-- New TiDB instance allocates next batch\nINSERT INTO t VALUES (); -- Returns ID 30001\n```\n\n----------------------------------------\n\nTITLE: Query Execution Plan Analysis in TiDB Before Optimization\nDESCRIPTION: Shows the execution plan of a join query between supplier and lineitem tables before changing the broadcast join threshold. Note that ExchangeType is HashPartition, indicating Shuffled Hash Join is being used.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain analyze select max(l_shipdate), max(l_commitdate), max(l_receiptdate) from supplier,lineitem where s_suppkey = l_suppkey;\n```\n\n----------------------------------------\n\nTITLE: Set Global Variable for Statistics Collection (SQL)\nDESCRIPTION: This SQL statement sets the global variable `tidb_analyze_column_options` to `ALL`. This ensures that the statistics collection process considers all relevant options, which is crucial for the TiDB optimizer to generate optimal execution plans, especially in OLAP scenarios. Setting this to `ALL` is introduced in v8.3.0 of TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nset global tidb_analyze_column_options='ALL';\n```\n\n----------------------------------------\n\nTITLE: Complex Join Query with Aggregation\nDESCRIPTION: SQL query that performs a join between supplier and lineitem tables and calculates maximum dates. Demonstrates MPP execution with TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nexplain analyze select max(l_shipdate), max(l_commitdate), max(l_receiptdate) from supplier,lineitem where s_suppkey = l_suppkey;\n```\n\n----------------------------------------\n\nTITLE: Creating and Inserting into DECIMAL Column in TiDB\nDESCRIPTION: Shows the creation of a table with a DECIMAL column and insertion of values to demonstrate rounding behavior in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/precision-math.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t (d DECIMAL(10,0));\n\nINSERT INTO t VALUES(2.5),(2.5E0);\n\nSELECT d FROM t;\n```\n\n----------------------------------------\n\nTITLE: Adjusting TiFlash Replicas for a Table in TiDB\nDESCRIPTION: This SQL command adjusts the number of TiFlash replicas for a specific table before scaling in TiFlash nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE <db-name>.<table-name> SET tiflash replica 'new_replica_num';\n```\n\n----------------------------------------\n\nTITLE: Starting a Transaction in TiDB SQL\nDESCRIPTION: This snippet shows how to start different types of transactions in TiDB using SQL commands. It includes options for default (pessimistic), explicitly pessimistic, and optimistic transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN\nBEGIN PESSIMISTIC\nBEGIN OPTIMISTIC\n```\n\n----------------------------------------\n\nTITLE: Checking CPU Frequency Policy\nDESCRIPTION: Command to view the current CPU frequency policy using the cpupower tool.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_31\n\nLANGUAGE: bash\nCODE:\n```\ncpupower frequency-info --policy\n```\n\n----------------------------------------\n\nTITLE: Using EXPLAIN ANALYZE for Vector Search Performance Analysis in TiDB\nDESCRIPTION: This SQL example demonstrates how to use the EXPLAIN ANALYZE statement to get detailed performance information about vector index usage. The query performs a cosine distance calculation and returns execution metrics including index loading time, search duration, and node statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-index.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n[tidb]> EXPLAIN ANALYZE SELECT * FROM vector_table_with_index\nORDER BY VEC_COSINE_DISTANCE(embedding, '[1, 2, 3]')\nLIMIT 10;\n+-----+--------------------------------------------------------+-----+\n|     | execution info                                         |     |\n+-----+--------------------------------------------------------+-----+\n| ... | time:339.1ms, loops:2, RU:0.000000, Concurrency:OFF    | ... |\n| ... | time:339ms, loops:2                                    | ... |\n| ... | time:339ms, loops:3, Concurrency:OFF                   | ... |\n| ... | time:339ms, loops:3, cop_task: {...}                   | ... |\n| ... | tiflash_task:{time:327.5ms, loops:1, threads:4}        | ... |\n| ... | tiflash_task:{time:327.5ms, loops:1, threads:4}        | ... |\n| ... | tiflash_task:{time:327.5ms, loops:1, threads:4}        | ... |\n| ... | tiflash_task:{time:327.5ms, loops:1, threads:4}        | ... |\n| ... | tiflash_task:{...}, vector_idx:{                       | ... |\n|     |   load:{total:68ms,from_s3:1,from_disk:0,from_cache:0},|     |\n|     |   search:{total:0ms,visited_nodes:2,discarded_nodes:0},|     |\n|     |   read:{vec_total:0ms,others_total:0ms}},...}          |     |\n+-----+--------------------------------------------------------+-----+\n```\n\n----------------------------------------\n\nTITLE: Querying Historical Data Within a Transaction in SQL\nDESCRIPTION: SQL query within a historical timestamp transaction that retrieves data as it existed at the specified timestamp point.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nselect * from t;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table and Performing Updates with Pessimistic Transactions - SQL\nDESCRIPTION: This example illustrates the behavior of snapshot read and current read within multiple sessions using pessimistic transactions. It highlights how locks are managed during concurrent updates and reads in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/pessimistic-transaction.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a INT);\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO T VALUES(1);\n```\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN PESSIMISTIC;\n```\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE t SET a = a + 1;\n```\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN PESSIMISTIC;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t;\n```\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN PESSIMISTIC;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t FOR UPDATE;\n```\n\nLANGUAGE: sql\nCODE:\n```\nCOMMIT;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t;\n```\n\n----------------------------------------\n\nTITLE: Backing Up Full TiDB Cluster Snapshot to S3\nDESCRIPTION: Command to back up the latest or specified snapshot of a TiDB cluster to Amazon S3 storage using the BR tool. It includes options for specifying backup timestamp, rate limiting, and log file location.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full \\\n    --pd \"${PD_IP}:2379\" \\\n    --backupts '2024-06-28 13:30:00 +08:00' \\\n    --storage \"s3://${backup_collection_addr}/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --ratelimit 128 \\\n    --log-file backupfull.log\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Migration Task\nDESCRIPTION: YAML configuration for a data migration task, including source and target database details, routing rules, and filtering.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-task.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nname: test\ntask-mode: all\nshard-mode: \"pessimistic\"\ntarget-database:\n  host: \"127.0.0.1\"\n  port: 4000\n  user: \"root\"\n  password: \"\"\n\nmysql-instances:\n  - source-id: \"mysql-replica-01\"\n    block-allow-list:  \"instance\"\n    route-rules: [\"sharding-route-rules-table\", \"sharding-route-rules-schema\"]\n    mydumper-thread: 4\n    loader-thread: 16\n    syncer-thread: 16\n  - source-id: \"mysql-replica-02\"\n    block-allow-list:  \"instance\"\n    route-rules: [\"sharding-route-rules-table\", \"sharding-route-rules-schema\"]\n    mydumper-thread: 4\n    loader-thread: 16\n    syncer-thread: 16\nblock-allow-list:\n  instance:\n    do-dbs: [\"~^sharding[\\\\d]+\"]\n    do-tables:\n    - db-name: \"~^sharding[\\\\d]+\"\n      tbl-name: \"~^t[\\\\d]+\"\nroutes:\n  sharding-route-rules-table:\n    schema-pattern: sharding*\n    table-pattern: t*\n    target-schema: db_target\n    target-table: t_target\n  sharding-route-rules-schema:\n    schema-pattern: sharding*\n    target-schema: db_target\n```\n\n----------------------------------------\n\nTITLE: Individual INSERT Statements Without Batch Rewriting\nDESCRIPTION: Shows how SQL statements are sent to TiDB without the rewriteBatchedStatements parameter enabled. Each statement is sent individually.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ninsert into t(a) values(10);\ninsert into t(a) values(11);\ninsert into t(a) values(12);\n```\n\n----------------------------------------\n\nTITLE: SQL Endpoint Response Example\nDESCRIPTION: This code snippet provides an example of a successful response from a SQL endpoint in TiDB Cloud Data Service when Batch Operation is enabled.  The response includes details about inserted rows, such as auto-increment IDs and success messages. It also includes execution-related information like latency and the number of rows affected.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"sql_endpoint\",\n    \"data\": {\n        \"columns\": [],\n        \"rows\": [\n            {\n                \"auto_increment_id\": \"270001\",\n                \"index\": \"0\",\n                \"message\": \"Row insert successfully\",\n                \"success\": \"true\"\n            },\n            {\n                \"auto_increment_id\": \"270002\",\n                \"index\": \"1\",\n                \"message\": \"Row insert successfully\",\n                \"success\": \"true\"\n            }\n        ],\n        \"result\": {\n            \"code\": 200,\n            \"message\": \"Query OK, 2 rows affected (8.359 sec)\",\n            \"start_ms\": 1689593360560,\n            \"end_ms\": 1689593368919,\n            \"latency\": \"8.359s\",\n            \"row_count\": 2,\n            \"row_affect\": 2,\n            \"limit\": 500\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Query Specific Replication Task\nDESCRIPTION: HTTP GET request to retrieve detailed information about a specific replication task by ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v2/changefeeds/test1\n```\n\n----------------------------------------\n\nTITLE: Complete DM Task Configuration for Shard Merge\nDESCRIPTION: A comprehensive example of a DM task configuration file for shard merging, including source configuration, target database settings, block-allow lists, filtering rules, and routing rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-task-configuration-guide.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n---\n\n## ********* Basic configuration *********\nname: test                      # The name of the task. Should be globally unique.\nshard-mode: \"pessimistic\"       # The shard merge mode. Optional modes are \"\"/\"pessimistic\"/\"optimistic\". The \"\" mode is used by default which means sharding DDL merge is disabled. If the task is a shard merge task, set it to the \"pessimistic\" mode. After getting a deep understanding of the principles and restrictions of the \"optimistic\" mode, you can set it to the \"optimistic\" mode.\ntask-mode: all                  # The task mode. Can be set to `full`(only migrates full data)/`incremental`(replicates binlog synchronously)/`all` (replicates both full and incremental binlogs).\ntimezone: \"UTC\"               # The timezone used in SQL Session. By default, DM uses the global timezone setting in the target cluster, which ensures the correctness automatically. A customized timezone does not affect data migration but is unnecessary.\n\n## ******** Data source configuration **********\nmysql-instances:\n  - source-id: \"mysql-replica-01\"                   # Migrate data from the data source whose `source-id` is `mysql-replica-01`.\n    block-allow-list:  \"bw-rule-1\"                  # The name of the block and allow list rule. If the DM version is earlier than v2.0.0-beta.2, use `black-white-list` instead.\n    filter-rules: [\"filter-rule-1\"]                 # The name of the rule that filters specific binlog events of the data source. You can configure multiple rules here.\n    route-rules: [\"route-rule-1\", \"route-rule-2\"]   # The name of the routing mapping rule. You can configure multiple rules here.\n  - source-id: \"mysql-replica-02\"                   # Migrate data from the data source whose `source-id` is `mysql-replica-02`.\n    block-allow-list:  \"bw-rule-2\"                  # The name of the block and allow list rule. If the DM version is earlier than v2.0.0-beta.2, use `black-white-list` instead.\n    filter-rules: [\"filter-rule-2\"]                 # The name of the rule that filters specific binlog events of the data source. You can configure multiple rules here.\n    route-rules: [\"route-rule-2\"]                   # The name of the routing mapping rule. You can configure multiple rules here.\n\n## ******** Downstream TiDB instance configuration **********\ntarget-database:       # Configuration of the downstream database instance.\n  host: \"127.0.0.1\"\n  port: 4000\n  user: \"root\"\n  password: \"\"         # If the password is not null, it is recommended to use a password encrypted with dmctl.\n\n## ******** Feature configuration set **********\n# The filter rule set of tables to be migrated from the upstream database instance. You can set multiple rules at the same time.\nblock-allow-list:                      # Use black-white-list if the DM version is earlier than v2.0.0-beta.2.\n  bw-rule-1:                           # The name of the block and allow list rule.\n    do-dbs: [\"test.*\", \"user\"]         # The allow list of upstream schemas to be migrated. Wildcard characters (*?) are supported. You only need to configure either `do-dbs` or `ignore-dbs`. If both fields are configured, only `do-dbs` takes effect.\n    # ignore-dbs: [\"mysql\", \"account\"] # The block list of upstream schemas to be migrated. Wildcard characters (*?) are supported.\n    do-tables:                         # The allow list of upstream tables to be migrated. You only need to configure either `do-tables` or `ignore-tables`. If both fields are configured, only `do-tables` takes effect.\n    - db-name: \"test.*\"\n      tbl-name: \"t.*\"\n    - db-name: \"user\"\n      tbl-name: \"information\"\n  bw-rule-2:                         # The name of the block allow list rule.\n    ignore-tables:                   # The block list of data source tables needs to be migrated.\n    - db-name: \"user\"\n      tbl-name: \"log\"\n\n# The filter rule set of data source binlog events.\nfilters:                                        # You can set multiple rules at the same time.\n  filter-rule-1:                                # The name of the filtering rule.\n    schema-pattern: \"test_*\"                    # The pattern of the data source schema name. Wildcard characters (*?) are supported.\n    table-pattern: \"t_*\"                        # The pattern of the data source table name. Wildcard characters (*?) are supported.\n    events: [\"truncate table\", \"drop table\"]    # The event types to be filtered out in schemas or tables that match the `schema-pattern` or the `table-pattern`.\n    action: Ignore                              # Whether to migrate (Do) or ignore (Ignore) the binlog that matches the filtering rule.\n  filter-rule-2:\n    schema-pattern: \"test\"\n    events: [\"all dml\"]\n    action: Do\n\n# The routing mapping rule set between the data source and target TiDB instance tables.\nroutes:                           # You can set multiple rules at the same time.\n  route-rule-1:                   # The name of the routing mapping rule.\n    schema-pattern: \"test_*\"      # The pattern of the data source schema name. Wildcard characters (*?) are supported.\n    table-pattern: \"t_*\"          # The pattern of the data source table name. Wildcard characters (*?) are supported.\n    target-schema: \"test\"         # The name of the downstream TiDB schema.\n    target-table: \"t\"             # The name of the downstream TiDB table.\n  route-rule-2:\n    schema-pattern: \"test_*\"\n    target-schema: \"test\"\n```\n\n----------------------------------------\n\nTITLE: Modifying TiKV GC I/O Limit Using tikv-ctl\nDESCRIPTION: Command to dynamically modify the GC I/O limit configuration in TiKV using tikv-ctl. This sets the maximum write bytes per second for a GC worker.\nSOURCE: https://github.com/pingcap/docs/blob/master/garbage-collection-configuration.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntikv-ctl --host=ip:port modify-tikv-config -n gc.max-write-bytes-per-sec -v 10MB\n```\n\n----------------------------------------\n\nTITLE: Import Command Output\nDESCRIPTION: Output of the 'tiup cluster import --help' command, showing all available options for importing TiDB Ansible deployed clusters into TiUP management.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nImport an exist TiDB cluster from TiDB-Ansible\n\nUsage:\n  cluster import [flags]\n\nFlags:\n  -d, --dir string         The path to TiDB-Ansible directory\n  -h, --help               help for import\n      --inventory string   The name of inventory file (default \"inventory.ini\")\n      --no-backup          Don't backup ansible dir, useful when there're multiple inventory files\n  -r, --rename NAME        Rename the imported cluster to NAME\n\nGlobal Flags:\n      --ssh string        (Experimental) The executor type. Optional values are 'builtin', 'system', and 'none'.\n      --wait-timeout int  Timeout of waiting the operation\n      --ssh-timeout int   Timeout in seconds to connect host via SSH, ignored for operations that don't need an SSH connection. (default 5)\n  -y, --yes               Skip all confirmations and assumes 'yes'\n```\n\n----------------------------------------\n\nTITLE: Comparing Metrics Between Time Periods\nDESCRIPTION: Demonstrates how to compare monitoring metrics between two time periods to identify significant changes and potential bottlenecks.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-metrics-summary.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT GREATEST(t1.avg_value,t2.avg_value)/LEAST(t1.avg_value,\n         t2.avg_value) AS ratio,\n         t1.metrics_name,\n         t1.avg_value as t1_avg_value,\n         t2.avg_value as t2_avg_value,\n         t2.comment\nFROM\n    (SELECT /*+ time_range(\"2020-03-03 17:08:00\", \"2020-03-03 17:11:00\")*/ *\n    FROM information_schema.metrics_summary ) t1\nJOIN\n    (SELECT /*+ time_range(\"2020-03-03 17:18:00\", \"2020-03-03 17:21:00\")*/ *\n    FROM information_schema.metrics_summary ) t2\n    ON t1.metrics_name = t2.metrics_name\nORDER BY ratio DESC LIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Creating a Database in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a database named `sbtest` within a TiDB cluster.  This database is used for running Sysbench benchmarks to test performance.  It's a prerequisite step to load data and run the actual Sysbench tests.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.5-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\n\"CREATE DATABASE sbtest;\"\n```\n\n----------------------------------------\n\nTITLE: Creating Tables with AUTO_INCREMENT in TiDB\nDESCRIPTION: This SQL snippet illustrates how to create a table with a centralized auto-increment ID allocating service in TiDB v6.4.0. The AUTO_ID_CACHE setting ensures IDs monotonically increase across all instances, improving sorting query results.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.4.0.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a INT AUTO_INCREMENT PRIMARY KEY) AUTO_ID_CACHE = 1;\n```\n\n----------------------------------------\n\nTITLE: Configuring 5-Replica Distribution Across Data Centers\nDESCRIPTION: SQL commands to create and apply a placement policy that distributes 5 replicas across multiple regions in a 2:2:1 ratio.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY `deploy221` CONSTRAINTS='{\"region=us-east-1\":2, \"+region=us-east-2\": 2, \"+region=us-west-1\": 1}';\n\nALTER RANGE global PLACEMENT POLICY = \"deploy221\";\n\nSHOW PLACEMENT;\n```\n\n----------------------------------------\n\nTITLE: MySQL User Table Column Output Display\nDESCRIPTION: Example output showing the comprehensive list of columns in the mysql.user table, including host, user, authentication details, and various privilege flags\nSOURCE: https://github.com/pingcap/docs/blob/master/mysql-schema/mysql-schema-user.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------+-------------------+------+------+-------------------+-------+\\n| Field                  | Type              | Null | Key  | Default           | Extra |\\n+------------------------+-------------------+------+------+-------------------+-------+\\n| Host                   | char(255)         | NO   | PRI  | NULL              |       |\\n| User                   | char(32)          | NO   | PRI  | NULL              |       |\\n| authentication_string  | text              | YES  |      | NULL              |       |\\n...\n```\n\n----------------------------------------\n\nTITLE: Querying with EXISTS Subquery in TiDB\nDESCRIPTION: Example showing how TiDB optimizes a query with EXISTS subquery. In this case, the non-correlated EXISTS subquery is evaluated during the optimization stage, and the condition is replaced with the result directly.\nSOURCE: https://github.com/pingcap/docs/blob/master/subquery-optimization.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t1(a int);\ncreate table t2(a int);\ninsert into t2 values(1);\nexplain select * from t1 where exists (select * from t2);\n```\n\n----------------------------------------\n\nTITLE: TPC-C Data Preparation with TiUP Bench (Bash)\nDESCRIPTION: This command prepares data for a TPC-C benchmark with 4 warehouses and 4 partitions using a hash partitioning scheme. It uses the `prepare` subcommand of the TiUP bench tpcc component, requiring the `tiup` command-line tool and a TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench tpcc --warehouses 4 --parts 4 prepare\n```\n\n----------------------------------------\n\nTITLE: Querying Slow Query Analysis in TiDB\nDESCRIPTION: SQL query to analyze slow queries by comparing digest patterns between two time ranges. It aggregates metrics like query time, process time, and key counts to identify problematic queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-diagnostics-usage.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM (SELECT count(*), min(time), sum(query_time) AS sum_query_time, sum(Process_time) AS sum_process_time, sum(Wait_time) AS sum_wait_time, sum(Commit_time), sum(Request_count), sum(process_keys), sum(Write_keys), max(Cop_proc_max), min(query),min(prev_stmt), digest FROM information_schema.CLUSTER_SLOW_QUERY WHERE time >= '2020-03-10 13:24:30' AND time < '2020-03-10 13:27:30' AND Is_internal = false GROUP BY digest) AS t1 WHERE t1.digest NOT IN (SELECT digest FROM information_schema.CLUSTER_SLOW_QUERY WHERE time >= '2020-03-10 13:21:00' AND time < '2020-03-10 13:24:00' GROUP BY digest) ORDER BY t1.sum_query_time DESC limit 10\\G\n```\n\n----------------------------------------\n\nTITLE: Java DAO Implementation for Book Management with Stale Reads\nDESCRIPTION: Java class implementing data access operations for books including regular queries, updates, and stale reads with error handling for GC life time and future timestamp constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-stale-read.md#2025-04-18_snippet_3\n\nLANGUAGE: java\nCODE:\n```\npublic class BookDAO {\n\n    // Omit some code...\n\n    public List<Book> getTop5LatestBooks() throws SQLException {\n        List<Book> books = new ArrayList<>();\n        try (Connection conn = ds.getConnection()) {\n            Statement stmt = conn.createStatement();\n            ResultSet rs = stmt.executeQuery(\"\"\"\n            SELECT id, title, type, price FROM books ORDER BY published_at DESC LIMIT 5;\n            \"\"\");\n            while (rs.next()) {\n                Book book = new Book();\n                book.setId(rs.getLong(\"id\"));\n                book.setTitle(rs.getString(\"title\"));\n                book.setType(rs.getString(\"type\"));\n                book.setPrice(rs.getDouble(\"price\"));\n                books.add(book);\n            }\n        }\n        return books;\n    }\n\n    public void updateBookPriceByID(Long id, Double price) throws SQLException {\n        try (Connection conn = ds.getConnection()) {\n            PreparedStatement stmt = conn.prepareStatement(\"\"\"\n            UPDATE books SET price = ? WHERE id = ?;\n            \"\"\");\n            stmt.setDouble(1, price);\n            stmt.setLong(2, id);\n            int affects = stmt.executeUpdate();\n            if (affects == 0) {\n                throw new SQLException(\"Failed to update the book with id: \" + id);\n            }\n        }\n    }\n\n    public List<Book> getTop5LatestBooksWithStaleRead(Integer seconds) throws SQLException {\n        List<Book> books = new ArrayList<>();\n        try (Connection conn = ds.getConnection()) {\n            PreparedStatement stmt = conn.prepareStatement(\"\"\"\n            SELECT id, title, type, price FROM books AS OF TIMESTAMP NOW() - INTERVAL ? SECOND ORDER BY published_at DESC LIMIT 5;\n            \"\"\");\n            stmt.setInt(1, seconds);\n            ResultSet rs = stmt.executeQuery();\n            while (rs.next()) {\n                Book book = new Book();\n                book.setId(rs.getLong(\"id\"));\n                book.setTitle(rs.getString(\"title\"));\n                book.setType(rs.getString(\"type\"));\n                book.setPrice(rs.getDouble(\"price\"));\n                books.add(book);\n            }\n        } catch (SQLException e) {\n            if (\"HY000\".equals(e.getSQLState()) && e.getErrorCode() == 1105) {\n                System.out.println(\"WARN: cannot set read timestamp to a future time.\");\n            } else if (\"HY000\".equals(e.getSQLState()) && e.getErrorCode() == 9006) {\n                System.out.println(\"WARN: GC life time is shorter than transaction duration.\");\n            } else {\n                throw e;\n            }\n        }\n        return books;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Example Response for Data Source Status in JSON\nDESCRIPTION: This JSON represents the response format when retrieving the status of a data source. It includes detailed information about the relay status, worker assignment, and any error messages.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_17\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"total\": 1,\n  \"data\": [\n    {\n      \"source_name\": \"mysql-replica-01\",\n      \"worker_name\": \"worker-1\",\n      \"relay_status\": {\n        \"master_binlog\": \"(mysql-bin.000001, 1979)\",\n        \"master_binlog_gtid\": \"e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849\",\n        \"relay_dir\": \"./sub_dir\",\n        \"relay_binlog_gtid\": \"e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849\",\n        \"relay_catch_up_master\": true,\n        \"stage\": \"Running\"\n      },\n      \"error_msg\": \"string\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Distinct Optimization in TiFlash\nDESCRIPTION: Sets the tidb_opt_distinct_agg_push_down variable to ON to enable pushing down aggregate functions with Distinct operations to Coprocessor.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_opt_distinct_agg_push_down = ON;\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cluster and Creating Vector Table\nDESCRIPTION: Uses TiDBVectorClient to connect to the TiDB cluster and create a table for storing vector embeddings.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-python.md#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom tidb_vector.integrations import TiDBVectorClient\nfrom dotenv import load_dotenv\n\n# Load the connection string from the .env file\nload_dotenv()\n\nvector_store = TiDBVectorClient(\n   # The 'embedded_documents' table will store the vector data.\n   table_name='embedded_documents',\n   # The connection string to the TiDB cluster.\n   connection_string=os.environ.get('TIDB_DATABASE_URL'),\n   # The dimension of the vector generated by the embedding model.\n   vector_dimension=embed_model_dims,\n   # Recreate the table if it already exists.\n   drop_existing_table=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Exporting data to Amazon S3 using Dumpling in Shell\nDESCRIPTION: Command to export data from TiDB/MySQL to Amazon S3 bucket storage using Dumpling with rate limiting.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup dumpling -u root -P 4000 -h 127.0.0.1 -r 200000 -o \"s3://${Bucket}/${Folder}\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Test Table and Explaining Query in SQL\nDESCRIPTION: Creates a sample table with a primary key and secondary index, then uses EXPLAIN with FORMAT=\"tidb_json\" to get the execution plan in JSON format for a simple query filtering on the indexed column.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id int primary key, a int, b int, key(a));\nEXPLAIN FORMAT = \"tidb_json\" SELECT id FROM t WHERE a = 1;\n```\n\n----------------------------------------\n\nTITLE: Dealing with incorrect UTF-8 values in replication\nDESCRIPTION: This snippet explains the error `Error 1366: incorrect utf8 value` that arises during replication due to incompatible character values when moving data into TiDB or MySQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_13\n\nLANGUAGE: markdown\nCODE:\n```\n- This value cannot be successfully written into MySQL 8.0 or TiDB, but can be written into MySQL 5.7. You can skip the data format check by enabling the `tidb_skip_utf8_check` parameter.\n```\n\n----------------------------------------\n\nTITLE: Creating a Changefeed with Canal Protocol\nDESCRIPTION: This code snippet demonstrates how to create a changefeed in TiCDC utilizing the Canal protocol for data replication to Kafka. It shows how to specify the sink URI and configuration file for the replication task.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://127.0.0.1:8300 --sink-uri=\"kafka://127.0.0.1:9092/cdc-test?kafka-version=2.4.0&protocol=canal-json\" --config changefeed.toml\n```\n\n----------------------------------------\n\nTITLE: Querying All Databases from SCHEMATA in TiDB\nDESCRIPTION: Demonstrates how to query all database information from the SCHEMATA table in TiDB's information_schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-schemata.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM SCHEMATA;\n```\n\n----------------------------------------\n\nTITLE: Querying GBK Character Set Information in TiDB\nDESCRIPTION: SQL commands to display GBK character set details and available collations in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-gbk.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CHARACTER SET WHERE CHARSET = 'gbk';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLLATION WHERE CHARSET = 'gbk';\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Connection Limit in TiDB SQL\nDESCRIPTION: SQL statements to create a new user 'newuser10' with a maximum connection limit of 3 and verify the limit in the mysql.user table in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser10'@'%' WITH MAX_USER_CONNECTIONS 3;\nSELECT User, Host, max_user_connections FROM mysql.user WHERE User='newuser10';\n```\n\n----------------------------------------\n\nTITLE: Adding Expression Index with ALTER TABLE in SQL\nDESCRIPTION: Shows an alternative way to create an expression index using the ALTER TABLE statement. This method can be used to add an expression index to an existing table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t1 ADD INDEX idx1((LOWER(col1)));\n```\n\n----------------------------------------\n\nTITLE: Configuring Binlog Value Filter YAML Configuration\nDESCRIPTION: This YAML configuration snippet demonstrates setting up a binlog value filter in DM to prevent insertion of even numbers in column 'c' from being replicated downstream. It requires DM setup and proper integration with MySQL source instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/filter-dml-event.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: test\ntask-mode: all\n\nmysql-instances:\n  - source-id: \"mysql-replica-01\"\n    expression-filters: [\"even_c\"]\n\nexpression-filter:\n  even_c:\n    schema: \"expr_filter\"\n    table: \"tbl\"\n    insert-value-expr: \"c % 2 = 0\"\n\n```\n\n----------------------------------------\n\nTITLE: SQL Syntax for CREATE DATABASE Statement\nDESCRIPTION: SQL syntax showing the basic structure and optional specifications for creating a database, including character set and collation options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-database.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name\n    [create_specification] ...\n\ncreate_specification:\n    [DEFAULT] CHARACTER SET [=] charset_name\n  | [DEFAULT] COLLATE [=] collation_name\n```\n\n----------------------------------------\n\nTITLE: Configuring ProxySQL Login Users\nDESCRIPTION: This SQL script adds a user to ProxySQL's mysql_users table with appropriate permissions for the TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO mysql_users(\n  username, password, active, default_hostgroup, \n  transaction_persistent\n) \nVALUES \n  (\n    '<tidb cloud dedicated cluster username>', \n    '<tidb cloud dedicated cluster password>', \n    1, 0, 1\n  );\nLOAD mysql users TO runtime;\nSAVE mysql users TO DISK;\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Cluster Topology File with TiUP\nDESCRIPTION: Creates a basic TiDB cluster topology template file to customize for deployment. This is the starting point for defining your TiDB cluster configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster template > topology.yaml\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into a Table with AUTO_RANDOM Primary Key in TiDB\nDESCRIPTION: Shows how to insert data into a table with an AUTO_RANDOM primary key, where TiDB automatically generates a unique primary key value.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-hot-spot-issues.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t (b) VALUES (\"foo\");\n```\n\n----------------------------------------\n\nTITLE: Example Decimal Precision SQL Query\nDESCRIPTION: SQL query demonstrating decimal precision calculation that can cause ERROR 1265 in TiDB versions before 3.0.10\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n(0.1^30) / 10\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating Sample Tables for Join Analysis in TiDB\nDESCRIPTION: This SQL script creates two tables (t1 and t2) with various columns and populates them with random data using nested joins. The script also updates some rows and analyzes the tables to ensure statistics are up-to-date for the optimizer.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id BIGINT NOT NULL PRIMARY KEY auto_increment, pad1 BLOB, pad2 BLOB, pad3 BLOB, int_col INT NOT NULL DEFAULT 0);\nCREATE TABLE t2 (id BIGINT NOT NULL PRIMARY KEY auto_increment, t1_id BIGINT NOT NULL, pad1 BLOB, pad2 BLOB, pad3 BLOB, INDEX(t1_id));\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024), 0 FROM dual;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024), 0 FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024), 0 FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024), 0 FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024), 0 FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024), 0 FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024), 0 FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024), 0 FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024), 0 FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024), 0 FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024), 0 FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t2 SELECT NULL, a.id, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t2 SELECT NULL, a.id, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t2 SELECT NULL, a.id, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t2 SELECT NULL, a.id, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t2 SELECT NULL, a.id, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t2 SELECT NULL, a.id, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t2 SELECT NULL, a.id, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t2 SELECT NULL, a.id, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t2 SELECT NULL, a.id, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nUPDATE t1 SET int_col = 1 WHERE pad1 = (SELECT pad1 FROM t1 ORDER BY RAND() LIMIT 1);\nSELECT SLEEP(1);\nANALYZE TABLE t1, t2;\n```\n\n----------------------------------------\n\nTITLE: Setting Default Connection Buffer Size (YAML)\nDESCRIPTION: This YAML configuration sets the default connection buffer size for TiProxy to optimize performance based on expected connection load. The adjustment helps ensure efficient handling of long-lasting connections without compromising on query performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-performance-test.md#2025-04-18_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nproxy.conn-buffer-size: 32768\n```\n\n----------------------------------------\n\nTITLE: Viewing Last 5 DDL Jobs in TiDB\nDESCRIPTION: Displays the 5 most recent DDL jobs in the queue, with detailed information about each job's execution status and metadata.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW DDL JOBS 5;\n```\n\n----------------------------------------\n\nTITLE: Rotating the Master Key - INI\nDESCRIPTION: This configuration snippet illustrates how to set up master key rotation in TiKV by specifying both new and old master keys in the configuration, highlighting the process for a restart.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_7\n\nLANGUAGE: ini\nCODE:\n```\n[security.encryption.master-key]\ntype = \"kms\"\nkey-id = \"50a0c603-1c6f-11e6-bb9e-3fadde80ce75\"\nregion = \"us-west-2\"\n\n[security.encryption.previous-master-key]\ntype = \"kms\"\nkey-id = \"0987dcba-09fe-87dc-65ba-ab0987654321\"\nregion = \"us-west-2\"\n```\n\n----------------------------------------\n\nTITLE: Hot Spot Information Commands\nDESCRIPTION: Commands to view cluster hot spot information including read, write, store operations and historical data with time ranges and filtering conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\n>> hot read\n>> hot write\n>> hot store\n>> hot history 1629294000000 1631980800000\n>> hot history 1629294000000 1631980800000 hot_region_type read region_id 1,2,3 store_id 1,2,3 peer_id 1,2,3 is_leader true is_learner true\n```\n\n----------------------------------------\n\nTITLE: Creating Database via MySQL CLI\nDESCRIPTION: Shell command to execute database creation using MySQL command-line client with root credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-database.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmysql\n    -u root \\\n    -h {host} \\\n    -P {port} \\\n    -p {password} \\\n    -e \"CREATE DATABASE IF NOT EXISTS bookshop;\"\n```\n\n----------------------------------------\n\nTITLE: Azure Blob Storage Backup Command\nDESCRIPTION: Command for backing up snapshot data to Azure Blob Storage using BR with account credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full -u \"${PD_IP}:2379\" \\\n--storage \"azure://external/backup-20220915?account-name=${account-name}&account-key=${account-key}\"\n```\n\n----------------------------------------\n\nTITLE: Importing S3 Data with IAM User Access Keys - Bash\nDESCRIPTION: This snippet illustrates how to import data from S3 using the access keys of an AWS IAM user in TiDB Lightning. This method is useful for authentication with AWS services through user credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ntiup tidb-lightning --tidb-port=4000 --pd-urls=127.0.0.1:2379 --backend=local --sorted-kv-dir=/tmp/sorted-kvs \\\n    -d 's3://my-bucket/test-data?access_key={my_access_key}&secret_access_key={my_secret_access_key}'\n```\n\n----------------------------------------\n\nTITLE: Checking Log Backup Status in TiDB\nDESCRIPTION: Command to query the status of a running log backup task, showing information like task name, status, start time, storage location, and checkpoint information.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-use-cases.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log status --task-name=pitr --pd=\"${PD_IP}:2379\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Collations in TiDB\nDESCRIPTION: SQL command to show the collations supported by TiDB, which is useful for planning character set and collation migrations from MariaDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-mariadb.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW COLLATION;\n```\n\n----------------------------------------\n\nTITLE: Setting up Minio as S3-compatible Storage\nDESCRIPTION: Commands to download, configure, and start Minio as an S3-compatible storage service for storing backup files.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nwget https://dl.min.io/server/minio/release/linux-amd64/minio\nchmod +x minio\n# Configure access-key access-screct-id to access minio\nexport HOST_IP='172.16.6.122' # Replace the value with the IP address of your upstream cluster\nexport MINIO_ROOT_USER='minio'\nexport MINIO_ROOT_PASSWORD='miniostorage'\n# Create the database directory. backup is the bucket name.\nmkdir -p data/backup\n# Start minio at port 6060\n./minio server ./data --address :6060 &\n```\n\n----------------------------------------\n\nTITLE: Changing to TiDB Cloud Connect Directory\nDESCRIPTION: Command to change to the tidb-cloud-connect directory in the cloned repository.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd tidb-proxysql-integration/example/tidb-cloud-connect\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed\nDESCRIPTION: Shell command to create a TiCDC changefeed for incremental replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc cli changefeed create --server=http://172.16.6.122:8300 --sink-uri=\"mysql://root:@172.16.6.125:4000\" --changefeed-id=\"primary-to-secondary\" --start-ts=\"431434047157698561\"\n```\n\n----------------------------------------\n\nTITLE: Importing Data with Sysbench for TiDB Benchmark\nDESCRIPTION: This shell command uses Sysbench to prepare a test database by importing a table with 2,000,000 rows of data into a TiDB cluster. The command specifies 16 threads with uniform random distribution for the data import operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/online-workloads-and-add-index-operations.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsysbench oltp_common \\\n    --threads=16 \\\n    --rand-type=uniform \\\n    --db-driver=mysql \\\n    --mysql-db=sbtest \\\n    --mysql-host=$tidb_host \\\n    --mysql-port=$tidb_port \\\n    --mysql-user=root \\\n    prepare --tables=1 --table-size=2000000\n```\n\n----------------------------------------\n\nTITLE: Describing CLUSTER_LOAD Table Structure in TiDB\nDESCRIPTION: Shows the structure of the CLUSTER_LOAD table including field names, data types, and constraints. This table contains columns for instance type, device information, metrics names and values.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-load.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC cluster_load;\n```\n\n----------------------------------------\n\nTITLE: Using pd-recover to Set Allocation IDs in Shell\nDESCRIPTION: Demonstrates the use of pd-recover to reset allocations with specific endpoint and cluster ID parameters. Suggests a safe allocation ID that prevents reallocation conflicts.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-recover.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n./pd-recover -endpoints http://10.0.1.13:2379 -cluster-id 6747551640615446306 -alloc-id 10000\n```\n\n----------------------------------------\n\nTITLE: Enabling In-Memory TiDB Instance\nDESCRIPTION: Command to start TiDB with pure in-memory storage, which is useful for testing and development environments.\nSOURCE: https://github.com/pingcap/docs/blob/master/command-line-flags-for-tidb-configuration.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntidb-server --store=unistore --path=\"\"\n```\n\n----------------------------------------\n\nTITLE: TiDB VITESS_HASH Function Addition\nDESCRIPTION: Implementation reference for new built-in VITESS_HASH() function\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.1.md#2025-04-18_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nVITESS_HASH()\n```\n\n----------------------------------------\n\nTITLE: Altering Last Partition in INTERVAL Partitioned Table in SQL\nDESCRIPTION: SQL syntax for changing the last partition in an INTERVAL partitioned table. This statement adds new partitions with the current interval up to and including the given expression, enabling room for new data.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name LAST PARTITION LESS THAN (<expression>)\n```\n\n----------------------------------------\n\nTITLE: Creating Changefeed using TiUP CLI\nDESCRIPTION: This code snippet demonstrates how to create a changefeed using the TiUP CLI. This command is executed after resolving any compatibility issues, such as those arising from using an incorrect CLI version. The command specifies the sink URI and PD address for the new changefeed.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-compatibility.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n\"tiup cdc:v4.0.9 cli changefeed create --sink-uri=xxxx --pd=xxx\"\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Fractional Second Precision in SQL\nDESCRIPTION: This snippet demonstrates how to create a table with columns that support fractional second precision for TIME and DATETIME types. The precision is specified using the fsp parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (t TIME(3), dt DATETIME(6));\n```\n\n----------------------------------------\n\nTITLE: Fixing binSearch function in builtinIntervalRealSig\nDESCRIPTION: Addresses potential incorrect results due to binSearch function not returning an error in builtinIntervalRealSig implementation.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.7.md#2025-04-18_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\n[#13767](https://github.com/pingcap/tidb/pull/13767)\n```\n\n----------------------------------------\n\nTITLE: Converting Server Key to RSA Format for TiDB\nDESCRIPTION: Command to ensure the server private key is in the proper RSA format for use with TiDB's TLS configuration. This writes the RSA key to the specified output file.\nSOURCE: https://github.com/pingcap/docs/blob/master/certificate-authentication.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsudo openssl rsa -in server-key.pem -out server-key.pem\n```\n\n----------------------------------------\n\nTITLE: Binary Representation of a TSO Timestamp\nDESCRIPTION: This snippet shows the binary representation of a TSO timestamp, including how it's split into physical timestamp (first 46 bits, representing milliseconds since epoch) and logical timestamp (last 18 bits).\nSOURCE: https://github.com/pingcap/docs/blob/master/tso.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n0000011000101000111000010001011110111000110111000000000000000100  ← This is 443852055297916932 in binary\n0000011000101000111000010001011110111000110111                    ← The first 46 bits are the physical timestamp\n                                              000000000000000100  ← The last 18 bits are the logical timestamp\n```\n\n----------------------------------------\n\nTITLE: Reloading NGINX Configuration\nDESCRIPTION: Shell command to reload NGINX configuration after making changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nsudo nginx -s reload\n```\n\n----------------------------------------\n\nTITLE: Evicting Owner Node - Shell\nDESCRIPTION: Example of how to evict the current owner node using POST /api/v2/owner/resign. Triggers a new election for owner node.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://127.0.0.1:8300/api/v2/owner/resign\n```\n\n----------------------------------------\n\nTITLE: Response Example - Querying Replication Subtask List - TiCDC - JSON\nDESCRIPTION: This JSON response shows the example output of the processor list query. It contains a list of objects containing the `changefeed_id` and `capture_id` of each processor.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_15\n\nLANGUAGE: json\nCODE:\n```\n[\n    {\n        \"changefeed_id\": \"test1\",\n        \"capture_id\": \"561c3784-77f0-4863-ad52-65a3436db6af\"\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Packaging TiUP Components for Transfer\nDESCRIPTION: This command creates a tarball of the cloned TiUP components for easy transfer to an offline environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup-offline.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntar czvf tidb-dm-${version}-linux-amd64.tar.gz tidb-dm-${version}-linux-amd64\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP Cluster Upgrade Command in Shell\nDESCRIPTION: This command upgrades a specified TiDB cluster to a target version. It requires the cluster name and the version to upgrade to. Various options can be used to customize the upgrade process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-upgrade.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster upgrade <cluster-name> <version> [flags]\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing Sample Documents with LlamaIndex\nDESCRIPTION: Loads the sample document from the specified directory and adds metadata to it for better organization and retrieval.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndocuments = SimpleDirectoryReader(\"./data/paul_graham\").load_data()\nprint(\"Document ID:\", documents[0].doc_id)\n\nfor index, document in enumerate(documents):\n   document.metadata = {\"book\": \"paul_graham\"}\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB cluster with tidb-ctl\nDESCRIPTION: This command-line example shows how to connect to a TiDB cluster using `tidb-ctl` after enabling TLS.  It specifies the HTTPS protocol, the CA certificate, the client certificate, and the client key for secure authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n    ```bash\n    ./tidb-ctl -u https://127.0.0.1:10080 --ca /path/to/ca.pem --ssl-cert /path/to/client.pem --ssl-key /path/to/client-key.pem\n    ```\n```\n\n----------------------------------------\n\nTITLE: Simplifying Output of Store Command in TiKV\nDESCRIPTION: This command formats the output of the store command using Jq to show only specific fields, making it easier to read and process.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_61\n\nLANGUAGE: bash\nCODE:\n```\nstore --jq=\".stores[].store | {id, address, state_name}\"\n```\n\n----------------------------------------\n\nTITLE: Configure Force Replication in TOML\nDESCRIPTION: This configuration snippet shows how to enable `force-replicate` in the changefeed configuration file. Setting `force-replicate` to `true` allows replicating tables without a valid index, but data consistency is not guaranteed.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_14\n\nLANGUAGE: toml\nCODE:\n```\nforce-replicate = true\n```\n\n----------------------------------------\n\nTITLE: AWS IAM Policy with KMS Key (JSON)\nDESCRIPTION: This code snippet adds a statement to the IAM policy to allow decryption using AWS Key Management Service (KMS). This is necessary when the S3 bucket is encrypted with SSE-KMS using a customer-managed key. The `Resource` field should be updated with the correct KMS key ARN, including all keys involved in copying the objects, if applicable.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/config-s3-and-gcs-access.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n            {\n                \"Sid\": \"AllowKMSkey\",\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"kms:Decrypt\"\n                ],\n                \"Resource\": \"arn:aws:kms:ap-northeast-1:105880447796:key/c3046e91-fdfc-4f3a-acff-00597dd3801f\"\n            }\n```\n\n----------------------------------------\n\nTITLE: Checksum Command Output Example\nDESCRIPTION: Example output showing the checksum calculation results including database name, table name, CRC64 checksum, total KVs, and total bytes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-checksum-table.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n+---------+------------+----------------------+-----------+-------------+\n| Db_name | Table_name | Checksum_crc64_xor   | Total_kvs | Total_bytes |\n+---------+------------+----------------------+-----------+-------------+\n| test    | t1         | 10909174369497628533 |         3 |          75 |\n+---------+------------+----------------------+-----------+-------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: DM Task Case Sensitivity Configuration\nDESCRIPTION: Configuration setting for handling case-sensitive schema names in DM tasks\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-best-practices.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ncase-sensitive: true\n```\n\n----------------------------------------\n\nTITLE: Decreasing Swap Priority for TiDB Without Disabling It\nDESCRIPTION: Alternative commands to set vm.swappiness to 0 without completely disabling swap. This approach helps prevent OOM issues when host memory is insufficient while minimizing performance impact.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\necho \"vm.swappiness = 0\">> /etc/sysctl.conf\nsysctl -p\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating a Table for ANALYZE Example\nDESCRIPTION: SQL commands to create a table 't1' with an auto-incrementing primary key and a column 'c1', then insert sample data and add an index on 'c1'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-analyze-table.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\n```\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5);\n```\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t1 ADD INDEX (c1);\n```\n\n----------------------------------------\n\nTITLE: Dropping Partitions in SQL\nDESCRIPTION: SQL statements to drop partitions from RANGE and LIST partitioned tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_36\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE members DROP PARTITION p1990;\n\nALTER TABLE member_level DROP PARTITION l5;\n```\n\n----------------------------------------\n\nTITLE: Enabling List Columns Partitioning in TiDB\nDESCRIPTION: This snippet shows how to enable the List COLUMNS partitioning feature in TiDB by setting the `tidb_enable_list_partition` session variable to `ON`. This allows the use of multiple columns as partition keys, including string, DATE, and DATETIME data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSET SESSION tidb_enable_list_partition = ON;\n```\n\n----------------------------------------\n\nTITLE: Querying Migration Task Status\nDESCRIPTION: Retrieves the current status of a specific migration task\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} query-status ${task-name}\n```\n\n----------------------------------------\n\nTITLE: Range INTERVAL Partitioning Syntax Definition in SQL\nDESCRIPTION: Syntax definition for Range INTERVAL partitioning, which extends Range partitioning to create partitions of a specified interval easily. This syntax was introduced in TiDB v6.3.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nPARTITION BY RANGE [COLUMNS] (<partitioning expression>)\nINTERVAL (<interval expression>)\nFIRST PARTITION LESS THAN (<expression>)\nLAST PARTITION LESS THAN (<expression>)\n[NULL PARTITION]\n[MAXVALUE PARTITION]\n```\n\n----------------------------------------\n\nTITLE: Setting PD mode to microservice in cluster configuration\nDESCRIPTION: This configuration snippet sets the `pd_mode` parameter to `ms` (microservice) within the `global` section of the TiDB cluster configuration. This setting enables the PD microservice mode, decoupling the timestamp allocation and cluster scheduling functions from the routing function.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_11\n\nLANGUAGE: ini\nCODE:\n```\n\"global:\\n  user: tidb\\n   ssh_port: 22\\n   listen_host: 0.0.0.0\\n   deploy_dir: /tidb-deploy\\n   data_dir: /tidb-data\\n   os: linux\\n   arch: amd64\\n   systemd_mode: system\\n   pd_mode: ms\"\n```\n\n----------------------------------------\n\nTITLE: Setting AWS credentials for S3 export in Shell\nDESCRIPTION: Sets environment variables for AWS credentials required to export data to Amazon S3 storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nexport AWS_ACCESS_KEY_ID=${AccessKey}\nexport AWS_SECRET_ACCESS_KEY=${SecretKey}\n```\n\n----------------------------------------\n\nTITLE: Defining BINARY Column in TiDB\nDESCRIPTION: Syntax for creating a BINARY column for fixed-length binary strings.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nBINARY(M)\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying Table Storage Stats Example\nDESCRIPTION: Demonstrates creating a test table, inserting data, and querying its storage statistics using TABLE_STORAGE_STATS.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-table-storage-stats.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test.t1 (id INT);\nINSERT INTO test.t1 VALUES (1);\nSELECT * FROM TABLE_STORAGE_STATS WHERE table_schema = 'test' AND table_name = 't1'\\G\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax for SHOW COLUMN_STATS_USAGE\nDESCRIPTION: This snippet shows the EBNF syntax for the `SHOW COLUMN_STATS_USAGE` statement, defining the structure of the statement and its optional clauses like `LIKE` and `WHERE`.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-column-stats-usage.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\n\"ShowColumnStatsUsageStmt ::= \\n    \\\"SHOW\\\" \\\"COLUMN_STATS_USAGE\\\" ShowLikeOrWhere?\\n\\nShowLikeOrWhere ::= \\n    \\\"LIKE\\\" SimpleExpr\\n|   \\\"WHERE\\\" Expression\"\n```\n\n----------------------------------------\n\nTITLE: Show Errors Syntax\nDESCRIPTION: This EBNF diagram shows the syntax of the SHOW ERRORS statement, which can optionally include LIKE or WHERE clauses to filter the errors displayed.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-errors.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\n\"ShowErrorsStmt ::= \\n    \\\"SHOW\\\" \\\"ERRORS\\\" ShowLikeOrWhere?\\n\\nShowLikeOrWhere ::= \\n    \\\"LIKE\\\" SimpleExpr\\n|   \\\"WHERE\\\" Expression\"\n```\n\n----------------------------------------\n\nTITLE: Issuing Client Certificate\nDESCRIPTION: Command to issue and generate the client certificate using the root CA and CSR.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nopenssl x509 -req -days 365 -CA root.crt -CAkey root.key -CAcreateserial -in client.csr -out client.crt\n```\n\n----------------------------------------\n\nTITLE: Querying All Inspection Rules from INSPECTION_RULES\nDESCRIPTION: This SQL query retrieves all records from the INSPECTION_RULES table, showing the available diagnostic tests with their names, types, and comments. The results show various inspection and summary type rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-rules.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM inspection_rules;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Region Read Progress Output in TiKV Log\nDESCRIPTION: This log output shows the detailed state of a TiKV region, including its safe timestamp, applied index, resolver status, and number of locks. It's crucial for identifying the root cause of stale read issues, particularly when there are many locks or discrepancies in index tracking.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-stale-read.md#2025-04-18_snippet_3\n\nLANGUAGE: log\nCODE:\n```\nRegion read progress:\n    exist: true,\n    safe_ts: 442918444145049601,\n    applied_index: 2477,\n    read_state.ts: 442918444145049601,\n    read_state.apply_index: 1532,\n    pending front item (oldest) ts: 0,\n    pending front item (oldest) applied index: 0,\n    pending back item (latest) ts: 0,\n    pending back item (latest) applied index: 0,\n    paused: false,\n    discarding: false,\nResolver:\n    exist: true,\n    resolved_ts: 442918444145049601,\n    tracked index: 2477,\n    number of locks: 480000,\n    number of transactions: 1,\n    stopped: false,\n```\n\n----------------------------------------\n\nTITLE: Creating Google Cloud VPC Peering Connection\nDESCRIPTION: Google Cloud CLI command to create a VPC peering connection between your Google Cloud VPC and TiDB Cloud VPC, specifying project IDs and network names for both sides of the connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-vpc-peering-connections.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ngcloud beta compute networks peerings create <your-peer-name> --project <your-project-id> --network <your-vpc-network-name> --peer-project <tidb-project-id> --peer-network <tidb-vpc-network-name>\n```\n\n----------------------------------------\n\nTITLE: Beginning a Transaction After Setting Historical Read in SQL\nDESCRIPTION: SQL command to start a transaction after configuring it to read historical data, initiating a read-only transaction with stale read capability.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nbegin;\n```\n\n----------------------------------------\n\nTITLE: Referencing Existing Cluster in TiDB Cloud Backup Configuration\nDESCRIPTION: Terraform configuration that creates a backup resource by referencing an existing cluster resource, eliminating the need to specify actual project ID and cluster ID values.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-backup-resource.md#2025-04-18_snippet_1\n\nLANGUAGE: hcl\nCODE:\n```\nresource \"tidbcloud_backup\" \"example_backup\" {\n  project_id  = tidbcloud_cluster.example_cluster.project_id\n  cluster_id  = tidbcloud_cluster.example_cluster.id\n  name        = \"firstBackup\"\n  description = \"create by terraform\"\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Inspection Rules from INSPECTION_RULES Table in SQL\nDESCRIPTION: SQL query to select all inspection-type rules from the inspection_rules system table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-result.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nselect * from information_schema.inspection_rules where type='inspection';\n```\n\n----------------------------------------\n\nTITLE: Creating a Branch in Interactive Mode\nDESCRIPTION: Example of creating a branch for a TiDB Cloud Serverless cluster in interactive mode. This mode prompts the user for required information through a CLI interface.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-create.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch create\n```\n\n----------------------------------------\n\nTITLE: Release 8.1 Event Splitting Configuration\nDESCRIPTION: Details event splitting compatibility matrix for TiDB version 8.1, showing protocol support and event splitting behavior\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-split-update-behavior.md#2025-04-18_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n| Version | Protocol | Split UK/PK `UPDATE` events | Not split UK/PK `UPDATE` events  | Comments |\n| -- | -- | -- | -- | -- |\n| v8.1.0 | ALL | ✓ | ✗ |\n| \\>= v8.1.1 | ALL | ✓ (Default value:`output-raw-change-event = false`) | ✓  (Optional: `output-raw-change-event = true`) | |\n```\n\n----------------------------------------\n\nTITLE: Enabling Joint Consensus in PD Configuration\nDESCRIPTION: Enables the Raft Joint Consensus algorithm to improve system availability during Region membership changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0-rc.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\npd-ctl config set enable-joint-consensus true\n```\n\n----------------------------------------\n\nTITLE: Deleting Table Schema with binlog-schema\nDESCRIPTION: Example of using the binlog-schema delete command to remove the schema for a specific table in a migration task.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-manage-schema.md#2025-04-18_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\nbinlog-schema delete -s mysql-replica-01 task_single db_single t1\n```\n\n----------------------------------------\n\nTITLE: Using INL_HASH_JOIN Optimizer Hint - SQL\nDESCRIPTION: This snippet shows how to leverage the INL_HASH_JOIN hint to specifically indicate the use of the index nested loop hash join algorithm, providing a balance between memory consumption and processing efficiency.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ INL_HASH_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Resetting gRPC Rate and Concurrency Limits in PD\nDESCRIPTION: Resets the rate (QPS) and concurrency limits for GetRegion gRPC API requests to 0, effectively removing the limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nconfig set service-middleware grpc-rate-limit GetRegion qps 0\nconfig set service-middleware grpc-rate-limit GetRegion concurrency 0\n```\n\n----------------------------------------\n\nTITLE: Predicate Simplification before Push Down\nDESCRIPTION: Shows how constant expressions in predicates can be pre-calculated and simplified before being pushed down to storage layer\nSOURCE: https://github.com/pingcap/docs/blob/master/predicate-push-down.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id int primary key, a int not null);\nexplain select * from t where a < substring('123', 1, 1);\n```\n\n----------------------------------------\n\nTITLE: Cloning the Sample Repository in Shell\nDESCRIPTION: Commands to clone the sample code repository and navigate to the project directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/tidb-samples/tidb-nodejs-typeorm-quickstart.git\ncd tidb-nodejs-typeorm-quickstart\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW PRIVILEGES SQL Command\nDESCRIPTION: Demonstrates how to execute the SHOW PRIVILEGES statement to view a comprehensive list of available privileges in the TiDB database system\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-privileges.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW PRIVILEGES;\n```\n\n----------------------------------------\n\nTITLE: Setting GC Life Time for Data Export\nDESCRIPTION: This SQL command sets the garbage collection life time for TiDB, ensuring that historical data is not deleted during the export and import operations while loading existing data to MySQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/changefeed-sink-to-mysql.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_life_time = '720h';\n```\n\n----------------------------------------\n\nTITLE: PD Etcd Network Latency Alert Query\nDESCRIPTION: PromQL query to monitor network latency between PD nodes using the 99th percentile of etcd round trip times\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_8\n\nLANGUAGE: promql\nCODE:\n```\nhistogram_quantile(0.99, sum(rate(etcd_network_peer_round_trip_time_seconds_bucket[1m])) by (To, instance, job, le)) > 1\n```\n\n----------------------------------------\n\nTITLE: Querying with json_overlaps using IndexMerge\nDESCRIPTION: Examples showing how IndexMerge works with json_overlaps when conditions are connected with AND/OR. Shows that IndexMerge works with OR semantics for json_overlaps.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1, mvi2) */ * FROM t4 WHERE json_overlaps(j->'$.a', '[1]') OR json_overlaps(j->'$.b', '[2, 3]');\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1, mvi2) */ * FROM t4 WHERE json_overlaps(j->'$.a', '[1]') AND json_overlaps(j->'$.b', '[2, 3]');\n```\n\n----------------------------------------\n\nTITLE: TiDB Pessimistic Auto-Commit Configuration Parameter (New)\nDESCRIPTION: New TiDB parameter that determines the transaction mode used by auto-commit transactions when pessimistic transaction mode is globally enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\npessimistic-txn.pessimistic-auto-commit\n```\n\n----------------------------------------\n\nTITLE: Replaying Traffic from S3 Storage in SQL\nDESCRIPTION: SQL example showing how to replay traffic from files stored in S3 storage using the TRAFFIC REPLAY syntax, including access key and secret access key.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-traffic-replay.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nTRAFFIC REPLAY FROM \"s3://external/traffic?access-key=${access-key}&secret-access-key=${secret-access-key}\" USER=\"u1\" PASSWORD=\"123456\";\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP Component Locally from Offline Package - Shell\nDESCRIPTION: This snippet installs the TiUP component from the prepared offline package. It extracts the files, runs the local install script, and sets the environment variables for TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntar xzvf tidb-community-server-${version}-linux-amd64.tar.gz && \\\nsh tidb-community-server-${version}-linux-amd64/local_install.sh && \\\nsource /home/tidb/.bash_profile\n```\n\n----------------------------------------\n\nTITLE: Equivalent Index Query Examples\nDESCRIPTION: Demonstrates two equivalent ways to query index information for a specific table in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-statistics.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.STATISTICS\n  WHERE table_name = 'tbl_name'\n  AND table_schema = 'db_name'\n\nSHOW INDEX\n  FROM tbl_name\n  FROM db_name\n```\n\n----------------------------------------\n\nTITLE: Supported File Formats for TiDB Lightning\nDESCRIPTION: TiDB Lightning can import data from various file formats including Dumpling exports, CSV files, and Apache Parquet files from different sources\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- Files exported by [Dumpling](/dumpling-overview.md)\n- CSV files\n- [Apache Parquet files generated by Amazon Aurora](/migrate-aurora-to-tidb.md), Apache Hive, or Snowflake\n```\n\n----------------------------------------\n\nTITLE: Java Example Usage of BookDAO with Stale Reads\nDESCRIPTION: Demonstrates how to use the BookDAO class to perform regular queries, updates, and stale reads on book data, including error handling scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-stale-read.md#2025-04-18_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nList<Book> top5LatestBooks = bookDAO.getTop5LatestBooks();\n\nif (top5LatestBooks.size() > 0) {\n    System.out.println(\"The latest book price (before update): \" + top5LatestBooks.get(0).getPrice());\n\n    Book book = top5LatestBooks.get(0);\n    bookDAO.updateBookPriceByID(book.getId(), book.price + 10);\n\n    top5LatestBooks = bookDAO.getTop5LatestBooks();\n    System.out.println(\"The latest book price (after update): \" + top5LatestBooks.get(0).getPrice());\n\n    // Use the stale read.\n    top5LatestBooks = bookDAO.getTop5LatestBooksWithStaleRead(5);\n    System.out.println(\"The latest book price (maybe stale): \" + top5LatestBooks.get(0).getPrice());\n\n    // Try to stale read the data at the future time.\n    bookDAO.getTop5LatestBooksWithStaleRead(-5);\n\n    // Try to stale read the data before 20 minutes.\n    bookDAO.getTop5LatestBooksWithStaleRead(20 * 60);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Monitoring Services in YAML\nDESCRIPTION: This YAML snippet specifies configuration settings for monitoring services within a TiUP cluster. It sets the 'node_exporter' port to 9100 and the 'blackbox_exporter' port to 9115. The 'monitored' section is used to configure components like 'node_exporter' and 'blackbox_exporter', controlling their ports and directories based on 'global' configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nmonitored:\n  node_exporter_port: 9100\n  blackbox_exporter_port: 9115\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Multiple Indexes in TiDB\nDESCRIPTION: Creates a table with four integer columns, each with its own index. This table structure is used to demonstrate the index merge feature in subsequent examples.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-index-merge.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a int, b int, c int, d int, INDEX idx_a(a), INDEX idx_b(b), INDEX idx_c(c), INDEX idx_d(d));\n```\n\n----------------------------------------\n\nTITLE: Configuring hard-pending-compaction-bytes-limit in TiKV\nDESCRIPTION: This snippet demonstrates how to adjust the `hard-pending-compaction-bytes-limit` parameter in the TiKV configuration file to alleviate `server is busy` errors triggered by too many pending compaction bytes. The parameter controls when the flow control mechanism begins to reject all write requests.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_5\n\nLANGUAGE: TOML\nCODE:\n```\n\"[storage.flow-control] hard-pending-compaction-bytes-limit = \\\"2048GiB\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Swapping Values in Unique Key Columns\nDESCRIPTION: SQL transaction consisting of DELETE and INSERT operations that attempt to swap unique key values between rows, which may cause replication errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM data_table WHERE id = 1;\nDELETE FROM data_table WHERE id = 2;\nINSERT INTO data_table (id, value) VALUES (1, 'v3');\nINSERT INTO data_table (id, value) VALUES (2, 'v1');\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed with Avro and Checksum Validation (Shell)\nDESCRIPTION: Shell command to create a TiCDC changefeed with Avro encoding and checksum validation enabled. It includes settings to prevent numerical precision loss during network transmission.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-integrity-check.md#2025-04-18_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\ncdc cli changefeed create --server=http://127.0.0.1:8300 --changefeed-id=\"kafka-avro-checksum\" --sink-uri=\"kafka://127.0.0.1:9092/topic-name?protocol=avro&enable-tidb-extension=true&avro-decimal-handling-mode=string&avro-bigint-unsigned-handling-mode=string\" --schema-registry=http://127.0.0.1:8081 --config changefeed_config.toml\n```\n\n----------------------------------------\n\nTITLE: Executing Multidimensional GROUP BY with ROLLUP in SQL\nDESCRIPTION: Demonstrates the ROLLUP modifier to generate summary results across multiple grouping levels for year and month columns. The query calculates aggregated profit with automatic subtotals.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-aggregation.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nexplain SELECT year, month, grouping(year), grouping(month), SUM(profit) AS profit FROM bank GROUP BY year, month WITH ROLLUP;\n```\n\n----------------------------------------\n\nTITLE: Transferring Data Source Binding in TiDB Data Migration\nDESCRIPTION: This snippet demonstrates how to change the binding between an upstream MySQL instance and a DM-worker. It uses the transfer-source command to move the binding from one worker to another.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-manage-source.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntransfer-source mysql-replica-01 dm-worker-2\n```\n\n----------------------------------------\n\nTITLE: Querying USER_PRIVILEGES Table Schema Output\nDESCRIPTION: Displays the table structure output showing the four columns: GRANTEE, TABLE_CATALOG, PRIVILEGE_TYPE, and IS_GRANTABLE with their respective data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-user-privileges.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+----------------+--------------+------+------+---------+-------+\n| Field          | Type         | Null | Key  | Default | Extra |\n+----------------+--------------+------+------+---------+-------+\n| GRANTEE        | varchar(81)  | YES  |      | NULL    |       |\n| TABLE_CATALOG  | varchar(512) | YES  |      | NULL    |       |\n| PRIVILEGE_TYPE | varchar(64)  | YES  |      | NULL    |       |\n| IS_GRANTABLE   | varchar(3)   | YES  |      | NULL    |       |\n+----------------+--------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV for Performance Optimization\nDESCRIPTION: TOML configuration for TiKV that optimizes snapshot transfer limits, pessimistic transaction memory limits, Titan storage engine settings, and flow control parameters to improve write performance and reduce I/O bottlenecks.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[server]\nconcurrent-send-snap-limit = 64\nconcurrent-recv-snap-limit = 64\nsnap-io-max-bytes-per-sec = \"400MiB\"\n\n[pessimistic-txn]\nin-memory-peer-size-limit = \"32MiB\"\nin-memory-instance-size-limit = \"512MiB\"\n\n[rocksdb.titan]\nenabled = true\n[rocksdb.defaultcf.titan]\nmin-blob-size = \"1KB\"\nblob-file-compression = \"zstd\"\n\n[storage.flow-control]\nl0-files-threshold = 60\n```\n\n----------------------------------------\n\nTITLE: Describing SESSION_CONNECT_ATTRS Table in SQL\nDESCRIPTION: This SQL snippet describes the columns of the SESSION_CONNECT_ATTRS table within the performance_schema. It contains fields related to session attributes, such as PROCESSLIST_ID, ATTR_NAME, ATTR_VALUE, and ORDINAL_POSITION. Users need access to the performance_schema database to execute this.\nSOURCE: https://github.com/pingcap/docs/blob/master/performance-schema/performance-schema-session-connect-attrs.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE performance_schema;\\nDESCRIBE session_connect_attrs;\n```\n\n----------------------------------------\n\nTITLE: Basic Table Rename Example\nDESCRIPTION: Example showing how to create a table and rename it from t1 to t2.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-rename-table.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (a int);\nRENAME TABLE t1 TO t2;\n```\n\n----------------------------------------\n\nTITLE: Creating Database for Sysbench Testing - SQL\nDESCRIPTION: This SQL command creates a new database 'sbtest' for running Sysbench tests. This step is crucial to prepare the database environment for performance benchmarking of various workloads.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE sbtest;\n```\n\n----------------------------------------\n\nTITLE: Show Stats Healthy Syntax\nDESCRIPTION: This EBNF diagram defines the syntax for the `SHOW STATS_HEALTHY` statement, including optional `LIKE` or `WHERE` clauses for filtering results.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-healthy.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\n\"ShowStatsHealthyStmt ::= \\n    \\\"SHOW\\\" \\\"STATS_HEALTHY\\\" ShowLikeOrWhere?\\n\\nShowLikeOrWhere ::= \\n    \\\"LIKE\\\" SimpleExpr\\n|   \\\"WHERE\\\" Expression\\n\"\n```\n\n----------------------------------------\n\nTITLE: Checking Cluster Health in Shell\nDESCRIPTION: This command checks the health status of Regions in the current cluster before upgrading. It uses the TiUP cluster check command with the --cluster flag.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster check <cluster-name> --cluster\n```\n\n----------------------------------------\n\nTITLE: Normalization IN Predicate\nDESCRIPTION: This example demonstrates the normalization process on SQL statements using the `IN` predicate. Specifically, `?` within the `IN` predicate is normalized as `...`, meaning any `IN` predicates of different lengths are recognized as the same statement, so only one binding is needed.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM books WHERE type IN ('Novel')\nSELECT * FROM books WHERE type IN ('Novel','Life','Education')\n-- After normalization, the above statements are as follows:\nSELECT * FROM bookshop . books WHERE type IN ( ... )\nSELECT * FROM bookshop . books WHERE type IN ( ... )\n```\n\n----------------------------------------\n\nTITLE: UPDATE Statements Generated by TiCDC\nDESCRIPTION: SQL UPDATE statements that TiCDC generates when replicating row changes from the combined DELETE and INSERT operations in the upstream transaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE data_table SET value = 'v3' WHERE id = 1;\nUPDATE data_table SET value = 'v1' WHERE id = 2;\n```\n\n----------------------------------------\n\nTITLE: Backing Up Multiple Tables Using Filter to S3\nDESCRIPTION: Command to back up multiple tables from a TiDB cluster to Amazon S3 storage using the BR tool with a table filter. It uses a filter pattern to select tables for backup.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full \\\n    --pd \"${PD_IP}:2379\" \\\n    --filter 'db*.tbl*' \\\n    --storage \"s3://${backup_collection_addr}/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --ratelimit 128 \\\n    --log-file backupfull.log\n```\n\n----------------------------------------\n\nTITLE: Setting TiFlash max_threads Variable\nDESCRIPTION: This SQL statement modifies the `tidb_max_tiflash_threads` system variable, used to adjust the maximum concurrency for TiFlash. Setting the value to 10 limits TiFlash to using 10 threads per request.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nset tidb_max_tiflash_threads = 10;\n```\n\n----------------------------------------\n\nTITLE: Retrieving Backup Time Point from Snapshot Backup\nDESCRIPTION: Command to extract and decode the end-version (timestamp) from a snapshot backup stored in S3, which helps identify the physical time of the backup for management purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-guide.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup br validate decode --field=\"end-version\" \\\n--storage \"s3://backup-101/snapshot-202209081330?access-key=${access-key}&secret-access-key=${secret-access-key}\" | tail -n1\n```\n\n----------------------------------------\n\nTITLE: Reloading Extended Statistics Cache\nDESCRIPTION: Administrative command to reload the extended statistics cache if direct modifications were made to the system table. This ensures all TiDB nodes have consistent cache data.\nSOURCE: https://github.com/pingcap/docs/blob/master/extended-statistics.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nADMIN RELOAD STATS_EXTENDED;\n```\n\n----------------------------------------\n\nTITLE: Decoding SQL Digests in SQL Transactions\nDESCRIPTION: This SQL snippet fetches transaction IDs, SQL digest arrays, and decoded SQL statements from the TIDB_TRX table. It uses the TIDB_DECODE_SQL_DIGESTS function to translate SQL digests into human-readable SQL statements. High overhead is involved during execution; thus, it is not recommended for clusters with many concurrent transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-trx.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, all_sql_digests, tidb_decode_sql_digests(all_sql_digests) AS all_sqls FROM INFORMATION_SCHEMA.TIDB_TRX\\G\n```\n\n----------------------------------------\n\nTITLE: Disable TiDB Dashboard\nDESCRIPTION: Command to disable TiDB Dashboard functionality across all PD instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-deploy.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd -u http://127.0.0.1:2379 config set dashboard-address none\n```\n\n----------------------------------------\n\nTITLE: Creating a Master Key with AWS KMS - Shell\nDESCRIPTION: This snippet shows how to create a master key using AWS KMS via the command line interface. It specifies the region and operations for creating a key and an alias.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\naws --region us-west-2 kms create-key\naws --region us-west-2 kms create-alias --alias-name \"alias/tidb-tde\" --target-key-id 0987dcba-09fe-87dc-65ba-ab0987654321\n```\n\n----------------------------------------\n\nTITLE: Defining TiDB Server Panic Alert Rule in Prometheus\nDESCRIPTION: Alert rule to detect panics in TiDB threads. Triggers when any panic occurs in the last 10 minutes.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_3\n\nLANGUAGE: prometheus\nCODE:\n```\nincrease(tidb_server_panic_total[10m]) > 0\n```\n\n----------------------------------------\n\nTITLE: Sending an HTTP Upgrade Start Request in TiDB\nDESCRIPTION: This snippet demonstrates how to initiate the smooth upgrade process by sending an HTTP POST request to a TiDB node. It enters the cluster into an 'Upgrading' state and pauses ongoing DDL operations. Prerequisites include having a running TiDB cluster where the version supports this feature.\nSOURCE: https://github.com/pingcap/docs/blob/master/smooth-upgrade-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://{TiDBIP}:10080/upgrade/start\n```\n\n----------------------------------------\n\nTITLE: Example STATISTICS Table Output\nDESCRIPTION: Shows the complete structure of the STATISTICS table with all its fields, their data types, and properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-statistics.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+---------------+---------------+------+------+---------+-------+\n| Field         | Type          | Null | Key  | Default | Extra |\n+---------------+---------------+------+------+---------+-------+\n| TABLE_CATALOG | varchar(512)  | YES  |      | NULL    |       |\n| TABLE_SCHEMA  | varchar(64)   | YES  |      | NULL    |       |\n| TABLE_NAME    | varchar(64)   | YES  |      | NULL    |       |\n| NON_UNIQUE    | varchar(1)    | YES  |      | NULL    |       |\n| INDEX_SCHEMA  | varchar(64)   | YES  |      | NULL    |       |\n| INDEX_NAME    | varchar(64)   | YES  |      | NULL    |       |\n| SEQ_IN_INDEX  | bigint(2)     | YES  |      | NULL    |       |\n| COLUMN_NAME   | varchar(21)   | YES  |      | NULL    |       |\n| COLLATION     | varchar(1)    | YES  |      | NULL    |       |\n| CARDINALITY   | bigint(21)    | YES  |      | NULL    |       |\n| SUB_PART      | bigint(3)     | YES  |      | NULL    |       |\n| PACKED        | varchar(10)   | YES  |      | NULL    |       |\n| NULLABLE      | varchar(3)    | YES  |      | NULL    |       |\n| INDEX_TYPE    | varchar(16)   | YES  |      | NULL    |       |\n| COMMENT       | varchar(16)   | YES  |      | NULL    |       |\n| INDEX_COMMENT | varchar(1024) | YES  |      | NULL    |       |\n| IS_VISIBLE    | varchar(3)    | YES  |      | NULL    |       |\n| Expression    | varchar(64)   | YES  |      | NULL    |       |\n+---------------+---------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Enable gRPC Message Compression in TiKV\nDESCRIPTION: This code snippet enables gRPC message compression in TiKV using gzip. This reduces network traffic when transmitting data within the cluster, particularly beneficial in multi-region deployments.\nSOURCE: https://github.com/pingcap/docs/blob/master/three-data-centers-in-two-cities-deployment.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n\"server.grpc-compression-type: gzip\"\n```\n\n----------------------------------------\n\nTITLE: RESTORE SQL Command in TiDB\nDESCRIPTION: The EBNF description for the RESTORE SQL statement syntax, used for restoring databases or tables from backup archives in TiDB. This statement uses options such as CHECKSUM_CONCURRENCY, CONCURRENCY, and CHECKSUM, among others, to fine-tune the restoration process. Syntax also includes parameters for storage sources like S3. Ensure to meet prerequisites like having the necessary privileges and conditions before running the command.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-restore.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nRestoreStmt ::= \n    \"RESTORE\" BRIETables \"FROM\" stringLit RestoreOption*\n\nBRIETables ::= \n    \"DATABASE\" ( '*' | DBName (',' DBName)* )\n|   \"TABLE\" TableNameList\n\nRestoreOption ::= \n    \"CHECKSUM_CONCURRENCY\" '='? LengthNum\n|   \"CONCURRENCY\" '='? LengthNum\n|   \"CHECKSUM\" '='? Boolean\n|   \"LOAD_STATS\" '='? Boolean\n|   \"RATE_LIMIT\" '='? LengthNum \"MB\" '/' \"SECOND\"\n|   \"SEND_CREDENTIALS_TO_TIKV\" '='? Boolean\n|   \"WAIT_TIFLASH_READY\" '='? Boolean\n|   \"WITH_SYS_TABLE\" '='? Boolean\n\nBoolean ::= \n    NUM | \"TRUE\" | \"FALSE\"\n```\n\n----------------------------------------\n\nTITLE: Introduction of New System Variables in TiDB (Markdown)\nDESCRIPTION: Enumerates newly added system variables that provide enhanced functionality and configurability in version 8.4.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.4.0.md#2025-04-18_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n| [`tidb_auto_analyze_concurrency`](/system-variables.md#tidb_auto_analyze_concurrency-new-in-v840)| Newly added | Sets the concurrency for auto-analyze operations within a TiDB cluster. Before v8.4.0, this concurrency is fixed at `1`. To speed up statistics collection tasks, you can increase this concurrency based on your cluster's available resources. |\n| [`tidb_enable_instance_plan_cache`](/system-variables.md#tidb_enable_instance_plan_cache-new-in-v840)| Newly added | Controls whether to enable the Instance Plan Cache feature. |\n| [`tidb_enable_stats_owner`](/system-variables.md#tidb_enable_stats_owner-new-in-v840)| Newly added | Controls whether the corresponding TiDB instance can run automatic statistics update tasks. |\n| [`tidb_hash_join_version`](/system-variables.md#tidb_hash_join_version-new-in-v840) | Newly added | Controls whether TiDB uses an optimized version of the Hash Join operator. The default value of `legacy` means that the optimized version is not used. If you set it to `optimized`, TiDB uses the optimized version of the Hash Join operator when executing it to improve Hash Join performance. |\n| [`tidb_instance_plan_cache_max_size`](/system-variables.md#tidb_instance_plan_cache_max_size-new-in-v840) | Newly added | Sets the maximum memory usage for Instance Plan Cache. |\n| [`tidb_instance_plan_cache_reserved_percentage`](/system-variables.md#tidb_instance_plan_cache_reserved_percentage-new-in-v840) | Newly added | Controls the percentage of idle memory reserved for Instance Plan Cache after memory eviction. |\n| [`tidb_pre_split_regions`](/system-variables.md#tidb_pre_split_regions-new-in-v840) | Newly added | Before v8.4.0, setting the default number of row split slices for newly created tables required declaring `PRE_SPLIT_REGIONS` in each `CREATE TABLE` SQL statement, which is complicated once a large number of tables need to be similarly configured. This variable is introduced to solve such problems. You can set this system variable at the `GLOBAL` or `SESSION` level to improve usability. |\n| [`tidb_shard_row_id_bits`](/system-variables.md#tidb_shard_row_id_bits-new-in-v840) | Newly added | Before v8.4.0, setting the default number of slices for row IDs for newly created tables required declaring `SHARD_ROW_ID_BITS` in each `CREATE TABLE` or `ALTER TABLE` SQL statement, which is complicated once a large number of tables need to be similarly configured. This variable is introduced to solve such problems. You can set this system variable at the `GLOBAL` or `SESSION` level to improve usability. |\n| [`tidb_tso_client_rpc_mode`](/system-variables.md#tidb_tso_client_rpc_mode-new-in-v840) | Newly added | Switches the mode in which TiDB sends TSO RPC requests to PD. The mode determines whether TSO RPC requests can be processed in parallel and affects the time spent on batch-waiting for each TS retrieval operation, thereby helping reduce the wait time for retrieving TS during the execution of queries in certain scenarios. |\n```\n\n----------------------------------------\n\nTITLE: Restoring TiDB data with encryption key in URI\nDESCRIPTION: This command demonstrates including the encryption-key parameter in the Azure Blob Storage URI when restoring TiDB data.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full --pd <pd-address> --storage \"azure://<bucket>/<prefix>?encryption-key=<aes256-key>\"\n```\n\n----------------------------------------\n\nTITLE: Specifying SQL Mode in TiDB\nDESCRIPTION: Defines the default SQL mode for parsing and executing SQL statements in TiDB, influencing how certain SQL queries are handled.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_13\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- Example: `\"ONLY_FULL_GROUP_BY,NO_AUTO_CREATE_USER\"` -->\n```\n\n----------------------------------------\n\nTITLE: Creating MySQL Data Source in DM\nDESCRIPTION: Command to create a MySQL data source in the DM cluster using dmctl and a configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-task.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n./dmctl --master-addr=127.0.0.1:8261 operate-source create conf/source1.yaml\n```\n\n----------------------------------------\n\nTITLE: TiDB ADMIN SHOW Statements\nDESCRIPTION: SQL statements for showing next row ID, slow queries, and creating workload snapshots.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW t NEXT_ROW_ID;\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW SLOW RECENT N;\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW SLOW TOP [INTERNAL | ALL] N;\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN CREATE WORKLOAD SNAPSHOT;\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for SHOW PROCESSLIST\nDESCRIPTION: Defines the formal grammatical structure for the SHOW PROCESSLIST statement, indicating optional FULL keyword and basic syntax\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-processlist.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowProcesslistStmt ::=\n    \"SHOW\" \"FULL\"? \"PROCESSLIST\"\n```\n\n----------------------------------------\n\nTITLE: Defining PD Endpoints\nDESCRIPTION: This snippet outlines how to configure PD endpoints for TiKV, including syntax for specifying multiple endpoints separated by commas and default settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n+ The endpoints of PD. When multiple endpoints are specified, you need to separate them using commas.\n+ Default value: `[\"127.0.0.1:2379\"]`\n```\n\n----------------------------------------\n\nTITLE: Generating Incremental Data with Sysbench\nDESCRIPTION: Bash command using Sysbench to continuously generate incremental data in the upstream MySQL database for 30 minutes, simulating real-time data changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-performance-test.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nsysbench --test=oltp_insert --tables=4 --num-threads=32 --mysql-host=172.17.4.40 --mysql-port=3306 --mysql-user=root --mysql-db=dm_benchmark --db-driver=mysql --report-interval=10 --time=1800 run\n```\n\n----------------------------------------\n\nTITLE: Starting DM Cluster Services with tiup dm start\nDESCRIPTION: This command starts services in a specified DM cluster. It supports options for selecting specific nodes or roles to start. The cluster name is required, and additional flags can be used to customize the startup process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-start.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm start <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Fixing ADMIN REPAIR TABLE Statement in TiDB\nDESCRIPTION: This fix enables the ADMIN REPAIR TABLE statement to correctly parse integers in expressions on range partitions. It improves the functionality of table repair operations for partitioned tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.5.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN REPAIR TABLE\n```\n\n----------------------------------------\n\nTITLE: Setting Dynamic Partition Prune Mode\nDESCRIPTION: Sets the session-level partition pruning mode to dynamic. This affects how TiDB handles partitioned tables for manual ANALYZE and normal queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_71\n\nLANGUAGE: sql\nCODE:\n```\nset @@session.tidb_partition_prune_mode = 'dynamic'\n```\n\n----------------------------------------\n\nTITLE: TIFLASH_SEGMENTS Table Schema Definition\nDESCRIPTION: Detailed table structure showing all columns in the TIFLASH_SEGMENTS table including field names, data types, and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tiflash-segments.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------------+-------------+------+------+---------+-------+\n| Field                         | Type        | Null | Key  | Default | Extra |\n+-------------------------------+-------------+------+------+---------+-------+\n| DATABASE                      | varchar(64) | YES  |      | NULL    |       |\n| TABLE                         | varchar(64) | YES  |      | NULL    |       |\n| TIDB_DATABASE                 | varchar(64) | YES  |      | NULL    |       |\n| TIDB_TABLE                    | varchar(64) | YES  |      | NULL    |       |\n| TABLE_ID                      | bigint(64)  | YES  |      | NULL    |       |\n| IS_TOMBSTONE                  | bigint(64)  | YES  |      | NULL    |       |\n| SEGMENT_ID                    | bigint(64)  | YES  |      | NULL    |       |\n| RANGE                         | varchar(64) | YES  |      | NULL    |       |\n| EPOCH                         | bigint(64)  | YES  |      | NULL    |       |\n| ROWS                          | bigint(64)  | YES  |      | NULL    |       |\n| SIZE                          | bigint(64)  | YES  |      | NULL    |       |\n| DELTA_RATE                    | double      | YES  |      | NULL    |       |\n| DELTA_MEMTABLE_ROWS           | bigint(64)  | YES  |      | NULL    |       |\n| DELTA_MEMTABLE_SIZE           | bigint(64)  | YES  |      | NULL    |       |\n| DELTA_MEMTABLE_COLUMN_FILES   | bigint(64)  | YES  |      | NULL    |       |\n| DELTA_MEMTABLE_DELETE_RANGES  | bigint(64)  | YES  |      | NULL    |       |\n| DELTA_PERSISTED_PAGE_ID       | bigint(64)  | YES  |      | NULL    |       |\n| DELTA_PERSISTED_ROWS          | bigint(64)  | YES  |      | NULL    |       |\n| DELTA_PERSISTED_SIZE          | bigint(64)  | YES  |      | NULL    |       |\n| DELTA_PERSISTED_COLUMN_FILES  | bigint(64)  | YES  |      | NULL    |       |\n| DELTA_PERSISTED_DELETE_RANGES | bigint(64)  | YES  |      | NULL    |       |\n| DELTA_CACHE_SIZE              | bigint(64)  | YES  |      | NULL    |       |\n| DELTA_INDEX_SIZE              | bigint(64)  | YES  |      | NULL    |       |\n| STABLE_PAGE_ID                | bigint(64)  | YES  |      | NULL    |       |\n| STABLE_ROWS                   | bigint(64)  | YES  |      | NULL    |       |\n| STABLE_SIZE                   | bigint(64)  | YES  |      | NULL    |       |\n| STABLE_DMFILES                | bigint(64)  | YES  |      | NULL    |       |\n| STABLE_DMFILES_ID_0           | bigint(64)  | YES  |      | NULL    |       |\n| STABLE_DMFILES_ROWS           | bigint(64)  | YES  |      | NULL    |       |\n| STABLE_DMFILES_SIZE           | bigint(64)  | YES  |      | NULL    |       |\n| STABLE_DMFILES_SIZE_ON_DISK   | bigint(64)  | YES  |      | NULL    |       |\n| STABLE_DMFILES_PACKS          | bigint(64)  | YES  |      | NULL    |       |\n| TIFLASH_INSTANCE              | varchar(64) | YES  |      | NULL    |       |\n+-------------------------------+-------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Installing BR using TiUP in TiDB\nDESCRIPTION: Command for installing the BR (Backup & Restore) tool at version 8.5.0 using TiUP package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-use-cases.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup install br:v8.5.0\n```\n\n----------------------------------------\n\nTITLE: Monitoring TiFlash Schema Errors using PromQL\nDESCRIPTION: This PromQL query alerts when there are any schema apply failures in the last 15 minutes. It helps detect issues with schema changes in TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-alert-rules.md#2025-04-18_snippet_0\n\nLANGUAGE: promql\nCODE:\n```\nincrease(tiflash_schema_apply_count{type=\"failed\"}[15m]) > 0\n```\n\n----------------------------------------\n\nTITLE: Converting String to Vector in TiDB SQL\nDESCRIPTION: VEC_FROM_TEXT function converts a string representation into a vector type for vector operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-functions-and-operators.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VEC_FROM_TEXT('[1,2]') + VEC_FROM_TEXT('[3,4]');\n```\n\n----------------------------------------\n\nTITLE: Querying TiCDC Service Process List - TiCDC - Shell\nDESCRIPTION: This example demonstrates how to retrieve a list of TiCDC service processes (captures) using a GET request to the `/api/v1/captures` endpoint.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v1/captures\n```\n\n----------------------------------------\n\nTITLE: Showing User Privileges in TiDB\nDESCRIPTION: Display the privileges granted to a specific user using the SHOW GRANTS statement, which lists all privileges for the specified user account.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS FOR 'admin'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Documentation Navigation Structure in Markdown\nDESCRIPTION: Markdown-formatted navigation structure organizing documentation links into categories like billing, partner integrations, APIs, and SQL references for TiDB Cloud\nSOURCE: https://github.com/pingcap/docs/blob/master/TOC-tidb-cloud.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n  - [Cost Explorer](/tidb-cloud/tidb-cloud-billing.md#cost-explorer)\n  - [Billing Profile](/tidb-cloud/tidb-cloud-billing.md#billing-profile)\n  - [Credits](/tidb-cloud/tidb-cloud-billing.md#credits)\n  - [Payment Method Setting](/tidb-cloud/tidb-cloud-billing.md#payment-method)\n  - [Billing from AWS or GCP Marketplace](/tidb-cloud/tidb-cloud-billing.md#billing-from-aws-marketplace-or-google-cloud-marketplace)\n  - [Billing for Changefeed](/tidb-cloud/tidb-cloud-billing-ticdc-rcu.md)\n  - [Billing for Data Migration](/tidb-cloud/tidb-cloud-billing-dm.md)\n```\n\n----------------------------------------\n\nTITLE: Selecting TiFlash max_threads Variable\nDESCRIPTION: This SQL statement retrieves the current value of `tidb_max_tiflash_threads` to verify the change. The variable's value should reflect the setting from the previous SET command.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nselect @@tidb_max_tiflash_threads;\n```\n\n----------------------------------------\n\nTITLE: Example of Detecting Index Inconsistency\nDESCRIPTION: SQL commands showing how to detect inconsistent data and index issues in a table using SELECT and ADMIN CHECK INDEX commands.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-cleanup.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM tbl;\nERROR 1105 (HY000): inconsistent index idx handle count 3 isn't equal to value count 2\n\nADMIN CHECK INDEX tbl idx ;\nERROR 1105 (HY000): handle &kv.CommonHandle{encoded:[]uint8{0x1, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0xf8}, colEndOffsets:[]uint16{0xa}}, index:types.Datum{k:0x5, decimal:0x0, length:0x0, i:0, collation:\"utf8mb4_bin\", b:[]uint8{0x0}, x:interface {}(nil)} != record:<nil>\n```\n\n----------------------------------------\n\nTITLE: Problematic DDL Statement\nDESCRIPTION: DDL statement that adds a column with UNIQUE constraint, which is not supported by TiDB and causes migration failure.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE `shard_db_*`.`shard_table_*` ADD COLUMN new_col INT UNIQUE;\n```\n\n----------------------------------------\n\nTITLE: Enabling automatic repair during scale-out check\nDESCRIPTION: This command extends the `check` command by enabling automatic repair of detected issues using the `--apply` flag. This attempts to automatically resolve potential risks before the scale-out operation, ensuring a smoother process.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster check <cluster-name> scale-out.yml --cluster --apply --user root [-p] [-i /home/root/.ssh/gcp_rsa]\"\n```\n\n----------------------------------------\n\nTITLE: Splitting Index Data for Integer Type in SQL\nDESCRIPTION: This SQL statement splits the index 'idx' of table 't' into 16 Regions, evenly dividing the integer range from minimum to maximum 64-bit integers.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT TABLE t INDEX idx BETWEEN (-9223372036854775808) AND (9223372036854775807) REGIONS 16;\n```\n\n----------------------------------------\n\nTITLE: SQL Query with Array Parameter\nDESCRIPTION: SQL statement showing how to use array parameters with the IN clause. When using array parameters, parentheses must be added around the parameter to ensure valid SQL syntax when the parameter is converted to comma-separated values.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-manage-endpoint.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM table_name WHERE id IN (${ID})\n```\n\n----------------------------------------\n\nTITLE: Stopping TiDB Cluster Services with TiUP\nDESCRIPTION: This command stops all or specific services in a TiDB cluster. It accepts options to target specific nodes or roles. The cluster name is required, and various flags can be used to customize the stop operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-stop.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster stop <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Checking TiFlash Version Using Command Line\nDESCRIPTION: Command to check TiFlash version by executing the binary with the required library path set. This requires setting the LD_LIBRARY_PATH environment variable to include the directory containing libtiflash_proxy.so.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/maintain-tiflash.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nLD_LIBRARY_PATH=./ ./tiflash version\n```\n\n----------------------------------------\n\nTITLE: Running query-status to Check Synchronization\nDESCRIPTION: This snippet outlines the command to fetch the current binlog position after a DROP TABLE command has been executed. This is essential to ensure that the data migration has progressed beyond the DROP TABLE statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/shard-merge-best-practices.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nquery-status;\n```\n\n----------------------------------------\n\nTITLE: Finding Table Name from tableID\nDESCRIPTION: HTTP request to retrieve the table name associated with a specific tableID from TiDB's HTTP API, useful for identifying tables involved in write conflicts.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-write-conflicts.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncurl http://{TiDBIP}:10080/db-table/{tableID}\n```\n\n----------------------------------------\n\nTITLE: Building and Deploying Lambda Package\nDESCRIPTION: Commands for building the integration package and deploying it to AWS Lambda using Maven and SAM CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-aws-appflow-integration.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd tidb-appflow-integration\nmvn clean package\n```\n\n----------------------------------------\n\nTITLE: Enabling TiDB Log Desensitization\nDESCRIPTION: To enable TiDB log desensitization, the system variable `tidb_redact_log` needs to be set to `MARKER`.  This marks the SQL text in TiDB logs, allowing sensitive data to be displayed securely based on the markers, thus protecting log information.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n\"tidb_redact_log` to `MARKER`\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Partitioned Table with TiFlash Replicas in TiDB\nDESCRIPTION: Creates a partitioned 'employees' table with 4 partitions and configures it with 2 TiFlash replicas. This setup is used in subsequent compaction examples.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table-compact.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    store_id INT\n)\nPARTITION BY LIST (store_id) (\n    PARTITION pNorth VALUES IN (1, 2, 3, 4, 5),\n    PARTITION pEast VALUES IN (6, 7, 8, 9, 10),\n    PARTITION pWest VALUES IN (11, 12, 13, 14, 15),\n    PARTITION pCentral VALUES IN (16, 17, 18, 19, 20)\n);\nALTER TABLE employees SET TIFLASH REPLICA 2;\n```\n\n----------------------------------------\n\nTITLE: JSON_EXTRACT() Result Example\nDESCRIPTION: The output shows that JSON_EXTRACT() returns the property value with quotes preserved.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-modify.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------------------------------+\n| JSON_EXTRACT('{\"database\": \"TiDB\"}', '$.database') |\n+----------------------------------------------------+\n| \"TiDB\"                                             |\n+----------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Executing Shipping Priority Query - SQL\nDESCRIPTION: This SQL statement is a shipping priority query against the 'test' database using the row-based storage engine. It calculates potential revenue, sorts orders by descending revenue, and limits the output to the top 10 unshipped orders, highlighting row-based processing performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-htap.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nUSE test;\nSELECT\n    l_orderkey,\n    SUM(\n        l_extendedprice * (1 - l_discount)\n    ) AS revenue,\n    o_orderdate,\n    o_shippriority\nFROM\n    customer,\n    orders,\n    lineitem\nWHERE\n    c_mktsegment = 'BUILDING'\nAND c_custkey = o_custkey\nAND l_orderkey = o_orderkey\nAND o_orderdate < DATE '1996-01-01'\nAND l_shipdate > DATE '1996-02-01'\nGROUP BY\n    l_orderkey,\n    o_orderdate,\n    o_shippriority\nORDER BY\n    revenue DESC,\n    o_orderdate\nlimit 10;\n```\n\n----------------------------------------\n\nTITLE: Creating Users and Roles in TiDB SQL\nDESCRIPTION: SQL commands to create a user 'u1'@'%' and three roles 'r1'@'%', 'r2'@'%', and 'r3'@'%'. It also grants these roles to the user and sets 'r1'@'%' as the default role.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-role.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'u1'@'%';\nCREATE ROLE 'r1', 'r2', 'r3';\nGRANT 'r1', 'r2', 'r3' TO 'u1'@'%';\nSET DEFAULT ROLE 'r1' TO 'u1'@'%';\n```\n\n----------------------------------------\n\nTITLE: Executing Log Backup Compaction with tikv-ctl\nDESCRIPTION: Command to initiate log backup compaction using tikv-ctl. It specifies the time range for compaction with --from and --until parameters, uses the Base64-encoded storage string, and sets the maximum number of concurrent compaction tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-compact-log-backup.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --log-level info compact-log-backup \\\n    --from \"<start-tso>\" --until \"<end-tso>\" \\\n    -s 'bAsE64==' -N 8\n```\n\n----------------------------------------\n\nTITLE: Prometheus API Response Format\nDESCRIPTION: Example JSON response from Prometheus API showing time series data for TiKV engine size. The response includes metric labels, timestamp-value pairs, and query status.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/grafana-monitor-best-practices.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"data\": {\n        \"result\": [\n            {\n                \"metric\": {\n                    \"instance\": \"xxxxxxxxxx:20180\"\n                },\n                \"values\": [\n                    [\n                        1565879269,\n                        \"1006046235280\"\n                    ],\n                    [\n                        1565879299,\n                        \"1006057877794\"\n                    ],\n                    [\n                        1565879329,\n                        \"1006021550039\"\n                    ],\n                    [\n                        1565879359,\n                        \"1006021550039\"\n                    ],\n                    [\n                        1565882869,\n                        \"1006132630123\"\n                    ]\n                ]\n            }\n        ],\n        \"resultType\": \"matrix\"\n    },\n    \"status\": \"success\"\n}\n```\n\n----------------------------------------\n\nTITLE: Hexadecimal Output Examples\nDESCRIPTION: Shows converting between strings and hexadecimal format using HEX function.\nSOURCE: https://github.com/pingcap/docs/blob/master/literal-values.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT HEX('TiDB');\n+-------------+\n| HEX('TiDB') |\n+-------------+\n| 54694442    |\n+-------------+\n1 row in set (0.01 sec)\n\nmysql> SELECT X'54694442';\n+-------------+\n| X'54694442' |\n+-------------+\n| TiDB        |\n+-------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: ADMIN CLEANUP Syntax Definition in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the ADMIN CLEANUP statement, showing both INDEX cleanup and TABLE LOCK cleanup options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-cleanup.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAdminCleanupStmt ::=\n    'ADMIN' 'CLEANUP' ( 'INDEX' TableName IndexName | 'TABLE' 'LOCK' TableNameList )\n\nTableNameList ::=\n    TableName ( ',' TableName )*\n```\n\n----------------------------------------\n\nTITLE: SQL System Variable Configuration\nDESCRIPTION: Configuration setting for enabling fast index creation which can triple the performance of adding indexes. This is controlled through the tidb_ddl_enable_fast_reorg system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.3.0.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ntidb_ddl_enable_fast_reorg\n```\n\n----------------------------------------\n\nTITLE: SHUTDOWN Statement Usage Example in SQL\nDESCRIPTION: A simple example showing how to execute the SHUTDOWN statement in TiDB SQL, along with the expected output indicating successful execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-shutdown.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHUTDOWN;\n```\n\nLANGUAGE: plaintext\nCODE:\n```\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Examples of SET SESSION TRANSACTION in MySQL\nDESCRIPTION: This snippet demonstrates multiple examples of using the SET SESSION TRANSACTION statement in MySQL. It shows setting various transaction isolation levels and retrieving the current transaction isolation settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-transaction.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW SESSION VARIABLES LIKE 'transaction_isolation';\n+-----------------------+-----------------+\n| Variable_name         | Value           |\n+-----------------------+-----------------+\n| transaction_isolation | REPEATABLE-READ |\n+-----------------------+-----------------+\n1 row in set (0.00 sec)\n\nmysql> SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SHOW SESSION VARIABLES LIKE 'transaction_isolation';\n+-----------------------+----------------+\n| Variable_name         | Value          |\n+-----------------------+----------------+\n| transaction_isolation | READ-COMMITTED |\n+-----------------------+----------------+\n1 row in set (0.01 sec)\n\nmysql> SET SESSION transaction_isolation = 'REPEATABLE-READ';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SHOW SESSION VARIABLES LIKE 'transaction_isolation';\n+-----------------------+-----------------+\n| Variable_name         | Value           |\n+-----------------------+-----------------+\n| transaction_isolation | REPEATABLE-READ |\n+-----------------------+-----------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Statement Summary Persistence in TiDB\nDESCRIPTION: TOML configuration to enable statement summary persistence in TiDB, which saves statement summary data to disk instead of memory. This experimental feature prevents data loss during server restarts and includes optional parameters for log file management.\nSOURCE: https://github.com/pingcap/docs/blob/master/statement-summary-tables.md#2025-04-18_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[instance]\ntidb_stmt_summary_enable_persistent = true\n# The following entries use the default values, which can be modified as needed.\n# tidb_stmt_summary_filename = \"tidb-statements.log\"\n# tidb_stmt_summary_file_max_days = 3\n# tidb_stmt_summary_file_max_size = 64 # MiB\n```\n\n----------------------------------------\n\nTITLE: Example GCS URI for TiDB Lightning and BR\nDESCRIPTION: Shows how to format a Google Cloud Storage URI for TiDB Lightning and BR tools, specifying a folder path and credentials file.\nSOURCE: https://github.com/pingcap/docs/blob/master/external-storage-uri.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ngcs://external/testfolder?credentials-file=${credentials-file-path}\n```\n\n----------------------------------------\n\nTITLE: Setting Session Time Zone in TiDB\nDESCRIPTION: SQL commands to set the time zone at the session level with examples.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-time-zone.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET time_zone = ${time-zone-value};\nSET time_zone = 'US/Pacific';\n```\n\n----------------------------------------\n\nTITLE: ANALYZE Statement Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the ANALYZE statement in TiDB, including options for table, index, and partition analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-analyze-table.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nAnalyzeTableStmt ::=\n    'ANALYZE' ( 'TABLE' ( TableNameList ( 'ALL COLUMNS' | 'PREDICATE COLUMNS' ) | TableName ( 'INDEX' IndexNameList? | AnalyzeColumnOption | 'PARTITION' PartitionNameList ( 'INDEX' IndexNameList? | AnalyzeColumnOption )? )? ) ) AnalyzeOptionListOpt\n\nAnalyzeOptionListOpt ::=\n( WITH AnalyzeOptionList )?\n\nAnalyzeOptionList ::=\nAnalyzeOption ( ',' AnalyzeOption )*\n\nAnalyzeOption ::=\n( NUM ( 'BUCKETS' | 'TOPN' | ( 'CMSKETCH' ( 'DEPTH' | 'WIDTH' ) ) | 'SAMPLES' ) ) | ( FLOATNUM 'SAMPLERATE' )\n\nAnalyzeColumnOption ::=\n( 'ALL COLUMNS' | 'PREDICATE COLUMNS' | 'COLUMNS' ColumnNameList )\n\nTableNameList ::=\n    TableName (',' TableName)*\n\nTableName ::=\n    Identifier ( '.' Identifier )?\n\nColumnNameList ::=\n    Identifier ( ',' Identifier )*\n\nIndexNameList ::=\n    Identifier ( ',' Identifier )*\n\nPartitionNameList ::=\n    Identifier ( ',' Identifier )*\n```\n\n----------------------------------------\n\nTITLE: TiDB SQL Command Example\nDESCRIPTION: Example of ALTER PLACEMENT POLICY command mentioned in fixes\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.5.2.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER PLACEMENT POLICY\n```\n\n----------------------------------------\n\nTITLE: Filtering Region Information by Store ID in TiDB\nDESCRIPTION: Example of using the WHERE clause with SHOW TABLE REGIONS to filter Regions by leader store ID. This allows viewing only the Regions hosted on a specific store.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-regions.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\ntest> SHOW TABLE t REGIONS WHERE leader_store_id =1;\n```\n\n----------------------------------------\n\nTITLE: Example Processor List Output\nDESCRIPTION: This is an example output of the `cdc cli processor list` command. It shows the ID, capture-id, and changefeed-id of each processor.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n[\n        {\n                \"id\": \"9f84ff74-abf9-407f-a6e2-56aa35b33888\",\n                \"capture-id\": \"b293999a-4168-4988-a4f4-35d9589b226b\",\n                \"changefeed-id\": \"simple-replication-task\"\n        }\n]\n```\n\n----------------------------------------\n\nTITLE: Calculating TiDB Node Number for Expected Performance\nDESCRIPTION: Formula to estimate the number of TiDB nodes needed based on expected performance, workload type, and performance metrics of a single node. It accounts for performance deviation coefficients when the number of nodes exceeds 8.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/size-your-cluster.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`node num = ceil(overall expected performance ÷ performance per node * (1 - performance deviation coefficient))`\n```\n\n----------------------------------------\n\nTITLE: Querying Conflict Errors in SQL\nDESCRIPTION: SQL query to retrieve conflict error information from the 'lightning_task_info.conflict_error_v3' table, showing table name, index name, key data, and row data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-physical-import-mode-usage.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nselect table_name,index_name,key_data,row_data from conflict_error_v3 limit 10;\n```\n\n----------------------------------------\n\nTITLE: Using Default Index Selectivity Ratio in TiDB SQL\nDESCRIPTION: Example showing query execution with the default value (-1) for tidb_opt_ordering_index_selectivity_ratio. This uses the existing estimation formula, assuming a small percentage of rows are scanned before finding qualified rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_56\n\nLANGUAGE: sql\nCODE:\n```\n> SET SESSION tidb_opt_ordering_index_selectivity_ratio = -1;\n\n> EXPLAIN SELECT * FROM t USE INDEX (ia) WHERE b <= 9000 ORDER BY a LIMIT 1;\n+-----------------------------------+---------+-----------+-----------------------+---------------------------------+\n| id                                | estRows | task      | access object         | operator info                   |\n+-----------------------------------+---------+-----------+-----------------------+---------------------------------+\n| Limit_12                          | 1.00    | root      |                       | offset:0, count:1               |\n| └─Projection_22                   | 1.00    | root      |                       | test.t.a, test.t.b, test.t.c    |\n|   └─IndexLookUp_21                | 1.00    | root      |                       |                                 |\n|     ├─IndexFullScan_18(Build)     | 109.20  | cop[tikv] | table:t, index:ia(a)  | keep order:true                 |\n|     └─Selection_20(Probe)         | 1.00    | cop[tikv] |                       | le(test.t.b, 9000)              |\n|       └─TableRowIDScan_19         | 109.20  | cop[tikv] | table:t               | keep order:false                |\n+-----------------------------------+---------+-----------+-----------------------+---------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Low Concurrency Query Analysis\nDESCRIPTION: EXPLAIN ANALYZE output showing performance bottleneck due to low concurrency in hash join and projection operations, which can be optimized by adjusting concurrency parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain analyze select sum(t1.a) from t t1, t t2 where t1.a=t2.a;\n```\n\n----------------------------------------\n\nTITLE: Setting Log Level in PD\nDESCRIPTION: This command sets the log level for the PD leader, allowing administrators to adjust verbosity for debugging or monitoring purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_58\n\nLANGUAGE: bash\nCODE:\n```\nlog warn\n```\n\n----------------------------------------\n\nTITLE: Explain Analyze for Detailed Execution Metrics in TiDB\nDESCRIPTION: This snippet uses EXPLAIN ANALYZE to provide a detailed report on the execution of a query. It shows actual versus estimated row counts and various execution metrics useful for performance tuning in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-aggregation.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT COUNT(*) FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning Task Settings\nDESCRIPTION: Defines task-level configuration parameters including concurrency settings, region management, error handling, and schema configurations\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\ncheck-requirements = true\nindex-concurrency = 2\ntable-concurrency = 6\nregion-concurrency = 8\nio-concurrency = 5\nmax-error = 9223372036854775807\ntask-info-schema-name = 'lightning_task_info'\nmeta-schema-name = 'lightning_metadata'\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Block Cache Settings in TiUP Configuration\nDESCRIPTION: YAML configuration for TiKV log level and RocksDB block cache sizes for Default CF and Write CF, optimized for a 40GB VM to improve performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  tikv:\n    log-level: \"error\"\n    rocksdb.defaultcf.block-cache-size: \"24GB\"\n    rocksdb.writecf.block-cache-size: \"6GB\"\n```\n\n----------------------------------------\n\nTITLE: EXPLAIN ANALYZE with Full Table Scan\nDESCRIPTION: Example of using EXPLAIN ANALYZE on a full table scan query to demonstrate more complex execution plans with multiple operators and their statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT * FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Paginating Query Results in Java\nDESCRIPTION: Shows how to implement pagination in Java, converting page number and page size parameters to offset and limit, and executing a prepared statement to fetch paginated results.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-paginate-results.md#2025-04-18_snippet_1\n\nLANGUAGE: java\nCODE:\n```\npublic List<Book> getLatestBooksPage(Long pageNumber, Long pageSize) throws SQLException {\n    pageNumber = pageNumber < 1L ? 1L : pageNumber;\n    pageSize = pageSize < 10L ? 10L : pageSize;\n    Long offset = (pageNumber - 1) * pageSize;\n    Long limit = pageSize;\n    List<Book> books = new ArrayList<>();\n    try (Connection conn = ds.getConnection()) {\n        PreparedStatement stmt = conn.prepareStatement(\"\"\"\n        SELECT id, title, published_at\n        FROM books\n        ORDER BY published_at DESC\n        LIMIT ?, ?;\n        \"\"\");\n        stmt.setLong(1, offset);\n        stmt.setLong(2, limit);\n        ResultSet rs = stmt.executeQuery();\n        while (rs.next()) {\n            Book book = new Book();\n            book.setId(rs.getLong(\"id\"));\n            book.setTitle(rs.getString(\"title\"));\n            book.setPublishedAt(rs.getDate(\"published_at\"));\n            books.add(book);\n        }\n    }\n    return books;\n}\n```\n\n----------------------------------------\n\nTITLE: Revoking and Showing Privileges with SQL\nDESCRIPTION: These SQL commands demonstrate creating a user, granting and revoking privileges, and showing the grants before and after the revocation in a TiDB environment. After revoking, the changes are immediate on the current connection, unlike in MySQL, where they may take effect only on subsequent connections.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-revoke-privileges.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE USER 'newuser' IDENTIFIED BY 'mypassword';\nQuery OK, 1 row affected (0.02 sec)\n\nmysql> GRANT ALL ON test.* TO 'newuser';\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> SHOW GRANTS FOR 'newuser';\n+-------------------------------------------------+\n| Grants for newuser@%                            |\n+-------------------------------------------------+\n| GRANT USAGE ON *.* TO 'newuser'@'%'             |\n| GRANT ALL PRIVILEGES ON test.* TO 'newuser'@'%' |\n+-------------------------------------------------+\n2 rows in set (0.00 sec)\n\nmysql> REVOKE ALL ON test.* FROM 'newuser';\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> SHOW GRANTS FOR 'newuser';\n+-------------------------------------+\n| Grants for newuser@%                |\n+-------------------------------------+\n| GRANT USAGE ON *.* TO 'newuser'@'%' |\n+-------------------------------------+\n1 row in set (0.00 sec)\n\nmysql> DROP USER 'newuser';\nQuery OK, 0 rows affected (0.14 sec)\n\nmysql> SHOW GRANTS FOR 'newuser';\nERROR 1141 (42000): There is no such grant defined for user 'newuser' on host '%'\n```\n\n----------------------------------------\n\nTITLE: Decompressing Data Using Python\nDESCRIPTION: A Python example to decode and decompress data from the COMPRESS SQL function. The `zlib` module is used to decompress the zlib compressed data.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport codecs\nimport zlib\ndata = codecs.decode('03000000789C72747206040000FFFF018D00C7','hex')\nprint(int.from_bytes(data[:4], byteorder='little'))  # 3\nprint(zlib.decompress(data[4:]))  # b'ABC'\n```\n\n----------------------------------------\n\nTITLE: Multi-Disk Deployment Configuration for Newer TiDB\nDESCRIPTION: Details the configuration for multi-disk deployment for TiDB v4.0.9 and later, allowing optimized data distribution across multiple disks.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_15\n\nLANGUAGE: TOML\nCODE:\n```\n\"storage.main.dir = [\\\"/sata_ssd_b/data/tiflash\\\", \\\"/sata_ssd_c/data/tiflash\\\"]\"\n```\n\nLANGUAGE: TOML\nCODE:\n```\n\"storage.latest.dir = [\\\"/nvme_ssd_a/data/tiflash\\\"]\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Sequence in TiDB\nDESCRIPTION: This snippet demonstrates how to create a sequence named 's1' using the CREATE SEQUENCE statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/sequence-functions.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SEQUENCE s1;\n```\n\n----------------------------------------\n\nTITLE: Setting JSON Variable\nDESCRIPTION: SQL command to store the JSON document in a user-defined variable for testing\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-validate.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET @j := '{\"fruits\": [\"orange\", \"apple\", \"pear\"], \"vegetables\": [\"carrot\", \"pepper\", \"kale\"]}'\n```\n\n----------------------------------------\n\nTITLE: Creating Placement Policies with Survival Preferences\nDESCRIPTION: SQL statements to create placement policies with survival preferences across regions, zones and hosts. Demonstrates both multi-region and single-region configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY multiaz SURVIVAL_PREFERENCES=\"[region, zone, host]\";\nCREATE PLACEMENT POLICY singleaz CONSTRAINTS=\"[+region=us-east-1]\" SURVIVAL_PREFERENCES=\"[zone]\";\n```\n\n----------------------------------------\n\nTITLE: EXPLAIN results showing execution plan for a COUNT query in TiDB\nDESCRIPTION: This output shows the execution plan generated by TiDB for a COUNT query with date filtering. It displays the operator tree with estimated row counts, execution tasks (root or cop), access objects, and detailed operator information.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------+----------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------+\n| id                           | estRows  | task      | access object | operator info                                                                                                          |\n+------------------------------+----------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------+\n| StreamAgg_20                 | 1.00     | root      |               | funcs:count(Column#13)->Column#11                                                                                      |\n| └─TableReader_21             | 1.00     | root      |               | data:StreamAgg_9                                                                                                       |\n|   └─StreamAgg_9              | 1.00     | cop[tikv] |               | funcs:count(1)->Column#13                                                                                              |\n|     └─Selection_19           | 250.00   | cop[tikv] |               | ge(bikeshare.trips.start_date, 2017-07-01 00:00:00.000000), le(bikeshare.trips.start_date, 2017-07-01 23:59:59.000000) |\n|       └─TableFullScan_18     | 10000.00 | cop[tikv] | table:trips   | keep order:false, stats:pseudo                                                                                         |\n+------------------------------+----------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Warning Notice Format in Markdown\nDESCRIPTION: Markdown formatting for an important warning notice about version 5.3.2's known bug, using blockquote syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.2.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n> **Warning:**\\n>\\n> It is not recommended to use v5.3.2, because this version has a known bug. For details, see [#12934](https://github.com/tikv/tikv/issues/12934). This bug has been fixed in v5.3.3. It is recommended to use [v5.3.3](/releases/release-5.3.3.md).\n```\n\n----------------------------------------\n\nTITLE: Configuring RocksDB Write Column Family in TiKV\nDESCRIPTION: Configuration settings for the write column family in RocksDB. This column family is used for write operations and shares many settings with the default column family.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-tikv-memory-performance.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[rocksdb.writecf]\n# Set it the same as `rocksdb.defaultcf.compression-per-level`.\ncompression-per-level = [\"no\", \"no\", \"lz4\", \"lz4\", \"lz4\", \"zstd\", \"zstd\"]\n\n# Set it the same as `rocksdb.defaultcf.write-buffer-size`.\nwrite-buffer-size = \"128MiB\"\nmax-write-buffer-number = 5\nmin-write-buffer-number-to-merge = 1\n\n# Set it the same as `rocksdb.defaultcf.max-bytes-for-level-base`.\nmax-bytes-for-level-base = \"512MiB\"\ntarget-file-size-base = \"32MiB\"\n```\n\n----------------------------------------\n\nTITLE: Creating a tpcc Database in TiDB\nDESCRIPTION: This SQL statement creates a database named `tpcc` in the TiDB cluster. It is a prerequisite for loading TPC-C data into the database for performance testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE tpcc;\n```\n\n----------------------------------------\n\nTITLE: Viewing Result from TIDB_IS_DDL_OWNER Function\nDESCRIPTION: Shows the output of TIDB_IS_DDL_OWNER function, which returns 1 indicating that the current TiDB instance is the DDL owner.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\n+---------------------+\n| TIDB_IS_DDL_OWNER() |\n+---------------------+\n|                   1 |\n+---------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Rewritten Batch UPDATE Statement\nDESCRIPTION: Example of how multiple UPDATE statements are rewritten into a single SQL string with multiple queries when rewriteBatchedStatements=true is enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE `t` SET `a` = 10 WHERE `id` = 1; UPDATE `t` SET `a` = 11 WHERE `id` = 2; UPDATE `t` SET `a` = 12 WHERE `id` = 3;\n```\n\n----------------------------------------\n\nTITLE: View Raft Region Information\nDESCRIPTION: Command to view detailed information about a specific Raft region.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --host 127.0.0.1:20160 raft region -r 1239\n```\n\n----------------------------------------\n\nTITLE: Batch Insert Using Prepared Statements in Go\nDESCRIPTION: Implementation of efficient batch insert operations using prepared statements in Go to avoid repeated SQL parsing overhead.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql-best-practices.md#2025-04-18_snippet_1\n\nLANGUAGE: go\nCODE:\n```\nfunc BatchInsert(db *sql.DB) error {\n    stmt, err := db.Prepare(\"INSERT INTO t (id) VALUES (?), (?), (?), (?), (?)\")\n    if err != nil {\n        return err\n    }\n    for i := 0; i < 1000; i += 5 {\n        values := []interface{}{i, i + 1, i + 2, i + 3, i + 4}\n        _, err = stmt.Exec(values...)\n        if err != nil {\n            return err\n        }\n    }\n    return nil\n}\n```\n\n----------------------------------------\n\nTITLE: Exporting Cluster Information using PLAN REPLAYER\nDESCRIPTION: This SQL command allows exporting the on-site information of a TiDB cluster into a ZIP file, which includes various cluster details such as version, configuration, session variables, and execution plan results. The exported file is retained for one hour.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-replayer.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nPLAN REPLAYER DUMP [WITH STATS AS OF TIMESTAMP expression] EXPLAIN [ANALYZE] sql-statement;\n```\n\nLANGUAGE: sql\nCODE:\n```\nplan replayer dump explain select * from t;\n```\n\nLANGUAGE: sql\nCODE:\n```\nplan replayer dump with stats as of timestamp '2023-07-17 12:00:00' explain select * from t;\n```\n\nLANGUAGE: sql\nCODE:\n```\nplan replayer dump with stats as of timestamp '442012134592479233' explain select * from t;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@tidb_last_plan_replayer_token;\n```\n\nLANGUAGE: sql\nCODE:\n```\nplan replayer dump explain 'sqls.txt';\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying Range Partitioned Table in SQL\nDESCRIPTION: This SQL snippet demonstrates creating a partitioned table by range, inserting values, and explaining a query to show how partition pruning works by eliminating unnecessary partitions in TiDB. Dependencies include a TiDB instance with partitioning capabilities.\nSOURCE: https://github.com/pingcap/docs/blob/master/partition-pruning.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n id INT NOT NULL PRIMARY KEY,\n pad VARCHAR(100)\n)\nPARTITION BY RANGE COLUMNS(id) (\n PARTITION p0 VALUES LESS THAN (100),\n PARTITION p1 VALUES LESS THAN (200),\n PARTITION p2 VALUES LESS THAN (MAXVALUE)\n);\n\nINSERT INTO t1 VALUES (1, 'test1'),(101, 'test2'), (201, 'test3');\nEXPLAIN SELECT * FROM t1 WHERE id BETWEEN 80 AND 120;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------+---------+-----------+------------------------+------------------------------------------------+\n| id                         | estRows | task      | access object          | operator info                                  |\n+----------------------------+---------+-----------+------------------------+------------------------------------------------+\n| PartitionUnion_8           | 80.00   | root      |                        |                                                |\n| ├─TableReader_10           | 40.00   | root      |                        | data:TableRangeScan_9                          |\n| │ └─TableRangeScan_9       | 40.00   | cop[tikv] | table:t1, partition:p0 | range:[80,120], keep order:false, stats:pseudo |\n| └─TableReader_12           | 40.00   | root      |                        | data:TableRangeScan_11                         |\n|   └─TableRangeScan_11      | 40.00   | cop[tikv] | table:t1, partition:p1 | range:[80,120], keep order:false, stats:pseudo |\n+----------------------------+---------+-----------+------------------------+------------------------------------------------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Monitoring Certificate Validity in TiDB\nDESCRIPTION: SQL command to monitor the validity period of the TLS certificate by showing the start and end dates. Available since TiDB v5.2.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-clients-and-servers.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GLOBAL STATUS LIKE 'Ssl\\_server\\_not\\_%';\n```\n\n----------------------------------------\n\nTITLE: SCHEMATA Table Structure in TiDB\nDESCRIPTION: Displays the field structure of the SCHEMATA table, showing column names, data types, and other attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-schemata.md#2025-04-18_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n+----------------------------+--------------+------+------+---------+-------+\n| Field                      | Type         | Null | Key  | Default | Extra |\n+----------------------------+--------------+------+------+---------+-------+\n| CATALOG_NAME               | varchar(512) | YES  |      | NULL    |       |\n| SCHEMA_NAME                | varchar(64)  | YES  |      | NULL    |       |\n| DEFAULT_CHARACTER_SET_NAME | varchar(64)  | YES  |      | NULL    |       |\n| DEFAULT_COLLATION_NAME     | varchar(32)  | YES  |      | NULL    |       |\n| SQL_PATH                   | varchar(512) | YES  |      | NULL    |       |\n+----------------------------+--------------+------+------+---------+-------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Using LASTVAL() Function in TiDB\nDESCRIPTION: This snippet demonstrates how to use the LASTVAL() function to get the last value generated by sequence 's1' in the current session.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/sequence-functions.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT LASTVAL(s1);\n```\n\n----------------------------------------\n\nTITLE: System Variable Configuration for LOAD DATA\nDESCRIPTION: Explains the usage and changes of tidb_dml_batch_size for controlling transaction batch size in LOAD DATA operations across TiDB versions\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-load-data.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_dml_batch_size = n\n```\n\n----------------------------------------\n\nTITLE: Inserting and Updating Data\nDESCRIPTION: These SQL statements insert and update data after a column has been dropped from one of the sharded tables. It's used to showcase continued data migration after schema changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-shard-merge-optimistic.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nINSERT INTO `tbl01` (`ID`, `Level`) VALUES (15, 7);\nUPDATE `tbl00` SET `Level` = 5 WHERE `ID` = 5;\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring JDBC Connector TLS\nDESCRIPTION: Example configuration for enabling TLS in the JDBC connector that connects to TiDB. This requires specifying server and client certificate stores and their respective passwords.\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_9\n\nLANGUAGE: properties\nCODE:\n```\nspark.tispark.jdbc.tls_enable                                  true\nspark.tispark.jdbc.server_cert_store                           /home/tispark/jdbc-truststore\nspark.tispark.jdbc.server_cert_password                        jdbc_truststore_password\nspark.tispark.jdbc.client_cert_store                           /home/tispark/jdbc-clientstore\nspark.tispark.jdbc.client_cert_password                        jdbc_clientstore_password\n```\n\n----------------------------------------\n\nTITLE: Checking GTID Mode in MySQL\nDESCRIPTION: SQL command to verify if GTID mode is enabled in the MySQL database. Returns ON or ON_PERMISSIVE if GTID is properly enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-incremental-data-from-mysql-using-data-migration.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW VARIABLES LIKE 'gtid_mode';\n```\n\n----------------------------------------\n\nTITLE: Configuring Maximum Split Regions in TiDB\nDESCRIPTION: Adds a new configuration parameter split-region-max-num to control the maximum number of regions allowed by SPLIT TABLE, with a default of 10000.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.17.md#2025-04-18_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nsplit-region-max-num = 10000\n```\n\n----------------------------------------\n\nTITLE: Creating a Local User with Full Privileges in TiDB\nDESCRIPTION: Create a user 'finley' that can connect from localhost with a password and grant all privileges on all databases with the ability to grant privileges to other users.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'finley'@'localhost' IDENTIFIED BY 'some_pass';\n```\n\n----------------------------------------\n\nTITLE: Removing CDC Reverse Replication - Shell\nDESCRIPTION: Shell command to remove active reverse replication Changefeeds after completing transition procedures and ensuring stable operation in the new cluster environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:${cluster_version} cdc changefeed remove --server http://${cdc_host}:${cdc_port} -c <changefeedid>\n```\n\n----------------------------------------\n\nTITLE: Dynamically Disable In-Memory Pessimistic Lock\nDESCRIPTION: SQL command to dynamically disable in-memory pessimistic locks in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/pessimistic-transaction.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nset config tikv pessimistic-txn.in-memory='false';\n```\n\n----------------------------------------\n\nTITLE: Checking Statement Summary Capacity and Usage in TiDB\nDESCRIPTION: SQL queries to check the current maximum statement count setting and the actual count of records in the statements_summary table to determine if eviction is occurring due to capacity limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/statement-summary-tables.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nselect @@global.tidb_stmt_summary_max_stmt_count;\nselect count(*) from information_schema.statements_summary;\n```\n\n----------------------------------------\n\nTITLE: Auto Random with Non-Clustered Primary Key Error\nDESCRIPTION: Demonstrates the error when attempting to use AUTO_RANDOM with a non-clustered primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/clustered-indexes.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (a bigint primary key nonclustered auto_random);\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning for Data Import\nDESCRIPTION: TOML configuration file for tidb-lightning that specifies import settings. This configuration uses the TiDB backend, sets the data source directory, enables CSV header recognition, and includes database connection parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/import-example-data.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[tikv-importer]\nbackend = \"tidb\"\n\n[mydumper]\nno-schema = true\ndata-source-dir = \"~/bikeshare-data\"\n\n[mydumper.csv]\nheader = true\n\n[tidb]\nhost = \"127.0.0.1\"\nport = 4000\nuser = \"root\"\npassword = \"very_secret\"\n```\n\n----------------------------------------\n\nTITLE: Splitting Joint Indexes in SQL\nDESCRIPTION: This SQL statement demonstrates how to split the index 'idx3', which contains two columns, based on a time range specified for column 'a' alone.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT TABLE t INDEX idx3 BETWEEN (\"2010-01-01 00:00:00\") AND (\"2020-01-01 00:00:00\") REGIONS 10;\n```\n\n----------------------------------------\n\nTITLE: DM-worker Configuration Template\nDESCRIPTION: This is a template configuration file for DM-worker, showing the main configuration options like worker name, log settings, addresses for communication, and security configurations using SSL. The `join` parameter specifies the addresses of DM-master instances. Relay log related configurations are also included.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-worker-configuration-file.md#2025-04-18_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n\"# Worker Configuration.\\nname = \\\"worker1\\\"\\n\\n# Log configuration.\\nlog-level = \\\"info\\\"\\nlog-file = \\\"dm-worker.log\\\"\\n\\n# DM-worker listen address.\\nworker-addr = \\\":8262\\\"\\nadvertise-addr = \\\"127.0.0.1:8262\\\"\\njoin = \\\"http://127.0.0.1:8261,http://127.0.0.1:8361,http://127.0.0.1:8461\\\"\\n\\nkeepalive-ttl = 60\\nrelay-keepalive-ttl = 1800 # New in DM v2.0.2.\\n# relay-dir = \\\"relay_log\\\" # New in 5.4.0. When you use a relative path, check the deployment and start method of DM-worker to determine the full path.\\n\\nssl-ca = \\\"/path/to/ca.pem\\\"\\nssl-cert = \\\"/path/to/cert.pem\\\"\\nssl-key = \\\"/path/to/key.pem\\\"\\ncert-allowed-cn = [\\\"dm\\\"]\"\n```\n\n----------------------------------------\n\nTITLE: Successful Changefeed Creation Message\nDESCRIPTION: This code snippet represents the output message after successfully creating a TiCDC changefeed. It provides information like the changefeed ID, upstream ID, sink URI, creation time, start timestamp, configuration details, state, creator version, resolved timestamp, checkpoint timestamp, and checkpoint time.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nCreate changefeed successfully!\nID: simple-replication-task\nInfo: {\"upstream_id\":7277814241002263370,\"namespace\":\"default\",\"id\":\"simple-replication-task\",\"sink_uri\":\"pulsar://127.0.0.1:6650/consumer-test?protocol=canal-json\",\"create_time\":\"2024-12-05T14:42:32.000904+08:00\",\"start_ts\":444203257406423044,\"config\":{\"memory_quota\":1073741824,\"case_sensitive\":false,\"force_replicate\":false,\"ignore_ineligible_table\":false,\"check_gc_safe_point\":true,\"enable_sync_point\":false,\"bdr_mode\":false,\"sync_point_interval\":600000000000,\"sync_point_retention\":86400000000000,\"filter\":{\"rules\":[\"pulsar_test.*\"]},\"mounter\":{\"worker_num\":16},\"sink\":{\"protocol\":\"canal-json\",\"csv\":{\"delimiter\":\",\",\"quote\":\"\\\"\",\"null\":\"\\\\N\",\"include_commit_ts\":false,\"binary_encoding_method\":\"base64\"},\"dispatchers\":[{\"matcher\":[\"pulsar_test.*\"],\"partition\":\"\",\"topic\":\"test_{schema}_{table}\"}],\"encoder_concurrency\":16,\"terminator\":\"\\r\\n\",\"date_separator\":\"day\",\"enable_partition_separator\":true,\"only_output_updated_columns\":false,\"delete_only_output_handle_key_columns\":false,\"pulsar_config\":{\"connection-timeout\":30,\"operation-timeout\":30,\"batching-max-messages\":1000,\"batching-max-publish-delay\":10,\"send-timeout\":30},\"advance_timeout\":150},\"consistent\":{\"level\":\"none\",\"max_log_size\":64,\"flush_interval\":2000,\"use_file_backend\":false},\"scheduler\":{\"enable_table_across_nodes\":false,\"region_threshold\":100000,\"write_key_threshold\":0},\"integrity\":{\"integrity_check_level\":\"none\",\"corruption_handle_level\":\"warn\"}},\"state\":\"normal\",\"creator_version\":\"v8.5.0\",\"resolved_ts\":444203257406423044,\"checkpoint_ts\":444203257406423044,\"checkpoint_time\":\"2024-12-05 14:42:31.410\"}\n```\n\n----------------------------------------\n\nTITLE: Example Query Demonstrating Error Summary\nDESCRIPTION: Demonstrates how to generate a warning with division by zero and view the error summary, followed by resetting the summary using FLUSH command.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/client-errors-summary-by-user.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 0/0;\nSELECT * FROM CLIENT_ERRORS_SUMMARY_BY_USER;\nFLUSH CLIENT_ERRORS_SUMMARY;\nSELECT * FROM CLIENT_ERRORS_SUMMARY_BY_USER;\n```\n\n----------------------------------------\n\nTITLE: Setting Properties in User Profile - Markdown\nDESCRIPTION: This snippet outlines how to set specific properties within a user profile using the TiDB Cloud CLI. It guides users on modifications to their profiles as needed, ensuring that they can customize their interactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/cli-reference.md#2025-04-18_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\nUse [`ticloud config set`](/tidb-cloud/ticloud-config-set.md) to set properties in a user profile.\n```\n\n----------------------------------------\n\nTITLE: Creating a Master Key with Google Cloud KMS - Shell\nDESCRIPTION: This snippet demonstrates the use of the gcloud CLI to create a key ring and a key in Google Cloud KMS. It provides command examples assuming the user replaces specific values with their actual configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ngcloud kms keyrings create \"key-ring-name\" --location \"global\"\ngcloud kms keys create \"key-name\" --keyring \"key-ring-name\" --location \"global\" --purpose \"encryption\" --rotation-period \"30d\"\n```\n\n----------------------------------------\n\nTITLE: Displaying DM Cluster Status\nDESCRIPTION: This command shows the status of the deployed 'dm-test' cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup-offline.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm display dm-test\n```\n\n----------------------------------------\n\nTITLE: Deploying a TiDB Cluster with TiUP Command Syntax in Shell\nDESCRIPTION: The basic syntax for deploying a new TiDB cluster using the tiup cluster deploy command. It requires specifying a cluster name, TiDB version, and a topology configuration file path.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-deploy.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster deploy <cluster-name> <version> <topology.yaml> [flags]\n```\n\n----------------------------------------\n\nTITLE: Structuring Release Notes with Markdown Headers and Lists\nDESCRIPTION: This snippet shows how the release notes are structured using Markdown headers and nested lists to organize information by component and feature.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.8.md#2025-04-18_snippet_1\n\nLANGUAGE: Markdown\nCODE:\n```\n## TiDB\n\n+ SQL Optimizer\n    - Fix the wrong SQL binding plan caused by untimely cache updates [#13891](https://github.com/pingcap/tidb/pull/13891)\n    - Fix the issue that the SQL binding might be invalid when an SQL statement contains a symbol list [#14004](https://github.com/pingcap/tidb/pull/14004)\n```\n\n----------------------------------------\n\nTITLE: Execution Plan After Fine Grained Shuffle Stream Count Configuration\nDESCRIPTION: Shows the beginning of the execution plan after setting `tiflash_fine_grained_shuffle_stream_count` to 20, indicating that the stream count would be updated to 20 for relevant operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain analyze select *, row_number() over (partition by a) from t;\n+----------------------------------+--------------+-----------+--------------+---------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------+--------+------+\n| id                               | estRows      | actRows   | task         | access object | execution info                                                                                                                                                                                                                                                                                                                                    | operator info                                                                                                         | memory | disk |\n+----------------------------------+--------------+-----------+--------------+---------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------+--------+------+\n```\n\n----------------------------------------\n\nTITLE: Defining the SHOW STATS_BUCKETS Statement Syntax\nDESCRIPTION: This code snippet provides the formal syntax definition for the SHOW STATS_BUCKETS statement in TiDB using EBNF. No additional dependencies are required. The syntax includes optional LIKE or WHERE expressions for filtering results.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-buckets.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\n\"ShowStatsBucketsStmt ::=\\n    \\\"SHOW\\\" \\\"STATS_BUCKETS\\\" ShowLikeOrWhere?\\n\\nShowLikeOrWhere ::=\\n    \\\"LIKE\\\" SimpleExpr\\n|   \\\"WHERE\\\" Expression\\n\"\n```\n\n----------------------------------------\n\nTITLE: Starting an Interactive Import Task in TiDB Cloud CLI\nDESCRIPTION: Example of starting a data import task in interactive mode. This command will prompt the user for necessary information to complete the import process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-start.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import start\n```\n\n----------------------------------------\n\nTITLE: Recording Backup TSO for Incremental Replication\nDESCRIPTION: Capture the backup timestamp (TSO) to ensure precise incremental data replication between clusters\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup br:${cluster_version} validate decode --field=\"end-version\" \\\n--storage \"s3://xxx?access-key=${access-key}&secret-access-key=${secret-access-key}\" | tail -n1\n```\n\n----------------------------------------\n\nTITLE: Changing Default Value for TiDB Variable in SQL\nDESCRIPTION: Changes the default value of the tidb_stmt_summary_max_stmt_count variable from 200 to 3000. This affects the maximum number of statements that can be summarized.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.4.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET @@global.tidb_stmt_summary_max_stmt_count = 3000;\n```\n\n----------------------------------------\n\nTITLE: Setting Empty Background Task Type in SQL\nDESCRIPTION: This SQL snippet sets the background task type of the `default` resource group to empty, effectively disabling background task designation. This requires access to modify resource groups in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-background-tasks.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nALTER RESOURCE GROUP `default` BACKGROUND=(TASK_TYPES=\"\");\n```\n\n----------------------------------------\n\nTITLE: TiCDC Changefeed Creation Command\nDESCRIPTION: This command creates a TiCDC changefeed with specific configurations for Kafka and Avro.  It sets the `sink-uri` with protocol to avro, specifies decimal and bigint unsigned handling modes as string, and links to schema registry.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-protocol.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://127.0.0.1:8300 --changefeed-id=\"kafka-avro-string-option\" --sink-uri=\"kafka://127.0.0.1:9092/topic-name?protocol=avro&avro-decimal-handling-mode=string&avro-bigint-unsigned-handling-mode=string\" --schema-registry=http://127.0.0.1:8081 --config changefeed_config.toml\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW CREATE RESOURCE GROUP Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the SHOW CREATE RESOURCE GROUP statement in TiDB. It specifies the structure of the statement and the possible variations for the resource group name.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-resource-group.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nShowCreateResourceGroupStmt ::=\n    \"SHOW\" \"CREATE\" \"RESOURCE\" \"GROUP\" ResourceGroupName\n\nResourceGroupName ::=\n    Identifier\n|   \"DEFAULT\"\n```\n\n----------------------------------------\n\nTITLE: Setting Storage Capacity for Raftstore\nDESCRIPTION: This snippet specifies the storage capacity configuration for Raftstore, allowing users to manage the data size limits and providing defaults.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\n+ The storage capacity, which is the maximum size allowed to store data. If `capacity` is left unspecified, the capacity of the current disk prevails.\n+ Default value: `0`\n+ Unit: KiB|MiB|GiB\n```\n\n----------------------------------------\n\nTITLE: Fetching Cluster ID from PD Log in Bash\nDESCRIPTION: Retrieves the cluster ID from the PD log using grep command. Requires access to the specific path of the PD log file.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-recover.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngrep \"init cluster id\" {{/path/to}}/pd.log\n```\n\n----------------------------------------\n\nTITLE: Executing ticloud serverless import describe command in Shell\nDESCRIPTION: This command is used to describe a data import task in TiDB Cloud. It can be run in both interactive and non-interactive modes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-describe.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import describe [flags]\n```\n\n----------------------------------------\n\nTITLE: Export ANALYZE TABLE Statements to SQL File (Shell)\nDESCRIPTION: This shell command executes a SQL query via the `mysql` client to generate `ANALYZE TABLE` statements for all partitioned tables. The output is then piped to the `tee` command, which simultaneously displays the output on the console and saves it to a file named `gatherGlobalStats.sql`.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_82\n\nLANGUAGE: shell\nCODE:\n```\nmysql --host xxxx --port xxxx -u root -p -e \"SELECT DISTINCT CONCAT('ANALYZE TABLE ',TABLE_SCHEMA,'.',TABLE_NAME,' ALL COLUMNS;') \\\n    FROM information_schema.PARTITIONS \\\n    WHERE TIDB_PARTITION_ID IS NOT NULL \\\n    AND TABLE_SCHEMA NOT IN ('INFORMATION_SCHEMA','mysql','sys','PERFORMANCE_SCHEMA','METRICS_SCHEMA');\" | tee gatherGlobalStats.sql\n```\n\n----------------------------------------\n\nTITLE: GCS Backup Command\nDESCRIPTION: Command for backing up snapshot data to Google Cloud Storage using BR with credentials file authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd \"${PD_IP}:2379\" \\\n--storage \"gcs://external/backup-20220915?credentials-file=${credentials-file-path}\"\n```\n\n----------------------------------------\n\nTITLE: Sample Output of User Privilege Query\nDESCRIPTION: This snippet shows the expected output from the previous SQL query, displaying a sample row from the mysql.user table with user, host, and privilege information.\nSOURCE: https://github.com/pingcap/docs/blob/master/privilege-management.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\n+------|------|-------------|-------------+\n| User | Host | Select_priv | Insert_priv |\n+------|------|-------------|-------------+\n| root | %    | Y           | Y           |\n+------|------|-------------|-------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Applying DDL Changes to New Table in pt-osc\nDESCRIPTION: SQL statement used by pt-osc to apply schema changes to the '_new' table. DM doesn't execute this directly but records it for later application to the real table.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE `test`.`_test4_new` add column c3 int;\n```\n\n----------------------------------------\n\nTITLE: Showing Regions of a Range Partitioned Table in SQL\nDESCRIPTION: This SQL snippet retrieves and displays the regions of the newly created range partitioned table 't', showing details for effective data management.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLE t REGIONS;\n```\n\n----------------------------------------\n\nTITLE: Response Example - Querying a Specific Replication Subtask - TiCDC - JSON\nDESCRIPTION: This JSON response provides an example of the detailed information returned when querying a specific replication subtask (processor). It includes details such as `checkpoint_ts`, `resolved_ts`, `table_ids`, and `error` status.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_17\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"checkpoint_ts\": 426919123303006208,\n    \"resolved_ts\": 426919123369066496,\n    \"table_ids\": [\n        63,\n        65\n    ],\n    \"error\": null\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Active Changefeeds - Shell\nDESCRIPTION: A shell command to list all active Changefeeds currently connected to CDC server. It's used to verify that operation tasks are set and running smoothly.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:${cluster_version} cdc changefeed list --server http://${cdc_host}:${cdc_port}\n```\n\n----------------------------------------\n\nTITLE: Optimizing Query with NULL and ORDER BY in TiDB\nDESCRIPTION: Utilization of index order to avoid extra sorting operations for queries involving NULL checks and ORDER BY clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.3.0.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nWHERE idx_col_1 IS NULL ORDER BY idx_col_2\n```\n\n----------------------------------------\n\nTITLE: Successful TiCDC Changefeed Creation Response\nDESCRIPTION: This is the expected successful response from the TiCDC CLI after creating a changefeed. It provides details about the changefeed configuration, including the sink URI, options, creation time, start TSO, target TSO, admin job type, sort engine, sort directory, configuration parameters (case sensitivity, filter rules, mounter worker number, sink dispatchers, scheduler type and polling time), state, history, and any errors encountered.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nCreate changefeed successfully!\nID: simple-replication-task\nInfo: {\"sink-uri\":\"kafka://127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094/topic-name?protocol=canal-json&kafka-version=2.4.0&partition-num=6&max-message-bytes=67108864&replication-factor=1\",\"opts\":{},\"create-time\":\"2023-11-28T22:04:08.103600025+08:00\",\"start-ts\":415241823337054209,\"target-ts\":0,\"admin-job-type\":0,\"sort-engine\":\"unified\",\"sort-dir\":\".\",\"config\":{\"case-sensitive\":false,\"filter\":{\"rules\":[\"*.*\"],\"ignore-txn-start-ts\":null,\"ddl-allow-list\":null},\"mounter\":{\"worker-num\":16},\"sink\":{\"dispatchers\":null},\"scheduler\":{\"type\":\"table-number\",\"polling-time\":-1}},\"state\":\"normal\",\"history\":null,\"error\":null}\n```\n\n----------------------------------------\n\nTITLE: Setting TiDB TSO Client Batch Max Wait Time\nDESCRIPTION: This SQL command adjusts the global variable tidb_tso_client_batch_max_wait_time to optimize TSO client behavior. Setting this to a non-zero value enables the TSO client batch wait feature, which helps reduce TSO requests and improve PD performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices-on-public-cloud.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nset global tidb_tso_client_batch_max_wait_time = 2; # default: 0\n```\n\n----------------------------------------\n\nTITLE: Viewing Placement Labels in TiKV Cluster SQL\nDESCRIPTION: The SQL statement retrieves all placement labels available in the current TiKV cluster, which assists in configuring placement policies.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW PLACEMENT LABELS;\n+--------+----------------+\n| Key    | Values         |\n+--------+----------------+\n| disk   | [\"ssd\"]        |\n| region | [\"us-east-1\"]  |\n| zone   | [\"us-east-1a\"] |\n+--------+----------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Date Format Example - TiDB/MySQL\nDESCRIPTION: Example of potentially problematic date format handling in MySQL where incorrectly formatted dates may be accepted. TiDB attempts to match this behavior but may differ in some cases.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/date-and-time-functions.md#2025-04-18_snippet_0\n\nLANGUAGE: mysql\nCODE:\n```\n'2020-01-01\\n\\t01:01:01'\n'2020-01_01\\n\\t01:01'\n```\n\n----------------------------------------\n\nTITLE: Basic DROP STATS Usage\nDESCRIPTION: Example showing basic usage of DROP STATS command to delete all statistics of a table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-stats.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP STATS TableName\n```\n\n----------------------------------------\n\nTITLE: Backup Database in TiDB\nDESCRIPTION: This SQL statement initiates a backup of the 'test' database to an Amazon S3 bucket named 'example-bucket'.  The backup is stored in a directory named 'backup-01' within the bucket.  This requires appropriate permissions to write to the specified S3 location.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-backups.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP DATABASE `test` TO 's3://example-bucket/backup-01';\n```\n\n----------------------------------------\n\nTITLE: Viewing Password Validation Variables in TiDB SQL\nDESCRIPTION: This query displays all system variables related to password validation in TiDB. These variables affect the behavior of the VALIDATE_PASSWORD_STRENGTH() function.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_13\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW VARIABLES LIKE 'validate_password.%';\n```\n\n----------------------------------------\n\nTITLE: Setting BDR Role to PRIMARY in TiDB\nDESCRIPTION: SQL command to set a TiDB cluster as the PRIMARY in a bidirectional replication setup, followed by verification. Only the PRIMARY cluster can execute replicable DDLs that will be propagated to SECONDARY clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-bidirectional-replication.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SET BDR ROLE PRIMARY;\nQuery OK, 0 rows affected\nTime: 0.003s\n\nADMIN SHOW BDR ROLE;\n+----------+\n| BDR_ROLE |\n+----------+\n| primary  |\n+----------+\n```\n\n----------------------------------------\n\nTITLE: Analyze Query Execution Plan in TiDB\nDESCRIPTION: This SQL statement analyzes the execution plan of a query to determine if TiFlash is being used. The `explain analyze` command provides detailed information about the query execution, including whether the `cop[tiflash]` engine is selected for processing.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-htap-cluster.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nexplain analyze select count(*) from test.t;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------+---------+---------+--------------+---------------+----------------------------------------------------------------------+--------------------------------+-----------+------+\n| id                       | estRows | actRows | task         | access object | execution info                                                       | operator info                  | memory    | disk |\n+--------------------------+---------+---------+--------------+---------------+----------------------------------------------------------------------+--------------------------------+-----------+------+\n| StreamAgg_9              | 1.00    | 1       | root         |               | time:83.8372ms, loops:2                                              | funcs:count(1)->Column#4       | 372 Bytes | N/A  |\n| └─TableReader_17         | 1.00    | 1       | root         |               | time:83.7776ms, loops:2, rpc num: 1, rpc time:83.5701ms, proc keys:0 | data:TableFullScan_16          | 152 Bytes | N/A  |\n|   └─TableFullScan_16     | 1.00    | 1       | cop[tiflash] | table:t       | time:43ms, loops:1                                                   | keep order:false, stats:pseudo | N/A       | N/A  |\n+--------------------------+---------+---------+--------------+---------------+----------------------------------------------------------------------+--------------------------------+-----------+------+\n```\n\n----------------------------------------\n\nTITLE: Configuring Prometheus Rule Files in TiUP\nDESCRIPTION: This YAML configuration snippet demonstrates how to set the 'rule_dir' for Prometheus in the topology.yaml file of TiUP. It specifies the directory path for Prometheus rule files, ensuring customized rules are applied when deploying or scaling a TiDB cluster. Requires TiUP v1.9.0 or above.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/customized-montior-in-tiup-environment.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmonitoring_servers:\n  - host: 127.0.0.1\n    rule_dir: /home/tidb/prometheus_rule\n```\n\n----------------------------------------\n\nTITLE: Resource Group Information Query\nDESCRIPTION: SQL query to retrieve information about created resource groups from the information_schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-resource-group.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.resource_groups WHERE NAME ='rg1' or NAME = 'rg2';\n```\n\n----------------------------------------\n\nTITLE: SHOW PLACEMENT LABELS Syntax\nDESCRIPTION: Defines the syntax of the `SHOW PLACEMENT LABELS` statement using EBNF notation.  The `ShowLikeOrWhere` component is optional.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-placement-labels.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\n\"SHOW\" \"PLACEMENT\" \"LABELS\" ShowLikeOrWhere?\n```\n\n----------------------------------------\n\nTITLE: Query TiDB Cluster ID using SQL\nDESCRIPTION: This SQL statement queries the `cluster_id` from the `mysql.tidb` table in a TiDB cluster. The `cluster_id` is a unique identifier for TiDB clusters, introduced in v9.0.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VARIABLE_VALUE FROM mysql.tidb WHERE VARIABLE_NAME = 'cluster_id';\n```\n\n----------------------------------------\n\nTITLE: Checking I/O Scheduler for SD/VD Devices\nDESCRIPTION: Command to verify the I/O Scheduler configuration for SD or VD storage devices.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\ncat /sys/block/sd[bc]/queue/scheduler\n```\n\n----------------------------------------\n\nTITLE: Example Usage of USE Statement in TiDB\nDESCRIPTION: An example showing how to use the USE statement to switch between databases, create tables, and view table listings. The example demonstrates switching to the mysql system database, creating a new database, and then switching to it to create and view tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-use.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> USE mysql;\nReading table information for completion of table and column names\nYou can turn off this feature to get a quicker startup with -A\n\nDatabase changed\nmysql> SHOW TABLES;\n+-------------------------+\n| Tables_in_mysql         |\n+-------------------------+\n| GLOBAL_VARIABLES        |\n| bind_info               |\n| columns_priv            |\n| db                      |\n| default_roles           |\n| expr_pushdown_blacklist |\n| gc_delete_range         |\n| gc_delete_range_done    |\n| global_priv             |\n| help_topic              |\n| opt_rule_blacklist      |\n| role_edges              |\n| stats_buckets           |\n| stats_feedback          |\n| stats_histograms        |\n| stats_meta              |\n| stats_top_n             |\n| tables_priv             |\n| tidb                    |\n| user                    |\n+-------------------------+\n20 rows in set (0.01 sec)\n\nmysql> CREATE DATABASE newtest;\nQuery OK, 0 rows affected (0.10 sec)\n\nmysql> USE newtest;\nDatabase changed\nmysql> SHOW TABLES;\nEmpty set (0.00 sec)\n\nmysql> CREATE TABLE t1 (a int);\nQuery OK, 0 rows affected (0.10 sec)\n\nmysql> SHOW TABLES;\n+-------------------+\n| Tables_in_newtest |\n+-------------------+\n| t1                |\n+-------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Viewing TiSpark Telemetry Logs\nDESCRIPTION: Command to view TiSpark telemetry information from Spark logs using grep.\nSOURCE: https://github.com/pingcap/docs/blob/master/telemetry.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ngrep \"Telemetry report\" {spark.log} | tail -n 1\n```\n\n----------------------------------------\n\nTITLE: Configuring Alertmanager Servers in YAML for TiDB Deployment\nDESCRIPTION: Example configuration for alertmanager_servers in a TiDB cluster deployment topology file. This example shows how to specify two Alertmanager instances with their hosts and custom configuration files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_17\n\nLANGUAGE: yaml\nCODE:\n```\nalertmanager_servers:\n  - host: 10.0.1.11\n    config_file: /local/config/file\n  - host: 10.0.1.12\n    config_file: /local/config/file\n```\n\n----------------------------------------\n\nTITLE: Deploying and Configuring TiDB Cluster\nDESCRIPTION: Shell commands for deploying the TiDB cluster, setting replica counts, and configuring leader priorities\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-multi-replica.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster deploy drtest v6.4.0 ./topo.yaml\ntiup cluster start drtest --init\ntiup cluster display drtest\n\ntiup ctl:v6.4.0 pd config set max-replicas 5\ntiup ctl:v6.4.0 pd config set label-property reject-leader Region Region3\n\ntiup bench tpcc  prepare -H 127.0.0.1 -P 4000 -D tpcc --warehouses 1\n\ntiup ctl:v6.4.0 pd member leader_priority  pd-1 4\ntiup ctl:v6.4.0 pd member leader_priority  pd-2 3\ntiup ctl:v6.4.0 pd member leader_priority  pd-3 2\ntiup ctl:v6.4.0 pd member leader_priority  pd-4 1\ntiup ctl:v6.4.0 pd member leader_priority  pd-5 0\n```\n\n----------------------------------------\n\nTITLE: Configuring Conflict Resolution Strategy\nDESCRIPTION: Defines conflict handling strategies for dealing with conflicting primary or unique key records during data import\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[conflict]\nstrategy = \"replace\"\nprecheck-conflict-before-import = false\n```\n\n----------------------------------------\n\nTITLE: Unsupported CHANGE COLUMN Operations in TiDB SQL\nDESCRIPTION: Examples of CHANGE COLUMN operations that are not supported in TiDB, including changing multiple columns, modifying primary key columns, and altering partitioned tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-change-column.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t1 CHANGE col3 col4 BIGINT, CHANGE id id2 INT NOT NULL;\n\nCREATE TABLE t (a int primary key);\nALTER TABLE t CHANGE COLUMN a a VARCHAR(10);\n\nCREATE TABLE t (c1 INT, c2 INT, c3 INT) partition by range columns(c1) ( partition p0 values less than (10), partition p1 values less than (maxvalue));\nALTER TABLE t CHANGE COLUMN c1 c1 DATETIME;\n\nCREATE TABLE t (a INT, b INT as (a+1));\nALTER TABLE t CHANGE COLUMN b b VARCHAR(10);\n\nCREATE TABLE t (a DECIMAL(13, 7));\nALTER TABLE t CHANGE COLUMN a a DATETIME;\n```\n\n----------------------------------------\n\nTITLE: Displaying the cluster status using TiUP\nDESCRIPTION: This command shows the current status of the TiDB cluster, including the roles, hosts, ports, and status of each component. This helps in verifying if the scale-out operation was successful.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster display <cluster-name>\"\n```\n\n----------------------------------------\n\nTITLE: Historical Plan Binding Example with Multiple Tables\nDESCRIPTION: Example showing how to create bindings based on historical execution plans using plan digests, including table setup and various query types.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-binding.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nUSE test;\nCREATE TABLE t1(a INT, b INT, c INT, INDEX ia(a));\nCREATE TABLE t2(a INT, b INT, c INT, INDEX ia(a));\nINSERT INTO t1 SELECT * FROM t2 WHERE a = 1;\nSELECT @@LAST_PLAN_FROM_BINDING;\nUPDATE /*+ INL_JOIN(t2) */ t1, t2 SET t1.a = 1 WHERE t1.b = t2.a;\nSELECT @@LAST_PLAN_FROM_BINDING;\n```\n\n----------------------------------------\n\nTITLE: Setting HTTP Rate Limit for GetRegion API in PD\nDESCRIPTION: Sets the maximum rate (QPS) for GetRegion HTTP API requests to 100.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nconfig set service-middleware rate-limit GetRegion qps 100\n```\n\n----------------------------------------\n\nTITLE: Checking Migration Task Configuration\nDESCRIPTION: Validates the migration task configuration before starting the task\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} check-task task.yaml\n```\n\n----------------------------------------\n\nTITLE: Releasing a Specific Lock with RELEASE_LOCK in TiDB SQL\nDESCRIPTION: Releases a previously acquired lock specified by lockName. The lockName parameter must not exceed 64 characters.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/locking-functions.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nRELEASE_LOCK(lockName)\n```\n\n----------------------------------------\n\nTITLE: Viewing Dumpling's metadata file format in Shell\nDESCRIPTION: Displays the content of the metadata file created by Dumpling, which contains the start time of the export and the position of the master binary log.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncat metadata\n```\n\nLANGUAGE: shell\nCODE:\n```\nStarted dump at: 2020-11-10 10:40:19\nSHOW MASTER STATUS:\n        Log: tidb-binlog\n        Pos: 420747102018863124\nFinished dump at: 2020-11-10 10:40:20\n```\n\n----------------------------------------\n\nTITLE: Creating User with Hostname Example for skip_name_resolve\nDESCRIPTION: Example showing how to create a user with a hostname in their identity, which would be affected by the skip_name_resolve variable. When skip_name_resolve is enabled, users with hostnames cannot log in.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'appuser'@'apphost' IDENTIFIED BY 'app-password';\n```\n\n----------------------------------------\n\nTITLE: Viewing schema creation SQL file in Shell\nDESCRIPTION: Shows the content of the schema creation SQL file which contains the database creation statement with character set specification.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncat test-schema-create.sql\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE `test` /*!40100 DEFAULT CHARACTER SET utf8mb4 */;\n```\n\n----------------------------------------\n\nTITLE: Sample TiDB Dashboard Address Output\nDESCRIPTION: Example output showing the TiDB Dashboard address format\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nhttp://192.168.0.123:2379/dashboard/\n```\n\n----------------------------------------\n\nTITLE: Run TPC-C Test with TiUP Bench (Bash)\nDESCRIPTION: This command runs the TPC-C benchmark with 4 warehouses for a duration of 10 minutes. It leverages the `run` subcommand of the TiUP bench tpcc component and specifies the `--time` flag to control the test duration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench tpcc --warehouses 4 --time 10m run\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for UPDATE Statement in TiDB\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the UPDATE statement in TiDB. It defines the structure including update options, table references, assignments, and optional clauses like WHERE, ORDER BY, and LIMIT.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-update.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nUpdateStmt ::=\n    \"UPDATE\" UpdateOption\n(   TableRef \"SET\" Assignment (\",\" Assignment)* WhereClause? OrderBy? Limit?\n|   TableRefs \"SET\" Assignment (\",\" Assignment)* WhereClause?\n)\n\nUpdateOption ::=\n    OptimizerHints? (\"LOW_PRIORITY\" | \"HIGH_PRIORITY\" | \"DELAYED\")? \"IGNORE\"?\n\nTableRef ::=\n    ( TableFactor | JoinTable )\n\nTableRefs ::=\n    EscapedTableRef (\",\" EscapedTableRef)*\n```\n\n----------------------------------------\n\nTITLE: Restricting Username-based Passwords in TiDB\nDESCRIPTION: This SQL command configures TiDB to disallow passwords that match the username by setting 'validate_password.check_user_name' to ON, helping to ensure stronger password practices.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL validate_password.check_user_name = ON;\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration\nDESCRIPTION: YAML configuration block defining the document title, aliases for URL routing, and summary of the TiDB 2.1.14 release.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.14.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: TiDB 2.1.14 Release Notes\naliases: ['/docs/dev/releases/release-2.1.14/','/docs/dev/releases/2.1.14/']\nsummary: TiDB 2.1.14 was released on July 04, 2019. It includes various bug fixes and improvements, such as fixing wrong query results, adding new system variables, optimizing memory usage, and adding new configuration items for TiDB Binlog and TiDB Ansible. Additionally, there are optimizations for TiKV and PD.\n---\n```\n\n----------------------------------------\n\nTITLE: Using TIDB_DECODE_SQL_DIGESTS Function in SQL\nDESCRIPTION: This function queries the normalized SQL statements corresponding to a set of SQL digests in the cluster, simplifying the process of retrieving historically executed statements by a transaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.2.0.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT TIDB_DECODE_SQL_DIGESTS(<digest_list>);\n```\n\n----------------------------------------\n\nTITLE: Scaling Out TiCDC Cluster\nDESCRIPTION: This command scales out a TiCDC cluster, adding new nodes based on the configurations defined in the `scale-out.yml` file. It assumes mutual trust is configured or needs `-p` or `-i` option.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster scale-out <cluster-name> scale-out.yml\"\n```\n\n----------------------------------------\n\nTITLE: Restoring Default GC Time After Sink Creation\nDESCRIPTION: This SQL command restores the garbage collection life time for TiDB to its default value of 10 minutes after the MySQL sink has been created.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/changefeed-sink-to-mysql.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_life_time = '10m';\n```\n\n----------------------------------------\n\nTITLE: Upgrading from TiDB 1.0.5 to 1.0.6\nDESCRIPTION: Instructions for the rolling upgrade process from TiDB version 1.0.5 to 1.0.6. The upgrade must follow a specific component order to maintain system stability.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-1.0.6.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nTo upgrade from 1.0.5 to 1.0.6, follow the rolling upgrade order of PD -> TiKV -> TiDB.\n```\n\n----------------------------------------\n\nTITLE: Identifying Bad Regions with tikv-ctl Shell\nDESCRIPTION: This command uses tikv-ctl to find Regions with errors in the Raft state machine and set these Regions to be skipped during startup. Dependencies include a prepared data directory and the tikv-ctl tool deployed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir /path/to/tikv bad-regions\n```\n\nLANGUAGE: shell\nCODE:\n```\nall regions are healthy\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for DROP DATABASE in TiDB\nDESCRIPTION: This EBNF (Extended Backus-Naur Form) diagram defines the syntax for the DROP DATABASE statement in TiDB. It shows that the statement consists of the keywords 'DROP DATABASE', an optional 'IF EXISTS' clause, and the database name.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-database.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDropDatabaseStmt ::=\n    'DROP' 'DATABASE' IfExists DBName\n\nIfExists ::= ( 'IF' 'EXISTS' )?\n```\n\n----------------------------------------\n\nTITLE: Setting Session Resource Group to RG2\nDESCRIPTION: SQL commands to change the current session's resource group to rg2 and verify the change.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-resource-group.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET RESOURCE GROUP `rg2`;\nSELECT CURRENT_RESOURCE_GROUP();\n```\n\n----------------------------------------\n\nTITLE: Range Partitioning with MAXVALUE\nDESCRIPTION: This example extends the previous Range partitioning example by using `MAXVALUE` to handle `store_id` values that exceed the defined ranges.  `MAXVALUE` ensures that any `store_id` greater than or equal to 16 will be placed in the `p3` partition, preventing insertion errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT NOT NULL\n)\n\nPARTITION BY RANGE (store_id) (\n    PARTITION p0 VALUES LESS THAN (6),\n    PARTITION p1 VALUES LESS THAN (11),\n    PARTITION p2 VALUES LESS THAN (16),\n    PARTITION p3 VALUES LESS THAN MAXVALUE\n);\n```\n\n----------------------------------------\n\nTITLE: Upgrading Alertmanager with TiUP\nDESCRIPTION: Command to upgrade Alertmanager in the TiDB cluster using TiUP\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-monitoring-services.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster patch <cluster-name> alertmanager-v{new-version}-linux-amd64.tar.gz -R alertmanager --overwrite\n```\n\n----------------------------------------\n\nTITLE: Implementing NTILE() Window Function in SQL\nDESCRIPTION: This snippet illustrates the use of NTILE() function to divide a result set into a specified number of groups. It shows how NTILE() distributes rows into 5 and 2 groups respectively.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/window-functions.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nWITH RECURSIVE cte(n) AS (\n    SELECT\n        1\n    UNION\n    SELECT\n        n+1\n    FROM\n        cte\n    WHERE\n    n<10\n)\nSELECT\n    n,\n    NTILE(5) OVER (),\n    NTILE(2) OVER ()\nFROM\n    cte;\n```\n\n----------------------------------------\n\nTITLE: Installing Required LlamaIndex and TiDB Vector Store Dependencies\nDESCRIPTION: Installs the necessary Python packages for integrating LlamaIndex with TiDB Vector Search.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npip install llama-index-vector-stores-tidbvector\npip install llama-index\n```\n\n----------------------------------------\n\nTITLE: Querying MEMORY_USAGE_OPS_HISTORY Data in TiDB\nDESCRIPTION: SQL command to retrieve all records from the MEMORY_USAGE_OPS_HISTORY table in the information_schema database.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-memory-usage-ops-history.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.memory_usage_ops_history;\n```\n\n----------------------------------------\n\nTITLE: Reloading PD Node Configuration in TiDB Cluster\nDESCRIPTION: This command performs a rolling update of the PD node configuration in the TiDB cluster using TiUP. It's the final step in switching from microservices mode to regular mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster reload <cluster-name> -R pd\n```\n\n----------------------------------------\n\nTITLE: Generating Hybrid Deployment Topology Template\nDESCRIPTION: Creates a full topology template for hybrid deployment scenarios where multiple TiDB instances are deployed on a single machine. This template includes more detailed configuration options than the basic template.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster template --full > topology.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating TEST_ITEM Table in Snowflake - SQL\nDESCRIPTION: Sets up a Snowflake table named `TEST_ITEM` with a structure identical to that in TiDB. This table is prepared for data merged from change logs.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\ncreate or replace table TEST_ITEM (\n    i_id INTEGER primary key,\n    i_im_id INTEGER,\n    i_name VARCHAR,\n    i_price DECIMAL(36,2),\n    i_data VARCHAR\n);\n```\n\n----------------------------------------\n\nTITLE: Successful PD Configuration Modification\nDESCRIPTION: This SQL statement confirms a successful modification of a PD configuration, indicated by the `Query OK` response. The `0 rows affected` message is standard for configuration updates.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Viewing Load Base Split Configuration with TiKV HTTP API\nDESCRIPTION: Shows how to view the Load Base Split configuration using TiKV's HTTP API.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-load-base-split.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncurl \"http://ip:status_port/config\"\n```\n\n----------------------------------------\n\nTITLE: TiCDC Schema Change Value Format\nDESCRIPTION: This JSON object represents the value format for a schema change event in TiCDC. It includes the 'payload' which contains the actual change data such as the source information, database name, DDL statement, and table changes. The 'schema' defines the structure and types of the data in the payload, using Debezium's schema definition.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-debezium.md#2025-04-18_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\n    \"payload\": {\n        \"source\": {\n            \"version\": \"2.4.0.Final\",\n            \"connector\": \"TiCDC\",\n            \"name\": \"test_cluster\",\n            \"ts_ms\": 0,\n            \"snapshot\": \"false\",\n            \"db\": \"test\",\n            \"table\": \"table1\",\n            \"server_id\": 0,\n            \"gtid\": null,\n            \"file\": \"\",\n            \"pos\": 0,\n            \"row\": 0,\n            \"thread\": 0,\n            \"query\": null,\n            \"commit_ts\": 1,\n            \"cluster_id\": \"test_cluster\"\n        },\n        \"ts_ms\": 1701326309000,\n        \"databaseName\": \"test\",\n        \"schemaName\": null,\n        \"ddl\": \"RENAME TABLE test.table1 to test.table2\",\n        \"tableChanges\": [\n            {\n                \"type\": \"ALTER\",\n                \"id\": \"\\\"test\\\".\\\"table2\\\",\\\"test\\\".\\\"table1\\\"\",\n                \"table\": {\n                    \"defaultCharsetName\": \"\",\n                    \"primaryKeyColumnNames\": [\n                        \"id\"\n                    ],\n                    \"columns\": [\n                        {\n                            \"name\": \"id\",\n                            \"jdbcType\": 4,\n                            \"nativeType\": null,\n                            \"comment\": null,\n                            \"defaultValueExpression\": null,\n                            \"enumValues\": null,\n                            \"typeName\": \"INT\",\n                            \"typeExpression\": \"INT\",\n                            \"charsetName\": null,\n                            \"length\": 0,\n                            \"scale\": null,\n                            \"position\": 1,\n                            \"optional\": false,\n                            \"autoIncremented\": false,\n                            \"generated\": false\n                        }\n                    ],\n                    \"comment\": null\n                }\n            }\n        ]\n    },\n    \"schema\": {\n        \"optional\": false,\n        \"type\": \"struct\",\n        \"version\": 1,\n        \"name\": \"io.debezium.connector.mysql.SchemaChangeValue\",\n        \"fields\": [\n            {\n                \"field\": \"source\",\n                \"name\": \"io.debezium.connector.mysql.Source\",\n                \"optional\": false,\n                \"type\": \"struct\",\n                \"fields\": [\n                    {\n                        \"field\": \"version\",\n                        \"optional\": false,\n                        \"type\": \"string\"\n                    },\n                    {\n                        \"field\": \"connector\",\n                        \"optional\": false,\n                        \"type\": \"string\"\n                    },\n                    {\n                        \"field\": \"name\",\n                        \"optional\": false,\n                        \"type\": \"string\"\n                    },\n                    {\n                        \"field\": \"ts_ms\",\n                        \"optional\": false,\n                        \"type\": \"int64\"\n                    },\n                    {\n                        \"field\": \"snapshot\",\n                        \"optional\": true,\n                        \"type\": \"string\",\n                        \"parameters\": {\n                            \"allowed\": \"true,last,false,incremental\"\n                        },\n                        \"default\": \"false\",\n                        \"name\": \"io.debezium.data.Enum\",\n                        \"version\": 1\n                    },\n                    {\n                        \"field\": \"db\",\n                        \"optional\": false,\n                        \"type\": \"string\"\n                    },\n                    {\n                        \"field\": \"sequence\",\n                        \"optional\": true,\n                        \"type\": \"string\"\n                    },\n                    {\n                        \"field\": \"table\",\n                        \"optional\": true,\n                        \"type\": \"string\"\n                    },\n                    {\n                        \"field\": \"server_id\",\n                        \"optional\": false,\n                        \"type\": \"int64\"\n                    },\n                    {\n                        \"field\": \"gtid\",\n                        \"optional\": true,\n                        \"type\": \"string\"\n                    },\n                    {\n                        \"field\": \"file\",\n                        \"optional\": false,\n                        \"type\": \"string\"\n                    },\n                    {\n                        \"field\": \"pos\",\n                        \"optional\": false,\n                        \"type\": \"int64\"\n                    },\n                    {\n                        \"field\": \"row\",\n                        \"optional\": false,\n                        \"type\": \"int32\"\n                    },\n                    {\n                        \"field\": \"thread\",\n                        \"optional\": true,\n                        \"type\": \"int64\"\n                    },\n                    {\n                        \"field\": \"query\",\n                        \"optional\": true,\n                        \"type\": \"string\"\n                    }\n                ]\n            },\n            {\n                \"field\": \"ts_ms\",\n                \"optional\": false,\n                \"type\": \"int64\"\n            },\n            {\n                \"field\": \"databaseName\",\n                \"optional\": true,\n                \"type\": \"string\"\n            },\n            {\n                \"field\": \"schemaName\",\n                \"optional\": true,\n                \"type\": \"string\"\n            },\n            {\n                \"field\": \"ddl\",\n                \"optional\": true,\n                \"type\": \"string\"\n            },\n            {\n                \"field\": \"tableChanges\",\n                \"optional\": false,\n                \"type\": \"array\",\n                \"items\": {\n                    \"name\": \"io.debezium.connector.schema.Change\",\n                    \"optional\": false,\n                    \"type\": \"struct\",\n                    \"version\": 1,\n                    \"fields\": [\n                        {\n                            \"field\": \"type\",\n                            \"optional\": false,\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"field\": \"id\",\n                            \"optional\": false,\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"field\": \"table\",\n                            \"optional\": true,\n                            \"type\": \"struct\",\n                            \"name\": \"io.debezium.connector.schema.Table\",\n                            \"version\": 1,\n                            \"fields\": [\n                                {\n                                    \"field\": \"defaultCharsetName\",\n                                    \"optional\": true,\n                                    \"type\": \"string\"\n                                },\n                                {\n                                    \"field\": \"primaryKeyColumnNames\",\n                                    \"optional\": true,\n                                    \"type\": \"array\",\n                                    \"items\": {\n                                        \"type\": \"string\",\n                                        \"optional\": false\n                                    }\n                                },\n                                {\n                                    \"field\": \"columns\",\n                                    \"optional\": false,\n                                    \"type\": \"array\",\n                                    \"items\": {\n                                        \"name\": \"io.debezium.connector.schema.Column\",\n                                        \"optional\": false,\n                                        \"type\": \"struct\",\n                                        \"version\": 1,\n                                        \"fields\": [\n                                            {\n                                                \"field\": \"name\",\n                                                \"optional\": false,\n                                                \"type\": \"string\"\n                                            },\n                                            {\n                                                \"field\": \"jdbcType\",\n                                                \"optional\": false,\n                                                \"type\": \"int32\"\n                                            },\n                                            {\n                                                \"field\": \"nativeType\",\n                                                \"optional\": true,\n                                                \"type\": \"int32\"\n                                            },\n                                            {\n                                                \"field\": \"typeName\",\n                                                \"optional\": false,\n                                                \"type\": \"string\"\n                                            },\n                                            {\n                                                \"field\": \"typeExpression\",\n                                                \"optional\": true,\n                                                \"type\": \"string\"\n                                            },\n                                            {\n                                                \"field\": \"charsetName\",\n                                                \"optional\": true,\n                                                \"type\": \"string\"\n                                            },\n                                            {\n                                                \"field\": \"length\",\n                                                \"optional\": true,\n                                                \"type\": \"int32\"\n\n```\n\n----------------------------------------\n\nTITLE: Efficient Paging for Single-Field Primary Key Tables in SQL\nDESCRIPTION: Demonstrates an efficient method for paginating large datasets with single-field primary keys using window functions and aggregation in SQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-paginate-results.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    floor((t.row_num - 1) / 1000) + 1 AS page_num,\n    min(t.id) AS start_key,\n    max(t.id) AS end_key,\n    count(*) AS page_size\nFROM (\n    SELECT id, row_number() OVER (ORDER BY id) AS row_num\n    FROM books\n) t\nGROUP BY page_num\nORDER BY page_num;\n```\n\n----------------------------------------\n\nTITLE: Creating Hibernate SessionFactory in Java\nDESCRIPTION: This Java function demonstrates how to create a Hibernate SessionFactory using the configuration file and entity classes. It's essential for establishing a connection to TiDB using Hibernate.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-hibernate.md#2025-04-18_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\npublic SessionFactory getSessionFactory() {\n    return new Configuration()\n            .configure(\"hibernate.cfg.xml\")\n            .addAnnotatedClass(${your_entity_class})\n            .buildSessionFactory();\n}\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud using Go\nDESCRIPTION: This snippet demonstrates how to connect to a TiDB Cloud Dedicated cluster using Go's `go-sql-driver/mysql` library with TLS enabled. It registers a custom TLS configuration with the CA certificate, sets the minimum TLS version, and specifies the server name. It then establishes a database connection using the registered TLS configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tls-connect-to-dedicated.md#2025-04-18_snippet_6\n\nLANGUAGE: go\nCODE:\n```\nrootCertPool := x509.NewCertPool()\npem, err := ioutil.ReadFile(\"ca.pem\")\nif err != nil {\n    log.Fatal(err)\n}\nif ok := rootCertPool.AppendCertsFromPEM(pem); !ok {\n    log.Fatal(\"Failed to append PEM.\")\n}\nmysql.RegisterTLSConfig(\"tidb\", &tls.Config{\n    RootCAs:    rootCertPool,\n    MinVersion: tls.VersionTLS12,\n    ServerName: \"tidb.srgnqxji5bc.clusters.staging.tidb-cloud.com\",\n})\n\ndb, err := sql.Open(\"mysql\", \"root:<your_password>@tcp(tidb.srgnqxji5bc.clusters.staging.tidb-cloud.com:4000)/test?tls=tidb\")\n```\n\n----------------------------------------\n\nTITLE: Executing query-status Command in TiDB Data Migration\nDESCRIPTION: This snippet shows how to execute the query-status command in TiDB Data Migration to check the status of ongoing tasks. The command returns a JSON object containing information about each task's status and associated sources.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-query-status.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n» query-status\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"result\": true,\n    \"msg\": \"\",\n    \"tasks\": [\n        {\n            \"taskName\": \"test\",\n            \"taskStatus\": \"Running\",\n            \"sources\": [\n                \"mysql-replica-01\",\n                \"mysql-replica-02\"\n            ]\n        },\n        {\n            \"taskName\": \"test2\",\n            \"taskStatus\": \"Paused\",\n            \"sources\": [\n                \"mysql-replica-01\",\n                \"mysql-replica-02\"\n            ]\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Session Bindings\nDESCRIPTION: This SQL snippet shows how to use SHOW SESSION BINDINGS to retrieve the currently set session bindings, providing useful metadata such as original SQL and status.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-bindings.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW SESSION BINDINGS\\G\n*************************** 1. row ***************************\nOriginal_sql: select * from t1 where b = ?\n    Bind_sql: SELECT * FROM t1 IGNORE INDEX (b) WHERE b = 123\n  Default_db: test\n      Status: using\n Create_time: 2020-05-22 14:38:03.456\n Update_time: 2020-05-22 14:38:03.456\n     Charset: utf8mb4\n   Collation: utf8mb4_0900_ai_ci\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Merging Custom Components into a TiUP Mirror\nDESCRIPTION: Sets up a mirror, grants user permissions, and merges components from another mirror location.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n$ tiup mirror set /data/my_mirror\n$ tiup mirror grant $USER\n$ tiup mirror merge /data/my_custom_components\n```\n\n----------------------------------------\n\nTITLE: Example usage of SHOW CREATE USER in TiDB\nDESCRIPTION: These SQL statements demonstrate the usage of `SHOW CREATE USER` to display the `CREATE USER` statement for the `root` user in TiDB. The output shows how to recreate the user using the `CREATE USER` syntax and also demonstrates how to check user grants.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-user.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW CREATE USER 'root';\n+--------------------------------------------------------------------------------------------------------------------------+\n| CREATE USER for root@%                                                                                                   |\n+--------------------------------------------------------------------------------------------------------------------------+\n| CREATE USER 'root'@'%' IDENTIFIED WITH 'mysql_native_password' AS '' REQUIRE NONE PASSWORD EXPIRE DEFAULT ACCOUNT UNLOCK |\n+--------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n\nmysql> SHOW GRANTS FOR 'root';\n+-------------------------------------------+\n| Grants for root@%                         |\n+-------------------------------------------+\n| GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' |\n+-------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Updating Store Label in TiKV\nDESCRIPTION: This command updates an existing label of a specified store by changing the value of a given key. Ensure the store ID is valid, and the new value is provided in the command.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_53\n\nLANGUAGE: bash\nCODE:\n```\nstore label 1 zone=us\n```\n\n----------------------------------------\n\nTITLE: Selecting TiDB slow-threshold Variable Result\nDESCRIPTION: This SQL statement is the response to the previous SELECT query.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\n+---------------------------+\n| @@tidb_slow_log_threshold |\n+---------------------------+\n| 200                       |\n+---------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Filtering SQL Plan Baseline by User Name\nDESCRIPTION: Exclude plan baseline capturing for specific database users to provide granular control over baseline generation.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_32\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO mysql.capture_plan_baselines_blacklist(filter_type, filter_value) VALUES('user', 'user1');\n```\n\n----------------------------------------\n\nTITLE: Creating Users in TiDB\nDESCRIPTION: This snippet demonstrates how to create multiple users in TiDB using the `CREATE USER` statement.  Each user is created with a specified username, host, and password. The user needs the `CREATE USER` privilege to execute this statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'dev1'@'localhost' IDENTIFIED BY 'dev1pass';\nCREATE USER 'read_user1'@'localhost' IDENTIFIED BY 'read_user1pass';\nCREATE USER 'read_user2'@'localhost' IDENTIFIED BY 'read_user2pass';\nCREATE USER 'rw_user1'@'localhost' IDENTIFIED BY 'rw_user1pass';\n```\n\n----------------------------------------\n\nTITLE: Removing User Comment in TiDB\nDESCRIPTION: Example of removing the comment from the user 'newuser' by setting it to null using ALTER USER and then querying the user_attributes table to verify the change. This demonstrates how to manage custom metadata for user accounts in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'newuser' ATTRIBUTE '{\"comment\": null}';\nmysql> SELECT * FROM information_schema.user_attributes;\n+-----------+------+---------------------------+\n| USER      | HOST | ATTRIBUTE                 |\n+-----------+------+---------------------------+\n| newuser   | %    | {\"newAttr\": \"value\"}      |\n+-----------+------+---------------------------+\n1 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Altering a Table to Set SHARD_ROW_ID_BITS in TiDB\nDESCRIPTION: Shows how to modify an existing table to set SHARD_ROW_ID_BITS to 4, enabling row ID sharding for newly written data.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-hot-spot-issues.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t SHARD_ROW_ID_BITS = 4;\n```\n\n----------------------------------------\n\nTITLE: Deleting a Table from a Schema (Shell)\nDESCRIPTION: This snippet shows how to use cURL to delete a specific table from a schema associated with a replication task. It sends a DELETE request to the API endpoint and expects a 200 status code if successful.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_43\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'DELETE' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1/sources/source-1/schemas/db1/table1' \\\n  -H 'accept: */*'\n```\n\n----------------------------------------\n\nTITLE: Lock Tables Example - Duplicate Table Lock\nDESCRIPTION: This SQL snippet demonstrates the error that occurs when attempting to acquire the same table lock multiple times in a single `LOCK TABLES` statement. It shows the resulting error message indicating a non-unique table alias.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-lock-tables-and-unlock-tables.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n\"> LOCK TABLES t WRITE, t READ;\\nERROR 1066 (42000): Not unique table/alias: 't'\"\n```\n\n----------------------------------------\n\nTITLE: MySQL Client Login with JWT Token\nDESCRIPTION: Authenticates a user using a generated JWT token with the MySQL clear text plugin\nSOURCE: https://github.com/pingcap/docs/blob/master/security-compatibility-with-mysql.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nmycli -h 127.0.0.1 -P 4000 -u 'user@pingcap.com' -p '<the-token-generated>'\n```\n\n----------------------------------------\n\nTITLE: TiDB Dashboard URL Example\nDESCRIPTION: Basic URL format for accessing TiDB Dashboard. Replace the IP and port with actual PD instance details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-access.md#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nhttp://127.0.0.1:2379/dashboard\n```\n\n----------------------------------------\n\nTITLE: Using TiUP Cluster Edit-Config Command in Shell\nDESCRIPTION: Command syntax for modifying cluster configuration using tiup cluster edit-config. The command requires a cluster name parameter and optionally accepts flags. After modification, the tiup cluster reload command must be executed to apply changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-edit-config.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster edit-config <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Setting Fine Grained Shuffle Stream Count to 20\nDESCRIPTION: Explicitly sets the `tiflash_fine_grained_shuffle_stream_count` system variable to 20 to increase the concurrency level for window function execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nmysql> set @@tiflash_fine_grained_shuffle_stream_count = 20;\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring soft-pending-compaction-bytes-limit in TiKV\nDESCRIPTION: This snippet demonstrates how to adjust the `soft-pending-compaction-bytes-limit` parameter in the TiKV configuration file to alleviate `server is busy` errors triggered by too many pending compaction bytes.  The parameter controls when the flow control mechanism begins to reject some write requests.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_4\n\nLANGUAGE: TOML\nCODE:\n```\n\"[storage.flow-control] soft-pending-compaction-bytes-limit = \\\"384GiB\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Backing up TiDB data with encryption key as command-line option\nDESCRIPTION: This command demonstrates how to use the --azblob.encryption-key option in the tiup br backup command to specify an AES256 encryption key for Azure Blob Storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd <pd-address> --storage \"azure://<bucket>/<prefix>\" --azblob.encryption-key <aes256-key>\n```\n\n----------------------------------------\n\nTITLE: Enabling All Granted Roles in the Current Session in TiDB\nDESCRIPTION: This snippet shows how to enable all roles granted to the user for the current session using the `SET ROLE ALL` statement. This activates all roles that have been granted to the user.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSET ROLE ALL\n```\n\n----------------------------------------\n\nTITLE: Checking Security Enhanced Mode Status in TiDB SQL\nDESCRIPTION: Indicates whether the TiDB server has Security Enhanced Mode (SEM) enabled. This variable cannot be changed without restarting the TiDB server.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.0.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW VARIABLES LIKE 'tidb_enable_enhanced_security';\n```\n\n----------------------------------------\n\nTITLE: MySQL Error Message\nDESCRIPTION: Error message shown when attempting to create duplicate table names with different cases\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-best-practices.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nERROR 1050 (42S01): Table '{tablename}' already exists\n```\n\n----------------------------------------\n\nTITLE: Setting Default Role SQL Command\nDESCRIPTION: SQL command to set the analyticsteam role as the default role for user jennifer.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-default-role.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSET DEFAULT ROLE analyticsteam TO jennifer;\nQuery OK, 0 rows affected (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Retrieving DDL Job Queries with LIMIT Clause\nDESCRIPTION: This set of commands demonstrates how to use the LIMIT clause to retrieve a specific number of DDL job queries. It provides flexibility in viewing only a subset of the DDL history.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW DDL JOB QUERIES LIMIT m;  # Retrieve first m rows\nADMIN SHOW DDL JOB QUERIES LIMIT n, m;  # Retrieve rows [n+1, n+m]\nADMIN SHOW DDL JOB QUERIES LIMIT m OFFSET n;  # Retrieve rows [n+1, n+m]\n```\n\n----------------------------------------\n\nTITLE: Checking DM Task Configuration with tiup dmctl\nDESCRIPTION: Shell command to validate a DM task configuration file before starting the migration task. This helps to identify any configuration errors early.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} check-task task.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring Raft Log Garbage Collection\nDESCRIPTION: This snippet details parameters for managing Raft log garbage collection, including intervals for log polling tasks and thresholds for log retention.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_11\n\nLANGUAGE: markdown\nCODE:\n```\n+ The time interval to compact unnecessary Raft logs\n+ Default value: `\"2s\"`\n+ Minimum value: `\"0s\"`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n+ The soft limit on the maximum allowable count of residual Raft logs\n+ Default value: `50`\n+ Minimum value: `1`\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables\nDESCRIPTION: Sources the shell profile to set up TiUP environment variables\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nsource ${your_shell_profile}\n```\n\n----------------------------------------\n\nTITLE: Specifying Key Path for TLS in TiDB\nDESCRIPTION: Identifies the private key of the TiDB service for establishing secure connections using TLS. The default mirrors the security.key-path setting.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_18\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- Example: `\"/path/to/lightning.key\"` -->\n```\n\n----------------------------------------\n\nTITLE: Running TiDB Lightning Migration Task\nDESCRIPTION: This bash snippet explains how to run the TiDB Lightning migration task. It highlights the importance of using `nohup` or similar tools to prevent process termination on SIGHUP signals and shows how to pass AWS credentials as environment variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nexport AWS_ACCESS_KEY_ID=${access_key}\nexport AWS_SECRET_ACCESS_KEY=${secret_key}\nnohup tiup tidb-lightning -config tidb-lightning.toml > nohup.out 2>&1 &\n```\n\n----------------------------------------\n\nTITLE: Enabling OpenAPI in DM-master Configuration (TOML)\nDESCRIPTION: Configuration snippet to enable OpenAPI in the DM-master configuration file when deploying DM using binary.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nopenapi = true\n```\n\n----------------------------------------\n\nTITLE: Running Data Recovery Command - Shell\nDESCRIPTION: This shell command is used to manually recover data in the secondary cluster following a disaster in the primary cluster. It involves specifying temporary directory, storage address for incremental data, and the secondary cluster address for restoration.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-mysql.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncdc redo apply --tmp-dir=\"/tmp/cdc/redo/apply\" \\\n    --storage=\"s3://logbucket/test-changefeed?endpoint=http://10.0.10.25:24927/\" \\\n    --sink-uri=\"mysql://normal:123456@10.0.10.55:3306/\"\n```\n\n----------------------------------------\n\nTITLE: Setting Global Session Plan Cache Size in TiDB - SQL\nDESCRIPTION: This SQL snippet sets the global variable 'tidb_session_plan_cache_size' to allow caching of more execution plans. This modification can help in performance tuning, specifically for workloads requiring cached plans.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_session_plan_cache_size = 1000;\n```\n\n----------------------------------------\n\nTITLE: Generated SQL for Downstream Systems\nDESCRIPTION: Shows the SQL statements generated by TiCDC based on upstream data changes for insertion and updating in downstream TiDB or MySQL systems. The task is to ensure consistency in database states rather than replicating exact SQL verbatim from upstream. Prerequisites include a compatible downstream database setup.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO `test.t1` (`A`,`B`) VALUES (1,2),(2,2),(3,3);\\nUPDATE `test`.`t1`\\nSET `A` = CASE\\n        WHEN `A` = 1 THEN 1\\n        WHEN `A` = 2 THEN 2\\nEND, `B` = CASE\\n        WHEN `A` = 1 THEN 4\\n        WHEN `A` = 2 THEN 4\\nEND\\nWHERE `A` = 1 OR `A` = 2;\n```\n\n----------------------------------------\n\nTITLE: Setting Old Cluster to Read-Only Mode - SQL\nDESCRIPTION: SQL command used to set the old cluster to read-only mode, effectively preventing further data changes. Requires administrator rights. It's recommended to restart TiDB nodes afterward to ensure all sessions comply.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_super_read_only=ON;\n```\n\n----------------------------------------\n\nTITLE: Starting a Local Import Task with Custom Concurrency in TiDB Cloud CLI\nDESCRIPTION: Example of starting a local data import task with a custom upload concurrency setting. This allows control over the number of concurrent file uploads during the import process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-start.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import start --local.file-path <file-path> --cluster-id <cluster-id> --file-type <file-type> --local.target-database <target-database> --local.target-table <target-table> --local.concurrency 10\n```\n\n----------------------------------------\n\nTITLE: Query Result for Correlated Subquery Without NO_DECORRELATE Hint in SQL\nDESCRIPTION: Shows the execution plan for the correlated subquery without the NO_DECORRELATE hint. The optimizer has automatically performed decorrelation, using join operations instead of an Apply operator.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------------+----------+-----------+---------------+--------------------------------------------------------------------------------------------------------------+\n| id                               | estRows  | task      | access object | operator info                                                                                                |\n+----------------------------------+----------+-----------+---------------+--------------------------------------------------------------------------------------------------------------+\n| HashJoin_11                      | 9990.00  | root      |               | inner join, equal:[eq(test.t1.b, test.t2.b)], other cond:lt(cast(test.t1.a, decimal(10,0) BINARY), Column#7) |\n| ├─HashAgg_23(Build)              | 7992.00  | root      |               | group by:test.t2.b, funcs:sum(Column#8)->Column#7, funcs:firstrow(test.t2.b)->test.t2.b                      |\n| │ └─TableReader_24               | 7992.00  | root      |               | data:HashAgg_16                                                                                              |\n| │   └─HashAgg_16                 | 7992.00  | cop[tikv] |               | group by:test.t2.b, funcs:sum(test.t2.a)->Column#8                                                           |\n| │     └─Selection_22             | 9990.00  | cop[tikv] |               | not(isnull(test.t2.b))                                                                                       |\n| │       └─TableFullScan_21       | 10000.00 | cop[tikv] | table:t2      | keep order:false, stats:pseudo                                                                               |\n| └─TableReader_15(Probe)          | 9990.00  | root      |               | data:Selection_14                                                                                            |\n|   └─Selection_14                 | 9990.00  | cop[tikv] |               | not(isnull(test.t1.b))                                                                                       |\n|     └─TableFullScan_13           | 10000.00 | cop[tikv] | table:t1      | keep order:false, stats:pseudo                                                                               |\n+----------------------------------+----------+-----------+---------------+--------------------------------------------------------------------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Modifying Components in TiUP Shell\nDESCRIPTION: The `tiup mirror modify` command is utilized to modify components that have already been published. Only the original component owner is authorized to make modifications. Key parameters include the component name and optional version to alter. The command includes several flags like -k for specifying the owner's private key, --yank for marking versions unavailable, --hide for hiding components, and --standalone, although the latter is currently non-functional. Successful execution results in no output, whereas unauthorized access or errors produce specified error messages.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-modify.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror modify <component>[:version] [flags]\n```\n\n----------------------------------------\n\nTITLE: Assigning Backoffer to Regions in Go\nDESCRIPTION: This code snippet assigns different Backoffer instances to each Region to prevent SQL timeout issues when multiple Region requests fail simultaneously.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.16.md#2025-04-18_snippet_0\n\nLANGUAGE: Go\nCODE:\n```\nAssign different `Backoffer`s to each Region to avoid the SQL timeout issue when multiple Region requests fail at the same time [#17583](https://github.com/pingcap/tidb/pull/17583)\n```\n\n----------------------------------------\n\nTITLE: Locking Table Statistics and Attempting ANALYZE in TiDB\nDESCRIPTION: This SQL snippet shows locking table statistics with LOCK STATS, viewing locked statistics with SHOW STATS_LOCKED, and attempting to run ANALYZE on a locked table. The ANALYZE statement skips the locked table as shown in the warnings.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nmysql> LOCK STATS t;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SHOW STATS_LOCKED;\n+---------+------------+----------------+--------+\n| Db_name | Table_name | Partition_name | Status |\n+---------+------------+----------------+--------+\n| test    | t          |                | locked |\n+---------+------------+----------------+--------+\n1 row in set (0.01 sec)\n\nmysql> ANALYZE TABLE t;\nQuery OK, 0 rows affected, 2 warnings (0.00 sec)\n\nmysql> SHOW WARNINGS;\n+---------+------+-----------------------------------------------------------------------------------------------------------------------------------------+\n| Level   | Code | Message                                                                                                                                 |\n+---------+------+-----------------------------------------------------------------------------------------------------------------------------------------+\n| Note    | 1105 | Analyze use auto adjusted sample rate 1.000000 for table test.t, reason to use this rate is \"use min(1, 110000/8) as the sample-rate=1\" |\n| Warning | 1105 | skip analyze locked table: test.t                                                                                                       |\n+---------+------+-----------------------------------------------------------------------------------------------------------------------------------------+\n2 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a Table for ORDER_INDEX Examples in TiDB\nDESCRIPTION: Example query that creates a table with indexes for demonstrating the ORDER_INDEX and NO_ORDER_INDEX hints.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_31\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a INT, b INT, key(a), key(b));\nEXPLAIN SELECT /*+ ORDER_INDEX(t, a) */ a FROM t ORDER BY a LIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Enabling TiDB Workload Repository\nDESCRIPTION: SQL command to enable the Workload Repository by setting the global system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/workload-repository.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_workload_repository_dest = 'table';\n```\n\n----------------------------------------\n\nTITLE: Corrected Non-Transactional DML with JOIN Syntax\nDESCRIPTION: Example showing how to correct a non-transactional DML statement by moving the condition to the JOIN ON clause instead of using it in the WHERE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nBATCH ON test.t2.id LIMIT 1 \nINSERT INTO t \nSELECT t2.id, t2.v, t3.id FROM t2 JOIN t3 ON t2.id = t3.id\n```\n\n----------------------------------------\n\nTITLE: Addressing `invalid connection` error\nDESCRIPTION: This snippet addresses the `invalid connection` error that involves interrupted replication tasks linking to various connection anomalies, alongside troubleshooting steps for versions pre and post DM 1.0.0 GA.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\n- The `invalid connection` error indicates that an anomaly has occurred in the connection between DM and the downstream TiDB database (such as network failure, TiDB restart, and TiKV busy), and that a part of the data for the current request has been sent to TiDB. Because DM has the feature of concurrently replicating data to the downstream in replication tasks, several errors might occur when a task is interrupted. You can check these errors by running `query-status` or `query-error`.\n\n    - If only the `invalid connection` error occurs during the incremental replication process, DM retries the task automatically.\n    - If DM does not retry or fails to retry automatically because of version problems (automatic retry is introduced in v1.0.0-rc.1), use `stop-task` to stop the task and then use `start-task` to restart the task.\n```\n\n----------------------------------------\n\nTITLE: Range Comparison Partition Pruning\nDESCRIPTION: Illustrates partition pruning with BETWEEN operator and range comparisons, showing how the query optimizer selects only the relevant partitions within the specified range.\nSOURCE: https://github.com/pingcap/docs/blob/master/partition-pruning.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (x int) partition by range (x) (\n    partition p0 values less than (5),\n    partition p1 values less than (10),\n    partition p2 values less than (15)\n    );\nexplain select * from t where x between 7 and 14;\n```\n\n----------------------------------------\n\nTITLE: Querying Updated Runaway Watches List in SQL\nDESCRIPTION: This SQL query retrieves all entries from the RUNAWAY_WATCHES table after adding a new watch item, showing the updated watch list.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-runaway-watches.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.RUNAWAY_WATCHES\\G\n```\n\n----------------------------------------\n\nTITLE: Restoring Single Database\nDESCRIPTION: Command to restore a specific database from a backup using BR, with rate limiting and logging options.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore db \\\n    --pd \"${PD_IP}:2379\" \\\n    --db \"test\" \\\n    --ratelimit 128 \\\n    --storage \"s3://${backup_collection_addr}/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --log-file restore_db.log\n```\n\n----------------------------------------\n\nTITLE: Invalid Creating Tables with Primary Keys - SQL\nDESCRIPTION: This snippet details SQL table creation statements that are invalid because the primary key does not incorporate all columns referenced in the partitioning expression, thus violating partitioning rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_58\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCREATE TABLE t5 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    PRIMARY KEY(col1, col2)\n)\n\nPARTITION BY HASH(col3)\nPARTITIONS 4;\n\nCREATE TABLE t6 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    PRIMARY KEY(col1, col3),\n    UNIQUE KEY(col2)\n)\n\nPARTITION BY HASH( YEAR(col2) )\nPARTITIONS 4;\n```\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax for ADMIN PAUSE DDL JOBS Statement in TiDB\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the ADMIN PAUSE DDL JOBS statement in TiDB. It shows the structure of the statement, including the required keywords and the NumList production.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-pause-ddl.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nAdminPauseDDLStmt ::=\n    'ADMIN' 'PAUSE' 'DDL' 'JOBS' NumList \n\nNumList ::=\n    Int64Num ( ',' Int64Num )*\n```\n\n----------------------------------------\n\nTITLE: Point-Get Query Explanation\nDESCRIPTION: Illustrates explaining a point-get query that retrieves a specific row by its primary key using EXPLAIN\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t1 WHERE id = 1;\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_ordered_result_mode in TiDB\nDESCRIPTION: Specifies whether to automatically sort the output of SQL queries. Default is OFF, and enabling this variable will affect the output order of grouped queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_33\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): Yes\n- Type: Boolean\n- Default value: `OFF`\n- Specifies whether to sort the final output result automatically.\n```\n\n----------------------------------------\n\nTITLE: Uploading collected diagnostic data to Clinic Server\nDESCRIPTION: Command to upload the previously collected diagnostic data to Clinic Server. After completion, a download URL will be provided for accessing the data. Note that the upload size limit is 3 GB.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/quick-start-with-clinic.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag upload ${filepath}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Session Attributes from SESSION_CONNECT_ATTRS Table in SQL\nDESCRIPTION: This SQL snippet retrieves and displays data from the SESSION_CONNECT_ATTRS table, showing details of connection attributes like client name, version, OS, PID, platform, and program name. Users must have permissions to access the performance_schema to execute this snippet.\nSOURCE: https://github.com/pingcap/docs/blob/master/performance-schema/performance-schema-session-connect-attrs.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nUSE performance_schema;\\nTABLE SESSION_CONNECT_ATTRS;\n```\n\n----------------------------------------\n\nTITLE: Adding TiDB User Resource Limits\nDESCRIPTION: Configure system resource limits for the tidb user to optimize performance and system constraints\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-no-sudo-mode.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncat << EOF >>/etc/security/limits.conf\ntidb           soft    nofile         1000000\ntidb           hard    nofile         1000000\ntidb           soft    stack          32768\ntidb           hard    stack          32768\ntidb           soft    core           unlimited\ntidb           hard    core           unlimited\nEOF\n```\n\n----------------------------------------\n\nTITLE: Splitting Index Data for Varchar Type in SQL\nDESCRIPTION: This SQL statement splits the index 'idx1' into 25 Regions, dividing the character range between 'a' and 'z' to distribute values based on string prefixes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT TABLE t INDEX idx1 BETWEEN (\"a\") AND (\"z\") REGIONS 25;\n```\n\n----------------------------------------\n\nTITLE: Monitoring TiFlash Raft Wait Index Duration using PromQL\nDESCRIPTION: This PromQL query alerts when the 99th percentile of Raft wait index duration exceeds 2 seconds in the last minute. It helps identify slow Raft index synchronization in TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-alert-rules.md#2025-04-18_snippet_3\n\nLANGUAGE: promql\nCODE:\n```\nhistogram_quantile(0.99, sum(rate(tiflash_raft_wait_index_duration_seconds_bucket[1m])) BY (le, instance)) > 2\n```\n\n----------------------------------------\n\nTITLE: Checking TiFlash Replicas Availability (SQL)\nDESCRIPTION: This SQL snippet checks the availability and progress of the TiFlash replicas for both the `catalog_sales` and `date_dim` tables after creation to ensure they are ready for query operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/runtime-filter.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.TIFLASH_REPLICA WHERE TABLE_NAME='catalog_sales';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.TIFLASH_REPLICA WHERE TABLE_NAME='date_dim';\n```\n\n----------------------------------------\n\nTITLE: Enabling Titan in TiDB Operator on Kubernetes\nDESCRIPTION: This snippet shows how to enable Titan by editing the cluster configuration YAML file for TiDB Operator on Kubernetes, followed by applying the changes to trigger a rolling restart.\nSOURCE: https://github.com/pingcap/docs/blob/master/storage-engine/titan-configuration.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nspec:\n  tikv:\n    ## Base image of the component\n    baseImage: pingcap/tikv\n    ## tikv-server configuration\n    ## Ref: https://docs.pingcap.com/tidb/stable/tikv-configuration-file\n    config: |\n      log-level = \"info\"\n      [rocksdb]\n        [rocksdb.titan]\n          enabled = true\n```\n\nLANGUAGE: shell\nCODE:\n```\nkubectl apply -f ${cluster_name} -n ${namespace}\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS Encrypted Transmission for Pulsar in TiCDC\nDESCRIPTION: This snippet demonstrates how to configure TLS encrypted transmission for Pulsar in TiCDC, enabling secure data transfer between TiCDC and Pulsar. It shows the required sink URI and the `tls-trust-certs-file-path` parameter in the changefeed configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"pulsar+ssl://127.0.0.1:6651/persistent://public/default/yktest?protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: Describing TiDB Cloud Serverless Cluster in Shell\nDESCRIPTION: Command to get information about a TiDB Cloud Serverless cluster, including configurations and status. Can be used in both interactive and non-interactive modes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-describe.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless describe [flags]\n```\n\n----------------------------------------\n\nTITLE: Creating User for TiCDC Authentication\nDESCRIPTION: Create a TiDB user with specific permissions for logging in from a TiCDC node.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-client-authentication.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'test'@'ticdc_ip_address' IDENTIFIED BY 'password';\n```\n\n----------------------------------------\n\nTITLE: Reloading TiDB Cluster Configuration\nDESCRIPTION: This command reloads the TiDB cluster configuration. This is only required for versions earlier than TiUP v1.15.0. This is especially important after adding PD nodes to ensure the cluster is aware of the new nodes and their configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster reload <cluster-name> --skip-restart\"\n```\n\n----------------------------------------\n\nTITLE: Configuring a MySQL Sink URI for TiCDC\nDESCRIPTION: This example command configures the sink URI for a MySQL-compatible database, establishing the connection details necessary for TiCDC to replicate data. Key parameters include database user credentials and the target database address.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-mysql.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"mysql://root:12345678@127.0.0.1:3306\"\n```\n\n----------------------------------------\n\nTITLE: Installing MySQL Client on Linux\nDESCRIPTION: Command to install MySQL client using YUM package manager on Linux distributions.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connect-to-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsudo yum install mysql\n```\n\n----------------------------------------\n\nTITLE: Restoring TiDB Database from S3\nDESCRIPTION: SQL command to restore database from S3 backup.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nRESTORE DATABASE * FROM 's3://backup?access-key=minio&secret-access-key=miniostorage&endpoint=http://${HOST_IP}:6060&force-path-style=true';\n```\n\n----------------------------------------\n\nTITLE: SMALLINT Type Declaration in SQL\nDESCRIPTION: Syntax for declaring SMALLINT type with optional display width, unsigned flag and zero-fill option\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-numeric.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSMALLINT[(M)] [UNSIGNED] [ZEROFILL]\n```\n\n----------------------------------------\n\nTITLE: Using TiDB Vector Store as a LangChain Retriever\nDESCRIPTION: This code demonstrates how to use TiDB vector store as a LangChain retriever with a similarity score threshold. The retriever will only return documents with a similarity score above the specified threshold when responding to queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nretriever = vector_store.as_retriever(\n   search_type=\"similarity_score_threshold\",\n   search_kwargs={\"k\": 3, \"score_threshold\": 0.8},\n)\ndocs_retrieved = retriever.invoke(query)\nfor doc in docs_retrieved:\n   print(\"-\" * 80)\n   print(doc.page_content)\n   print(\"-\" * 80)\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS Trust Certs File Path for Pulsar in TiCDC\nDESCRIPTION: This TOML snippet shows how to configure the path to the TLS trust certificates file for Pulsar in the TiCDC changefeed configuration. This configuration is required for verifying the Pulsar server's certificate during TLS handshake.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\n[sink.pulsar-config]\ntls-trust-certs-file-path=\"/data/pulsar/tls-trust-certs-file\"\n```\n\n----------------------------------------\n\nTITLE: Tagged Deployment\nDESCRIPTION: Command to deploy TiDB cluster with a tag for data persistence.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground --tag ${tag_name}\n```\n\n----------------------------------------\n\nTITLE: Listing All Replication Tasks with cURL (DM API)\nDESCRIPTION: This example shows how to retrieve a list of all existing replication tasks. The GET request returns configurations for all tasks managed by the DM cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_36\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/tasks' \\\n  -H 'accept: application/json'\n```\n\n----------------------------------------\n\nTITLE: Fixing SQL Query Error in TiDB\nDESCRIPTION: This fix addresses the 'unknown column error' for SQL statements like 'select a from t having t.a'. It resolves an issue where the column reference in the HAVING clause was not properly recognized.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.5.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nselect a from t having t.a\n```\n\n----------------------------------------\n\nTITLE: Disabling Subquery Pre-Execution with System Variable\nDESCRIPTION: Example of setting the tidb_opt_enable_non_eval_scalar_subquery system variable to ON to prevent TiDB from pre-executing subqueries during EXPLAIN.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSET @@tidb_opt_enable_non_eval_scalar_subquery = ON;\nEXPLAIN SELECT * FROM t2 WHERE a = (SELECT a FROM t1);\n```\n\n----------------------------------------\n\nTITLE: Adjusting GC Life Time in TiDB v5.0+\nDESCRIPTION: For TiDB v5.0 and later versions, adjust the system variable tidb_gc_life_time to increase the retention time of MVCC versions. This affects all existing snapshots globally and immediately.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-timeouts-in-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_gc_life_time = '30m';\n```\n\n----------------------------------------\n\nTITLE: Recover from MVCC Data Corruption\nDESCRIPTION: This command tries to recover TiKV from MVCC data corruption by cross-checking necessary column families. It is crucial for restoring system stability.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir /path/to/tikv recover-mvcc -r 1001,1002 -p 127.0.0.1:2379\n```\n\n----------------------------------------\n\nTITLE: Querying DDL Lock Status\nDESCRIPTION: Command to view DDL lock information for a specific task on the DM-master\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/manually-handling-sharding-ddl-locks.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nshard-ddl-lock test\n```\n\n----------------------------------------\n\nTITLE: Preparing Sample Data for MySQL Instances\nDESCRIPTION: SQL commands to create sample databases and tables with example data in the two MySQL instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-task.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ndrop database if exists `sharding1`;\ncreate database `sharding1`;\nuse `sharding1`;\ncreate table t1 (id bigint, uid int, name varchar(80), info varchar(100), primary key (`id`), unique key(`uid`)) DEFAULT CHARSET=utf8mb4;\ncreate table t2 (id bigint, uid int, name varchar(80), info varchar(100), primary key (`id`), unique key(`uid`)) DEFAULT CHARSET=utf8mb4;\ninsert into t1 (id, uid, name) values (1, 10001, 'Gabriel García Márquez'), (2 ,10002, 'Cien años de soledad');\ninsert into t2 (id, uid, name) values (3,20001, 'José Arcadio Buendía'), (4,20002, 'Úrsula Iguarán'), (5,20003, 'José Arcadio');\n```\n\nLANGUAGE: sql\nCODE:\n```\ndrop database if exists `sharding2`;\ncreate database `sharding2`;\nuse `sharding2`;\ncreate table t2 (id bigint, uid int, name varchar(80), info varchar(100), primary key (`id`), unique key(`uid`)) DEFAULT CHARSET=utf8mb4;\ncreate table t3 (id bigint, uid int, name varchar(80), info varchar(100), primary key (`id`), unique key(`uid`)) DEFAULT CHARSET=utf8mb4;\ninsert into t2 (id, uid, name, info) values (6, 40000, 'Remedios Moscote', '{}');\ninsert into t3 (id, uid, name, info) values (7, 30001, 'Aureliano José', '{}'), (8, 30002, 'Santa Sofía de la Piedad', '{}'), (9, 30003, '17 Aurelianos', NULL);\n```\n\n----------------------------------------\n\nTITLE: Warning Example: Using COPY Algorithm with INPLACE Operation\nDESCRIPTION: SQL statements showing that using ALGORITHM=COPY for an operation that requires INPLACE generates a warning rather than an error. This behavior is due to TiDB interpreting the assertion as 'this algorithm or better'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t1 ADD INDEX (c1), ALGORITHM=COPY;\nSHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: Starting DM Replication Task\nDESCRIPTION: Command example for launching DM incremental replication using a task YAML file. Ensures connectivity to DM-Master through an advertised address.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-to-tidb.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} start-task task.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating Sample Table for Extended Statistics Example\nDESCRIPTION: Creates a sample table with two columns and corresponding indexes to demonstrate how correlated columns can benefit from extended statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/extended-statistics.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(col1 INT, col2 INT, KEY(col1), KEY(col2));\n```\n\n----------------------------------------\n\nTITLE: Using GET_LOCK Function in TiDB SQL\nDESCRIPTION: Acquires an advisory lock with a specified name and timeout. The lockName must not exceed 64 characters. The function waits for a maximum of timeout seconds before failing.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/locking-functions.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nGET_LOCK(lockName, timeout)\n```\n\n----------------------------------------\n\nTITLE: Explain Hash Aggregation in TiDB\nDESCRIPTION: This SQL query uses the `EXPLAIN` statement with the `HASH_AGG()` hint to force the use of Hash Aggregation for a `count(*)` query on table `t1`. The output shows the plan and the functions used for aggregation.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-aggregation.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ HASH_AGG() */ count(*) FROM t1;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+---------------------------+-----------+-----------+---------------+---------------------------------+\n| id                        | estRows   | task      | access object | operator info                   |\n+---------------------------+-----------+-----------+---------------+---------------------------------+\n| HashAgg_9                 | 1.00      | root      |               | funcs:count(Column#6)->Column#5 |\n| └─TableReader_10          | 1.00      | root      |               | data:HashAgg_5                  |\n|   └─HashAgg_5             | 1.00      | cop[tikv] |               | funcs:count(1)->Column#6        |\n|     └─TableFullScan_8     | 242020.00 | cop[tikv] | table:t1      | keep order:false                |\n+---------------------------+-----------+-----------+---------------+---------------------------------+\n4 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Application Retry Logic for Transaction Errors\nDESCRIPTION: Python pseudocode that implements transaction retry logic for handling common errors in TiDB's optimistic transaction mode. The code includes exponential backoff and handles specific error codes: 9007 (Write conflict), 8028 (Schema change), 8002 (SELECT FOR UPDATE conflict), and 8022 (KV error).\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-troubleshoot.md#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwhile True:\n    n++\n    if n == max_retries:\n        raise(\"did not succeed within #{n} retries\")\n    try:\n        connection.execute(\"your sql statement here\")\n        connection.exec('COMMIT')\n        break\n    catch error:\n        if (error.code != \"9007\" && error.code != \"8028\" && error.code != \"8002\" && error.code != \"8022\"):\n            raise error\n        else:\n            connection.exec('ROLLBACK')\n\n            # Capture the error types that require application-side retry,\n            # wait for a short period of time,\n            # and exponentially increase the wait time for each transaction failure\n            sleep_ms = int(((1.5 ** n) + rand) * 100)\n            sleep(sleep_ms) # make sure your sleep() takes milliseconds\n```\n\n----------------------------------------\n\nTITLE: Setting Concurrency for Statistics Collection\nDESCRIPTION: These SQL commands set various concurrency parameters to expedite the collection of statistics for the tables before running tests.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_build_stats_concurrency=16;\nSET tidb_distsql_scan_concurrency=16;\nSET tidb_index_serial_scan_concurrency=16;\n```\n\n----------------------------------------\n\nTITLE: Encoding DELETE Event in TiCDC - JSON\nDESCRIPTION: This snippet illustrates the JSON format for a DELETE event in TiCDC. It includes essential fields such as version, database name, table name, and the old data that was deleted. This structure is critical for understanding which data has been removed from the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-simple-protocol.md#2025-04-18_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"version\":1,\n   \"database\":\"simple\",\n   \"table\":\"user\",\n   \"tableID\":148,\n   \"type\":\"DELETE\",\n   \"commitTs\":447984114259722243,\n   \"buildTs\":1708923776484,\n   \"schemaVersion\":447984074911121426,\n   \"old\":{\n      \"age\":\"25\",\n      \"id\":\"1\",\n      \"name\":\"John Doe\",\n      \"score\":\"95\"\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Sequence as Default Value in Table Creation\nDESCRIPTION: Demonstrates how to use a sequence as the default value for a column when creating a table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-sequence.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE table t(a int default next value for seq2);\n```\n\n----------------------------------------\n\nTITLE: Defining TRAFFIC REPLAY Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) representation of the TRAFFIC REPLAY syntax, including the main statement structure and optional parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-traffic-replay.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nTrafficStmt ::=\n    \"TRAFFIC\" \"REPLAY\" \"FROM\" stringLit TrafficReplayOptList\n\nTrafficReplayOptList ::=\n    TrafficReplayOpt\n|   TrafficReplayOptList TrafficReplayOpt\n\nTrafficReplayOpt ::=\n    \"USER\" EqOpt stringLit\n|   \"PASSWORD\" EqOpt stringLit\n|   \"SPEED\" EqOpt NumLiteral\n|   \"READ_ONLY\" EqOpt Boolean\n```\n\n----------------------------------------\n\nTITLE: Enabling Cross-Table Merge in TiDB\nDESCRIPTION: Command to enable cross-table region merging in clusters with TiDB instances by setting enable-cross-table-merge to true.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/pd-scheduling-best-practices.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nconfig set enable-cross-table-merge true\n```\n\n----------------------------------------\n\nTITLE: Configuring Merger in DM Sync Module\nDESCRIPTION: YAML configuration example demonstrating how to enable the Merger feature in DM's sync processing unit by setting syncer.multiple-rows to true.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-replication-logic.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nsyncers:                            # The configuration parameters of the sync processing unit\n  global:                           # Configuration name\n    ...                              # Other configurations are omitted\n    multiple-rows: true\n```\n\n----------------------------------------\n\nTITLE: Table Creation and Data Insertion\nDESCRIPTION: Creates two tables t1 and t2 and inserts sample data for set operation examples.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/set-operators.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (a int);\nCREATE TABLE t2 (a int);\nINSERT INTO t1 VALUES (1),(2);\nINSERT INTO t2 VALUES (1),(3);\n```\n\n----------------------------------------\n\nTITLE: Updating TiUP Playground\nDESCRIPTION: Commands to update TiUP and playground components to their latest versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-faq.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ntiup update --self\ntiup update playground\n```\n\n----------------------------------------\n\nTITLE: Collecting diagnostic data with time range\nDESCRIPTION: Command to collect diagnostic data from a TiDB cluster for a specific time range (4 to 2 hours ago in this example). After execution, Diag will show the estimated data size and ask for confirmation.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/quick-start-with-clinic.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag collect ${cluster-name} -f=\"-4h\" -t=\"-2h\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with List COLUMNS Partitioning by City in SQL\nDESCRIPTION: This snippet demonstrates how to create a table 'employees_1' using List COLUMNS partitioning based on the 'city' column. It divides employees from 12 cities into 4 regions.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_22\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE employees_1 (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT,\n    city VARCHAR(15)\n)\nPARTITION BY LIST COLUMNS(city) (\n    PARTITION pRegion_1 VALUES IN('LosAngeles', 'Seattle', 'Houston'),\n    PARTITION pRegion_2 VALUES IN('Chicago', 'Columbus', 'Boston'),\n    PARTITION pRegion_3 VALUES IN('NewYork', 'LongIsland', 'Baltimore'),\n    PARTITION pRegion_4 VALUES IN('Atlanta', 'Raleigh', 'Cincinnati')\n);\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax for ALTER TABLE Statement in TiDB\nDESCRIPTION: The Extended Backus-Naur Form syntax diagram showing the complete grammar for the ALTER TABLE statement in TiDB, including all supported operations such as adding/dropping columns and indexes, modifying columns, setting table properties, and partition operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAlterTableStmt ::=\n    'ALTER' IgnoreOptional 'TABLE' TableName (\n        AlterTableSpecListOpt AlterTablePartitionOpt |\n        'ANALYZE' 'PARTITION' PartitionNameList ( 'INDEX' IndexNameList )? AnalyzeOptionListOpt |\n        'COMPACT' ( 'PARTITION' PartitionNameList )? 'TIFLASH' 'REPLICA'\n    )\n\nTableName ::=\n    Identifier ('.' Identifier)?\n\nAlterTableSpec ::=\n    TableOptionList\n|   'SET' 'TIFLASH' 'REPLICA' LengthNum LocationLabelList\n|   'CONVERT' 'TO' CharsetKw ( CharsetName | 'DEFAULT' ) OptCollate\n|   'ADD' ( ColumnKeywordOpt IfNotExists ( ColumnDef ColumnPosition | '(' TableElementList ')' ) | Constraint | 'PARTITION' IfNotExists NoWriteToBinLogAliasOpt ( PartitionDefinitionListOpt | 'PARTITIONS' NUM ) )\n|   ( ( 'CHECK' | 'TRUNCATE' ) 'PARTITION' | ( 'OPTIMIZE' | 'REPAIR' | 'REBUILD' ) 'PARTITION' NoWriteToBinLogAliasOpt ) AllOrPartitionNameList\n|   'COALESCE' 'PARTITION' NoWriteToBinLogAliasOpt NUM\n|   'DROP' ( ColumnKeywordOpt IfExists ColumnName RestrictOrCascadeOpt | 'PRIMARY' 'KEY' |  'PARTITION' IfExists PartitionNameList | ( KeyOrIndex IfExists | 'CHECK' ) Identifier | 'FOREIGN' 'KEY' Symbol )\n|   'EXCHANGE' 'PARTITION' Identifier 'WITH' 'TABLE' TableName WithValidationOpt\n|   ( 'IMPORT' | 'DISCARD' ) ( 'PARTITION' AllOrPartitionNameList )? 'TABLESPACE'\n|   'REORGANIZE' 'PARTITION' NoWriteToBinLogAliasOpt ReorganizePartitionRuleOpt\n|   'ORDER' 'BY' AlterOrderItem ( ',' AlterOrderItem )*\n|   ( 'DISABLE' | 'ENABLE' ) 'KEYS'\n|   ( 'MODIFY' ColumnKeywordOpt IfExists | 'CHANGE' ColumnKeywordOpt IfExists ColumnName ) ColumnDef ColumnPosition\n|   'ALTER' ( ColumnKeywordOpt ColumnName ( 'SET' 'DEFAULT' ( SignedLiteral | '(' Expression ')' ) | 'DROP' 'DEFAULT' ) | 'CHECK' Identifier EnforcedOrNot | 'INDEX' Identifier (\"VISIBLE\" | \"INVISIBLE\") )\n|   'RENAME' ( ( 'COLUMN' | KeyOrIndex ) Identifier 'TO' Identifier | ( 'TO' | '='? | 'AS' ) TableName )\n|   LockClause\n|   AlgorithmClause\n|   'FORCE'\n|   ( 'WITH' | 'WITHOUT' ) 'VALIDATION'\n|   'SECONDARY_LOAD'\n|   'SECONDARY_UNLOAD'\n|   ( 'AUTO_INCREMENT' | 'AUTO_ID_CACHE' | 'AUTO_RANDOM_BASE' | 'SHARD_ROW_ID_BITS' ) EqOpt LengthNum\n|   ( 'CACHE' | 'NOCACHE' )\n|   (\n        'TTL' EqOpt TimeColumnName '+' 'INTERVAL' Expression TimeUnit (TTLEnable EqOpt ( 'ON' | 'OFF' ))?\n        | 'REMOVE' 'TTL'\n        | TTLEnable EqOpt ( 'ON' | 'OFF' )\n        | TTLJobInterval EqOpt stringLit\n    )\n|   PlacementPolicyOption\n\nPlacementPolicyOption ::=\n    \"PLACEMENT\" \"POLICY\" EqOpt PolicyName\n|   \"PLACEMENT\" \"POLICY\" (EqOpt | \"SET\") \"DEFAULT\"\n```\n\n----------------------------------------\n\nTITLE: Setting Disabling MPP Mode in TiDB\nDESCRIPTION: This SQL snippet disables the MPP mode in TiDB using the session variable 'tidb_allow_mpp'. Setting this variable to 0 ensures that MPP mode is not utilized for query executions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tiflash-mpp-mode.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nset @@session.tidb_allow_mpp=0;\n```\n\n----------------------------------------\n\nTITLE: Get Position of a Substring in TiDB\nDESCRIPTION: Demonstrates how to find the position of a substring in both Oracle and TiDB using different functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nINSTR('abcdefg','b',1,1)\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSTR('abcdefg','b')\n```\n\n----------------------------------------\n\nTITLE: tiup mirror grant Syntax\nDESCRIPTION: This snippet shows the basic syntax for using the `tiup mirror grant` command. It requires specifying the component owner's ID and accepts optional flags for further configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-grant.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror grant <id> [flags]\n```\n\n----------------------------------------\n\nTITLE: Querying DEADLOCKS Table in SQL\nDESCRIPTION: This SQL query retrieves all columns from the INFORMATION_SCHEMA.DEADLOCKS table to analyze deadlock information.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-deadlocks.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.DEADLOCKS;\n```\n\n----------------------------------------\n\nTITLE: Java Prepared Statement Query - Authors by Birth Year\nDESCRIPTION: Java implementation using PreparedStatement to safely query authors by birth year, preventing SQL injection.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_4\n\nLANGUAGE: java\nCODE:\n```\npublic List<Author> getAuthorsByBirthYear(Short birthYear) throws SQLException {\n    List<Author> authors = new ArrayList<>();\n    try (Connection conn = ds.getConnection()) {\n        PreparedStatement stmt = conn.prepareStatement(\"\"\"\n        SELECT * FROM authors WHERE birth_year = ?;\n        \"\"\");\n        stmt.setShort(1, birthYear);\n        ResultSet rs = stmt.executeQuery();\n        while (rs.next()) {\n            Author author = new Author();\n            author.setId(rs.getLong(\"id\"));\n            author.setName(rs.getString(\"name\"));\n            authors.add(author);\n        }\n    }\n    return authors;\n}\n```\n\n----------------------------------------\n\nTITLE: Backing Up Cluster Snapshot with Statistics to Local Storage\nDESCRIPTION: Command to back up a TiDB cluster snapshot including table statistics to local storage. It uses the --ignore-stats=false parameter to include statistics in the backup.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full \\\n--storage local:///br_data/ --pd \"${PD_IP}:2379\" --log-file restore.log \\\n--ignore-stats=false\n```\n\n----------------------------------------\n\nTITLE: TiDB Dashboard URL Pattern\nDESCRIPTION: Default URL pattern to access the TiDB Dashboard interface. The dashboard is accessed through the PD component's IP and port.\nSOURCE: https://github.com/pingcap/docs/blob/master/daily-check.md#2025-04-18_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nhttp://${pd-ip}:${pd_port}/dashboard\n```\n\n----------------------------------------\n\nTITLE: Enabling MPP Mode in TiDB using SQL\nDESCRIPTION: This SQL command sets the tidb_enforce_mpp system variable to ON, which forces the optimizer to use TiFlash's MPP mode for query execution, ignoring cost estimation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_enforce_mpp = ON;\n```\n\n----------------------------------------\n\nTITLE: Setting strict-picking-store for balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command enables or disables strict store picking for hot region scheduling. When enabled, it ensures balance on both configured dimensions.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_41\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-hot-region-scheduler set strict-picking-store true\n```\n\n----------------------------------------\n\nTITLE: Creating Tables with AUTO_RANDOM Columns in TiDB\nDESCRIPTION: Different ways to create tables with AUTO_RANDOM columns. The AUTO_RANDOM column must be included in the primary key, and is typically the first column in the key.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-random.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a BIGINT AUTO_RANDOM, b VARCHAR(255), PRIMARY KEY (a));\nCREATE TABLE t (a BIGINT PRIMARY KEY AUTO_RANDOM, b VARCHAR(255));\nCREATE TABLE t (a BIGINT AUTO_RANDOM(6), b VARCHAR(255), PRIMARY KEY (a));\nCREATE TABLE t (a BIGINT AUTO_RANDOM(5, 54), b VARCHAR(255), PRIMARY KEY (a));\nCREATE TABLE t (a BIGINT AUTO_RANDOM(5, 54), b VARCHAR(255), PRIMARY KEY (a, b));\n```\n\n----------------------------------------\n\nTITLE: Querying Key Constraints for MySQL User Table in SQL\nDESCRIPTION: This SQL query retrieves all key constraint information for the user table in the mysql schema, showing primary key constraints on the Host and User columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-key-column-usage.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM key_column_usage WHERE table_schema='mysql' and table_name='user';\n```\n\n----------------------------------------\n\nTITLE: Configuring Amazon S3 URI for Global Sort\nDESCRIPTION: Sets the tidb_cloud_storage_uri variable to specify the Amazon S3 cloud storage URI for enabling Global Sort feature. This is used in conjunction with the TiDB Distributed eXecution Framework.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_21\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_cloud_storage_uri = 's3://your-bucket/your-path';\n```\n\n----------------------------------------\n\nTITLE: Implementing Kysely with TiDB Cloud in Node.js\nDESCRIPTION: TypeScript code demonstrating how to use Kysely with TiDB Cloud serverless driver to query data in a Node.js environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-kysely-example.md#2025-04-18_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Kysely,GeneratedAlways,Selectable } from 'kysely'\nimport { TiDBServerlessDialect } from '@tidbcloud/kysely'\n\n// Types\ninterface Database {\n  person: PersonTable\n}\n\ninterface PersonTable {\n  id: GeneratedAlways<number>\n  name: string\n  gender: \"male\" | \"female\"\n}\n\n// Dialect\nconst db = new Kysely<Database>({\n  dialect: new TiDBServerlessDialect({\n    url: process.env.DATABASE_URL\n  }),\n})\n\n// Simple Querying\ntype Person = Selectable<PersonTable>\nexport async function findPeople(criteria: Partial<Person> = {}) {\n  let query = db.selectFrom('person')\n\n  if (criteria.name){\n    query = query.where('name', '=', criteria.name)\n  }\n\n  return await query.selectAll().execute()\n}\n\nconsole.log(await findPeople())\n```\n\n----------------------------------------\n\nTITLE: Composite Multi-valued Index Query Examples\nDESCRIPTION: Detailed EXPLAIN output showing how TiDB processes queries using composite multi-valued indexes with IndexMerge.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n> EXPLAIN SELECT /*+ use_index_merge(t2, idx) */ * FROM t2 WHERE a=1 AND (1 MEMBER OF (j->'$.path')) AND b=2;\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------------+-----------------------------------------------------+\n| id                            | estRows | task      | access object                                                                     | operator info                                       |\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------------+-----------------------------------------------------+\n| IndexMerge_7                  | 0.00    | root      |                                                                                   | type: union                                         |\n| ├─IndexRangeScan_5(Build)     | 0.00    | cop[tikv] | table:t2, index:idx(a, cast(json_extract(`j`, _utf8'$.path') as signed array), b) | range:[1 1 2,1 1 2], keep order:false, stats:pseudo |\n| └─TableRowIDScan_6(Probe)     | 0.00    | cop[tikv] | table:t2                                                                          | keep order:false, stats:pseudo                      |\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------------+-----------------------------------------------------+\n\n> EXPLAIN SELECT /*+ use_index_merge(t2, idx) */ * FROM t2 WHERE a=1 AND JSON_CONTAINS((j->'$.path'), '[1, 2, 3]');\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------------+-------------------------------------------------+\n| id                            | estRows | task      | access object                                                                     | operator info                                   |\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------------+-------------------------------------------------+\n| IndexMerge_9                  | 0.00    | root      |                                                                                   | type: intersection                              |\n| ├─IndexRangeScan_5(Build)     | 0.10    | cop[tikv] | table:t2, index:idx(a, cast(json_extract(`j`, _utf8'$.path') as signed array), b) | range:[1 1,1 1], keep order:false, stats:pseudo |\n```\n\n----------------------------------------\n\nTITLE: Example record from mysql.tidb_runaway_queries table\nDESCRIPTION: This is an example record from the `mysql.tidb_runaway_queries` table. It includes information about the runaway query, such as the resource group, start time, number of repeats, match type, action taken, sample SQL, SQL digest, plan digest, and the TiDB server where the query was executed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\n\"*************************** 1. row ***************************\\n    resource_group_name: default\\n         start_time: 2024-09-09 17:43:42\\n            repeats: 2\\n         match_type: watch\\n             action: kill\\n         sample_sql: select sleep(2) from t\\n         sql_digest: 4adbc838b86c573265d4b39a3979d0a362b5f0336c91c26930c83ab187701a55\\n        plan_digest: 5d094f78efbce44b2923733b74e1d09233cb446318293492901c5e5d92e27dbc\\n        tidb_server: 127.0.0.1:4000\"\n```\n\n----------------------------------------\n\nTITLE: Setting Global tidb_gc_life_time for Data Export\nDESCRIPTION: This SQL command sets the global garbage collection life time for TiDB to ensure historical data is retained during the changefeed setup process. It is crucial to extend this parameter to prevent data loss while exporting existing data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/changefeed-sink-to-tidb-cloud.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_life_time = '720h';\n```\n\n----------------------------------------\n\nTITLE: BIT Type Declaration in SQL\nDESCRIPTION: Syntax for declaring BIT data type that stores M-bit values ranging from 1 to 64 bits\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-numeric.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nBIT[(M)]\n```\n\n----------------------------------------\n\nTITLE: Navigating to ProxySQL Rules Directory\nDESCRIPTION: Command to change directory to the ProxySQL rules example location.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\ncd tidb-proxysql-integration/example/proxy-rule-admin-interface\n```\n\n----------------------------------------\n\nTITLE: Generating AES-256 Secret Key using SHA256 in Bash\nDESCRIPTION: This command generates a 64-character hexadecimal AES-256 secret key by calculating the SHA256 checksum of random data from /dev/urandom.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-customized-secret-key.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhead -n 256 /dev/urandom | sha256sum\n```\n\n----------------------------------------\n\nTITLE: Enabling Prevotes in Raft\nDESCRIPTION: This snippet highlights the configuration option to enable or disable prevoting in Raft, aimed at reducing system jitter after a network partition.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n+ Enables or disables `prevote`. Enabling this feature helps reduce jitter on the system after recovery from network partition.\n+ Default value: `true`\n```\n\n----------------------------------------\n\nTITLE: Root Certificate Paths for Unix-like Systems\nDESCRIPTION: Default storage paths for root certificates across different Unix-like operating systems including MacOS, Debian/Ubuntu, RedHat/Fedora, Alpine, and OpenSUSE.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/secure-connections-to-serverless-clusters.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n/etc/ssl/cert.pem\n/etc/ssl/certs/ca-certificates.crt\n/etc/pki/tls/certs/ca-bundle.crt\n/etc/ssl/cert.pem\n/etc/ssl/ca-bundle.pem\n```\n\n----------------------------------------\n\nTITLE: Using the TiUP DM Template Command in Shell\nDESCRIPTION: Basic syntax for the 'tiup dm template' command which outputs a built-in topology template for DM cluster deployment. The default output includes 3 DM-master instances, 3 DM-worker instances, and monitoring components (Prometheus, Grafana, and Alertmanager).\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-template.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm template [flags]\n```\n\n----------------------------------------\n\nTITLE: Setting GOMEMLIMIT Environment Variable in Go\nDESCRIPTION: Example showing the configuration of GOMEMLIMIT to 40000 MiB to prevent OOM issues in TiDB. This setting helps maintain stable memory usage around 40.8 GiB when tested with a system having approximately 48 GiB of memory.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-memory-usage.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nGOMEMLIMIT=40000MiB\n```\n\n----------------------------------------\n\nTITLE: Configuring Retry Count for PD Connection Initialization\nDESCRIPTION: This snippet explains how to set the maximum number of retries when initializing a PD connection in TiKV, including options for disabling and removing limits on retries.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n+ The maximum number of times to retry to initialize PD connection\n+ To disable the retry, set its value to `0`. To release the limit on the number of retries, set the value to `-1`.\n+ Default value: `-1`\n```\n\n----------------------------------------\n\nTITLE: Log Backup Status Output Example in Shell\nDESCRIPTION: Example output of the log backup status command, showing details like task status, start time, storage location, and checkpoint information.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\n● Total 1 Tasks.\n> #1 <\n              name: pitr\n            status: ● NORMAL\n             start: 2022-07-14 20:08:03.268 +0800\n               end: 2090-11-18 22:07:45.624 +0800\n           storage: s3://backup-101/logbackup\n       speed(est.): 0.82 ops/s\ncheckpoint[global]: 2022-07-25 22:52:15.518 +0800; gap=2m52s\n```\n\n----------------------------------------\n\nTITLE: Querying Session Status Variables in TiDB\nDESCRIPTION: Command to retrieve status variables for the current session\nSOURCE: https://github.com/pingcap/docs/blob/master/status-variables.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW SESSION STATUS;\n```\n\n----------------------------------------\n\nTITLE: TiKV RocksDB Pipelined Write Configuration Parameter (Modified)\nDESCRIPTION: TiKV parameter that controls whether to use the pipelined write mechanism in RocksDB. The default value has been changed from true to false to use the new Pipelined Commit mechanism instead of Pipelined Write.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\nrocksdb.enable-pipelined-write\n```\n\n----------------------------------------\n\nTITLE: Running the TiDB Vector Search with peewee Demo\nDESCRIPTION: Command to run the peewee quickstart example script that demonstrates vector search capabilities in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-peewee.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython peewee-quickstart.py\n```\n\n----------------------------------------\n\nTITLE: Setting Data Retention Period\nDESCRIPTION: SQL command to configure the data retention period to 30 days.\nSOURCE: https://github.com/pingcap/docs/blob/master/workload-repository.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_workload_repository_retention_days = 30;\n```\n\n----------------------------------------\n\nTITLE: Check DM Migration Task Configuration\nDESCRIPTION: This shell command uses `tiup dmctl` to check the DM migration task configuration file (task.yaml) for potential errors before starting the task. This command helps ensure that the configuration meets the requirements of DM.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-to-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup dmctl --master-addr ${advertise-addr} check-task task.yaml\"\n```\n\n----------------------------------------\n\nTITLE: Basic TiDB Cloud Authentication Command\nDESCRIPTION: The basic command syntax for authenticating with TiDB Cloud using the CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-auth-login.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud auth login [flags]\n```\n\n----------------------------------------\n\nTITLE: Upgrading TiProxy with TiUP Shell Command\nDESCRIPTION: This shell command upgrades the TiProxy component of a TiDB cluster using TiUP, explicitly specifying the version to upgrade. Requires the cluster name, desired version, and ensures the TiProxy version is maintained across upgrades.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-overview.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster upgrade <cluster-name> <version> --tiproxy-version <tiproxy-version>\n```\n\n----------------------------------------\n\nTITLE: Configuring Sink URI connection\nDESCRIPTION: This snippet illustrates the general format for setting up a sink URI, which is used to specify the connection details for a TiCDC target system. It includes placeholders for scheme, host, port, path, and query parameters. This format is essential for constructing valid URIs to connect to different endpoints.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n[scheme]://[host]:[port][/path]?[query_parameters]\n```\n\n----------------------------------------\n\nTITLE: VARIABLES_INFO Table Output Structure\nDESCRIPTION: Displays the complete table structure with field definitions including data types, null constraints, keys, and default values.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-variables-info.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+-----------------+---------------------+------+------+---------+-------+\n| Field           | Type                | Null | Key  | Default | Extra |\n+-----------------+---------------------+------+------+---------+-------+\n| VARIABLE_NAME   | varchar(64)         | NO   |      | NULL    |       |\n| VARIABLE_SCOPE  | varchar(64)         | NO   |      | NULL    |       |\n| DEFAULT_VALUE   | varchar(64)         | NO   |      | NULL    |       |\n| CURRENT_VALUE   | varchar(64)         | NO   |      | NULL    |       |\n| MIN_VALUE       | bigint(64)          | YES  |      | NULL    |       |\n| MAX_VALUE       | bigint(64) unsigned | YES  |      | NULL    |       |\n| POSSIBLE_VALUES | varchar(256)        | YES  |      | NULL    |       |\n| IS_NOOP         | varchar(64)         | NO   |      | NULL    |       |\n+-----------------+---------------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Analyzing Query Performance with EXPLAIN ANALYZE in TiDB MPP Mode\nDESCRIPTION: Example of using EXPLAIN ANALYZE to examine the execution plan and runtime information for a GROUP BY COUNT query. Shows detailed operator statistics including estimated/actual rows, execution time, and thread utilization across MPP tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-mpp.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT COUNT(*) FROM t1 GROUP BY id;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------------+---------+---------+-------------------+---------------+---------------------------------------------------------------------------------------------------+----------------------------------------------------------------+--------+------+\n| id                                 | estRows | actRows | task              | access object | execution info                                                                                    | operator info                                                  | memory | disk |\n+------------------------------------+---------+---------+-------------------+---------------+---------------------------------------------------------------------------------------------------+----------------------------------------------------------------+--------+------+\n| TableReader_31                     | 4.00    | 2       | root              |               | time:44.5ms, loops:2, cop_task: {num: 1, max: 0s, proc_keys: 0, copr_cache_hit_ratio: 0.00}       | data:ExchangeSender_30                                         | N/A    | N/A  |\n| └─ExchangeSender_30                | 4.00    | 2       | batchCop[tiflash] |               | tiflash_task:{time:16.5ms, loops:1, threads:1}                                                    | ExchangeType: PassThrough, tasks: [2, 3, 4]                    | N/A    | N/A  |\n|   └─Projection_26                  | 4.00    | 2       | batchCop[tiflash] |               | tiflash_task:{time:16.5ms, loops:1, threads:1}                                                    | Column#4                                                       | N/A    | N/A  |\n|     └─HashAgg_27                   | 4.00    | 2       | batchCop[tiflash] |               | tiflash_task:{time:16.5ms, loops:1, threads:1}                                                    | group by:test.t1.id, funcs:sum(Column#7)->Column#4             | N/A    | N/A  |\n|       └─ExchangeReceiver_29        | 4.00    | 2       | batchCop[tiflash] |               | tiflash_task:{time:14.5ms, loops:1, threads:20}                                                   |                                                                | N/A    | N/A  |\n|         └─ExchangeSender_28        | 4.00    | 0       | batchCop[tiflash] |               | tiflash_task:{time:9.49ms, loops:0, threads:0}                                                    | ExchangeType: HashPartition, Hash Cols: test.t1.id, tasks: [1] | N/A    | N/A  |\n|           └─HashAgg_9              | 4.00    | 0       | batchCop[tiflash] |               | tiflash_task:{time:9.49ms, loops:0, threads:0}                                                    | group by:test.t1.id, funcs:count(1)->Column#7                  | N/A    | N/A  |\n|             └─TableFullScan_25     | 6.00    | 0       | batchCop[tiflash] | table:t1      | tiflash_task:{time:9.49ms, loops:0, threads:0}, tiflash_scan:{dtfile:{total_scanned_packs:1,...}} | keep order:false                                               | N/A    | N/A  |\n+------------------------------------+---------+---------+-------------------+---------------+---------------------------------------------------------------------------------------------------+----------------------------------------------------------------+--------+------+\n```\n\n----------------------------------------\n\nTITLE: Configuring Titan Engine Parameters in TiKV\nDESCRIPTION: These configuration parameters allow dynamic modification of Titan engine settings to improve performance and flexibility, including blob size thresholds, compression, and discard ratios.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\nmin-blob-size\n```\n\nLANGUAGE: markdown\nCODE:\n```\nblob-file-compression\n```\n\nLANGUAGE: markdown\nCODE:\n```\ndiscardable-ratio\n```\n\n----------------------------------------\n\nTITLE: Storing Vectors with Different Dimensions in SQL\nDESCRIPTION: Demonstrates how to create a table that can store vectors of different dimensions using the VECTOR type without specifying a dimension.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-data-types.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE vector_table (\n    id INT PRIMARY KEY,\n    embedding VECTOR\n);\n\nINSERT INTO vector_table VALUES (1, '[0.3, 0.5, -0.1]'); -- 3 dimensions vector, OK\nINSERT INTO vector_table VALUES (2, '[0.3, 0.5]');       -- 2 dimensions vector, OK\n```\n\n----------------------------------------\n\nTITLE: Running Transaction Example in Golang\nDESCRIPTION: Shell command to build and run the Golang transaction example with Alice buying 4 books and Bob buying 7 books from a limited inventory of 10 books.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ngo build -o bin/txn\n./bin/txn -a 4 -b 7\n```\n\n----------------------------------------\n\nTITLE: Populating the Partitioned Table with Sample Data\nDESCRIPTION: Series of INSERT statements to populate the partitioned table with sample data. The first INSERT adds 15 rows with dates spanning from 2016 to 2020, while subsequent INSERT statements add thousands more rows using JOIN operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-partitions.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t1 (d, pad1, pad2, pad3) VALUES \n ('2016-01-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2016-06-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2016-09-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2017-01-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2017-06-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2017-09-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2018-01-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2018-06-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2018-09-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2019-01-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2019-06-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2019-09-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2020-01-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2020-06-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024)),\n ('2020-09-01', RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024));\n\nINSERT INTO t1 SELECT NULL, a.d, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, a.d, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, a.d, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, a.d, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\n\nSELECT SLEEP(1);\nANALYZE TABLE t1;\n```\n\n----------------------------------------\n\nTITLE: Configuring Analyze Behavior in TiDB\nDESCRIPTION: Specifies the execution of ANALYZE TABLE for data optimization after completing the checksum, offering flexibility to enforce or skip this operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_23\n\nLANGUAGE: markdown\nCODE:\n```\nValue options: \"required\", \"optional\", \"off\"\n```\n\n----------------------------------------\n\nTITLE: Cloning TiDB-ProxySQL Integration Repository\nDESCRIPTION: Command to clone the TiDB and ProxySQL integration example code repository from GitHub.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/pingcap-inc/tidb-proxysql-integration.git\n```\n\n----------------------------------------\n\nTITLE: Sample Metadata JSON Structure\nDESCRIPTION: This JSON snippet describes the structure for saving metadata in TiCDC, including the key checkpoint timestamp for transaction tracking.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"checkpoint-ts\":433305438660591626\n}\n```\n\n----------------------------------------\n\nTITLE: Fixing CASE WHEN Behavior in TiDB SQL\nDESCRIPTION: Addresses incorrect behavior of CASE WHEN (not_int) in SQL statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_14\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT CASE WHEN non_integer_column THEN result1 ELSE result2 END FROM table\n```\n\n----------------------------------------\n\nTITLE: Reading the Result of Binary Literal Assignments\nDESCRIPTION: Shows the result of querying the different methods of binary literal assignments, demonstrating how TiDB handles each type of conversion.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @v1, @v2, @v3;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Hot Index Region Distribution in SQL\nDESCRIPTION: This SQL query counts hot index regions grouped by index_name and store_id for a specific table and time range. It helps analyze the distribution of hot index regions.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-hot-regions-history.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT count(region_id) cnt, index_name, store_id FROM INFORMATION_SCHEMA.TIDB_HOT_REGIONS_HISTORY WHERE update_time >'2021-08-18 21:40:00' and update_time <'2021-09-19 00:00:00' and table_name = 'table_name' group by index_name, store_id order by index_name,cnt desc;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Log Level in TiUP Configuration\nDESCRIPTION: YAML configuration for setting TiDB log level to 'error' in TiUP to reduce log output and improve performance during benchmarking.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  tidb:\n    log.level: \"error\"\n```\n\n----------------------------------------\n\nTITLE: Console Audit Log Field Schema\nDESCRIPTION: Defines the structure and attributes of TiDB Cloud console audit log entries, capturing comprehensive details about user operations, including event type, operator information, and result status\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-console-auditing.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"string\",\n  \"ends_at\": \"timestamp\",\n  \"operator_type\": \"enum\",\n  \"operator_id\": \"uint64\",\n  \"operator_name\": \"string\",\n  \"operator_ip\": \"string\",\n  \"operator_login_method\": \"enum\",\n  \"org_id\": \"uint64\",\n  \"org_name\": \"string\",\n  \"project_id\": \"uint64\",\n  \"project_name\": \"string\",\n  \"cluster_id\": \"uint64\",\n  \"cluster_name\": \"string\",\n  \"trace_id\": \"string\",\n  \"result\": \"enum\",\n  \"details\": \"json\"\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying specific store information in TiDB PD\nDESCRIPTION: This command displays detailed information about a specific store in the TiDB cluster, identified by its store ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_48\n\nLANGUAGE: bash\nCODE:\n```\nstore 1\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB as root user\nDESCRIPTION: Shell command to connect to TiDB as the root user using the MySQL client.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-role.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 127.0.0.1 -P 4000 -u root\n```\n\n----------------------------------------\n\nTITLE: Example tiflash_wait Output in TiDB Query Plan\nDESCRIPTION: Shows the structure of the tiflash_wait information that appears when a query involves MPP tasks. This output includes three timing metrics: minTSO_wait, pipeline_breaker_wait, and pipeline_queue_wait, each measuring different aspects of execution delays.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_14\n\nLANGUAGE: json\nCODE:\n```\ntiflash_wait: {minTSO_wait: 425ms, pipeline_breaker_wait: 133ms, pipeline_queue_wait: 512ms}\n```\n\n----------------------------------------\n\nTITLE: Configuring Statistics Collection Version in TiDB SQL\nDESCRIPTION: Controls how TiDB collects statistics. This is a newly added experimental system variable in TiDB 5.1 with a default value of 2.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.0.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_analyze_version = <value>;\n```\n\n----------------------------------------\n\nTITLE: MySQL Compatibility Example for UPDATE Statement\nDESCRIPTION: An example illustrating the difference in behavior between TiDB and MySQL when evaluating expressions in UPDATE statements. TiDB uses the original value of a column for all evaluations, while MySQL updates columns sequentially.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-update.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a int, b int);\nINSERT INTO t VALUES (1,2);\nUPDATE t SET a = a+1,b=a;\n```\n\n----------------------------------------\n\nTITLE: Configuring Incremental Data Replication in YAML\nDESCRIPTION: This YAML snippet shows the configuration for optimizing incremental data replication in DM. It includes options for worker count and batch size for DML replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-tune-configuration.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nsyncers:\n  worker-count: 16\n  batch: 100\n```\n\n----------------------------------------\n\nTITLE: Remove First Line from SQL File (Sed Command)\nDESCRIPTION: These `sed` commands are used to remove the first line from the `gatherGlobalStats.sql` file. This is typically done to remove the header row that the `mysql` command might add when exporting data. The command varies slightly between macOS and Linux.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_83\n\nLANGUAGE: shell\nCODE:\n```\nsed -i \"\" '1d' gatherGlobalStats.sql --- mac\nsed -i '1d' gatherGlobalStats.sql --- linux\n```\n\n----------------------------------------\n\nTITLE: Adding Column to Table\nDESCRIPTION: This SQL statement adds a column named `Level` of type `INT` to the `tbl00` table. It is used as part of demonstrating optimistic DDL changes during data migration with DM.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-shard-merge-optimistic.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER TABLE `tbl00` ADD COLUMN `Level` INT;\n```\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP Cluster Enable Command in Shell\nDESCRIPTION: Command syntax for enabling automatic service startup in a TiUP cluster. Takes a cluster name as a required parameter and supports optional flags for specifying nodes (-N) and roles (-R).\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-enable.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster enable <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Scale In Cluster\nDESCRIPTION: Command to scale in the TiDB cluster by removing specific instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground scale-in --pid 86526\n```\n\n----------------------------------------\n\nTITLE: Decoding Row Keys and Values - Shell\nDESCRIPTION: Shows how to utilize the 'decoder' command in TiDB Control to interpret raw keys and values in a more readable format. Demonstrates decoding both table rows and index values.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-control.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ ./tidb-ctl decoder \"t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c_r\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xfa\"\n```\n\nLANGUAGE: shell\nCODE:\n```\n$ ./tidb-ctl decoder AhZoZWxsbyB3b3JsZAiAEA==\n```\n\n----------------------------------------\n\nTITLE: USER_PRIVILEGES Query Results\nDESCRIPTION: Displays the complete list of global privileges for the root user, showing various permission types and their grantable status.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-user-privileges.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+------------+---------------+-------------------------+--------------+\n| GRANTEE    | TABLE_CATALOG | PRIVILEGE_TYPE          | IS_GRANTABLE |\n+------------+---------------+-------------------------+--------------+\n| 'root'@'%' | def           | SELECT                  | YES          |\n| 'root'@'%' | def           | INSERT                  | YES          |\n| 'root'@'%' | def           | UPDATE                  | YES          |\n| 'root'@'%' | def           | DELETE                  | YES          |\n| 'root'@'%' | def           | CREATE                  | YES          |\n| 'root'@'%' | def           | DROP                    | YES          |\n| 'root'@'%' | def           | PROCESS                 | YES          |\n| 'root'@'%' | def           | REFERENCES              | YES          |\n| 'root'@'%' | def           | ALTER                   | YES          |\n| 'root'@'%' | def           | SHOW DATABASES          | YES          |\n| 'root'@'%' | def           | SUPER                   | YES          |\n| 'root'@'%' | def           | EXECUTE                 | YES          |\n| 'root'@'%' | def           | INDEX                   | YES          |\n| 'root'@'%' | def           | CREATE USER             | YES          |\n| 'root'@'%' | def           | CREATE TABLESPACE       | YES          |\n| 'root'@'%' | def           | TRIGGER                 | YES          |\n| 'root'@'%' | def           | CREATE VIEW             | YES          |\n| 'root'@'%' | def           | SHOW VIEW               | YES          |\n| 'root'@'%' | def           | CREATE ROLE             | YES          |\n| 'root'@'%' | def           | DROP ROLE               | YES          |\n| 'root'@'%' | def           | CREATE TEMPORARY TABLES | YES          |\n| 'root'@'%' | def           | LOCK TABLES             | YES          |\n| 'root'@'%' | def           | CREATE ROUTINE          | YES          |\n| 'root'@'%' | def           | ALTER ROUTINE           | YES          |\n| 'root'@'%' | def           | EVENT                   | YES          |\n| 'root'@'%' | def           | SHUTDOWN                | YES          |\n| 'root'@'%' | def           | RELOAD                  | YES          |\n| 'root'@'%' | def           | FILE                    | YES          |\n| 'root'@'%' | def           | CONFIG                  | YES          |\n| 'root'@'%' | def           | REPLICATION CLIENT      | YES          |\n| 'root'@'%' | def           | REPLICATION SLAVE       | YES          |\n+------------+---------------+-------------------------+--------------+\n```\n\n----------------------------------------\n\nTITLE: Backing Up TiDB Cluster Snapshot with br\nDESCRIPTION: Command for creating a snapshot backup of a TiDB cluster using the br tool. It specifies the PD address, backup timestamp, S3 storage location, and rate limit for the backup operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-guide.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd \"${PD_IP}:2379\" \\\n    --backupts '2022-09-08 13:30:00 +08:00' \\\n    --storage \"s3://backup-101/snapshot-202209081330?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --ratelimit 128 \\\n```\n\n----------------------------------------\n\nTITLE: Displaying Builtin Functions SQL Syntax\nDESCRIPTION: The SHOW BUILTINS statement allows users to retrieve a list of all supported builtin functions in TiDB. This command provides a quick overview of available built-in function capabilities within the database system.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-builtins.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW BUILTINS\n```\n\n----------------------------------------\n\nTITLE: Adjusting PD TSO Update Interval for Better Performance\nDESCRIPTION: This configuration reduces the interval at which the PD server updates physical TSO batches. Decreasing this interval from the default 50ms to 10ms allows more frequent TSO batch allocations, reducing wait times for the next allocation.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices-on-public-cloud.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ntso-update-physical-interval = \"10ms\" # default: 50ms\n```\n\n----------------------------------------\n\nTITLE: Explain Query with Invisible Index\nDESCRIPTION: Example showing query execution plan where optimizer cannot use the invisible index.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-index.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT c1 FROM t1 ORDER BY c1;\n```\n\n----------------------------------------\n\nTITLE: JDBC Connection URL Parameter for Streaming\nDESCRIPTION: Parameter to automatically close resultset when using streaming results, preventing the 'No statements may be issued' error when making subsequent queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nclobberStreamingResults=true\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in TiDB SQL\nDESCRIPTION: Creates a simple table 't' with a single integer column 'c'. This is the first step in demonstrating the historical data access feature.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-read-staleness.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\ncreate table t (c int);\n```\n\n----------------------------------------\n\nTITLE: Checking TiCDC Changefeed Status\nDESCRIPTION: Verify the status of the TiCDC replication task and confirm continuous advancement of TSO\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:${cluster_version} cdc changefeed list --server http://${cdc_host}:${cdc_port}\n```\n\n----------------------------------------\n\nTITLE: Adding a Default Partition to a List Partitioned Table in SQL\nDESCRIPTION: Example of adding a default partition named 'pDef' to an existing List partitioned table. This feature is available from TiDB v7.3.0 and allows rows that don't match any defined partition to be placed in the default partition.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t ADD PARTITION (PARTITION pDef DEFAULT);\n```\n\n----------------------------------------\n\nTITLE: Example JSON Output for Schema - JSON\nDESCRIPTION: Provides a sample JSON output returned from executing the 'schema in' command in TiDB Control. The output shows detailed schema information for the requested tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-control.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\"id\": 13, \"name\": { \"O\": \"columns_priv\", \"L\": \"columns_priv\" }, \"update_timestamp\": 399494726837600268, \"ShardRowIDBits\": 0, \"Partition\": null}\n```\n\n----------------------------------------\n\nTITLE: Adding Hibernate Maven Dependencies\nDESCRIPTION: Maven configuration for adding Hibernate ORM and MySQL connector dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-choose-driver-or-orm.md#2025-04-18_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>org.hibernate.orm</groupId>\n    <artifactId>hibernate-core</artifactId>\n    <version>6.2.3.Final</version>\n</dependency>\n\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>8.0.33</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Setting MySQL Client PATH on macOS\nDESCRIPTION: Command to add MySQL client to system PATH in macOS.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-build-cluster-in-cloud.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\necho 'export PATH=\"/opt/homebrew/opt/mysql-client/bin:$PATH\"' >> ~/.zshrc\n```\n\n----------------------------------------\n\nTITLE: Creating a Range-Partitioned Table in TiDB\nDESCRIPTION: This SQL statement creates a range-partitioned table in TiDB. It's used to demonstrate the difference in SELECT result ordering between TiDB and MySQL for partitioned tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_68\n\nLANGUAGE: SQL\nCODE:\n```\ncreate table t (id int, val int) partition by range (id) (\n    partition p0 values less than (3),\n    partition p1 values less than (7),\n    partition p2 values less than (11));\n```\n\n----------------------------------------\n\nTITLE: Splitting Index Regions in a Partitioned Table in SQL\nDESCRIPTION: This SQL snippet splits the index 'idx' of the partitioned table 't' in the range [1000,10000] into two regions, which can help optimize query performance on the index.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT PARTITION TABLE t INDEX idx BETWEEN (1000) AND (10000) REGIONS 2;\n```\n\n----------------------------------------\n\nTITLE: Committing a Read-Only Transaction in SQL\nDESCRIPTION: SQL command to commit the read-only transaction after reading historical data, returning to the default behavior of reading current data.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\ncommit;\n```\n\n----------------------------------------\n\nTITLE: TiDB Cloud Connection Command for MacOS\nDESCRIPTION: Example command to connect to a TiDB Cloud Serverless cluster using MySQL CLI with SSL verification.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-sql.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmysql -u '<prefix>.root' -h '<host>' -P 4000 -D 'test' --ssl-mode=VERIFY_IDENTITY --ssl-ca=/etc/ssl/cert.pem -p'<password>'\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB Server Metrics Using Curl\nDESCRIPTION: Command to query SQL statement QPS metrics from a TiDB server's HTTP interface. This uses curl to access the metrics endpoint and filters for statement execution statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/grafana-monitor-best-practices.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://__tidb_ip__:10080/metrics |grep tidb_executor_statement_total\n```\n\n----------------------------------------\n\nTITLE: Checking Index Consistency with Range in TiDB SQL\nDESCRIPTION: This SQL snippet illustrates how to use the ADMIN CHECK INDEX command with specified data ranges to check the consistency of column data and index data for a specific index in a table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-check-table-index.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN CHECK INDEX tbl_name idx_name (lower_val, upper_val) [, (lower_val, upper_val)] ...;\n```\n\n----------------------------------------\n\nTITLE: Editing TiUP Cluster Configuration\nDESCRIPTION: This command retrieves the existing cluster configuration. Understanding the existing configuration is necessary because the scale-out configuration inherits the global and server configurations of the original cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster edit-config <cluster-name>\"\n```\n\n----------------------------------------\n\nTITLE: Inserting and Querying Fractional Second Data in SQL\nDESCRIPTION: This example shows how to create a table with fractional second precision, insert data with more precision than defined, and query the results. It demonstrates automatic rounding of fractional seconds.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE fractest( c1 TIME(2), c2 DATETIME(2), c3 TIMESTAMP(2) );\n\nINSERT INTO fractest VALUES\n('17:51:04.777', '2014-09-08 17:51:04.777',   '2014-09-08 17:51:04.777');\n\nSELECT * FROM fractest;\n```\n\n----------------------------------------\n\nTITLE: Viewing pause-task Help Command in TiDB Data Migration\nDESCRIPTION: Shows the help information for the pause-task command including usage syntax and available flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-pause-task.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhelp pause-task\n```\n\n----------------------------------------\n\nTITLE: Modifying TiKV Configuration - Set Shared Block Cache Size\nDESCRIPTION: This command sets the size of the shared block cache in TiKV to 10GB. The `-n` option specifies the configuration item, while the `-v` option sets its value.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --host ip:port modify-tikv-config -n storage.block-cache.capacity -v 10GB\n```\n\n----------------------------------------\n\nTITLE: Modifying NIC RX Buffer Size\nDESCRIPTION: Command to increase the RX buffer size of a network interface to avoid packet loss using ethtool.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nethtool -G ${NIC_DEV_NAME}\n```\n\n----------------------------------------\n\nTITLE: Viewing Topology Configuration File\nDESCRIPTION: Opens the topology.yaml file for editing with vi. This command allows reviewing and modifying the cluster configuration before deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nvi topology.yaml\n```\n\n----------------------------------------\n\nTITLE: Array Property Validation\nDESCRIPTION: SQL queries validating array properties and their types\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-validate.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SCHEMA_VALID('{\"properties\": {\"fruits\": {\"type\": \"array\"}}}',@j)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SCHEMA_VALID('{\"properties\": {\"fruits\": {\"type\": \"string\"}}}',@j)\n```\n\n----------------------------------------\n\nTITLE: EXPLAIN Output Showing Composite Index Usage in TiDB\nDESCRIPTION: This snippet shows the execution plans with a composite index. The first query uses both parts of the index (bike_number and duration) to satisfy both view and query conditions, while the second query only uses the first part (bike_number) of the composite index.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-views.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (2 min 31.20 sec)\n\n+--------------------------------+----------+-----------+-------------------------------------------------------+-------------------------------------------------------+\n| id                             | estRows  | task      | access object                                         | operator info                                         |\n+--------------------------------+----------+-----------+-------------------------------------------------------+-------------------------------------------------------+\n| IndexLookUp_13                 | 63725.48 | root      |                                                       |                                                       |\n| ├─IndexRangeScan_11(Build)     | 63725.48 | cop[tikv] | table:trips, index:bike_number(bike_number, duration) | range:(\"W00950\" 3600,\"W00950\" +inf], keep order:false |\n| └─TableRowIDScan_12(Probe)     | 63725.48 | cop[tikv] | table:trips                                           | keep order:false                                      |\n+--------------------------------+----------+-----------+-------------------------------------------------------+-------------------------------------------------------+\n3 rows in set (0.00 sec)\n\n+-------------------------------+----------+-----------+-------------------------------------------------------+---------------------------------------------+\n| id                            | estRows  | task      | access object                                         | operator info                               |\n+-------------------------------+----------+-----------+-------------------------------------------------------+---------------------------------------------+\n| IndexLookUp_10                | 19117.64 | root      |                                                       |                                             |\n| ├─IndexRangeScan_8(Build)     | 19117.64 | cop[tikv] | table:trips, index:bike_number(bike_number, duration) | range:[\"W00950\",\"W00950\"], keep order:false |\n| └─TableRowIDScan_9(Probe)     | 19117.64 | cop[tikv] | table:trips                                           | keep order:false                            |\n+-------------------------------+----------+-----------+-------------------------------------------------------+---------------------------------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying Foreign Key Information Using INFORMATION_SCHEMA\nDESCRIPTION: Retrieves foreign key information from the INFORMATION_SCHEMA.KEY_COLUMN_USAGE system table, which includes details like table schema, table name, column name, and constraint name for each foreign key defined. No additional prerequisites are needed.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, CONSTRAINT_NAME FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE WHERE REFERENCED_TABLE_SCHEMA IS NOT NULL;\n+--------------+---------------+------------------+-----------------+\n| TABLE_SCHEMA | TABLE_NAME    | COLUMN_NAME      | CONSTRAINT_NAME |\n+--------------+---------------+------------------+-----------------+\n| test         | child         | pid              | fk_1            |\n| test         | product_order | product_category | fk_1            |\n| test         | product_order | product_id       | fk_1            |\n| test         | product_order | customer_id      | fk_2            |\n+--------------+---------------+------------------+-----------------+\n\n```\n\n----------------------------------------\n\nTITLE: Example Amazon S3 URI for IMPORT INTO Statement\nDESCRIPTION: Shows how to format an S3 URI for the IMPORT INTO SQL statement, specifying a specific CSV file with access credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/external-storage-uri.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ns3://external/test.csv?access-key=${access-key}&secret-access-key=${secret-access-key}\n```\n\n----------------------------------------\n\nTITLE: TiDB Dashboard Slow Query URL Access\nDESCRIPTION: Example URL pattern for accessing the slow query page directly through a browser. Replace the IP and port with actual PD address.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-slow-query.md#2025-04-18_snippet_0\n\nLANGUAGE: url\nCODE:\n```\nhttp://127.0.0.1:2379/dashboard/#/slow_query\n```\n\n----------------------------------------\n\nTITLE: Generating Client Private Key\nDESCRIPTION: Command to generate a 2048-bit RSA private key for client certificates.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nopenssl genrsa -out client.key 2048\n```\n\n----------------------------------------\n\nTITLE: Key Format Conversion Examples\nDESCRIPTION: Commands demonstrating conversion between hex and escaped key formats.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --to-escaped 0xaaff\ntikv-ctl --to-hex \"\\252\\377\"\n```\n\n----------------------------------------\n\nTITLE: TiUP Cluster Import Command Usage\nDESCRIPTION: Shows the syntax and flags for the 'import' command, which imports an existing TiDB cluster deployed with TiDB Ansible into TiUP management.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster import --help\n```\n\n----------------------------------------\n\nTITLE: Deleting and Updating Data in SQL\nDESCRIPTION: This SQL code demonstrates deleting a row, updating an existing row and updating with both the id and val then committing the changes to the `test.t1` table.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n\"BEGIN;\\nDELETE FROM test.t1 WHERE id = 1;\\nUPDATE test.t1 SET val = 'dd' WHERE id = 3;\\nUPDATE test.t1 SET id = 4, val = 'ee' WHERE id = 2;\\nCOMMIT;\"\n```\n\n----------------------------------------\n\nTITLE: Monitoring TiFlash Schema Apply Duration using PromQL\nDESCRIPTION: This PromQL query alerts when the 99th percentile of schema apply duration exceeds 20 seconds in the last minute. It helps identify slow schema changes in TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-alert-rules.md#2025-04-18_snippet_1\n\nLANGUAGE: promql\nCODE:\n```\nhistogram_quantile(0.99, sum(rate(tiflash_schema_apply_duration_seconds_bucket[1m])) BY (le, instance)) > 20\n```\n\n----------------------------------------\n\nTITLE: Restarting Specific Cluster Nodes\nDESCRIPTION: Command to restart specific nodes in a TiUP cluster after interrupted upgrade\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-troubleshooting-guide.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster restart -N <node1> -N <node2>\n```\n\n----------------------------------------\n\nTITLE: Showing Column Statistics Usage in SQL\nDESCRIPTION: Retrieves the usage statistics of columns in table 't' from the mysql.column_stats_usage table, filtering for columns that have been used (last_used_at IS NOT NULL).\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\n-- Specify `last_used_at IS NOT NULL` to show the `PREDICATE COLUMNS` collected by TiDB.\nSHOW COLUMN_STATS_USAGE\nWHERE db_name = 'test' AND table_name = 't' AND last_used_at IS NOT NULL;\n```\n\n----------------------------------------\n\nTITLE: SQL Statement: REORGANIZE PARTITION\nDESCRIPTION: Enables merging adjacent partitions or splitting a single partition, providing enhanced flexibility for partitioned table management in TiDB\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.0.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nREORGANIZE PARTITION\n```\n\n----------------------------------------\n\nTITLE: Querying Slow Queries with Pseudo Stats in SQL\nDESCRIPTION: SQL query to find slow queries that used pseudo statistics during execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nselect query, query_time, stats\nfrom information_schema.slow_query\nwhere is_internal = false\n  and stats like '%pseudo%';\n```\n\n----------------------------------------\n\nTITLE: Creating Bookshop Database Schema in SQL\nDESCRIPTION: This SQL script creates the database and tables for a bookshop application. It defines the structure for books, authors, book-author relationships, user ratings, users, and orders. The script includes primary keys, foreign key relationships, and some default values.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-bookshop-schema-design.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE IF NOT EXISTS `bookshop`;\n\nDROP TABLE IF EXISTS `bookshop`.`books`;\nCREATE TABLE `bookshop`.`books` (\n  `id` bigint AUTO_RANDOM NOT NULL,\n  `title` varchar(100) NOT NULL,\n  `type` enum('Magazine', 'Novel', 'Life', 'Arts', 'Comics', 'Education & Reference', 'Humanities & Social Sciences', 'Science & Technology', 'Kids', 'Sports') NOT NULL,\n  `published_at` datetime NOT NULL,\n  `stock` int DEFAULT '0',\n  `price` decimal(15,2) DEFAULT '0.0',\n  PRIMARY KEY (`id`) CLUSTERED\n) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\n\nDROP TABLE IF EXISTS `bookshop`.`authors`;\nCREATE TABLE `bookshop`.`authors` (\n  `id` bigint AUTO_RANDOM NOT NULL,\n  `name` varchar(100) NOT NULL,\n  `gender` tinyint DEFAULT NULL,\n  `birth_year` smallint DEFAULT NULL,\n  `death_year` smallint DEFAULT NULL,\n  PRIMARY KEY (`id`) CLUSTERED\n) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\n\nDROP TABLE IF EXISTS `bookshop`.`book_authors`;\nCREATE TABLE `bookshop`.`book_authors` (\n  `book_id` bigint NOT NULL,\n  `author_id` bigint NOT NULL,\n  PRIMARY KEY (`book_id`,`author_id`) CLUSTERED\n) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\n\nDROP TABLE IF EXISTS `bookshop`.`ratings`;\nCREATE TABLE `bookshop`.`ratings` (\n  `book_id` bigint NOT NULL,\n  `user_id` bigint NOT NULL,\n  `score` tinyint NOT NULL,\n  `rated_at` datetime NOT NULL DEFAULT NOW() ON UPDATE NOW(),\n  PRIMARY KEY (`book_id`,`user_id`) CLUSTERED,\n  UNIQUE KEY `uniq_book_user_idx` (`book_id`,`user_id`)\n) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\nALTER TABLE `bookshop`.`ratings` SET TIFLASH REPLICA 1;\n\nDROP TABLE IF EXISTS `bookshop`.`users`;\nCREATE TABLE `bookshop`.`users` (\n  `id` bigint AUTO_RANDOM NOT NULL,\n  `balance` decimal(15,2) DEFAULT '0.0',\n  `nickname` varchar(100) UNIQUE NOT NULL,\n  PRIMARY KEY (`id`)\n) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\n\nDROP TABLE IF EXISTS `bookshop`.`orders`;\nCREATE TABLE `bookshop`.`orders` (\n  `id` bigint AUTO_RANDOM NOT NULL,\n  `book_id` bigint NOT NULL,\n  `user_id` bigint NOT NULL,\n  `quality` tinyint NOT NULL,\n  `ordered_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  PRIMARY KEY (`id`) CLUSTERED,\n  KEY `orders_book_id_idx` (`book_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\n```\n\n----------------------------------------\n\nTITLE: Fetching Cluster ID from TiDB Log in Bash\nDESCRIPTION: Extracts the cluster ID from TiDB log files using grep command. Requires the proper path to the TiDB log.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-recover.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngrep \"init cluster id\" {{/path/to}}/tidb.log\n```\n\n----------------------------------------\n\nTITLE: Configuring Sysbench for TiDB\nDESCRIPTION: Sample configuration file for sysbench to connect to the TiDB cluster and set test parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nmysql-host=172.16.6.122 # Replace the value with the IP address of your upstream cluster\nmysql-port=4000\nmysql-user=root\nmysql-password=\ndb-driver=mysql         # Set database driver to MySQL\nmysql-db=test           # Set the database as a test database\nreport-interval=10      # Set data collection period to 10s\nthreads=10              # Set the number of worker threads to 10\ntime=0                  # Set the time required for executing the script. O indicates time unlimited\nrate=100                # Set average TPS to 100\n```\n\n----------------------------------------\n\nTITLE: Index Invalidity Example in TiDB SQL Query\nDESCRIPTION: Demonstrates how implicit type conversion causes index invalidity when querying a varchar primary key with a numeric value. The execution plan shows a table full scan instead of using the index due to type casting.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-implicit-type-conversion.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDESC SELECT * FROM `account` WHERE `account_id`=6010000000009801;\n```\n\n----------------------------------------\n\nTITLE: Revoke Privileges using SQL\nDESCRIPTION: Details the use of the SQL `REVOKE` statement to remove specified privileges from a user. The operation requires exact matches of previous `GRANT` commands and may result in errors if no such grants exist. The input consists of SQL commands specifying privileges to be revoked, and the main output is the database change confirmation or an error message if the command fails due to mismatches.\nSOURCE: https://github.com/pingcap/docs/blob/master/privilege-management.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE ALL PRIVILEGES ON `test`.* FROM 'genius'@'localhost';\n```\n\nLANGUAGE: sql\nCODE:\n```\nREVOKE ALL PRIVILEGES ON `te%`.* FROM 'genius'@'%';\n```\n\n----------------------------------------\n\nTITLE: Performing Transactions with TiDB Cloud Serverless Driver\nDESCRIPTION: Example showing how to perform an interactive transaction with the TiDB Cloud Serverless Driver, including commit and rollback functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_2\n\nLANGUAGE: ts\nCODE:\n```\nimport { connect } from '@tidbcloud/serverless'\n\nconst conn = connect({url: 'mysql://[username]:[password]@[host]/[database]'})\nconst tx = await conn.begin()\n\ntry {\n  await tx.execute('insert into test values (1)')\n  await tx.execute('select * from test')\n  await tx.commit()\n} catch (err) {\n  await tx.rollback()\n  throw err\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a List Partitioned Table by Store Region in SQL\nDESCRIPTION: Example of creating an employees table with List partitioning based on store_id. This partitions employee data by geographic region (North, East, West, Central) based on store ID ranges to improve data management efficiency.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    store_id INT\n)\nPARTITION BY LIST (store_id) (\n    PARTITION pNorth VALUES IN (1, 2, 3, 4, 5),\n    PARTITION pEast VALUES IN (6, 7, 8, 9, 10),\n    PARTITION pWest VALUES IN (11, 12, 13, 14, 15),\n    PARTITION pCentral VALUES IN (16, 17, 18, 19, 20)\n);\n```\n\n----------------------------------------\n\nTITLE: Restoring Single Table\nDESCRIPTION: Command to restore a specific table from a backup using BR, specifying both database and table names.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore table \\\n    --pd \"${PD_IP}:2379\" \\\n    --db \"test\" \\\n    --table \"usertable\" \\\n    --ratelimit 128 \\\n    --storage \"s3://${backup_collection_addr}/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --log-file restore_table.log\n```\n\n----------------------------------------\n\nTITLE: Accessing ProxySQL Admin Interface\nDESCRIPTION: This command connects to the ProxySQL Admin interface using the MySQL client.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nmysql -u admin -padmin -h 127.0.0.1 -P6032 --prompt 'ProxySQL Admin> '\n```\n\n----------------------------------------\n\nTITLE: Capturing Traffic with SQL in TiProxy\nDESCRIPTION: This SQL snippet is used to capture traffic for one hour and save it to a specified directory on TiProxy instances. Requires SUPER or TRAFFIC_CAPTURE_ADMIN privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-traffic-replay.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nTRAFFIC CAPTURE TO \"/tmp/traffic\" DURATION=\"1h\"\n```\n\n----------------------------------------\n\nTITLE: Dynamically Configuring Auto-Tune Feature in TiKV\nDESCRIPTION: This command uses tikv-ctl to dynamically enable or disable the auto-tune feature without restarting the cluster by modifying the TiKV configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-auto-tune.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl modify-tikv-config -n backup.enable-auto-tune -v <true|false>\n```\n\n----------------------------------------\n\nTITLE: Displaying Help for DM Config Command\nDESCRIPTION: This snippet shows the help output for the 'config' command in DM, listing available subcommands and usage information.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-export-import-config.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n» help config\nCommands to import/export config\nUsage:\n  dmctl config [command]\nAvailable Commands:\n  export      Export the configurations of sources and tasks.\n  import      Import the configurations of sources and tasks.\nFlags:\n  -h, --help   help for config\nGlobal Flags:\n  -s, --source strings   MySQL Source ID.\nUse \"dmctl config [command] --help\" for more information about a command.\n```\n\n----------------------------------------\n\nTITLE: Creating a TiDB Cloud Serverless Cluster\nDESCRIPTION: This snippet shows the command to create a TiDB Cloud Serverless cluster, prompting the user for required information in the CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless create\n```\n\n----------------------------------------\n\nTITLE: Checking Connection Status with MySQL Client\nDESCRIPTION: Using the STATUS or \\s command in the official MySQL client to view connection status, including the SSL cipher in use.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-clients-and-servers.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nmysql> \\s\n```\n\n----------------------------------------\n\nTITLE: Setting DDL Error Count Limit\nDESCRIPTION: Configures the tidb_ddl_error_count_limit variable to set the number of retries for DDL operations before canceling. This helps prevent endless retries of faulty DDL operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_22\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_ddl_error_count_limit = 512;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with NOT NULL Constraints in TiDB\nDESCRIPTION: This snippet demonstrates creating a 'users' table with NOT NULL constraints applied to the 'id' and 'age' columns, while allowing NULL values in the 'last_login' column.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE users (\n id INT NOT NULL PRIMARY KEY AUTO_INCREMENT,\n age INT NOT NULL,\n last_login TIMESTAMP\n);\n```\n\n----------------------------------------\n\nTITLE: Running the sample application\nDESCRIPTION: npm command to execute the sample code and connect to TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysqljs.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nnpm start\n```\n\n----------------------------------------\n\nTITLE: Pull Docker Image for TiDB PDF Building\nDESCRIPTION: This command pulls the specified Docker image, which contains the necessary tools and dependencies for building TiDB PDF documentation.  This step is a prerequisite for generating the PDF.\nSOURCE: https://github.com/pingcap/docs/blob/master/resources/tidb-pdf-generation-tutorial.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull andelf/doc-build:0.1.9\n```\n\n----------------------------------------\n\nTITLE: Selecting Database in TiDB Cloud\nDESCRIPTION: SQL command to select the bikeshare database for querying the imported sample data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-sample-data.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nuse bikeshare;\n```\n\n----------------------------------------\n\nTITLE: Creating Temporary Directory for Fast Online DDL Operations\nDESCRIPTION: Command to create a dedicated directory for TiDB's Fast Online DDL temporary files and set appropriate permissions. This is recommended when DDL operations on large objects are expected.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nsudo mkdir -p /data/tidb-deploy/tempdir\n```\n\n----------------------------------------\n\nTITLE: Invalid Time Value Handling Example\nDESCRIPTION: Shows how TiDB handles invalid time values based on SQL mode settings, including table creation and value insertion.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nshow create table t1;\nselect @@sql_mode;\ninsert into t1 values ('2090-11-32:22:33:44');\nset @@sql_mode='';\ninsert into t1 values ('2090-11-32:22:33:44');\nselect * from t1;\n```\n\n----------------------------------------\n\nTITLE: Pulling Latest ProxySQL and TiDB Docker Images\nDESCRIPTION: Commands to change directory and pull the latest Docker images for ProxySQL and TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ncd tidb-proxysql-integration && docker compose pull\n```\n\n----------------------------------------\n\nTITLE: Applying TiCDC Redo Log\nDESCRIPTION: Shell command to apply redo logs for ensuring data consistency after disaster recovery.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc redo apply --storage \"s3://redo?access-key=minio&secret-access-key=miniostorage&endpoint=http://172.16.6.123:6060&force-path-style=true\" --tmp-dir /tmp/redo --sink-uri \"mysql://root:@172.16.6.124:4000\"\n```\n\n----------------------------------------\n\nTITLE: Configuring MB4 Value Check via Session Variable\nDESCRIPTION: Setting session-level configuration for MB4 value checking\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/upgrade-faq.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nset @@session.tidb_check_mb4_value_in_utf8 = 1;\n```\n\n----------------------------------------\n\nTITLE: Disabling Titan with Fallback Configuration\nDESCRIPTION: Configuration to disable Titan storage mode by setting blob-run-mode to fallback and adjusting discardable ratio\nSOURCE: https://github.com/pingcap/docs/blob/master/storage-engine/titan-configuration.md#2025-04-18_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[rocksdb.defaultcf.titan]\nblob-run-mode = \"fallback\"\ndiscardable-ratio = 1.0\n```\n\n----------------------------------------\n\nTITLE: Binding IN (?) Migration\nDESCRIPTION: This example shows how bindings containing `IN (?)` are migrated to `IN (...)` after upgrading to v7.4.0 or a later version. This ensures the bindings continue to work as intended after the upgrade.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a binding on v7.3.0\nmysql> CREATE GLOBAL BINDING FOR SELECT * FROM t WHERE a IN (1) USING SELECT /*+ use_index(t, idx_a) */ * FROM t WHERE a IN (1);\nmysql> SHOW GLOBAL BINDINGS;\n+-----------------------------------------------+------------------------------------------------------------------------+------------+---------+-------------------------+-------------------------+---------+--------------------+--------+------------------------------------------------------------------+-------------+\n| Original_sql                                  | Bind_sql                                                               | Default_db | Status  | Create_time             | Update_time             | Charset | Collation          | Source | Sql_digest                                                       | Plan_digest |\n+-----------------------------------------------+------------------------------------------------------------------------+------------+---------+-------------------------+-------------------------+---------+--------------------+--------+------------------------------------------------------------------+-------------+\n| select * from `test` . `t` where `a` in ( ? ) | SELECT /*+ use_index(`t` `idx_a`)*/ * FROM `test`.`t` WHERE `a` IN (1) | test       | enabled | 2024-09-03 15:39:02.695 | 2024-09-03 15:39:02.695 | utf8mb4 | utf8mb4_general_ci | manual | 8b9c4e6ab8fad5ba29b034311dcbfc8a8ce57dde2e2d5d5b65313b90ebcdebf7 |             |\n+-----------------------------------------------+------------------------------------------------------------------------+------------+---------+-------------------------+-------------------------+---------+--------------------+--------+------------------------------------------------------------------+-------------+\n\n-- After the upgrade to v7.4.0 or a later version\nmysql> SHOW GLOBAL BINDINGS;\n+-------------------------------------------------+------------------------------------------------------------------------+------------+---------+-------------------------+-------------------------+---------+--------------------+--------+------------------------------------------------------------------+-------------+\n| Original_sql                                    | Bind_sql                                                               | Default_db | Status  | Create_time             | Update_time             | Charset | Collation          | Source | Sql_digest                                                       | Plan_digest |\n+-------------------------------------------------+------------------------------------------------------------------------+------------+---------+-------------------------+-------------------------+---------+--------------------+--------+------------------------------------------------------------------+-------------+\n| select * from `test` . `t` where `a` in ( ... ) | SELECT /*+ use_index(`t` `idx_a`)*/ * FROM `test`.`t` WHERE `a` IN (1) | test       | enabled | 2024-09-03 15:35:59.861 | 2024-09-03 15:35:59.861 | utf8mb4 | utf8mb4_general_ci | manual | da38bf216db4a53e1a1e01c79ffa42306419442ad7238480bb7ac510723c8bdf |             |\n+-------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Restoring TiDB data with encryption key as command-line option\nDESCRIPTION: This command shows how to use the --azblob.encryption-key option in the tiup br restore command to specify the encryption key when restoring TiDB data from Azure Blob Storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full --pd <pd-address> --storage \"azure://<bucket>/<prefix>\" --azblob.encryption-key <aes256-key>\n```\n\n----------------------------------------\n\nTITLE: Listing Regions in Default Format - Shell\nDESCRIPTION: This example command demonstrates how to list all available regions for TiDB Cloud Serverless using default output format.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-region.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless region\n```\n\n----------------------------------------\n\nTITLE: Checking Current Mode in TiDB Lightning with tidb-lightning-ctl\nDESCRIPTION: Command to check if the TiDB cluster is stuck in import mode, which is not suitable for production. This helps diagnose performance issues after using TiDB Lightning.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/troubleshoot-tidb-lightning.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntidb-lightning-ctl --config tidb-lightning.toml --fetch-mode\n```\n\n----------------------------------------\n\nTITLE: Inserting, Updating, and Committing Data in SQL\nDESCRIPTION: This SQL code block demonstrates a transaction involving inserting new rows, updating an existing row, and then committing the changes to the `test.t1` table.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n\"BEGIN;\\nINSERT INTO test.t1(id, val) VALUES (1, 'aa');\\nINSERT INTO test.t1(id, val) VALUES (2, 'aa');\\nUPDATE test.t1 SET val = 'bb' WHERE id = 2;\\nINSERT INTO test.t1(id, val) VALUES (3, 'cc');\\nCOMMIT;\"\n```\n\n----------------------------------------\n\nTITLE: Querying TiCDC Changefeed State shell\nDESCRIPTION: This shell command queries the state of a TiCDC changefeed to determine if it was stopped manually. The output includes `admin-job-type`, which indicates the task's current state. Replace `--server=http://127.0.0.1:8300` with the actual TiCDC server address.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/troubleshoot-ticdc.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed query --server=http://127.0.0.1:8300 --changefeed-id 28c43ffc-2316-4f4f-a70b-d1a7c59ba79f\n```\n\n----------------------------------------\n\nTITLE: Creating a TiCDC Changefeed Replication Task\nDESCRIPTION: This shell command initializes a changefeed task using the TiCDC CLI, configuring parameters such as the TiCDC server address, the sink URI for the target database, and the changefeed ID. The task continuously replicates data from the source to the specified MySQL-compatible database.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-mysql.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create \\\n    --server=http://10.0.10.25:8300 \\\n    --sink-uri=\"mysql://root:123456@127.0.0.1:3306/\" \\\n    --changefeed-id=\"simple-replication-task\"\n```\n\nLANGUAGE: shell\nCODE:\n```\nCreate changefeed successfully!\nID: simple-replication-task\nInfo: {\"sink-uri\":\"mysql://root:123456@127.0.0.1:3306/\",\"opts\":{},\"create-time\":\"2023-11-28T22:04:08.103600025+08:00\",\"start-ts\":...\n```\n\n----------------------------------------\n\nTITLE: Log Backup File Directory Structure Example\nDESCRIPTION: Example showing the hierarchical organization of backup files including metadata, global checkpoints, and log data files with their naming conventions and timestamps.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-log-architecture.md#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n.\n├── v1\n│   ├── backupmeta\n│   │   ├── ...\n│   │   └── {resolved_ts}-{uuid}.meta\n│   ├── global_checkpoint\n│   │   └── {store_id}.ts\n│   └── {date}\n│       └── {hour}\n│           └── {store_id}\n│               ├── ...\n│               └── {min_ts}-{uuid}.log\n└── v1_stream_truncate_safepoint.txt\n```\n\n----------------------------------------\n\nTITLE: Starting DM Cluster\nDESCRIPTION: This command starts the deployed 'dm-test' cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup-offline.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm start dm-test\n```\n\n----------------------------------------\n\nTITLE: Disabling All Roles with SET ROLE NONE in TiDB SQL\nDESCRIPTION: SQL commands to disable all roles for the current session using SET ROLE NONE, followed by a query to check the current role status.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-role.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSET ROLE NONE;\nSELECT CURRENT_ROLE();\n```\n\n----------------------------------------\n\nTITLE: Defining Row Changed Event Key Format in JSON\nDESCRIPTION: Specifies the key format for Row Changed Events in the TiCDC Open Protocol. It includes timestamp, schema name, table name, and event type identifier.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"ts\":<TS>,\n    \"scm\":<Schema Name>,\n    \"tbl\":<Table Name>,\n    \"t\":1\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Load-Based Split in TiKV\nDESCRIPTION: These YAML configuration options set thresholds for identifying hotspot Regions based on traffic, QPS, and CPU usage for load-based splitting in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_35\n\nLANGUAGE: yaml\nCODE:\n```\nsplit:\n  byte-threshold: \"30MiB\"\n  qps-threshold: 3000\n  region-cpu-overload-threshold-ratio: 0.25\n```\n\n----------------------------------------\n\nTITLE: Scale-Out Configuration for TiDB Servers\nDESCRIPTION: This INI configuration example defines the settings for a new TiDB server to be added to the cluster. It specifies the host, SSH port, TiDB port, status port, deployment directory, and log directory for the new TiDB instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_2\n\nLANGUAGE: ini\nCODE:\n```\n\"tidb_servers:\\n- host: 10.0.1.5\\n  ssh_port: 22\\n  port: 4000\\n  status_port: 10080\\n  deploy_dir: /tidb-deploy/tidb-4000\\n  log_dir: /tidb-deploy/tidb-4000/log\"\n```\n\n----------------------------------------\n\nTITLE: Creating Database in TiDB using SQL\nDESCRIPTION: SQL command to create a new database named 'bookshop' if it doesn't already exist.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-database.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE IF NOT EXISTS `bookshop`;\n```\n\n----------------------------------------\n\nTITLE: Unsupported Sequelize Feature: Database Version\nDESCRIPTION: This code snippet shows an unsupported Sequelize option in TiDB for retrieving the database version.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-third-party-tools-compatibility.md#2025-04-18_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nsequelize.options.databaseVersion\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP DM Disable Command in Shell\nDESCRIPTION: This command disables the auto-enabling of cluster services after machine restart. It can be used with options to specify nodes or roles for disabling.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-disable.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm disable <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: DROP STATS for Global Statistics\nDESCRIPTION: Example showing how to drop global statistics generated in dynamic pruning mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-stats.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nDROP STATS TableName GLOBAL;\n```\n\n----------------------------------------\n\nTITLE: Checking Updated Data in SQL\nDESCRIPTION: SQL query to view data after the update operation, confirming that the value in one row has changed from 2 to 22.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nselect * from t;\n```\n\n----------------------------------------\n\nTITLE: Explain Query with IndexJoin Hint in TiDB\nDESCRIPTION: This SQL statement uses the `EXPLAIN` command to display the execution plan for a query that joins tables `t1` and `t2` using the `TIDB_INLJ` hint. The hint suggests using IndexJoin. The query selects all columns from `t1` where `t2.code = 0` and `t2.id = t1.id`.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_79\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain select /*+ TIDB_INLJ(t1, t2) */ t1.* from t1, t2 where t2.code = 0 and t2.id = t1.id;\n+---------------------------------+----------+-----------+------------------------+---------------------------------------------------------------------------------------------------------------------+\n| id                              | estRows  | task      | access object          | operator info                                                                                                       |\n+---------------------------------+----------+-----------+------------------------+---------------------------------------------------------------------------------------------------------------------+\n| IndexJoin_11                    | 12.49    | root      |                        | inner join, inner:IndexLookUp_10, outer key:test.t2.id, inner key:test.t1.id, equal cond:eq(test.t2.id, test.t1.id) |\n| ├─TableReader_16(Build)         | 9.99     | root      |                        | data:Selection_15                                                                                                  |\n| │ └─Selection_15                | 9.99     | cop[tikv] |                        | eq(test.t2.code, 0), not(isnull(test.t2.id))                                                                       |\n| │   └─TableFullScan_14          | 10000.00 | cop[tikv] | table:t2               | keep order:false, stats:pseudo                                                                                     |\n| └─IndexLookUp_10(Probe)         | 12.49    | root      | partition:all          |                                                                                                                     |\n|   ├─Selection_9(Build)          | 12.49    | cop[tikv] |                        | not(isnull(test.t1.id))                                                                                             |\n|   │ └─IndexRangeScan_7          | 12.50    | cop[tikv] | table:t1, index:id(id) | range: decided by [eq(test.t1.id, test.t2.id)], keep order:false, stats:pseudo                                     |\n|   └─TableRowIDScan_8(Probe)     | 12.49    | cop[tikv] | table:t1               | keep order:false, stats:pseudo                                                                                     |\n+---------------------------------+----------+-----------+------------------------+---------------------------------------------------------------------------------------------------------------------+\n8 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Examining ENGINES Table Structure in SQL\nDESCRIPTION: This SQL snippet shows how to switch to the information_schema database and view the structure of the ENGINES table using the DESC command.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-engines.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC engines;\n```\n\n----------------------------------------\n\nTITLE: Example Output from TiFlash Query using EXPLAIN ANALYZE\nDESCRIPTION: This SQL snippet shows an example of the output from the `EXPLAIN ANALYZE` statement when querying with TiFlash. The output is a table showing execution information for each stage of the query plan, including execution time, number of rows, and resource unit consumption.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-htap-quickstart.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n    \"id                                   | estRows  | actRows | task         | access object | execution info                                        | operator info                              | memory  | disk    \\n    -------------------------------------+----------+---------+--------------+---------------+-------------------------------------------------------+--------------------------------------------+---------+---------\\n    Sort_5                               | 4019.00  | 28      | root         |               | time:222.2ms, loops:2, RU:25.609675                   | Column#36:desc                             | 3.77 KB | 0 Bytes \\n    └─TableReader_39                     | 4019.00  | 28      | root         |               | time:222.1ms, loops:2, cop_task: {num: 2, max: 0s,... | MppVersion: 1, data:ExchangeSender_38      | 4.64 KB | N/A     \\n      └─ExchangeSender_38                | 4019.00  | 28      | mpp[tiflash] |               | tiflash_task:{time:214.8ms, loops:1, threads:1}       | ExchangeType: PassThrough                  | N/A     | N/A     \\n        └─Projection_8                   | 4019.00  | 28      | mpp[tiflash] |               | tiflash_task:{time:214.8ms, loops:1, threads:1}       | year(game.games.release_date)->Column#3... | N/A     | N/A     \\n          └─Projection_34                | 4019.00  | 28      | mpp[tiflash] |               | tiflash_task:{time:214.8ms, loops:1, threads:1}       | Column#33, div(Column#34, cast(case(eq(... | N/A     | N/A     \\n            └─HashAgg_35                 | 4019.00  | 28      | mpp[tiflash] |               | tiflash_task:{time:214.8ms, loops:1, threads:1}       | group by:Column#63, funcs:sum(Column#64... | N/A     | N/A     \\n              └─ExchangeReceiver_37      | 4019.00  | 28      | mpp[tiflash] |               | tiflash_task:{time:214.8ms, loops:1, threads:8}       |                                            | N/A     | N/A     \\n                └─ExchangeSender_36      | 4019.00  | 28      | mpp[tiflash] |               | tiflash_task:{time:210.6ms, loops:1, threads:1}       | ExchangeType: HashPartition, Compressio... | N/A     | N/A     \\n                  └─HashAgg_33           | 4019.00  | 28      | mpp[tiflash] |               | tiflash_task:{time:210.6ms, loops:1, threads:1}       | group by:Column#75, funcs:count(1)->Col... | N/A     | N/A     \\n                    └─Projection_40      | 68223.00 | 68223   | mpp[tiflash] |               | tiflash_task:{time:210.6ms, loops:2, threads:8}       | game.games.price, game.games.price, gam... | N/A     | N/A     \\n                      └─TableFullScan_23 | 68223.00 | 68223   | mpp[tiflash] | table:games   | tiflash_task:{time:210.6ms, loops:2, threads:8}, ...  | keep order:false                           | N/A     | N/A     \\n    (11 rows)\"\n```\n\n----------------------------------------\n\nTITLE: Dump Encryption Metadata of Data Files\nDESCRIPTION: This command dumps the encryption metadata for specified data files in TiKV, which is important for data security checks.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_25\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --config=./conf.toml encryption-meta dump-file --path=/path/to/tikv/data/db/CURRENT\n```\n\n----------------------------------------\n\nTITLE: Prepared statement with member of operator, JSON_CONTAINS, and plan cache\nDESCRIPTION: This SQL code prepares and executes a statement that selects from table `t5` using both the `member of` operator and the `JSON_CONTAINS` function. It then examines `@@LAST_PLAN_FROM_CACHE` variable to determine if the plan was cached.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nmysql> PREPARE st FROM 'SELECT /*+ use_index(t5, idx1) */ * FROM t5 WHERE (? member of (j1)) AND JSON_CONTAINS(j2, ?)';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SET @a=1, @b='[1,2]';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> EXECUTE st USING @a, @b;\nEmpty set (0.00 sec)\n\nmysql> EXECUTE st USING @a, @b;\nEmpty set (0.00 sec)\n\nmysql> SELECT @@LAST_PLAN_FROM_CACHE; -- can hit plan cache if the JSON_CONTAINS doesn't impact index selection\n+------------------------+\n| @@LAST_PLAN_FROM_CACHE |\n+------------------------+\n|                      1 |\n+------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Fixing SHOW CREATE PLACEMENT POLICY Output in TiDB\nDESCRIPTION: Addresses an issue in TiDB where the output of the `SHOW CREATE PLACEMENT POLICY` command was incorrect. This fix ensures that the command provides accurate information about placement policies, aiding in the proper management and understanding of data placement within the TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.4.3.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\n\"SHOW CREATE PLACEMENT POLICY\"\n```\n\n----------------------------------------\n\nTITLE: Administering DDL Job Parameters in SQL\nDESCRIPTION: Introduces new ADMIN ALTER DDL JOBS statement for dynamically modifying DDL job parameters online, enabling flexible resource management and performance tuning\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.5.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nADMIN ALTER DDL JOBS job_id THREAD = 8;\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN ALTER DDL JOBS job_id BATCH_SIZE = 256;\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN ALTER DDL JOBS job_id MAX_WRITE_SPEED = '200MiB';\n```\n\n----------------------------------------\n\nTITLE: Creating Global Temporary Table in SQL\nDESCRIPTION: SQL statement to create a global temporary table for storing the top 50 eldest authors, visible to the entire TiDB cluster but with data visible only to the current transaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE GLOBAL TEMPORARY TABLE IF NOT EXISTS top_50_eldest_authors_global (\n    id BIGINT,\n    name VARCHAR(255),\n    age INT,\n    PRIMARY KEY(id)\n) ON COMMIT DELETE ROWS;\n```\n\n----------------------------------------\n\nTITLE: Generating ANALYZE Table Statements for All Tables in SQL\nDESCRIPTION: Generates a list of ANALYZE TABLE SQL statements for each table where statistics version is set to 2, allowing for batch analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DISTINCT(CONCAT('ANALYZE TABLE ', table_schema, '.', table_name, ';'))\nFROM information_schema.tables JOIN mysql.stats_histograms\nON table_id = tidb_table_id\nWHERE stats_ver = 2;\n```\n\n----------------------------------------\n\nTITLE: Defining the SHOW GRANTS Statement Syntax\nDESCRIPTION: The EBNF representation of the SQL syntax for the SHOW GRANTS command, which shows user privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-grants.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowGrantsStmt ::=\n    \"SHOW\" \"GRANTS\" (\"FOR\" Username (\"USING\" RolenameList)?)? \n\nUsername ::=\n    \"CURRENT_USER\" ( \"(\" \")\" )?\n| Username (\"@\" Hostname)?\n\nRolenameList ::=\n    Rolename (\"@\" Hostname)? (\",\" Rolename (\"@\" Hostname)? )*\n```\n\n----------------------------------------\n\nTITLE: Configuring Systemd User Mode for TiDB User\nDESCRIPTION: Set up systemd user mode by configuring environment variables and starting user services\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-no-sudo-mode.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsudo -iu tidb\nmkdir -p ~/.bashrc.d\necho \"export XDG_RUNTIME_DIR=/run/user/$(id -u)\" > ~/.bashrc.d/systemd\nsource ~/.bashrc.d/systemd\n```\n\n----------------------------------------\n\nTITLE: Starting Log Backup for TiDB using BR\nDESCRIPTION: Command to start the log backup task on TiKV nodes. The task continuously backs up data changes to the specified storage in small batches.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-use-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup br log start\n```\n\n----------------------------------------\n\nTITLE: Scaling TiDB Cluster with Terraform\nDESCRIPTION: This snippet showcases how to edit a 'cluster.tf' to increase the number of TiDB, TiKV, and TiFlash nodes as needed. The example updates node quantities and requires knowledge of cluster specifications and correct syntax. Ensure all syntax changes comply with the cluster's requirements.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_9\n\nLANGUAGE: HCL\nCODE:\n```\n   components = {\n     tidb = {\n       node_size : \"8C16G\"\n       node_quantity : 2\n     }\n     tikv = {\n       node_size : \"8C32G\"\n       storage_size_gib : 500\n       node_quantity : 6\n     }\n     tiflash = {\n       node_size : \"8C64G\"\n       storage_size_gib : 500\n       node_quantity : 2\n     }\n   }\n```\n\n----------------------------------------\n\nTITLE: Data Migration Alerts Table in Markdown\nDESCRIPTION: Markdown table showing data migration alert conditions and recommended actions for TiDB Cloud monitoring\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/monitor-built-in-alerting.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Condition | Recommended Action |\n|:--- |:--- |\n| Data migration job met error during data export | Check the error and see [Troubleshoot data migration](/tidb-cloud/tidb-cloud-dm-precheck-and-troubleshooting.md#migration-errors-and-solutions) for help. |\n| Data migration job met error during data import | Check the error and see [Troubleshoot data migration](/tidb-cloud/tidb-cloud-dm-precheck-and-troubleshooting.md#migration-errors-and-solutions) for help. |\n```\n\n----------------------------------------\n\nTITLE: Example of Error Status Output\nDESCRIPTION: This shows an example output from the `br log status` command, indicating an `ERROR` status for a log backup task. The output includes detailed error information, such as the store ID, the time the error occurred, and the error message itself, providing clues for troubleshooting the issue.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n\"br log status --pd x.x.x.x:2379\\n\\n● Total 1 Tasks.\\n> #1 <\\n                    name: task1\\n                  status: ○ ERROR\\n                   start: 2022-07-25 13:49:02.868 +0000\\n                     end: 2090-11-18 14:07:45.624 +0000\\n                 storage: s3://tmp/br-log-backup0ef49055-5198-4be3-beab-d382a2189efb/Log\\n             speed(est.): 0.00 ops/s\\n      checkpoint[global]: 2022-07-25 14:46:50.118 +0000; gap=11h31m29s\\n          error[store=1]: KV:LogBackup:RaftReq\\nerror-happen-at[store=1]: 2022-07-25 14:54:44.467 +0000; gap=11h23m35s\\n  error-message[store=1]: retry time exceeds: and error failed to get initial snapshot: failed to get the snapshot (region_id = 94812): Error during requesting raftstore: message: \\\"read index not ready, reason can not read index due to merge, region 94812\\\" read_index_not_ready { reason: \\\"can not read index due to merge\\\" region_id: 94812 }: failed to get initial snapshot: failed to get the snapshot (region_id = 94812): Error during requesting raftstore: message: \\\"read index not ready, reason can not read index due to merge, region 94812\\\" read_index_not_ready { reason: \\\"can not read index due to merge\\\" region_id: 94812 }: failed to get initial snapshot: failed to get the snapshot (region_id = 94812): Error during requesting raftstore: message: \\\"read index not ready, reason can not read index due to merge, region 94812\\\" read_index_not_ready { reason: \\\"can not read index due to merge\\\" region_id: 94812 }\"\n```\n\n----------------------------------------\n\nTITLE: Logging Configuration Properties\nDESCRIPTION: Log configuration settings including log level, format, and timestamp options.\nSOURCE: https://github.com/pingcap/docs/blob/master/tso-configuration-file.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nlog:\n  level: \"info\"\n  format: \"text\"\n  disable-timestamp: false\n  file:\n    max-size: 300\n    max-days: 0\n    max-backups: 0\n```\n\n----------------------------------------\n\nTITLE: Dynamically Disable Pipelined Locking\nDESCRIPTION: SQL command to dynamically disable pipelined locking in TiKV without restart.\nSOURCE: https://github.com/pingcap/docs/blob/master/pessimistic-transaction.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nset config tikv pessimistic-txn.pipelined='false';\n```\n\n----------------------------------------\n\nTITLE: Fetching Binary Log Position for DROP TABLE\nDESCRIPTION: This snippet describes the SQL command to fetch binary log events to identify the position of a DDL operation, specifically a DROP TABLE statement. It requires MySQL or MariaDB to be installed with appropriate privileges to access binary logs.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/shard-merge-best-practices.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW BINLOG EVENTS;\n```\n\n----------------------------------------\n\nTITLE: Describing User Profile in TiCloud CLI - Shell\nDESCRIPTION: This snippet demonstrates how to use the 'ticloud config describe' command to retrieve property information of a user profile. Required parameters include the profile name, and optional flags can modify command behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-describe.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud config describe <profile-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Installing MySQL Client on macOS\nDESCRIPTION: Commands to install and configure MySQL client using Homebrew package manager on macOS systems.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-build-cluster-in-cloud.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbrew install mysql-client\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW VARIABLES Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the SHOW VARIABLES statement, including optional GLOBAL/SESSION scope and LIKE/WHERE clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-variables.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nShowVariablesStmt ::=\n    \"SHOW\" (\"GLOBAL\" | \"SESSION\")? VARIABLES ShowLikeOrWhere?\n    \nShowLikeOrWhere ::=\n    \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Global Hints with QB_NAME in Views\nDESCRIPTION: Examples showing how to use QB_NAME hint to define query block names in views for applying global hints.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_40\n\nLANGUAGE: sql\nCODE:\n```\nCREATE VIEW v AS SELECT /* Comment: The name of the current query block is the default @SEL_1 */ * FROM t;\n\nSELECT /*+ QB_NAME(v_1, v) USE_INDEX(t@v_1, idx) */ * FROM v;\n```\n\n----------------------------------------\n\nTITLE: Cleaning TIDB_TEST_ITEM Table in Snowflake - SQL\nDESCRIPTION: Creates a Snowflake `TASK` to periodically `TRUNCATE` the `TIDB_TEST_ITEM` table every two hours. Useful for preventing data accumulation.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_12\n\nLANGUAGE: SQL\nCODE:\n```\n-- Clean up the TIDB_TEST_ITEM table every two hours\ncreate or replace task TRUNCATE_TIDB_TEST_ITEM\n    warehouse = test\n    schedule = '120 minute'\nwhen\n    system$stream_has_data('TIDB_TEST_ITEM')\nas\n    TRUNCATE table TIDB_TEST_ITEM;\n```\n\n----------------------------------------\n\nTITLE: Creating a tpcc Database in TiDB\nDESCRIPTION: This snippet demonstrates how to create a database named `tpcc` in a TiDB cluster. It's a prerequisite for loading the TPC-C data into the cluster for performance testing. It ensures a dedicated space for the benchmark data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v6.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE DATABASE tpcc;\"\n```\n\n----------------------------------------\n\nTITLE: Querying Clustered Index Status in SQL\nDESCRIPTION: SQL query to check if a table has a clustered index by querying the information_schema.tables view.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0-rc.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nselect tidb_pk_type from information_schema.tables where table_name = '{tbl_name}'\n```\n\n----------------------------------------\n\nTITLE: Installing dependencies for the sample app\nDESCRIPTION: npm command to install required packages including mysql and dotenv for the sample application.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysqljs.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Backup and Restore Data in TiDB SQL\nDESCRIPTION: New SQL statements to backup and restore data in TiDB, providing data protection and migration capabilities.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.2.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nBACKUP DATABASE mydatabase TO '/path/to/backup';\nRESTORE DATABASE mydatabase FROM '/path/to/backup';\n```\n\n----------------------------------------\n\nTITLE: Analyzing MVCC Version Impact on TiDB Query Performance\nDESCRIPTION: This slow query log excerpt shows the Total_keys and Processed_keys fields, which can indicate if excessive MVCC versions are impacting query performance in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\n...\n# Total_keys: 2215187529 Processed_keys: 1108056368\n...\n```\n\n----------------------------------------\n\nTITLE: Running TPC-C Performance Test\nDESCRIPTION: Command to execute TPC-C benchmark test for 10 minutes using 100 threads across 1000 warehouses on multiple TiDB servers.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-tpcc.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup bench tpcc -H 172.16.5.140,172.16.5.141 -P 4000 -D tpcc --warehouses 1000 --threads 100 --time 10m run\n```\n\n----------------------------------------\n\nTITLE: DDL Execution Query Results\nDESCRIPTION: Shows the output of tracking a DDL job execution across different TiDB instances with timestamps and execution stages.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-log.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n| time                    | instance       | left(message,150)                                                                                                                                      |\n+-------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 2020/05/18 21:37:54.784 | 127.0.0.1:4002 | [ddl_worker.go:261] [\"[ddl] add DDL jobs\"] [\"batch count\"=1] [jobs=\"ID:80, Type:create table, State:none, SchemaState:none, SchemaID:1, TableID:79, Ro |\n| 2020/05/18 21:37:54.784 | 127.0.0.1:4002 | [ddl.go:477] [\"[ddl] start DDL job\"] [job=\"ID:80, Type:create table, State:none, SchemaState:none, SchemaID:1, TableID:79, RowCount:0, ArgLen:1, start |\n| 2020/05/18 21:37:55.327 | 127.0.0.1:4000 | [ddl_worker.go:568] [\"[ddl] run DDL job\"] [worker=\"worker 1, tp general\"] [job=\"ID:80, Type:create table, State:none, SchemaState:none, SchemaID:1, Ta |\n| 2020/05/18 21:37:55.381 | 127.0.0.1:4000 | [ddl_worker.go:763] [\"[ddl] wait latest schema version changed\"] [worker=\"worker 1, tp general\"] [ver=70] [\"take time\"=50.809848ms] [job=\"ID:80, Type: |\n| 2020/05/18 21:37:55.382 | 127.0.0.1:4000 | [ddl_worker.go:359] [\"[ddl] finish DDL job\"] [worker=\"worker 1, tp general\"] [job=\"ID:80, Type:create table, State:synced, SchemaState:public, SchemaI |\n| 2020/05/18 21:37:55.786 | 127.0.0.1:4002 | [ddl.go:509] [\"[ddl] DDL job is finished\"] [jobID=80]                                                                                                  |\n+-------------------------+----------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Adding Upper Bound to Scan Command in TiDB\nDESCRIPTION: Adds an upper bound to the Scan command of ticlient to prevent overbound scans. This change improves query performance and resource utilization.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1-rc.5.md#2025-04-18_snippet_0\n\nLANGUAGE: Go\nCODE:\n```\n// Example code structure (not actual implementation)\nfunc ScanWithUpperBound(client *Client, key []byte, limit int) ([]KVPair, error) {\n    // Implementation with upper bound logic\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Checkpoints in TiDB Lightning with TOML\nDESCRIPTION: This TOML snippet shows how to enable and configure checkpoints in TiDB Lightning, including setting the storage location and conditional retention post-import. It includes options for using local files or a remote MySQL-compatible database for checkpoint storage, highlighting the requisite schema name and DSN configurations for different drivers.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-checkpoints.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[checkpoint]\n# Whether to enable checkpoints.\n# While importing data, TiDB Lightning records which tables have been imported, so\n# even if TiDB Lightning or some other component crashes, you can start from a known\n# good state instead of restarting from scratch.\nenable = true\n\n# Where to store the checkpoints.\n#  - file:  store as a local file (requires v2.1.1 or later)\n#  - mysql: store into a remote MySQL-compatible database\ndriver = \"file\"\n\n# The schema name (database name) to store the checkpoints\n# Enabled only when `driver = \"mysql\"`.\n# schema = \"tidb_lightning_checkpoint\"\n\n# The data source name (DSN) indicating the location of the checkpoint storage.\n#\n# For the \"file\" driver, the DSN is a path. If the path is not specified, Lightning would\n# default to \"/tmp/CHECKPOINT_SCHEMA.pb\".\n#\n# For the \"mysql\" driver, the DSN is a URL in the form of \"USER:PASS@tcp(HOST:PORT)/\".\n# If the URL is not specified, the TiDB server from the [tidb] section is used to\n# store the checkpoints. You should specify a different MySQL-compatible\n# database server to reduce the load of the target TiDB cluster.\n#dsn = \"/tmp/tidb_lightning_checkpoint.pb\"\n\n# Whether to keep the checkpoints after all data are imported. If false, the\n# checkpoints are deleted. Keeping the checkpoints can aid debugging but\n# might leak metadata about the data source.\n# keep-after-success = false\n```\n\n----------------------------------------\n\nTITLE: Dumping MariaDB Data with Dumpling - Shell\nDESCRIPTION: This code snippet demonstrates how to use the 'tiup dumpling' command to dump data from a MariaDB database. It allows for specifying connection parameters such as port, host, user, and output directory, and it includes an option for limiting the file size.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-mariadb.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup dumpling --port 3306 --host 127.0.0.1 --user root --password secret -F 256MB  -o /data/backup\n```\n\n----------------------------------------\n\nTITLE: Data Type Validation for Multi-Valued Index\nDESCRIPTION: These snippets demonstrate the importance of matching the data type defined in the multi-valued index. Inserting incompatible data types (e.g., negative numbers or strings when expecting unsigned integers) will result in errors.  It showcases inserting a valid array of unsigned integers which succeeds.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\n-- All elements in the zipcode field must be the UNSIGNED type.\nmysql> INSERT INTO customers VALUES (1, 'pingcap', '{\"zipcode\": [-1]}');\nERROR 3752 (HY000): Value is out of range for expression index 'zips' at row 1\n\nmysql> INSERT INTO customers VALUES (1, 'pingcap', '{\"zipcode\": [\"1\"]}'); -- Incompatible with MySQL\nERROR 3903 (HY000): Invalid JSON value for CAST for expression index 'zips'\n\nmysql> INSERT INTO customers VALUES (1, 'pingcap', '{\"zipcode\": [1]}');\nQuery OK, 1 row affected (0.00 sec)\n\n```\n\n----------------------------------------\n\nTITLE: Querying Processors List - Shell and JSON\nDESCRIPTION: Example of how to retrieve a list of all processors using the GET /api/v2/processors endpoint. Returns a list of changefeed and capture IDs.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v2/processors\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"total\": 3,\n  \"items\": [\n    {\n      \"changefeed_id\": \"test2\",\n      \"capture_id\": \"d2912e63-3349-447c-90ba-72a4e04b5e9e\"\n    },\n    {\n      \"changefeed_id\": \"test1\",\n      \"capture_id\": \"d2912e63-3349-447c-90ba-72a4e04b5e9e\"\n    },\n    {\n      \"changefeed_id\": \"test\",\n      \"capture_id\": \"d2912e63-3349-447c-90ba-72a4e04b5e9e\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting DDL Reorganization Batch Size\nDESCRIPTION: Configures the tidb_ddl_reorg_batch_size variable to set the batch size for DDL operations during the re-organize phase. This affects the performance and conflict probability of operations like ADD INDEX.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_24\n\nLANGUAGE: SQL\nCODE:\n```\nSET SESSION tidb_ddl_reorg_batch_size = 256;\n```\n\n----------------------------------------\n\nTITLE: Checking Changefeed Status - Shell\nDESCRIPTION: Lists all changefeeds to check the status after creation, ensuring the changefeed is operational.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-data-to-kafka.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc:v<CLUSTER_VERSION> cli changefeed list --server=\"http://127.0.0.1:8300\"\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW Status Syntax in EBNF\nDESCRIPTION: This snippet defines the syntax for the SHOW [GLOBAL|SESSION] STATUS SQL statement using Extended Backus-Naur Form (EBNF). It includes the scope options and possible expressions for filtering results.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-status.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowStatusStmt ::=\n    'SHOW' Scope? 'STATUS' ShowLikeOrWhere?\n\nScope ::=\n    ( 'GLOBAL' | 'SESSION' )\n\nShowLikeOrWhere ::=\n    \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Altering Table to Set TiFlash Replica in SQL\nDESCRIPTION: Alters a table to set the number of TiFlash replicas for HTAP capabilities.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE {table_name} SET TIFLASH REPLICA {count};\n```\n\n----------------------------------------\n\nTITLE: CREATE INDEX EBNF Syntax Definition in TiDB\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the CREATE INDEX statement in TiDB. It defines all possible syntax variations including options for index types, expressions, and modifiers.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCreateIndexStmt ::=\n    'CREATE' IndexKeyTypeOpt 'INDEX' IfNotExists Identifier IndexTypeOpt 'ON' TableName '(' IndexPartSpecificationList ')' IndexOptionList IndexLockAndAlgorithmOpt\n\nIndexKeyTypeOpt ::=\n    ( 'UNIQUE' | 'SPATIAL' | 'FULLTEXT' )?\n\nIfNotExists ::=\n    ( 'IF' 'NOT' 'EXISTS' )?\n\nIndexTypeOpt ::=\n    IndexType?\n\nIndexPartSpecificationList ::=\n    IndexPartSpecification ( ',' IndexPartSpecification )*\n\nIndexOptionList ::=\n    IndexOption*\n\nIndexLockAndAlgorithmOpt ::=\n    ( LockClause AlgorithmClause? | AlgorithmClause LockClause? )?\n\nIndexType ::=\n    ( 'USING' | 'TYPE' ) IndexTypeName\n\nIndexPartSpecification ::=\n    ( ColumnName OptFieldLen | '(' Expression ')' ) Order\n\nIndexOption ::=\n    'KEY_BLOCK_SIZE' '='? LengthNum\n|   IndexType\n|   'WITH' 'PARSER' Identifier\n|   'COMMENT' stringLit\n|   (\"VISIBLE\" | \"INVISIBLE\")\n|   (\"GLOBAL\" | \"LOCAL\")\n\nIndexTypeName ::=\n    'BTREE'\n|   'HASH'\n|   'RTREE'\n\nColumnName ::=\n    Identifier ( '.' Identifier ( '.' Identifier )? )?\n\nOptFieldLen ::=\n    FieldLen?\n\nIndexNameList ::=\n    ( Identifier | 'PRIMARY' )? ( ',' ( Identifier | 'PRIMARY' ) )*\n\nKeyOrIndex ::=\n    'Key' | 'Index'\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Cloud Terraform Provider with API keys\nDESCRIPTION: Terraform configuration that specifies both the required provider and the provider configuration with API credentials. This configuration connects Terraform to your TiDB Cloud account.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-get-tidbcloud-provider.md#2025-04-18_snippet_3\n\nLANGUAGE: terraform\nCODE:\n```\nterraform {\n  required_providers {\n    tidbcloud = {\n      source = \"tidbcloud/tidbcloud\"\n    }\n  }\n}\n\nprovider \"tidbcloud\" {\n  public_key = \"your_public_key\"\n  private_key = \"your_private_key\"\n}\n```\n\n----------------------------------------\n\nTITLE: Converting Binary Literal to Uint64 in Go\nDESCRIPTION: This function converts a byte slice representing a binary literal to a uint64 integer. It trims leading zero bytes, handles various lengths up to 8 bytes, and performs bitwise operations to construct the final value.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-checksum-verification.md#2025-04-18_snippet_7\n\nLANGUAGE: Go\nCODE:\n```\nfunc binaryLiteralToInt(bytes []byte) (uint64, error) {\n    bytes = trimLeadingZeroBytes(bytes)\n    length := len(bytes)\n\n    if length > 8 {\n        log.Error(\"invalid bit value found\", zap.ByteString(\"value\", bytes))\n        return math.MaxUint64, errors.New(\"invalid bit value\")\n    }\n\n    if length == 0 {\n        return 0, nil\n    }\n\n    val := uint64(bytes[0])\n    for i := 1; i < length; i++ {\n        val = (val << 8) | uint64(bytes[i])\n    }\n    return val, nil\n}\n```\n\n----------------------------------------\n\nTITLE: DDL Event Key Format in Debezium Protocol\nDESCRIPTION: JSON structure defining the key format for DDL events in the Debezium protocol. It includes a payload with the database name and a schema describing the structure of the payload.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-debezium.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"payload\": {\n        \"databaseName\": \"test\"\n    },\n    \"schema\": {\n        \"type\": \"struct\",\n        \"name\": \"io.debezium.connector.mysql.SchemaChangeKey\",\n        \"optional\": false,\n        \"version\": 1,\n        \"fields\": [\n            {\n                \"field\": \"databaseName\",\n                \"optional\": false,\n                \"type\": \"string\"\n            }\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP List Command with Basic Syntax\nDESCRIPTION: Basic command to list all available TiUP components without any additional flags. Retrieves a standard list of components with their names, owners, and descriptions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-list.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup list\n```\n\n----------------------------------------\n\nTITLE: Downloading and Setting Root Certificate for TIUP Mirror\nDESCRIPTION: This shell command downloads the root certificate for a specified network mirror address to a local file. This is a security measure to prevent man-in-the-middle attacks when using network mirrors. Once the certificate is verified, it can be used to securely set the mirror.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-set.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nwget <mirror-addr>/root.json -O /path/to/local/root.json\n```\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror set <mirror-addr> -r /path/to/local/root.json\n```\n\n----------------------------------------\n\nTITLE: Resolving Partition Pruning Failure in TiDB Plan Cache\nDESCRIPTION: Fixes an issue where partition pruning failed due to the plan cache.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_11\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM partitioned_table WHERE partition_column = value\n```\n\n----------------------------------------\n\nTITLE: Querying Top Time-Consuming Monitoring Items\nDESCRIPTION: Demonstrates how to query the three monitoring items with highest average time consumption using time range hints.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-metrics-summary.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ time_range('2020-03-08 13:23:00','2020-03-08 13:33:00') */ *\nFROM information_schema.metrics_summary\nWHERE metrics_name LIKE 'tidb%duration'\n AND avg_value > 0\n AND quantile = 0.99\nORDER BY avg_value DESC\nLIMIT 3\\G\n```\n\n----------------------------------------\n\nTITLE: Configuring Raftstore Store Pool Size\nDESCRIPTION: Defines the size of the Raftstore thread pool, controlling the number of threads processing Raft operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_7\n\nLANGUAGE: TOML\nCODE:\n```\n\"raftstore.store-pool-size = 4\"\n```\n\n----------------------------------------\n\nTITLE: Creating and Analyzing a Partitioned Table in TiDB\nDESCRIPTION: This SQL snippet shows creating a partitioned table with RANGE partitioning, inserting data, and analyzing it. The ANALYZE statement runs successfully on all partitions when none are locked.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t(a INT, b INT) PARTITION BY RANGE (a) (PARTITION p0 VALUES LESS THAN (10), PARTITION p1 VALUES LESS THAN (20), PARTITION p2 VALUES LESS THAN (30));\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> INSERT INTO t VALUES (1,2), (3,4), (5,6), (7,8);\nQuery OK, 4 rows affected (0.00 sec)\nRecords: 4  Duplicates: 0  Warnings: 0\n\nmysql> ANALYZE TABLE t;\nQuery OK, 0 rows affected, 6 warning (0.02 sec)\n\nmysql> SHOW WARNINGS;\n+---------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Level   | Code | Message                                                                                                                                                                                                                              |\n+---------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Warning | 1105 | disable dynamic pruning due to t has no global stats                                                                                                                                                                                 |\n| Note    | 1105 | Analyze use auto adjusted sample rate 1.000000 for table test.t's partition p0, reason to use this rate is \"Row count in stats_meta is much smaller compared with the row count got by PD, use min(1, 15000/4) as the sample-rate=1\" |\n| Warning | 1105 | disable dynamic pruning due to t has no global stats                                                                                                                                                                                 |\n| Note    | 1105 | Analyze use auto adjusted sample rate 1.000000 for table test.t's partition p1, reason to use this rate is \"TiDB assumes that the table is empty, use sample-rate=1\"                                                                 |\n| Warning | 1105 | disable dynamic pruning due to t has no global stats                                                                                                                                                                                 |\n| Note    | 1105 | Analyze use auto adjusted sample rate 1.000000 for table test.t's partition p2, reason to use this rate is \"TiDB assumes that the table is empty, use sample-rate=1\"                                                                 |\n+---------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n6 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying DEADLOCKS Table in SQL\nDESCRIPTION: This system table shows deadlock errors recently occurred on a TiDB node, including retryable deadlock errors when enabled via configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.2.0.md#2025-04-18_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.DEADLOCKS;\n```\n\n----------------------------------------\n\nTITLE: Configuring Basic Table Routing Rules in YAML\nDESCRIPTION: Example configuration showing basic table routing rules including schema/table patterns, target locations, and optional extract configurations for handling sharded tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-table-routing.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nroutes:\n  rule-1:\n    schema-pattern: \"test_*\"\n    table-pattern: \"t_*\"\n    target-schema: \"test\"\n    target-table: \"t\"\n    extract-table:\n      table-regexp: \"t_(.*)\"\n      target-column: \"c_table\"\n    extract-schema:\n      schema-regexp: \"test_(.*)\"\n      target-column: \"c_schema\"\n    extract-source:\n      source-regexp: \"(.*)\"\n      target-column: \"c_source\"\n  rule-2:\n    schema-pattern: \"test_*\"\n    target-schema: \"test\"\n```\n\n----------------------------------------\n\nTITLE: Querying Data in TiDB with SELECT\nDESCRIPTION: Commands for retrieving data from tables, including selecting all columns, specific columns, and filtering results with conditions using the WHERE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/basic-sql-operations.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM person;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT name FROM person;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM person where id<5;\n```\n\n----------------------------------------\n\nTITLE: Set Password with PASSWORD() Function\nDESCRIPTION: This SQL statement demonstrates setting a password using the PASSWORD() function, which is a deprecated syntax from older MySQL releases. It changes the password for the user 'newuser' using the PASSWORD() function.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-password.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSET PASSWORD FOR newuser = PASSWORD('test');\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW CREATE USER 'newuser';\n```\n\n----------------------------------------\n\nTITLE: Updating Records in TiDB with SQL\nDESCRIPTION: This SQL statement updates the 'birthday' field of a record in the 'person' table where the ID equals 2. It demonstrates how to modify existing data based on a condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-tidb-crud-sql.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE person SET birthday='20180808' WHERE id=2;\n```\n\n----------------------------------------\n\nTITLE: Setting Table Attributes in SQL\nDESCRIPTION: Shows how to set attributes for a table or partition using SQL. The attribute is in the form of 'key=value', with multiple attributes separated by commas.\nSOURCE: https://github.com/pingcap/docs/blob/master/table-attributes.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t [PARTITION p] ATTRIBUTES [=] 'key=value[, key1=value1...]';\n```\n\n----------------------------------------\n\nTITLE: Showing Configuration with WHERE Clause\nDESCRIPTION: This SQL statement demonstrates how to use the `WHERE` clause to filter the configuration results based on specific conditions.  The example filters the configuration where the type is 'tidb' and name is 'advertise-address'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-config.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n\"SHOW CONFIG WHERE type = 'tidb' AND name = 'advertise-address';\"\n```\n\n----------------------------------------\n\nTITLE: TiUP Uninstall Command Syntax\nDESCRIPTION: Basic syntax for the tiup uninstall command. Allows uninstalling specific component versions or multiple components. Requires --all flag when uninstalling all versions of a component.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-uninstall.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup uninstall <component1>:<version> [component2...N] [flags]\n```\n\n----------------------------------------\n\nTITLE: Setting HTTP Concurrency Limit for GetRegion API in PD\nDESCRIPTION: Sets the maximum concurrency for GetRegion HTTP API requests to 10.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nconfig set service-middleware rate-limit GetRegion concurrency 10\n```\n\n----------------------------------------\n\nTITLE: Querying Eldest Authors in SQL\nDESCRIPTION: SQL query to get the top 50 eldest authors from the authors table, calculating their age based on birth and death years.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT a.id, a.name, (IFNULL(a.death_year, YEAR(NOW())) - a.birth_year) AS age\nFROM authors a\nORDER BY age DESC\nLIMIT 50;\n```\n\n----------------------------------------\n\nTITLE: Monitoring NIC Hardware Drops with ethtool\nDESCRIPTION: Command to observe packet drops at the hardware level using ethtool. The 'drops' field indicates packet loss that might occur when processing speed cannot match receiving speed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nethtool -S ${NIC_DEV_NAME}\n```\n\n----------------------------------------\n\nTITLE: Managing Users and Privileges in TiDB\nDESCRIPTION: Commands for user management, including creating users with passwords, granting specific privileges, checking user permissions, and deleting users.\nSOURCE: https://github.com/pingcap/docs/blob/master/basic-sql-operations.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'tiuser'@'localhost' IDENTIFIED BY '123456';\n```\n\nLANGUAGE: sql\nCODE:\n```\nGRANT SELECT ON samp_db.* TO 'tiuser'@'localhost';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS for tiuser@localhost;\n```\n\nLANGUAGE: sql\nCODE:\n```\nDROP USER 'tiuser'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Updating TiUP Cluster Component - Shell\nDESCRIPTION: This snippet shows the commands to update the TiUP cluster component to the latest version, ensuring that the user has the most recent features and fixes.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup update --self && tiup update cluster\n```\n\n----------------------------------------\n\nTITLE: TABLE Statement Syntax in EBNF Format\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the TABLE statement, showing its structure with optional ORDER BY and LIMIT clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-table.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nTableStmt ::=\n    \"TABLE\" Table ( \"ORDER BY\" Column )? ( \"LIMIT\" NUM )?\n```\n\n----------------------------------------\n\nTITLE: Filtering Procedure Statements in YAML Configuration\nDESCRIPTION: Configuration rule to filter out CREATE PROCEDURE and DROP PROCEDURE statements for tables matching the test_*.t_* pattern. This helps prevent migration of procedures that TiDB doesn't support.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-binlog-event-filter.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nfilters:\n  filter-procedure-rule:\n    schema-pattern: \"test_*\"\n    table-pattern: \"t_*\"\n    sql-pattern: [\"^DROP\\\\s+PROCEDURE\", \"^CREATE\\\\s+PROCEDURE\"]\n    action: Ignore\n```\n\n----------------------------------------\n\nTITLE: Encrypting Log Backup with Google Cloud KMS in Shell\nDESCRIPTION: Example of starting a log backup task with encryption using a master key managed by Google Cloud Key Management Service (KMS).\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log start \\\n    --task-name=pitr-with-encryption \\\n    --pd ${PD_IP}:2379 \\\n    --storage \"s3://${BACKUP_COLLECTION_ADDR}/snapshot-${DATE}?access-key=${AWS_ACCESS_KEY}&secret-access-key=${AWS_SECRET_ACCESS_KEY}\" \\\n    --master-key-crypter-method aes128-ctr \\\n    --master-key \"gcp-kms:///projects/$GCP_PROJECT_ID/locations/$GCP_LOCATION/keyRings/$GCP_KEY_RING/cryptoKeys/$GCP_KEY_NAME?AUTH=specified&CREDENTIALS=$GCP_CREDENTIALS_PATH\"\n```\n\n----------------------------------------\n\nTITLE: Example of Configured TiCDC Changefeed Command\nDESCRIPTION: A complete example of the TiCDC changefeed creation command with placeholder values replaced with actual credentials and endpoints for connecting to Confluent Cloud.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc:v<CLUSTER_VERSION> cli changefeed create --server=\"http://127.0.0.1:8300\" --sink-uri=\"kafka://xxx-xxxxx.ap-east-1.aws.confluent.cloud:9092/ticdc-meta?protocol=avro&replication-factor=3&enable-tls=true&auto-create-topic=true&sasl-mechanism=plain&sasl-user=L5WWA4GK4NAT2EQV&sasl-password=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\" --schema-registry=\"https://7NBH2CAFM2LMGTH7:xxxxxxxxxxxxxxxxxx@yyy-yyyyy.us-east-2.aws.confluent.cloud\" --changefeed-id=\"confluent-changefeed\" --config changefeed.conf\n```\n\n----------------------------------------\n\nTITLE: Setting ZSTD Compression for All Levels in RocksDB Default Column Family\nDESCRIPTION: Configuration snippet for increasing all the compression levels of the default column family in RocksDB to ZSTD. This is recommended when the average row size is smaller than 512 bytes.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices-on-public-cloud.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[rocksdb.defaultcf]\ncompression-per-level = [\"zstd\", \"zstd\", \"zstd\", \"zstd\", \"zstd\", \"zstd\", \"zstd\"]\n```\n\n----------------------------------------\n\nTITLE: Configuring Django Database Connection to TiDB\nDESCRIPTION: Django settings configuration to connect to a TiDB cluster, including support for SSL connections and loading environment variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndotenv.load_dotenv()\n\nDATABASES = {\n    \"default\": {\n        # https://github.com/pingcap/django-tidb\n        \"ENGINE\": \"django_tidb\",\n        \"HOST\": os.environ.get(\"TIDB_HOST\", \"127.0.0.1\"),\n        \"PORT\": int(os.environ.get(\"TIDB_PORT\", 4000)),\n        \"USER\": os.environ.get(\"TIDB_USERNAME\", \"root\"),\n        \"PASSWORD\": os.environ.get(\"TIDB_PASSWORD\", \"\"),\n        \"NAME\": os.environ.get(\"TIDB_DATABASE\", \"test\"),\n        \"OPTIONS\": {\n            \"charset\": \"utf8mb4\",\n        },\n    }\n}\n\nTIDB_CA_PATH = os.environ.get(\"TIDB_CA_PATH\", \"\")\nif TIDB_CA_PATH:\n    DATABASES[\"default\"][\"OPTIONS\"][\"ssl_mode\"] = \"VERIFY_IDENTITY\"\n    DATABASES[\"default\"][\"OPTIONS\"][\"ssl\"] = {\n        \"ca\": TIDB_CA_PATH,\n    }\n```\n\n----------------------------------------\n\nTITLE: ADMIN CANCEL DDL EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the ADMIN CANCEL DDL statement, showing the structure of the command and its components.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-cancel-ddl.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAdminCancelDDLStmt ::=\n    'ADMIN' 'CANCEL' 'DDL' 'JOBS' NumList \n\nNumList ::=\n    Int64Num ( ',' Int64Num )*\n```\n\n----------------------------------------\n\nTITLE: Configuring RocksDB WriteStall Triggers in TiKV\nDESCRIPTION: Configuration settings to adjust the L0 file thresholds that trigger WriteStall in RocksDB for TiKV. These settings can help mitigate sudden increases in write delay caused by too many L0 files.\nSOURCE: https://github.com/pingcap/docs/blob/master/storage-engine/rocksdb-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```\nrocksdb.defaultcf.level0-slowdown-writes-trigger\nrocksdb.writecf.level0-slowdown-writes-trigger\nrocksdb.lockcf.level0-slowdown-writes-trigger\nrocksdb.defaultcf.level0-stop-writes-trigger\nrocksdb.writecf.level0-stop-writes-trigger\nrocksdb.lockcf.level0-stop-writes-trigger\n```\n```\n\n----------------------------------------\n\nTITLE: Split Region EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the Split Region SQL statement in TiDB, showing the grammar rules for different split options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nSplitRegionStmt ::=\n    \"SPLIT\" SplitSyntaxOption \"TABLE\" TableName PartitionNameList? (\"INDEX\" IndexName)? SplitOption\n\nSplitSyntaxOption ::=\n    (\"REGION\" \"FOR\")? \"PARTITION\"?\n\nTableName ::=\n    (SchemaName \".\")? Identifier\n\nPartitionNameList ::=\n    \"PARTITION\" \"(\" PartitionName (\",\" PartitionName)* \")\"\n\nSplitOption ::=\n    (\"BETWEEN\" RowValue \"AND\" RowValue \"REGIONS\" NUM\n|   \"BY\" RowValue (\",\" RowValue)* )\n\nRowValue ::=\n    \"(\" ValuesOpt \")\"\n```\n\n----------------------------------------\n\nTITLE: Cloning the Sample Application Repository\nDESCRIPTION: Git commands to clone the sample code repository for the TiDB and MyBatis integration.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-mybatis.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/tidb-samples/tidb-java-mybatis-quickstart.git\ncd tidb-java-mybatis-quickstart\n```\n\n----------------------------------------\n\nTITLE: HAProxy Reverse Proxy Configuration\nDESCRIPTION: HAProxy configuration for reverse proxying TiDB Dashboard on port 8033\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_3\n\nLANGUAGE: haproxy\nCODE:\n```\nfrontend tidb_dashboard_front\n  bind *:8033\n  use_backend tidb_dashboard_back if { path /dashboard } or { path_beg /dashboard/ }\n\nbackend tidb_dashboard_back\n  mode http\n  server tidb_dashboard 192.168.0.123:2379\n```\n\n----------------------------------------\n\nTITLE: Using /* */ for Block Comments in TiDB SQL\nDESCRIPTION: Shows how to use C-style block comments to add inline comments within a SQL statement. This allows comments to be placed anywhere within a query.\nSOURCE: https://github.com/pingcap/docs/blob/master/comment-syntax.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1 /* this is an in-line comment */ + 1;\n```\n\n----------------------------------------\n\nTITLE: Modifying MAXVALUE of a Sequence\nDESCRIPTION: Example showing how to create a sequence with a specific MAXVALUE and then alter it to a different maximum value. The example includes verification using SHOW CREATE SEQUENCE.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-sequence.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SEQUENCE s2 MAXVALUE=10;\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER SEQUENCE s2 MAXVALUE=100;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE SEQUENCE s2\\G\n```\n\n----------------------------------------\n\nTITLE: Creating Data Source Command\nDESCRIPTION: Command to create a new data source using dmctl with the specified configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-source.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup dmctl --master-addr <master-addr> operate-source create ./source-mysql-01.yaml\n```\n\n----------------------------------------\n\nTITLE: Running the Sample Code to Connect to TiDB\nDESCRIPTION: Command to execute the quickstart script demonstrating TiDB connectivity with Rails.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nbundle exec rails runner ./quickstart.rb\n```\n\n----------------------------------------\n\nTITLE: Displaying Platform-Specific Support Information in Markdown\nDESCRIPTION: This snippet uses custom content blocks to display different support information based on the platform (TiDB or TiDB Cloud). It includes links to community channels and support ticket submission options.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-gui-datagrip.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<CustomContent platform=\"tidb\">\n\nAsk the community on [Discord](https://discord.gg/DQZ2dy3cuc?utm_source=doc) or [Slack](https://slack.tidb.io/invite?team=tidb-community&channel=everyone&ref=pingcap-docs), or [submit a support ticket](/support.md).\n\n</CustomContent>\n\n<CustomContent platform=\"tidb-cloud\">\n\nAsk the community on [Discord](https://discord.gg/DQZ2dy3cuc?utm_source=doc) or [Slack](https://slack.tidb.io/invite?team=tidb-community&channel=everyone&ref=pingcap-docs), or [submit a support ticket](https://tidb.support.pingcap.com/).\n\n</CustomContent>\n```\n\n----------------------------------------\n\nTITLE: Converting Client Key to RSA Format for TiDB Authentication\nDESCRIPTION: Command to ensure the client private key is in the proper RSA format for use in TiDB's TLS client authentication. This writes the RSA key to the specified output file.\nSOURCE: https://github.com/pingcap/docs/blob/master/certificate-authentication.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nsudo openssl rsa -in client-key.pem -out client-key.pem\n```\n\n----------------------------------------\n\nTITLE: Interactive Mode dmctl Command\nDESCRIPTION: Command to enter dmctl interactive mode by connecting to DM-master at specified address. Shows welcome message and available commands.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dmctl-introduction.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./dmctl --master-addr 172.16.30.14:8261\n```\n\n----------------------------------------\n\nTITLE: Installing gh-ost using brew on macOS\nDESCRIPTION: Command to install gh-ost on a macOS system using the Homebrew package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/styles/config/vocabularies/PingCAP/accept.txt#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbrew install gh-ost\n```\n\n----------------------------------------\n\nTITLE: Stopping a Log Backup Task\nDESCRIPTION: This command is used to stop a log backup task. It's typically used before creating a new backup task or when the existing task cannot be resumed due to data loss or corruption beyond the GC safe point window.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n\"br log stop\"\n```\n\n----------------------------------------\n\nTITLE: Modifying Column Charset to UTF8MB4\nDESCRIPTION: Altering table column charset to support 4-byte Unicode characters\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/upgrade-faq.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nalter table t change column a a varchar(100) character set utf8mb4;\n```\n\n----------------------------------------\n\nTITLE: Configuring HAProxy Path-Specific Reverse Proxy for TiDB Dashboard\nDESCRIPTION: HAProxy configuration for proxying TiDB Dashboard under a specific path (/foo/). Includes frontend and backend configuration with path rewriting rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_7\n\nLANGUAGE: haproxy\nCODE:\n```\nfrontend tidb_dashboard_front\n  bind *:8033\n  use_backend tidb_dashboard_back if { path /foo } or { path_beg /foo/ }\n\nbackend tidb_dashboard_back\n  mode http\n  http-request set-path %[path,regsub(^/foo/?,/dashboard/)]\n  server tidb_dashboard 192.168.0.123:2379\n```\n\n----------------------------------------\n\nTITLE: Sample Output of Statement Summary Query in SQL\nDESCRIPTION: This snippet shows an example output of the statement summary query. It displays high-frequency SELECT statements, their execution counts, plan hints, and the corresponding binding statements for optimal execution plans.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\n+---------------------------------------------+------------+-----------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------+\n| query                                       | exec_count | plan_hint                                                                   | binding_stmt                                                                                                            |\n+---------------------------------------------+------------+-----------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------+\n| select * from `t` where `a` = ? and `b` = ? |        401 | use_index(@`sel_1` `test`.`t` `a`), no_order_index(@`sel_1` `test`.`t` `a`) | create global binding from history using plan digest \"0d6e97fb1191bbd08dddefa7bd007ec0c422b1416b152662768f43e64a9958a6\" |\n| select * from `t` where `b` = ? and `c` = ? |        104 | use_index(@`sel_1` `test`.`t` `b`), no_order_index(@`sel_1` `test`.`t` `b`) | create global binding from history using plan digest \"80c2aa0aa7e6d3205755823aa8c6165092c8521fb74c06a9204b8d35fc037dd9\" |\n+---------------------------------------------+------------+-----------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Backing up TiDB data with encryption key in URI\nDESCRIPTION: This command shows how to include the encryption-key parameter in the Azure Blob Storage URI when backing up TiDB data. The key may need to be percent-encoded if it contains reserved characters.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd <pd-address> --storage \"azure://<bucket>/<prefix>?encryption-key=<aes256-key>\"\n```\n\n----------------------------------------\n\nTITLE: Configuring ProxySQL Rules\nDESCRIPTION: Command to apply ProxySQL configuration using the prepare script via the admin interface.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_27\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose exec proxysql sh -c \"mysql -uadmin -padmin -h127.0.0.1 -P6032 < ./proxysql-prepare.sql\"\n```\n\n----------------------------------------\n\nTITLE: Release 7.1 Event Splitting Configuration\nDESCRIPTION: Details compatibility matrix for event splitting in TiDB version 7.1, showing supported protocols and event splitting behavior\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-split-update-behavior.md#2025-04-18_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n| Version | Protocol | Split UK/PK `UPDATE` events | Not split UK/PK `UPDATE` events  | Comments |\n| -- | -- | -- | -- | -- |\n| v7.1.0 | ALL | ✗ | ✓ |  |\n| v7.1.1 | Canal/Open | ✗ | ✓ |  |\n| v7.1.1 | CSV/Avro | ✗ | ✗ | Split but does not sort. See [#9086](https://github.com/pingcap/tiflow/issues/9658) |\n| v7.1.2  ~ v7.1.5 | ALL | ✓ | ✗ |  |\n| \\>= v7.1.6 | ALL | ✓ (Default value: `output-raw-change-event = false`) | ✓ (Optional: `output-raw-change-event = true`)  | |\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Node Labels\nDESCRIPTION: Label configuration for TiKV nodes to enable smart scheduling and ensure proper replica distribution across different physical locations.\nSOURCE: https://github.com/pingcap/docs/blob/master/geo-distributed-deployment-topology.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nconfig:\n  server.labels:\n    zone: bj\n    dc: bja\n    rack: rack1\n    host: host2\n```\n\n----------------------------------------\n\nTITLE: Creating Salesforce Account Table Schema\nDESCRIPTION: SQL command to create the destination table schema in TiDB for storing Salesforce account data.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-aws-appflow-integration.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `sf_account` (\n    `id` varchar(255) NOT NULL,\n    `name` varchar(150) NOT NULL DEFAULT '',\n    `type` varchar(150) NOT NULL DEFAULT '',\n    `billing_state` varchar(255) NOT NULL DEFAULT '',\n    `rating` varchar(255) NOT NULL DEFAULT '',\n    `industry` varchar(255) NOT NULL DEFAULT '',\n    PRIMARY KEY (`id`)\n);\n```\n\n----------------------------------------\n\nTITLE: Binlog Replace Command for Second Shard\nDESCRIPTION: Command to replace the problematic DDL with two equivalent statements for the second MySQL instance's shard_table_1.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nbinlog replace test -s mysql-replica-02 \"ALTER TABLE `shard_db_2`.`shard_table_1` ADD COLUMN `new_col` INT;ALTER TABLE `shard_db_2`.`shard_table_1` ADD UNIQUE(`new_col`)\"\n```\n\n----------------------------------------\n\nTITLE: Installing MySQL Client on Debian-based distros\nDESCRIPTION: This snippet shows the command to install the MySQL command-line client on Debian-based Linux distributions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nsudo apt-get install mysql-client\n```\n\n----------------------------------------\n\nTITLE: Task Status Response Structure\nDESCRIPTION: This JSON structure represents the response when querying the status of a replication task. It includes information about the task's stage, progress, and synchronization details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_35\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"total\": 1,\n  \"data\": [\n    {\n      \"name\": \"string\",\n      \"source_name\": \"string\",\n      \"worker_name\": \"string\",\n      \"stage\": \"running\",\n      \"unit\": \"sync\",\n      \"unresolved_ddl_lock_id\": \"string\",\n      \"load_status\": {\n        \"finished_bytes\": 0,\n        \"total_bytes\": 0,\n        \"progress\": \"string\",\n        \"meta_binlog\": \"string\",\n        \"meta_binlog_gtid\": \"string\"\n      },\n      \"sync_status\": {\n        \"total_events\": 0,\n        \"total_tps\": 0,\n        \"recent_tps\": 0,\n        \"master_binlog\": \"string\",\n        \"master_binlog_gtid\": \"string\",\n        \"syncer_binlog\": \"string\",\n        \"syncer_binlog_gtid\": \"string\",\n        \"blocking_ddls\": [\n          \"string\"\n        ],\n        \"unresolved_groups\": [\n          {\n            \"target\": \"string\",\n            \"ddl_list\": [\n              \"string\"\n            ],\n            \"first_location\": \"string\",\n            \"synced\": [\n              \"string\"\n            ],\n            \"unsynced\": [\n              \"string\"\n            ]\n          }\n        ],\n        \"synced\": true,\n        \"binlog_type\": \"string\",\n        \"seconds_behind_master\": 0\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Removing Operator from Blocklist\nDESCRIPTION: SQL commands to remove the > operator from the blocklist and reload the configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/blocklist-control-plan.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM mysql.expr_pushdown_blacklist WHERE name = '>';\nadmin reload expr_pushdown_blacklist;\n```\n\n----------------------------------------\n\nTITLE: Performing Offline Upgrade of TiDB Cluster in Shell\nDESCRIPTION: This command upgrades the TiDB cluster to a specified version using the offline method. It requires the cluster to be stopped before execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster upgrade <cluster-name> <version> --offline\n```\n\n----------------------------------------\n\nTITLE: Get Current System Time in Microsecond Precision in TiDB\nDESCRIPTION: This snippet illustrates the difference between retrieving current system time in microsecond precision using CURRENT_TIMESTAMP in TiDB versus SYSTIMESTAMP in Oracle.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSYSTIMESTAMP\n```\n\nLANGUAGE: sql\nCODE:\n```\nCURRENT_TIMESTAMP(6)\n```\n\n----------------------------------------\n\nTITLE: TiDB Statement Summary Configuration Parameters (Deleted)\nDESCRIPTION: Configuration parameters related to statement summary tables that have been removed from TiDB. Users now need to use SQL variables to control statement summary tables instead.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nstmt-summary.enable\nstmt-summary.enable-internal-query\nstmt-summary.history-size\nstmt-summary.max-sql-length\nstmt-summary.max-stmt-count\nstmt-summary.refresh-interval\n```\n\n----------------------------------------\n\nTITLE: Installing sync-diff-inspector with TiUP\nDESCRIPTION: Installation command for TiDB v9.0.0 and later versions using TiUP package manager\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/sync-diff-inspector-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup install sync-diff-inspector\n```\n\n----------------------------------------\n\nTITLE: Creating and Granting a Role to a User\nDESCRIPTION: SQL commands demonstrating how to create a role, grant privileges to the role, create a user, and assign the role to the user.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-grant-role.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE ROLE analyticsteam;\nQuery OK, 0 rows affected (0.02 sec)\n\nGRANT SELECT ON test.* TO analyticsteam;\nQuery OK, 0 rows affected (0.02 sec)\n\nCREATE USER jennifer;\nQuery OK, 0 rows affected (0.01 sec)\n\nGRANT analyticsteam TO jennifer;\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Quoting Table Names with Backticks\nDESCRIPTION: Demonstrate how to use backticks to quote table names, especially when they contain special characters or are reserved keywords\nSOURCE: https://github.com/pingcap/docs/blob/master/schema-object-names.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM `table` WHERE `table`.id = 20;\n```\n\n----------------------------------------\n\nTITLE: Setting max-peer-number for balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command sets the maximum number of peers to be solved by the scheduler, preventing it from becoming too slow.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_37\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-hot-region-scheduler set max-peer-number 1000\n```\n\n----------------------------------------\n\nTITLE: Enabling TiDB Distributed Execution Framework (DXF)\nDESCRIPTION: This SQL statement enables the TiDB Distributed eXecution Framework (DXF) globally.  Enabling this allows multiple TiDB nodes to execute the same DDL task in parallel, improving DDL performance. The statement sets the `tidb_enable_dist_task` system variable to `ON`.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.1.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_dist_task = ON;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiCDC in scale-out.yml for TiDB cluster\nDESCRIPTION: YAML configuration for adding TiCDC servers to an existing TiDB cluster. The configuration specifies host addresses, garbage collection TTL, and data directories for two TiCDC servers.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ncdc_servers:\n- host: 10.0.1.3\n  gc-ttl: 86400\n  data_dir: /tidb-data/cdc-8300\n- host: 10.0.1.4\n  gc-ttl: 86400\n  data_dir: /tidb-data/cdc-8300\n```\n\n----------------------------------------\n\nTITLE: Configuring AWS IAM JSON Policy for TiDB Cloud Access\nDESCRIPTION: AWS IAM policy template that defines the necessary permissions for TiDB Cloud to access S3 buckets and KMS encryption. Includes permissions for GetObject, ListBucket, GetBucketLocation, and optional KMS Decrypt operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:GetObjectVersion\"\n            ],\n            \"Resource\": \"arn:aws:s3:::<Your customized directory>\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:ListBucket\",\n                \"s3:GetBucketLocation\"\n            ],\n            \"Resource\": \"<Your S3 bucket ARN>\"\n        }\n        // If you have enabled SSE-KMS for the S3 bucket, you need to add the following permissions.\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"kms:Decrypt\"\n            ],\n            \"Resource\": \"<Your AWS KMS ARN>\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"kms:Decrypt\",\n            \"Resource\": \"<Your AWS KMS ARN>\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring TiCDC Settings in TiKV YAML\nDESCRIPTION: YAML configuration for TiKV TiCDC settings, including Resolved TS interval, memory quotas, and scan speed limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_32\n\nLANGUAGE: yaml\nCODE:\n```\ncdc:\n  min-ts-interval: \"1s\"\n  old-value-cache-memory-quota: 512MiB\n  sink-memory-quota: 512MiB\n  incremental-scan-speed-limit: \"128MiB\"\n  incremental-scan-threads: 4\n```\n\n----------------------------------------\n\nTITLE: Sample Output from MEMORY_USAGE_OPS_HISTORY in TiDB\nDESCRIPTION: Example output showing a terminated session record with memory usage details, including timestamp, memory limits, SQL being executed, and connection information.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-memory-usage-ops-history.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+---------------------+-------------+--------------+----------------+---------------------+------------+------+-----------------+------+------+------------------------------------------------------------------+----------------------------------------------------------------------+\n| TIME                | OPS         | MEMORY_LIMIT | MEMORY_CURRENT | PROCESSID           | MEM        | DISK | CLIENT          | DB   | USER | SQL_DIGEST                                                       | SQL_TEXT                                                             |\n+---------------------+-------------+--------------+----------------+---------------------+------------+------+-----------------+------+------+------------------------------------------------------------------+----------------------------------------------------------------------+\n| 2022-10-17 22:46:25 | SessionKill |  10737418240 |    10880237568 | 6718275530455515543 | 7905028235 |    0 | 127.0.0.1:34394 | test | root | 146b3d812852663a20635fbcf02be01688f52c8d433dafec0d496a14f0b59df6 | desc analyze select * from t t1 join t t2 on t1.a=t2.a order by t1.a |\n+---------------------+-------------+--------------+----------------+---------------------+------------+------+-----------------+------+------+------------------------------------------------------------------+----------------------------------------------------------------------+\n2 rows in set (0.002 sec)\n```\n\n----------------------------------------\n\nTITLE: Exiting TiDB Session\nDESCRIPTION: This SQL command exits the MySQL monitor session, allowing users to cleanly terminate their database interaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/post-installation-check.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nexit\n```\n\n----------------------------------------\n\nTITLE: TiCDC TOML Configuration\nDESCRIPTION: Example of configuring table filters and dispatchers in TiCDC's TOML configuration file\nSOURCE: https://github.com/pingcap/docs/blob/master/table-filter.md#2025-04-18_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[filter]\nrules = ['foo*.*', 'bar*.*']\n\n[[sink.dispatchers]]\nmatcher = ['db1.*', 'db2.*', 'db3.*']\ndispatcher = 'ts'\n```\n\n----------------------------------------\n\nTITLE: FLUSH TABLES Usage Examples in SQL\nDESCRIPTION: Examples of using FLUSH TABLES statements in TiDB, demonstrating both a simple flush operation that executes without effect and an attempted read lock operation that produces an error because table locking is not supported in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flush-tables.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> FLUSH TABLES;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> FLUSH TABLES WITH READ LOCK;\nERROR 1105 (HY000): FLUSH TABLES WITH READ LOCK is not supported.  Please use @@tidb_snapshot\n```\n\n----------------------------------------\n\nTITLE: Converting Date to Timestamp on macOS for Log Backup Operations\nDESCRIPTION: Alternative command for macOS users to convert a date to the required timestamp format. It uses gdate from coreutils instead of the default date command.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-compact-log-backup.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\necho $(( $(gdate --date '2004-05-06 15:02:01Z' +%s%3N) << 18 ))\n```\n\n----------------------------------------\n\nTITLE: Generating Client Code from OpenAPI Specification\nDESCRIPTION: This shell command generates client code using the OpenAPI Specification downloaded earlier. The generated code will be output to the 'gen/api' directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-oas-with-nextjs.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nyarn run openapi-generator-cli generate -i oas/doc.json --generator-name typescript-fetch -o gen/api\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV and RocksDB Parameters in TOML\nDESCRIPTION: This snippet shows key configuration options for TiKV and RocksDB, including log levels, server settings, storage parameters, and RocksDB options. It demonstrates how to set block cache size, configure compaction, and adjust other performance-related parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-tikv-memory-performance.md#2025-04-18_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n# Log level: trace, debug, warn, error, info, off.\nlog-level = \"info\"\n\n[server]\n# Set listening address\n# addr = \"127.0.0.1:20160\"\n\n# Size of thread pool for gRPC\n# grpc-concurrency = 4\n# The number of gRPC connections between each TiKV instance\n# grpc-raft-conn-num = 10\n\n# Most read requests from TiDB are sent to the coprocessor of TiKV. This parameter is used to set the number of threads\n# of the coprocessor. If many read requests exist, add the number of threads and keep the number within that of the\n# system CPU cores. For example, for a 32-core machine deployed with TiKV, you can even set this parameter to 30 in\n# repeatable read scenarios. If this parameter is not set, TiKV automatically sets it to CPU cores * 0.8.\n# end-point-concurrency = 8\n\n# Tag the TiKV instances to schedule replicas.\n# labels = {zone = \"cn-east-1\", host = \"118\", disk = \"ssd\"}\n\n[storage]\n# The data directory\n# data-dir = \"/tmp/tikv/store\"\n\n# In most cases, you can use the default value. When importing data, it is recommended to set the parameter to 1024000.\n# scheduler-concurrency = 102400\n# This parameter controls the number of write threads. When write operations occur frequently, set this parameter value\n# higher. Run `top -H -p tikv-pid` and if the threads named `sched-worker-pool` are busy, set the value of parameter\n# `scheduler-worker-pool-size` higher and increase the number of write threads.\n# scheduler-worker-pool-size = 4\n\n[storage.block-cache]\n## Whether to create a shared block cache for all RocksDB column families.\n##\n## Block cache is used by RocksDB to cache uncompressed blocks. Big block cache can speed up read.\n## It is recommended to turn on shared block cache. Since only the total cache size need to be\n## set, it is easier to configure. In most cases, it should be able to auto-balance cache usage\n## between column families with standard LRU algorithm.\n##\n## The rest of config in the storage.block-cache session is effective only when shared block cache\n## is on.\n## Starting from v6.6.0, the `shared` option is always enabled and cannot be disabled.\n# shared = true\n\n## Size of the shared block cache. Normally it should be tuned to 30%-50% of system's total memory.\n## When the config is not set, it is decided by the sum of the following fields or their default\n## value:\n##   * rocksdb.defaultcf.block-cache-size or 25% of system's total memory\n##   * rocksdb.writecf.block-cache-size   or 15% of system's total memory\n##   * rocksdb.lockcf.block-cache-size    or  2% of system's total memory\n##   * raftdb.defaultcf.block-cache-size  or  2% of system's total memory\n##\n## To deploy multiple TiKV nodes on a single physical machine, configure this parameter explicitly.\n## Otherwise, the OOM problem might occur in TiKV.\n# capacity = \"1GiB\"\n\n[pd]\n# PD address\n# endpoints = [\"127.0.0.1:2379\",\"127.0.0.2:2379\",\"127.0.0.3:2379\"]\n\n[metric]\n# The interval of pushing metrics to Prometheus Pushgateway\ninterval = \"15s\"\n# Prometheus Pushgateway address\naddress = \"\"\njob = \"tikv\"\n\n[raftstore]\n# Raft RocksDB directory. The default value is Raft subdirectory of [storage.data-dir].\n# If there are multiple disks on the machine, store the data of Raft RocksDB on different disks to improve TiKV performance.\n# raftdb-path = \"/tmp/tikv/store/raft\"\n\n# When the data size change in a Region is larger than the threshold value, TiKV checks whether this Region needs split.\n# To reduce the costs of scanning data in the checking process, set the value to 32 MiB during the data import process. In the normal operation status, set it to the default value.\nregion-split-check-diff = \"32MiB\"\n\n[coprocessor]\n## If the size of a Region with the range of [a,e) is larger than the value of `region_max_size`, TiKV tries to split the Region to several Regions, for example, the Regions with the ranges of [a,b), [b,c), [c,d), and [d,e).\n## After the Region split, the size of the split Regions is equal to the value of `region_split_size` (or slightly larger than the value of `region_split_size`).\n# region-max-size = \"144MiB\"\n# region-split-size = \"96MiB\"\n\n[rocksdb]\n# The maximum number of threads of RocksDB background tasks. The background tasks include compaction and flush.\n# For detailed information why RocksDB needs to implement compaction, see RocksDB-related materials. When write\n# traffic (like the importing data size) is big, it is recommended to enable more threads. But set the number of the enabled\n# threads smaller than that of CPU cores. For example, when importing data, for a machine with a 32-core CPU,\n# set the value to 28.\n# max-background-jobs = 8\n\n# The maximum number of file handles RocksDB can open\n# max-open-files = 40960\n\n# The file size limit of RocksDB MANIFEST. For more details, see https://github.com/facebook/rocksdb/wiki/MANIFEST\nmax-manifest-file-size = \"20MiB\"\n\n# The directory of RocksDB write-ahead logs. If there are two disks on the machine, store the RocksDB data and WAL logs\n# on different disks to improve TiKV performance.\n# wal-dir = \"/tmp/tikv/store\"\n\n# Use the following two parameters to deal with RocksDB archiving WAL.\n# For more details, see https://github.com/facebook/rocksdb/wiki/How-to-persist-in-memory-RocksDB-database%3F\n# wal-ttl-seconds = 0\n# wal-size-limit = 0\n\n# In most cases, set the maximum total size of RocksDB WAL logs to the default value.\n# max-total-wal-size = \"4GiB\"\n\n# Use this parameter to enable the readahead feature during RocksDB compaction. If you are using mechanical disks, it is recommended to set the value to 2MiB at least.\n# compaction-readahead-size = \"2MiB\"\n\n[rocksdb.defaultcf]\n# The data block size. RocksDB compresses data based on the unit of block.\n# Similar to page in other databases, block is the smallest unit cached in block-cache.\nblock-size = \"64KB\"\n\n# The compaction mode of each layer of RocksDB data. The optional values include no, snappy, zlib,\n# bzip2, lz4, lz4hc, and zstd. Note that the Snappy compressed file must be in the [official Snappy format](https://github.com/google/snappy). Other variants of Snappy compression are not supported.\n# \"no:no:lz4:lz4:lz4:zstd:zstd\" indicates there is no compaction of level0 and level1; lz4 compaction algorithm is used\n# from level2 to level4; zstd compaction algorithm is used from level5 to level6.\n# \"no\" means no compaction. \"lz4\" is a compaction algorithm with moderate speed and compaction ratio. The\n# compaction ratio of zlib is high. It is friendly to the storage space, but its compaction speed is slow. This\n# compaction occupies many CPU resources. Different machines deploy compaction modes according to CPU and I/O resources.\n# For example, if you use the compaction mode of \"no:no:lz4:lz4:lz4:zstd:zstd\" and find much I/O pressure of the\n# system (run the iostat command to find %util lasts 100%, or run the top command to find many iowaits) when writing\n# (importing) a lot of data while the CPU resources are adequate, you can compress level0 and level1 and exchange CPU\n# resources for I/O resources. If you use the compaction mode of \"no:no:lz4:lz4:lz4:zstd:zstd\" and you find the I/O\n# pressure of the system is not big when writing a lot of data, but CPU resources are inadequate. Then run the top\n# command and choose the -H option. If you find a lot of bg threads (namely the compaction thread of RocksDB) are\n# running, you can exchange I/O resources for CPU resources and change the compaction mode to \"no:no:no:lz4:lz4:zstd:zstd\".\n# In a word, it aims at making full use of the existing resources of the system and improving TiKV performance\n```\n\n----------------------------------------\n\nTITLE: Truncating Old TiDB Log Backups\nDESCRIPTION: Removes log backup data older than a specified timestamp to maintain storage efficiency.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-guide.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log truncate --until=${FULL_BACKUP_TS} --storage='s3://backup-101/logbackup?access-key=${access-key}&secret-access-key=${secret-access-key}'\n```\n\n----------------------------------------\n\nTITLE: Querying Cache Hit Rate with EXPLAIN ANALYZE in TiDB\nDESCRIPTION: Example SQL query using EXPLAIN ANALYZE to view the Coprocessor Cache hit rate information in TiDB. The execution info shows details like cache hit ratio, processing time, and memory usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/coprocessor-cache.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT * FROM t USE INDEX(a);\n```\n\n----------------------------------------\n\nTITLE: Verifying TiKV Certificate SAN Field\nDESCRIPTION: Command to display the contents of the TiKV certificate, including the Subject Alternative Name (SAN) field for verification.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nopenssl x509 -text -in tikv.crt -noout\n```\n\n----------------------------------------\n\nTITLE: Verifying Default Role Permissions\nDESCRIPTION: SQL commands showing the effect of setting default role on user permissions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-default-role.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS;\n+---------------------------------------------+\n| Grants for User                             |\n+---------------------------------------------+\n| GRANT USAGE ON *.* TO 'jennifer'@'%'        |\n| GRANT Select ON test.* TO 'jennifer'@'%'    |\n| GRANT 'analyticsteam'@'%' TO 'jennifer'@'%' |\n+---------------------------------------------+\n3 rows in set (0.00 sec)\n\nSHOW TABLES IN test;\n+----------------+\n| Tables_in_test |\n+----------------+\n| t1             |\n+----------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Inefficient Date Formatting in SQL WHERE Clause\nDESCRIPTION: Demonstrates an inefficient way of using a function on a field in the WHERE clause, which can lead to index failure.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sql-development-specification.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT gmt_create\nFROM ...\nWHERE DATE_FORMAT(gmt_create, '%Y%m%d %H:%i:%s') = '20090101 00:00:00'\n```\n\n----------------------------------------\n\nTITLE: Setting TiDB Replica Read System Variable\nDESCRIPTION: Shows how to use the tidb_replica_read system variable to enable reading data from follower nodes in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.1.0-beta.2.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_replica_read = 'follower';\n```\n\n----------------------------------------\n\nTITLE: Fixing Statement Summary TABLE_NAMES Column in TiDB\nDESCRIPTION: Corrects incorrect values in the TABLE_NAMES column of the Statement Summary.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.STATEMENTS_SUMMARY\n```\n\n----------------------------------------\n\nTITLE: Deleting a TiDB Cloud Backup\nDESCRIPTION: Terminal output showing how to delete a backup using the terraform destroy command, which removes the backup resource.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-backup-resource.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform destroy\n\nPlan: 0 to add, 0 to change, 1 to destroy.\n\nDo you really want to destroy all resources?\nTerraform will destroy all your managed infrastructure, as shown above.\nThere is no undo. Only 'yes' will be accepted to confirm.\n\nEnter a value: yes\n```\n\n----------------------------------------\n\nTITLE: Installing SQLAlchemy for Python\nDESCRIPTION: Command to install SQLAlchemy version 1.4.44 using pip. This version or later is recommended for use with TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-choose-driver-or-orm.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npip install SQLAlchemy==1.4.44\n```\n\n----------------------------------------\n\nTITLE: Enabling Accelerated Table Creation in TiDB\nDESCRIPTION: Sets the global system variable tidb_enable_fast_create_table to ON to enable performance optimization for creating tables. This allows table creation statements with the same schema to be merged into batches.\nSOURCE: https://github.com/pingcap/docs/blob/master/accelerated-table-creation.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_fast_create_table = ON;\n```\n\n----------------------------------------\n\nTITLE: DROP PLACEMENT POLICY Usage Example\nDESCRIPTION: Demonstrates the complete workflow of creating a placement policy, applying it to a table, attempting to drop it while in use, checking references, removing the policy from the table, and finally successfully dropping it.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-placement-policy.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY p1 FOLLOWERS=4;\nCREATE TABLE t1 (a INT PRIMARY KEY) PLACEMENT POLICY=p1;\nDROP PLACEMENT POLICY p1;  -- This statement fails because the placement policy p1 is referenced.\n\n-- Finds which tables and partitions reference the placement policy.\nSELECT table_schema, table_name FROM information_schema.tables WHERE tidb_placement_policy_name='p1';\nSELECT table_schema, table_name FROM information_schema.partitions WHERE tidb_placement_policy_name='p1';\n\nALTER TABLE t1 PLACEMENT POLICY=default;  -- Removes the placement policy from t1.\nDROP PLACEMENT POLICY p1;  -- Succeeds.\n```\n\n----------------------------------------\n\nTITLE: Implementing Optimistic Transactions in Python\nDESCRIPTION: This Python snippet demonstrates the implementation of optimistic transactions for a book purchase operation. It includes functions for creating database connections, preparing data, and executing buy operations with retry logic for handling transaction conflicts.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nimport time\nimport MySQLdb\nimport os\nimport datetime\nfrom threading import Thread\n\nREPEATABLE_ERROR_CODE_SET = {\n    9007,  # Transactions in TiKV encounter write conflicts.\n    8028,  # table schema changes\n    8002,  # \"SELECT FOR UPDATE\" commit conflict\n    8022   # The transaction commit fails and has been rolled back\n}\n\ndef create_connection():\n    return MySQLdb.connect(\n        host=\"127.0.0.1\",\n        port=4000,\n        user=\"root\",\n        password=\"\",\n        database=\"bookshop\",\n        autocommit=False\n    )\n\ndef prepare_data() -> None:\n    connection = create_connection()\n    with connection:\n        with connection.cursor() as cursor:\n            cursor.execute(\"INSERT INTO `books` (`id`, `title`, `type`, `published_at`, `price`, `stock`) \"\n                           \"values (%s, %s, %s, %s, %s, %s)\",\n                           (1, \"Designing Data-Intensive Application\", \"Science & Technology\",\n                            datetime.datetime(2018, 9, 1), 100, 10))\n\n            cursor.executemany(\"INSERT INTO `users` (`id`, `nickname`, `balance`) VALUES (%s, %s, %s)\",\n                               [(1, \"Bob\", 10000), (2, \"ALICE\", 10000)])\n            connection.commit()\n\ndef buy_optimistic(thread_id: int, order_id: int, book_id: int, user_id: int, amount: int,\n                   optimistic_retry_times: int = 5) -> None:\n    connection = create_connection()\n\n    txn_log_header = f\"/* txn {thread_id} */\"\n    if thread_id != 1:\n        txn_log_header = \"\\t\" + txn_log_header\n\n    with connection:\n        with connection.cursor() as cursor:\n            cursor.execute(\"BEGIN OPTIMISTIC\")\n            print(f'{txn_log_header} BEGIN OPTIMISTIC')\n            time.sleep(1)\n\n            try:\n                # read the price of book\n                select_book_for_update = \"SELECT `price`, `stock` FROM books WHERE id = %s FOR UPDATE\"\n                cursor.execute(select_book_for_update, (book_id,))\n                # ... (rest of the implementation)\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up TPC-C Test Data\nDESCRIPTION: Command to remove all test data from the TiDB cluster after completing the TPC-C benchmark test.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-tpcc.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup bench tpcc -H 172.16.5.140 -P 4000 -D tpcc --warehouses 4 cleanup\n```\n\n----------------------------------------\n\nTITLE: Configuring SQL File for Data App Endpoint\nDESCRIPTION: Example SQL file with parameter usage for an endpoint. The SQL statement queries the sample_data database and uses a parameter placeholder for filtering data by country.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-app-config-files.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n/* Getting Started:\nEnter \"USE {database};\" before entering your SQL statements.\nType \"--your question\" + Enter to try out AI-generated SQL queries in the TiDB Cloud console.\nDeclare a parameter like \"Where id = ${arg}\".\n*/\nUSE sample_data;\nSELECT\n  rank,\n  company_name,\nFROM\n  global_fortune_500_2018_2022\nWHERE\n  country = ${country};\n```\n\n----------------------------------------\n\nTITLE: Dropping Global Temporary Table in SQL\nDESCRIPTION: SQL statement to manually drop a global temporary table.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nDROP GLOBAL TEMPORARY TABLE top_50_eldest_authors_global;\n```\n\n----------------------------------------\n\nTITLE: Disabling Automatic Collection of Execution Information\nDESCRIPTION: SQL statement to disable the automatic collection of execution information for operators, which can be useful when conducting performance tests to reduce overhead.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nset @@tidb_enable_collect_execution_info=0;\n```\n\n----------------------------------------\n\nTITLE: Setting TiDB Cloud CLI Configuration\nDESCRIPTION: This command sets a configuration property for the active user profile in the TiDB Cloud CLI. It requires a property name and value, and can optionally use flags for specific profiles.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-set.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud config set <property-name> <value> [flags]\n```\n\n----------------------------------------\n\nTITLE: Region Properties with tikv-ctl Shell\nDESCRIPTION: This shell snippet shows how to view Region properties using tikv-ctl. It can be used to check the health of a Region by measuring statistics like num_files, num_entries, and mvcc-related metrics. Dependencies require a specific region id and either a data directory or a host address.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --host localhost:20160 region-properties -r 2\n```\n\nLANGUAGE: shell\nCODE:\n```\nnum_files: 0\nnum_entries: 0\nnum_deletes: 0\nmvcc.min_ts: 18446744073709551615\nmvcc.max_ts: 0\nmvcc.num_rows: 0\nmvcc.num_puts: 0\nmvcc.num_versions: 0\nmvcc.max_row_versions: 0\nmiddle_key_by_approximate_size:\n```\n\n----------------------------------------\n\nTITLE: Parsing TSO Using PD Control Tool\nDESCRIPTION: This snippet shows how to parse a TSO timestamp using the PD control tool via the TiUP package manager, which displays both the physical timestamp (system time) and the logical component.\nSOURCE: https://github.com/pingcap/docs/blob/master/tso.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ tiup ctl:v7.1.0 pd tso 443852055297916932\n```\n\n----------------------------------------\n\nTITLE: Querying CHECK_CONSTRAINTS Table Structure\nDESCRIPTION: Shows how to view the structure of the CHECK_CONSTRAINTS table in the INFORMATION_SCHEMA database.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-check-constraints.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC CHECK_CONSTRAINTS;\n```\n\n----------------------------------------\n\nTITLE: Setting Up a Custom Repository with Key Generation\nDESCRIPTION: Creates a test repository, generates keys, sets the repository location, and grants the current user access.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ tiup mirror init /tmp/m\n$ tiup mirror genkey\n$ tiup mirror set /tmp/m\n$ tiup mirror grant $USER\n```\n\n----------------------------------------\n\nTITLE: Enabling Active PD Follower via System Variable\nDESCRIPTION: Code snippet showing how to enable the Active PD Follower feature in TiDB 7.6.0 by setting the system variable 'pd_enable_follower_handle_region' to 'ON'. This configuration allows PD followers to handle Region information requests, reducing CPU pressure on the PD leader.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.6.0.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\npd_enable_follower_handle_region\n```\n\n----------------------------------------\n\nTITLE: Analyzing Tables for TiDB Optimizer\nDESCRIPTION: These SQL statements collect statistics for various tables in the `tpcc` database. This helps the TiDB optimizer generate optimal execution plans for queries, thus improving the performance of the TPC-C test.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE customer;\nANALYZE TABLE district;\nANALYZE TABLE history;\nANALYZE TABLE item;\nANALYZE TABLE new_order;\nANALYZE TABLE order_line;\nANALYZE TABLE orders;\nANALYZE TABLE stock;\nANALYZE TABLE warehouse;\n```\n\n----------------------------------------\n\nTITLE: Forcing Delta Layer Merge for Vector Indexing in TiDB\nDESCRIPTION: This SQL command forces the merge of the Delta layer into the Stable layer, allowing all data to be indexed for optimal vector search performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-index.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE <TABLE_NAME> COMPACT;\n```\n\n----------------------------------------\n\nTITLE: Vector Table Schema Definition\nDESCRIPTION: SQLAlchemy model definition for document storage with vector embeddings.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-jinaai-embedding.md#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom sqlalchemy import Column, Integer, String, create_engine\nfrom sqlalchemy.orm import declarative_base\n\nBase = declarative_base()\n\nclass Document(Base):\n    __tablename__ = \"jinaai_tidb_demo_documents\"\n\n    id = Column(Integer, primary_key=True)\n    content = Column(String(255), nullable=False)\n    content_vec = Column(\n        # DIMENSIONS is determined by the embedding model,\n        # for Jina AI's jina-embeddings-v2-base-en model it's 768.\n        VectorType(dim=768),\n        comment=\"hnsw(distance=cosine)\"\n```\n\n----------------------------------------\n\nTITLE: Restoring Single Table Using BR\nDESCRIPTION: Command to restore a specific table from backup data using BR. Uses the tiup br restore table command with PD endpoint, database name, table name, and S3 storage location parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-guide.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore table --pd \"${PD_IP}:2379\" \\\n--db \"test\" \\\n--table \"usertable\" \\\n--storage \"s3://backup-101/snapshot-202209081330?access-key=${access-key}&secret-access-key=${secret-access-key}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TPC-H DBGEN Format in TOML for TiDB Lightning\nDESCRIPTION: TOML configuration for parsing TPC-H DBGEN formatted files in TiDB Lightning, using pipe separator and specific terminator.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\n[mydumper.csv]\nseparator = '|'\ndelimiter = ''\nterminator = \"|\\n\"\nheader = false\nnot-null = true\nbackslash-escape = false\n```\n\n----------------------------------------\n\nTITLE: Clean Up TPC-C Data with TiUP Bench (Bash)\nDESCRIPTION: This command cleans up the data associated with a TPC-C benchmark with 4 warehouses.  It employs the `cleanup` subcommand of the TiUP bench tpcc component to remove the benchmark data from the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench tpcc --warehouses 4 cleanup\n```\n\n----------------------------------------\n\nTITLE: Enabling GC in Compaction Filter in TiKV Configuration\nDESCRIPTION: TOML configuration to enable the GC in Compaction Filter mechanism in TiKV. This uses RocksDB's compaction process for GC instead of a separate worker thread.\nSOURCE: https://github.com/pingcap/docs/blob/master/garbage-collection-configuration.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[gc]\nenable-compaction-filter = true\n```\n\n----------------------------------------\n\nTITLE: Successful Execution Result Format\nDESCRIPTION: Example showing the output format when a non-transactional DML statement executes successfully, displaying the number of jobs and their status.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\n+----------------+---------------+\n| number of jobs | job status    |\n+----------------+---------------+\n| 0              | all succeeded |\n+----------------+---------------+\n```\n\n----------------------------------------\n\nTITLE: Running Another Snapshot Backup in TiDB with Different Timestamp\nDESCRIPTION: Command to execute a snapshot (full) backup with a specified backup timestamp of May 16, 2022.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-use-cases.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd=\"${PD_IP}:2379\" \\\n--storage='s3://tidb-pitr-bucket/backup-data/snapshot-20220516000000' \\\n--backupts='2022/05/16 00:00:00 +08:00'\n```\n\n----------------------------------------\n\nTITLE: Searching Relevant Regions for Data Restoration in TiKV\nDESCRIPTION: This command helps identify relevant Regions based on the replicas that are down, simplifying data recovery efforts.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_68\n\nLANGUAGE: bash\nCODE:\n```\nregion --jq=\".regions[] | {id: .id, peer_stores: [.peers[].store_id] | select(length as $total | map(if .==(1,30,31) then . else empty end) | length>=$total-length)}\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nregion --jq=\".regions[] | {id: .id, peer_stores: [.peers[].store_id] | select(length>1 and any(.==1) and all(.!=(30,31)))}\"\n```\n\n----------------------------------------\n\nTITLE: Performance Tuning Configuration for Logical Import Mode\nDESCRIPTION: Configuration for adjusting write concurrency and performance settings in TiDB Lightning's logical import mode, including region-concurrency settings\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-logical-import-mode-usage.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\nregion-concurrency = 32\n```\n\n----------------------------------------\n\nTITLE: DROP VIEW Syntax in EBNF Notation\nDESCRIPTION: The formal syntax definition for the DROP VIEW statement in Extended Backus-Naur Form (EBNF). It shows the structure of the command including optional IF EXISTS clause and the ability to drop multiple views.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-view.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDropViewStmt ::=\n    'DROP' 'VIEW' ( 'IF' 'EXISTS' )? TableNameList RestrictOrCascadeOpt\n\nTableNameList ::=\n    TableName ( ',' TableName )*\n\nTableName ::=\n    Identifier ('.' Identifier)?\n```\n\n----------------------------------------\n\nTITLE: Creating Users with Descriptions in TiDB\nDESCRIPTION: This SQL snippet demonstrates how to create database users in TiDB v6.4.0 with additional descriptions using COMMENT and ATTRIBUTE. This compatibility feature enhances integration with MySQL tools and platforms.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.4.0.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser1'@'%' COMMENT 'This user is created only for test';\nCREATE USER 'newuser2'@'%' ATTRIBUTE '{\"email\": \"user@pingcap.com\"}';\nSELECT * FROM INFORMATION_SCHEMA.USER_ATTRIBUTES;\n```\n\n----------------------------------------\n\nTITLE: Optimize TiKV Network Configuration\nDESCRIPTION: This code snippet modifies TiKV parameters to optimize network configuration for a TiKV node in a remote region (San Francisco) and reduce its likelihood of participating in Raft elections. This helps minimize cross-region network latency impact.\nSOURCE: https://github.com/pingcap/docs/blob/master/three-data-centers-in-two-cities-deployment.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n\"raftstore.raft-min-election-timeout-ticks: 50\\nraftstore.raft-max-election-timeout-ticks: 60\"\n```\n\n----------------------------------------\n\nTITLE: Describing CLUSTER_HARDWARE Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the CLUSTER_HARDWARE table in the information_schema database, showing the fields, their types, and other attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-hardware.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC cluster_hardware;\n```\n\n----------------------------------------\n\nTITLE: Forcing Component Update\nDESCRIPTION: Force update a component even if the specified version is already installed, using the --force flag\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-update.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup update [component] --force\n```\n\n----------------------------------------\n\nTITLE: PD TSO Request Handler Duration Alert Query\nDESCRIPTION: PromQL query to monitor PD's TSO request handling duration using the 99th percentile\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_9\n\nLANGUAGE: promql\nCODE:\n```\nhistogram_quantile(0.99, sum(rate(pd_client_request_handle_requests_duration_seconds_bucket{type=\"tso\"}[1m])) by (instance, job, le)) > 0.1\n```\n\n----------------------------------------\n\nTITLE: TiUP Cluster Update Commands\nDESCRIPTION: Commands to update TiUP and cluster components to latest version\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup update --self\ntiup update cluster --force\n```\n\n----------------------------------------\n\nTITLE: Configuring Downstream TiDB Cluster for DM Task in YAML\nDESCRIPTION: This YAML snippet demonstrates how to configure the target TiDB cluster for a DM task. It includes connection details like host, port, user, and password for the downstream database.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-task-configuration-guide.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n---\n\n## ********* Basic configuration *********\nname: test             # The name of the task. Should be globally unique.\n\n## ******** Data source configuration **********\nmysql-instances:\n  - source-id: \"mysql-replica-01\"  # Migrate data from the data source whose `source-id` is `mysql-replica-01`.\n  - source-id: \"mysql-replica-02\"  # Migrate data from the data source whose `source-id` is `mysql-replica-02`.\n\n## ******** Downstream TiDB database configuration **********\ntarget-database:       # Configuration of target TiDB database.\n  host: \"127.0.0.1\"\n  port: 4000\n  user: \"root\"\n  password: \"\"         # If the password is not null, it is recommended to use a password encrypted with dmctl.\n```\n\n----------------------------------------\n\nTITLE: Querying Authors Older Than Gender-Specific Average Age Using Correlated Subquery in SQL\nDESCRIPTION: This SQL query selects authors who are older than the average age of other authors of the same gender. It uses a correlated subquery, which TiDB will attempt to decorrelate for better performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-subqueries.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM authors a1 WHERE (IFNULL(a1.death_year, YEAR(NOW())) - a1.birth_year) > (\n    SELECT\n        AVG(\n            IFNULL(a2.death_year, YEAR(NOW())) - IFNULL(a2.birth_year, YEAR(NOW()))\n        ) AS average_age\n    FROM\n        authors a2\n    WHERE a1.gender = a2.gender\n);\n```\n\n----------------------------------------\n\nTITLE: RocksDB Write Buffer Configuration Parameters\nDESCRIPTION: Settings for write buffer management including memtable configuration and level-based parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_16\n\nLANGUAGE: yaml\nCODE:\n```\nwrite-buffer-size:\n  defaultcf: \"128MiB\"\n  writecf: \"128MiB\"\n  lockcf: \"32MiB\"\n\nmax-write-buffer-number: 5\nmin-write-buffer-number-to-merge: 1\nmax-bytes-for-level-base: \"512MiB\"\n```\n\n----------------------------------------\n\nTITLE: Setting Global Dynamic Pruning Mode\nDESCRIPTION: Enables dynamic pruning mode globally for all SQL statements and auto-analyze operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_74\n\nLANGUAGE: sql\nCODE:\n```\nset global tidb_partition_prune_mode = dynamic\n```\n\n----------------------------------------\n\nTITLE: Execution Plan for json_contains with AND\nDESCRIPTION: Detailed execution plan showing how TiDB uses IndexMerge intersection for json_contains conditions connected with AND.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\n> EXPLAIN SELECT /*+ use_index_merge(t4, mvi1, mvi2) */ * FROM t4 WHERE json_contains(j->'$.a', '[1]') AND json_contains(j->'$.b', '[2, 3]');\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------+---------------------------------------------+\n| id                            | estRows | task      | access object                                                               | operator info                               |\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------+---------------------------------------------+\n| IndexMerge_9                  | 0.00    | root      |                                                                             | type: intersection                          |\n| ├─IndexRangeScan_5(Build)     | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[1,1], keep order:false, stats:pseudo |\n| ├─IndexRangeScan_6(Build)     | 10.00   | cop[tikv] | table:t4, index:mvi2(cast(json_extract(`j`, _utf8'$.b') as unsigned array)) | range:[2,2], keep order:false, stats:pseudo |\n| ├─IndexRangeScan_7(Build)     | 10.00   | cop[tikv] | table:t4, index:mvi2(cast(json_extract(`j`, _utf8'$.b') as unsigned array)) | range:[3,3], keep order:false, stats:pseudo |\n| └─TableRowIDScan_8(Probe)     | 0.00    | cop[tikv] | table:t4                                                                    | keep order:false, stats:pseudo              |\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------+---------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Configuring Grafana\nDESCRIPTION: Grafana configuration file setup including paths, server settings, security, and logging configurations\nSOURCE: https://github.com/pingcap/docs/blob/master/deploy-monitoring-services.md#2025-04-18_snippet_4\n\nLANGUAGE: ini\nCODE:\n```\n[paths]\ndata = ./data\nlogs = ./data/log\nplugins = ./data/plugins\n[server]\nhttp_port = 3000\ndomain = 192.168.199.113\n[database]\n[session]\n[analytics]\ncheck_for_updates = true\n[security]\nadmin_user = admin\nadmin_password = admin\n[snapshots]\n[users]\n[auth.anonymous]\n[auth.basic]\n[auth.ldap]\n[smtp]\n[emails]\n[log]\nmode = file\n[log.console]\n[log.file]\nlevel = info\nformat = text\n[log.syslog]\n[event_publisher]\n[dashboards.json]\nenabled = false\npath = ./data/dashboards\n[metrics]\n[grafana_net]\nurl = https://grafana.net\n```\n\n----------------------------------------\n\nTITLE: Checking Placement Rules Configuration with pd-ctl\nDESCRIPTION: Shell command to verify the current replication configuration status using pd-ctl tool, checking if Placement Rules are enabled\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\necho 'config show replication' | /path/to/pd-ctl -u http://<pd-ip>:<pd-port>\n```\n\n----------------------------------------\n\nTITLE: Using alias command for ticloud serverless import describe in Shell\nDESCRIPTION: An alternative command that serves the same purpose as 'ticloud serverless import describe'. It can be used interchangeably.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-describe.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import get [flags]\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud Serverless Cluster with Cluster ID and Password\nDESCRIPTION: This snippet demonstrates connecting to a TiDB Cloud Serverless cluster using the cluster ID and password in non-interactive mode. The `-c` flag specifies the cluster ID, and `--password` specifies the password.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-shell.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless shell -c <cluster-id> --password <password>\n```\n\n----------------------------------------\n\nTITLE: Configuring Sign-in Redirect URI for SSO\nDESCRIPTION: URI format for configuring the sign-in redirect in SSO providers. Replace DASHBOARD_IP:PORT with actual TiDB Dashboard access details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-session-sso.md#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nhttp://DASHBOARD_IP:PORT/dashboard/?sso_callback=1\n```\n\n----------------------------------------\n\nTITLE: Configuring Prometheus Scrape Configuration in YAML\nDESCRIPTION: Add TiDB Lightning server address to Prometheus scrape configuration for metrics discovery and collection\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/monitor-tidb-lightning.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nscrape_configs:\\n  - job_name: 'tidb-lightning'\\n    static_configs:\\n      - targets: ['192.168.20.10:8289']\n```\n\n----------------------------------------\n\nTITLE: Configuring Balance Leader Scheduler in TiDB\nDESCRIPTION: This command demonstrates how to set the batch size for the balance-leader scheduler, which controls the speed of task processing. It's available since TiDB v6.0.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_31\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-leader-scheduler set batch 3 // Set the size of the operator that the balance-leader scheduler can execute in a batch to 3\n```\n\n----------------------------------------\n\nTITLE: Logging into TiDB Cloud via CLI\nDESCRIPTION: This snippet shows the command to log into TiDB Cloud using the TiDB Cloud CLI, which assigns an OAuth token to the user profile.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nticloud auth login\n```\n\n----------------------------------------\n\nTITLE: Preserving precision in integer to unsigned float/decimal conversion\nDESCRIPTION: Fixes data inaccuracy caused by precision loss when converting integers to unsigned floating point or decimal types.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.7.md#2025-04-18_snippet_3\n\nLANGUAGE: Go\nCODE:\n```\n[#13755](https://github.com/pingcap/tidb/pull/13755)\n```\n\n----------------------------------------\n\nTITLE: Cloning TiDB-ProxySQL Integration Repository\nDESCRIPTION: Git command to clone the repository containing example code for TiDB and ProxySQL integration.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/pingcap-inc/tidb-proxysql-integration.git\n```\n\n----------------------------------------\n\nTITLE: Importing TPC-C Data Using go-tpc\nDESCRIPTION: This shell command imports TPC-C data into the `tpcc` database using the `go-tpc tpcc` tool. It populates the database with 1000 warehouses and allows configuring threads, host, password, and other parameters. `${HOST}`, `${THREAD}`, and `${PASSWORD}` need to be replaced by actual values.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ngo-tpc tpcc --host ${HOST} --warehouses 1000 prepare -P 4000 -D tpcc -T ${THREAD} --time 2h0m0s -p ${PASSWORD} --ignore-error\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Containers\nDESCRIPTION: Commands to stop and remove the Docker containers and return to the previous directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_30\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose down\ncd -\n```\n\n----------------------------------------\n\nTITLE: Defining Warning Alert Rule for TiCDC Processor Exit with Error in YAML\nDESCRIPTION: YAML configuration for a warning alert rule that triggers when a TiCDC replication task reports an error and exits.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-alert-rules.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nchanges(ticdc_processor_exit_with_error_count[1m]) > 0\n```\n\n----------------------------------------\n\nTITLE: Accessing TiDB Prometheus Metrics\nDESCRIPTION: HTTP endpoint format for accessing Prometheus metrics from TiDB server's status port.\nSOURCE: https://github.com/pingcap/docs/blob/master/command-line-flags-for-tidb-configuration.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nhttp://host:status_port/metrics\n```\n\n----------------------------------------\n\nTITLE: Fixing LOAD DATA Statement Compatibility in TiDB\nDESCRIPTION: Addresses incompatibility with MySQL in the LOAD DATA statement when encountering backslashes.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nLOAD DATA INFILE 'file.csv' INTO TABLE table_name\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB as Root\nDESCRIPTION: Shell command showing how to connect to a TiDB server as the root user.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-grant-role.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 127.0.0.1 -P 4000 -u root\n```\n\n----------------------------------------\n\nTITLE: Retrieving First N DDL Job Queries Example\nDESCRIPTION: This example shows how to retrieve the first 3 DDL job queries from the history. The output includes job IDs and the corresponding SQL statements that created those jobs.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW DDL JOB QUERIES LIMIT 3;  # Retrieve first 3 rows\n+--------+--------------------------------------------------------------+\n| JOB_ID | QUERY                                                        |\n+--------+--------------------------------------------------------------+\n|     59 | ALTER TABLE t1 ADD INDEX index2 (col2)                       |\n|     60 | ALTER TABLE t2 ADD INDEX index1 (col1)                       |\n|     58 | CREATE TABLE t2 (id INT NOT NULL PRIMARY KEY auto_increment) |\n+--------+--------------------------------------------------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Converting Date to Timestamp for Log Backup Operations\nDESCRIPTION: Command to convert a specific date and time to a timestamp format required for log backup operations. The command shifts the Unix timestamp (in milliseconds) left by 18 bits.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-compact-log-backup.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\necho $(( $(date --date '2004-05-06 15:02:01Z' +%s%3N) << 18 ))\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into TiDB Table\nDESCRIPTION: This SQL command inserts a new record into the 'tab_tidb' table, demonstrating how to add data entries in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/post-installation-check.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\ninsert into `tab_tidb` values (1,'TiDB',5,'TiDB-v5.0.0');\n```\n\n----------------------------------------\n\nTITLE: Viewing Databases via MySQL CLI\nDESCRIPTION: Shell command to list all databases in the cluster using MySQL command-line client.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-database.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nmysql\n    -u root \\\n    -h {host} \\\n    -P {port} \\\n    -p {password} \\\n    -e \"SHOW DATABASES;\"\n```\n\n----------------------------------------\n\nTITLE: Importing S3 Data with Path-Style Request - Bash\nDESCRIPTION: This snippet demonstrates how to configure a path-style request for S3 data access using TiDB Lightning. This is useful when dealing with non-standard S3 endpoints and requires the same TiDB server connection details as previous snippets.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ntiup tidb-lightning --tidb-port=4000 --pd-urls=127.0.0.1:2379 --backend=local --sorted-kv-dir=/tmp/sorted-kvs \\\n    -d 's3://my-bucket/sql-backup?force-path-style=true&endpoint=http://10.154.10.132:8088'\n```\n\n----------------------------------------\n\nTITLE: Setting Placement Rules with JSON Configuration\nDESCRIPTION: Example of creating and saving placement rules using a JSON configuration file that defines voter roles and replica counts.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-placement-rules.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncat > rules.json <<EOF\n[\n    {\n        \"group_id\": \"pd\",\n        \"id\": \"rule1\",\n        \"role\": \"voter\",\n        \"count\": 3,\n        \"location_labels\": [\"zone\", \"rack\", \"host\"]\n    },\n    {\n        \"group_id\": \"pd\",\n        \"id\": \"rule2\",\n        \"role\": \"voter\",\n        \"count\": 2,\n        \"location_labels\": [\"zone\", \"rack\", \"host\"]\n    }\n]\nEOF\n\n» ./pd-ctl -u 127.0.0.1:2379 config placement-rules save --in=rules.json\n```\n\n----------------------------------------\n\nTITLE: Mapping TiDB Types to MySQL Types - Go\nDESCRIPTION: The function `mysqlTypeFromTiDBType` maps TiDB-specific column types to corresponding MySQL column types. This mapping ensures compatibility during checksum calculations. It handles most standard TiDB types, logging a panic error if an unsupported type is encountered. There are no external dependencies beyond conventional Go libraries.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-checksum-verification.md#2025-04-18_snippet_3\n\nLANGUAGE: Go\nCODE:\n```\nfunc mysqlTypeFromTiDBType(tidbType string) byte {\n    var result byte\n    switch tidbType {\n    case \"INT\", \"INT UNSIGNED\":\n        result = mysql.TypeLong\n    case \"BIGINT\", \"BIGINT UNSIGNED\":\n        result = mysql.TypeLonglong\n    case \"FLOAT\":\n        result = mysql.TypeFloat\n    case \"DOUBLE\":\n        result = mysql.TypeDouble\n    case \"BIT\":\n        result = mysql.TypeBit\n    case \"DECIMAL\":\n        result = mysql.TypeNewDecimal\n    case \"TEXT\":\n        result = mysql.TypeVarchar\n    case \"BLOB\":\n        result = mysql.TypeLongBlob\n    case \"ENUM\":\n        result = mysql.TypeEnum\n    case \"SET\":\n        result = mysql.TypeSet\n    case \"JSON\":\n        result = mysql.TypeJSON\n    case \"DATE\":\n        result = mysql.TypeDate\n    case \"DATETIME\":\n        result = mysql.TypeDatetime\n    case \"TIMESTAMP\":\n        result = mysql.TypeTimestamp\n    case \"TIME\":\n        result = mysql.TypeDuration\n    case \"YEAR\":\n        result = mysql.TypeYear\n    default:\n        log.Panic(\"this should not happen, unknown TiDB type\", zap.String(\"type\", tidbType))\n    }\n    return result\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Prerequisites on CentOS\nDESCRIPTION: Commands to install Git, Python, Docker, Docker Compose, and MySQL client on CentOS.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -fsSL https://get.docker.com | bash -s docker\nyum install -y git python39 docker-ce docker-ce-cli containerd.io docker-compose-plugin mysql\nsystemctl start docker\n```\n\n----------------------------------------\n\nTITLE: Deploying Lambda Function\nDESCRIPTION: Command to deploy the built package as an AWS Lambda function using SAM CLI with guided setup.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-aws-appflow-integration.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsam deploy --guided\n```\n\n----------------------------------------\n\nTITLE: Retrieving Table Names for a Specific Schema (Shell)\nDESCRIPTION: This snippet demonstrates how to use cURL to retrieve a list of table names for a specified schema in a replication task's data source. It sends a GET request to the API endpoint and expects a JSON array response containing table names.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_40\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1/sources/source-1/schemas/db1' \\\n  -H 'accept: application/json'\n```\n\nLANGUAGE: json\nCODE:\n```\n[\n  \"table1\"\n]\n```\n\n----------------------------------------\n\nTITLE: Locking Partition Statistics in TiDB\nDESCRIPTION: SQL commands to lock statistics for a specific partition, show locked statistics, and attempt to analyze the partition. This demonstrates how ANALYZE is skipped for locked partitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-lock-stats.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nLOCK STATS t PARTITION p1;\nSHOW STATS_LOCKED;\nANALYZE TABLE t PARTITION p1;\nSHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating a Table in TiDB\nDESCRIPTION: Demonstrates how to create a table and insert data in bulk using RANDOM_BYTES and multiple JOIN operations in TiDB. This setup is used to analyze the behavior of aggregation operators in execution plans.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-aggregation.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, pad1 BLOB, pad2 BLOB, pad3 BLOB);\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM dual;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nSELECT SLEEP(1);\nANALYZE TABLE t1;\n```\n\n----------------------------------------\n\nTITLE: Importing TPC-C Data with go-tpc\nDESCRIPTION: This shell command imports TPC-C data into the `tpcc` database using the `go-tpc tpcc` tool.  It specifies the host, the number of warehouses (1000), the database name (`tpcc`), the number of threads, the duration of the data loading, and the password for database access. The `${HOST}`, `${THREAD}`, and `${PASSWORD}` are placeholders to be replaced with actual values.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v6.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n\"go-tpc tpcc --host ${HOST} --warehouses 1000 prepare -P 4000 -D tpcc -T ${THREAD} --time 2h0m0s -p ${PASSWORD} --ignore-error\"\n```\n\n----------------------------------------\n\nTITLE: Creating Table for JSON Overlap Queries in TiDB\nDESCRIPTION: This SQL creates a table 't4' with a JSON column and multi-valued indexes on specific JSON paths for demonstrating JSON overlap queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t4(a INT, j JSON, INDEX mvi1((CAST(j->'$.a' AS UNSIGNED ARRAY))), INDEX mvi2((CAST(j->'$.b' AS UNSIGNED ARRAY)));\n```\n\n----------------------------------------\n\nTITLE: Global Configuration Example for DM Cluster using TiUP\nDESCRIPTION: Example configuration for the global section of a DM cluster topology file. This shows how to set the user that will start the cluster and configure resource control parameters like memory limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-dm-topology-reference.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nglobal:\n  user: \"tidb\"\n  resource_control:\n    memory_limit: \"2G\"\n```\n\n----------------------------------------\n\nTITLE: Using tiup dm display Command in Shell\nDESCRIPTION: The basic syntax for using the tiup dm display command to check the operational status of components in a DM cluster. The command requires the cluster name and can be customized with optional flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-display.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm display <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Conditional Check in SQL\nDESCRIPTION: Demonstrates how to create a table with a conditional check to prevent errors if the table already exists.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sql-development-specification.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncreate table if not exists table_name\n```\n\n----------------------------------------\n\nTITLE: Generating Certificate Request for DM-master\nDESCRIPTION: Command to generate a certificate request file for DM-master using the custom OpenSSL configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nopenssl req -new -key master-key.pem -out master-cert.pem -config openssl.cnf\n```\n\n----------------------------------------\n\nTITLE: Checking Table Creation Charset\nDESCRIPTION: SQL command to display the charset configuration of a created table, useful for understanding potential upgrade compatibility issues\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/upgrade-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nshow create table t;\n```\n\n----------------------------------------\n\nTITLE: CommonTableExpr EBNF Syntax Definition\nDESCRIPTION: The EBNF syntax definition for a Common Table Expression (CTE), showing how it's composed of an identifier, optional column list, and a subquery.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-with.md#2025-04-18_snippet_2\n\nLANGUAGE: ebnf\nCODE:\n```\nCommonTableExpr ::=\n        Identifier IdentListWithParenOpt \"AS\" SubSelect\n```\n\n----------------------------------------\n\nTITLE: Complete Log Backup Directory Structure Example\nDESCRIPTION: Detailed example of an actual backup directory structure showing real timestamps, UUIDs, and organization across multiple stores and timeframes.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-log-architecture.md#2025-04-18_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n.\n├── v1\n│   ├── backupmeta\n│   │   ├── ...\n│   │   ├── 435213818858112001-e2569bda-a75a-4411-88de-f469b49d6256.meta\n│   │   ├── 435214043785779202-1780f291-3b8a-455e-a31d-8a1302c43ead.meta\n│   │   └── 435214443785779202-224f1408-fff5-445f-8e41-ca4fcfbd2a67.meta\n│   ├── global_checkpoint\n│   │   ├── 1.ts\n│   │   ├── 2.ts\n│   │   └── 3.ts\n│   └── 20220811\n│       └── 03\n│           ├── 1\n│           │   ├── ...\n│           │   ├── 435213866703257604-60fcbdb6-8f55-4098-b3e7-2ce604dafe54.log\n│           │   └── 435214023989657606-72ce65ff-1fa8-4705-9fd9-cb4a1e803a56.log\n│           ├── 2\n│           │   ├── ...\n│           │   ├── 435214102632857605-11deba64-beff-4414-bc9c-7a161b6fb22c.log\n│           │   └── 435214417205657604-e6980303-cbaa-4629-a863-1e745d7b8aed.log\n│           └── 3\n│               ├── ...\n│               ├── 435214495848857605-7bf65e92-8c43-427e-b81e-f0050bd40be0.log\n│               └── 435214574492057604-80d3b15e-3d9f-4b0c-b133-87ed3f6b2697.log\n└── v1_stream_truncate_safepoint.txt\n```\n\n----------------------------------------\n\nTITLE: Correcting VALUES Function Behavior with BIT(N) Parameter in TiDB\nDESCRIPTION: Fixes incorrect behavior when the parameter type of the VALUES function is BIT(N).\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_27\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO table_name (bit_column) VALUES (b'1010')\n```\n\n----------------------------------------\n\nTITLE: Showing Sequence Creation Details in SQL\nDESCRIPTION: An SQL example showing how to use the SHOW CREATE SEQUENCE statement to display detailed information about the previously created 'seq' sequence.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-sequence.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE SEQUENCE seq;\n```\n\n----------------------------------------\n\nTITLE: Installing OpenSSL on Debian/Ubuntu\nDESCRIPTION: Command to install OpenSSL on Debian or Ubuntu operating systems using the apt package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\napt install openssl\n```\n\n----------------------------------------\n\nTITLE: Correcting JSON Unquote Function Arguments in TiKV Coprocessor\nDESCRIPTION: This fix resolves an issue with the json_unquote() function in the TiKV coprocessor where the argument types were incorrect. The fix ensures proper handling of JSON data in TiKV operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.3.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\njson_unquote()\n```\n\n----------------------------------------\n\nTITLE: Example SQL Statements with Identical Digest\nDESCRIPTION: Two SQL statements that have different constants but produce the same SQL digest after normalization, demonstrating how TiDB groups similar queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/statement-summary-tables.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM employee WHERE id IN (1, 2, 3) AND salary BETWEEN 1000 AND 2000;\nselect * from EMPLOYEE where ID in (4, 5) and SALARY between 3000 and 4000;\n```\n\n----------------------------------------\n\nTITLE: Importing Data Files from Google Cloud Storage (GCS)\nDESCRIPTION: This SQL statement imports a data file from a Google Cloud Storage (GCS) bucket into a TiDB table. The URI includes the bucket name, file path, and the path to the credentials file. Ensure the TiDB server has access to the specified credentials file.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t FROM 'gs://import/test.csv?credentials-file=${credentials-file-path}';\n```\n\n----------------------------------------\n\nTITLE: JSON Payload Example\nDESCRIPTION: This JSON snippet provides an example of the payload format used by TiCDC to represent a data change event, specifically an update operation. The example shows the structure of the payload, including fields like `source`, `ts_ms`, `transaction`, `op`, `before`, and `after`, along with sample data.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-debezium.md#2025-04-18_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"payload\": {\n        \"source\": {\n            \"version\": \"2.4.0.Final\",\n            \"connector\": \"TiCDC\",\n            \"name\": \"test_cluster\",\n            \"ts_ms\": 0,\n            \"snapshot\": \"false\",\n            \"db\": \"test\",\n            \"table\": \"table1\",\n            \"server_id\": 0,\n            \"gtid\": null,\n            \"file\": \"\",\n            \"pos\": 0,\n            \"row\": 0,\n            \"thread\": 0,\n            \"query\": null,\n            \"commit_ts\": 1,\n            \"cluster_id\": \"test_cluster\"\n        },\n        \"ts_ms\": 1701326309000,\n        \"transaction\": null,\n        \"op\": \"u\",\n        \"before\": { \"tiny\": 2 },\n        \"after\": { \"tiny\": 1 }\n    },\n    \"schema\": {\n        \"type\": \"struct\",\n        \"optional\": false,\n        \"name\": \"test_cluster.test.table1.Envelope\",\n        \"version\": 1,\n        \"fields\": [\n            {\n                \"type\": \"struct\",\n                \"optional\": true,\n                \"name\": \"test_cluster.test.table1.Value\",\n                \"field\": \"before\",\n                \"fields\": [{ \"type\": \"int16\", \"optional\": true, \"field\": \"tiny\" }]\n            },\n            {\n                \"type\": \"struct\",\n                \"optional\": true,\n                \"name\": \"test_cluster.test.table1.Value\",\n                \"field\": \"after\",\n                \"fields\": [{ \"type\": \"int16\", \"optional\": true, \"field\": \"tiny\" }]\n            },\n            {\n                \"type\": \"struct\",\n                \"fields\": [\n                    { \"type\": \"string\", \"optional\": false, \"field\": \"version\" },\n                    { \"type\": \"string\", \"optional\": false, \"field\": \"connector\" },\n                    { \"type\": \"string\", \"optional\": false, \"field\": \"name\" },\n                    { \"type\": \"int64\", \"optional\": false, \"field\": \"ts_ms\" },\n                    {\n                        \"type\": \"string\",\n                        \"optional\": true,\n                        \"name\": \"io.debezium.data.Enum\",\n                        \"version\": 1,\n                        \"parameters\": { \"allowed\": \"true,last,false,incremental\" },\n                        \"default\": \"false\",\n                        \"field\": \"snapshot\"\n                    },\n                    { \"type\": \"string\", \"optional\": false, \"field\": \"db\" },\n                    { \"type\": \"string\", \"optional\": true, \"field\": \"sequence\" },\n                    { \"type\": \"string\", \"optional\": true, \"field\": \"table\" },\n                    { \"type\": \"int64\", \"optional\": false, \"field\": \"server_id\" },\n                    { \"type\": \"string\", \"optional\": true, \"field\": \"gtid\" },\n                    { \"type\": \"string\", \"optional\": false, \"field\": \"file\" },\n                    { \"type\": \"int64\", \"optional\": false, \"field\": \"pos\" },\n                    { \"type\": \"int32\", \"optional\": false, \"field\": \"row\" },\n                    { \"type\": \"int64\", \"optional\": true, \"field\": \"thread\" },\n                    { \"type\": \"string\", \"optional\": true, \"field\": \"query\" }\n                ],\n                \"optional\": false,\n                \"name\": \"io.debezium.connector.mysql.Source\",\n                \"field\": \"source\"\n            },\n            { \"type\": \"string\", \"optional\": false, \"field\": \"op\" },\n            { \"type\": \"int64\", \"optional\": true, \"field\": \"ts_ms\" },\n            {\n                \"type\": \"struct\",\n                \"fields\": [\n                    { \"type\": \"string\", \"optional\": false, \"field\": \"id\" },\n                    { \"type\": \"int64\", \"optional\": false, \"field\": \"total_order\" },\n                    {\n                        \"type\": \"int64\",\n                        \"optional\": false,\n                        \"field\": \"data_collection_order\"\n                    }\n                ],\n                \"optional\": true,\n                \"name\": \"event.block\",\n                \"version\": 1,\n                \"field\": \"transaction\"\n            }\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Database in TiDB\nDESCRIPTION: This SQL command is used to create a new database named 'pingcap' in the TiDB server. It is essential for organizing the data managed by TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/post-installation-check.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncreate database pingcap;\n```\n\n----------------------------------------\n\nTITLE: Removing Changefeed in TiDB Cluster\nDESCRIPTION: This shell command stops and removes a changefeed between TiDB clusters, a crucial step in planned disaster recovery (DR) switchover to prevent further data replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc cli changefeed remove --server=http://10.1.1.9:8300 --changefeed-id=\"dr-primary-to-secondary\"\n```\n\n----------------------------------------\n\nTITLE: CREATE RESOURCE GROUP Syntax Definition in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the CREATE RESOURCE GROUP statement, showing all possible parameters and configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-resource-group.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCreateResourceGroupStmt ::=\n   \"CREATE\" \"RESOURCE\" \"GROUP\" IfNotExists ResourceGroupName ResourceGroupOptionList\n\nIfNotExists ::=\n    ('IF' 'NOT' 'EXISTS')?\n\nResourceGroupName ::=\n    Identifier\n|   \"DEFAULT\"\n\nResourceGroupOptionList ::=\n    DirectResourceGroupOption\n|   ResourceGroupOptionList DirectResourceGroupOption\n|   ResourceGroupOptionList ',' DirectResourceGroupOption\n\nDirectResourceGroupOption ::=\n    \"RU_PER_SEC\" EqOpt stringLit\n|   \"PRIORITY\" EqOpt ResourceGroupPriorityOption\n|   \"BURSTABLE\"\n|   \"BURSTABLE\" EqOpt Boolean\n|   \"QUERY_LIMIT\" EqOpt '(' ResourceGroupRunawayOptionList ')'\n|   \"QUERY_LIMIT\" EqOpt '(' ')'\n|   \"QUERY_LIMIT\" EqOpt \"NULL\"\n|   \"BACKGROUND\" EqOpt '(' BackgroundOptionList ')'\n|   \"BACKGROUND\" EqOpt '(' ')'\n|   \"BACKGROUND\" EqOpt \"NULL\"\n```\n\n----------------------------------------\n\nTITLE: Specifying Architecture in Topology File\nDESCRIPTION: This snippet shows how to configure the architecture settings in the topology file for TiDB deployment, allowing for specific machine architecture configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nglobal:\n  arch: \"arm64\"           # Configures all machines to use the binary files of the arm64 architecture by default\n\ntidb_servers:\n  - host: 172.16.5.134\n    arch: \"amd64\"         # Configures this machine to use the binary files of the amd64 architecture\n  - host: 172.16.5.139\n    arch: \"arm64\"         # Configures this machine to use the binary files of the arm64 architecture\n  - host: 172.16.5.140    # Machines that are not configured with the arch field use the default value in the global field, which is arm64 in this case.\n```\n\n----------------------------------------\n\nTITLE: Manual Relay Log Purge Command - Bash\nDESCRIPTION: This command purges relay logs before a specific binlog file. The `-s` option specifies the MySQL replica and the `--sub-dir` option allows to specify the subdirectory of logs to be purged.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/relay-log.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npurge-relay -s mysql-replica-01 --filename mysql-bin.000001 --sub-dir e4e0e8ab-09cc-11e9-9220-82cc35207219.000002\n```\n\n----------------------------------------\n\nTITLE: Adding Operators to Blocklist\nDESCRIPTION: SQL commands to add < and > operators to the expression pushdown blocklist and reload the configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/blocklist-control-plan.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO mysql.expr_pushdown_blacklist VALUES('<','tikv',''), ('>','tikv','');\nadmin reload expr_pushdown_blacklist;\n```\n\n----------------------------------------\n\nTITLE: LOAD STATS Syntax in TiDB\nDESCRIPTION: This snippet shows the syntax of the `LOAD STATS` statement in TiDB. It is used to load statistics from a specified file into the TiDB database. The `stringLit` represents the path to the statistics file.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-load-stats.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\n\"LoadStatsStmt ::=\\n    'LOAD' 'STATS' stringLit\"\n```\n\n----------------------------------------\n\nTITLE: Defining ENUM Column in TiDB\nDESCRIPTION: Syntax for creating an ENUM column with predefined string values and example usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nENUM('value1','value2',...) [CHARACTER SET charset_name] [COLLATE collation_name]\n\n# For example:\nENUM('apple', 'orange', 'pear')\n```\n\n----------------------------------------\n\nTITLE: Explain Query with use_index_merge hint and plan\nDESCRIPTION: This SQL code demonstrates the use of the `use_index_merge` hint with a multi-valued index. Unlike `use_index`, it successfully produces a query plan without errors. The plan involves a `Selection` operation based on conditions related to the `member of` operator and `TableFullScan`.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nmysql> EXPLAIN SELECT /*+ use_index_merge(t3, idx) */ * FROM t3 WHERE ((1 member of (j)) AND (2 member of (j))) OR ((3 member of (j)) AND (4 member of (j)));\n+-------------------------+----------+-----------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| id                      | estRows  | task      | access object | operator info                                                                                                                                                                                                |\n+-------------------------+----------+-----------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Selection_5             | 8000.00  | root      |               | or(and(json_memberof(cast(1, json BINARY), test.t3.j), json_memberof(cast(2, json BINARY), test.t3.j)), and(json_memberof(cast(3, json BINARY), test.t3.j), json_memberof(cast(4, json BINARY), test.t3.j))) |\n| └─TableReader_7         | 10000.00 | root      |               | data:TableFullScan_6                                                                                                                                                                                         |\n|   └─TableFullScan_6     | 10000.00 | cop[tikv] | table:t3      | keep order:false, stats:pseudo                                                                                                                                                                               |\n+-------------------------+----------+-----------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n3 rows in set, 2 warnings (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Packaging Diagnostic Data\nDESCRIPTION: Command to package collected diagnostic data for offline transfer when internet access is not available.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag package ${filepath}\n```\n\n----------------------------------------\n\nTITLE: Output of PARTITIONS Table Description in TiDB\nDESCRIPTION: Shows the result of describing the PARTITIONS table, listing all 27 fields with their data types, nullable status, key information, default values, and extra properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-partitions.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------------+--------------+------+------+---------+-------+\n| Field                         | Type         | Null | Key  | Default | Extra |\n+-------------------------------+--------------+------+------+---------+-------+\n| TABLE_CATALOG                 | varchar(512) | YES  |      | NULL    |       |\n| TABLE_SCHEMA                  | varchar(64)  | YES  |      | NULL    |       |\n| TABLE_NAME                    | varchar(64)  | YES  |      | NULL    |       |\n| PARTITION_NAME                | varchar(64)  | YES  |      | NULL    |       |\n| SUBPARTITION_NAME             | varchar(64)  | YES  |      | NULL    |       |\n| PARTITION_ORDINAL_POSITION    | bigint(21)   | YES  |      | NULL    |       |\n| SUBPARTITION_ORDINAL_POSITION | bigint(21)   | YES  |      | NULL    |       |\n| PARTITION_METHOD              | varchar(18)  | YES  |      | NULL    |       |\n| SUBPARTITION_METHOD           | varchar(12)  | YES  |      | NULL    |       |\n| PARTITION_EXPRESSION          | longtext     | YES  |      | NULL    |       |\n| SUBPARTITION_EXPRESSION       | longtext     | YES  |      | NULL    |       |\n| PARTITION_DESCRIPTION         | longtext     | YES  |      | NULL    |       |\n| TABLE_ROWS                    | bigint(21)   | YES  |      | NULL    |       |\n| AVG_ROW_LENGTH                | bigint(21)   | YES  |      | NULL    |       |\n| DATA_LENGTH                   | bigint(21)   | YES  |      | NULL    |       |\n| MAX_DATA_LENGTH               | bigint(21)   | YES  |      | NULL    |       |\n| INDEX_LENGTH                  | bigint(21)   | YES  |      | NULL    |       |\n| DATA_FREE                     | bigint(21)   | YES  |      | NULL    |       |\n| CREATE_TIME                   | datetime     | YES  |      | NULL    |       |\n| UPDATE_TIME                   | datetime     | YES  |      | NULL    |       |\n| CHECK_TIME                    | datetime     | YES  |      | NULL    |       |\n| CHECKSUM                      | bigint(21)   | YES  |      | NULL    |       |\n| PARTITION_COMMENT             | varchar(80)  | YES  |      | NULL    |       |\n| NODEGROUP                     | varchar(12)  | YES  |      | NULL    |       |\n| TABLESPACE_NAME               | varchar(64)  | YES  |      | NULL    |       |\n| TIDB_PARTITION_ID             | bigint(21)   | YES  |      | NULL    |       |\n| TIDB_PLACEMENT_POLICY_NAME    | varchar(64)  | YES  |      | NULL    |       |\n+-------------------------------+--------------+------+------+---------+-------+\n27 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Kill Specific Connection in TiDB\nDESCRIPTION: Example of using KILL statement to terminate a specific connection identified by its connection ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-kill.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nKILL 5857102839209263511;\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Unique Constraint in SQL\nDESCRIPTION: Creates a 'users' table with a UNIQUE constraint on the 'nickname' column to prevent duplicate values.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `bookshop`.`users` (\n  `id` bigint AUTO_RANDOM,\n  `balance` decimal(15,2),\n  `nickname` varchar(100) UNIQUE,\n  PRIMARY KEY (`id`)\n);\n```\n\n----------------------------------------\n\nTITLE: Setting Shell Environment\nDESCRIPTION: Sources shell profile to configure environment variables for TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nsource ${your_shell_profile}\n```\n\n----------------------------------------\n\nTITLE: Using 100% Index Selectivity Ratio in TiDB SQL\nDESCRIPTION: Example showing query execution with a value of 1.0 (100%) for tidb_opt_ordering_index_selectivity_ratio. This assumes that 100% of rows will be scanned before finding qualified rows, resulting in a pessimistic estimation of 990,843 rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_59\n\nLANGUAGE: sql\nCODE:\n```\n> SET SESSION tidb_opt_ordering_index_selectivity_ratio = 1;\n\n> EXPLAIN SELECT * FROM t USE INDEX (ia) WHERE b <= 9000 ORDER BY a LIMIT 1;\n+-----------------------------------+-----------+-----------+-----------------------+---------------------------------+\n| id                                | estRows   | task      | access object         | operator info                   |\n+-----------------------------------+-----------+-----------+-----------------------+---------------------------------+\n| Limit_12                          | 1.00      | root      |                       | offset:0, count:1               |\n| └─Projection_22                   | 1.00      | root      |                       | test.t.a, test.t.b, test.t.c    |\n|   └─IndexLookUp_21                | 1.00      | root      |                       |                                 |\n|     ├─IndexFullScan_18(Build)     | 990843.14 | cop[tikv] | table:t, index:ia(a)  | keep order:true                 |\n|     └─Selection_20(Probe)         | 1.00      | cop[tikv] |                       | le(test.t.b, 9000)              |\n|       └─TableRowIDScan_19         | 990843.14 | cop[tikv] | table:t               | keep order:false                |\n+-----------------------------------+-----------+-----------+-----------------------+---------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with List COLUMNS Partitioning using Multiple Columns in SQL\nDESCRIPTION: This snippet illustrates how to create a table 't' using List COLUMNS partitioning with multiple columns (id and name) as partition keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_24\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t (\n    id int,\n    name varchar(10)\n)\nPARTITION BY LIST COLUMNS(id,name) (\n     partition p0 values IN ((1,'a'),(2,'b')),\n     partition p1 values IN ((3,'c'),(4,'d')),\n     partition p3 values IN ((5,'e'),(null,null))\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Token Authentication from File for Pulsar in TiCDC\nDESCRIPTION: This snippet shows how to configure token authentication for Pulsar in TiCDC using a token file.  The `token-from-file` parameter specifies the path to the file containing the token.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"pulsar://127.0.0.1:6650/persistent://public/default/yktest?protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: Applying Redo Logs to TiDB Cluster\nDESCRIPTION: This shell command applies redo logs to bring a secondary TiDB cluster to a transaction-consistent state during a DR switchover upon disaster. It requires specifying redo log storage, temporary directory, and sink URI.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc redo apply --storage \"s3://redo?access-key=minio&secret-access-key=miniostorage&endpoint=http://10.0.1.10:6060&force-path-style=true\" --tmp-dir /tmp/redo --sink-uri \"mysql://{username}:{password}@10.1.1.4:4000\"\n```\n\n----------------------------------------\n\nTITLE: Running TiDB Lightning with Specified Timezone\nDESCRIPTION: Command to force a specific timezone when running TiDB Lightning directly, which helps resolve timestamp-related errors by ensuring TiDB Lightning and the source database use the same timezone.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/troubleshoot-tidb-lightning.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n# Manual deployment, and force Asia/Shanghai.\nTZ='Asia/Shanghai' bin/tidb-lightning -config tidb-lightning.toml\n```\n\n----------------------------------------\n\nTITLE: JSON_TYPE Date Comparison\nDESCRIPTION: Examples showing how JSON_TYPE handles date values differently based on their original type.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-return.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT '\"2025-06-14\"',CAST(CAST('2025-06-14' AS date) AS json);\nSELECT JSON_TYPE('\"2025-06-14\"'),JSON_TYPE(CAST(CAST('2025-06-14' AS date) AS json));\n```\n\n----------------------------------------\n\nTITLE: Filtered SQL Query - Authors by Birth Year\nDESCRIPTION: SQL query demonstrating filtering results using WHERE clause to find authors born in a specific year.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM authors WHERE birth_year = 1998;\n```\n\n----------------------------------------\n\nTITLE: Defining AlterTableStmt Syntax in TiDB\nDESCRIPTION: This EBNF diagram describes the syntax for adding a new column to an existing table in TiDB. It outlines the different components involved in the ADD COLUMN operation, including options for the column type and options. Note that TiDB supports online column addition, which does not block reads or writes during the operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-add-column.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\nAlterTableStmt\n         ::= 'ALTER' 'IGNORE'? 'TABLE' TableName AddColumnSpec ( ',' AddColumnSpec )*\n\nTableName ::=\n    Identifier ('.' Identifier)?\n\nAddColumnSpec\n         ::= 'ADD' 'COLUMN' 'IF NOT EXISTS'? ColumnName ColumnType ColumnOption+ ( 'FIRST' | 'AFTER' ColumnName )?\n\nColumnType\n         ::= NumericType\n           | StringType\n           | DateAndTimeType\n           | 'SERIAL'\n\nColumnOption\n         ::= 'NOT'? 'NULL'\n           | 'AUTO_INCREMENT'\n           | 'PRIMARY'? 'KEY' ( 'CLUSTERED' | 'NONCLUSTERED' )? ( 'GLOBAL' | 'LOCAL' )?\n           | 'UNIQUE' 'KEY'? ( 'GLOBAL' | 'LOCAL' )?\n           | 'DEFAULT' ( NowSymOptionFraction | SignedLiteral | NextValueForSequence )\n           | 'SERIAL' 'DEFAULT' 'VALUE'\n           | 'ON' 'UPDATE' NowSymOptionFraction\n           | 'COMMENT' stringLit\n           | ( 'CONSTRAINT' Identifier? )? 'CHECK' '(' Expression ')' ( 'NOT'? ( 'ENFORCED' | 'NULL' ) )?\n           | 'GENERATED' 'ALWAYS' 'AS' '(' Expression ')' ( 'VIRTUAL' | 'STORED' )?\n           | 'REFERENCES' TableName ( '(' IndexPartSpecificationList ')' )? Match? OnDeleteUpdateOpt\n           | 'COLLATE' CollationName\n           | 'COLUMN_FORMAT' ColumnFormat\n           | 'STORAGE' StorageMedia\n           | 'AUTO_RANDOM' ( '(' LengthNum ')' )?\n```\n\n----------------------------------------\n\nTITLE: Creating User with No Password Expiration in SQL\nDESCRIPTION: SQL command to create a new user with a password that never expires, overriding any global expiration policy.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_16\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE USER 'test'@'localhost' PASSWORD EXPIRE NEVER;\n```\n\n----------------------------------------\n\nTITLE: Capturing Multiple Execution Plans\nDESCRIPTION: Demonstrates how to capture all execution plans for a given SQL digest using wildcard.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-replayer.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nPLAN REPLAYER CAPTURE 'sql_digest' '*';\n```\n\n----------------------------------------\n\nTITLE: Data Source Configuration File Structure\nDESCRIPTION: YAML configuration file template for defining a DM data source. Includes source ID, connection details, and optional TLS security settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-source.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nsource-id: \"mysql-01\"    \n\nfrom:\n  host: \"127.0.0.1\"\n  port: 3306\n  user: \"root\"\n  password: \"MKxn0Qo3m3XOyjCnhEMtsUCm83EhGQDZ/T4=\" \n  security:                                        \n    ssl-ca: \"/path/to/ca.pem\"\n    ssl-cert: \"/path/to/cert.pem\"\n    ssl-key: \"/path/to/key.pem\"\n```\n\n----------------------------------------\n\nTITLE: Tracing SQL Query Execution on Cached Table\nDESCRIPTION: SQL statement to trace the execution of a SELECT query on the 'users' table, showing whether data is read from memory or TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/cached-tables.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nTRACE SELECT * FROM users;\n```\n\n----------------------------------------\n\nTITLE: Using TIDB_ENCODE_SQL_DIGEST to Get Digest for a Query\nDESCRIPTION: Demonstrates using TIDB_ENCODE_SQL_DIGEST function to get the SQL digest for a query. This example shows how to get the digest for 'SELECT 1'.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_ENCODE_SQL_DIGEST('SELECT 1');\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Prefix Index in TiDB\nDESCRIPTION: This SQL snippet creates a table named 't' with columns 'a', 'b', and 'c', and an index 'idx_a_b' on columns 'a' and the first 5 characters of 'b'.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_63\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a INT, b VARCHAR(10), c INT, INDEX idx_a_b(a, b(5)));\n```\n\n----------------------------------------\n\nTITLE: Using HASH_JOIN_PROBE Hint in SQL Queries\nDESCRIPTION: The HASH_JOIN_PROBE hint tells the optimizer to use specified tables as the probe side when using the hash join algorithm. This controls which tables are used to probe the hash tables during join operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ HASH_JOIN_PROBE(t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Query Execution Plan in TiDB\nDESCRIPTION: Uses the EXPLAIN statement to view the execution plan of a slow query, showing that it performs a full table scan.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM books WHERE title = 'Marian Yost';\n```\n\n----------------------------------------\n\nTITLE: Displaying Warnings for Exceeded tidb_opt_range_max_size in TiDB\nDESCRIPTION: This SQL query shows warnings generated when the memory required to build exact scan ranges exceeds the limit set by tidb_opt_range_max_size.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_72\n\nLANGUAGE: sql\nCODE:\n```\nSHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: Querying MEMORY_USAGE Table in TiDB\nDESCRIPTION: This SQL query selects all columns and rows from the MEMORY_USAGE table in the information_schema, providing a snapshot of the current memory usage statistics for the TiDB instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-memory-usage.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.memory_usage;\n```\n\n----------------------------------------\n\nTITLE: Copying and renaming the environment file\nDESCRIPTION: Shell command to copy the .env.example file and rename it to .env for configuring connection parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysqljs.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Set sync-diff-inspector Chunk Size in TOML\nDESCRIPTION: Specifies the chunk size for dividing the data table during comparison. A value of 0 indicates the setting can be omitted and default behavior is employed.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/sync-diff-inspector-overview.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\n\"chunk-size = 0\"\n```\n\n----------------------------------------\n\nTITLE: Database Name Missing Hint Example\nDESCRIPTION: Demonstrates how hints fail when database name is not specified during connection. Shows SQL query and resulting warning message.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_52\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ use_index(t, a) */ a FROM test.t;\nSHOW WARNINGS;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+---------+------+----------------------------------------------------------------------+\n| Level   | Code | Message                                                              |\n+---------+------+----------------------------------------------------------------------+\n| Warning | 1815 | use_index(.t, a) is inapplicable, check whether the table(.t) exists |\n+---------+------+----------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Uneven Split Example with Fixed Points in TiDB\nDESCRIPTION: SQL example for splitting a table at specific boundary points (10000 and 90000) for unevenly distributed data in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nSPLIT TABLE t BY (10000), (90000);\n```\n\n----------------------------------------\n\nTITLE: Querying SCHEMATA Table Structure in TiDB\nDESCRIPTION: Shows how to examine the structure of the SCHEMATA information_schema table in TiDB by using the DESC command.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-schemata.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\ndesc SCHEMATA;\n```\n\n----------------------------------------\n\nTITLE: Region Information Commands\nDESCRIPTION: Commands for querying and managing region information, including viewing specific regions, scanning regions, and analyzing region statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\n>> region\n>> region 2\n>> region key 7480000000000000FF1300000000000000F8\n>> region key --format=raw abc\n>> region key --format=encode 't\\200\\000\\000\\000\\000\\000\\000\\377\\035_r\\200\\000\\000\\000\\000\\377\\017U\\320\\000\\000\\000\\000\\000\\372'\n>> region scan\n>> region sibling 2\n>> region store 2\n>> region topread\n>> region topwrite\n>> region topconfver\n>> region topversion\n>> region topsize\n```\n\n----------------------------------------\n\nTITLE: Querying DDL Jobs in TiDB\nDESCRIPTION: SQL command to display the current DDL job queue including running, pending, and last 10 executed jobs. Shows detailed information about job status, schema states, and execution timeline.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW DDL JOBS;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+--------+---------+------------+---------------------------------+----------------------+-----------+----------+-----------+----------------------------+----------------------------+----------------------------+----------+-------------+\n```\n\n----------------------------------------\n\nTITLE: Configure sync-diff-inspector Index Fields in TOML\nDESCRIPTION: Specifies index columns used by sync-diff-inspector to divide data into chunks. This helps in executing data comparison operations. No specific prerequisites needed aside from ensuring the columns exist in the database schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/sync-diff-inspector-overview.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\n\"index-fields = [\\\"col1\\\",\\\"col2\\\"]\"\n```\n\n----------------------------------------\n\nTITLE: EXPLAIN Query Without Partition Pruning\nDESCRIPTION: An EXPLAIN statement for a query that cannot benefit from partition pruning. Because the YEAR() function is applied to the column in the WHERE clause, TiDB must scan all partitions since this is considered a non-sargable predicate.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-partitions.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT COUNT(*) FROM t1 WHERE YEAR(d) = 2017;\n```\n\n----------------------------------------\n\nTITLE: Setting Multiple User-Defined Variables in TiDB\nDESCRIPTION: Sets multiple user-defined variables in a single statement. This example assigns three different string values to variables @a, @b, and @c.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET @a = 'a', @b = 'b', @c = 'c';\n```\n\n----------------------------------------\n\nTITLE: Convert ASCII Code to Character in TiDB\nDESCRIPTION: This snippet illustrates how to convert an ASCII code to a character in TiDB using CHAR, paralleling the CHR function in Oracle.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nCHR(n)\n```\n\nLANGUAGE: sql\nCODE:\n```\nCHAR(n)\n```\n\n----------------------------------------\n\nTITLE: INTERSECT Operation in TiDB\nDESCRIPTION: Shows the INTERSECT operation which returns elements present in both sets.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/set-operators.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 INTERSECT SELECT * FROM t2;\n```\n\n----------------------------------------\n\nTITLE: Creating Valid Primary Key Definitions - SQL\nDESCRIPTION: This snippet presents corrected SQL commands for creating tables 't5' and 't6', where the primary keys now conform to the partitioning requirements by including all necessary columns, making them valid.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_59\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCREATE TABLE t5 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    PRIMARY KEY(col1, col2, col3)\n)\nPARTITION BY HASH(col3)\nPARTITIONS 4;\nCREATE TABLE t6 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    PRIMARY KEY(col1, col2, col3),\n    UNIQUE KEY(col2)\n)\nPARTITION BY HASH( YEAR(col2) )\nPARTITIONS 4;\n```\n```\n\n----------------------------------------\n\nTITLE: Example of a replace-down-replica operator in PD\nDESCRIPTION: This snippet shows the structure of a replace-down-replica operator, which contains multiple scheduling operations including adding a learner peer, promoting it to a voter, and removing a peer from another store.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-store-limit.md#2025-04-18_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n\"replace-down-replica {mv peer: store [2] to [3]} (kind:region,replica, region:10(4,5), createAt:2020-05-18 06:40:25.775636418 +0000 UTC m=+2168762.679540369, startAt:2020-05-18 06:40:25.775684648 +0000 UTC m=+2168762.679588599, currentStep:0, steps:[add learner peer 20 on store 3, promote learner peer 20 on store 3 to voter, remove peer on store 2])\"\n```\n\n----------------------------------------\n\nTITLE: TiFlash Master Key Rotation Configuration\nDESCRIPTION: Configuration for rotating KMS master key with both new and previous key details.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\n[security.encryption.master-key]\ntype = \"kms\"\nkey-id = \"50a0c603-1c6f-11e6-bb9e-3fadde80ce75\"\nregion = \"us-west-2\"\n\n[security.encryption.previous-master-key]\ntype = \"kms\"\nkey-id = \"0987dcba-09fe-87dc-65ba-ab0987654321\"\nregion = \"us-west-2\"\n```\n\n----------------------------------------\n\nTITLE: Dynamic Partition Pruning Mode Explanation\nDESCRIPTION: Shows query execution in dynamic partition pruning mode, with a more compact MPP execution plan across all partitions\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tiflash-mpp-mode.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_partition_prune_mode=dynamic;\nexplain SELECT count(*) FROM test.employees;\n```\n\n----------------------------------------\n\nTITLE: CPU Load Query Results\nDESCRIPTION: Shows the output of querying CPU load information, displaying load averages over 1, 5, and 15 minute periods for TiDB, PD, and TiKV instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-load.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+------+-----------------+-------------+-------------+--------+-------+\n| TYPE | INSTANCE        | DEVICE_TYPE | DEVICE_NAME | NAME   | VALUE |\n+------+-----------------+-------------+-------------+--------+-------+\n| tidb | 0.0.0.0:4000    | cpu         | cpu         | load1  | 0.13  |\n| tidb | 0.0.0.0:4000    | cpu         | cpu         | load5  | 0.25  |\n| tidb | 0.0.0.0:4000    | cpu         | cpu         | load15 | 0.31  |\n| pd   | 127.0.0.1:2379  | cpu         | cpu         | load1  | 0.13  |\n| pd   | 127.0.0.1:2379  | cpu         | cpu         | load5  | 0.25  |\n| pd   | 127.0.0.1:2379  | cpu         | cpu         | load15 | 0.31  |\n| tikv | 127.0.0.1:20165 | cpu         | cpu         | load1  | 0.13  |\n| tikv | 127.0.0.1:20165 | cpu         | cpu         | load5  | 0.25  |\n| tikv | 127.0.0.1:20165 | cpu         | cpu         | load15 | 0.31  |\n+------+-----------------+-------------+-------------+--------+-------+\n9 rows in set (1.50 sec)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating SHOW PLACEMENT Usage in SQL\nDESCRIPTION: This snippet shows how to create placement policies and use the SHOW PLACEMENT command to retrieve placement information in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-placement.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY p1 PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\" FOLLOWERS=4;\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (a INT) PLACEMENT POLICY=p1;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW PLACEMENT;\n```\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.01 sec)\n```\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.00 sec)\n```\n\nLANGUAGE: sql\nCODE:\n```\n+---------------+----------------------------------------------------------------------+------------------+\\\n| Target        | Placement                                                            | Scheduling_State |\\\n+---------------+----------------------------------------------------------------------+------------------+\\\n| POLICY p1     | PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\" FOLLOWERS=4 | NULL             |\\\n| DATABASE test | PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\" FOLLOWERS=4 | INPROGRESS       |\\\n| TABLE test.t1 | PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\" FOLLOWERS=4 | INPROGRESS       |\\\n+---------------+----------------------------------------------------------------------+------------------+\\\n4 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Store Weights in TiKV\nDESCRIPTION: This command sets the leader and Region weights for a given store ID. Users must ensure that the weights are integers representing the desired priority.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_56\n\nLANGUAGE: bash\nCODE:\n```\nstore weight 1 5 10\n```\n\n----------------------------------------\n\nTITLE: Markdown Headers and Metadata\nDESCRIPTION: YAML frontmatter and markdown headers defining the document structure and metadata for TiFlash performance analysis documentation\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash-performance-tuning-methods.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: TiFlash Performance Analysis and Tuning Methods\nsummary: Introduces the TiFlash metrics on the Performance Overview dashboard to help you better understand and monitor TiFlash workloads.\n---\n\n# TiFlash Performance Analysis and Tuning Methods\n```\n\n----------------------------------------\n\nTITLE: Verifying Lock Usage with IS_USED_LOCK in TiDB SQL\nDESCRIPTION: Checks if a specified lock is currently in use. If the lock is in use, it returns the corresponding connection ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/locking-functions.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nIS_USED_LOCK(lockName)\n```\n\n----------------------------------------\n\nTITLE: Verifying Data Consistency with sync-diff-inspector\nDESCRIPTION: A shell command to utilize the sync-diff-inspector tool for checking data consistency between clusters. Requires sync-diff-inspector installed and a config file defined. Outputs results of data comparison.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n./sync_diff_inspector --config=./config.toml\n```\n\n----------------------------------------\n\nTITLE: Creating and Analyzing a Partitioned Table in TiDB\nDESCRIPTION: SQL commands to create a partitioned table, insert data, and analyze it before locking partition statistics. This shows the normal behavior for partitioned tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-lock-stats.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t(a INT, b INT) PARTITION BY RANGE (a) (PARTITION p0 VALUES LESS THAN (10), PARTITION p1 VALUES LESS THAN (20), PARTITION p2 VALUES LESS THAN (30));\nINSERT INTO t VALUES (1,2), (3,4), (5,6), (7,8);\nANALYZE TABLE t;\nSHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: Executing ROLLUP Query in TiDB without TiFlash\nDESCRIPTION: This SQL snippet demonstrates the execution plan for a ROLLUP query in a TiDB cluster without TiFlash nodes. The Expand operator is executed on a single TiDB node, which may lead to increased data redundancy as the number of dimension groupings grows.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/group-by-modifier.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT year, month, grouping(year), grouping(month), SUM(profit) AS profit FROM bank GROUP BY year, month WITH ROLLUP;\n```\n\n----------------------------------------\n\nTITLE: Explaining Query Execution Plan in TiDB\nDESCRIPTION: This SQL statement uses `EXPLAIN` to display the execution plan for a given query. The execution plan shows how TiDB intends to execute the query, including the operators used, the order of operations, and the estimated number of rows processed. This helps to identify performance bottlenecks.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n\"EXPLAIN SELECT count(*) FROM trips WHERE start_date BETWEEN '2017-07-01 00:00:00' AND '2017-07-01 23:59:59';\"\n```\n\n----------------------------------------\n\nTITLE: Querying GC Status in TiDB\nDESCRIPTION: This SQL command checks the status of garbage collection (GC) to confirm that it has been disabled, ensuring that the historical data remains accessible during migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nMySQL [test]> SELECT @@global.tidb_gc_enable;\n\n```\n+-------------------------+\n| @@global.tidb_gc_enable |\n+-------------------------+\n|                       0 |\n+-------------------------+\n1 row in set (0.00 sec)\n```\n```\n\n----------------------------------------\n\nTITLE: Executing PD Control command in interactive mode\nDESCRIPTION: This snippet shows how to use PD Control in interactive mode. It uses `tiup ctl` with the `-i` flag, which allows you to enter multiple commands without specifying the PD address repeatedly.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd -i -u http://127.0.0.1:2379\n```\n\n----------------------------------------\n\nTITLE: Using tiup cluster disable Command in Shell\nDESCRIPTION: The basic syntax for the `tiup cluster disable` command. This command prevents cluster services from automatically starting after system reboot for the specified cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-disable.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster disable <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Querying Global Status Variables in TiDB\nDESCRIPTION: Command to retrieve global server status variables\nSOURCE: https://github.com/pingcap/docs/blob/master/status-variables.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GLOBAL STATUS;\n```\n\n----------------------------------------\n\nTITLE: Resuming a Replication Task - TiCDC - Shell\nDESCRIPTION: This example shows how to resume a replication task using a POST request. The `changefeed_id` is used as a path parameter to specify the replication task to be resumed.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://127.0.0.1:8300/api/v1/changefeeds/test1/resume\n```\n\n----------------------------------------\n\nTITLE: Defining DDL Event Value Format in JSON\nDESCRIPTION: Describes the value format for DDL Events. It contains the DDL query and DDL type.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"q\":<DDL Query>,\n    \"t\":<DDL Type>\n}\n```\n\n----------------------------------------\n\nTITLE: Cleanup Operations in pt-osc\nDESCRIPTION: SQL statements used by pt-osc to clean up the '_old' table and triggers after the schema change is complete. DM doesn't execute these operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nDROP TABLE IF EXISTS `test`.`_test4_old`;\nDROP TRIGGER IF EXISTS `pt_osc_test_test4_del` AFTER DELETE ON `test`.`test4` ...... ;\nDROP TRIGGER IF EXISTS `pt_osc_test_test4_upd` AFTER UPDATE ON `test`.`test4` ...... ;\nDROP TRIGGER IF EXISTS `pt_osc_test_test4_ins` AFTER INSERT ON `test`.`test4` ...... ;\n```\n\n----------------------------------------\n\nTITLE: Updating Data in TiDB with Go-MySQL-Driver\nDESCRIPTION: Example of updating data in a 'player' table using Go-MySQL-Driver. It demonstrates executing an UPDATE SQL statement with parameterized values to modify existing records.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-golang-sql-driver.md#2025-04-18_snippet_3\n\nLANGUAGE: Go\nCODE:\n```\nopenDB(\"mysql\", func(db *sql.DB) {\n    updateSQL = \"UPDATE player set goods = goods + ?, coins = coins + ? WHERE id = ?\"\n    _, err := db.Exec(updateSQL, 1, -1, \"id\")\n\n    if err != nil {\n        panic(err)\n    }\n})\n```\n\n----------------------------------------\n\nTITLE: Querying Key Ranges with TiDB-CTL\nDESCRIPTION: The `keyrange` command within `tidb-ctl` is used to fetch and display global or table-specific key ranges in a TiDB cluster. Examples demonstrate querying global key ranges, fetching encoded keys using the `--encode` option, and retrieving key ranges relevant to specific databases and tables. The primary dependency is the `tidb-ctl` command line tool and appropriate permissions to query these ranges.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-control.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntidb-ctl keyrange\n```\n\nLANGUAGE: shell\nCODE:\n```\ntidb-ctl keyrange --encode\n```\n\nLANGUAGE: shell\nCODE:\n```\ntidb-ctl keyrange --database test --table ttt\n```\n\n----------------------------------------\n\nTITLE: Setting Public Key for Specific Profile\nDESCRIPTION: This example shows how to set the public key for a specific user profile named 'test' in the TiDB Cloud CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-set.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud config set public-key <public-key> -P test\n```\n\n----------------------------------------\n\nTITLE: MySQL Function Enhancement\nDESCRIPTION: Fix for the behavior of comparison operators and functions in TiDB SQL processing.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.7.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\n!= any()\n```\n\n----------------------------------------\n\nTITLE: Generating ProxySQL Configuration Files\nDESCRIPTION: Command to run the Python script that generates ProxySQL configuration files.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython3 proxysql-config.py\n```\n\n----------------------------------------\n\nTITLE: Querying DATA_LOCK_WAITS Table in SQL\nDESCRIPTION: This system table provides information about pessimistic lock-waiting events occurring on all TiKV nodes in the cluster, including table name, row ID, and index value interpreted from keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.2.0.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.DATA_LOCK_WAITS;\n```\n\n----------------------------------------\n\nTITLE: Creating Non-Partitionable Table with Conflicting Unique Keys - SQL\nDESCRIPTION: This snippet illustrates creating a table that cannot be partitioned due to conflicting unique key definitions. It highlights the importance of aligning unique key definitions with partitioning criteria.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_57\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCREATE TABLE t4 (\n    col1 INT NOT NULL,\n    col2 INT NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    UNIQUE KEY (col1, col3),\n    UNIQUE KEY (col2, col4)\n);\n```\n```\n\n----------------------------------------\n\nTITLE: Querying All TiFlash Nodes in TiKV\nDESCRIPTION: This command filters to find all TiFlash nodes among the stores by their labels, returning the needed store information.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_64\n\nLANGUAGE: bash\nCODE:\n```\nstore --jq='.stores[].store | select(.labels | length>0 and contains([{\\\"key\\\":\\\"engine\\\",\\\"value\\\":\\\"tiflash\\\"}])) | {id, address, state_name}'\n```\n\n----------------------------------------\n\nTITLE: Basic TIMESTAMP Type Declaration\nDESCRIPTION: Syntax for declaring TIMESTAMP type with optional fractional seconds precision parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nTIMESTAMP[(fsp)]\n```\n\n----------------------------------------\n\nTITLE: FLASHBACK CLUSTER with TSO Example in TiDB\nDESCRIPTION: Example showing how to use FLASHBACK CLUSTER with a TSO to precisely restore mistakenly deleted data.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-cluster.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO t VALUES (1);\n\nSELECT * FROM t;\n\nBEGIN;\n\nSELECT @@tidb_current_ts;\n\nROLLBACK;\n\nDELETE FROM t;\n\nFLASHBACK CLUSTER TO TSO 446113975683252225;\n\nSELECT * FROM t;\n```\n\n----------------------------------------\n\nTITLE: Creating a Sequence with Custom Parameters\nDESCRIPTION: Example of creating a sequence 'seq2' with custom start, increment, min/max values, and cache size.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-sequence.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SEQUENCE seq2 start 3 increment 2 minvalue 1 maxvalue 10 cache 3;\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAPI Generator Client Library\nDESCRIPTION: This command installs OpenAPI Generator as a development dependency in the Next.js project. This is necessary for generating API client libraries from the OpenAPI Specification.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-oas-with-nextjs.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nyarn add @openapitools/openapi-generator-cli --dev\n```\n\n----------------------------------------\n\nTITLE: Alias Command for Listing User Profiles\nDESCRIPTION: An alternative command that serves as an alias for 'ticloud config list'. It provides the same functionality with a shorter syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-list.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud config ls [flags]\n```\n\n----------------------------------------\n\nTITLE: Enabling Explicit Insertion for AUTO_RANDOM Primary Keys\nDESCRIPTION: SQL commands to enable explicit insertion on AUTO_RANDOM columns by setting the allow_auto_random_explicit_insert variable to true, followed by an insert statement that specifies the AUTO_RANDOM column value.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-insert-data.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSET @@allow_auto_random_explicit_insert = true;\nINSERT INTO `bookshop`.`users` (`id`, `balance`, `nickname`) VALUES (1, 0.00, 'nicky');\n```\n\n----------------------------------------\n\nTITLE: Table Name Capture Configuration for File Patterns in TiDB Lightning\nDESCRIPTION: Configuration for capturing table name from regex pattern matching. The $2 refers to the second capture group in the pattern expression used for parsing files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\n'$2'\n```\n\n----------------------------------------\n\nTITLE: Listing Serverless Import Tasks - JSON Output\nDESCRIPTION: Command to list import tasks with JSON output format for complete result retrieval\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-list.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import list --cluster-id <cluster-id> --output json\n```\n\n----------------------------------------\n\nTITLE: Starting ProxySQL Container with Docker Compose\nDESCRIPTION: Command to pull the ProxySQL image and start a ProxySQL container in the background using Docker Compose.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Defining Critical Alert Rule for TiCDC Changefeed Failure in YAML\nDESCRIPTION: YAML configuration for a critical alert rule that triggers when a TiCDC replication task encounters an unrecoverable error and enters the failed state.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-alert-rules.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n(max_over_time(ticdc_owner_status[1m]) == 2) > 0\n```\n\n----------------------------------------\n\nTITLE: Checking TiDB Server OOM Using Shell Command\nDESCRIPTION: Command to check OOM-killer logs for tidb-server using dmesg\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndmesg -T | grep tidb-server\n```\n\n----------------------------------------\n\nTITLE: Configuring Changefeed for Eventual Consistency - TOML\nDESCRIPTION: This TOML configuration sets parameters for ensuring eventual consistency in TiCDC during disaster scenarios. It specifies options such as consistency level, max log size, flush interval, and storage path for redo logs.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-mysql.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[consistent]\n# Consistency level. Options include:\n# - none: the default value. In a non-disaster scenario, eventual consistency is only guaranteed if and only if finished-ts is specified.\n# - eventual: Uses redo log to guarantee eventual consistency in case of the primary cluster disasters.\nlevel = \"eventual\"\n\n# Individual redo log file size, in MiB. By default, it's 64. It is recommended to be no more than 128.\nmax-log-size = 64\n\n# The interval for flushing or uploading redo logs to Amazon S3, in milliseconds. It is recommended that this configuration be equal to or greater than 2000.\nflush-interval = 2000\n\n# The path under which redo log backup is stored. The scheme can be nfs (NFS directory), or Amazon S3, GCS, and Azure (uploaded to object storage).\nstorage = \"$SCHEME://logbucket/test-changefeed?endpoint=http://$ENDPOINT/\"\n```\n\n----------------------------------------\n\nTITLE: Starting DM Cluster\nDESCRIPTION: Command to start a deployed DM cluster using TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm start dm-test\n```\n\n----------------------------------------\n\nTITLE: Installing HAProxy Dependencies on Linux\nDESCRIPTION: Command to install required dependencies for HAProxy including epel-release, gcc, and systemd-devel using yum package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/haproxy-best-practices.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyum -y install epel-release gcc systemd-devel\n```\n\n----------------------------------------\n\nTITLE: Using tiup dm restart Command in Shell\nDESCRIPTION: Basic syntax for restarting services in a DM cluster. The command requires a cluster name and supports optional flags for targeting specific nodes or roles.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-restart.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm restart <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Connection Pool Size Formula for HDD Systems\nDESCRIPTION: Formula for calculating optimal connection pool size when using traditional hard disk drives (HDD). The formula accounts for CPU cores and effective spindle count for maximum throughput.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nconnections = ((core_count * 2) + effective_spindle_count)\n```\n\n----------------------------------------\n\nTITLE: Stopping TiDB Lightning in Shell\nDESCRIPTION: This shell command is used to terminate the TiDB Lightning process manually. Use Ctrl+C if running in the foreground, or kill the process with its PID retrieved using `ps aux | grep tidb-lightning` if running in the background. Applicable only for manually deployed TiDB Lightning processes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-faq.md#2025-04-18_snippet_2\n\n\n\n----------------------------------------\n\nTITLE: Fixing NOT NOT Column Optimization in TiDB\nDESCRIPTION: Corrects an issue where (NOT NOT col) was incorrectly optimized as col.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_29\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM table WHERE NOT NOT column = value\n```\n\n----------------------------------------\n\nTITLE: Checking TiFlash Proxy Status via pd-ctl\nDESCRIPTION: This command uses `pd-ctl` to retrieve information about the stores in the cluster, including the TiFlash proxy. By examining the `store.labels`, you can confirm if a specific store is a TiFlash proxy, which is identified by the `engine: tiflash` label.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n```shell\ntiup ctl:nightly pd -u http://${pd-ip}:${pd-port} store\n```\n```\n\n----------------------------------------\n\nTITLE: Creating a Data Source (Shell/JSON)\nDESCRIPTION: Example of using curl to create a data source via the API and the expected JSON response.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'POST' \\\n  'http://127.0.0.1:8261/api/v1/sources' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source_name\": \"mysql-01\",\n  \"host\": \"127.0.0.1\",\n  \"port\": 3306,\n  \"user\": \"root\",\n  \"password\": \"123456\",\n  \"enable\": true,\n  \"enable_gtid\": false,\n  \"security\": {\n    \"ssl_ca_content\": \"\",\n    \"ssl_cert_content\": \"\",\n    \"ssl_key_content\": \"\",\n    \"cert_allowed_cn\": [\n      \"string\"\n    ]\n  },\n  \"purge\": {\n    \"interval\": 3600,\n    \"expires\": 0,\n    \"remain_space\": 15\n  }\n}'\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"source_name\": \"mysql-01\",\n  \"host\": \"127.0.0.1\",\n  \"port\": 3306,\n  \"user\": \"root\",\n  \"password\": \"123456\",\n  \"enable\": true,\n  \"enable_gtid\": false,\n  \"security\": {\n    \"ssl_ca_content\": \"\",\n    \"ssl_cert_content\": \"\",\n    \"ssl_key_content\": \"\",\n    \"cert_allowed_cn\": [\n      \"string\"\n    ]\n  },\n  \"purge\": {\n    \"interval\": 3600,\n    \"expires\": 0,\n    \"remain_space\": 15\n  },\n  \"status_list\": [\n    {\n      \"source_name\": \"mysql-replica-01\",\n      \"worker_name\": \"worker-1\",\n      \"relay_status\": {\n        \"master_binlog\": \"(mysql-bin.000001, 1979)\",\n        \"master_binlog_gtid\": \"e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849\",\n        \"relay_dir\": \"./sub_dir\",\n        \"relay_binlog_gtid\": \"e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849\",\n        \"relay_catch_up_master\": true,\n        \"stage\": \"Running\"\n      },\n      \"error_msg\": \"string\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Selecting Orders with Filters and Sorting - SQL\nDESCRIPTION: This SQL query retrieves rows from the orders table based on multiple filter conditions, including mode, user_id, and date range, and sorts the results by order ID. However, it demonstrates inefficient execution due to lack of optimal indexing.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSELECT `orders`.*\nFROM `orders`\nWHERE \n    `orders`.`mode` = 'production'\n    AND `orders`.`user_id` = 11111\n    AND orders.label_id IS NOT NULL\n    AND orders.created_at >= '2024-04-07 18:07:52'\n    AND orders.created_at <= '2024-05-11 18:07:52'\n    AND orders.id >= 1000000000\n    AND orders.id < 1500000000\nORDER BY orders.id DESC \nLIMIT 101;\n```\n\n----------------------------------------\n\nTITLE: Performing Full Backup Using BR\nDESCRIPTION: Execute a full backup of the existing TiDB cluster using BR (Backup & Restore) tool, preparing for migration to a new cluster\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup br:${cluster_version} backup full --pd ${pd_host}:${pd_port} -s ${backup_location}\n```\n\n----------------------------------------\n\nTITLE: DM Control Commands in Bash\nDESCRIPTION: Collection of command-line operations for managing DM tasks including creating sources, starting/stopping tasks and querying status\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/migrate-data-using-dm.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup dmctl --master-addr 172.16.10.71:8261 operate-source create conf/source1.yaml\ntiup dmctl --master-addr 172.16.10.71:8261 start-task ./task.yaml\ntiup dmctl --master-addr 172.16.10.71:8261 query-status\ntiup dmctl --master-addr 172.16.10.71:8261 stop-task test\n```\n\n----------------------------------------\n\nTITLE: Getting TiUP Help Information\nDESCRIPTION: Command to get help information for TiUP, displaying available commands, usage examples, and flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-overview.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup --help\n```\n\nLANGUAGE: bash\nCODE:\n```\nTiUP is a command-line component management tool that can help to download and install\nTiDB platform components to the local system. You can run a specific version of a component via\n\"tiup <component>[:version]\". If no version number is specified, the latest version installed\nlocally will be used. If the specified component does not have any version installed locally,\nthe latest stable version will be downloaded from the repository.\n\nUsage:\n  tiup [flags] <command> [args...]\n  tiup [flags] <component> [args...]\n  tiup [command]\n\nExamples:\n  $ tiup playground                    # Quick start\n  $ tiup playground nightly            # Start a playground with the latest nightly version\n  $ tiup install <component>[:version] # Install a component of specific version\n  $ tiup update --all                  # Update all installed components to the latest version\n  $ tiup update --nightly              # Update all installed components to the nightly version\n  $ tiup update --self                 # Update the \"tiup\" to the latest version\n  $ tiup list                          # Fetch the latest supported components list\n  $ tiup status                        # Display all running/terminated instances\n  $ tiup clean <name>                  # Clean the data of running/terminated instance (Kill process if it's running)\n  $ tiup clean --all                   # Clean the data of all running/terminated instances\n\nAvailable Commands:\n  install     Install a specific version of a component\n  list        List the available TiDB components or versions\n  uninstall   Uninstall components or versions of a component\n  update      Update tiup components to the latest version\n  status      List the status of instantiated components\n  clean       Clean the data of instantiated components\n  mirror      Manage a repository mirror for TiUP components\n  telemetry   Controls things about telemetry\n  env         Show the list of system environment variable that related to TiUP\n  history     Display the historical execution record of TiUP, displays 100 lines by default\n  link        Link component binary to $TIUP_HOME/bin/\n  unlink      Unlink component binary to $TIUP_HOME/bin/\n  help        Help about any command\n  completion  Generate the autocompletion script for the specified shell\n\nFlags:\n      --binary <component>[:version]   Print binary path of a specific version of a component <component>[:version]\n                                       and the latest version installed will be selected if no version specified\n      --binpath string                 Specify the binary path of component instance\n  -h, --help                           help for tiup\n  -T, --tag string                     [Deprecated] Specify a tag for component instance\n  -v, --version                        Print the version of tiup\n\nUse \"tiup [command] --help\" for more information about a command.\n```\n\n----------------------------------------\n\nTITLE: Using TIDB_PARSE_TSO to Extract Physical Timestamp\nDESCRIPTION: Demonstrates using TIDB_PARSE_TSO function to extract the physical timestamp component from a TSO (Time Stamp Oracle) timestamp. This example uses the current transaction timestamp.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN;\nSELECT TIDB_PARSE_TSO(@@tidb_current_ts);\nROLLBACK;\n```\n\n----------------------------------------\n\nTITLE: Executing Commands on TiDB Cluster Hosts\nDESCRIPTION: Usage of the exec command to run shell commands on specific nodes or roles within a TiDB cluster. Includes command structure and example for executing ls command.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster exec test-cluster --command='ls /tmp'\n```\n\n----------------------------------------\n\nTITLE: Query Changefeed Configuration with CDC CLI\nDESCRIPTION: This command uses the `cdc cli` tool to query the configuration of a specific changefeed. It filters the output to display the `sort-engine` setting, which indicates whether Unified Sorter is enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli --server=\"http://10.0.10.25:8300\" changefeed query --changefeed-id=simple-replication-task | grep 'sort-engine'\n```\n\n----------------------------------------\n\nTITLE: Unsupported Date Formatting Options in TiDB\nDESCRIPTION: Lists the date and time formatting options that are not implemented in TiDB's STR_TO_DATE() function. These include various week and weekday formatting patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/date-and-time-functions.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n\"%a\"   | Abbreviated weekday name (Sun..Sat)\n\"%D\"   | Day of the month with English suffix (0th, 1st, 2nd, 3rd)\n\"%U\"   | Week (00..53), where Sunday is the first day of the week; WEEK() mode 0\n\"%u\"   | Week (00..53), where Monday is the first day of the week; WEEK() mode 1\n\"%V\"   | Week (01..53), where Sunday is the first day of the week; WEEK() mode 2; used with %X\n\"%v\"   | Week (01..53), where Monday is the first day of the week; WEEK() mode 3; used with %x\n\"%W\"   | Weekday name (Sunday..Saturday)\n\"%w\"   | Day of the week (0=Sunday..6=Saturday)\n\"%X\"   | Year for the week where Sunday is the first day of the week, numeric, four digits\n\"%x\"   | Year for the week, where Monday is the first day of the week, numeric, four digits\n```\n\n----------------------------------------\n\nTITLE: SQL Non-Prepared Plan Cache Configuration\nDESCRIPTION: Experimental feature supporting automatic plan cache reuse at the session level to reduce query compilation time and improve performance for repetitive SQL patterns\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.0.0.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n-- Non-prepared plan cache (session level)\n```\n\n----------------------------------------\n\nTITLE: Deprecating TiFlash HTTP Service Port\nDESCRIPTION: Security improvement in TiFlash by replacing the default HTTP service port (8123) with gRPC port. This change affects system table access during upgrade to v7.1.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.1.0.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n* To improve security, TiFlash deprecates the HTTP service port (default `8123`) and uses the gRPC port as a replacement\n```\n\n----------------------------------------\n\nTITLE: Syntax for SHOW IMPORT - EBNF\nDESCRIPTION: This EBNF diagram defines the syntax structure for the SHOW IMPORT statements, including both showing all jobs and specific job details.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-import-job.md#2025-04-18_snippet_2\n\nLANGUAGE: ebnf\nCODE:\n```\nShowImportJobsStmt ::=\n    'SHOW' 'IMPORT' 'JOBS'\n\nShowImportJobStmt ::=\n    'SHOW' 'IMPORT' 'JOB' JobID\n```\n\n----------------------------------------\n\nTITLE: Retrieving Disk Serial ID\nDESCRIPTION: Command to get the ID_SERIAL of a disk device for identification purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_27\n\nLANGUAGE: bash\nCODE:\n```\nudevadm info --name=/dev/sdb | grep ID_SERIAL\n```\n\n----------------------------------------\n\nTITLE: Viewing MySQL Binlog Position in Dumpling Metadata\nDESCRIPTION: Example of a metadata file exported by Dumpling for MySQL instance1, showing the binlog position and GTID information for configuring replication starting point.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\nStarted dump at: 2022-05-25 10:16:26\nSHOW MASTER STATUS:\n       Log: mysql-bin.000002\n       Pos: 246546174\n       GTID:b631bcad-bb10-11ec-9eee-fec83cf2b903:1-194801\nFinished dump at: 2022-05-25 10:16:27\n```\n\n----------------------------------------\n\nTITLE: Checking Replication Mode Status with curl (Bash)\nDESCRIPTION: Bash command using curl to query the PD API for checking the current replication status of the TiDB cluster. Helps verify the current mode and state of replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/two-data-centers-in-one-city-deployment.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://pd_ip:pd_port/pd/api/v1/replication_mode/status\n```\n\n----------------------------------------\n\nTITLE: Compacting Physical Data in TiFlash Tables with SQL (SQL)\nDESCRIPTION: TiDB 6.2.0 makes the physical data compaction feature Generally Available (GA). This allows manually executing SQL statements to compact physical data in TiFlash tables, reducing storage space usage and improving query performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.2.0.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE <table_name> COMPACT;\n```\n\n----------------------------------------\n\nTITLE: Reloading Prometheus Configuration\nDESCRIPTION: Command to reload Prometheus configuration after making changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-faq.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster reload ${cluster-name} --role prometheus\n```\n\n----------------------------------------\n\nTITLE: Setting Up TiDB Cluster with TiCDC Using TiUP Playground - Shell\nDESCRIPTION: Deploys a TiDB cluster with TiCDC included using the TiUP Playground command, and checks the cluster status.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-data-to-kafka.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground --host 0.0.0.0 --db 1 --pd 1 --kv 1 --tiflash 0 --ticdc 1\n# View cluster status\ntiup status\n```\n\n----------------------------------------\n\nTITLE: Conditional Use of SHOW STATS_HISTOGRAMS in TiDB\nDESCRIPTION: Illustrates how to utilize the SHOW STATS_HISTOGRAMS statement with a WHERE condition to filter results for a specific table. This example targets the table named 't2' to constrain the output.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-histograms.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW STATS_HISTOGRAMS WHERE table_name = 't2';\n```\n\n----------------------------------------\n\nTITLE: Setting Up Garbage Collection in TiKV YAML\nDESCRIPTION: YAML configuration for TiKV garbage collection, including batch size, write speed limit, and thread count.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_29\n\nLANGUAGE: yaml\nCODE:\n```\ngc:\n  batch-keys: 512\n  max-write-bytes-per-sec: \"0\"\n  enable-compaction-filter: true\n  ratio-threshold: 1.1\n  num-threads: 1\n```\n\n----------------------------------------\n\nTITLE: Creating Data Source Configuration in TiDB Data Migration\nDESCRIPTION: This example shows how to use the operate-source command to create a new data source configuration in TiDB Data Migration. It references a source.yaml file for the configuration details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-manage-source.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\noperate-source create ./source.yaml\n```\n\n----------------------------------------\n\nTITLE: Checking the Effectiveness of SET_VAR in Subqueries\nDESCRIPTION: This SQL example illustrates the ineffectiveness of `SET_VAR` hints within subqueries. The snippet emphasizes that `SET_VAR` should be applied at the top-level query to function correctly as subqueries handle it differently, leading to unexpected results.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_62\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> SELECT @@MAX_EXECUTION_TIME, a FROM (SELECT /*+ SET_VAR(MAX_EXECUTION_TIME=123) */ 1 as a) t;\\n+----------------------+---+\\n| @@MAX_EXECUTION_TIME | a |\\n+----------------------+---+\\n|                    0 | 1 |\\n+----------------------+---+\\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Cloud CLI via TiUP on macOS/Linux\nDESCRIPTION: This snippet demonstrates how to install the TiDB Cloud CLI using TiUP, a tool for managing TiDB clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup install cloud\n```\n\n----------------------------------------\n\nTITLE: Displaying the cluster name list using TiUP\nDESCRIPTION: This command is used to list all the TiDB clusters managed by TiUP. It helps in identifying the cluster that needs to be scaled or modified.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster list\"\n```\n\n----------------------------------------\n\nTITLE: Querying Current Slow Log Without Time Range\nDESCRIPTION: SQL query to count slow queries and display the minimum and maximum timestamps from the current slow log file without specifying a time range.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nselect count(*),\n      min(time),\n      max(time)\nfrom slow_query;\n```\n\n----------------------------------------\n\nTITLE: TiKV Parameter Configuration in YAML\nDESCRIPTION: This snippet shows the YAML configuration for enabling the `prefill-for-recycle` parameter in TiKV. This parameter is intended to make log recycling effective immediately after initialization. It's used for specific Sysbench workloads during the performance testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.5-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_1\n\nLANGUAGE: YAML\nCODE:\n```\n\"raft-engine.prefill-for-recycle = true\"\n```\n\n----------------------------------------\n\nTITLE: Modifying TiKV Configuration - Disable Auto Compactions\nDESCRIPTION: This command disables auto compactions for the default column family in TiKV, which may be necessary for certain performance tuning.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --host ip:port modify-tikv-config -n raftdb.defaultcf.disable-auto-compactions -v true\n```\n\n----------------------------------------\n\nTITLE: Querying TIDB_HOT_REGIONS Table Structure in SQL\nDESCRIPTION: This SQL query displays the structure of the TIDB_HOT_REGIONS table in the information_schema database. It shows the column names, data types, and other attributes of the table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-hot-regions.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC tidb_hot_regions;\n```\n\n----------------------------------------\n\nTITLE: Describing CLUSTER_SYSTEMINFO Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the CLUSTER_SYSTEMINFO table, showing its fields, types, and properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-systeminfo.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE information_schema;\nDESC cluster_systeminfo;\n```\n\n----------------------------------------\n\nTITLE: Configuring Username/Password Authentication in TiCDC Server\nDESCRIPTION: Enable username and password authentication by configuring client-user-required and client-allowed-user parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-client-authentication.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[security]\n# This parameter controls whether to use username and password for client authentication. The default value is false.\nclient-user-required = true\n# This parameter lists the usernames that are allowed for client authentication. Authentication requests with usernames not in this list will be rejected. The default value is null.\nclient-allowed-user = [\"test\"]\n```\n\n----------------------------------------\n\nTITLE: SCHEMATA Query Results in TiDB\nDESCRIPTION: Shows sample output from querying the SCHEMATA table, displaying all databases in the TiDB instance with their character sets and collations.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-schemata.md#2025-04-18_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n+--------------+--------------------+----------------------------+------------------------+----------+\n| CATALOG_NAME | SCHEMA_NAME        | DEFAULT_CHARACTER_SET_NAME | DEFAULT_COLLATION_NAME | SQL_PATH |\n+--------------+--------------------+----------------------------+------------------------+----------+\n| def          | INFORMATION_SCHEMA | utf8mb4                    | utf8mb4_bin            | NULL     |\n| def          | METRICS_SCHEMA     | utf8mb4                    | utf8mb4_bin            | NULL     |\n| def          | mysql              | utf8mb4                    | utf8mb4_bin            | NULL     |\n| def          | PERFORMANCE_SCHEMA | utf8mb4                    | utf8mb4_bin            | NULL     |\n| def          | test               | utf8mb4                    | utf8mb4_bin            | NULL     |\n+--------------+--------------------+----------------------------+------------------------+----------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: FastScan Mechanism Description in TiFlash\nDESCRIPTION: This section explains the operational mechanism of FastScan in TiFlash, outlining how data is processed without sacrificing performance but with a potential trade-off on data consistency. It specifically describes how the TableScan operator functions under both normal conditions and when FastScan is enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-fastscan.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n1. Read data: create separate data streams in the Delta layer and Stable layer to read the respective data.\n2. Sort Merge: merge the data streams created in step 1. Then return the data after sorting in the order of (primary key column, timestamp column).\n3. Range Filter: according to the data range, filter the data generated in step 2, and then return the data.\n4. MVCC + Column Filter: filter the data generated in step 3 through MVCC (that is, filtering the data version according to the primary key column and the timestamp column) and through columns (that is, filtering out unneeded columns), and then return the data.\n```\n\n----------------------------------------\n\nTITLE: Configuring NGINX Root Path Reverse Proxy for TiDB Dashboard\nDESCRIPTION: NGINX configuration for proxying TiDB Dashboard at the root path. Includes server block with root location routing.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_10\n\nLANGUAGE: nginx\nCODE:\n```\nserver {\n  listen 8033;\n  location / {\n    proxy_pass http://192.168.0.123:2379/dashboard/;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Metadata Lock Information in TiDB\nDESCRIPTION: This SQL query selects from the mysql.tidb_mdl_view to obtain information about currently blocked DDL operations. It requires the PROCESS privilege.\nSOURCE: https://github.com/pingcap/docs/blob/master/metadata-lock.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nTABLE mysql.tidb_mdl_view\\G\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW PLACEMENT Statement Syntax in EBNF\nDESCRIPTION: This snippet defines the EBNF syntax for the SHOW PLACEMENT statement, which summarizes placement options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-placement.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowStmt ::=\\\n    \"SHOW\" \"PLACEMENT\" ShowLikeOrWhere?\n```\n\n----------------------------------------\n\nTITLE: Using Dumpling with Table Filters\nDESCRIPTION: Example of using table filters with Dumpling tool to export schemas matching 'foo*' and 'bar*' patterns\nSOURCE: https://github.com/pingcap/docs/blob/master/table-filter.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup dumpling -f 'foo*.*' -f 'bar*.*' -P 3306 -o /tmp/data/\n```\n\n----------------------------------------\n\nTITLE: Configuring Component Versions in YAML\nDESCRIPTION: This YAML snippet demonstrates how to specify the version of a component within the TiDB cluster. It ensures that the specified versions are used in cluster scaling and upgrade operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n\"component_versions:\\n  kvcdc: \\\"v1.1.1\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Setting region to US for international Clinic Server\nDESCRIPTION: Command to configure Diag to use the US region for international users, which determines the encryption certificate and target service for data uploads.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/quick-start-with-clinic.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag config clinic.region US\n```\n\n----------------------------------------\n\nTITLE: Executing Test Queries in TiDB\nDESCRIPTION: Executes three similar SELECT queries with different conditions to demonstrate plan cache behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-non-prepared-plan-cache.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t WHERE a<1;\nSELECT * FROM t WHERE a<2;\nSELECT * FROM t WHERE a<3;\n```\n\n----------------------------------------\n\nTITLE: Retrieving Current TSO in a TiDB Transaction\nDESCRIPTION: This snippet demonstrates how to get the current TSO timestamp in TiDB by using a transaction with BEGIN and ROLLBACK statements, and storing the timestamp in a variable using the @@tidb_current_ts system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/tso.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN; SET @ts := @@tidb_current_ts; ROLLBACK;\nQuery OK, 0 rows affected (0.0007 sec)\nQuery OK, 0 rows affected (0.0002 sec)\nQuery OK, 0 rows affected (0.0001 sec)\n\nSELECT @ts;\n+--------------------+\n| @ts                |\n+--------------------+\n| 443852055297916932 |\n+--------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: DM Validation Status Output\nDESCRIPTION: Example JSON output showing the validation status details including task name, source, mode, and various statistics about processed rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-continuous-data-validation.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n\"subTaskStatus\": [\n    {\n        \"name\": \"test\",\n        \"stage\": \"Running\",\n        \"unit\": \"Sync\",\n        \"result\": null,\n        \"unresolvedDDLLockID\": \"\",\n        \"sync\": {},\n        \"validation\": {\n            \"task\": \"test\",\n            \"source\": \"mysql-01\",\n            \"mode\": \"full\",\n            \"stage\": \"Running\",\n            \"validatorBinlog\": \"(mysql-bin.000001, 5989)\",\n            \"validatorBinlogGtid\": \"1642618e-cf65-11ec-9e3d-0242ac110002:1-30\",\n            \"cutoverBinlogPos\": \"\",\n            \"cutoverBinlogGTID\": \"1642618e-cf65-11ec-9e3d-0242ac110002:1-30\",\n            \"result\": null,\n            \"processedRowsStatus\": \"insert/update/delete: 0/0/0\",\n            \"pendingRowsStatus\": \"insert/update/delete: 0/0/0\",\n            \"errorRowsStatus\": \"new/ignored/resolved: 0/0/0\"\n        }\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW INDEXES in SQL\nDESCRIPTION: This SQL code snippet demonstrates the execution of the SHOW INDEXES statement to list the indexes of a table in TiDB. The snippet shows creating a table and then retrieving the index information using variations of the SHOW INDEX statement. It verifies compatibility with MySQL by using MySQL-like syntax and displaying detailed index meta-information.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-indexes.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id int not null primary key AUTO_INCREMENT, col1 INT, INDEX(col1));\nQuery OK, 0 rows affected (0.12 sec)\n\nmysql> SHOW INDEXES FROM t1;\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\n| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression |\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\n| t1    |          0 | PRIMARY  |            1 | id          | A         |           0 |     NULL | NULL   |      | BTREE      |         |               | YES     | NULL       |\n| t1    |          1 | col1     |            1 | col1        | A         |           0 |     NULL | NULL   | YES  | BTREE      |         |               | YES     | NULL       |\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\n2 rows in set (0.00 sec)\n\nmysql> SHOW INDEX FROM t1;\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\n| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression |\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\n| t1    |          0 | PRIMARY  |            1 | id          | A         |           0 |     NULL | NULL   |      | BTREE      |         |               | YES     | NULL       |\n| t1    |          1 | col1     |            1 | col1        | A         |           0 |     NULL | NULL   | YES  | BTREE      |         |               | YES     | NULL       |\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\n2 rows in set (0.00 sec)\n\nmysql> SHOW KEYS FROM t1;\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\n| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression |\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\n| t1    |          0 | PRIMARY  |            1 | id          | A         |           0 |     NULL | NULL   |      | BTREE      |         |               | YES     | NULL       |\n| t1    |          1 | col1     |            1 | col1        | A         |           0 |     NULL | NULL   | YES  | BTREE      |         |               | YES     | NULL       |\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+\n2 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Filter Out SQL Statements Not Supported by TiDB - YAML\nDESCRIPTION: This snippet details how to create a filter rule specifically to ignore SQL statements that TiDB does not support by using SQL patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/filter-binlog-event.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nfilters:\n  filter-procedure-rule:\n    schema-pattern: \"*\"\n    sql-pattern: [\".*\\\\s+DROP\\\\s+PROCEDURE\", \".*\\\\s+CREATE\\\\s+PROCEDURE\", \"ALTER\\\\s+TABLE[\\\\s\\\\S]*ADD\\\\s+PARTITION\", \"ALTER\\\\s+TABLE[\\\\s\\\\S]*DROP\\\\s+PARTITION\"]\n    action: Ignore\n```\n\n----------------------------------------\n\nTITLE: Creating Table with CHECK Constraint\nDESCRIPTION: Demonstrates how to create a table with a CHECK constraint and query the constraint information.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-check-constraints.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_check_constraint = ON;\nCREATE TABLE test.t1 (id INT PRIMARY KEY, CHECK (id%2 = 0));\nSELECT * FROM CHECK_CONSTRAINTS\\G\n```\n\n----------------------------------------\n\nTITLE: Granting User Access to a TiUP Mirror\nDESCRIPTION: Sets the mirror location and grants a user ownership permissions using their private key.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ntiup mirror set /data/mirror\ntiup mirror grant jdoe\n```\n\n----------------------------------------\n\nTITLE: TiDB Lightning TOML Configuration\nDESCRIPTION: Example of configuring table filters in TiDB Lightning's TOML configuration file\nSOURCE: https://github.com/pingcap/docs/blob/master/table-filter.md#2025-04-18_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[mydumper]\nfilter = ['foo*.*', 'bar*.*']\n```\n\n----------------------------------------\n\nTITLE: Configure Memory Limits for Pessimistic Locks\nDESCRIPTION: TOML configuration to set memory limits for in-memory pessimistic locks per Region and instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/pessimistic-transaction.md#2025-04-18_snippet_9\n\nLANGUAGE: toml\nCODE:\n```\n[pessimistic-txn]\nin-memory-peer-size-limit = \"512KiB\"\nin-memory-instance-size-limit = \"100MiB\"\n```\n\n----------------------------------------\n\nTITLE: Importing CSV Files from Google Cloud Storage to TiDB Cloud\nDESCRIPTION: Detailed steps for importing CSV files from Google Cloud Storage buckets to TiDB Cloud clusters, including configuration options, URI formatting, and advanced mapping settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-csv-files.md#2025-04-18_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n1. Open the **Import** page for your target cluster.\n\n    1. Log in to the [TiDB Cloud console](https://tidbcloud.com/) and navigate to the [**Clusters**](https://tidbcloud.com/console/clusters) page of your project.\n\n        > **Tip:**\n        >\n        > If you have multiple projects, you can click <MDSvgIcon name=\"icon-left-projects\" /> in the lower-left corner and switch to another project.\n\n    2. Click the name of your target cluster to go to its overview page, and then click **Import** in the left navigation pane.\n\n2. Click **Import Data** in the upper-right corner.\n\n    If this is your first time importing data into this cluster, select **Import From GCS**.\n\n3. On the **Import Data from GCS** page, provide the following information for the source CSV files:\n\n    - **Import File Count**: select **One file** or **Multiple files** as needed.\n    - **Included Schema Files**: this field is only visible when importing multiple files. If the source folder contains the target table schemas, select **Yes**. Otherwise, select **No**.\n    - **Data Format**: select **CSV**.\n    - **File URI** or **Folder URI**:\n        - When importing one file, enter the source file URI and name in the following format `gs://[bucket_name]/[data_source_folder]/[file_name].csv`. For example, `gs://sampledata/ingest/TableName.01.csv`.\n        - When importing multiple files, enter the source file URI and name in the following format `gs://[bucket_name]/[data_source_folder]/`. For example, `gs://sampledata/ingest/`.\n    - **Bucket Access**: you can use a GCS IAM Role to access your bucket. For more information, see [Configure GCS access](/tidb-cloud/config-s3-and-gcs-access.md#configure-gcs-access).\n\n4. Click **Connect**.\n\n5. In the **Destination** section, select the target database and table.\n\n    When importing multiple files, you can use **Advanced Settings** > **Mapping Settings** to define a custom mapping rule for each target table and its corresponding CSV file. After that, the data source files will be re-scanned using the provided custom mapping rule.\n\n    When you enter the source file URI and name in **Source File URIs and Names**, make sure it is in the following format `gs://[bucket_name]/[data_source_folder]/[file_name].csv`. For example, `gs://sampledata/ingest/TableName.01.csv`.\n\n    You can also use wildcards to match the source files. For example:\n\n    - `gs://[bucket_name]/[data_source_folder]/my-data?.csv`: all CSV files starting with `my-data` followed by one character (such as `my-data1.csv` and `my-data2.csv`) in that folder will be imported into the same target table.\n\n    - `gs://[bucket_name]/[data_source_folder]/my-data*.csv`: all CSV files in the folder starting with `my-data` will be imported into the same target table.\n\n    Note that only `?` and `*` are supported.\n\n    > **Note:**\n    >\n    > The URI must contain the data source folder.\n\n6. Click **Start Import**.\n\n7. When the import progress shows **Completed**, check the imported tables.\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB Log Backup Status\nDESCRIPTION: Checks the status of an ongoing log backup task, displaying information such as task name, status, timestamps, and progress.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-guide.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log status --task-name=pitr --pd \"${PD_IP}:2379\"\n```\n\n----------------------------------------\n\nTITLE: Querying USER_PRIVILEGES Table Content\nDESCRIPTION: Shows how to retrieve all privilege information from the USER_PRIVILEGES table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-user-privileges.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM USER_PRIVILEGES;\n```\n\n----------------------------------------\n\nTITLE: Listing Tables in METRICS_SCHEMA\nDESCRIPTION: This SQL command shows how to list all available tables in the METRICS_SCHEMA, providing an overview of the metrics available for querying.\nSOURCE: https://github.com/pingcap/docs/blob/master/metrics-schema.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES;\n```\n\n----------------------------------------\n\nTITLE: Explain MIN/MAX queries with IndexFullScan in TiDB\nDESCRIPTION: These SQL statements demonstrate how to use `IndexFullScan` to efficiently find the minimum and maximum values of an indexed column (`intkey`) in a TiDB table (`t1`). The `EXPLAIN` statement reveals the execution plan, showing that `IndexFullScan` is used to read only the first row from each TiKV region to determine the `MIN` or `MAX`.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-indexes.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT MIN(intkey) FROM t1;\nEXPLAIN SELECT MAX(intkey) FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Disabling Pipelined Locking in TiKV Configuration\nDESCRIPTION: TOML configuration snippet to disable the pipelined locking feature in TiKV for pessimistic transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/pessimistic-transaction.md#2025-04-18_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[pessimistic-txn]\npipelined = false\n```\n\n----------------------------------------\n\nTITLE: Example JSON Document Structure for JSONPath Demonstration\nDESCRIPTION: A sample JSON document that demonstrates the structure of a database and migration tool configuration, used to illustrate various JSONPath expressions and their results.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions.md#2025-04-18_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"database\": {\n        \"name\": \"TiDB\",\n        \"features\": [\n            \"distributed\",\n            \"scalable\",\n            \"relational\",\n            \"cloud native\"\n        ],\n        \"license\": \"Apache-2.0 license\",\n        \"versions\": [\n            {\n                \"version\": \"v8.1.0\",\n                \"type\": \"lts\",\n                \"release_date\": \"2024-05-24\" \n            },\n            {\n                \"version\": \"v8.0.0\",        \n                \"type\": \"dmr\",\n                \"release_date\": \"2024-03-29\"\n            }\n        ]\n    },\n    \"migration_tool\": {\n        \"name\": \"TiDB Data Migration\",\n        \"features\": [\n            \"MySQL compatible\",            \n            \"Shard merging\"\n        ],\n        \"license\": \"Apache-2.0 license\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Managing `ERROR 1236` related to purged binary logs\nDESCRIPTION: This snippet provides guidance on handling the `ERROR 1236` message linked to purged binary logs and GTIDs in DM replication, including checks for integrity and configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\n- Check whether the master binlog is purged.\n- Check the position information recorded in `relay.meta`.\n\n    - `relay.meta` has recorded the empty GTID information. DM-worker saves the GTID information in memory to `relay.meta` when it exits or in every 30s. When DM-worker does not obtain the upstream GTID information, it saves the empty GTID information to `relay.meta`. See [case-772](https://github.com/pingcap/tidb-map/blob/master/maps/diagnose-case-study/case772.md) in Chinese.\n\n    - The binlog event recorded in `relay.meta` triggers the incomplete recover process and records the wrong GTID information. This issue is fixed in v1.0.2, and might occur in earlier versions.\n```\n\n----------------------------------------\n\nTITLE: Checking CPU Support for TiFlash on Linux ARM64\nDESCRIPTION: Command to verify ARMv8 instruction set support required for TiFlash deployment on Linux ARM64 architecture.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngrep 'crc32' /proc/cpuinfo | grep 'asimd'\n```\n\n----------------------------------------\n\nTITLE: Basic TiUP Cluster Patch Command Syntax\nDESCRIPTION: The basic syntax for the tiup cluster patch command, which requires a cluster name and package path.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-patch.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster patch <cluster-name> <package-path> [flags]\n```\n\n----------------------------------------\n\nTITLE: Starting node_exporter Service\nDESCRIPTION: Command to start the node_exporter service with specific web listening address and log level configuration\nSOURCE: https://github.com/pingcap/docs/blob/master/deploy-monitoring-services.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd node_exporter-v1.3.1-linux-amd64\n\n# Starts the node_exporter service.\n$ ./node_exporter --web.listen-address=\":9100\" \\\n    --log.level=\"info\" &\n```\n\n----------------------------------------\n\nTITLE: Response Example - Querying TiCDC Service Process List - TiCDC - JSON\nDESCRIPTION: This JSON response shows the basic information returned for each TiCDC capture. It includes the `id`, `is_owner` status, and `address` of each capture.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_19\n\nLANGUAGE: json\nCODE:\n```\n[\n    {\n        \"id\": \"561c3784-77f0-4863-ad52-65a3436db6af\",\n        \"is_owner\": true,\n        \"address\": \"127.0.0.1:8300\"\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Querying VARIABLES_INFO Sample Data\nDESCRIPTION: Demonstrates how to query the VARIABLES_INFO table, showing the first 3 rows ordered by variable name.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-variables-info.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM variables_info ORDER BY variable_name LIMIT 3;\n```\n\n----------------------------------------\n\nTITLE: DM's DDL Transformation for pt-osc\nDESCRIPTION: Examples of how DM transforms the recorded DDL operation from targeting the ghost table to targeting the original table when applying the schema change.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE `test`.`_test4_new` add column c3 int;\n-- Replaced with:\nALTER TABLE `test`.`test4` add column c3 int;\n```\n\n----------------------------------------\n\nTITLE: Setting Default Role in TiDB\nDESCRIPTION: SQL command to set a default role for a user, eliminating the need to manually set the role each session.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-role.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSET DEFAULT ROLE analyticsteam TO jennifer;\n```\n\n----------------------------------------\n\nTITLE: Issuing TiKV Certificate\nDESCRIPTION: Command to issue and generate the TiKV certificate using the root CA, CSR, and custom OpenSSL configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nopenssl x509 -req -days 365 -CA root.crt -CAkey root.key -CAcreateserial -in tikv.csr -out tikv.crt -extensions v3_req -extfile openssl.cnf\n```\n\n----------------------------------------\n\nTITLE: Using tiup dm list Command with Shell\nDESCRIPTION: Basic syntax for the tiup dm list command which displays information about deployed DM clusters. This command shows clusters deployed by the currently logged-in user with details including cluster name, user, version, path, and private key location.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-list.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm list [flags]\n```\n\n----------------------------------------\n\nTITLE: ADMIN CHECKSUM TABLE Syntax Definition in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the ADMIN CHECKSUM TABLE statement, showing the grammar rules for the statement and table name list.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-checksum-table.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAdminChecksumTableStmt ::=\n    'ADMIN' 'CHECKSUM' 'TABLE' TableNameList\n\nTableNameList ::=\n    TableName ( ',' TableName )*\n```\n\n----------------------------------------\n\nTITLE: Cloning TiDB AppFlow Integration Repository\nDESCRIPTION: Command to clone the example code repository containing TiDB and Amazon AppFlow integration code.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-aws-appflow-integration.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/pingcap-inc/tidb-appflow-integration\n```\n\n----------------------------------------\n\nTITLE: Querying a Specific Replication Subtask - TiCDC - Shell\nDESCRIPTION: This example shows how to query the detailed information of a specific replication subtask (processor) using a GET request. The `changefeed_id` and `capture_id` are used as path parameters to identify the target subtask.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v1/processors/test1/561c3784-77f0-4863-ad52-65a3436db6af\n```\n\n----------------------------------------\n\nTITLE: DROP PLACEMENT POLICY Example Output\nDESCRIPTION: Shows the execution results of the placement policy operations, including success messages, error responses, and query results.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-placement-policy.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.10 sec)\n\nQuery OK, 0 rows affected (0.11 sec)\n\nERROR 8241 (HY000): Placement policy 'p1' is still in use\n\n+--------------+------------+\n| table_schema | table_name |\n+--------------+------------+\n| test         | t1         |\n+--------------+------------+\n1 row in set (0.00 sec)\n\nEmpty set (0.01 sec)\n\nQuery OK, 0 rows affected (0.08 sec)\n\nQuery OK, 0 rows affected (0.21 sec)\n```\n\n----------------------------------------\n\nTITLE: Viewing Labels with PD Control\nDESCRIPTION: Shell command for using PD Control to view how the replicas are distributed according to the zone labels set previously, verifying the correct assignment of region replicas based on configured locations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\n> tiup ctl:v<CLUSTER_VERSION> pd -u http://<PD_ADDRESS>:2379 store\n\n    ...\n    \"address\": \"172.16.5.82:23913\",\n    \"labels\": [\n      { \"key\": \"engine\", \"value\": \"tiflash\"},\n      { \"key\": \"zone\", \"value\": \"z1\" }\n    ],\n    \"region_count\": 4,\n\n    ...\n    \"address\": \"172.16.5.81:23913\",\n    \"labels\": [\n      { \"key\": \"engine\", \"value\": \"tiflash\"},\n      { \"key\": \"zone\", \"value\": \"z1\" }\n    ],\n    \"region_count\": 5,\n    ...\n\n    \"address\": \"172.16.5.85:23913\",\n    \"labels\": [\n      { \"key\": \"engine\", \"value\": \"tiflash\"},\n      { \"key\": \"zone\", \"value\": \"z2\" }\n    ],\n    \"region_count\": 9,\n    ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Prometheus Data Retention\nDESCRIPTION: This snippet shows the configuration parameter for setting the data retention period in Prometheus to 60 days.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/monitor-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n--storage.tsdb.retention=\"60d\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Prisma Client with Environment Variables\nDESCRIPTION: Set up Prisma Client using environment variables and the TiDB Cloud adapter in a Node.js environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-prisma-example.md#2025-04-18_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nimport { connect } from '@tidbcloud/serverless';\nimport { PrismaTiDBCloud } from '@tidbcloud/prisma-adapter';\nimport { PrismaClient } from '@prisma/client';\nimport dotenv from 'dotenv';\n\n// setup\ndotenv.config();\nconst connectionString = `${process.env.DATABASE_URL}`;\n\n// Initialize Prisma Client\nconst connection = connect({ url: connectionString });\nconst adapter = new PrismaTiDBCloud(connection);\nconst prisma = new PrismaClient({ adapter });\n```\n\n----------------------------------------\n\nTITLE: Disabling Garbage Collection in TiDB\nDESCRIPTION: SQL command to disable garbage collection when encountering inconsistent index errors. This should be used when reporting bugs related to index inconsistency after running admin check table command fails.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_enable = 0;\n```\n\n----------------------------------------\n\nTITLE: Enabling Relay Log in DM v5.4.0+\nDESCRIPTION: Command to enable relay log for a data source in DM v5.4.0 and later versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/relay-log.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nstart-relay -s mysql-replica-01\n```\n\n----------------------------------------\n\nTITLE: Handling Invalid Arguments in CONVERT_TZ Function (SQL)\nDESCRIPTION: Fixes an issue where the CONVERT_TZ function did not correctly return NULL when given invalid arguments.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.16.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT CONVERT_TZ('2004-01-01 12:00:00', '+00:00', '+10:32');\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Sink Dispatchers in TiCDC\nDESCRIPTION: Example configuration for different partition dispatcher rules that determine how data is distributed across Kafka partitions. This includes index-value, columns, and table-based partitioning strategies.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_12\n\nLANGUAGE: toml\nCODE:\n```\n[sink]\ndispatchers = [\n    {matcher = ['test.*'], partition = \"index-value\"},\n    {matcher = ['test1.*'], partition = \"index-value\", index = \"index1\"},\n    {matcher = ['test2.*'], partition = \"columns\", columns = [\"id\", \"a\"]},\n    {matcher = ['test3.*'], partition = \"table\"},\n]\n```\n\n----------------------------------------\n\nTITLE: Optimizing Thread Pool Settings in TiKV TOML\nDESCRIPTION: This TOML configuration snippet adjusts the gRPC thread pool and raftstore settings based on CPU cores. It aims to optimize resource utilization for write-intensive workloads, especially on high-core instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_18\n\nLANGUAGE: toml\nCODE:\n```\n[server]\n# Increase gRPC thread pool \ngrpc-concurrency = 10\n\n[raftstore]\n# Optimize for write-intensive workloads\napply-pool-size = 4\nstore-pool-size = 4\nstore-io-pool-size = 2\n```\n\n----------------------------------------\n\nTITLE: Get TiCDC Node Status Response\nDESCRIPTION: Example response showing node status information including version, git hash, ID, PID and owner status.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"version\": \"v5.2.0-master-dirty\",\n    \"git_hash\": \"f191cd00c53fdf7a2b1c9308a355092f9bf8824e\",\n    \"id\": \"c6a43c16-0717-45af-afd6-8b3e01e44f5d\",\n    \"pid\": 25432,\n    \"is_owner\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Disabling Placement Rules with pd-ctl\nDESCRIPTION: Command to disable the Placement Rules feature and revert to the previous scheduling strategy using pd-ctl. This will restore the use of max-replicas, location-labels, and isolation-level configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-placement-rules.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules disable\n```\n\n----------------------------------------\n\nTITLE: Defining String Type in JSON Schema\nDESCRIPTION: This JSON snippet specifies how string types are represented in schemas, detailing the column name, type, and maximum length.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_16\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"ColumnName\":\"COL1\",\n    \"ColumnType\":\"{ST}\",\n    \"ColumnLength\":\"{M}\"\n}\n```\n\n----------------------------------------\n\nTITLE: Setting TiKV Periodic Full Compaction Start Times\nDESCRIPTION: Example configuration for specifying multiple time schedules for TiKV's periodic full compaction. The time can be specified in different formats, including local time or with explicit timezone offset.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\nperiodic-full-compact-start-times = [\"03:00\", \"23:00\"]\n```\n\nLANGUAGE: yaml\nCODE:\n```\nperiodic-full-compact-start-times = [\"03:00 +0000\", \"23:00 +0000\"]\n```\n\nLANGUAGE: yaml\nCODE:\n```\nperiodic-full-compact-start-times = [\"03:00 +0800\", \"23:00 +0800\"]\n```\n\n----------------------------------------\n\nTITLE: Simulating Workload with go-tpc in Shell\nDESCRIPTION: These commands use go-tpc to write data to the TiDB cluster. It creates a database named 'tpcc' and runs a TPC-C workload for 300 seconds.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-mysql.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup bench tpcc -H 127.0.0.1 -P 4000 -D tpcc --warehouses 4 prepare\ntiup bench tpcc -H 127.0.0.1 -P 4000 -D tpcc --warehouses 4 run --time 300s\n```\n\n----------------------------------------\n\nTITLE: Example dbt Run Output for TiDB Cloud\nDESCRIPTION: Sample output from a successful dbt run showing the creation of 3 view models and 2 table models in TiDB Cloud. The output details each model being created and the execution time.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nRunning with dbt=1.0.1\nFound 5 models, 20 tests, 0 snapshots, 0 analyses, 170 macros, 0 operations, 3 seed files, 0 sources, 0 exposures, 0 metrics\n\nConcurrency: 1 threads (target='dev')\n\n1 of 5 START view model analytics.stg_customers................................. [RUN]\n1 of 5 OK created view model analytics.stg_customers............................ [SUCCESS 0 in 0.31s]\n2 of 5 START view model analytics.stg_orders.................................... [RUN]\n2 of 5 OK created view model analytics.stg_orders............................... [SUCCESS 0 in 0.23s]\n3 of 5 START view model analytics.stg_payments.................................. [RUN]\n3 of 5 OK created view model analytics.stg_payments............................. [SUCCESS 0 in 0.29s]\n4 of 5 START table model analytics.customers.................................... [RUN]\n4 of 5 OK created table model analytics.customers............................... [SUCCESS 0 in 0.76s]\n5 of 5 START table model analytics.orders....................................... [RUN]\n5 of 5 OK created table model analytics.orders.................................. [SUCCESS 0 in 0.63s]\n\nFinished running 3 view models, 2 table models in 2.27s.\n\nCompleted successfully\n\nDone. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5\n```\n\n----------------------------------------\n\nTITLE: Creating Upstream Table Schema\nDESCRIPTION: This SQL snippet defines the schema for an upstream table named 'messages'. The table consists only of an 'id' field set as the primary key. This schema is referenced when resolving column count mismatches during data migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-with-more-columns-downstream.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n# Upstream table schema\nCREATE TABLE `messages` (\n  `id` int NOT NULL,\n  PRIMARY KEY (`id`)\n)\n```\n\n----------------------------------------\n\nTITLE: Handling User-Defined Variables vs Identifiers\nDESCRIPTION: Demonstrates that user-defined variables are not recognized as column identifiers in SQL statements, even if they contain what looks like column references.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * from t;\n```\n\n----------------------------------------\n\nTITLE: Defining TiDB Region Error Alert Rule in Prometheus\nDESCRIPTION: Alert rule to detect excessive Region cache errors in TiDB when accessing TiKV. Triggers when errors exceed 6000 in 10 minutes.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_1\n\nLANGUAGE: prometheus\nCODE:\n```\nincrease(tidb_tikvclient_region_err_total[10m]) > 6000\n```\n\n----------------------------------------\n\nTITLE: Defining BLOB Column in TiDB\nDESCRIPTION: Syntax for creating a BLOB column for binary objects up to 65,535 bytes.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nBLOB[(M)]\n```\n\n----------------------------------------\n\nTITLE: Preparing the DM Software Package\nDESCRIPTION: Commands to extract the current DM software packages into a temporary directory. This is necessary to prepare the base files for creating a hotfix package.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-patch.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nmkdir -p /tmp/package\ntar -zxvf /root/.tiup/storage/dm/packages/dm-master-v5.3.0-linux-amd64.tar.gz -C /tmp/package/\ntar -zxvf /root/.tiup/storage/dm/packages/dm-worker-v5.3.0-linux-amd64.tar.gz -C /tmp/package/\n```\n\n----------------------------------------\n\nTITLE: TiUP DM Reload Basic Syntax\nDESCRIPTION: The basic syntax for the tiup dm reload command. The command requires a cluster name argument and accepts optional flags for customizing the reload behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-reload.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm reload <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Using CREATE VIEW in TiDB with Examples\nDESCRIPTION: A complete example demonstrating how to create a table, insert data, create a view based on that table with a filter condition, and query both the table and view. Also shows the current limitation that views cannot be inserted into.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-view.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5);\nQuery OK, 5 rows affected (0.03 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\nmysql> CREATE VIEW v1 AS SELECT * FROM t1 WHERE c1 > 2;\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> SELECT * FROM t1;\n+----+----+\n| id | c1 |\n+----+----+\n|  1 |  1 |\n|  2 |  2 |\n|  3 |  3 |\n|  4 |  4 |\n|  5 |  5 |\n+----+----+\n5 rows in set (0.00 sec)\n\nmysql> SELECT * FROM v1;\n+----+----+\n| id | c1 |\n+----+----+\n|  3 |  3 |\n|  4 |  4 |\n|  5 |  5 |\n+----+----+\n3 rows in set (0.00 sec)\n\nmysql> INSERT INTO t1 (c1) VALUES (6);\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> SELECT * FROM v1;\n+----+----+\n| id | c1 |\n+----+----+\n|  3 |  3 |\n|  4 |  4 |\n|  5 |  5 |\n|  6 |  6 |\n+----+----+\n4 rows in set (0.00 sec)\n\nmysql> INSERT INTO v1 (c1) VALUES (7);\nERROR 1105 (HY000): insert into view v1 is not supported now.\n```\n\n----------------------------------------\n\nTITLE: Importing Data with Sysbench\nDESCRIPTION: Bash command for preparing test data using Sysbench with 32 tables and 10 million rows per table, using the previously created configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nsysbench --config-file=config oltp_point_select --tables=32 --table-size=10000000 prepare\n```\n\n----------------------------------------\n\nTITLE: Querying Lock Conflict Information (SQL)\nDESCRIPTION: The DATA_LOCK_WAITS system view now shows waiting information for optimistic transactions blocked by pessimistic locks. This helps detect lock conflicts quickly to improve application performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.2.0.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.DATA_LOCK_WAITS;\n```\n\n----------------------------------------\n\nTITLE: Local Traffic Capture Example\nDESCRIPTION: SQL example showing how to capture traffic for one day to a local directory on the TiProxy instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-traffic-capture.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nTRAFFIC CAPTURE TO \"/tmp/traffic\" DURATION=\"1d\";\n```\n\n----------------------------------------\n\nTITLE: Using tiup dm edit-config Command in Shell\nDESCRIPTION: This command launches an editor to modify the topology file of a specified DM cluster. After modifying, users need to run tiup dm reload to apply changes. Note that this command doesn't support adding or removing machines.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-edit-config.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm edit-config <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Configuring Binlog Event Filters for DM Task in YAML\nDESCRIPTION: This YAML snippet demonstrates how to configure filters for binlog events in a DM task. It defines rules to ignore or allow specific events for certain schemas and tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-task-configuration-guide.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nfilters:                                        # The filter rule set of data source binlog events. You can set multiple rules at the same time.\n  filter-rule-1:                                # The name of the filtering rule.\n    schema-pattern: \"test_*\"                    # The pattern of the data source schema name. Wildcard characters (*?) are supported.\n    table-pattern: \"t_*\"                        # The pattern of the data source table name. Wildcard characters (*?) are supported.\n    events: [\"truncate table\", \"drop table\"]    # The event types to be filtered out in schemas or tables that match the `schema-pattern` or the `table-pattern`.\n    action: Ignore                              # Whether to migrate (Do) or ignore (Ignore) the binlog that matches the filtering rule.\n  filter-rule-2:\n    schema-pattern: \"test\"\n    events: [\"all dml\"]\n    action: Do\n```\n\n----------------------------------------\n\nTITLE: Using ticloud serverless branch describe Command in Shell\nDESCRIPTION: The main syntax for the 'ticloud serverless branch describe' command, which retrieves information about a branch in a TiDB Cloud Serverless cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-describe.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch describe [flags]\n```\n\n----------------------------------------\n\nTITLE: Setting tidb_mem_quota_apply_cache for Apply Operator\nDESCRIPTION: Sets the memory usage threshold for the local cache in the Apply operator. This cache speeds up Apply operator computations. Set to 0 to disable the Apply cache feature.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_53\n\nLANGUAGE: SQL\nCODE:\n```\nSET [SESSION | GLOBAL] tidb_mem_quota_apply_cache = <value>;\n```\n\n----------------------------------------\n\nTITLE: Setting Store Label in TiKV\nDESCRIPTION: This command sets a label for a specified store by providing the store ID and the key-value pair for the label. The store ID should be an integer, and the label key and value should be strings.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_52\n\nLANGUAGE: bash\nCODE:\n```\nstore label 1 zone=cn\n```\n\n----------------------------------------\n\nTITLE: Configuring CSV Header Settings in TiDB Lightning YAML\nDESCRIPTION: This YAML configuration snippet disables the CSV header in TiDB Lightning. It's used when the CSV data file does not contain a header row (column names) as the first line.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/troubleshoot-tidb-lightning.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n[mydumper.csv]\nheader = false\n```\n\n----------------------------------------\n\nTITLE: Encrypting Database Password with dmctl\nDESCRIPTION: Command to encrypt a database password using the dmctl tool for secure configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-task.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./dmctl encrypt \"123456\"\n```\n\n----------------------------------------\n\nTITLE: Starting MinIO Server for Backup Storage - Shell\nDESCRIPTION: This shell script sets up a MinIO server to simulate Amazon S3 for backing up data during migration and replication processes in a TiDB disaster recovery setup.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nwget https://dl.min.io/server/minio/release/linux-amd64/minio\nchmod +x minio\n# Configure access-key and access-secret-id to access MinIO\nexport HOST_IP='10.0.1.10' # Replace it with the IP address of MinIO\nexport MINIO_ROOT_USER='minio'\nexport MINIO_ROOT_PASSWORD='miniostorage'\n# Create the redo and backup directories. `backup` and `redo` are bucket names.\nmkdir -p data/redo\nmkdir -p data/backup\n# Start minio at port 6060\nnohup ./minio server ./data --address :6060 &\n```\n\n----------------------------------------\n\nTITLE: Controlling Slow Query Log Masking in TiDB SQL\nDESCRIPTION: Global variable to control whether queries in the slow query log should be desensitized for security purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.2.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_slow_log_masking = ON;\n```\n\n----------------------------------------\n\nTITLE: Scale Out Cluster\nDESCRIPTION: Command to scale out the TiDB cluster by adding new instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground scale-out --db 2\n```\n\n----------------------------------------\n\nTITLE: NVL Function Comparison\nDESCRIPTION: Demonstrates the use of NVL in Oracle and its equivalent IFNULL in TiDB for handling NULL values.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nNVL(key,val)\n```\n\nLANGUAGE: sql\nCODE:\n```\nIFNULL(key,val)\n```\n\n----------------------------------------\n\nTITLE: Configuring TiUP Connection Parameters\nDESCRIPTION: This snippet demonstrates how to configure connection information for the TiUP command to connect to a TiDB instance. It lists parameters like user, password, host, and database name with their default values.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-bookshop-schema-design.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup demo bookshop prepare -U <username> -H <endpoint> -P 4000 -p <password>\n```\n\n----------------------------------------\n\nTITLE: Default JDBC Batch Execution without Rewrite\nDESCRIPTION: SQL statements sent to TiDB by default when using batch operations without the rewriteBatchedStatements parameter. Each statement is sent individually.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO `t` (`a`) VALUES(10);\nINSERT INTO `t` (`a`) VALUES(11);\nINSERT INTO `t` (`a`) VALUES(12);\n```\n\n----------------------------------------\n\nTITLE: Configuring Region Split Size in TiKV\nDESCRIPTION: Use the 'coprocessor.region-split-size' configuration item to adjust the Region size in TiKV. The recommended range is between 48 MiB and 256 MiB, with common sizes being 96 MiB, 128 MiB, and 256 MiB.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-region-performance.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ncoprocessor:\n  region-split-size: 256MiB\n```\n\n----------------------------------------\n\nTITLE: TiKV Configuration for Google Cloud KMS Encryption\nDESCRIPTION: Configuration example for enabling encryption at rest using Google Cloud Key Management Service in TiKV, supporting master key management for enhanced data security\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.5.0.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[security.encryption.master-key]\n# Google Cloud KMS encryption configuration\n```\n\n----------------------------------------\n\nTITLE: Java Optimistic Transaction Implementation\nDESCRIPTION: A comprehensive Java example demonstrating optimistic transaction handling for a book purchasing system with concurrent processing, error handling, and transaction retry mechanism\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_14\n\nLANGUAGE: java\nCODE:\n```\npackage com.pingcap.txn.optimistic;\n\nimport com.zaxxer.hikari.HikariDataSource;\n\nimport java.math.BigDecimal;\nimport java.sql.*;\nimport java.util.Arrays;\nimport java.util.concurrent.*;\n```\n\n----------------------------------------\n\nTITLE: Setting GC Life Time in TiDB\nDESCRIPTION: SQL commands to adjust the garbage collection (GC) time before and after large data exports. Sets GC life time to 720 hours for export operation and restores it to default 10 minutes after completion.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_life_time = '720h';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_life_time = '10m';\n```\n\n----------------------------------------\n\nTITLE: Resetting Status Variables in TiDB\nDESCRIPTION: Command to reset status variables for MySQL compatibility\nSOURCE: https://github.com/pingcap/docs/blob/master/status-variables.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nFLUSH STATUS;\n```\n\n----------------------------------------\n\nTITLE: TINYINT Type Declaration in SQL\nDESCRIPTION: Syntax for declaring TINYINT type with optional display width, unsigned flag and zero-fill option\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-numeric.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nTINYINT[(M)] [UNSIGNED] [ZEROFILL]\n```\n\n----------------------------------------\n\nTITLE: Describing TABLE_CONSTRAINTS Structure in TiDB (SQL)\nDESCRIPTION: This SQL query describes the structure of the TABLE_CONSTRAINTS table in the information_schema database of TiDB. It shows the fields, their types, and other attributes of the table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-table-constraints.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC table_constraints;\n```\n\n----------------------------------------\n\nTITLE: Directing Backup Operations to Read-Only Nodes\nDESCRIPTION: This shell command uses the BR (Backup & Restore) tool with the '--replica-read-label' option to read data from nodes labeled as read-only during backup operations. Single quotes prevent shell expansion of the $ character.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/readonly-nodes.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ntiup br backup full ... --replica-read-label '$mode:readonly'\n```\n\n----------------------------------------\n\nTITLE: Pause Log Backup Help Command\nDESCRIPTION: Shows help information for the log backup pause command including available flags and global options.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log pause --help\npause a log backup task\n\nUsage:\n  br log pause [flags]\n\nFlags:\n  --gc-ttl int         the TTL (in seconds) that PD holds for BR's GC safepoint (default 86400)\n  -h, --help           help for status\n  --task-name string   The task name for backup stream log.\n\nGlobal Flags:\n --ca string                  CA certificate path for TLS connection\n --cert string                Certificate path for TLS connection\n --key string                 Private key path for TLS connection\n -u, --pd strings             PD address (default [127.0.0.1:2379])\n```\n\n----------------------------------------\n\nTITLE: TiKV RocksDB Background Flushes Configuration Parameter (Modified)\nDESCRIPTION: TiKV parameter that controls the maximum number of concurrent background flushes in RocksDB. Default values are now CPU-dependent, with 3 for 10-core machines and 2 for 8-core machines.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\nrocksdb.max-background-flushes\n```\n\n----------------------------------------\n\nTITLE: Enabling Table Across Nodes in TiCDC Configuration\nDESCRIPTION: TOML configuration snippet to enable TiCDC to replicate a single table with multiple nodes by setting table-across-nodes to true in the scheduler section.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_11\n\nLANGUAGE: toml\nCODE:\n```\n[scheduler]\nenable-table-across-nodes = true\n```\n\n----------------------------------------\n\nTITLE: Initializing Test Data with Sysbench\nDESCRIPTION: This snippet initializes test data in the upstream TiDB cluster using Sysbench. The script prepares 10 tables with 10,000 rows each based on the specified configuration. Prerequisites include Sysbench installation and proper configuration of the tidb-config file.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsysbench oltp_write_only --config-file=./tidb-config --tables=10 --table-size=10000 prepare\n```\n\n----------------------------------------\n\nTITLE: Altering User to Use Default Password Expiration in SQL\nDESCRIPTION: SQL command to modify an existing user to follow the global password expiration policy rather than having an account-level override.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_19\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER 'test'@'localhost' PASSWORD EXPIRE DEFAULT;\n```\n\n----------------------------------------\n\nTITLE: Displaying TiKV Configuration in JSON Format\nDESCRIPTION: Example JSON output from the --config-info flag showing configuration parameters with their default and current values. The output includes component name, version, and a list of parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/command-line-flags-for-tikv-configuration.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Component\": \"TiKV Server\",\n    \"Version\": \"6.2.0\",\n    \"Parameters\": [\n        {\n        \"Name\": \"log-level\",\n        \"DefaultValue\": \"info\",\n        \"ValueInFile\": \"warn\"\n        },\n        {\n        \"Name\": \"log-file\",\n        \"DefaultValue\": \"\"\n        },\n        ...\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Starting TiDB Log Backup with BR Tool\nDESCRIPTION: Initiates a log backup task using the br command-line tool. Uses Amazon S3 for storage and requires PD endpoint configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-guide.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log start --task-name=pitr --pd \"${PD_IP}:2379\" \\\n--storage 's3://backup-101/logbackup?access-key=${access-key}&secret-access-key=${secret-access-key}'\n```\n\n----------------------------------------\n\nTITLE: Non-Rewritable INSERT Statements with DUPLICATE KEY UPDATE\nDESCRIPTION: Example of INSERT statements with ON DUPLICATE KEY UPDATE clauses that cannot be rewritten because they have different literal values in the update expression.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO `t` (`a`) VALUES (10) ON DUPLICATE KEY UPDATE `a` = 10;\nINSERT INTO `t` (`a`) VALUES (11) ON DUPLICATE KEY UPDATE `a` = 11;\nINSERT INTO `t` (`a`) VALUES (12) ON DUPLICATE KEY UPDATE `a` = 12;\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP Package Manager\nDESCRIPTION: Command to install TiUP, a cluster operation and maintenance tool for TiDB ecosystem.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Creating Placement Policy in SQL\nDESCRIPTION: This SQL snippet defines a placement policy used to dictate where data is located across different TiKV nodes. It's critical in scenarios where the source and target clusters have differing topologies. Users must ensure that labels and objects are pre-created before data import.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-faq.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY p1 PRIMARY_REGION=\"us-east\" REGIONS=\"us-east,us-west\";\n```\n\n----------------------------------------\n\nTITLE: Executing ANALYZE TABLE SQL Statement in TiDB\nDESCRIPTION: This SQL statement is used to manually analyze table statistics after importing a large single table with TiDB Lightning when the analyze operation was disabled during import. The ANALYZE TABLE command collects statistics about tables for the query optimizer.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/data-import-best-practices.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE\n```\n\n----------------------------------------\n\nTITLE: Querying ANALYZE_STATUS Table in SQL\nDESCRIPTION: This SQL query retrieves all records from the ANALYZE_STATUS table in the information_schema database, showing currently running and historical statistics collection tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-analyze-status.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.analyze_status;\n```\n\n----------------------------------------\n\nTITLE: MyDumper Regular Expression Patterns - TOML\nDESCRIPTION: This snippet illustrates how to set up pattern matching configurations for MyDumper files in TiDB Lightning using TOML. It shows how to use regular expressions to dynamically rename tables and schemas by specifying naming patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[mydumper]\ndata-source-dir = \"/some-subdir/some-database/\"\n[[mydumper.files]]\npattern = '^(srcdb)\\.(.*?)-schema-create\\.sql'\nschema = 'tgtdb'\ntype = \"schema-schema\"\n[[mydumper.files]]\npattern = '^(srcdb)\\.(.*?)-schema\\.sql'\nschema = 'tgtdb'\ntable = '$2'\ntype = \"table-schema\"\n[[mydumper.files]]\npattern = '^(srcdb)\\.(.*?)\\.(?:[0-9]+)\\.(csv|parquet|sql)'\nschema = 'tgtdb'\ntable = '$2'\ntype = '$3'\n```\n\n----------------------------------------\n\nTITLE: Disabling TiUP Telemetry\nDESCRIPTION: Command to disable telemetry data collection in TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/telemetry.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup telemetry disable\n```\n\n----------------------------------------\n\nTITLE: Installing Docker and Dependencies\nDESCRIPTION: Shell script for installing Docker and Docker Compose on Linux systems. Prepares the environment for WordPress and TiDB Cloud Serverless deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/dev-guide-wordpress.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsudo sh install.sh\n```\n\n----------------------------------------\n\nTITLE: Creating a Test Table for Index Recommendation Demo\nDESCRIPTION: Creates a simple table with three integer columns that will be used to demonstrate the Index Advisor functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a INT, b INT, c INT);\n```\n\n----------------------------------------\n\nTITLE: Configuring max_execution_time in TiDB\nDESCRIPTION: This variable specifies the maximum execution time allowed for queries, applicable to SESSION and GLOBAL scopes. It defaults to `0`, indicating no limit.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\n-- Default value: `0`\n-- Range: `[0, 2147483647]`\nSET GLOBAL max_execution_time = 0;\n```\n\n----------------------------------------\n\nTITLE: Setting tidb_max_paging_size for Coprocessor Paging\nDESCRIPTION: Controls the maximum number of rows during coprocessor paging requests. Affects RPC count between TiDB and TiKV, and memory usage in scenarios like data loading and full table scans.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_49\n\nLANGUAGE: SQL\nCODE:\n```\nSET [SESSION | GLOBAL] tidb_max_paging_size = <value>;\n```\n\n----------------------------------------\n\nTITLE: Describing Execution Plan for Querying tidb_query_duration\nDESCRIPTION: This command provides an execution plan for the earlier SELECT statement to the `tidb_query_duration`, helping to understand the underlying processes in querying metrics data, including how the data is accessed and manipulated during execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/metrics-schema.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nDESC SELECT * FROM metrics_schema.tidb_query_duration WHERE value is not null AND time>='2020-03-25 23:40:00' AND time <= '2020-03-25 23:42:00' AND quantile=0.99;\n```\n\n----------------------------------------\n\nTITLE: Creating Order Line Table in SQL\nDESCRIPTION: SQL statement to create the 'order_line' table with a primary key and various fields for order details.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-physical-import-mode-usage.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE IF NOT EXISTS `order_line` (\n  `ol_o_id` int NOT NULL,\n  `ol_d_id` int NOT NULL,\n  `ol_w_id` int NOT NULL,\n  `ol_number` int NOT NULL,\n  `ol_i_id` int NOT NULL,\n  `ol_supply_w_id` int DEFAULT NULL,\n  `ol_delivery_d` datetime DEFAULT NULL,\n  `ol_quantity` int DEFAULT NULL,\n  `ol_amount` decimal(6,2) DEFAULT NULL,\n  `ol_dist_info` char(24) DEFAULT NULL,\n  PRIMARY KEY (`ol_w_id`,`ol_d_id`,`ol_o_id`,`ol_number`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\n```\n\n----------------------------------------\n\nTITLE: Enabling Historical Data Read and Selecting Data\nDESCRIPTION: This SQL snippet enables the `tidb_enable_external_ts_read` variable and selects data from the table. The expected output is adjusted based on the timestamp set earlier. It confirms how to read historical data post-setup.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-external-ts.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_enable_external_ts_read=ON;\nSELECT * FROM t;\n```\n\n----------------------------------------\n\nTITLE: Performing Bitwise XOR Operation in SQL\nDESCRIPTION: The '^' operator performs a bitwise XOR operation, returning 1 for each bit position where the corresponding bits of its operands are different. The input is two binary numbers, and the output will reflect their bitwise XOR result.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/bit-functions-and-operators.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONV(b'1010' ^ b'1100',10,2);\n```\n\n----------------------------------------\n\nTITLE: Deleting Outdated Snapshot Backup Data in TiDB\nDESCRIPTION: Command to remove a snapshot backup directory from S3 storage, used for cleaning up outdated backup data.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-use-cases.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nrm s3://tidb-pitr-bucket/backup-data/snapshot-20220514000000\n```\n\n----------------------------------------\n\nTITLE: Showing Current Traffic Jobs Status with tiproxyctl - Shell\nDESCRIPTION: This command shows the current status of traffic jobs using the `tiproxyctl` tool, providing information on job type, status, and progress.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-traffic-replay.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntiproxyctl traffic show --host 10.0.1.10 --port 3080\n```\n\n----------------------------------------\n\nTITLE: Checking TiProxy Health Status using Bash\nDESCRIPTION: Shows how to retrieve the health status of TiProxy, which returns the configuration checksum when TiProxy is running normally.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-api.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:3080/api/debug/health\n```\n\n----------------------------------------\n\nTITLE: Locating OpenSSL Configuration File\nDESCRIPTION: Command to search for the OpenSSL configuration file in the root directory if the location is unknown.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nfind / -name openssl.cnf\n```\n\n----------------------------------------\n\nTITLE: Defining Index File Path - Shell\nDESCRIPTION: This shell snippet provides the format for an index file used to prevent data overwriting by recording the largest file name in the current directory. It is essential for maintaining data integrity across nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n{scheme}://{prefix}/{schema}/{table}/{table-version-separator}/{partition-separator}/{date-separator}/meta/CDC.index\n```\n\n----------------------------------------\n\nTITLE: Load DM Data Source Configuration\nDESCRIPTION: This shell command uses `tiup dmctl` to load the data source configuration defined in `source1.yaml` into the DM cluster. It connects to the DM-master at the specified address and executes the `operate-source create` command.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-to-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup dmctl --master-addr ${advertise-addr} operate-source create source1.yaml\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Key Partitioned Table by VARCHAR Column in SQL\nDESCRIPTION: This SQL snippet shows how to create a Key partitioned table divided into 4 partitions based on the fname column, which is a VARCHAR type.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_29\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT\n)\n\nPARTITION BY KEY(fname)\nPARTITIONS 4;\n```\n\n----------------------------------------\n\nTITLE: Setting the Fine Grained Shuffle Stream Count in TiFlash\nDESCRIPTION: Sets the `tiflash_fine_grained_shuffle_stream_count` system variable to 20 threads to increase concurrency for window function execution in TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nset @@tiflash_fine_grained_shuffle_stream_count = 20;\n```\n\n----------------------------------------\n\nTITLE: Deleting Data with ActiveRecord ORM in Rails\nDESCRIPTION: Ruby code that deletes a Player record from the database using ActiveRecord's destroy method.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_14\n\nLANGUAGE: ruby\nCODE:\n```\nplayer.destroy\n```\n\n----------------------------------------\n\nTITLE: Resume Task Command with Response\nDESCRIPTION: Example of resuming a specific task and the JSON response showing the operation result.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-resume-task.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nresume-task test\n```\n\nLANGUAGE: bash\nCODE:\n```\n{\n    \"op\": \"Resume\",\n    \"result\": true,\n    \"msg\": \"\",\n    \"sources\": [\n        {\n            \"result\": true,\n            \"msg\": \"\",\n            \"source\": \"mysql-replica-01\",\n            \"worker\": \"worker1\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Inserting Sample Data into Table in SQL\nDESCRIPTION: SQL command to insert three rows with values 1, 2, and 3 into the table 't' for stale read demonstration.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ninsert into t values (1), (2), (3);\n```\n\n----------------------------------------\n\nTITLE: Deleting a Cross-database Binding in TiDB\nDESCRIPTION: Demonstrates how to delete a cross-database binding using its SQL digest in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_28\n\nLANGUAGE: SQL\nCODE:\n```\nDROP GLOBAL BINDING FOR SQL DIGEST 'ea8720583e80644b58877663eafb3579700e5f918a748be222c5b741a696daf4';\nSHOW GLOBAL BINDINGS;\n```\n\n----------------------------------------\n\nTITLE: Setting AWS Credentials for S3 Access\nDESCRIPTION: Shell commands to set environment variables for AWS access key and secret key, required when importing data from Amazon S3.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-parquet-files-to-tidb.md#2025-04-18_snippet_4\n\nLANGUAGE: Shell\nCODE:\n```\nexport AWS_ACCESS_KEY_ID=${access_key}\nexport AWS_SECRET_ACCESS_KEY=${secret_key}\n```\n\n----------------------------------------\n\nTITLE: Community Support Channel Links - TiDB Platform\nDESCRIPTION: Markdown content block specific to TiDB platform that provides links to Discord, Slack communities and support ticket system.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\n<CustomContent platform=\"tidb\">\n\nAsk the community on [Discord](https://discord.gg/DQZ2dy3cuc?utm_source=doc) or [Slack](https://slack.tidb.io/invite?team=tidb-community&channel=everyone&ref=pingcap-docs), or [submit a support ticket](/support.md).\n\n</CustomContent>\n```\n\n----------------------------------------\n\nTITLE: Displaying DM Cluster Status\nDESCRIPTION: Command to view status of all components in the DM cluster\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm display prod-cluster\n```\n\n----------------------------------------\n\nTITLE: Using the tiup cluster reload command in Shell\nDESCRIPTION: Basic syntax for the 'tiup cluster reload' command that refreshes configuration and restarts services in a TiDB cluster. The command requires a cluster name parameter and supports various flags to control the reload process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-reload.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster reload <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Using tiup cluster scale-in Command in Shell\nDESCRIPTION: The basic syntax for scaling in a TiDB cluster using the tiup cluster scale-in command. The command requires a cluster name parameter and supports various flags for specifying nodes and controlling the removal behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-scale-in.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster scale-in <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Backing up Schema with Dumpling\nDESCRIPTION: Uses the Dumpling tool to create a backup of a specific schema named 'test'\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-faq.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ntiup dumpling -B test -o /tmp/bck1\n```\n\n----------------------------------------\n\nTITLE: Executing TiCDC Scale-Out with TiUP\nDESCRIPTION: Command to scale out a TiCDC cluster using TiUP, which applies the configuration specified in a scale-out.yml file to the named cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/deploy-ticdc.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster scale-out <cluster-name> scale-out.yml\n```\n\n----------------------------------------\n\nTITLE: Describing CHARACTER_SETS Table Schema\nDESCRIPTION: Shows the structure of the CHARACTER_SETS table using the DESC command in the INFORMATION_SCHEMA database.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-character-sets.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC CHARACTER_SETS;\n```\n\n----------------------------------------\n\nTITLE: Restoring TiUP Meta File Using tiup cluster meta restore Command in Shell\nDESCRIPTION: This command is used to restore a TiUP meta file from a backup. It requires specifying the cluster name and the path to the backup file. This operation overwrites the current meta file and should only be performed when the meta file is lost.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-meta-restore.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster meta restore <cluster-name> <backup-file> [flags]\n```\n\n----------------------------------------\n\nTITLE: Describing CLUSTER_SLOW_QUERY Table Schema - SQL\nDESCRIPTION: This SQL snippet describes the CLUSTER_SLOW_QUERY table schema, showing the fields, their types, and attributes such as nullability and defaults. It is essential for understanding the structure of slow query logs in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-slow-query.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nDESC CLUSTER_SLOW_QUERY;\n```\n\n----------------------------------------\n\nTITLE: Performing Online Unsafe Recovery in TiKV\nDESCRIPTION: This command initiates lossy recovery operations to remove permanently damaged stores, and must be used with caution due to integrity risks.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_60\n\nLANGUAGE: bash\nCODE:\n```\nunsafe remove-failed-stores 101,102,103\n```\n\nLANGUAGE: bash\nCODE:\n```\nunsafe remove-failed-stores show\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for DROP STATS\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition showing the grammar rules for the DROP STATS command.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-stats.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDropStatsStmt ::=\n    'DROP' 'STATS' TableName  (\"PARTITION\" partition | \"GLOBAL\")? ( ',' TableName )*\n\nTableName ::=\n    Identifier ('.' Identifier)?\n```\n\n----------------------------------------\n\nTITLE: Updating Git Submodules\nDESCRIPTION: Git command to initialize and update the TiDB Compatibility Plugin submodule. Ensures all necessary plugin components are present.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/dev-guide-wordpress.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ngit submodule update --init --recursive\n```\n\n----------------------------------------\n\nTITLE: Launching TiDB Lightning Import Process (Shell)\nDESCRIPTION: Shell commands to set AWS credentials as environment variables and start the TiDB Lightning import process using nohup. This ensures the process continues running even if the terminal session ends.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-sql-files-to-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\nexport AWS_ACCESS_KEY_ID=${access_key}\nexport AWS_SECRET_ACCESS_KEY=${secret_key}\nnohup tiup tidb-lightning -config tidb-lightning.toml > nohup.out 2>&1 &\n```\n\n----------------------------------------\n\nTITLE: Variable Configuration Change - tidb_stmt_summary_max_stmt_count\nDESCRIPTION: Default value change for tidb_stmt_summary_max_stmt_count variable from 200 to 3000.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.1.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_stmt_summary_max_stmt_count = 3000;\n```\n\n----------------------------------------\n\nTITLE: Controlling IN Subquery Optimization in TiDB SQL\nDESCRIPTION: Introduces a variable to control the optimization of IN subqueries to Inner Join after aggregation, enabled by default.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0-beta.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_opt_insubq_to_join_and_agg = 1;\n```\n\n----------------------------------------\n\nTITLE: Adding a Few-Shot Example to Knowledge Base - Bash\nDESCRIPTION: This snippet illustrates how to add a few-shot example type of knowledge to an existing knowledge base by making a POST request to the appropriate API endpoint. It includes the necessary parameters such as the question and answer related to the knowledge.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-knowledge.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user ${PUBLIC_KEY}:${PRIVATE_KEY} --request POST 'https://<region>.data.tidbcloud.com/api/v1beta/app/chat2query-<ID>/endpoint/v3/knowledgeBases/<knowledge_base_id>/data'\\\n --header 'content-type: application/json'\\\n --data-raw '{\n    \"type\": \"few-shot\",\n    \"meta_data\": {},\n    \"raw_data\": {\n         \"question\": \"How many records are in the 'test' table?\",\n         \"answer\": \"SELECT COUNT(*) FROM `test`;\"\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Verifying Pipelined DML Usage in TiDB\nDESCRIPTION: Queries the 'tidb_last_txn_info' variable to check if Pipelined DML was used during statement execution. A 'pipelined' field set to true indicates successful Pipelined DML usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/pipelined-dml.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@tidb_last_txn_info;\n```\n\n----------------------------------------\n\nTITLE: Querying DM Task Status\nDESCRIPTION: Shell command to check the status of a running migration task. This provides information about the progress and health of the migration task.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} query-status ${task-name}\n```\n\n----------------------------------------\n\nTITLE: Create Unique Multi-Valued Index\nDESCRIPTION: This snippet shows how to create a unique multi-valued index. This enforces uniqueness on the extracted values from the JSON array. Dependencies include a JSON column and the `CAST` function.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-index.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE customers (\n    id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    name CHAR(10),\n    custinfo JSON,\n    UNIQUE INDEX zips( (CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)))\n);\n\n```\n\n----------------------------------------\n\nTITLE: Scheduling Snowflake Task with MERGE Command - SQL\nDESCRIPTION: Configures a Snowflake `TASK` that periodically executes the `MERGE INTO` statement every minute, ensuring the `TEST_ITEM` table is always up-to-date.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_11\n\nLANGUAGE: SQL\nCODE:\n```\n-- Create a TASK to periodically execute the MERGE INTO statement\ncreate or replace task STREAM_TO_ITEM\n    warehouse = test\n    -- Execute the TASK every minute\n    schedule = '1 minute'\nwhen\n    -- Skip the TASK when there is no data in TEST_ITEM_STREAM\n    system$stream_has_data('TEST_ITEM_STREAM')\nas\n-- Merge data into the TEST_ITEM table. The statement is the same as that in the preceding example\nmerge into TEST_ITEM n\n  using\n      (select RECORD_METADATA:key as k, RECORD_CONTENT:val as v from TEST_ITEM_STREAM) stm\n      on k:i_id = n.i_id\n  when matched and IS_NULL_VALUE(v) = true then\n      delete\n  when matched and IS_NULL_VALUE(v) = false then\n      update set n.i_data = v:i_data, n.i_im_id = v:i_im_id, n.i_name = v:i_name, n.i_price = v:i_price\n  when not matched then\n      insert\n          (i_data, i_id, i_im_id, i_name, i_price)\n      values\n          (v:i_data, v:i_id, v:i_im_id, v:i_name, v:i_price)\n;\n```\n\n----------------------------------------\n\nTITLE: Batch Renaming Files - Shell\nDESCRIPTION: This snippet shows how to use the 'rename' command in a shell environment (specifically on Red Hat Linux) to batch rename files in the data source directory. This is useful for aligning the filenames with database and table naming conventions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nrename srcdb. tgtdb. *.sql\n```\n\n----------------------------------------\n\nTITLE: TiDB New Collations Configuration Parameter (Modified)\nDESCRIPTION: Configuration parameter that controls whether to enable support for the new collation in TiDB. The default value has changed from false to true in v6.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\nnew_collations_enabled_on_first_bootstrap\n```\n\n----------------------------------------\n\nTITLE: Showing privileges in TiDB\nDESCRIPTION: Shows how to list all supported privileges within TiDB, especially dynamic privileges, using the `SHOW PRIVILEGES` statement. This allows administrators to check available privileges for fine-grained access control.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.0.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSHOW PRIVILEGES\n```\n\n----------------------------------------\n\nTITLE: Setting batch value for evict-leader-scheduler in TiDB PD\nDESCRIPTION: This command sets the 'batch' value for an existing evict-leader-scheduler. The batch value controls the number of Operators generated in a single scheduling process, affecting scheduling speed.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_46\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config evict-leader-scheduler set batch 10 // Set the batch value to 10\n```\n\n----------------------------------------\n\nTITLE: Executing Store Removal for Unsafe Recovery\nDESCRIPTION: Command to trigger automatic recovery by specifying unrecoverable TiKV and TiFlash nodes using PD Control\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl -u <pd_addr> unsafe remove-failed-stores <store_id1,store_id2,...>\n```\n\n----------------------------------------\n\nTITLE: Viewing TiUP DM Audit Logs\nDESCRIPTION: Commands to view the operation logs of TiUP DM commands. It shows a list of executed commands and allows viewing detailed logs for specific operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm audit\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm audit 4D5kQY\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Security Settings using YAML\nDESCRIPTION: This snippet is a YAML configuration block that sets the security session token signing certificate and key for TiDB instances, along with the graceful wait duration before shutdown. This configuration ensures secure token management and graceful server shutdowns. No special dependencies are needed; paths to cert files must be accessible.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  tidb:\n    security.session-token-signing-cert: \"/var/sess/cert.pem\"\n    security.session-token-signing-key: \"/var/sess/key.pem\"\n    graceful-wait-before-shutdown: 15\n```\n\n----------------------------------------\n\nTITLE: Configuring Diag Access Token\nDESCRIPTION: Command to set up the access token in Diag for data upload authentication\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag config clinic.token ${token-value}\n```\n\n----------------------------------------\n\nTITLE: Configuring Dump Processing Unit - YAML\nDESCRIPTION: This snippet defines the configuration parameters for the dump processing unit, including thread count, chunk file size, and extra arguments for consistency settings. The defaults are specified for each parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/task-configuration-file-full.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmydumpers:\n  global:                            # The configuration name of the processing unit.\n    threads: 4                       # The number of threads that access the upstream when the dump processing unit performs the precheck and exports data from the upstream database (4 by default)\n    chunk-filesize: 64               # The size of the file generated by the dump processing unit (64 MB by default).\n    extra-args: \"--consistency none\" # Other arguments of the dump processing unit. You do not need to manually configure table-list in `extra-args`, because it is automatically generated by DM.\n```\n\n----------------------------------------\n\nTITLE: Describing TIFLASH_REPLICA Table Structure in SQL\nDESCRIPTION: This SQL snippet shows how to view the structure of the TIFLASH_REPLICA table in the INFORMATION_SCHEMA database. It displays the field names, data types, and other attributes of the table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tiflash-replica.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC TIFLASH_REPLICA;\n```\n\n----------------------------------------\n\nTITLE: Basic UNION Operation in TiDB\nDESCRIPTION: Demonstrates a simple UNION operation between two SELECT statements returning distinct values.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/set-operators.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1 UNION SELECT 2;\n```\n\n----------------------------------------\n\nTITLE: Setting High Space Ratio in PD\nDESCRIPTION: Sets the threshold value for sufficient store space to 0.5. This affects PD's scheduling decisions when region-score-formula-version is set to v1.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nconfig set high-space-ratio 0.5\n```\n\n----------------------------------------\n\nTITLE: Executing FLUSH PRIVILEGES in TiDB\nDESCRIPTION: Example SQL query demonstrating how to execute the FLUSH PRIVILEGES statement in TiDB, showing both the command and its expected output. The result shows a successful execution with 0 rows affected.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flush-privileges.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> FLUSH PRIVILEGES;\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Checking TiUP Telemetry Status\nDESCRIPTION: Command to check the current status of telemetry collection in TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/telemetry.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup telemetry status\n```\n\n----------------------------------------\n\nTITLE: Defining Column Character Set and Collation\nDESCRIPTION: SQL syntax for specifying character set and collation for string-type columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\ncol_name {CHAR | VARCHAR | TEXT} (col_length)\n    [CHARACTER SET charset_name]\n    [COLLATE collation_name]\n\ncol_name {ENUM | SET} (val_list)\n    [CHARACTER SET charset_name]\n    [COLLATE collation_name]\n```\n\n----------------------------------------\n\nTITLE: Checking TiFlash Replication Rules\nDESCRIPTION: This command retrieves all data replication rules related to TiFlash from the PD instance. These rules define how data is replicated to TiFlash nodes, including the number of replicas and the constraints that must be met for replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n```shell\ncurl http://<pd_ip>:<pd_port>/pd/api/v1/config/rules/group/tiflash\n```\n```\n\nLANGUAGE: shell\nCODE:\n```\n```\n[\n  {\n    \"group_id\": \"tiflash\",\n    \"id\": \"table-45-r\",\n    \"override\": true,\n    \"start_key\": \"7480000000000000FF2D5F720000000000FA\",\n    \"end_key\": \"7480000000000000FF2E00000000000000F8\",\n    \"role\": \"learner\",\n    \"count\": 1,\n    \"label_constraints\": [\n      {\n        \"key\": \"engine\",\n        \"op\": \"in\",\n        \"values\": [\n          \"tiflash\"\n        ]\n      }\n    ]\n  }\n]\n```\n```\n\n----------------------------------------\n\nTITLE: Describing TIFLASH_TABLES Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the TIFLASH_TABLES system table, showing all fields, their data types, and other attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tiflash-tables.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC tiflash_tables;\n```\n\n----------------------------------------\n\nTITLE: Listing User Profiles in TiDB Cloud CLI - Markdown\nDESCRIPTION: This snippet explains how to list all user profiles in the TiDB Cloud CLI. It emphasizes capturing the names of currently available profiles and highlights which profile is currently active. This is essential for users to manage their configurations effectively.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/cli-reference.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nUse [`ticloud config list`](/tidb-cloud/ticloud-config-list.md) to list all user profiles.\n```\n\n----------------------------------------\n\nTITLE: Handling Compatibility between TiKV Versions - Warning Message\nDESCRIPTION: This snippet highlights a warning message that appears when downgrading from TiKV v4.0.9 to earlier versions after enabling specific encryption metadata configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_9\n\nLANGUAGE: ini\nCODE:\n```\n[2020/12/07 07:26:31.106 +08:00] [ERROR] [mod.rs:110] [\"encryption: failed to load file dictionary.\"]\n[2020/12/07 07:26:33.598 +08:00] [FATAL] [lib.rs:483] [\"called `Result::unwrap()` on an `Err` value: Other(\\\"[components/encryption/src/encrypted_file/header.rs:18]: unknown version 2\\\")\"]\n```\n\n----------------------------------------\n\nTITLE: Set User Password\nDESCRIPTION: This SQL statement demonstrates how to change the current user's password using the `SET PASSWORD` statement. It changes the current user's password to 'test'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-password.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET PASSWORD='test';\n```\n\n----------------------------------------\n\nTITLE: Using DESC as an Alias for EXPLAIN in TiDB SQL\nDESCRIPTION: The DESC statement in TiDB SQL is an alias for the EXPLAIN statement. It is provided for compatibility with MySQL syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-desc.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# DESC\n\nThis statement is an alias to [`EXPLAIN`](/sql-statements/sql-statement-explain.md). It is included for compatibility with MySQL.\n```\n\n----------------------------------------\n\nTITLE: TiDB DDL Owner Migration Command\nDESCRIPTION: Command to trigger DDL owner re-election when TiDB server is accessible\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://{TiDBIP}:10080/ddl/owner/resign\n```\n\n----------------------------------------\n\nTITLE: Importing Data to TiDB using TiDB Lightning\nDESCRIPTION: This command runs TiDB Lightning to import the data snapshot from S3 to TiDB using the configuration file created for data import.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_5\n\nLANGUAGE: Shell\nCODE:\n```\nexport AWS_ACCESS_KEY_ID=${access_key}\nexport AWS_SECRET_ACCESS_KEY=${secret_key}\nnohup tiup tidb-lightning -config tidb-lightning-data.toml > nohup.out 2>&1 &\n```\n\n----------------------------------------\n\nTITLE: Run YCSB Workload against TiKV (Bash)\nDESCRIPTION: This command runs the YCSB workload against a TiKV cluster. It uses the `run` subcommand of the TiUP bench ycsb component, specifying the PD address and the operation count. The `-p` flag is used to set properties for the YCSB benchmark.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench ycsb run tikv -p tikv.pd=\"127.0.0.1:2379\" -p operationcount=10000\n```\n\n----------------------------------------\n\nTITLE: Unlocking Partition Statistics in TiDB - SQL\nDESCRIPTION: Illustrates how to unlock statistics for a specific partition 'p1' of a table named 't'. This includes the unlocking command followed by an analyze operation, showing the results along with warnings about the sample rate for the partition.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-unlock-stats.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nmysql> UNLOCK STATS t PARTITION p1;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> ANALYZE TABLE t PARTITION p1;\nQuery OK, 0 rows affected, 1 warning (0.01 sec)\n\nmysql> SHOW WARNINGS;\n+-------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Level | Code | Message                                                                                                                                                              |\n+-------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Note  | 1105 | Analyze use auto adjusted sample rate 1.000000 for table test.t's partition p1, reason to use this rate is \"TiDB assumes that the table is empty, use sample-rate=1\" |\n+-------+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: TiKV JSON Log Format\nDESCRIPTION: Implementation of JSON log format support in TiKV for improved log structuring and parsing.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.7.md#2025-04-18_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\nJSON log format\n```\n\n----------------------------------------\n\nTITLE: Displaying Service Middleware Configuration in PD\nDESCRIPTION: Shows the current configuration of service middleware, including audit logging and rate limiting settings for HTTP and gRPC requests.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nconfig show service-middleware\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for TiDB Rails Project\nDESCRIPTION: Command to install required Ruby gems for the sample application using Bundler.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbundle install\n```\n\n----------------------------------------\n\nTITLE: View TiUP Playground Help\nDESCRIPTION: Command to display help information for TiUP playground component.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground --help\n```\n\n----------------------------------------\n\nTITLE: Inserting Multiple Rows into Table\nDESCRIPTION: Demonstrates inserting multiple rows into a previously created table using a single INSERT statement\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t1 (c1) VALUES (1), (2), (3);\n```\n\n----------------------------------------\n\nTITLE: Using /* */ for Multi-line Comments in TiDB SQL\nDESCRIPTION: Demonstrates how to use C-style block comments for writing multi-line comments in SQL queries. This allows for more extensive documentation within the code.\nSOURCE: https://github.com/pingcap/docs/blob/master/comment-syntax.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1+\n/*\n/*> this is a\n/*> multiple-line comment\n/*> */\n    1;\n```\n\n----------------------------------------\n\nTITLE: Query Task Status Command\nDESCRIPTION: Command to check the status of the migration task after applying DDL fixes.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nquery-status test\n```\n\n----------------------------------------\n\nTITLE: Exporting Data using Dumpling in Shell\nDESCRIPTION: This command uses Dumpling to export data from TiDB in SQL format. It specifies various parameters like user, port, host, and output directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-mysql.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup dumpling -u root -P 4000 -h 127.0.0.1 --filetype sql -t 8 -o ./dumpling_output -r 200000 -F256MiB\n```\n\n----------------------------------------\n\nTITLE: Comparing Execution Plans with and without Bindings\nDESCRIPTION: Diagnostic method to compare execution plans with baseline bindings enabled and disabled to assess plan consistency and decide on binding retention.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_33\n\nLANGUAGE: sql\nCODE:\n```\n-- View the plan with the binding enabled\nSET @@SESSION.TIDB_USE_PLAN_BASELINES = true;\nEXPLAIN FORMAT='VERBOSE' SELECT * FROM t1 WHERE ...;\n\n-- View the plan with the binding disabled\nSET @@SESSION.TIDB_USE_PLAN_BASELINES = false;\nEXPLAIN FORMAT='VERBOSE' SELECT * FROM t1 WHERE ...;\n```\n\n----------------------------------------\n\nTITLE: Checking Potential Deployment Risks with TiUP\nDESCRIPTION: Runs a pre-deployment check to identify potential issues in the TiDB cluster topology configuration. This command validates the configuration against best practices and system requirements.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster check ./topology.yaml --user root [-p] [-i /home/root/.ssh/gcp_rsa]\n```\n\n----------------------------------------\n\nTITLE: SHOW STATS_TOPN Example\nDESCRIPTION: This SQL example demonstrates how to use the `SHOW STATS_TOPN` statement with a `WHERE` clause to filter results for a specific table named 't'. The query retrieves Top-N statistics for that table, including column names, values, and counts.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-topn.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW STATS_TOPN WHERE Table_name='t';\n```\n\n----------------------------------------\n\nTITLE: Altering Table SHARD_ROW_ID_BITS\nDESCRIPTION: Shows how to modify the SHARD_ROW_ID_BITS attribute for an existing table. This allows adjusting the number of shards to optimize write distribution after table creation.\nSOURCE: https://github.com/pingcap/docs/blob/master/shard-row-id-bits.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t SHARD_ROW_ID_BITS = 4;\n```\n\n----------------------------------------\n\nTITLE: Configuration Update in TiDB 5.0.1\nDESCRIPTION: Change in default value of committer-concurrency configuration from 16 to 128\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.1.md#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ncommitter-concurrency = 128\n```\n\n----------------------------------------\n\nTITLE: Creating a TiCDC Changefeed with Canal-JSON Protocol\nDESCRIPTION: CLI command to create a new changefeed with the Canal-JSON protocol, which sends TiDB data change events to a Kafka topic. This configures TiCDC to wrap and construct Canal-JSON messages with Event as the basic unit.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://127.0.0.1:8300 --changefeed-id=\"kafka-canal-json\" --sink-uri=\"kafka://127.0.0.1:9092/topic-name?kafka-version=2.4.0&protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: Describing import task in interactive mode using Shell\nDESCRIPTION: This example demonstrates how to describe an import task using the interactive mode, where the CLI will prompt for necessary information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-describe.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import describe\n```\n\n----------------------------------------\n\nTITLE: Calculate Months Between Two Dates in TiDB\nDESCRIPTION: This snippet compares the calculations of months between dates in Oracle using MONTHS_BETWEEN and in TiDB using TIMESTAMPDIFF.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nMONTHS_BETWEEN(ENDDATE,SYSDATE)\n```\n\nLANGUAGE: sql\nCODE:\n```\nTIMESTAMPDIFF(MONTH,SYSDATE,ENDDATE)\n```\n\n----------------------------------------\n\nTITLE: Exporting SQL Commands to a Text File in SQL\nDESCRIPTION: Illustrates how to export results of generated SQL commands to a temporary text file for execution purposes, enhancing the handling of long command outputs.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DISTINCT ... INTO OUTFILE '/tmp/sql.txt';\nmysql -h ${TiDB_IP} -u user -P ${TIDB_PORT} ... < '/tmp/sql.txt';\n```\n\n----------------------------------------\n\nTITLE: Matching Schemas with Prefix in YAML Configuration\nDESCRIPTION: This YAML configuration demonstrates how to match all schemas and tables that have a 'schema_' prefix in the schema name using Table Selector.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/table-selector.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nschema-pattern: \"schema_*\"\ntable-pattern: \"\"\n```\n\n----------------------------------------\n\nTITLE: Delete Query Execution Plan\nDESCRIPTION: Demonstrates the execution plan for a DELETE statement, showing table scan and selection operations\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN DELETE FROM t1 WHERE c1=3;\n```\n\n----------------------------------------\n\nTITLE: Purging Relay Logs with cURL in Shell\nDESCRIPTION: This example demonstrates how to purge relay log files that are no longer required. The request specifies the binlog name and directory from which to purge old relay logs.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'POST' \\\n  'http://127.0.0.1:8261/api/v1/sources/mysql-01/relay/purge' \\\n  -H 'accept: */*' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"relay_binlog_name\": \"mysql-bin.000002\",\n  \"relay_dir\": \"string\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Unsupported Function Predicate Push Down\nDESCRIPTION: Demonstrates scenarios where predicates with unsupported functions cannot be pushed down to storage layer\nSOURCE: https://github.com/pingcap/docs/blob/master/predicate-push-down.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id int primary key, a varchar(10) not null);\ndesc select * from t where truncate(a, \" \") = '1';\n```\n\n----------------------------------------\n\nTITLE: Execution Plan Before Fine Grained Shuffle Stream Count Configuration\nDESCRIPTION: Shows the detailed execution plan for a window function query before configuring `tiflash_fine_grained_shuffle_stream_count`. Note that the `stream_count` is 8 for relevant operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain analyze select *, row_number() over (partition by a) from t;\n+----------------------------------+--------------+-----------+--------------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+--------+------+\n| id                               | estRows      | actRows   | task         | access object | execution info                                                                                                                                                                                                                                                                                                                                  | operator info                                                                                                        | memory | disk |\n+----------------------------------+--------------+-----------+--------------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+--------+------+\n| TableReader_24                   | 600000000.00 | 600000000 | root         |               | time:4m30.5s, loops:585941, cop_task: {num: 9163, max: 0s, min: 0s, avg: 0s, p95: 0s, copr_cache_hit_ratio: 0.00}                                                                                                                                                                                                                               | data:ExchangeSender_23                                                                                               | N/A    | N/A  |\n| └─ExchangeSender_23              | 600000000.00 | 600000000 | mpp[tiflash] |               | tiflash_task:{proc max:4m30.5s, min:3m4.8s, avg: 3m36.1s, p80:4m30.5s, p95:4m30.5s, iters:9160, tasks:3, threads:24}                                                                                                                                                                                                                            | ExchangeType: PassThrough                                                                                            | N/A    | N/A  |\n|   └─Window_22                    | 600000000.00 | 600000000 | mpp[tiflash] |               | tiflash_task:{proc max:3m31.6s, min:2m26.2s, avg: 2m50.7s, p80:3m31.6s, p95:3m31.6s, iters:9160, tasks:3, threads:24}                                                                                                                                                                                                                           | row_number()->Column#23 over(partition by test.t.a rows between current row and current row), stream_count: 8        | N/A    | N/A  |\n|     └─Sort_13                    | 600000000.00 | 600000000 | mpp[tiflash] |               | tiflash_task:{proc max:3m28.6s, min:2m24.2s, avg: 2m48.4s, p80:3m28.6s, p95:3m28.6s, iters:9160, tasks:3, threads:24}                                                                                                                                                                                                                           | test.t.a, stream_count: 8                                                                                            | N/A    | N/A  |\n|       └─ExchangeReceiver_12      | 600000000.00 | 600000000 | mpp[tiflash] |               | tiflash_task:{proc max:32.4s, min:32s, avg: 32.1s, p80:32.4s, p95:32.4s, iters:49307, tasks:3, threads:24}                                                                                                                                                                                                                                      | stream_count: 8                                                                                                      | N/A    | N/A  |\n|         └─ExchangeSender_11      | 600000000.00 | 600000000 | mpp[tiflash] |               | tiflash_task:{proc max:32s, min:0s, avg: 10.7s, p80:32s, p95:32s, iters:9386, tasks:3, threads:60}                                                                                                                                                                                                                                              | ExchangeType: HashPartition, Hash Cols: [name: test.t.a, collate: binary], stream_count: 8                           | N/A    | N/A  |\n|           └─TableFullScan_10     | 600000000.00 | 600000000 | mpp[tiflash] | table:t       | tiflash_task:{proc max:113.9ms, min:0s, avg: 38ms, p80:113.9ms, p95:113.9ms, iters:9386, tasks:3, threads:60}, tiflash_scan:{dtfile:{total_scanned_packs:73834, total_skipped_packs:190, total_scanned_rows:600000000, total_skipped_rows:1536382, total_rs_index_load_time: 16ms, total_read_time: 166324ms}, total_create_snapshot_time: 0ms} | keep order:false                                                                                                     | N/A    | N/A  |\n+----------------------------------+--------------+-----------+--------------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+--------+------+\n7 rows in set (4 min 30.59 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining Warning Alert Rule for TiCDC Sink Execution Error in YAML\nDESCRIPTION: YAML configuration for a warning alert rule that triggers when an error occurs when a TiCDC replication task writes data to the downstream.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-alert-rules.md#2025-04-18_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nchanges(ticdc_sink_execution_error[1m]) > 0\n```\n\n----------------------------------------\n\nTITLE: Configuring HAProxy System Path\nDESCRIPTION: Commands to add HAProxy binary location to system PATH and verify installation.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/haproxy-best-practices.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\necho 'export PATH=/app/haproxy/bin:$PATH' >> /etc/profile\n. /etc/profile\n```\n\nLANGUAGE: bash\nCODE:\n```\nwhich haproxy\n```\n\n----------------------------------------\n\nTITLE: Scan MVCC Range\nDESCRIPTION: Command to scan and view MVCC information for a specific key range.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir /path/to/tikv scan --from 'zm' --limit 2 --show-cf lock,default,write\n```\n\n----------------------------------------\n\nTITLE: Partitioning an Existing Table with Hash in SQL\nDESCRIPTION: This SQL snippet demonstrates how to convert an existing non-partitioned table to a Hash partitioned table with 10 partitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_46\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE members PARTITION BY HASH(id) PARTITIONS 10;\n```\n\n----------------------------------------\n\nTITLE: Hierarchical Structure Example in TiDB Cloud\nDESCRIPTION: This snippet demonstrates the hierarchical structure of organizations, projects, and clusters in TiDB Cloud. It shows how an organization can contain multiple projects, each of which can contain multiple clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/manage-user-access.md#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n- Your organization\n    - Project 1\n        - Cluster 1\n        - Cluster 2\n    - Project 2\n        - Cluster 3\n        - Cluster 4\n    - Project 3\n        - Cluster 5\n        - Cluster 6\n```\n\n----------------------------------------\n\nTITLE: Defining an SQLAlchemy Model with Vector Column\nDESCRIPTION: Python code defining an SQLAlchemy ORM model with a vector column to store embeddings of 3 dimensions using VectorType.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nBase = declarative_base()\n\nclass Document(Base):\n    __tablename__ = 'sqlalchemy_demo_documents'\n    id = Column(Integer, primary_key=True)\n    content = Column(Text)\n    embedding = Column(VectorType(3))\n```\n\n----------------------------------------\n\nTITLE: Checking TiDB-Supported Storage Engines using tidb-server command\nDESCRIPTION: This command-line example demonstrates how to check the storage engines supported by TiDB using the `tidb-server` command. The `-h` flag displays help information, which includes the list of registered store names, such as `tikv`, `mocktikv`, and `unistore`.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/tidb-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n\n./bin/tidb-server -h\n\n```\n\n----------------------------------------\n\nTITLE: TiKV GC Status Alert Query\nDESCRIPTION: PromQL query to monitor if garbage collection is working properly on TiKV instances\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_13\n\nLANGUAGE: promql\nCODE:\n```\nsum(increase(tikv_gcworker_gc_tasks_vec{task=\"gc\"}[1d])) < 1 and (sum(increase(tikv_gc_compaction_filter_perform[1d])) < 1 and sum(increase(tikv_engine_event_total{db=\"kv\", cf=\"write\", type=\"compaction\"}[1d])) >= 1)\n```\n\n----------------------------------------\n\nTITLE: DDL Event Format in Canal-JSON\nDESCRIPTION: Sample of a DDL Event encoded in Canal-JSON format. This shows the structure of a DDL (Data Definition Language) change event including the TiDB extension field that contains the transaction's CommitTS.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"id\": 0,\n    \"database\": \"test\",\n    \"table\": \"\",\n    \"pkNames\": null,\n    \"isDdl\": true,\n    \"type\": \"QUERY\",\n    \"es\": 1639633094670,\n    \"ts\": 1639633095489,\n    \"sql\": \"drop database if exists test\",\n    \"sqlType\": null,\n    \"mysqlType\": null,\n    \"data\": null,\n    \"old\": null,\n    \"_tidb\": {     // TiDB extension field\n        \"commitTs\": 429918007904436226  // A TiDB TSO timestamp\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Disabling Hash Join with System Variable in TiDB\nDESCRIPTION: This snippet shows how disabling hash joins via the `tidb_opt_enable_hash_join` system variable, combined with `NO_MERGE_JOIN` hint, can lead to physical plan errors. By default, TiDB uses hash joins; thus, overriding the default behavior without alternatives will result in an error.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_61\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t1 (a INT);\\nCREATE TABLE t2 (a INT);\\nset tidb_opt_enable_hash_join=off;\\nEXPLAIN SELECT /*+ NO_MERGE_JOIN(t1) */ * FROM t1, t2 WHERE t1.a=t2.a;\\nERROR 1815 (HY000): Internal : Can't find a proper physical plan for this query\n```\n\n----------------------------------------\n\nTITLE: Original Execution Plan\nDESCRIPTION: Execution plan showing the query performance before optimization, with multiple cop tasks and table lookups.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------------+------------+---------+-----------+--------------------------------------------------------------------------+------------------------------------------------------------+\n| id                            | estRows    | actRows | task      | access object                                                            | execution info                                             | \n+-------------------------------+------------+---------+-----------+--------------------------------------------------------------------------+------------------------------------------------------------+\n| HashAgg_18                   | 1.00       | 2571625.22 | 1       | root      |                                                              | time:46.4s, loops:2, partial_worker:{wall_time:46.37,   ...|\n| └─IndexLookUp_19             | 1.00       | 2570096.68 | 301     | root      |                                                              | time:46.4s, loops:2, index_task: {total_time: 45.8s,    ...|\n|   ├─IndexRangeScan_11(Build) | 1309.50    | 317033.98  | 2597411 | cop[tikv] | table:logs, index:logs_idx(snapshot_id, user_id, status)     | time:228ms, loops:2547, cop_task: {num: 67, max: 2.17s, ...|\n|   └─HashAgg_7(Probe)         | 1.00       | 588434.48  | 301     | cop[tikv] |                                                              | time:3m46.7s, loops:260, cop_task: {num: 301,           ...|\n|     └─Selection_13           | 1271.37    | 561549.27  | 2566562 | cop[tikv] |                                                              | tikv_task:{proc max:10s, min:0s, avg: 915.3ms,          ...|\n|       └─TableRowIDScan_12    | 1309.50    | 430861.31  | 2597411 | cop[tikv] | table:logs                                                   | tikv_task:{proc max:10s, min:0s, avg: 908.7ms,          ...|\n+-------------------------------+------------+---------+-----------+--------------------------------------------------------------------------+------------------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Creating Sample MySQL Database\nDESCRIPTION: SQL commands to create a test database and table with sample data.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE hello;\nUSE hello;\n\nCREATE TABLE hello_tidb (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    name VARCHAR(50)\n);\n\nINSERT INTO hello_tidb (name) VALUES ('Hello World');\n\nSELECT * FROM hello_tidb;\n```\n\n----------------------------------------\n\nTITLE: Configuring User Limits for TiDB\nDESCRIPTION: Commands to set resource limits for the tidb user in the limits.conf file.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_33\n\nLANGUAGE: bash\nCODE:\n```\ncat << EOF >>/etc/security/limits.conf\ntidb           soft    nofile         1000000\ntidb           hard    nofile         1000000\ntidb           soft    stack          32768\ntidb           hard    stack          32768\ntidb           soft    core           unlimited\ntidb           hard    core           unlimited\nEOF\n```\n\n----------------------------------------\n\nTITLE: Sample JSON Message Format with Handle Keys Only in TiCDC Kafka Sink\nDESCRIPTION: This JSON snippet illustrates the message format when only handle keys are sent due to large message size. It includes TiDB extension fields to indicate that only handle keys are present.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_17\n\nLANGUAGE: JSON\nCODE:\n```\n{\n    \"id\": 0,\n    \"database\": \"test\",\n    \"table\": \"tp_int\",\n    \"pkNames\": [\n        \"id\"\n    ],\n    \"isDdl\": false,\n    \"type\": \"INSERT\",\n    \"es\": 1639633141221,\n    \"ts\": 1639633142960,\n    \"sql\": \"\",\n    \"sqlType\": {\n        \"id\": 4\n    },\n    \"mysqlType\": {\n        \"id\": \"int\"\n    },\n    \"data\": [\n        {\n          \"id\": \"2\"\n        }\n    ],\n    \"old\": null,\n    \"_tidb\": {     // TiDB extension fields\n        \"commitTs\": 429918007904436226,  // A TiDB TSO timestamp\n        \"onlyHandleKey\": true\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Describing MEMORY_USAGE Table Structure in TiDB\nDESCRIPTION: This SQL query describes the structure of the MEMORY_USAGE table in the information_schema database, showing column names, data types, and other attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-memory-usage.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC memory_usage;\n```\n\n----------------------------------------\n\nTITLE: Updating TiDB Cloud Serverless Cluster interactively\nDESCRIPTION: This command demonstrates updating a TiDB Cloud Serverless cluster in interactive mode, prompting the user for required information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-update.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless update\n```\n\n----------------------------------------\n\nTITLE: Adding Watch Item to Resource Group in SQL\nDESCRIPTION: This SQL command adds a new watch item to the resource group 'rg1', specifying an exact SQL text match for monitoring.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-runaway-watches.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nQUERY WATCH ADD RESOURCE GROUP rg1 SQL TEXT EXACT TO 'select * from sbtest.sbtest1';\n```\n\n----------------------------------------\n\nTITLE: Querying Role Edges Table in TiDB\nDESCRIPTION: SQL query to display role authorization relationships from the mysql.role_edges system table.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM mysql.role_edges;\n```\n\n----------------------------------------\n\nTITLE: YCSB Data Loading for Titan Storage Engine Testing\nDESCRIPTION: Bash command for loading test data with go-ycsb to benchmark the Titan storage engine optimization, creating 5 million records with 31 fields of 1024 bytes each to test large value storage performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngo-ycsb load mysql -P /ycsb/workloads/workloada -p {host} -p mysql.port={port} -p threadcount=100 -p recordcount=5000000 -p operationcount=5000000 -p workload=core -p requestdistribution=uniform -pfieldcount=31 -p fieldlength=1024\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS for DM-master in TOML\nDESCRIPTION: TOML configuration for enabling TLS encryption in DM-master component, including certificate paths and allowed Common Names for identity verification.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-enable-tls.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nssl-ca = \"/path/to/ca.pem\"\nssl-cert = \"/path/to/master-cert.pem\"\nssl-key = \"/path/to/master-key.pem\"\ncert-allowed-cn = [\"dm\"]\n```\n\n----------------------------------------\n\nTITLE: Running Point Select Test with Sysbench\nDESCRIPTION: Bash command for executing the point select benchmark test with Sysbench, using prepared statements (auto mode) and uniform random distribution.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nsysbench --config-file=config oltp_point_select --tables=32 --table-size=10000000 --db-ps-mode=auto --rand-type=uniform run\n```\n\n----------------------------------------\n\nTITLE: Enabling GC in TiDB after Changefeed Creation\nDESCRIPTION: This SQL command enables garbage collection (GC) in the TiDB cluster after creating a changefeed, to allow the cleaning up of historical data that has already been replicated to the downstream cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nMySQL [test]> SET GLOBAL tidb_gc_enable=TRUE;\n\n```\nQuery OK, 0 rows affected (0.01 sec)\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Raw Value Storage for Large Messages in TiCDC Kafka Sink (TOML)\nDESCRIPTION: This configuration snippet demonstrates how to set up TiCDC Kafka sink to send only the 'value' field of Kafka messages to external storage. This feature, introduced in v8.4.0, is applicable to non-Open Protocol scenarios and can reduce CPU and deserialization overhead.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_20\n\nLANGUAGE: TOML\nCODE:\n```\nprotocol = \"simple\"\n\n[sink.kafka-config.large-message-handle]\nlarge-message-handle-option = \"claim-check\"\nclaim-check-storage-uri = \"s3://claim-check-bucket\"\nclaim-check-raw-value = true\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB as Root\nDESCRIPTION: Shell command to connect to TiDB database as the root user on localhost port 4000.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-default-role.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 127.0.0.1 -P 4000 -u root\n```\n\n----------------------------------------\n\nTITLE: Handling timestamp formatting errors in TiDB Lightning\nDESCRIPTION: This snippet addresses timestamp type errors that occur due to invalid time formats in entries during TiDB Lightning operations, along with suggested solutions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_18\n\nLANGUAGE: markdown\nCODE:\n```\n- Cause: A timestamp type entry has a time value that does not exist. This is either because of DST changes or because the time value has exceeded the supported range (from Jan 1, 1970 to Jan 19, 2038).\n\n    - Solution: See [Troubleshooting Solution](/tidb-lightning/troubleshoot-tidb-lightning.md#sql2kv-sql-encode-error--types1292invalid-time-format-1970-1-1-).\n```\n\n----------------------------------------\n\nTITLE: Querying Clustered Index Information\nDESCRIPTION: SQL commands to check whether a table's primary key is implemented as a clustered index using various system queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/clustered-indexes.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE t;\nSHOW INDEX FROM t;\nSELECT TIDB_PK_TYPE FROM information_schema.tables WHERE table_schema = 'test' AND table_name = 't';\n```\n\n----------------------------------------\n\nTITLE: Handling `driver: bad connection` error\nDESCRIPTION: This snippet discusses the `driver: bad connection` error due to connection issues between DM and the downstream TiDB database, including corrective actions based on DM version.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\n- The `driver: bad connection` error indicates that an anomaly has occurred in the connection between DM and the downstream TiDB database (such as network failure and TiDB restart), and that the data of the current request has not yet been sent to TiDB.\n\n    - For versions earlier than DM 1.0.0 GA, stop the task by running `stop-task` and then restart the task by running `start-task`.\n    - For DM 1.0.0 GA or later versions, an automatic retry mechanism for this type of error is added. See [#265](https://github.com/pingcap/dm/pull/265).\n```\n\n----------------------------------------\n\nTITLE: Editing Cluster Configuration\nDESCRIPTION: Command to edit the cluster configuration file using TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-faq.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster edit-config ${cluster-name}\n```\n\n----------------------------------------\n\nTITLE: Creating Index and View for EXPLAIN Comparison in TiDB\nDESCRIPTION: This snippet creates an index on the duration column of the trips table and defines a view called long_trips for trips with a duration greater than 3600 seconds. It then compares the execution plans of querying the view versus the equivalent direct table query.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-views.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE trips ADD INDEX (duration);\nCREATE OR REPLACE VIEW long_trips AS SELECT * FROM trips WHERE duration > 3600;\nEXPLAIN SELECT * FROM long_trips;\nEXPLAIN SELECT * FROM trips WHERE duration > 3600;\n```\n\n----------------------------------------\n\nTITLE: DM Relay Log Error Message\nDESCRIPTION: Error message shown when executing start-relay command in DM versions 2.0.2 to 2.0.6, indicating issues with relay log metadata.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-faq.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nflush local meta, Rawcause: open relay-dir/xxx.000001/relay.metayyyy: no such file or directory\n```\n\n----------------------------------------\n\nTITLE: Output of TIFLASH_REPLICA Table Description in SQL\nDESCRIPTION: This SQL output shows the structure of the TIFLASH_REPLICA table, including field names, data types, null constraints, keys, default values, and extra information for each column in the table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tiflash-replica.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+-----------------+-------------+------+------+---------+-------+\n| Field           | Type        | Null | Key  | Default | Extra |\n+-----------------+-------------+------+------+---------+-------+\n| TABLE_SCHEMA    | varchar(64) | YES  |      | NULL    |       |\n| TABLE_NAME      | varchar(64) | YES  |      | NULL    |       |\n| TABLE_ID        | bigint(21)  | YES  |      | NULL    |       |\n| REPLICA_COUNT   | bigint(64)  | YES  |      | NULL    |       |\n| LOCATION_LABELS | varchar(64) | YES  |      | NULL    |       |\n| AVAILABLE       | tinyint(1)  | YES  |      | NULL    |       |\n| PROGRESS        | double      | YES  |      | NULL    |       |\n+-----------------+-------------+------+------+---------+-------+\n7 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: SHOW WARNINGS EBNF Syntax Definition\nDESCRIPTION: Defines the formal syntax for the SHOW WARNINGS statement using EBNF notation\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-warnings.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowWarningsStmt ::=\n    \"SHOW\" \"WARNINGS\"\n```\n\n----------------------------------------\n\nTITLE: Combining JSON_UNQUOTE() and JSON_EXTRACT() for String Extraction\nDESCRIPTION: This example demonstrates how to combine JSON_UNQUOTE() with JSON_EXTRACT() to extract a property from a JSON document and remove its quotes in one operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-modify.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_UNQUOTE(JSON_EXTRACT('{\"database\": \"TiDB\"}', '$.database'));\n```\n\n----------------------------------------\n\nTITLE: Sysbench Performance Testing Command\nDESCRIPTION: Bash command used to execute Sysbench performance tests with configurable parameters for threads, time, and database connection\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-performance-test.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsysbench $testname \\\n    --threads=$threads \\\n    --time=1200 \\\n    --report-interval=10 \\\n    --rand-type=uniform \\\n    --db-driver=mysql \\\n    --mysql-db=sbtest \\\n    --mysql-host=$host \\\n    --mysql-port=$port \\\n    run --tables=32 --table-size=1000000\n```\n\n----------------------------------------\n\nTITLE: Showing Indexes on the 'books' Table in TiDB\nDESCRIPTION: SQL statement to display all indexes on the 'books' table in the 'bookshop' database.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-secondary-indexes.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSHOW INDEXES FROM `bookshop`.`books`;\n```\n\n----------------------------------------\n\nTITLE: Creating Valid Partitioned Tables with Unique Keys - SQL\nDESCRIPTION: This SQL snippet displays valid table creation statements where unique keys conform to the partitioning key requirements, ensuring that all columns from the unique keys include those used in the partitioning expression.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_54\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCREATE TABLE t1 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    UNIQUE KEY (col1, col2, col3)\n)\n\nPARTITION BY HASH(col3)\nPARTITIONS 4;\n\nCREATE TABLE t2 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    UNIQUE KEY (col1, col3)\n)\n\nPARTITION BY HASH(col1 + col3)\nPARTITIONS 4;\n```\n```\n\n----------------------------------------\n\nTITLE: Managing TiFlash Nodes - Shell Commands\nDESCRIPTION: Shell commands using tiup to scale in, display, and prune TiFlash nodes from a TiDB cluster. These commands remove nodes, verify their status, and clean up tombstone nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-disaggregated-and-s3.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster scale-in mycluster -N 'node0,node1...' # Remove all TiFlash nodes\ntiup cluster display mycluster                     # Wait for all TiFlash nodes to enter the Tombstone state\ntiup cluster prune mycluster                       # Remove all TiFlash nodes in the Tombstone state\n```\n\n----------------------------------------\n\nTITLE: Creating a Replication Task via POST API in Shell\nDESCRIPTION: This example demonstrates how to create a new data replication task using the DM API. The request contains comprehensive configuration including task name, mode, target database settings, binlog filtering rules, and source configuration with migration parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_26\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'POST' \\\n  'http://127.0.0.1:8261/api/v1/tasks' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"task\": {\n    \"name\": \"task-1\",\n    \"task_mode\": \"all\",\n    \"shard_mode\": \"pessimistic\",\n    \"meta_schema\": \"dm-meta\",\n    \"enhance_online_schema_change\": true,\n    \"on_duplicate\": \"overwrite\",\n    \"target_config\": {\n      \"host\": \"127.0.0.1\",\n      \"port\": 3306,\n      \"user\": \"root\",\n      \"password\": \"123456\",\n      \"security\": {\n        \"ssl_ca_content\": \"\",\n        \"ssl_cert_content\": \"\",\n        \"ssl_key_content\": \"\",\n        \"cert_allowed_cn\": [\n          \"string\"\n        ]\n      }\n    },\n    \"binlog_filter_rule\": {\n      \"rule-1\": {\n        \"ignore_event\": [\n          \"all dml\"\n        ],\n        \"ignore_sql\": [\n          \"^Drop\"\n        ]\n      },\n      \"rule-2\": {\n        \"ignore_event\": [\n          \"all dml\"\n        ],\n        \"ignore_sql\": [\n          \"^Drop\"\n        ]\n      },\n      \"rule-3\": {\n        \"ignore_event\": [\n          \"all dml\"\n        ],\n        \"ignore_sql\": [\n          \"^Drop\"\n        ]\n      }\n    },\n    \"table_migrate_rule\": [\n      {\n        \"source\": {\n          \"source_name\": \"source-name\",\n          \"schema\": \"db-*\",\n          \"table\": \"tb-*\"\n        },\n        \"target\": {\n          \"schema\": \"db1\",\n          \"table\": \"tb1\"\n        },\n        \"binlog_filter_rule\": [\n          \"rule-1\",\n          \"rule-2\",\n          \"rule-3\",\n        ]\n      }\n    ],\n    \"source_config\": {\n      \"full_migrate_conf\": {\n        \"export_threads\": 4,\n        \"import_threads\": 16,\n        \"data_dir\": \"./exported_data\",\n        \"consistency\": \"auto\"\n        \"import_mode\": \"physical\",\n        \"sorting_dir\": \"./sort_dir\",\n        \"disk_quota\": \"80G\",\n        \"checksum\": \"required\",\n        \"analyze\": \"optional\",\n        \"range_concurrency\": 0,\n        \"compress-kv-pairs\": \"\",\n        \"pd_addr\": \"\",\n        \"on_duplicate_logical\": \"error\",\n        \"on_duplicate_physical\": \"none\"\n      },\n      \"incr_migrate_conf\": {\n        \"repl_threads\": 16,\n        \"repl_batch\": 100\n      },\n      \"source_conf\": [\n        {\n          \"source_name\": \"mysql-replica-01\",\n          \"binlog_name\": \"binlog.000001\",\n          \"binlog_pos\": 4,\n          \"binlog_gtid\": \"03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170\"\n        }\n      ]\n    }\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Killing TiDB Lightning Process with USR1 Signal\nDESCRIPTION: This shell command sends a USR1 signal to TiDB Lightning, enabling the status port for debugging purposes. It is used to retrieve runtime goroutine information and requires access to TiDB Lightning's process ID (PID). Suitable for purposes where status-port is not pre-specified.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-faq.md#2025-04-18_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\nkill -USR1 <lightning-pid>\n```\n\n----------------------------------------\n\nTITLE: Parsing TSO in TiKV\nDESCRIPTION: This command parses the physical and logical time of the provided TSO value, returning formatted date and time along with logical time.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_59\n\nLANGUAGE: bash\nCODE:\n```\ntso 395181938313123110\n```\n\n----------------------------------------\n\nTITLE: WITH Clause EBNF Syntax Definition\nDESCRIPTION: The EBNF syntax definition for the WITH clause in TiDB SQL, showing both the regular WITH syntax and the recursive variant.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-with.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nWithClause ::=\n        \"WITH\" WithList\n|       \"WITH\" \"RECURSIVE\" WithList\n```\n\n----------------------------------------\n\nTITLE: Deleting TiKV Pod with kubectl\nDESCRIPTION: This command deletes a TiKV pod in a Kubernetes environment managed by TiDB Operator. This is performed to trigger the creation of a new pod to replace the deleted one and have it rejoin the cluster. Requires the namespace and pod name.\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nkubectl delete -n ${namespace} pod ${pod_name}\n```\n\n----------------------------------------\n\nTITLE: Unlocking Table Statistics in TiDB - SQL\nDESCRIPTION: Demonstrates how to unlock statistics for a table named 't' in the TiDB database, followed by an analyze operation. It shows the expected output and generates a warning regarding the sample rate used during analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-unlock-stats.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> UNLOCK STATS t;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> ANALYZE TABLE t;\nQuery OK, 0 rows affected, 1 warning (0.03 sec)\n\nmysql> SHOW WARNINGS;\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------+\n| Level | Code | Message                                                                                                                                 |\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------+\n| Note  | 1105 | Analyze use auto adjusted sample rate 1.000000 for table test.t, reason to use this rate is \"use min(1, 110000/8) as the sample-rate=1\" |\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Disabling a Data Source with cURL in Shell\nDESCRIPTION: This example shows how to disable a data source by making a POST request to the DM API. When disabled, all subtasks that rely on this data source will be stopped in batch.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'POST' \\\n  'http://127.0.0.1:8261/api/v1/sources/mysql-01/disable' \\\n  -H 'accept: */*' \\\n  -H 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Replaying Traffic with SQL in TiProxy\nDESCRIPTION: This SQL snippet is used to replay traffic from captured files in TiProxy with specified user credentials. Requires SUPER or TRAFFIC_REPLAY_ADMIN privileges for executing.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-traffic-replay.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nTRAFFIC REPLAY FROM \"/tmp/traffic\" USER=\"u1\" PASSWORD=\"123456\"\n```\n\n----------------------------------------\n\nTITLE: Non-recursive CTE SQL Example\nDESCRIPTION: Example of a non-recursive Common Table Expression that creates a simple result set and then references it twice in a join.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-with.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nWITH cte AS (SELECT 1, 2) SELECT * FROM cte t1, cte t2;\n```\n\n----------------------------------------\n\nTITLE: Configuring Compactor in DM Sync Module\nDESCRIPTION: YAML configuration example showing how to enable the Compactor feature in DM's sync processing unit by setting syncer.compact to true.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-replication-logic.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsyncers:                            # The configuration parameters of the sync processing unit\n  global:                           # Configuration name\n    ...                              # Other configurations are omitted\n    compact: true\n```\n\n----------------------------------------\n\nTITLE: Response Structure for Creating a Knowledge Base - JSON\nDESCRIPTION: This snippet defines the expected JSON response structure after successfully creating a knowledge base. It includes the status code and the knowledge base ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-knowledge.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"code\":200,\n    \"msg\":\"\",\n    \"result\":\n        {\n            \"default\":true,\n            \"description\":\"\",\n            \"knowledge_base_id\":2\n        }\n}\n```\n\n----------------------------------------\n\nTITLE: Decoding Avro Data and Fetching Schema in Go\nDESCRIPTION: This code snippet contains functions for decoding Avro-encoded data and fetching the corresponding schema from a schema registry. It includes methods to extract schema ID, fetch schema from registry, and decode the binary data.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-checksum-verification.md#2025-04-18_snippet_1\n\nLANGUAGE: go\nCODE:\n```\nfunc getValueMapAndSchema(data []byte, url string) (map[string]interface{}, map[string]interface{}, error) {\n    schemaID, binary, err := extractSchemaIDAndBinaryData(data)\n    if err != nil {\n        return nil, nil, err\n    }\n\n    codec, err := GetSchema(url, schemaID)\n    if err != nil {\n        return nil, nil, err\n    }\n\n    native, _, err := codec.NativeFromBinary(binary)\n    if err != nil {\n        return nil, nil, err\n    }\n\n    result, ok := native.(map[string]interface{})\n    if !ok {\n        return nil, nil, errors.New(\"raw avro message is not a map\")\n    }\n\n    schema := make(map[string]interface{})\n    if err := json.Unmarshal([]byte(codec.Schema()), &schema); err != nil {\n        return nil, nil, errors.Trace(err)\n    }\n\n    return result, schema, nil\n}\n\nfunc extractSchemaIDAndBinaryData(data []byte) (int, []byte, error) {\n    if len(data) < 5 {\n        return 0, nil, errors.ErrAvroInvalidMessage.FastGenByArgs()\n    }\n    if data[0] != magicByte {\n        return 0, nil, errors.ErrAvroInvalidMessage.FastGenByArgs()\n    }\n    return int(binary.BigEndian.Uint32(data[1:5])), data[5:], nil\n}\n\nfunc GetSchema(url string, schemaID int) (*goavro.Codec, error) {\n    requestURI := url + \"/schemas/ids/\" + strconv.Itoa(schemaID)\n\n    req, err := http.NewRequest(\"GET\", requestURI, nil)\n    if err != nil {\n        log.Error(\"Cannot create the request to look up the schema\", zap.Error(err))\n        return nil, errors.WrapError(errors.ErrAvroSchemaAPIError, err)\n    }\n    req.Header.Add(\n        \"Accept\",\n        \"application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, \"+\n            \"application/json\",\n    )\n\n    httpClient := &http.Client{}\n    resp, err := httpClient.Do(req)\n    if err != nil {\n        return nil, err\n    }\n    defer resp.Body.Close()\n\n    body, err := io.ReadAll(resp.Body)\n    if err != nil {\n        log.Error(\"Cannot parse the lookup schema response\", zap.Error(err))\n        return nil, errors.WrapError(errors.ErrAvroSchemaAPIError, err)\n    }\n\n    if resp.StatusCode == 404 {\n        log.Warn(\"Specified schema not found in Registry\", zap.String(\"requestURI\", requestURI), zap.Int(\"schemaID\", schemaID))\n        return nil, errors.ErrAvroSchemaAPIError.GenWithStackByArgs(\"Schema not found in Registry\")\n    }\n\n    if resp.StatusCode != 200 {\n        log.Error(\"Failed to query schema from the Registry, HTTP error\",\n            zap.Int(\"status\", resp.StatusCode), zap.String(\"uri\", requestURI), zap.ByteString(\"responseBody\", body))\n        return nil, errors.ErrAvroSchemaAPIError.GenWithStack(\"Failed to query schema from the Registry, HTTP error\")\n    }\n\n    var jsonResp lookupResponse\n    err = json.Unmarshal(body, &jsonResp)\n    if err != nil {\n        log.Error(\"Failed to parse result from Registry\", zap.Error(err))\n        return nil, errors.WrapError(errors.ErrAvroSchemaAPIError, err)\n    }\n\n    codec, err := goavro.NewCodec(jsonResp.Schema)\n    if err != nil {\n        return nil, errors.WrapError(errors.ErrAvroSchemaAPIError, err)\n    }\n    return codec, nil\n}\n\ntype lookupResponse struct {\n    Name     string `json:\"name\"`\n    SchemaID int    `json:\"id\"`\n    Schema   string `json:\"schema\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Readpool for Hybrid Deployment in YAML\nDESCRIPTION: YAML configuration for enabling unified thread pool for TiKV readpool storage and coprocessor. This optimizes resource utilization in hybrid deployments.\nSOURCE: https://github.com/pingcap/docs/blob/master/hybrid-deployment-topology.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nreadpool.storage.use-unified-pool: true\nreadpool.coprocessor.use-unified-pool: true\n```\n\n----------------------------------------\n\nTITLE: Establishing password_history in TiDB\nDESCRIPTION: This global variable enforces a password reuse policy by limiting the number of previous passwords a user cannot reuse. Setting it to a positive integer enables this policy.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n-- Default value: `0`\n-- Range: `[0, 4294967295]`\nSET GLOBAL password_history = 0;\n```\n\n----------------------------------------\n\nTITLE: Using Sqoop for Data Export with TiDB - Bash\nDESCRIPTION: This bash command provides a solution to the `statement count exceeds the transaction limitation` error in TiDB while exporting data using Sqoop. It reduces the number of statements per batch to comply with TiDB transaction limits. Ensure Sqoop and JDBC dependencies are correctly configured.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/migration-tidb-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsqoop export \\\n    -Dsqoop.export.records.per.statement=10 \\\n    --connect jdbc:mysql://mysql.example.com/sqoop \\\n    --username sqoop ${user} \\\n    --password ${passwd} \\\n    --table ${tab_name} \\\n    --export-dir ${dir} \\\n    --batch\n```\n\n----------------------------------------\n\nTITLE: Using Index Selectivity Ratio with Index-Matching Filter in TiDB SQL\nDESCRIPTION: Example showing query execution with 100% ratio but with an additional predicate on column 'a' that limits the scan range since it matches the index. This results in a more reasonable estimation of 9,074 rows to scan.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_60\n\nLANGUAGE: sql\nCODE:\n```\n> SET SESSION tidb_opt_ordering_index_selectivity_ratio = 1;\n\n> EXPLAIN SELECT * FROM t USE INDEX (ia) WHERE a <= 9000 AND b <= 9000 ORDER BY a LIMIT 1;\n+------------------------------------+---------+-----------+-----------------------+------------------------------------+\n| id                                 | estRows | task      | access object         | operator info                      |\n+------------------------------------+---------+-----------+-----------------------+------------------------------------+\n| Limit_12                           | 1.00    | root      |                       | offset:0, count:1                  |\n| └─Projection_22                    | 1.00    | root      |                       | test.t.a, test.t.b, test.t.c       |\n|   └─IndexLookUp_21                 | 1.00    | root      |                       |                                    |\n|     ├─IndexRangeScan_18(Build)     | 9074.99 | cop[tikv] | table:t, index:ia(a)  | range:[-inf,9000], keep order:true |\n|     └─Selection_20(Probe)          | 1.00    | cop[tikv] |                       | le(test.t.b, 9000)                 |\n|       └─TableRowIDScan_19          | 9074.99 | cop[tikv] | table:t               | keep order:false                   |\n+------------------------------------+---------+-----------+-----------------------+------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Configuring TiSpark to Read from Read-Only Nodes\nDESCRIPTION: This configuration entry for Spark directs TiSpark to read data from learner replicas on read-only nodes. It should be added to the Spark configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/readonly-nodes.md#2025-04-18_snippet_6\n\nLANGUAGE: properties\nCODE:\n```\nspark.tispark.replica_read learner\n```\n\n----------------------------------------\n\nTITLE: Unlocking User Accounts and Restoring Write Mode - SQL\nDESCRIPTION: SQL command sequence to unlock user accounts and switch the cluster back to read-write mode. Essential for reverting transactional operations to normal after a switchover is completed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nALTER USER ACCOUNT UNLOCK;\nSET GLOBAL tidb_super_read_only=OFF;\n```\n\n----------------------------------------\n\nTITLE: Creating a tpcc Database in SQL\nDESCRIPTION: This SQL statement creates a database named `tpcc`. This database will be used to load the TPC-C data for the performance tests. This SQL code is executed in the TiDB Cloud environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE DATABASE tpcc;\"\n```\n\n----------------------------------------\n\nTITLE: Show Backups with WHERE Clause in TiDB\nDESCRIPTION: This SQL statement filters the output of SHOW BACKUPS based on a condition applied to the columns. This example shows backups where the `Progress` is less than 25.0%.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-backups.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW BACKUPS WHERE `Progress` < 25.0;\n```\n\n----------------------------------------\n\nTITLE: TiDB Cloud Login with Insecure Storage\nDESCRIPTION: Example demonstrating how to log into TiDB Cloud while saving credentials in plain text instead of using the credential store.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-auth-login.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud auth login --insecure-storage\n```\n\n----------------------------------------\n\nTITLE: Deleting a Branch in Non-Interactive Mode in Shell\nDESCRIPTION: Example of deleting a TiDB Cloud Serverless branch in non-interactive mode. This requires explicitly specifying the branch ID and cluster ID as command parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-delete.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud branch delete --branch-id <branch-id> --cluster-id <cluster-id>\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration\nDESCRIPTION: YAML configuration block defining the document metadata including title, category, and summary for the TiDB 5.2.4 release notes.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.2.4.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: TiDB 5.2.4 Release Notes\ncategory: Releases\nsummary: Learn about the new features, compatibility changes, improvements, and bug fixes in TiDB 5.2.4.\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring Firewall Rules for Grafana\nDESCRIPTION: Command to set up firewall rules for Grafana monitoring service.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nfirewall-cmd --permanent --zone=public --add-service=grafana\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_plan_cache_for_param_limit in TiDB\nDESCRIPTION: Controls caching for execution plans using a variable as the LIMIT parameter. Its default of ON means it supports standard parameters, with limits defined for caching larger variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_38\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): No\n- Type: Boolean\n- Default value: `ON`\n- This variable controls whether Prepared Plan Cache caches execution plans with a variable as the `LIMIT` parameter (`LIMIT ?`).\n```\n\n----------------------------------------\n\nTITLE: Example Bash Script Invocation\nDESCRIPTION: This example demonstrates how to call the bash script to split a CSV file into smaller files. `split.sh` is the name of the splitting script, `3` is the number of parts to split the file into, and `mytest.customer.csv` is the input file to be split.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-import-local-files.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n\"> sh ./split.sh 3 mytest.customer.csv\\n> ls -h | grep mytest\\nmytest.customer.0.csv\\nmytest.customer.1.csv\\nmytest.customer.2.csv\\nmytest.customer.csv\"\n```\n\n----------------------------------------\n\nTITLE: Defining TiDB Schema Error Alert Rule in Prometheus\nDESCRIPTION: Alert rule to detect if TiDB fails to reload the latest schema information within one lease. Triggers when schema lease errors occur in the last 15 minutes.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_0\n\nLANGUAGE: prometheus\nCODE:\n```\nincrease(tidb_session_schema_lease_error_total{type=\"outdated\"}[15m]) > 0\n```\n\n----------------------------------------\n\nTITLE: Sink URI Configuration Example 2\nDESCRIPTION: This code snippet provides another example of a Sink URI configuration, where the topic is in the default namespace `default` of the default tenant `public` in Pulsar. Therefore, the URI only contains the topic name.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"pulsar://127.0.0.1:6650/yktest?protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: Raft Engine Recovery and Performance Settings\nDESCRIPTION: Configuration options for Raft Engine recovery behavior, threading, memory limits, and format versioning.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_24\n\nLANGUAGE: yaml\nCODE:\n```\nrecovery-mode: \"tolerate-tail-corruption\"\nrecovery-read-block-size: \"16KiB\"\nrecovery-threads: 4\nmemory-limit: \"Total machine memory * 15%\"\nformat-version: 2\nenable-log-recycle: true\nprefill-for-recycle: false\ncompression-level: 1\n```\n\n----------------------------------------\n\nTITLE: TiCDC OpenAPI Authentication with Username/Password\nDESCRIPTION: Authenticate TiCDC OpenAPI requests using username and password.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-client-authentication.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v2/status --cert client.crt --key client.key --cacert ca.crt\n```\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v2/status --user test:password\n```\n\n----------------------------------------\n\nTITLE: Querying Salesforce Account Table\nDESCRIPTION: SQL query to verify the empty state of the newly created Salesforce account table in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-aws-appflow-integration.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM sf_account;\n```\n\n----------------------------------------\n\nTITLE: Using # for Line Comments in TiDB SQL\nDESCRIPTION: Demonstrates how to use the hash symbol (#) to add a single-line comment to a SQL statement in TiDB. This style allows you to add comments after a SQL statement on the same line.\nSOURCE: https://github.com/pingcap/docs/blob/master/comment-syntax.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1+1;     # comments\n```\n\n----------------------------------------\n\nTITLE: IMPORT INTO Syntax in TiDB SQL\nDESCRIPTION: EBNF syntax definition for the IMPORT INTO statement in TiDB. Includes syntax for importing from files and SELECT statements, with options for specifying columns, file formats, and import options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nImportIntoStmt ::=\n    'IMPORT' 'INTO' TableName ColumnNameOrUserVarList? SetClause? FROM fileLocation Format? WithOptions?\n    |\n    'IMPORT' 'INTO' TableName ColumnNameList? FROM SelectStatement WithOptions?\n\nColumnNameOrUserVarList ::=\n    '(' ColumnNameOrUserVar (',' ColumnNameOrUserVar)* ')'\n\nColumnNameList ::=\n    '(' ColumnName (',' ColumnName)* ')'\n\nSetClause ::=\n    'SET' SetItem (',' SetItem)*\n\nSetItem ::=\n    ColumnName '=' Expr\n\nFormat ::=\n    'CSV' | 'SQL' | 'PARQUET'\n\nWithOptions ::=\n    'WITH' OptionItem (',' OptionItem)*\n\nOptionItem ::=\n    optionName '=' optionVal | optionName\n```\n\n----------------------------------------\n\nTITLE: Example Usage of ticloud config list\nDESCRIPTION: This example demonstrates how to use the 'ticloud config list' command without any flags to display all available user profiles.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-list.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud config list\n```\n\n----------------------------------------\n\nTITLE: Checking IAM User Policy Permissions\nDESCRIPTION: The provided JSON snippet is a sample IAM user policy that grants permissions necessary for accessing Amazon S3 resources. It includes critical actions like retrieving objects from a bucket and listing bucket contents.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/troubleshoot-import-access-denied-error.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::tidb-cloud-source-data/mydata/*\"\n        },\n        {\n            \"Sid\": \"VisualEditor1\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:ListBucket\",\n                \"s3:GetBucketLocation\"\n            ],\n            \"Resource\": \"arn:aws:s3:::tidb-cloud-source-data\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Authenticating Wrangler CLI\nDESCRIPTION: Command to log in and authenticate Wrangler CLI with Cloudflare account.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-cloudflare.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nwrangler login\n```\n\n----------------------------------------\n\nTITLE: Index File Structure in JSON\nDESCRIPTION: The index file records all components in the mirror along with their owner information. It includes signatures, component details, owner information, and versioning metadata.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror-reference.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"signatures\": [                                             # The file's signature.\n        {\n            \"keyid\": \"{id-of-index-key-1}\",                     # The ID of the first private key that participates in the signature.\n            \"sig\": \"{signature-by-index-key-1}\",                # The signed part of this file by this private key.\n        },\n        ...\n        {\n            \"keyid\": \"{id-of-root-key-N}\",                      # The ID of the Nth private key that participates in the signature.\n            \"sig\": \"{signature-by-root-key-N}\"                  # The signed part of this file by this private key.\n        }\n    ],\n    \"signed\": {\n        \"_type\": \"index\",                                       # The file type.\n        \"components\": {                                         # The component list.\n            \"{component1}\": {                                   # The name of the first component.\n                \"hidden\": {bool},                               # Whether it is a hidden component.\n                \"owner\": \"{owner-id}\",                          # The component owner's ID.\n                \"standalone\": {bool},                           # Whether it is a standalone component.\n                \"url\": \"/{component}.json\",                     # The address from which the component can be obtained. You need to prefix it with the version number (for example, /{N}.{component}.json).\n                \"yanked\": {bool}                                # Indicates whether the component is marked as deleted.\n            },\n            ...\n            \"{componentN}\": {                                   # The name of the Nth component.\n                ...\n            },\n        },\n        \"default_components\": [\"{component1}\"...\"{componentN}\"], # The default component that a mirror must contain. Currently, this field defaults to empty (disabled).\n        \"expires\": \"{expiration-date-of-this-file}\",            # The expiration time of the file. If the file expires, the client rejects the file.\n        \"owners\": {\n            \"{owner1}\": {                                       # The ID of the first owner.\n                \"keys\": {                                       # Only the key's signature recorded in `keys` is valid.\n                    \"{id-of-the-key-1}\": {                      # The first key of the owner.\n                        \"keytype\": \"rsa\",                       # The key's type. Currently, the key type is fixed as rsa.\n                        \"keyval\": {                             # The key's payload.\n                            \"public\": \"{public-key-content}\"    # The public key's content.\n                        },\n                        \"scheme\": \"rsassa-pss-sha256\"           # Currently, the scheme is fixed as rsassa-pss-sha256.\n                    },\n                    ...\n                    \"{id-of-the-key-N}\": {                      # The Nth key of the owner.\n                        ...\n                    }\n                },\n                \"name\": \"{owner-name}\",                         # The name of the owner.\n                \"threshold\": {N}                                 # Indicates that the components owned by the owner must have at least N valid signatures.\n            },\n            ...\n            \"{ownerN}\": {                                       # The ID of the Nth owner.\n                ...\n            }\n        }\n        \"spec_version\": \"0.1.0\",                                # The specified version followed by this file. If the file structure is changed in the future, the version number needs to be upgraded. The current version number is 0.1.0.\n        \"version\": {N}                                          # The version number of this file. You need to create a new {N+1}.index.json every time you update the file, and set its version to N + 1.\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining DO Statement Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the DO statement in TiDB SQL. It outlines the structure of the statement including expressions and predicates.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-do.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nDoStmt   ::= 'DO' ExpressionList\n\nExpressionList ::=\n    Expression ( ',' Expression )*\n\nExpression ::=\n    ( singleAtIdentifier assignmentEq | 'NOT' | Expression ( logOr | 'XOR' | logAnd ) ) Expression\n|   'MATCH' '(' ColumnNameList ')' 'AGAINST' '(' BitExpr FulltextSearchModifierOpt ')'\n|   PredicateExpr ( IsOrNotOp 'NULL' | CompareOp ( ( singleAtIdentifier assignmentEq )? PredicateExpr | AnyOrAll SubSelect ) )* ( IsOrNotOp ( trueKwd | falseKwd | 'UNKNOWN' ) )?\n```\n\n----------------------------------------\n\nTITLE: Disable Scheduling Fallback via pd-ctl\nDESCRIPTION: This command disables the dynamic switching function of the `scheduling` microservice, preventing PD from taking over the scheduling service if the `scheduling` microservice terminates.  It ensures consistency in scheduling logic when versions differ between the microservice and PD. After execution, cluster scheduling will be unavailable until the `scheduling` microservice is restarted.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-microservices.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n\"pd-ctl config set enable-scheduling-fallback false\"\n```\n\n----------------------------------------\n\nTITLE: Creating TiDB Cloud Serverless Cluster (Shell)\nDESCRIPTION: This command creates a TiDB Cloud Serverless cluster. It can be used in both interactive and non-interactive modes. In interactive mode, the user is prompted for input, while in non-interactive mode, flags must be specified.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-create.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless create [flags]\n```\n\n----------------------------------------\n\nTITLE: Viewing Capture Status\nDESCRIPTION: Illustrates how to view capture results and download tokens from the mysql.plan_replayer_status table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-replayer.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT * FROM mysql.plan_replayer_status;\n+------------------------------------------------------------------+------------------------------------------------------------------+------------+-----------------------------------------------------------+---------------------+-------------+-----------------+\n| sql_digest                                                       | plan_digest                                                      | origin_sql | token                                                     | update_time         | fail_reason | instance        |\n+------------------------------------------------------------------+------------------------------------------------------------------+------------+-----------------------------------------------------------+---------------------+-------------+-----------------+\n| 086e3fbd2732f7671c17f299d4320689deeeb87ba031240e1e598a0ca14f808c | 042de2a6652a6d20afc629ff90b8507b7587a1c7e1eb122c3e0b808b1d80cc02 |            | replayer_Utah4nkz2sIEzkks7tIRog==_1668746293523179156.zip | 2022-11-18 12:38:13 | NULL        | 172.16.4.4:4022 |\n| b5b38322b7be560edb04f33f15b15a885e7c6209a22b56b0804622e397199b54 | 1770efeb3f91936e095f0344b629562bf1b204f6e46439b7d8f842319297c3b5 |            | replayer_Z2mUXNHDjU_WBmGdWQqifw==_1668746293560115314.zip | 2022-11-18 12:38:13 | NULL        | 172.16.4.4:4022 |\n| 96d00c0b3f08795fe94e2d712fa1078ab7809faf4e81d198f276c0dede818cf9 | 8892f74ac2a42c2c6b6152352bc491b5c07c73ac3ed66487b2c990909bae83e8 |            | replayer_RZcRHJB7BaCccxFfOIAhWg==_1668746293578282450.zip | 2022-11-18 12:38:13 | NULL        | 172.16.4.4:4022 |\n+------------------------------------------------------------------+------------------------------------------------------------------+------------+-----------------------------------------------------------+---------------------+-------------+-----------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Cross-Table Query Hint Example\nDESCRIPTION: Shows how hints fail in cross-table queries when database names are not explicitly specified. Includes table creation and query execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_53\n\nLANGUAGE: sql\nCODE:\n```\nUSE test1;\nCREATE TABLE t1(a INT, KEY(a));\nUSE test2;\nCREATE TABLE t2(a INT, KEY(a));\nSELECT /*+ use_index(t1, a) */ * FROM test1.t1, t2;\nSHOW WARNINGS;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+---------+------+----------------------------------------------------------------------------------+\n| Level   | Code | Message                                                                          |\n+---------+------+----------------------------------------------------------------------------------+\n| Warning | 1815 | use_index(test2.t1, a) is inapplicable, check whether the table(test2.t1) exists |\n+---------+------+----------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Data App properties in dataapp_config.json\nDESCRIPTION: This code snippet illustrates the configuration of Data App properties within the `dataapp_config.json` file. It includes fields such as `app_id`, `app_name`, `app_type`, `app_version`, and `description`, which define the characteristics and metadata of the Data App. The `app_id` is crucial for identifying the Data App, while `app_name` and `description` provide human-readable information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-app-config-files.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"app_id\": \"<Data App ID>\",\n  \"app_name\": \"<Data App name>\",\n  \"app_type\": \"dataapi\",\n  \"app_version\": \"<Data App version>\",\n  \"description\": \"<Data App description>\"\n}\n\n```\n\n----------------------------------------\n\nTITLE: Basic UPDATE Statement in SQL\nDESCRIPTION: SQL syntax for updating data in a table using the UPDATE statement with a WHERE clause to filter rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-update-data.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE {table} SET {update_column} = {update_value} WHERE {filter_column} = {filter_value}\n```\n\n----------------------------------------\n\nTITLE: Enabling Default Role with SET ROLE DEFAULT in TiDB SQL\nDESCRIPTION: SQL commands to enable the default role(s) for the current session using SET ROLE DEFAULT, followed by a query to check the current role.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-role.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSET ROLE DEFAULT;\nSELECT CURRENT_ROLE();\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Decimal Division Incompatibility Between TiDB and TiFlash\nDESCRIPTION: SQL example showing how decimal division calculations differ between TiDB and TiFlash. The example demonstrates that TiFlash's decimal division uses the type inferred from compilation, while TiDB uses a more precise runtime type, leading to different query results.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-compatibility.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nmysql> create table t (a decimal(3,0), b decimal(10, 0));\nQuery OK, 0 rows affected (0.07 sec)\nmysql> insert into t values (43, 1044774912);\nQuery OK, 1 row affected (0.03 sec)\nmysql> alter table t set tiflash replica 1;\nQuery OK, 0 rows affected (0.07 sec)\nmysql> set session tidb_isolation_read_engines='tikv';\nQuery OK, 0 rows affected (0.00 sec)\nmysql> select a/b, a/b + 0.0000000000001 from t where a/b;\n+--------+-----------------------+\n| a/b    | a/b + 0.0000000000001 |\n+--------+-----------------------+\n| 0.0000 |       0.0000000410001 |\n+--------+-----------------------+\n1 row in set (0.00 sec)\nmysql> set session tidb_isolation_read_engines='tiflash';\nQuery OK, 0 rows affected (0.00 sec)\nmysql> select a/b, a/b + 0.0000000000001 from t where a/b;\nEmpty set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Disabling garbage collection in TiDB cluster\nDESCRIPTION: SQL command to disable the garbage collection mechanism in TiDB before migration to prevent historical data from being cleaned up, followed by verification of the setting.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_enable = FALSE;\n```\n\n----------------------------------------\n\nTITLE: Restoring Global tidb_gc_life_time Post Changefeed Creation\nDESCRIPTION: This SQL command restores the global garbage collection life time back to its original value after the changefeed has been successfully created. This ensures normal operation and maintains the health of the TiDB instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/changefeed-sink-to-tidb-cloud.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_life_time = '10m';\n```\n\n----------------------------------------\n\nTITLE: Java Helper Class for Stale Read Transactions\nDESCRIPTION: Implements a helper class to manage stale read transactions in Java, including methods to start transactions with historical timestamps.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-stale-read.md#2025-04-18_snippet_7\n\nLANGUAGE: java\nCODE:\n```\npublic static class StaleReadHelper {\n\n    public static void startTxnWithStaleRead(Connection conn, Integer seconds) throws SQLException {\n        conn.setAutoCommit(false);\n        PreparedStatement stmt = conn.prepareStatement(\n            \"START TRANSACTION READ ONLY AS OF TIMESTAMP NOW() - INTERVAL ? SECOND;\"\n        );\n        stmt.setInt(1, seconds);\n        stmt.execute();\n    }\n\n}\n```\n\n----------------------------------------\n\nTITLE: TiDB Cluster Topology Configuration\nDESCRIPTION: YAML configuration defining the complete topology of a TiDB cluster including global settings, server configurations, and node specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\n# # Global variables are applied to all deployments and used as the default value of\n# # the deployments if a specific deployment value is missing.\nglobal:\n user: \"tidb\"\n ssh_port: 22\n deploy_dir: \"/tidb-deploy\"\n data_dir: \"/tidb-data\"\n\n# # Monitored variables are applied to all the machines.\nmonitored:\n node_exporter_port: 9100\n blackbox_exporter_port: 9115\n\nserver_configs:\n tidb:\n   instance.tidb_slow_log_threshold: 300\n tikv:\n   readpool.storage.use-unified-pool: false\n   readpool.coprocessor.use-unified-pool: true\n pd:\n   replication.enable-placement-rules: true\n   replication.location-labels: [\"host\"]\n tiflash:\n   logger.level: \"info\"\n\npd_servers:\n - host: 10.0.1.1\n\ntidb_servers:\n - host: 10.0.1.1\n\ntikv_servers:\n - host: 10.0.1.1\n   port: 20160\n   status_port: 20180\n   config:\n     server.labels: { host: \"logic-host-1\" }\n\n - host: 10.0.1.1\n   port: 20161\n   status_port: 20181\n   config:\n     server.labels: { host: \"logic-host-2\" }\n\n - host: 10.0.1.1\n   port: 20162\n   status_port: 20182\n   config:\n     server.labels: { host: \"logic-host-3\" }\n\ntiflash_servers:\n - host: 10.0.1.1\n\nmonitoring_servers:\n - host: 10.0.1.1\n\ngrafana_servers:\n - host: 10.0.1.1\n```\n\n----------------------------------------\n\nTITLE: Successful Modification Response - SQL\nDESCRIPTION: This statement represents the expected response after a successful configuration modification in TiKV, indicating that the operation was successful with no rows changed.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining Warning Alert Rule for TiKV CDC Min Resolved TS No Change in YAML\nDESCRIPTION: YAML configuration for a warning alert rule that triggers when the minimum Resolved TS of TiKV CDC has not advanced for 1 minute.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-alert-rules.md#2025-04-18_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nchanges(tikv_cdc_min_resolved_ts[1m]) < 1 and ON (instance) tikv_cdc_region_resolve_status{status=\"resolved\"} > 0 and ON (instance) tikv_cdc_captured_region_total > 0\n```\n\n----------------------------------------\n\nTITLE: Node CPU Load Alert Rule\nDESCRIPTION: PromQL query to monitor CPU load average over 5 minutes compared to available CPU cores\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_21\n\nLANGUAGE: promql\nCODE:\n```\n(node_load5 / count without (cpu, mode) (node_cpu_seconds_total{mode=\"system\"})) > 1\n```\n\n----------------------------------------\n\nTITLE: View Log Backup Metadata Example\nDESCRIPTION: Example command to view log backup metadata from S3 storage with access configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log metadata --storage='s3://backup-101/logbackup?access-key=${access-key}&secret-access-key=${secret-access-key}'\n```\n\n----------------------------------------\n\nTITLE: Encoding and Decoding Record Key with TIDB Functions\nDESCRIPTION: Provides functionality to encode a record key and decode it using TiDB-specific functions, which is crucial for assessing database state or key index manipulations.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_31\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id int PRIMARY KEY, a int, KEY `idx` (a));\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES(1,1);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_ENCODE_RECORD_KEY('test', 't', 1);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_DECODE_KEY('7480000000000000845f728000000000000001');\n```\n\n----------------------------------------\n\nTITLE: Status Code 404 Response Example\nDESCRIPTION: This code snippet presents a Data Service response with an HTTP status code of 404, indicating that the specified endpoint could not be found.  The `result.code` mirrors the 404 status, and the `message` field reads \"endpoint not found\". This response suggests that the requested endpoint does not exist or is not accessible.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"sql_endpoint\",\n    \"data\": {\n        \"columns\": [],\n        \"rows\": [],\n        \"result\": {\n            \"code\": 404,\n            \"message\": \"endpoint not found\",\n            \"start_ms\": \"\",\n            \"end_ms\": \"\",\n            \"latency\": \"\",\n            \"row_count\": 0,\n            \"row_affect\": 0,\n            \"limit\": 0\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Testing IPv6 Addresses with IS_IPV6() in SQL\nDESCRIPTION: This function tests whether the given argument is an IPv6 address. It returns 1 if the argument is a valid IPv6 address, otherwise 0.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT IS_IPV6('::1');\n```\n\n----------------------------------------\n\nTITLE: Using NTH_VALUE() Window Function in SQL\nDESCRIPTION: This example demonstrates the NTH_VALUE() function along with FIRST_VALUE() and LAST_VALUE(). It shows how to retrieve specific values from different positions within a window frame.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/window-functions.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nWITH RECURSIVE cte(n) AS (\n    SELECT\n        1\n    UNION\n    SELECT\n        n+1\n    FROM\n        cte\n    WHERE\n        n<10\n)\nSELECT\n    n,\n    FIRST_VALUE(n) OVER w AS 'First',\n    NTH_VALUE(n, 2) OVER w AS 'Second',\n    NTH_VALUE(n, 3) OVER w AS 'Third',\n    LAST_VALUE(n) OVER w AS 'Last'\nFROM\n    cte\nWINDOW\n    w AS (PARTITION BY n<=5)\nORDER BY\n    n;\n```\n\n----------------------------------------\n\nTITLE: Pausing TiCDC Replication Task\nDESCRIPTION: Command to pause an active replication task.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed pause --server=http://10.0.10.25:8300 --changefeed-id simple-replication-task\n```\n\n----------------------------------------\n\nTITLE: Configuring SQL Checksum via TiDB\nDESCRIPTION: Controls whether to execute the ADMIN CHECKSUM TABLE operation via TiDB, providing flexibility in managing checksum operations during data import.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_22\n\nLANGUAGE: markdown\nCODE:\n```\nValue options:\n    - \"false\": the ADMIN CHECKSUM TABLE command is sent to TiKV for execution via TiDB Lightning.\n    - \"true\": if you want to adjust concurrency when this value is \"true\", you need to set the [tidb_checksum_table_concurrency](/system-variables.md#tidb_checksum_table_concurrency) variable in TiDB.\n```\n\n----------------------------------------\n\nTITLE: Analyzing Running SQL with EXPLAIN FOR CONNECTION\nDESCRIPTION: Uses EXPLAIN FOR CONNECTION to analyze the status information of currently executing SQL statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0-rc.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN FOR CONNECTION connection_id;\n```\n\n----------------------------------------\n\nTITLE: Configuring Raftstore Apply Pool Size\nDESCRIPTION: Sets the number of threads allowed in the pool that applies Raft data to storage, optimizing performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_6\n\nLANGUAGE: TOML\nCODE:\n```\n\"raftstore.apply-pool-size = 4\"\n```\n\n----------------------------------------\n\nTITLE: CHECK Constraint Query Result\nDESCRIPTION: Shows the output of querying the CHECK_CONSTRAINTS table after creating a table with a CHECK constraint.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-check-constraints.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n*************************** 1. row ***************************\nCONSTRAINT_CATALOG: def\n CONSTRAINT_SCHEMA: test\n   CONSTRAINT_NAME: t1_chk_1\n      CHECK_CLAUSE: (`id` % 2 = 0)\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Precheck Arguments in YAML for TiDB DM\nDESCRIPTION: This YAML snippet demonstrates how to configure the 'mydumpers' field in a migration task configuration file to specify precheck arguments, including the number of threads and chunk file size.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-precheck.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nmydumpers:                           # Configuration arguments of the dump processing unit\n  global:                            # Configuration name\n    threads: 4                       # The number of threads that access the upstream when the dump processing unit performs the precheck and exports data from the upstream database (4 by default)\n    chunk-filesize: 64               # The size of the files generated by the dump processing unit (64 MB by default)\n    extra-args: \"--consistency none\" # Other arguments of the dump processing unit. You do not need to manually configure table-list in `extra-args`, because it is automatically generated by DM.\n```\n\n----------------------------------------\n\nTITLE: Tombstone a Region with tikv-ctl Shell\nDESCRIPTION: The tikv-ctl tombstone command sets specified Regions in a TiKV instance to tombstone state. This is useful for avoiding startup errors related to damaged Raft states. Dependencies include a data directory and raft-related configurations for the specific regions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir /path/to/tikv tombstone -p 127.0.0.1:2379 -r <region_id>\n```\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir /path/to/tikv tombstone -p 127.0.0.1:2379 -r <region_id>,<region_id> --force\n```\n\nLANGUAGE: shell\nCODE:\n```\nsuccess!\n```\n\n----------------------------------------\n\nTITLE: Checking Index Consistency in TiDB SQL\nDESCRIPTION: This SQL snippet shows how to use the ADMIN CHECK INDEX command to check the consistency of column data and index data for a specific index in a table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-check-table-index.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN CHECK INDEX tbl_name idx_name;\n```\n\n----------------------------------------\n\nTITLE: Retrieving TiDB Version Details using TIDB_VERSION\nDESCRIPTION: The `TIDB_VERSION()` function is used to fetch the version and build details of the TiDB server, which is beneficial for issue reporting and system audits.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_VERSION()\\G\n```\n\n----------------------------------------\n\nTITLE: Reloading PD nodes configuration using TiUP\nDESCRIPTION: This command performs a rolling update (reload) of the PD node configuration in the TiDB cluster. The `-R pd` option specifies that only the PD nodes should be reloaded. This is necessary after modifying the cluster configuration, such as switching the PD working mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster reload <cluster-name> -R pd\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Client TLS with JKS Certificates\nDESCRIPTION: Example configuration for enabling TLS in TiKV Client using Java KeyStore (JKS) certificates. This requires specifying JKS trust and key paths along with their respective passwords.\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_8\n\nLANGUAGE: properties\nCODE:\n```\nspark.tispark.tikv.tls_enable                                  true\nspark.tispark.tikv.jks_enable                                  true\nspark.tispark.tikv.jks_key_path                                /home/tispark/config/tikv-truststore\nspark.tispark.tikv.jks_key_password                            tikv_trustore_password\nspark.tispark.tikv.jks_trust_path                              /home/tispark/config/tikv-clientstore\nspark.tispark.tikv.jks_trust_password                          tikv_clientstore_password\n```\n\n----------------------------------------\n\nTITLE: Viewing Log Status Command Options in Shell\nDESCRIPTION: Displays help information for the log backup status command, showing available parameters for querying the status of backup tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log status --help\nget status for the log backup task\n\nUsage:\n  br log status [flags]\n\nFlags:\n  -h, --help           help for status\n  --json               Print JSON as the output.\n  --task-name string   The task name for backup stream log. If default, get status of all of tasks (default \"*\")\n\nGlobal Flags:\n --ca string                  CA certificate path for TLS connection\n --cert string                Certificate path for TLS connection\n --key string                 Private key path for TLS connection\n -u, --pd strings             PD address (default [127.0.0.1:2379])\n\n```\n\n----------------------------------------\n\nTITLE: Viewing Uncompleted DDL Jobs for Specific Database\nDESCRIPTION: Displays running and failed DDL jobs (last 5) for a specific database, filtering out successfully synced jobs.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW DDL JOBS 5 WHERE state != 'synced' AND db_name = 'test';\n```\n\n----------------------------------------\n\nTITLE: Using S3 Wildcard Pattern for Single Character Matching\nDESCRIPTION: Demonstrates how to use the question mark wildcard in S3 URIs to match any single character in filenames during import.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-parquet-files.md#2025-04-18_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\ns3://[bucket_name]/[data_source_folder]/my-data?.parquet\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying a View in SQL\nDESCRIPTION: This SQL example demonstrates creating tables, inserting data, creating a view, querying the view, and then dropping the view. It showcases the basic workflow of using views in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/views.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\ncreate table t(a int, b int);\n\ninsert into t values(1, 1),(2,2),(3,3);\n\ncreate table s(a int);\n\ninsert into s values(2),(3);\n\ncreate view v as select s.a from t left join s on t.a = s.a;\n\nselect * from v;\n\ndrop view v;\n```\n\n----------------------------------------\n\nTITLE: Example SQL Query for Joining TIDB_INDEXES with Other Tables\nDESCRIPTION: This SQL query demonstrates how to join the TIDB_INDEXES table with the tables table to retrieve specific index information based on TABLE_ID and INDEX_ID obtained from other sources like the SLOW_QUERY table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-indexes.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n tidb_indexes.*\nFROM\n tidb_indexes,\n tables\nWHERE\n  tidb_indexes.table_schema = tables.table_schema\n AND tidb_indexes.table_name = tidb_indexes.table_name\n AND tables.tidb_table_id = ?\n AND index_id = ?\n```\n\n----------------------------------------\n\nTITLE: Granting Downstream Privileges for DM-worker in SQL\nDESCRIPTION: This SQL snippet grants the required privileges to the downstream TiDB user for DM-worker. It includes privileges for data manipulation (SELECT, INSERT, UPDATE, DELETE), schema management (CREATE, DROP, ALTER, INDEX), and access to the DM-worker's metadata database.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-worker-intro.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nGRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP,ALTER,INDEX ON db.table TO 'your_user'@'your_wildcard_of_host';\nGRANT ALL ON dm_meta.* TO 'your_user'@'your_wildcard_of_host';\n```\n\n----------------------------------------\n\nTITLE: Sink URI Example for NFS\nDESCRIPTION: Basic sink URI configuration for NFS storage, specifying the directory, prefix, and protocol for data replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"file:///my-directory/prefix?protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: Installing dbt-tidb for TiDB Cloud Integration\nDESCRIPTION: Command to install dbt-tidb package which includes dbt as a dependency. This is the first step to integrate TiDB Cloud with dbt.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install dbt-tidb\n```\n\n----------------------------------------\n\nTITLE: Setting Slow Query Log File Path in SQL\nDESCRIPTION: SQL statement to set the session variable controlling which slow query log file to parse.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nset tidb_slow_query_file = \"/path-to-log/tidb-slow.log\"\n```\n\n----------------------------------------\n\nTITLE: Identifying SQL Categories with Long Execution Time\nDESCRIPTION: This SQL query retrieves categories of SQL statements with the longest execution time from history, ordered by total latency. Dependencies include access to TiDB's statement history. Inputs include a specific summary begin time. Outputs are total and average latencies, execution counts, and sample queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/statement-summary-tables.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT sum_latency, avg_latency, exec_count, query_sample_text\n    FROM information_schema.statements_summary_history\n    WHERE summary_begin_time='2020-01-02 10:00:00'\n    ORDER BY sum_latency DESC LIMIT 3;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+-------------+-------------+------------+-----------------------------------------------------------------------+\n| sum_latency | avg_latency | exec_count | query_sample_text                                                     |\n+-------------+-------------+------------+-----------------------------------------------------------------------+\n|     7855660 |     1122237 |          7 | select avg(salary) from employee where company_id=2013                |\n|     7241960 |     1448392 |          5 | select * from employee join company on employee.company_id=company.id |\n|     2084081 |     1042040 |          2 | select * from employee where name='eric'                              |\n+-------------+-------------+------------+-----------------------------------------------------------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting PD Key Type Configuration in TiDB\nDESCRIPTION: Command to set the key-type parameter to 'txn' in PD configuration for clusters without TiDB instances to enable cross-table region merging.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/pd-scheduling-best-practices.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nconfig set key-type txn\n```\n\n----------------------------------------\n\nTITLE: Building and Bundling for AWS Lambda Deployment (Bash)\nDESCRIPTION: Commands to build the application bundle for AWS Lambda deployment. This creates a zip file in the dist directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\n\n# Bundle for AWS Lambda\n# =====================\n# dist/index.zip\n```\n\n----------------------------------------\n\nTITLE: Setting Auto Analyze in TiDB SQL\nDESCRIPTION: This SQL snippet disables the automatic analysis feature in TiDB before performing batch operations. It ensures that the data remains stable without unexpected statistics updates that could impact performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\n-- Disable auto analyze\nSET GLOBAL tidb_enable_auto_analyze = OFF;\n```\n\n----------------------------------------\n\nTITLE: Analyzing TiDB Server Logs for LockNotFound Error\nDESCRIPTION: This log snippet shows the typical warning message when a TxnLockNotFound error occurs in TiDB. It contains the transaction information including connection ID, transaction state, start timestamp, and commit timestamp.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-lock-conflicts.md#2025-04-18_snippet_5\n\nLANGUAGE: log\nCODE:\n```\n[WARN] [session.go:446] [\"commit failed\"] [conn=149370] [\"finished txn\"=\"Txn{state=invalid}\"] [error=\"[kv:6]Error: KV error safe to retry tikv restarts txn: Txn(Mvcc(TxnLockNotFound{ start_ts: 412720515987275779, commit_ts: 412720519984971777, key: [116, 128, 0, 0, 0, 0, 1, 111, 16, 95, 114, 128, 0, 0, 0, 0, 0, 0, 2] })) [try again later]\"]\n```\n\n----------------------------------------\n\nTITLE: Failed TRUNCATE Operation on Cached Table\nDESCRIPTION: Demonstrates that TRUNCATE TABLE operation is not supported on cached tables, resulting in an error.\nSOURCE: https://github.com/pingcap/docs/blob/master/cached-tables.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nTRUNCATE TABLE users;\n```\n\nLANGUAGE: sql\nCODE:\n```\nERROR 8242 (HY000): 'Truncate Table' is unsupported on cache tables.\n```\n\n----------------------------------------\n\nTITLE: Sending an HTTP Upgrade Finish Request in TiDB\nDESCRIPTION: This snippet is used to signal the completion of a TiDB smooth upgrade by sending an HTTP POST request. All paused user DDL operations will be resumed on successful execution. Dependencies include a successfully upgraded TiDB cluster to the target version.\nSOURCE: https://github.com/pingcap/docs/blob/master/smooth-upgrade-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://{TiDBIP}:10080/upgrade/finish\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB and TiFlash Components in Terraform\nDESCRIPTION: The code snippet shows the configuration of TiDB, TiKV, and TiFlash components in a 'cluster.tf' file. These configurations help define the node size, quantity, and storage parameters necessary for cluster creation. Ensure you have Terraform installed and the 'cluster.tf' file located in your working directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_6\n\nLANGUAGE: HCL\nCODE:\n```\n    components = {\n      tidb = {\n        node_size : \"8C16G\"\n        node_quantity : 1\n      }\n      tikv = {\n        node_size : \"8C32G\"\n        storage_size_gib : 500\n        node_quantity : 3\n      }\n      tiflash = {\n        node_size : \"8C64G\"\n        storage_size_gib : 500\n        node_quantity : 1\n      }\n    }\n```\n\n----------------------------------------\n\nTITLE: Running Sysbench Scalability Test (Bash)\nDESCRIPTION: This snippet runs a Sysbench test to assess TiProxy's scalability with different vCPU configurations and thread counts. It measures how well increasing resources improves query performance and CPU usage across several configurations. Requires Sysbench and MySQL database access.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-performance-test.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nsysbench oltp_point_select \\\n    --threads=$threads \\\n    --time=1200 \\\n    --report-interval=10 \\\n    --rand-type=uniform \\\n    --db-driver=mysql \\\n    --mysql-db=sbtest \\\n    --mysql-host=$host \\\n    --mysql-port=$port \\\n    run --tables=32 --table-size=1000000\n```\n\n----------------------------------------\n\nTITLE: User Response Time Components Formula\nDESCRIPTION: This snippet defines the components that make up user response time, including service time, queuing delay, and coherency delay, which help understand factors affecting performance in TiDB Cloud.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tune-performance-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nUser Response time = Service time + Queuing delay + Coherency delay\n```\n\n----------------------------------------\n\nTITLE: Configuring Checkpoints in TiDB Lightning\nDESCRIPTION: Defines checkpoint settings for tracking import progress, storing checkpoint metadata, and managing import state recovery\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[checkpoint]\nenable = true\nschema = \"tidb_lightning_checkpoint\"\ndriver = \"file\"\ndsn = \"/tmp/tidb_lightning_checkpoint.pb\"\nkeep-after-success = false\n```\n\n----------------------------------------\n\nTITLE: API Error Message Template (JSON)\nDESCRIPTION: Template for error messages returned by the API when an error occurs.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"error_msg\": \"\",\n    \"error_code\": \"\"\n}\n```\n\n----------------------------------------\n\nTITLE: VARIABLES_INFO Sample Data Output\nDESCRIPTION: Shows example output containing system variable information including scope, default values, and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-variables-info.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+-----------------------------------+----------------+---------------+---------------+-----------+-----------+-----------------+---------+\n| VARIABLE_NAME                     | VARIABLE_SCOPE | DEFAULT_VALUE | CURRENT_VALUE | MIN_VALUE | MAX_VALUE | POSSIBLE_VALUES | IS_NOOP |\n+-----------------------------------+----------------+---------------+---------------+-----------+-----------+-----------------+---------+\n| allow_auto_random_explicit_insert | SESSION,GLOBAL | OFF           | OFF           |      NULL |      NULL | NULL            | NO      |\n| auto_increment_increment          | SESSION,GLOBAL | 1             | 1             |         1 |     65535 | NULL            | NO      |\n| auto_increment_offset             | SESSION,GLOBAL | 1             | 1             |         1 |     65535 | NULL            | NO      |\n+-----------------------------------+----------------+---------------+---------------+-----------+-----------+-----------------+---------+\n```\n\n----------------------------------------\n\nTITLE: Metric Configuration Parameters\nDESCRIPTION: Settings for monitoring metric data collection and Prometheus integration.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-configuration-file.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nmetric:\n  interval: \"15s\" # Interval for pushing metrics to Prometheus\n```\n\n----------------------------------------\n\nTITLE: Viewing DDL Lock Help Command\nDESCRIPTION: Shows help information for the shard-ddl-lock command which is used to maintain and show DDL lock information\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/manually-handling-sharding-ddl-locks.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nshard-ddl-lock -h\n```\n\n----------------------------------------\n\nTITLE: DECODE Function Comparison\nDESCRIPTION: This snippet illustrates the use of DECODE in Oracle and its equivalents using IF and CASE statements in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nDECODE(key,val1,val2,val3)\nDECODE(value,if1,val1,if2,val2,...,ifn,valn,val)\n```\n\nLANGUAGE: sql\nCODE:\n```\nIF(key=val1,val2,val3)\nCASE WHEN value=if1 THEN val1 WHEN value=if2 THEN val2,...,WHEN value=ifn THEN valn ELSE val END\n```\n\n----------------------------------------\n\nTITLE: Configuring Topic Dispatcher for Kafka Sink with Extension\nDESCRIPTION: This TOML configuration snippet defines a topic dispatcher for the Kafka sink when using TiDB extension.  It configures how data is routed to different Kafka topics based on schema and table names, ensuring that each table's data resides in its dedicated topic when using the Avro protocol with extensions enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-protocol.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n[sink]\ndispatchers = [\n {matcher = ['*.*'], topic = \"tidb_{schema}_{table}\"},\n]\n```\n\n----------------------------------------\n\nTITLE: Adding Secondary Index to Existing Table in SQL\nDESCRIPTION: SQL syntax for adding a secondary index to an existing table in TiDB. Requires specifying the index name, table name, and column names to be indexed.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-secondary-indexes.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX {index_name} ON {table_name} ({column_names});\n```\n\n----------------------------------------\n\nTITLE: Configuring Query Feedback Limit in TiDB\nDESCRIPTION: Decreases the default value of the query-feedback-limit configuration item from 1024 to 512 to improve the statistics feedback mechanism and reduce its impact on the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.17.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL query-feedback-limit = 512;\n```\n\n----------------------------------------\n\nTITLE: Adding MyBatis Maven Dependencies\nDESCRIPTION: Maven configuration for adding MyBatis and MySQL connector dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-choose-driver-or-orm.md#2025-04-18_snippet_5\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>org.mybatis</groupId>\n    <artifactId>mybatis</artifactId>\n    <version>3.5.13</version>\n</dependency>\n\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>8.0.33</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Trimming Leading Zero Bytes from Byte Slice in Go\nDESCRIPTION: This utility function removes leading zero bytes from a byte slice. It iterates through the slice until it finds a non-zero byte or reaches the end, then returns the remaining slice.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-checksum-verification.md#2025-04-18_snippet_8\n\nLANGUAGE: Go\nCODE:\n```\nfunc trimLeadingZeroBytes(bytes []byte) []byte {\n    if len(bytes) == 0 {\n        return bytes\n    }\n    pos, posMax := 0, len(bytes)-1\n    for ; pos < posMax; pos++ {\n        if bytes[pos] != 0 {\n            break\n        }\n    }\n    return bytes[pos:]\n}\n```\n\n----------------------------------------\n\nTITLE: Stopping a DM-worker Node (Shell)\nDESCRIPTION: Example of using curl to stop a DM-worker node via the API.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'DELETE' \\\n  'http://127.0.0.1:8261/api/v1/cluster/workers/worker1' \\\n  -H 'accept: */*'\n```\n\n----------------------------------------\n\nTITLE: Executing PD Control command using environment variables\nDESCRIPTION: This snippet illustrates how to use environment variables to specify the PD address. The `PD_ADDR` environment variable is set, and then `tiup ctl` is executed without explicitly specifying the address.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport PD_ADDR=http://127.0.0.1:2379\ntiup ctl:v<CLUSTER_VERSION> pd\n```\n\n----------------------------------------\n\nTITLE: Displaying Help for stop-task Command in DM\nDESCRIPTION: This command shows the help information for the 'stop-task' command in DM, including its usage, flags, and global flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-stop-task.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhelp stop-task\n```\n\nLANGUAGE: plaintext\nCODE:\n```\nstop a specified task\n\nUsage:\n dmctl stop-task [-s source ...] <task-name | task-file> [flags]\n\nFlags:\n -h, --help   help for stop-task\n\nGlobal Flags:\n -s, --source strings   MySQL Source ID\n```\n\n----------------------------------------\n\nTITLE: Querying Region Replica Distribution in TiKV\nDESCRIPTION: This command retrieves the distribution of Region replicas by querying their IDs and peer store IDs, formatted for legibility.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_65\n\nLANGUAGE: bash\nCODE:\n```\nregion --jq=\".regions[] | {id: .id, peer_stores: [.peers[].store_id]}\"\n```\n\n----------------------------------------\n\nTITLE: Viewing DM Cluster List\nDESCRIPTION: Command to view list of deployed DM clusters\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm list\n```\n\n----------------------------------------\n\nTITLE: Getting Session User (SQL)\nDESCRIPTION: The `SESSION_USER()` function is a synonym for `USER()`, and returns the user context for the current session, useful for auditing and security contexts.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/information-functions.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SESSION_USER();\n```\n\n----------------------------------------\n\nTITLE: Alias Command for Starting a Data Import Task\nDESCRIPTION: An alternative command that can be used to start a data import task in TiDB Cloud CLI. This alias provides the same functionality as the primary command.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-start.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import create [flags]\n```\n\n----------------------------------------\n\nTITLE: Viewing Node Information in TiDB Cluster\nDESCRIPTION: This command displays the node information of a TiDB cluster, including roles, hosts, ports, and status of each component.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster display <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Changing TiCDC default value for transaction-atomicity\nDESCRIPTION: This snippet reflects the change in the default value of `transaction-atomicity` in TiCDC from `table` to `none`. This adjustment aims to decrease replication latency, reduce OOM risks by limiting transaction splitting to larger transactions (over 1024 rows), rather than all transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.3.md#2025-04-18_snippet_0\n\n\n\n----------------------------------------\n\nTITLE: Complete ALTER PLACEMENT POLICY Usage Example\nDESCRIPTION: Comprehensive example showing creation of a placement policy, table assignment, policy modification, and verification of the changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-placement-policy.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY p1 PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\";\nCREATE TABLE t1 (i INT) PLACEMENT POLICY=p1; -- Assign policy p1 to table t1\nALTER PLACEMENT POLICY p1 PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1,us-west-2\" FOLLOWERS=4; -- The rules of t1 will be updated automatically.\nSHOW CREATE PLACEMENT POLICY p1\\G\n```\n\n----------------------------------------\n\nTITLE: Configuring Rule Group Override Settings in TiDB\nDESCRIPTION: JSON configuration for rule group settings that enables forced override of existing placement rules. Sets a high index value of 1024 and enables override flag to ensure the new rules take precedence.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-placement-rules.md#2025-04-18_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": \"ssd-override\",\n  \"index\": 1024,\n  \"override\": true,\n}\n```\n\n----------------------------------------\n\nTITLE: Example SQL Query Result Showing MVCC Amplification\nDESCRIPTION: Sample output from the MVCC amplification detection SQL query, demonstrating a case where the TiKV processes over 1.3 million MVCC versions but only returns 2 actual records.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-in-memory-engine.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------+-----+-------------------+--------------+------------+-----------------------------------+--------------------+--------------------+--------------------+\n| Time                       | DB  | Index_names       | Process_keys | Total_keys | Query                             | Query_time         | Cop_time           | Process_time       |\n+----------------------------+-----+-------------------+--------------+------------+-----------------------------------+--------------------+--------------------+--------------------+\n| 2024-11-18 11:56:10.303228 | db1 | [tbl1:some_index] |            2 |    1358517 |  SELECT * FROM tbl1 ... LIMIT 1 ; | 1.2581352350000001 |         1.25651062 |        1.251837479 |\n| 2024-11-18 11:56:11.556257 | db1 | [tbl1:some_index] |            2 |    1358231 |  SELECT * FROM tbl1 ... LIMIT 1 ; |        1.252694002 |        1.251129038 |        1.240532546 |\n| 2024-11-18 12:00:10.553331 | db1 | [tbl1:some_index] |            2 |    1342914 |  SELECT * FROM tbl1 ... LIMIT 1 ; |        1.473941872 | 1.4720495900000001 | 1.3666103170000001 |\n| 2024-11-18 12:01:52.122548 | db1 | [tbl1:some_index] |            2 |    1128064 |  SELECT * FROM tbl1 ... LIMIT 1 ; |        1.058942591 |        1.056853228 |        1.023483875 |\n| 2024-11-18 12:01:52.107951 | db1 | [tbl1:some_index] |            2 |    1128064 |  SELECT * FROM tbl1 ... LIMIT 1 ; |        1.044847031 |        1.042546122 |        0.934768555 |\n+----------------------------+-----+-------------------+--------------+------------+-----------------------------------+--------------------+--------------------+--------------------+\n5 rows in set (1.26 sec)\n```\n\n----------------------------------------\n\nTITLE: Hash Join Query Execution Plan\nDESCRIPTION: Details a hash join execution plan with build and probe phases. Includes performance metrics for hash table construction and probing operations between tables t1 and t2.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------+----------+---------+-----------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+---------+---------+\n| id                           | estRows  | actRows | task      | access object | execution info                                                                                                                                                                                                                                                                                                             | operator info                                     | memory  | disk    |\n+------------------------------+----------+---------+-----------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+---------+---------+\n| HashJoin_32                  | 90000.00 | 0       | root      |               | time:320.2ms, loops:1, build_hash_table:{total:19.3ms, fetch:16.8ms, build:2.52ms}, probe:{concurrency:5, total:1.6s, max:320.1ms, probe:16.1ms, fetch:1.58s}                                                                                                                                                              | inner join, equal:[eq(test.t1.id, test.t2.t1_id)] | 32.0 MB | 0 Bytes |\n| ├─TableReader_35(Build)      | 9955.54  | 10000   | root      |               | time:18.6ms, loops:12, cop_task: {num: 11, max: 713.8µs, min: 197.3µs, avg: 368.5µs, p95: 713.8µs, rpc_num: 11, rpc_time: 3.83ms, copr_cache_hit_ratio: 1.00, distsql_concurrency: 15}                                                                                                                                     | data:Selection_34                                 | 14.9 MB | N/A     |\n| │ └─Selection_34             | 9955.54  | 10000   | cop[tikv] |               | tikv_task:{proc max:104ms, min:3ms, avg: 24.4ms, p80:33ms, p95:104ms, iters:113, tasks:11}, scan_detail: {get_snapshot_time: 178.9µs, rocksdb: {block: {}}}                                                                                                                                                                | eq(test.t1.int_col, 1)                            | N/A     | N/A     |\n```\n\n----------------------------------------\n\nTITLE: Creating Sample Table with Multiple Regions in TiDB\nDESCRIPTION: SQL commands to create a table with columns for testing and insert enough data to fill multiple Regions. The example uses random data generation and multiple INSERT statements to populate the table with sufficient volume.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-regions.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n id INT NOT NULL PRIMARY KEY auto_increment,\n b INT NOT NULL,\n pad1 VARBINARY(1024),\n pad2 VARBINARY(1024),\n pad3 VARBINARY(1024)\n);\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM dual;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nINSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(1024), RANDOM_BYTES(1024), RANDOM_BYTES(1024) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 10000;\nSELECT SLEEP(5);\nSHOW TABLE t1 REGIONS;\n```\n\n----------------------------------------\n\nTITLE: Querying Data from Flink Table - SQL\nDESCRIPTION: Executes a SQL query to retrieve all records from the specified Flink table, allowing observation of replicated data.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-data-to-kafka.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM tpcc_orders;\n```\n\n----------------------------------------\n\nTITLE: Configuring Placement Rules for TiDB Two-AZ Deployment\nDESCRIPTION: JSON configuration for placement rules that determine replica distribution across availability zones, including voter, follower, and learner roles.\nSOURCE: https://github.com/pingcap/docs/blob/master/two-data-centers-in-one-city-deployment.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"group_id\": \"pd\",\n    \"group_index\": 0,\n    \"group_override\": false,\n    \"rules\": [\n      {\n        \"group_id\": \"pd\",\n        \"id\": \"az-east\",\n        \"start_key\": \"\",\n        \"end_key\": \"\",\n        \"role\": \"voter\",\n        \"count\": 3,\n        \"label_constraints\": [\n          {\n            \"key\": \"az\",\n            \"op\": \"in\",\n            \"values\": [\n              \"east\"\n            ]\n          }\n        ],\n        \"location_labels\": [\n          \"az\",\n          \"rack\",\n          \"host\"\n        ]\n      },\n      {\n        \"group_id\": \"pd\",\n        \"id\": \"az-west-1\",\n        \"start_key\": \"\",\n        \"end_key\": \"\",\n        \"role\": \"follower\",\n        \"count\": 2,\n        \"label_constraints\": [\n          {\n            \"key\": \"az\",\n            \"op\": \"in\",\n            \"values\": [\n              \"west\"\n            ]\n          }\n        ],\n        \"location_labels\": [\n          \"az\",\n          \"rack\",\n          \"host\"\n        ]\n      },\n      {\n        \"group_id\": \"pd\",\n        \"id\": \"az-west-2\",\n        \"start_key\": \"\",\n        \"end_key\": \"\",\n        \"role\": \"learner\",\n        \"count\": 1,\n        \"label_constraints\": [\n          {\n            \"key\": \"az\",\n            \"op\": \"in\",\n            \"values\": [\n              \"west\"\n            ]\n          }\n        ],\n        \"location_labels\": [\n          \"az\",\n          \"rack\",\n          \"host\"\n        ]\n      }\n    ]\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Exporting DM Cluster Configuration\nDESCRIPTION: This snippet demonstrates how to use the 'config export' command to export data source and task configurations to a specified directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-export-import-config.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nconfig export -d /tmp/configs\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for the Sample Application\nDESCRIPTION: Command to install the required packages, including Prisma, for the sample application.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Setting a Local File System Mirror\nDESCRIPTION: This command configures TiUP to use a mirror located in a local file system path, which is useful for shared mirrors in an isolated network.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup mirror set /shared_data/tiup\n```\n\n----------------------------------------\n\nTITLE: Sample JSON Message Format for Large Messages in External Storage\nDESCRIPTION: This JSON snippet demonstrates the message format when large messages are stored in external storage. It includes a TiDB extension field with the location of the large message in the external storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_19\n\nLANGUAGE: JSON\nCODE:\n```\n{\n    \"id\": 0,\n    \"database\": \"test\",\n    \"table\": \"tp_int\",\n    \"pkNames\": [\n        \"id\"\n    ],\n    \"isDdl\": false,\n    \"type\": \"INSERT\",\n    \"es\": 1639633141221,\n    \"ts\": 1639633142960,\n    \"sql\": \"\",\n    \"sqlType\": {\n        \"id\": 4\n    },\n    \"mysqlType\": {\n        \"id\": \"int\"\n    },\n    \"data\": [\n        {\n          \"id\": \"2\"\n        }\n    ],\n    \"old\": null,\n    \"_tidb\": {     // TiDB extension fields\n        \"commitTs\": 429918007904436226,  // A TiDB TSO timestamp\n        \"claimCheckLocation\": \"s3:/claim-check-bucket/${uuid}.json\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing FLASHBACK CLUSTER TO TSO in TiDB\nDESCRIPTION: Introduces support for the FLASHBACK CLUSTER TO TSO syntax in TiDB, allowing users to revert the entire cluster to a specific point in time.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.5.6.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nFLASHBACK CLUSTER TO TSO\n```\n\n----------------------------------------\n\nTITLE: Starting Grafana Service\nDESCRIPTION: Command to start the Grafana service with the specified configuration file\nSOURCE: https://github.com/pingcap/docs/blob/master/deploy-monitoring-services.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n./bin/grafana-server \\\n    --config=\"./conf/grafana.ini\" &\n```\n\n----------------------------------------\n\nTITLE: Enabling Table Distribution Across TiCDC Nodes\nDESCRIPTION: Configuration to enable the distribution of data changes from a single large table to multiple TiCDC nodes when using Kafka as downstream. This feature improves scalability for large tables in data integration scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.0.0.md#2025-04-18_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nenable_table_across_nodes: true\nregion_threshold: <number_of_regions>\n```\n\n----------------------------------------\n\nTITLE: Splitting a Non-clustered Primary Index in SQL\nDESCRIPTION: In this SQL example for splitting a non-clustered primary index, backticks are used around the 'PRIMARY' keyword to avoid syntax errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT TABLE t INDEX `PRIMARY` BETWEEN (-9223372036854775808) AND (9223372036854775807) REGIONS 16;\n```\n\n----------------------------------------\n\nTITLE: Listing TiCDC Changefeed Tasks\nDESCRIPTION: This command lists all TiCDC changefeed tasks for the specified TiDB cluster, allowing verification of the replication task status.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc cli changefeed list --pd=http://172.16.6.122:2379\n```\n\n----------------------------------------\n\nTITLE: Enabling TiUP Telemetry\nDESCRIPTION: Command to enable telemetry data collection in TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/telemetry.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup telemetry enable\n```\n\n----------------------------------------\n\nTITLE: Creating MySQL Sale Table Schema\nDESCRIPTION: SQL schema definition for the sale_01 table with auto-increment primary key and unique index\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE sale_01 (\nid bigint(20) NOT NULL auto_increment,\nuid varchar(40) NOT NULL,\nsale_num bigint DEFAULT NULL,\nPRIMARY KEY (id),\nUNIQUE KEY ind_uid (uid)\n);\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Cloud Serverless Driver with npm\nDESCRIPTION: Command to install the TiDB Cloud Serverless Driver package using npm package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @tidbcloud/serverless\n```\n\n----------------------------------------\n\nTITLE: Installing HashiCorp tap with Homebrew for Terraform\nDESCRIPTION: Command to install the HashiCorp tap, which is a repository containing all required Homebrew packages needed before installing Terraform.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-get-tidbcloud-provider.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbrew tap hashicorp/tap\n```\n\n----------------------------------------\n\nTITLE: Formatting Terraform Configuration\nDESCRIPTION: This command applies Terraform's built-in formatting to ensure the configuration file adheres to style guidelines, enhancing readability and consistency across the configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform fmt\n```\n\n----------------------------------------\n\nTITLE: Setting Execution Priority in SQL Statements\nDESCRIPTION: This SQL snippet demonstrates how to adjust execution priority for select, insert, delete, update, and replace operations in TiDB. The HIGH_PRIORITY, LOW_PRIORITY, and DELAYED options adjust the execution timing of SQL operations, influencing TiDB's performance behavior. The snippet requires SQL DML statements and is constrained by the TiDB version and configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/sql-faq.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT HIGH_PRIORITY | LOW_PRIORITY | DELAYED COUNT(*) FROM table_name;\nINSERT HIGH_PRIORITY | LOW_PRIORITY | DELAYED INTO table_name insert_values;\nDELETE HIGH_PRIORITY | LOW_PRIORITY | DELAYED FROM table_name;\nUPDATE HIGH_PRIORITY | LOW_PRIORITY | DELAYED table_reference SET assignment_list WHERE where_condition;\nREPLACE HIGH_PRIORITY | LOW_PRIORITY | DELAYED INTO table_name;\n```\n\n----------------------------------------\n\nTITLE: Operator Control Commands\nDESCRIPTION: Commands for viewing and controlling scheduling operations including adding peers, removing peers, transferring leaders, and managing regions.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\n>> operator show\n>> operator show admin\n>> operator show leader\n>> operator show region\n>> operator add add-peer 1 2\n>> operator add add-learner 1 2\n>> operator add remove-peer 1 2\n>> operator add transfer-leader 1 2\n>> operator add transfer-region 1 2 3 4\n>> operator add transfer-peer 1 2 3\n>> operator add merge-region 1 2\n>> operator add split-region 1 --policy=approximate\n>> operator add split-region 1 --policy=scan\n>> operator remove 1\n>> operator check 1\n```\n\n----------------------------------------\n\nTITLE: Updating Checkpoint in DM Meta Database (SQL)\nDESCRIPTION: SQL command to update the binlog name and position in the DM meta database checkpoint table when manually recovering from a binlog file size error.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-error-handling.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE dm_test_syncer_checkpoint SET binlog_name='mysql-bin|000001.004451', binlog_pos = 4 WHERE id='replica-1';\n```\n\n----------------------------------------\n\nTITLE: Example Metadata JSON Format for TiDB Vector Store\nDESCRIPTION: This JSON example shows the valid format for metadata in TiDB vector store. Keys are always strings, while values can be strings, numbers (integers or floating point), or booleans.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_13\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"page\": 12,\n  \"book_title\": \"Siddhartha\"\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Temporary Table in SQL\nDESCRIPTION: SQL query to select all data from a temporary table.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM top_50_eldest_authors;\n```\n\n----------------------------------------\n\nTITLE: Creating AWS Route Table Rules for VPC Peering\nDESCRIPTION: Script to create route table entries for all route tables in your VPC, enabling traffic to flow to the TiDB Cloud VPC CIDR block through the peering connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-vpc-peering-connections.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# Creates route table rules.\naws ec2 describe-route-tables --region \"$app_region\" --filters Name=vpc-id,Values=\"$app_vpc_id\" --query 'RouteTables[*].RouteTableId' --output text | tr \"\\t\" \"\\n\" | while read row\ndo\n    app_route_table_id=\"$row\"\n    aws ec2 create-route --region \"$app_region\" --route-table-id \"$app_route_table_id\" --destination-cidr-block \"$tidbcloud_project_cidr\" --vpc-peering-connection-id \"$pcx_tidb_to_app_id\"\ndone\n```\n\n----------------------------------------\n\nTITLE: DROP SEQUENCE Multiple Sequences Example\nDESCRIPTION: Example demonstrating how to drop multiple sequences ('seq' and 'seq2') in a single statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-sequence.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP SEQUENCE seq, seq2;\n```\n\n----------------------------------------\n\nTITLE: Encrypted PITR Restore Command\nDESCRIPTION: Shows how to restore encrypted log backup data using AES-128-CTR encryption method with specified encryption keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore point --pd=\"${PD_IP}:2379\" \n--storage='s3://backup-101/logbackup?access-key=${ACCESS-KEY}&secret-access-key=${SECRET-ACCESS-KEY}' \n--full-backup-storage='s3://backup-101/snapshot-202205120000?access-key=${ACCESS-KEY}&secret-access-key=${SECRET-ACCESS-KEY}' \n--crypter.method aes128-ctr \n--crypter.key 0123456789abcdef0123456789abcdef \n--log.crypter.method aes128-ctr \n--log.crypter.key 0123456789abcdef0123456789abcdef\n```\n\n----------------------------------------\n\nTITLE: Checking Master Status for GTID\nDESCRIPTION: SQL command to check the current GTID status of the MySQL master database.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-incremental-data-from-mysql-using-data-migration.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW MASTER STATUS;\n```\n\n----------------------------------------\n\nTITLE: Using CDC CLI with TiDB Operator Deployed Cluster\nDESCRIPTION: Shell command to list changefeeds in a TiCDC cluster deployed by TiDB Operator, specifying the custom port 8301 instead of the default 8300.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\n./cdc cli changefeed list --server \"127.0.0.1:8301\"\n[\n  {\n    \"id\": \"4k-table\",\n    \"namespace\": \"default\",\n    \"summary\": {\n      \"state\": \"stopped\",\n      \"tso\": 441832628003799353,\n      \"checkpoint\": \"2023-05-30 22:41:57.910\",\n      \"error\": null\n    }\n  },\n  {\n    \"id\": \"big-table\",\n    \"namespace\": \"default\",\n    \"summary\": {\n      \"state\": \"normal\",\n      \"tso\": 441872834546892882,\n      \"checkpoint\": \"2023-06-01 17:18:13.700\",\n      \"error\": null\n    }\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring Incremental Replication with DM\nDESCRIPTION: This YAML snippet outlines the creation of a new data source configuration for TiDB DM. It includes setting up a unique source ID, determining GTID enabling, and providing host and access credentials for the MySQL database. This configuration is essential for proper data replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n# Configuration.\nsource-id: \"mysql-01\" # Must be unique.\n\n# Specifies whether DM-worker pulls binlogs with GTID (Global Transaction Identifier).\n# The prerequisite is that you have already enabled GTID in the upstream MySQL.\n# If you have configured the upstream database service to switch master between different nodes automatically, you must enable GTID.\nenable-gtid: true\n\nfrom:\n  host: \"${host}\"           # For example: 172.16.10.81\n  user: \"root\"\n  password: \"${password}\"   # Plaintext passwords are supported but not recommended. It is recommended that you use dmctl encrypt to encrypt plaintext passwords.\n  port: ${port}             # For example: 3306\n```\n\n----------------------------------------\n\nTITLE: Date Arithmetic with Invalid Date in SQL\nDESCRIPTION: Shows a date arithmetic operation with an invalid date. This query demonstrates how TiDB handles and reports errors for invalid date values in date functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.2.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT ADDDATE('2008-01-34', -1)\n```\n\n----------------------------------------\n\nTITLE: Ignore Unsupported Columns in sync-diff-inspector in TOML\nDESCRIPTION: Lists column types ignored during data comparison to prevent errors due to unsupported data types by sync-diff-inspector. This step helps bypass known discrepancies between TiDB and MySQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/sync-diff-inspector-overview.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\n\"ignore-columns = [\\\"\\\",\\\"\\\"]\"\n```\n\n----------------------------------------\n\nTITLE: Composite Multi-valued Index Creation\nDESCRIPTION: Example showing how to create and query composite multi-valued indexes with multiple columns and JSON paths.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t2 (a INT, j JSON, b INT, k JSON, INDEX idx(a, (CAST(j->'$.path' AS SIGNED ARRAY)), b), INDEX idx2(b, (CAST(k->'$.path' AS SIGNED ARRAY))));\nEXPLAIN SELECT /*+ use_index_merge(t2, idx) */ * FROM t2 WHERE a=1 AND (1 MEMBER OF (j->'$.path')) AND b=2;\nEXPLAIN SELECT /*+ use_index_merge(t2, idx) */ * FROM t2 WHERE a=1 AND JSON_CONTAINS((j->'$.path'), '[1, 2, 3]');\nEXPLAIN SELECT /*+ use_index_merge(t2, idx) */ * FROM t2 WHERE a=1 AND JSON_OVERLAPS((j->'$.path'), '[1, 2, 3]');\nEXPLAIN SELECT /*+ use_index_merge(t2, idx, idx2) */ * FROM t2 WHERE (a=1 AND 1 member of (j->'$.path')) AND (b=1 AND 2 member of (k->'$.path'));\n```\n\n----------------------------------------\n\nTITLE: Querying Global and Session SQL Mode in TiDB\nDESCRIPTION: SQL commands to show the current global and session SQL mode settings in TiDB, demonstrating how to retrieve system variable values.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-variable.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GLOBAL VARIABLES LIKE 'sql_mode';\nSHOW SESSION VARIABLES LIKE 'sql_mode';\n```\n\n----------------------------------------\n\nTITLE: TypeScript Configuration Setup\nDESCRIPTION: TypeScript compiler options configuration for the project.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-drizzle-example.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"compilerOptions\": {\n    \"module\": \"ES2022\",\n    \"target\": \"ES2022\",\n    \"moduleResolution\": \"node\",\n    \"strict\": false,\n    \"declaration\": true,\n    \"outDir\": \"dist\",\n    \"removeComments\": true,\n    \"allowJs\": true,\n    \"esModuleInterop\": true,\n    \"resolveJsonModule\": true\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: SQL Authentication Plugin Configuration\nDESCRIPTION: Configuration for enabling SM3 algorithm-based authentication plugin in TiDB for password encryption and validation.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.3.0.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ntidb_sm3_password\n```\n\n----------------------------------------\n\nTITLE: Restoring Execution Plan Bindings\nDESCRIPTION: Commands to restore and verify execution plan bindings from the mysql schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full \\\n    --pd \"${PD_IP}:2379\" \\\n    --filter 'mysql.bind_info' \\\n    --with-sys-table \\\n    --ratelimit 128 \\\n    --storage \"s3://${backup_collection_addr}/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --log-file restore_system_table.log\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GLOBAL BINDINGS;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT count(*) FROM mysql.bind_info WHERE original_sql = 'builtin_pseudo_sql_for_bind_lock';\nDELETE FROM bind_info WHERE original_sql = 'builtin_pseudo_sql_for_bind_lock' LIMIT 1;\n\nADMIN RELOAD BINDINGS;\n```\n\n----------------------------------------\n\nTITLE: Inserting Data and Displaying NEXT_ROW_ID in SQL\nDESCRIPTION: The snippet illustrates how to insert data into an existing table and then use the SHOW TABLE NEXT_ROW_ID command to display the updated next row ID, showing that the ID count increases based on the inserted records.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-next-rowid.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES (), (), ();\nQuery OK, 3 rows affected (0.02 sec)\nRecords: 3  Duplicates: 0  Warnings: 0\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLE t NEXT_ROW_ID;\n+---------+------------+-------------+--------------------+\n| DB_NAME | TABLE_NAME | COLUMN_NAME | NEXT_GLOBAL_ROW_ID |\n+---------+------------+-------------+--------------------+\n| test    | t          | _tidb_rowid |              30001 |\n+---------+------------+-------------+--------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Automatic Purge Parameters - YAML\nDESCRIPTION: This snippet defines the parameters for automatic relay log purging, including how often to purge, the expiration time for logs, and the amount of remaining disk space that triggers a purge.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/relay-log.md#2025-04-18_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\npurge:\n    interval: 3600\n    expires: 24\n    remain-space: 15\n```\n\n----------------------------------------\n\nTITLE: Configuring TiCDC Changefeed for Data Integrity Validation (TOML)\nDESCRIPTION: TOML configuration to enable data integrity validation in the TiCDC changefeed configuration file. It sets the integrity check level and corruption handle level.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-integrity-check.md#2025-04-18_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[integrity]\nintegrity-check-level = \"correctness\"\ncorruption-handle-level = \"warn\"\n```\n\n----------------------------------------\n\nTITLE: Metric Configuration Properties\nDESCRIPTION: Monitoring metric configuration for Prometheus integration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tso-configuration-file.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nmetric:\n  interval: \"15s\"\n```\n\n----------------------------------------\n\nTITLE: Data Type Definition Pattern in TiDB\nDESCRIPTION: Demonstrates the standard pattern for defining data types in TiDB using T(M[, D]) format, where T is the data type, M is the maximum display width or precision, and D represents decimal places for floating-point numbers.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nT(M[, D])\n```\n\n----------------------------------------\n\nTITLE: TIDB_CHECK_CONSTRAINTS Query Result Example\nDESCRIPTION: Shows an example output of querying the TIDB_CHECK_CONSTRAINTS table after creating a table with a CHECK constraint.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-check-constraints.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n*************************** 1. row ***************************\nCONSTRAINT_CATALOG: def\n CONSTRAINT_SCHEMA: test\n   CONSTRAINT_NAME: t1_chk_1\n      CHECK_CLAUSE: (`id` % 2 = 0)\n        TABLE_NAME: t1\n          TABLE_ID: 107\n```\n\n----------------------------------------\n\nTITLE: Setting Timezone in TiDB Cloud\nDESCRIPTION: This SQL command sets the global timezone for the TiDB Cloud cluster to +08:00 (UTC+8).\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL time_zone = '+08:00';\n```\n\n----------------------------------------\n\nTITLE: Display Cluster Information\nDESCRIPTION: Command to view information about the running TiDB cluster instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground display\n```\n\n----------------------------------------\n\nTITLE: Prometheus Metrics Schema for TiDB Cloud\nDESCRIPTION: Metric definitions for monitoring TiDB cluster performance, including query statistics, connections, latency, storage, CPU, and memory metrics. Each metric includes specific labels for cluster identification and component tracking.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/monitor-prometheus-and-grafana-integration.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntidbcloud_db_queries_total:\n  type: count\n  labels:\n    sql_type: \"Select|Insert|...\"\n    cluster_name: \"<cluster name>\"\n    instance: \"tidb-0|tidb-1…\"\n    component: \"tidb\"\n  description: \"The total number of statements executed\"\n\ntidbcloud_node_storage_used_bytes:\n  type: gauge\n  labels:\n    cluster_name: \"<cluster name>\"\n    instance: \"tikv-0|tikv-1…|tiflash-0|tiflash-1…\"\n    component: \"tikv|tiflash\"\n  description: \"The disk usage bytes of TiKV/TiFlash nodes\"\n```\n\n----------------------------------------\n\nTITLE: Log Stack Information Configuration\nDESCRIPTION: Reference to a feature that reduces redundant stack information in logs using a configuration option.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.1.0-ga.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n- Reduce the redundant stack information of log using the `disable-error-stack` configuration item [#16182](https://github.com/pingcap/tidb/pull/16182)\n```\n\n----------------------------------------\n\nTITLE: Set Engine Isolation in TiDB\nDESCRIPTION: This SQL statement sets the `tidb_isolation_read_engines` variable to specify the engine(s) used for reading data. Available options include \"tikv\", \"tidb\", and \"tiflash\". Multiple engines can be specified by separating them with commas.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-htap-cluster.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nset @@session.tidb_isolation_read_engines = \"engine list separated by commas\";\n```\n\n----------------------------------------\n\nTITLE: Using READ_FROM_STORAGE Hint in TiDB SQL\nDESCRIPTION: Example of using the READ_FROM_STORAGE hint to specify which storage engine (TIFLASH or TIKV) to read data from for each table in a join operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_35\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ READ_FROM_STORAGE(TIFLASH[t1], TIKV[t2]) */ t1.a from t t1, t t2 where t1.a = t2.a;\n```\n\n----------------------------------------\n\nTITLE: Identifying Sequences in MariaDB\nDESCRIPTION: SQL query to find sequences in MariaDB, which may require special attention during migration as they are not supported by DM.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-mariadb.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n  TABLE_SCHEMA,\n  TABLE_NAME\nFROM\n  information_schema.tables\nWHERE\n  TABLE_TYPE='SEQUENCE';\n```\n\n----------------------------------------\n\nTITLE: Setting TiProxy Server Versions with YAML\nDESCRIPTION: This YAML snippet defines the version of TiProxy and the details of TiProxy servers within the TiDB deployment topology. This ensures consistent versioning and connectivity details for TiProxy instances. The configuration specifies host and port details, requiring network accessibility to specified servers.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ncomponent_versions:\n  tiproxy: \"v1.2.0\"\ntiproxy_servers:\n  - host: 10.0.1.11\n    port: 6000\n    status_port: 3080\n  - host: 10.0.1.12\n    port: 6000\n    status_port: 3080\n```\n\n----------------------------------------\n\nTITLE: Basic URI Format for External Storage Services in Shell\nDESCRIPTION: Shows the basic format of URIs used to connect to external storage services. The format includes scheme, host, path, and parameter components.\nSOURCE: https://github.com/pingcap/docs/blob/master/external-storage-uri.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n[scheme]://[host]/[path]?[parameters]\n```\n\n----------------------------------------\n\nTITLE: Checking the TiDB Cloud CLI version\nDESCRIPTION: This snippet demonstrates the command to check the current version of the TiDB Cloud CLI tool.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nticloud version\n```\n\n----------------------------------------\n\nTITLE: Querying Authentication Methods in MariaDB\nDESCRIPTION: SQL query to check the authentication methods used in MariaDB user accounts. This helps identify any incompatible authentication methods before migration to TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-mariadb.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n  plugin,\n  COUNT(*)\nFROM\n  mysql.user\nGROUP BY\n  plugin;\n```\n\n----------------------------------------\n\nTITLE: Auto-Increment Insert Sequence with AUTO_ID_CACHE 1\nDESCRIPTION: Example showing sequential ID generation with AUTO_ID_CACHE 1, demonstrating minimal gaps even after failover.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES (); -- Returns ID 1\nINSERT INTO t VALUES (); -- Returns ID 2\nINSERT INTO t VALUES (); -- Returns ID 3\n-- After failover\nINSERT INTO t VALUES (); -- Might return ID 5\n```\n\n----------------------------------------\n\nTITLE: Creating New Table with pt-osc\nDESCRIPTION: SQL statement used by pt-osc to create a new '_new' table that will eventually replace the original table after DDL changes are applied. DM doesn't actually create this table but instead manages metadata about it.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `test`.`_test4_new` ( id int NOT NULL AUTO_INCREMENT,\ndate date DEFAULT NULL, account_id bigint DEFAULT NULL, conversion_price decimal(20,3) DEFAULT NULL, ocpc_matched_conversions bigint DEFAULT NULL, ad_cost decimal(20,3) DEFAULT NULL,cl2 varchar(20) COLLATE utf8mb4_bin NOT NULL,cl1 varchar(20) COLLATE utf8mb4_bin NOT NULL,PRIMARY KEY (id) ) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin ;\n```\n\n----------------------------------------\n\nTITLE: Formatting Table in Markdown - Cluster Information\nDESCRIPTION: Markdown table showing TiDB cluster information data types, exported files and collection parameters\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-data-instruction-for-tiup.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Data type | Exported file | Parameter for data collection by PingCAP Clinic |\n| :------ | :------ |:-------- |\n| Basic information of the cluster, including the cluster ID | `cluster.json` | The data is collected per run by default. |\n| Detailed information of the cluster | `meta.yaml` | The data is collected per run by default. |\n```\n\n----------------------------------------\n\nTITLE: Configuring Firewall Rules for PD Server\nDESCRIPTION: Commands to set up firewall rules for the PD component, opening ports 2379/tcp and 2380/tcp.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nfirewall-cmd --permanent --new-service pd\nfirewall-cmd --permanent --service pd --set-description=\"PD Server\"\nfirewall-cmd --permanent --service pd --set-short=\"PD\"\nfirewall-cmd --permanent --service pd --add-port=2379/tcp\nfirewall-cmd --permanent --service pd --add-port=2380/tcp\nfirewall-cmd --permanent --zone=public --add-service=pd\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with Log Redaction in Marker Mode\nDESCRIPTION: This SQL snippet demonstrates inserting data into a table with a unique key constraint when log redaction is in marker mode. The error message in the log will have sensitive data enclosed in '‹›' markers.\nSOURCE: https://github.com/pingcap/docs/blob/master/log-redaction.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (a int, unique key (a));\ninsert into t values (1),(1);\n```\n\n----------------------------------------\n\nTITLE: Configuring DM-master Settings in TOML\nDESCRIPTION: Complete configuration template for DM-master showing all available settings including logging, networking, cluster configuration, and SSL settings. This template can be used as a base for creating new DM-master configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-master-configuration-file.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nname = \"dm-master\"\n\n# log configuration\nlog-level = \"info\"\nlog-file = \"dm-master.log\"\n\n# DM-master listening address\nmaster-addr = \":8261\"\nadvertise-addr = \"127.0.0.1:8261\"\n\n# URLs for peer traffic\npeer-urls = \"http://127.0.0.1:8291\"\nadvertise-peer-urls = \"http://127.0.0.1:8291\"\n\n# cluster configuration\ninitial-cluster = \"master1=http://127.0.0.1:8291,master2=http://127.0.0.1:8292,master3=http://127.0.0.1:8293\"\njoin = \"\"\n\nssl-ca = \"/path/to/ca.pem\"\nssl-cert = \"/path/to/cert.pem\"\nssl-key = \"/path/to/key.pem\"\ncert-allowed-cn = [\"dm\"]\n\nsecret-key-path = \"/path/to/secret/key\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TiCDC Filter Rules in TOML\nDESCRIPTION: Example of configuring filter rules for changefeed replication, specifying which tables and databases should be included in replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-ddl.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[filter]\nrules = ['test.t*']\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS for DM-worker in TOML\nDESCRIPTION: TOML configuration for enabling TLS encryption in DM-worker component, including certificate paths and allowed Common Names for identity verification.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-enable-tls.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\nssl-ca = \"/path/to/ca.pem\"\nssl-cert = \"/path/to/worker-cert.pem\"\nssl-key = \"/path/to/worker-key.pem\"\ncert-allowed-cn = [\"dm\"]\n```\n\n----------------------------------------\n\nTITLE: Exporting Hive Table to Parquet Format\nDESCRIPTION: SQL command to create a temporary table in Hive, stored as Parquet format, containing data from the original table. This exports the table data to the HDFS system.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-parquet-files-to-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE temp STORED AS PARQUET LOCATION '/path/in/hdfs'\nAS SELECT * FROM test;\n```\n\n----------------------------------------\n\nTITLE: Configuring Cache Sync Interval for TiKV\nDESCRIPTION: This snippet describes the configuration parameter for TiKV that controls the interval at which the local PD TSO cache is updated, providing default settings to maintain timestamp validity.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n+ Controls the interval at which TiKV updates its local PD TSO cache. TiKV periodically retrieves the latest timestamp from PD and caches it locally to check the validity of `max-ts`.\n+ Default value: `\"15s\"`\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning Server Mode in TOML\nDESCRIPTION: TOML configuration to enable server mode in TiDB Lightning by setting the server-mode option to true and specifying the status address.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-web-interface.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\nserver-mode = true\nstatus-addr = ':8289'\n```\n\n----------------------------------------\n\nTITLE: TiUP DM Scale-In Command Syntax in Shell\nDESCRIPTION: The basic syntax for the tiup dm scale-in command used to remove nodes from a DM cluster. The command requires a cluster name argument and supports various flags for customizing the operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-scale-in.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm scale-in <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Optimizing TiDB Lightning Performance\nDESCRIPTION: This snippet provides troubleshooting insights into slow import speeds in TiDB Lightning, including adjusting `region-concurrency` based on CPU settings and workload.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_14\n\nLANGUAGE: markdown\nCODE:\n```\n- `region-concurrency` is set too high, which causes thread contention and reduces performance. Three ways to troubleshoot:\n\n    - The setting can be found from the start of the log by searching `region-concurrency`.\n    - If TiDB Lightning shares a server with other services (for example, Importer), you must manually set `region-concurrency` to 75% of the total number of CPU cores on that server.\n    - If there is a quota on CPU (for example, limited by Kubernetes settings), TiDB Lightning might not be able to read this out. In this case, `region-concurrency` must also be manually reduced.\n```\n\n----------------------------------------\n\nTITLE: Adding a watch list item with similar SQL matching and action\nDESCRIPTION: This code snippet adds a watch item to the `rg1` resource group. The SQL is parsed into SQL Digest for matching, and the `ACTION` is explicitly set to `SWITCH_GROUP(rg2)`.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-runaway-queries.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n\"QUERY WATCH ADD RESOURCE GROUP rg1 ACTION SWITCH_GROUP(rg2) SQL TEXT SIMILAR TO 'select * from test.t2';\"\n```\n\n----------------------------------------\n\nTITLE: Create Replication Task API Call\nDESCRIPTION: cURL command to create a new replication task with specified ID and sink URI.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST -H \"'Content-type':'application/json'\" http://127.0.0.1:8300/api/v1/changefeeds -d '{\"changefeed_id\":\"test5\",\"sink_uri\":\"blackhole://\"}'\n```\n\n----------------------------------------\n\nTITLE: Configuring Alertmanager Servers in YAML\nDESCRIPTION: Example YAML configuration for deploying Alertmanager services on two machines with custom configuration files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-dm-topology-reference.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nalertmanager_servers:\n  - host: 10.0.1.11\n    config_file: /local/config/file\n  - host: 10.0.1.12\n    config_file: /local/config/file\n```\n\n----------------------------------------\n\nTITLE: INSERT INTO SELECT Memory and Concurrency Guidelines\nDESCRIPTION: Code example showing memory configuration and concurrency recommendations for INSERT INTO SELECT operations in TiDB. Specifies different concurrency limits based on transaction size.\nSOURCE: https://github.com/pingcap/docs/blob/master/CONTRIBUTING.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO SELECT\n```\n\n----------------------------------------\n\nTITLE: Using the TiUP DM Replay Command in Shell\nDESCRIPTION: Command syntax for the `tiup dm replay` operation that allows retrying failed cluster operations. It requires an audit-id parameter which can be obtained using the `tiup dm audit` command.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-replay.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm replay <audit-id> [flags]\n```\n\n----------------------------------------\n\nTITLE: Resume Log Backup Help Command\nDESCRIPTION: Shows help information for the log backup resume command including available flags and global options.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log resume --help\nresume a log backup task\n\nUsage:\n  br log resume [flags]\n\nFlags:\n  -h, --help           help for status\n  --task-name string   The task name for backup stream log.\n\nGlobal Flags:\n --ca string                  CA certificate path for TLS connection\n --cert string                Certificate path for TLS connection\n --key string                 Private key path for TLS connection\n -u, --pd strings             PD address (default [127.0.0.1:2379])\n```\n\n----------------------------------------\n\nTITLE: Retrying S3 Read Errors in TiDB Lightning\nDESCRIPTION: Adds support for retrying errors that occur when reading data from S3 storage in TiDB Lightning, improving reliability during data import operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.10.md#2025-04-18_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\n// GitHub PR: https://github.com/pingcap/tidb-lightning/pull/533\n// Implementation details not provided in the release notes\n```\n\n----------------------------------------\n\nTITLE: Amazon S3 Restore Command\nDESCRIPTION: Command for restoring snapshot data from Amazon S3 using BR with access key authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full -u \"${PD_IP}:2379\" \\\n--storage \"s3://external/backup-20220915?access-key=${access-key}&secret-access-key=${secret-access-key}\"\n```\n\n----------------------------------------\n\nTITLE: Performing Sequential UPDATE Operations\nDESCRIPTION: The second SQL snippet models a scenario where `UPDATE` events may be received out of order by TiCDC. It illustrates the initial input and intended record changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-split-update-behavior.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nUPDATE t SET a = 2 WHERE a = 1;\nUPDATE t SET a = 3 WHERE a = 2;\n```\n\n----------------------------------------\n\nTITLE: Deploying to Netlify Production in Shell\nDESCRIPTION: Command to deploy your application to Netlify's production environment using the trigger method, which initiates a build from your connected GitHub repository.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nnetlify deploy --prod --trigger\n```\n\n----------------------------------------\n\nTITLE: Hash Partitioned Tables: Inapplicable Partition Pruning Using Range Queries in SQL\nDESCRIPTION: This SQL snippet demonstrates an inapplicable scenario of partition pruning in a hash-partitioned table with range conditions. The inability to confirm which specific partitions the data falls into results in scanning multiple partitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/partition-pruning.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (x int) partition by hash(x) partitions 4;\nexplain select * from t where x > 2;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------+----------+-----------+-----------------------+--------------------------------+\n| id                           | estRows  | task      | access object         | operator info                  |\n+------------------------------+----------+-----------+-----------------------+--------------------------------+\n| Union_10                     | 13333.33 | root      |                       |                                |\n| ├─TableReader_13             | 3333.33  | root      |                       | data:Selection_12              |\n| │ └─Selection_12             | 3333.33  | cop[tikv] |                       | gt(test.t.x, 2)                |\n| │   └─TableFullScan_11       | 10000.00 | cop[tikv] | table:t, partition:p0 | keep order:false, stats:pseudo |\n| ├─TableReader_16             | 3333.33  | root      |                       | data:Selection_15              |\n| │ └─Selection_15             | 3333.33  | cop[tikv] |                       | gt(test.t.x, 2)                |\n| │   └─TableFullScan_14       | 10000.00 | cop[tikv] | table:t, partition:p1 | keep order:false, stats:pseudo |\n| ├─TableReader_19             | 3333.33  | root      |                       | data:Selection_18              |\n| │ └─Selection_18             | 3333.33  | cop[tikv] |                       | gt(test.t.x, 2)                |\n| │   └─TableFullScan_17       | 10000.00 | cop[tikv] | table:t, partition:p2 | keep order:false, stats:pseudo |\n| └─TableReader_22             | 3333.33  | root      |                       | data:Selection_21              |\n|   └─Selection_21             | 3333.33  | cop[tikv] |                       | gt(test.t.x, 2)                |\n|     └─TableFullScan_20       | 10000.00 | cop[tikv] | table:t, partition:p3 | keep order:false, stats:pseudo |\n+------------------------------+----------+-----------+-----------------------+--------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Using GCS Wildcard Pattern for Single Character Matching\nDESCRIPTION: Demonstrates how to use the question mark wildcard in GCS URIs to match any single character in filenames during import.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-parquet-files.md#2025-04-18_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\ngs://[bucket_name]/[data_source_folder]/my-data?.parquet\n```\n\n----------------------------------------\n\nTITLE: Renaming an Index in TiDB\nDESCRIPTION: This SQL command renames an existing index within a table. This step is part of the process to fix inconsistent indexes after a recovery by replacing them.\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name RENAME INDEX index_name TO index_name_lame_duck;\n```\n\n----------------------------------------\n\nTITLE: Using IN and NOT IN subqueries in TiDB\nDESCRIPTION: IN and NOT IN subqueries in certain patterns were reporting a 'Can't find column' error. This issue has been resolved in the current release.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.4.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM table1 WHERE column1 IN (SELECT column2 FROM table2);\n```\n\n----------------------------------------\n\nTITLE: SQL Window Functions in TiFlash\nDESCRIPTION: New window functions supported in TiFlash including RANK(), DENSE_RANK(), and ROW_NUMBER().\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.0.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nRANK()\nDENSE_RANK()\nROW_NUMBER()\n```\n\n----------------------------------------\n\nTITLE: Querying Historical Book Data in SQL\nDESCRIPTION: Shows how to query historical book data within a stale read transaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-stale-read.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, title, type, price FROM books ORDER BY published_at DESC LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Configuring TypeScript Compiler Options\nDESCRIPTION: Set up tsconfig.json with compiler options for the TypeScript project.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-kysely-example.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"compilerOptions\": {\n    \"module\": \"ES2022\",\n    \"target\": \"ES2022\",\n    \"moduleResolution\": \"node\",\n    \"strict\": false,\n    \"declaration\": true,\n    \"outDir\": \"dist\",\n    \"removeComments\": true,\n    \"allowJs\": true,\n    \"esModuleInterop\": true,\n    \"resolveJsonModule\": true\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Starting a TiDB Server\nDESCRIPTION: Commands to download and start a TiDB server for testing purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-task.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nwget https://download.pingcap.org/tidb-community-server-v8.5.0-linux-amd64.tar.gz\ntar -xzvf tidb-latest-linux-amd64.tar.gz\nmv tidb-latest-linux-amd64/bin/tidb-server ./\n./tidb-server\n```\n\n----------------------------------------\n\nTITLE: Implementing Write Skew Prevention in Go\nDESCRIPTION: This Go code demonstrates how to use SELECT FOR UPDATE to prevent write skew in a concurrent environment. It manages doctor leave requests while ensuring at least one doctor remains on call.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-restraints.md#2025-04-18_snippet_4\n\nLANGUAGE: go\nCODE:\n```\nfunc askForLeave(db *sql.DB, waitingChan chan bool, goroutineID, doctorID int) error {\n    txnComment := fmt.Sprintf(\"/* txn %d */ \", goroutineID)\n    if goroutineID != 1 {\n        txnComment = \"\\t\" + txnComment\n    }\n\n    txn, err := util.TiDBSqlBegin(db, true)\n    if err != nil {\n        return err\n    }\n    fmt.Println(txnComment + \"start txn\")\n\n    // Txn 1 should be waiting until txn 2 is done.\n    if goroutineID == 1 {\n        <-waitingChan\n    }\n\n    txnFunc := func() error {\n        queryCurrentOnCall := \"SELECT COUNT(*) AS `count` FROM `doctors` WHERE `on_call` = ? AND `shift_id` = ?\"\n        rows, err := txn.Query(queryCurrentOnCall, true, 123)\n        if err != nil {\n            return err\n        }\n        defer rows.Close()\n        fmt.Println(txnComment + queryCurrentOnCall + \" successful\")\n\n        count := 0\n        if rows.Next() {\n            err = rows.Scan(&count)\n            if err != nil {\n                return err\n            }\n        }\n        rows.Close()\n\n        if count < 2 {\n            return fmt.Errorf(\"at least one doctor is on call\")\n        }\n\n        shift := \"UPDATE `doctors` SET `on_call` = ? WHERE `id` = ? AND `shift_id` = ?\"\n        _, err = txn.Exec(shift, false, doctorID, 123)\n        if err == nil {\n            fmt.Println(txnComment + shift + \" successful\")\n        }\n        return err\n    }\n\n    err = txnFunc()\n    if err == nil {\n        txn.Commit()\n        fmt.Println(\"[runTxn] commit success\")\n    } else {\n        txn.Rollback()\n        fmt.Printf(\"[runTxn] got an error, rollback: %+v\\n\", err)\n    }\n\n    // Txn 2 is done. Let txn 1 run again.\n    if goroutineID == 2 {\n        waitingChan <- true\n    }\n\n    return nil\n}\n```\n\n----------------------------------------\n\nTITLE: TiDB Component Changelog Documentation\nDESCRIPTION: Structured documentation of changes and updates implemented across TiDB project components including improvements to Raftstore, Server components, Storage systems, PD functionality, Tools and Ansible deployment system.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.4.md#2025-04-18_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n## TiKV\n\n- Raftstore\n    - Fix the issue that Raftstore inaccurately counts the number of keys in empty Regions [#5414]\n    - Support double linked list for RocksDB to improve the performance of reverse scan [#5368]\n    - Support batch Region split command and empty split command to improve split performance [#5470]\n- Server\n    - Fix the issue that the output format of the `-V` command is not consistent with the format of 2.X [#5501]\n    - Upgrade Titan to the latest version in the 3.0 branch [#5517]\n    - Upgrade grpcio to v0.4.5 [#5523]\n    - Fix the issue of gRPC coredump and support shared memory to avoid OOM [#5524]\n    - Fix the issue in TiKV that file descriptor leak in idle clusters might cause TiKV processes to exit abnormally [#5567]\n- Storage\n    - Support the `txn_heart_beat` API to make the pessimistic lock in TiDB consistent with that in MySQL [#5507]\n    - Fix the issue that the performance of point queries is low in some situations [#5495] [#5463]\n\n## PD\n\n- Fix the issue that adjacent small Regions cannot be merged [#1726]\n- Fix the issue that the TLS enabling parameter in `pd-ctl` is invalid [#1738]\n- Fix the thread-safety issue that the PD operator is accidentally removed [#1734]\n- Support TLS for Region syncer [#1739]\n\n## Tools\n\n- TiDB Binlog\n    - Add the `worker-count` and `txn-batch` configuration items in Reparo [#746]\n    - Optimize the memory usage of Drainer to enhance the efficiency [#737]\n- TiDB Lightning\n    - Fix the issue that re-importing data from checkpoint might cause panic [#237]\n    - Optimize the algorithm of `AUTO_INCREMENT` [#227]\n\n## TiDB Ansible\n\n- Upgrade TiSpark to v2.2.0 [#926]\n- Update the default value of `pessimistic_txn` to `true` [#933]\n- Add more system-level monitoring metrics to `node_exporter` [#938]\n- Add perf tools `iosnoop` and `funcslower` [#946]\n- Replace raw module to shell module [#949]\n- Update default value of `txn_local_latches` to `false`\n- Optimize monitoring metrics and alert rules [#962] [#963] [#969]\n- Check configuration file before deployment and upgrade [#934] [#972]\n```\n\n----------------------------------------\n\nTITLE: Creating a Key Partitioned Table with Unique Key in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Key partitioned table using a unique key as the partitioning key when there's no primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_32\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE k1 (\n    id INT NOT NULL,\n    name VARCHAR(20),\n    UNIQUE KEY (id)\n)\nPARTITION BY KEY()\nPARTITIONS 2;\n```\n\n----------------------------------------\n\nTITLE: Querying Specific Keywords in TiDB INFORMATION_SCHEMA.KEYWORDS\nDESCRIPTION: This SQL query retrieves information about the 'ADD' and 'USER' keywords from the KEYWORDS table, demonstrating how to check if a keyword is reserved or non-reserved.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-keywords.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.KEYWORDS WHERE WORD IN ('ADD','USER');\n```\n\n----------------------------------------\n\nTITLE: Viewing Result from TIDB_PARSE_TSO Function\nDESCRIPTION: Shows the output of TIDB_PARSE_TSO function, which converts the numeric TSO value to a human-readable datetime format. The example shows a timestamp from May 26, 2021.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\n+-----------------------------------+\n| TIDB_PARSE_TSO(@@tidb_current_ts) |\n+-----------------------------------+\n| 2021-05-26 11:33:37.776000        |\n+-----------------------------------+\n1 row in set (0.0012 sec)\n```\n\n----------------------------------------\n\nTITLE: Utilizing IFNULL for NULL Values in SQL\nDESCRIPTION: The IFNULL function manages NULL values in SQL by returning the first non-null expression or a substitute if the first is null. It relies on compatible SQL databases. This function helps to prevent null value issues by returning a non-null substitute.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/control-flow-functions.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nWITH data AS (SELECT NULL AS x UNION ALL SELECT 1 )\nSELECT x, IFNULL(x,'x has no value') FROM data;\n```\n\n----------------------------------------\n\nTITLE: Checking I/O Scheduler for NVMe Devices\nDESCRIPTION: Command to verify the I/O Scheduler configuration for NVMe storage devices.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\ncat /sys/block/nvme[01]*/queue/scheduler\n```\n\n----------------------------------------\n\nTITLE: Setting default authentication plugin in TiDB 5.2\nDESCRIPTION: Sets the authentication method that the server advertises. The default value is 'mysql_native_password'.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.2.0.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL default_authentication_plugin = 'mysql_native_password';\n```\n\n----------------------------------------\n\nTITLE: Selecting Data From t2 Table in SQL\nDESCRIPTION: This SQL snippet shows how to select all rows and columns from the table 't2'. It is used to verify the results of the non-transactional UPDATE statement executed in the previous example. The output shows the modified data in the table after the update operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT * FROM t2;\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"+----+---+\\n| id | v |\\n+----+---+\\n| 1  | 1 |\\n| 3  | 3 |\\n| 6  | 5 |\\n+----+---+\"\n```\n\n----------------------------------------\n\nTITLE: Querying GROUP_CONCAT With ORDER BY in SQL\nDESCRIPTION: This snippet shows how to use ORDER BY within GROUP_CONCAT() to ensure stable and ordered results in TiDB queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-unstable-result-set.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nselect GROUP_CONCAT( customer_id order by customer_id SEPARATOR ',' ) FROM customer where customer_id like '200002%';\n```\n\n----------------------------------------\n\nTITLE: Encrypting Data Using AES in SQL\nDESCRIPTION: The `AES_ENCRYPT(data, key [,iv])` function encrypts the given data using a specified key. Users can specify the initialization vector for certain encryption modes, which defaults to NULL.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT AES_ENCRYPT(0x616263,'secret');\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed Configuration File for Confluent Cloud\nDESCRIPTION: A configuration file that sets up dispatchers for replicating TiDB data to Confluent Cloud. It ensures each table's data is sent to an independent topic with appropriate partitioning based on primary key values.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[sink]\ndispatchers = [\n{matcher = ['*.*'], topic = \"tidb_{schema}_{table}\", partition=\"index-value\"},\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring RaftDB and its Default Column Family in TiKV\nDESCRIPTION: Configuration settings for RaftDB, which is used to store Raft logs. It includes both general RaftDB settings and specific settings for its default column family.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-tikv-memory-performance.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[raftdb]\n# The maximum number of the file handles RaftDB can open\n# max-open-files = 40960\n\n# Enable the readahead feature in RaftDB compaction. If you are using mechanical disks, it is recommended to set\n# this value to 2MB at least.\n# compaction-readahead-size = \"2MiB\"\n\n[raftdb.defaultcf]\n# Set it the same as `rocksdb.defaultcf.compression-per-level`.\ncompression-per-level = [\"no\", \"no\", \"lz4\", \"lz4\", \"lz4\", \"zstd\", \"zstd\"]\n\n# Set it the same as `rocksdb.defaultcf.write-buffer-size`.\nwrite-buffer-size = \"128MiB\"\nmax-write-buffer-number = 5\nmin-write-buffer-number-to-merge = 1\n\n# Set it the same as `rocksdb.defaultcf.max-bytes-for-level-base`.\nmax-bytes-for-level-base = \"512MiB\"\ntarget-file-size-base = \"32MiB\"\n```\n\n----------------------------------------\n\nTITLE: Upgrading TiUP and TiUP Cluster\nDESCRIPTION: Commands to upgrade TiUP and TiUP Cluster components to the latest version to resolve metrics reporting issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup update --self\ntiup update cluster --force\n```\n\n----------------------------------------\n\nTITLE: Configuring Log Level in TiFlash Proxy\nDESCRIPTION: Sets the log level for TiFlash Proxy, with options for different verbosity levels to control the amount of detail logged.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_3\n\nLANGUAGE: TOML\nCODE:\n```\n\"log.level = \\\"info\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Checking NIC Interrupt Coalescing Settings\nDESCRIPTION: Command to check the current interrupt coalescing configuration of a network interface using ethtool.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nethtool -c ${NIC_DEV_NAME}\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Replication Task to Pulsar\nDESCRIPTION: This code snippet demonstrates how to create a TiCDC replication task to replicate incremental data to Pulsar. It uses the `cdc cli changefeed create` command with several parameters, including the TiCDC server address, Sink URI for Pulsar, configuration file, and changefeed ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create \\\n    --server=http://127.0.0.1:8300 \\\n--sink-uri=\"pulsar://127.0.0.1:6650/persistent://public/default/yktest?protocol=canal-json\" \\\n--config=./t_changefeed.toml \\\n--changefeed-id=\"simple-replication-task\"\n```\n\n----------------------------------------\n\nTITLE: Querying GitHub Event Data in TiDB Cloud with SQL\nDESCRIPTION: SQL query to fetch all rows from the github_global_event table in the test database, demonstrating the data structure after the Zapier integration has successfully captured GitHub events.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-zapier.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT * FROM test.github_global_event;\n+-------------+-------------+------------+-----------------+----------------------------------------------+--------+---------------------+\n| id          | type        | actor      | repo_name       | repo_url                                     | public | created_at          |\n+-------------+-------------+------------+-----------------+----------------------------------------------+--------+---------------------+\n| 25324462424 | CreateEvent | shiyuhang0 | shiyuhang0/docs | https://api.github.com/repos/shiyuhang0/docs | True   | 2022-11-18 08:03:14 |\n+-------------+-------------+------------+-----------------+----------------------------------------------+--------+---------------------+\n1 row in set (0.17 sec)\n```\n\n----------------------------------------\n\nTITLE: Dropping Extended Statistics Object\nDESCRIPTION: SQL statement to remove an extended statistics object from a table. This marks the object for deletion rather than removing it immediately.\nSOURCE: https://github.com/pingcap/docs/blob/master/extended-statistics.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name DROP STATS_EXTENDED stats_name;\n```\n\n----------------------------------------\n\nTITLE: Removing Capture Tasks\nDESCRIPTION: Demonstrates how to remove specific capture tasks using PLAN REPLAYER CAPTURE REMOVE command.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-replayer.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nmysql> PLAN REPLAYER CAPTURE '077a87a576e42360c95530ccdac7a1771c4efba17619e26be50a4cfd967204a0' '4838af52c1e07fc8694761ad193d16a689b2128bc5ced9d13beb31ae27b370ce';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> SELECT * FROM mysql.plan_replayer_task;\n+------------------------------------------------------------------+------------------------------------------------------------------+---------------------+\n| sql_digest                                                       | plan_digest                                                      | update_time         |\n+------------------------------------------------------------------+------------------------------------------------------------------+---------------------+\n| 077a87a576e42360c95530ccdac7a1771c4efba17619e26be50a4cfd967204a0 | 4838af52c1e07fc8694761ad193d16a689b2128bc5ced9d13beb31ae27b370ce | 2024-05-21 11:26:10 |\n+------------------------------------------------------------------+------------------------------------------------------------------+---------------------+\n1 row in set (0.01 sec)\n\nmysql> PLAN REPLAYER CAPTURE REMOVE '077a87a576e42360c95530ccdac7a1771c4efba17619e26be50a4cfd967204a0' '4838af52c1e07fc8694761ad193d16a689b2128bc5ced9d13beb31ae27b370ce';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> SELECT * FROM mysql.plan_replayer_task;\nEmpty set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: MySQL connection string example for TiDB Cloud Serverless\nDESCRIPTION: This is an example of the connection string to be used for TiDB Cloud Serverless when using the LOAD DATA statement to load data from local data files. It includes options for user, host, port, database, SSL mode, and enables local file loading.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-load-data.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nmysql --connect-timeout 15 -u '<user_name>' -h <host_name> -P 4000 -D test --ssl-mode=VERIFY_IDENTITY --ssl-ca=/etc/ssl/cert.pem -p<your_password> --local-infile\n```\n\n----------------------------------------\n\nTITLE: Viewing Imported Cluster Status\nDESCRIPTION: The snippet provides the command to check the status of an imported TiDB Cloud cluster, detailing its properties and configuration to ensure it is correctly recognized by Terraform.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform state show tidbcloud_cluster.import_cluster\n\n# tidbcloud_cluster.import_cluster:\nresource \"tidbcloud_cluster\" \"import_cluster\" {\n    cloud_provider = \"AWS\"\n    cluster_type   = \"DEDICATED\"\n    config         = {\n        components = {\n            tidb    = {\n                node_quantity = 2\n                node_size     = \"8C16G\"\n            }\n            tiflash = {\n                node_quantity    = 2\n                node_size        = \"8C64G\"\n                storage_size_gib = 500\n            }\n            tikv    = {\n                node_quantity    = 6\n                node_size     = \"8C32G\"\n                storage_size_gib = 500\n            }\n        }\n        port       = 4000\n    }\n    id             = \"1379661944630264072\"\n    name           = \"restoreCluster\"\n    project_id     = \"1372813089189561287\"\n    region         = \"eu-central-1\"\n    status         = \"AVAILABLE\"\n}\n```\n\n----------------------------------------\n\nTITLE: TiKV Low Space Alert Rule\nDESCRIPTION: Monitors available storage space in TiKV nodes. Alerts when available space falls below 20% of total capacity.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_18\n\nLANGUAGE: promql\nCODE:\n```\nsum(tikv_store_size_bytes{type=\"available\"}) by (instance) / sum(tikv_store_size_bytes{type=\"capacity\"}) by (instance) < 0.2\n```\n\n----------------------------------------\n\nTITLE: Creating Snapshot Backups in TiDB\nDESCRIPTION: Examples of backing up historical data by specifying a timestamp, TSO, or relative time for the snapshot point.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-backup.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n-- relative time\nBACKUP DATABASE `test` TO 'local:///mnt/backup/hist01'\n    SNAPSHOT = 36 HOUR AGO;\n\n-- timestamp (in current time zone)\nBACKUP DATABASE `test` TO 'local:///mnt/backup/hist02'\n    SNAPSHOT = '2020-04-01 12:00:00';\n\n-- timestamp oracle\nBACKUP DATABASE `test` TO 'local:///mnt/backup/hist03'\n    SNAPSHOT = 415685305958400;\n```\n\n----------------------------------------\n\nTITLE: Prepare Data for RawSQL Test (SQL)\nDESCRIPTION: This SQL script prepares data for a RawSQL test. It creates a table named `t` and inserts three rows of data into it.  This data is used by the example query provided in the subsequent code snippet.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\n-- Prepare data\nCREATE TABLE t (a int);\nINSERT INTO t VALUES (1), (2), (3);\n```\n\n----------------------------------------\n\nTITLE: TiDB Database Connection Setup\nDESCRIPTION: Establishing connection to TiDB cluster using SQLAlchemy.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-jinaai-embedding.md#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport dotenv\n\nfrom tidb_vector.sqlalchemy import VectorType\nfrom sqlalchemy.orm import Session, declarative_base\n\ndotenv.load_dotenv()\n\nTIDB_DATABASE_URL = os.getenv('TIDB_DATABASE_URL')\nassert TIDB_DATABASE_URL is not None\nengine = create_engine(url=TIDB_DATABASE_URL, pool_recycle=300)\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for ALTER TABLE ... COMPACT in TiDB\nDESCRIPTION: EBNF syntax diagram showing the structure of the ALTER TABLE ... COMPACT statement, which allows compaction of table data, particularly for TiFlash replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table-compact.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\nAlterTableCompactStmt ::=\n    'ALTER' 'TABLE' TableName 'COMPACT' ( 'PARTITION' PartitionNameList )? ( 'TIFLASH' 'REPLICA' )?\n```\n\n----------------------------------------\n\nTITLE: Creating Table and Inserting Data in TiDB SQL\nDESCRIPTION: SQL commands to create a table named 't1' with an auto-incrementing primary key and insert sample data into it.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-change-column.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t1 (id int not null primary key AUTO_INCREMENT, col1 INT);\n\nINSERT INTO t1 (col1) VALUES (1),(2),(3),(4),(5);\n```\n\n----------------------------------------\n\nTITLE: Basic TSO Configuration Properties\nDESCRIPTION: Core configuration properties for TSO node including name, data directory, and network settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tso-configuration-file.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: \"TSO\"\ndata-dir: \"default.${name}\"\nlisten-addr: \"http://127.0.0.1:3379\"\nadvertise-listen-addr: \"${listen-addr}\"\nbackend-endpoints: \"http://127.0.0.1:2379\"\nlease: 3\ntso-update-physical-interval: \"50ms\"\n```\n\n----------------------------------------\n\nTITLE: Querying Data from TiDB using MySQL Connector/Python\nDESCRIPTION: This code snippet shows how to query data from a TiDB database using MySQL Connector/Python. It establishes a connection, creates a cursor, executes a SELECT statement, and fetches the result.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-mysql-connector.md#2025-04-18_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nwith get_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT count(*) FROM players\")\n        print(cur.fetchone()[0])\n```\n\n----------------------------------------\n\nTITLE: Serving dbt Documentation\nDESCRIPTION: Command to start a local server to view the generated dbt documentation. The documentation will be accessible at localhost:8080.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ndbt docs serve\n```\n\n----------------------------------------\n\nTITLE: File Type Capture Configuration for File Patterns in TiDB Lightning\nDESCRIPTION: Configuration for capturing file type from regex pattern matching. The $3 refers to the third capture group in the pattern expression used for parsing files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n'$3'\n```\n\n----------------------------------------\n\nTITLE: Generating zsh completion file for TiUP\nDESCRIPTION: This snippet shows how to generate the zsh completion file for TiUP using the `tiup completion zsh` command. The generated file provides auto-completion for TiUP commands in the zsh shell. The file is placed in a directory present in the `$fpath` array, specifically the second directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-completion.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup completion zsh > \"${fpath[1]}/_tiup\"\n```\n\n----------------------------------------\n\nTITLE: Restoring Database Using BR\nDESCRIPTION: Command to restore a specific database from backup data using BR. Uses the tiup br restore db command with PD endpoint, database name, and S3 storage location parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-guide.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore db \\\n--pd \"${PD_IP}:2379\" \\\n--db \"test\" \\\n--storage \"s3://backup-101/snapshot-202209081330?access-key=${access-key}&secret-access-key=${secret-access-key}\"\n```\n\n----------------------------------------\n\nTITLE: Querying Placement Policies in Cluster SQL\nDESCRIPTION: This SQL statement shows all placement policies defined in the cluster, aiding in policy management and verification processes.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.placement_policies\\G\n***************************[ 1. row ]***************************\nPOLICY_ID            | 1\nCATALOG_NAME         | def\nPOLICY_NAME          | p1\nPRIMARY_REGION       | us-east-1\nREGIONS              | us-east-1,us-west-1\nCONSTRAINTS          |\nLEADER_CONSTRAINTS   |\nFOLLOWER_CONSTRAINTS |\nLEARNER_CONSTRAINTS  |\nSCHEDULE             |\nFOLLOWERS            | 4\nLEARNERS             | 0\n1 row in set\n```\n\n----------------------------------------\n\nTITLE: IMPORT INTO SQL Statement for Data Import\nDESCRIPTION: New experimental SQL statement that simplifies data import from remote storage systems like Amazon S3 or Google Cloud Storage directly into TiDB, integrating physical import mode of TiDB Lightning\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.2.0.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO table_name FROM 's3://bucket/path'\n    WITH FORMAT = 'CSV',\n    DELIMITER = ',',\n    FIELDS_ENCLOSED_BY = '\"'\n```\n\n----------------------------------------\n\nTITLE: Calculating MD5 Hash in SQL\nDESCRIPTION: The `MD5(expr)` function computes a 128-bit MD5 hash of the provided expression. It returns the MD5 hash string.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MD5('abc');\n```\n\n----------------------------------------\n\nTITLE: Getting Table List for Schema with cURL in Shell\nDESCRIPTION: This example demonstrates how to retrieve a list of table names available in a specific schema of a data source by making a GET request to the DM API.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_24\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/sources/source-1/schemas/db1' \\\n  -H 'accept: application/json'\n```\n\n----------------------------------------\n\nTITLE: Checking TiFlash Replicas\nDESCRIPTION: This SQL query checks the `information_schema.tiflash_replica` table to identify tables that have more TiFlash replicas configured than the number of available TiFlash nodes after a scale-in operation. This situation can prevent the removal of TiFlash nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\n```sql\nSELECT * FROM information_schema.tiflash_replica WHERE REPLICA_COUNT > 'tobe_left_nodes';\n```\n```\n\n----------------------------------------\n\nTITLE: Example SQL Insert and Query to Demonstrate Expression Filter\nDESCRIPTION: This SQL snippet covers inserting records into a source table and querying the downstream table to confirm that only rows with odd values in column 'c' are replicated due to the configured expression filter. Requires connectivity with MySQL sources and DM setup as preconditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/filter-dml-event.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO tbl(id, c) VALUES (1, 1), (2, 2), (3, 3), (4, 4);\n\nMySQL [test]> select * from tbl;\n+------+------+\n| id   | c    |\n+------+------+\n|    1 |    1 |\n|    3 |    3 |\n+------+------+\n2 rows in set (0.001 sec)\n\n```\n\n----------------------------------------\n\nTITLE: Encoding Storage Path to Base64 for Log Backup Compaction\nDESCRIPTION: Command to encode the storage path to Base64 format, which is required for the log backup compaction process. The --load-creds option includes credential information from the current BR environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-compact-log-backup.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbr operator base64ify --storage \"s3://your/log/backup/storage/here\" --load-creds\n```\n\n----------------------------------------\n\nTITLE: Viewing ANALYZE Status in SQL\nDESCRIPTION: This SQL query displays the current state of ANALYZE operations, showing table schema, name, partition details, job information, processed rows, timestamps, state, and any failure reasons.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_17\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> SHOW ANALYZE STATUS [ShowLikeOrWhere];\n+--------------+------------+----------------+-------------------------------------------------------------------------------------------+----------------+---------------------+---------------------+----------+-------------------------------------------------------------------------------|\n| Table_schema | Table_name | Partition_name | Job_info                                                                                  | Processed_rows | Start_time          | End_time            | State    | Fail_reason                                                                   |\n+--------------+------------+----------------+-------------------------------------------------------------------------------------------+----------------+---------------------+---------------------+----------+-------------------------------------------------------------------------------|\n| test         | sbtest1    |                | retry auto analyze table all columns with 100 topn, 0.055 samplerate                      |        2000000 | 2022-05-07 16:41:09 | 2022-05-07 16:41:20 | finished | NULL                                                                          |\n| test         | sbtest1    |                | auto analyze table all columns with 100 topn, 0.5 samplerate                              |              0 | 2022-05-07 16:40:50 | 2022-05-07 16:41:09 | failed   | analyze panic due to memory quota exceeds, please try with smaller samplerate |\n```\n\n----------------------------------------\n\nTITLE: Default Placement Rule JSON Configuration\nDESCRIPTION: The default JSON configuration generated when Placement Rules is enabled, based on max-replicas, location-labels, and isolation-level settings. This defines voter placement with 3 replicas across zone/rack/host topology.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-placement-rules.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"group_id\": \"pd\",\n  \"id\": \"default\",\n  \"start_key\": \"\",\n  \"end_key\": \"\",\n  \"role\": \"voter\",\n  \"count\": 3,\n  \"location_labels\": [\"zone\", \"rack\", \"host\"],\n  \"isolation_level\": \"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Deleting a User Profile with TiCloud CLI\nDESCRIPTION: This command allows users to delete a specified user profile from TiCloud using the `ticloud config delete` command. Users can provide flags to modify the behavior of this command. The command can also be aliased with `ticloud config rm` for convenience.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-delete.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud config delete <profile-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Creating and Verifying Resource Group\nDESCRIPTION: Example sequence showing creation of a resource group, verifying its existence through information_schema, dropping it, and confirming deletion.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-resource-group.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE RESOURCE GROUP IF NOT EXISTS rg1 RU_PER_SEC = 500 BURSTABLE;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.resource_groups WHERE NAME ='rg1';\n```\n\nLANGUAGE: sql\nCODE:\n```\nDROP RESOURCE GROUP IF EXISTS rg1;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.resource_groups WHERE NAME ='rg1';\n```\n\n----------------------------------------\n\nTITLE: Extracting Prometheus Package\nDESCRIPTION: Command to extract the Prometheus package from the downloaded TiDB distribution\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-monitoring-services.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntar -xzf prometheus-v{version}-linux-amd64.tar.gz\n```\n\n----------------------------------------\n\nTITLE: API List Interface Response Format\nDESCRIPTION: Standard JSON response format for API endpoints that return lists of resources, including total count and items array.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"total\": 2,\n  \"items\": [\n    {\n      \"id\": \"d2912e63-3349-447c-90ba-wwww\",\n      \"is_owner\": true,\n      \"address\": \"127.0.0.1:8300\"\n    },\n    {\n      \"id\": \"d2912e63-3349-447c-90ba-xxxx\",\n      \"is_owner\": false,\n      \"address\": \"127.0.0.1:8302\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for CREATE DATABASE in TiDB\nDESCRIPTION: Extended Backus-Naur Form (EBNF) notation defining the complete syntax structure for the CREATE DATABASE statement, including optional parameters and placement policy options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-database.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCreateDatabaseStmt ::=\n    'CREATE' 'DATABASE' IfNotExists DBName DatabaseOptionListOpt\n\nIfNotExists ::=\n    ( 'IF' 'NOT' 'EXISTS' )?\n\nDBName ::=\n    Identifier\n\nDatabaseOptionListOpt ::=\n    DatabaseOptionList?\n\nDatabaseOptionList ::=\n    DatabaseOption ( ','? DatabaseOption )*\n\nDatabaseOption ::=\n    DefaultKwdOpt ( CharsetKw '='? CharsetName | 'COLLATE' '='? CollationName | 'ENCRYPTION' '='? EncryptionOpt )\n|   DefaultKwdOpt PlacementPolicyOption\n\nPlacementPolicyOption ::=\n    \"PLACEMENT\" \"POLICY\" EqOpt PolicyName\n|   \"PLACEMENT\" \"POLICY\" (EqOpt | \"SET\") \"DEFAULT\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Table Migration Rule for SSD Nodes in TiDB\nDESCRIPTION: JSON configuration that defines placement rules for migrating a specific table range to nodes with SSD disks. Specifies voter role, replica count, and label constraints to ensure data is stored on SSD disks.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-placement-rules.md#2025-04-18_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"group_id\": \"ssd-override\",\n  \"id\": \"ssd-table-45\",\n  \"start_key\": \"7480000000000000ff2d5f720000000000fa\",\n  \"end_key\": \"7480000000000000ff2e00000000000000f8\",\n  \"role\": \"voter\",\n  \"count\": 3,\n  \"label_constraints\": [\n    {\"key\": \"disk\", \"op\": \"in\", \"values\": [\"ssd\"]}\n  ],\n  \"location_labels\": [\"rack\", \"host\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Cloud Storage URI for TiDB\nDESCRIPTION: This SQL statement sets the `tidb_cloud_storage_uri` global variable, which specifies the cloud storage path to be used by the Global Sort feature. It is required to be set to a correct cloud storage path like Amazon S3. The `role-arn` parameter specifies the AWS IAM role to be used for accessing the storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-global-sort.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_cloud_storage_uri = 's3://my-bucket/test-data?role-arn=arn:aws:iam::888888888888:role/my-role'\n```\n\n----------------------------------------\n\nTITLE: Data Summary Response Format in JavaScript\nDESCRIPTION: Example response from the /v3/dataSummaries endpoint. It includes the success code, a data summary ID, and a job ID which can be used to check the status of the analysis process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"code\": 200,\n  \"msg\": \"\",\n  \"result\": {\n    \"data_summary_id\": 304823,\n    \"job_id\": \"fb99ef785da640ab87bf69afed60903d\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Altering a user and unbinding from a resource group\nDESCRIPTION: This SQL statement unbinds the user `usr3` from their current resource group by binding them to the `default` resource group.  The `default` resource group has unlimited RU and is burstable.  This effectively removes any resource constraints previously applied to the user.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-ru-groups.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n\"ALTER USER 'usr3'@'%' RESOURCE GROUP `default`;\"\n```\n\n----------------------------------------\n\nTITLE: Explaining Aggregation with MPP in SQL\nDESCRIPTION: This snippet demonstrates using the EXPLAIN statement in SQL to display an execution plan for an aggregation query in TiDB. It shows how different exchange operators are used to process the query in parallel using MPP mode. The plan details how data is read, processed, and sent between query fragments.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-mpp.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT COUNT(*) FROM t1 GROUP BY id;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------------+---------+-------------------+---------------+----------------------------------------------------+\n| id                                 | estRows | task              | access object | operator info                                      |\n+------------------------------------+---------+-------------------+---------------+----------------------------------------------------+\n| TableReader_31                     | 2.00    | root              |               | data:ExchangeSender_30                             |\n| └─ExchangeSender_30                | 2.00    | batchCop[tiflash] |               | ExchangeType: PassThrough                          |\n|   └─Projection_26                  | 2.00    | batchCop[tiflash] |               | Column#4                                           |\n|     └─HashAgg_27                   | 2.00    | batchCop[tiflash] |               | group by:test.t1.id, funcs:sum(Column#7)->Column#4 |\n|       └─ExchangeReceiver_29        | 2.00    | batchCop[tiflash] |               |                                                    |\n|         └─ExchangeSender_28        | 2.00    | batchCop[tiflash] |               | ExchangeType: HashPartition, Hash Cols: test.t1.id |\n|           └─HashAgg_9              | 2.00    | batchCop[tiflash] |               | group by:test.t1.id, funcs:count(1)->Column#7      |\n|             └─TableFullScan_25     | 3.00    | batchCop[tiflash] | table:t1      | keep order:false                                   |\n+------------------------------------+---------+-------------------+---------------+----------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Viewing Specific Component Versions\nDESCRIPTION: Command to view the latest version information for a specific TiUP component\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-troubleshooting-guide.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup list <component>\n```\n\n----------------------------------------\n\nTITLE: Initializing Test Data with Sysbench\nDESCRIPTION: Command to generate test data using sysbench, creating 10 tables with 10,000 rows each in the test database.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsysbench oltp_write_only --config-file=./tidb-config --tables=10 --table-size=10000 prepare\n```\n\n----------------------------------------\n\nTITLE: Cloning the TiDB Cloud Next.js Prisma Example Repository in Shell\nDESCRIPTION: Commands for forking and cloning the TiDB Cloud fullstack example repository built with Next.js and Prisma to your local development environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/${your_username}/nextjs-prisma-example.git\ncd nextjs-prisma-example/\n```\n\n----------------------------------------\n\nTITLE: TiDB Lightning Parallel Import Configuration\nDESCRIPTION: TOML configuration for parallel import of single tables from Amazon S3, including file pattern matching and parallel import settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-distributed-import.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[[mydumper.files]]\n# the db schema file\npattern = '(?i)^(?:[^/]*/)*my_db-schema-create\\.sql'\nschema = \"my_db\"\ntype = \"schema-schema\"\n\n[[mydumper.files]]\n# the table schema file\npattern = '(?i)^(?:[^/]*/)*my_db\\.my_table-schema\\.sql'\nschema = \"my_db\"\ntable = \"my_table\"\ntype = \"table-schema\"\n\n[[mydumper.files]]\n# Only import 00001~05000 and ignore other files\npattern = '(?i)^(?:[^/]*/)*my_db\\.my_table\\.(0[0-4][0-9][0-9][0-9]|05000)\\.sql'\nschema = \"my_db\"\ntable = \"my_table\"\ntype = \"sql\"\n\n[tikv-importer]\n# Whether to allow importing data into tables that already have data. The default value is `false`.\n# When using parallel import, because multiple TiDB Lightning instances import a table at the same time, this configuration item must be set to `true`.\nparallel-import = true\n```\n\n----------------------------------------\n\nTITLE: Encrypting Log Backup with Direct Key in Shell\nDESCRIPTION: Example of starting a log backup task with encryption using the AES-128-CTR algorithm and a direct encryption key.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log start \\\n    --task-name=pitr-with-encryption\n    --pd ${PD_IP}:2379 \\\n    --storage \"s3://${BACKUP_COLLECTION_ADDR}/snapshot-${DATE}?access-key=${AWS_ACCESS_KEY}&secret-access-key=${AWS_SECRET_ACCESS_KEY}\" \\\n    --log.crypter.method aes128-ctr \\\n    --log.crypter.key 0123456789abcdef0123456789abcdef\n```\n\n----------------------------------------\n\nTITLE: Adding a Term-Sheet Explanation to Knowledge Base - Bash\nDESCRIPTION: This snippet demonstrates how to add a term-sheet explanation type of knowledge to a knowledge base using the Chat2Query API. It requires an accurate description of terms to enhance Chat2Query's understanding of specific vocabulary.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-knowledge.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user ${PUBLIC_KEY}:${PRIVATE_KEY} --request POST 'https://<region>.data.tidbcloud.com/api/v1beta/app/chat2query-<ID>/endpoint/v3/knowledgeBases/<knowledge_base_id>/data'\\\n --header 'content-type: application/json'\\\n --data-raw '{\n    \"type\": \"term-sheet\",\n    \"meta_data\": {},\n    \"raw_data\": {\n        \"term\": [\"OSS\"],\n        \"description\": \"OSS Insight is a powerful tool that provides online data analysis for users based on nearly 6 billion rows of GitHub event data.\"\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Running TiDB Lightning for Data Import\nDESCRIPTION: Shell command to execute tidb-lightning using the TiUP package manager. This command references the configuration file to import the prepared CSV data into the TiDB database.\nSOURCE: https://github.com/pingcap/docs/blob/master/import-example-data.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup tidb-lightning -c tidb-lightning.toml\n```\n\n----------------------------------------\n\nTITLE: Displaying DM Cluster Status\nDESCRIPTION: Command to query and display the current status of a DM cluster before applying a hotfix. This provides information about the nodes, roles, and versions to target for the hotfix.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-patch.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm display dm-test\n```\n\n----------------------------------------\n\nTITLE: Generating Root CA Certificate\nDESCRIPTION: Command to generate a self-signed root CA certificate valid for 1000 days using the previously generated root key.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nopenssl req -new -x509 -days 1000 -key root.key -out root.crt\n```\n\n----------------------------------------\n\nTITLE: Disabling Account Locking Policy for Existing User in TiDB\nDESCRIPTION: This SQL command disables the account locking policy for an existing user 'test3'@'localhost' by setting both FAILED_LOGIN_ATTEMPTS and PASSWORD_LOCK_TIME to 0.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_32\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER 'test3'@'localhost' FAILED_LOGIN_ATTEMPTS 0 PASSWORD_LOCK_TIME 0;\n```\n\n----------------------------------------\n\nTITLE: Single-line SQL Insert Statements\nDESCRIPTION: Shows how to insert multiple rows using separate INSERT statements. While less efficient than multi-line insertion, this approach might be more readable.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-insert-data.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO `player` (`id`, `coins`, `goods`) VALUES (1, 1000, 1);\nINSERT INTO `player` (`id`, `coins`, `goods`) VALUES (2, 230, 2);\nINSERT INTO `player` (`id`, `coins`, `goods`) VALUES (3, 300, 5);\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Primary Key and Auto-increment in TiDB\nDESCRIPTION: Example demonstrating how to conditionally create a table if it doesn't exist, with a primary key that auto-increments and a required VARCHAR column.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-table.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP TABLE IF EXISTS t1;\nCREATE TABLE IF NOT EXISTS t1 (\n id BIGINT NOT NULL PRIMARY KEY auto_increment,\n b VARCHAR(200) NOT NULL\n);\nDESC t1;\n```\n\n----------------------------------------\n\nTITLE: Hashing Number Using VITESS_HASH for Migration\nDESCRIPTION: The `VITESS_HASH(num)` function hashes a number following Vitess' method, facilitating migration from Vitess to TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VITESS_HASH(123);\n```\n\n----------------------------------------\n\nTITLE: TiDB System Variable Reference\nDESCRIPTION: Reference to the tidb_opt_fix_control system variable introduced in TiDB v6.5.3 and v7.1.0 for fine-grained optimizer control.\nSOURCE: https://github.com/pingcap/docs/blob/master/control-execution-plan.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ntidb_opt_fix_control\n```\n\n----------------------------------------\n\nTITLE: Select First N Rows Syntax Differences\nDESCRIPTION: Demonstrates how to retrieve the first n rows from a query in Oracle using ROWNUM versus using LIMIT in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\nROWNUM <= n\n```\n\nLANGUAGE: sql\nCODE:\n```\nLIMIT n\n```\n\n----------------------------------------\n\nTITLE: Configuring Scheduling node in scale-out.yml\nDESCRIPTION: This configuration example shows how to add a Scheduling node to the TiDB cluster. It specifies the host IP address and port number for the Scheduling service.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_3\n\nLANGUAGE: ini\nCODE:\n```\n\"scheduling_servers:\\n  - host: 10.0.1.9\\n    port: 3379\"\n```\n\n----------------------------------------\n\nTITLE: Using SHUFFLE_JOIN Hint for MPP Mode\nDESCRIPTION: The SHUFFLE_JOIN hint forces the optimizer to use the Shuffle Join algorithm for specified tables. This hint only takes effect in the MPP mode with TiFlash and can be combined with other join hints.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ SHUFFLE_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Listing All Data Sources\nDESCRIPTION: Command to display all configured data sources and their associated workers.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-source.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntiup dmctl --master-addr <master-addr> operate-source show\n```\n\n----------------------------------------\n\nTITLE: Displaying the TiDB cluster details\nDESCRIPTION: This command displays detailed information about the TiDB cluster, including the node ID, role, host, ports, status, data directory, and deploy directory for each instance. This information is necessary for identifying the nodes to be removed during scale-in operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster display <cluster-name>\"\n```\n\n----------------------------------------\n\nTITLE: Kafka Sink Dispatcher Configuration Example\nDESCRIPTION: This configuration example for the Kafka sink specifies dispatching rules using matcher patterns that determine how data change events are routed based on table names.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\n[sink]\ndispatchers = [\n  {matcher = ['test1.*', 'test2.*'], topic = \"Topic expression 1\", partition = \"ts\" },\n  {matcher = ['test3.*', 'test4.*'], topic = \"Topic expression 2\", partition = \"index-value\" },\n  {matcher = ['test1.*', 'test5.*'], topic = \"Topic expression 3\", partition = \"table\"},\n  {matcher = ['test6.*'], partition = \"ts\"}\n]\n```\n\n----------------------------------------\n\nTITLE: API Key Expiration Error Response in Bash\nDESCRIPTION: Example of a 401 HTTP response when an API key has expired, showing the authentication failure error message\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-api-key.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nHTTP/2 401\ndate: Mon, 05 Sep 2023 02:50:52 GMT\ncontent-type: application/json\ncontent-length: 420\nx-debug-trace-id: 202309040250529dcdf2055e7b2ae5e9\nx-kong-response-latency: 1\nserver: kong/2.8.1\n\n{\"data\":{\"result\":{\"start_ms\":0,\"end_ms\":0,\"latency\":\"\",\"row_affect\":0,\"limit\":0,\"code\":49900002,\"message\":\"API Key is no longer valid\",\"row_count\":0}},\"columns\":[],\"rows\":[],\"type\":\"\"}\n```\n\n----------------------------------------\n\nTITLE: Response After Document Deletion\nDESCRIPTION: Shows the expected output after deleting a document, resulting in an empty response because the document containing the relevant information has been removed from the vector store.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_16\n\nLANGUAGE: plain\nCODE:\n```\nEmpty Response\n```\n\n----------------------------------------\n\nTITLE: Modifying Global Configuration in TiDB Cluster\nDESCRIPTION: This snippet shows the global configuration section of a TiDB cluster. The 'pd_mode: ms' line should be removed to switch from microservices mode to regular mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_14\n\nLANGUAGE: ini\nCODE:\n```\nglobal:\n  user: tidb\n   ssh_port: 22\n   listen_host: 0.0.0.0\n   deploy_dir: /tidb-deploy\n   data_dir: /tidb-data\n   os: linux\n   arch: amd64\n   systemd_mode: system\n```\n\n----------------------------------------\n\nTITLE: Verifying Default Firewall Zone Configuration\nDESCRIPTION: Command to check the current default firewall zone, which should be 'trusted' if the previous command was successful.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nfirewall-cmd --get-default-zone\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for TiDB Vector with peewee\nDESCRIPTION: Commands to install required Python packages for the TiDB Vector with peewee project. Provides two options: installing from requirements.txt or installing packages individually.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-peewee.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install peewee pymysql python-dotenv tidb-vector\n```\n\n----------------------------------------\n\nTITLE: Defining Master Key for Encryption\nDESCRIPTION: Specifies the master key to be used when encryption is enabled for data, essential for data security.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_12\n\nLANGUAGE: TOML\nCODE:\n```\n\"security.encryption.master-key = \\\"my_master_key\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Specification of TLS Object Fields - TOML\nDESCRIPTION: This section details the various fields that can be configured within TLS objects. It includes parameters like `ca`, `cert`, `key`, and others that influence the TLS behavior in client and server contexts, outlining their purposes and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-configuration.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n+ `ca`: specifies the CA\n+ `cert`: specifies the certificate\n+ `key`: specifies the private key\n+ `cert-allowed-cn`: when other components connect to TiProxy with TLS, TiProxy can prevent unauthorized access by verifying the `Common Name` in the caller's certificate. This item specifies a list of `Common Name` of valid callers. After setting this item, this TLS object must enable TLS; otherwise, the item does not take effect. For more information on verifying component caller's identity, see [verify component caller's identity](/enable-tls-between-components.md#verify-component-callers-identity).\n+ `auto-certs`: mostly used for tests. It generates certificates if no certificate or key is specified.\n+ `skip-ca`: skips verifying certificates using CA on client object or skips server-side verification on server object.\n+ `min-tls-version`: sets the minimum TLS version. Possible values are `1.0`、`1.1`、`1.2`, and `1.3`. The default value is `1.2`, which allows v1.2 or higher TLS versions.\n+ `rsa-key-size`: sets the RSA key size when `auto-certs` is enabled.\n+ `autocert-expire-duration`: sets the default expiration duration for auto-generated certificates.\n```\n\n----------------------------------------\n\nTITLE: Uninstalling TiUP\nDESCRIPTION: This snippet provides the command to completely uninstall TiUP from the system, effectively cleaning up all associated files and directories.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\nrm -rf ~/.tiup\n```\n\n----------------------------------------\n\nTITLE: RocksDB Sync and Logging Configuration\nDESCRIPTION: Settings for file synchronization intervals and logging behavior in RocksDB, including WAL sync frequency and log file management parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_22\n\nLANGUAGE: yaml\nCODE:\n```\nbytes-per-sync: \"1MiB\"\nwal-bytes-per-sync: \"512KiB\"\ninfo-log-max-size: \"1GiB\"\ninfo-log-roll-time: \"0s\"\ninfo-log-keep-log-file-num: 10\ninfo-log-dir: \"\"\ninfo-log-level: \"info\"\n```\n\n----------------------------------------\n\nTITLE: Creating table with multi-valued index\nDESCRIPTION: This SQL code creates a table `t5` with two JSON columns, `j1` and `j2`, and defines a multi-valued index `idx1` on the `j1` column by casting it as a signed array.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t5 (j1 JSON, j2 JSON, INDEX idx1((CAST(j1 AS SIGNED ARRAY))));\n```\n\n----------------------------------------\n\nTITLE: Forcing TiDB Cluster Back to Normal Mode\nDESCRIPTION: Command to force the TiDB cluster to return to normal mode from import mode, which resolves performance issues after an abnormal TiDB Lightning exit.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/troubleshoot-tidb-lightning.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntidb-lightning-ctl --config tidb-lightning.toml --fetch-mode\n```\n\n----------------------------------------\n\nTITLE: SQL Statement Classification Example\nDESCRIPTION: Demonstrates how TiDB Dashboard classifies similar SQL queries with different parameters as the same statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-statement-list.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM employee WHERE id IN (1, 2, 3)\n```\n\nLANGUAGE: sql\nCODE:\n```\nselect * from EMPLOYEE where ID in (4, 5)\n```\n\nLANGUAGE: sql\nCODE:\n```\nselect * from employee where id in (...)\n```\n\n----------------------------------------\n\nTITLE: Using TiUP DM Command in Shell\nDESCRIPTION: The basic syntax for using the TiUP DM component to manage DM clusters. The command allows specifying various operations and flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm [command] [flags]\n```\n\n----------------------------------------\n\nTITLE: Creating Secondary Index During Table Creation in SQL\nDESCRIPTION: SQL syntax for creating a secondary index while creating a new table in TiDB. Uses the KEY keyword within CREATE TABLE statement to define the index.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-secondary-indexes.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nKEY `{index_name}` (`{column_names}`)\n```\n\n----------------------------------------\n\nTITLE: Defining Show Index Statement in EBNF\nDESCRIPTION: The EBNF diagram defines the syntax for the SHOW INDEXES statement in TiDB, which is used for displaying the indexes of a specified table. It optionally includes schema name and filtering using LIKE or WHERE clauses. The main purpose of this code snippet is to outline the structure of the SQL statement in a formal grammar.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-indexes.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowIndexStmt ::= \"SHOW\" ( \"INDEX\" | \"INDEXES\" | \"KEYS\" ) (\"FROM\" | \"IN\" ) TableName ((\"FROM\" | \"IN\") SchemaName )? ShowLikeOrWhere?\n\nShowLikeOrWhere ::= \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Resolving Expression Results with Plan Cache in TiDB\nDESCRIPTION: Fixes incorrect results of some expressions when the plan cache is enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\n-- Example of an affected expression\nSELECT * FROM table WHERE complex_expression\n```\n\n----------------------------------------\n\nTITLE: Displaying Traffic Jobs in SQL\nDESCRIPTION: This SQL snippet shows how to use the SHOW TRAFFIC JOBS command to display current traffic capture or replay jobs in TiDB. It displays information such as start time, instance, type, progress, and status of the jobs.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-cancel-traffic-jobs.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TRAFFIC JOBS;\n```\n\n----------------------------------------\n\nTITLE: Deploying Netlify Edge Function (Shell)\nDESCRIPTION: This shell command deploys the edge function to Netlify. It uses the '--prod' flag to deploy to the production environment and '--trigger' to trigger a new build and deploy.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nnetlify deploy --prod --trigger\n```\n\n----------------------------------------\n\nTITLE: Security Configuration Properties\nDESCRIPTION: Security-related configuration options including certificate paths and log redaction settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tso-configuration-file.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nsecurity:\n  cacert-path: \"\"\n  cert-path: \"\"\n  key-path: \"\"\n  redact-info-log: false\n```\n\n----------------------------------------\n\nTITLE: Checking the Current DM Version\nDESCRIPTION: Command to verify the current version of DM software before applying a hotfix. This helps ensure compatibility with the prepared hotfix package.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-patch.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n/home/tidb/dm/deploy/dm-master-8261/bin/dm-master/dm-master -V\n```\n\n----------------------------------------\n\nTITLE: Stopping and Removing Docker Containers\nDESCRIPTION: Commands to stop and remove Docker containers, and return to the previous directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose down\ncd -\n```\n\n----------------------------------------\n\nTITLE: Setting Remote TiUP Mirror URL\nDESCRIPTION: Command to configure TiUP to use a custom HTTP server as the mirror source for component downloads and management.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-terminology-and-concepts.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nTIUP_MIRRORS=https://private-mirrors.example.com tiup list\n```\n\n----------------------------------------\n\nTITLE: Error Demonstration for Invalid Default Role\nDESCRIPTION: SQL command showing the error when attempting to set a default role that hasn't been granted.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-default-role.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSET DEFAULT ROLE analyticsteam TO jennifer;\nERROR 3530 (HY000): `analyticsteam`@`%` is is not granted to jennifer@%\n```\n\n----------------------------------------\n\nTITLE: Compacting TiFlash Replicas for Specific Partitions\nDESCRIPTION: SQL statement to manually trigger compaction only for the TiFlash replicas of specific partitions (pNorth and pEast) in the 'employees' table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table-compact.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE employees COMPACT PARTITION pNorth, pEast TIFLASH REPLICA;\n```\n\n----------------------------------------\n\nTITLE: Applying Hotfix Packages to TiDB Cluster\nDESCRIPTION: Commands to replace running components with temporary hotfix packages for debugging purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/maintain-tidb-using-tiup.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster patch test-cluster /tmp/tidb-hotfix.tar.gz -R tidb\ntiup cluster patch test-cluster /tmp/tidb-hotfix.tar.gz -N 172.16.4.5:4000\n```\n\n----------------------------------------\n\nTITLE: Pause Replication Task\nDESCRIPTION: HTTP POST request to pause a specific replication task.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://127.0.0.1:8300/api/v2/changefeeds/test1/pause\n```\n\n----------------------------------------\n\nTITLE: Configuring Grafana Servers with Dashboard Directory in YAML\nDESCRIPTION: Example configuration for grafana_servers showing basic Grafana setup with host specification and custom dashboard directory configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_16\n\nLANGUAGE: yaml\nCODE:\n```\ngrafana_servers:\n  - host: 10.0.1.11\n    dashboard_dir: /local/dashboard/dir\n```\n\n----------------------------------------\n\nTITLE: Cloning TiUP Mirror Using Shell\nDESCRIPTION: This shell snippet demonstrates the use of the `tiup mirror clone` command to clone an existing mirror or some of its components into a new location with a different signature key. The required dependency is TiUP, and key parameters include `<target-dir>`, `[global version]`, and various flags for customization like `-f`, `-a`, `-o`, and `--prefix`. Inputs are mirror specifications and outputs are mirror copies written to the target directory. There are constraints when using the `--full` flag, as it overrides other options.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-clone.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror clone <target-dir> [global version] [flags]\n```\n\n----------------------------------------\n\nTITLE: Showing Import Jobs - SQL\nDESCRIPTION: This SQL command retrieves all import jobs associated with the user. It requires the proper privileges depending on the user's permission level.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-import-job.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW IMPORT JOBS;\n```\n\n----------------------------------------\n\nTITLE: Checking Socket Receive Queue Status\nDESCRIPTION: Command to monitor application socket receive queues, useful for detecting if sockets are filling up and potentially causing packet loss.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nss -nmp\n```\n\n----------------------------------------\n\nTITLE: Defining LONGBLOB Column in TiDB\nDESCRIPTION: Syntax for creating a LONGBLOB column supporting up to 4,294,967,295 bytes.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nLONGBLOB\n```\n\n----------------------------------------\n\nTITLE: Converting Character Set using CONVERT\nDESCRIPTION: Shows how to convert a hex literal to a string using a specific character set (utf8mb4) with the CONVERT function\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/cast-functions-and-operators.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CONVERT(0x616263 USING utf8mb4);\n```\n\n----------------------------------------\n\nTITLE: Configuring PiTR Log Backup RPO Alert in YAML\nDESCRIPTION: YAML configuration for setting up Point-in-Time Recovery (PiTR) log backup RPO monitoring alert. Triggers a warning when the log backup RPO exceeds 10 minutes.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-monitoring-and-alert.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ngroups:\n- name: PiTR\n  rules:\n  - alert: LogBackupRunningRPOMoreThan10m\n    expr: max(time() - tidb_log_backup_last_checkpoint / 262144000) by (task) / 60 > 10 and max(tidb_log_backup_last_checkpoint) by (task) > 0 and max(tikv_log_backup_task_status) by (task) == 0\n    labels:\n      severity: warning\n    annotations:\n      summary: RPO of log backup is high\n      message: RPO of the log backup task {{ $labels.task }} is more than 10m\n```\n\n----------------------------------------\n\nTITLE: Setting an HTTP Mirror\nDESCRIPTION: This command configures TiUP to use a mirror available over HTTP/HTTPS, allowing network distribution of the mirror.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntiup mirror set https://tiup-mirror.example.com/\n```\n\n----------------------------------------\n\nTITLE: Sink URI Example for Amazon S3\nDESCRIPTION: Basic sink URI configuration for Amazon S3 storage service, specifying the bucket, prefix, and protocol for data replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"s3://bucket/prefix?protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: Update Replication Task Target TS\nDESCRIPTION: HTTP PUT request to update the target_ts parameter of a replication task to 32.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X PUT -H \"'Content-type':'application/json'\" http://127.0.0.1:8300/api/v2/changefeeds/test1 -d '{\"target_ts\":32}'\n```\n\n----------------------------------------\n\nTITLE: Connecting as User Jennifer\nDESCRIPTION: Shell command showing how to connect to a TiDB server as the jennifer user after the role has been assigned.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-grant-role.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 127.0.0.1 -P 4000 -u jennifer\n```\n\n----------------------------------------\n\nTITLE: Converting DM-Ansible Worker Configuration to v2.0+ Source Configuration\nDESCRIPTION: This snippet demonstrates how to convert the dm_worker_servers configuration from the inventory.ini file in v1.0.x to individual source configuration files in YAML format for v2.0+.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/manually-upgrade-dm-1.0-to-2.0.md#2025-04-18_snippet_0\n\nLANGUAGE: INI\nCODE:\n```\n[dm_master_servers]\ndm_worker1 ansible_host=172.16.10.72 server_id=101 source_id=\"mysql-replica-01\" mysql_host=172.16.10.81 mysql_user=root mysql_password='VjX8cEeTX+qcvZ3bPaO4h0C80pe/1aU=' mysql_port=3306\ndm_worker2 ansible_host=172.16.10.73 server_id=102 source_id=\"mysql-replica-02\" mysql_host=172.16.10.82 mysql_user=root mysql_password='VjX8cEeTX+qcvZ3bPaO4h0C80pe/1aU=' mysql_port=3306\n```\n\nLANGUAGE: YAML\nCODE:\n```\nserver-id: 101\nsource-id: \"mysql-replica-01\"\nfrom:\n  host: \"172.16.10.81\"\n  port: 3306\n  user: \"root\"\n  password: \"VjX8cEeTX+qcvZ3bPaO4h0C80pe/1aU=\"\n```\n\nLANGUAGE: YAML\nCODE:\n```\nserver-id: 102\nsource-id: \"mysql-replica-02\"\nfrom:\n  host: \"172.16.10.82\"\n  port: 3306\n  user: \"root\"\n  password: \"VjX8cEeTX+qcvZ3bPaO4h0C80pe/1aU=\"\n```\n\n----------------------------------------\n\nTITLE: Example CSV Content for TiDB Lightning Import\nDESCRIPTION: Sample CSV content demonstrating the format expected by TiDB Lightning with headers, quoted strings, and null values.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_6\n\nLANGUAGE: csv\nCODE:\n```\nID,Region,Count\n1,\"East\",32\n2,\"South\",\\N\n3,\"West\",10\n4,\"North\",39\n```\n\n----------------------------------------\n\nTITLE: Deploy Specific TiDB Version\nDESCRIPTION: Command to deploy a TiDB cluster of a specific version.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground ${version}\n```\n\n----------------------------------------\n\nTITLE: Installing peewee for Python\nDESCRIPTION: Command to install peewee version 3.15.4 using pip. This version or later is recommended for use with TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-choose-driver-or-orm.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npip install peewee==3.15.4\n```\n\n----------------------------------------\n\nTITLE: Checking Cluster Status with Terraform State Show\nDESCRIPTION: This snippet illustrates how to check the current status of a TiDB Cloud cluster using the 'terraform state show' command for an existing cluster marked as paused.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform state show tidbcloud_cluster.example_cluster\n\n# tidbcloud_cluster.example_cluster:\nresource \"tidbcloud_cluster\" \"example_cluster\" {\n    cloud_provider = \"AWS\"\n    cluster_type   = \"DEDICATED\"\n    config         = {\n        components     = {\n            tidb    = {\n                node_quantity = 2\n                node_size     = \"8C16G\"\n            }\n            tiflash = {\n                node_quantity    = 2\n                node_size        = \"8C64G\"\n                storage_size_gib = 500\n            }\n            tikv    = {\n                node_quantity    = 6\n                node_size     = \"8C32G\"\n                storage_size_gib = 500\n            }\n        }\n        ip_access_list = [\n            # (1 unchanged element hidden)\n        ]\n        paused         = true\n        port           = 4000\n        root_password  = \"Your_root_password1.\"\n    }\n    id             = \"1379661944630234067\"\n    name           = \"firstCluster\"\n    project_id     = \"1372813089189561287\"\n    region         = \"eu-central-1\"\n    status         = \"PAUSED\"\n}\n```\n\n----------------------------------------\n\nTITLE: Granting Upstream Privileges for DM-worker in SQL\nDESCRIPTION: This SQL snippet grants the necessary privileges to the upstream MySQL/MariaDB user to allow DM-worker to migrate data from a specific database to TiDB. It includes `RELOAD`, `REPLICATION SLAVE`, and `REPLICATION CLIENT` privileges at the global level, and `SELECT` privilege on the target database.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-worker-intro.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nGRANT RELOAD,REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'your_user'@'your_wildcard_of_host';\nGRANT SELECT ON db1.* TO 'your_user'@'your_wildcard_of_host';\n```\n\n----------------------------------------\n\nTITLE: Retrieving Schema Names for a Task and Source (Shell)\nDESCRIPTION: This snippet shows how to use cURL to get a list of schema names associated with a specific replication task and source. It sends a GET request to the API endpoint and expects a JSON array response containing schema names.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_39\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1/sources/source-1/schemas' \\\n  -H 'accept: application/json'\n```\n\nLANGUAGE: json\nCODE:\n```\n[\n  \"db1\"\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring Basic Shard Merge Task Parameters in YAML\nDESCRIPTION: This snippet shows the minimal configuration required to set up a shard merge task in DM, specifically highlighting the shard-mode parameter which must be explicitly configured for sharding DDL migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-task-configuration-guide.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n---\n\n## ********* Basic information *********\nname: test                      # The name of the task. Should be globally unique.\nshard-mode: \"pessimistic\"       # The shard merge mode. Optional modes are \"\"/\"pessimistic\"/\"optimistic\". The \"\" mode is used by default which means sharding DDL merge is disabled. If the task is a shard merge task, set it to the \"pessimistic\" mode. After getting a deep understanding of the principles and restrictions of the \"optimistic\" mode, you can set it to the \"optimistic\" mode.\n```\n\n----------------------------------------\n\nTITLE: Parsing TiDB Slow Logs with pt-query-digest\nDESCRIPTION: Shell command to use the pt-query-digest tool to analyze TiDB slow query logs.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\npt-query-digest --report tidb-slow.log\n```\n\n----------------------------------------\n\nTITLE: Creating and Analyzing a Table in SQL\nDESCRIPTION: This snippet demonstrates creating a table and analyzing it in MySQL, applicable to TiDB as well. It includes steps to create a table, insert data, and execute ANALYZE TABLE, noting that its behavior is consistent when statistics aren't locked.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-locked.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t(a INT, b INT);\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> INSERT INTO t VALUES (1,2), (3,4), (5,6), (7,8);\nQuery OK, 4 rows affected (0.00 sec)\nRecords: 4  Duplicates: 0  Warnings: 0\n\nmysql> ANALYZE TABLE t;\nQuery OK, 0 rows affected, 1 warning (0.02 sec)\n\nmysql> SHOW WARNINGS;\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Level | Code | Message                                                                                                                                                                                                               |\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Note  | 1105 | Analyze use auto adjusted sample rate 1.000000 for table test.t, reason to use this rate is \"Row count in stats_meta is much smaller compared with the row count got by PD, use min(1, 15000/4) as the sample-rate=1\" |\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Continuing an Optimistic Transaction Before Commit\nDESCRIPTION: This snippet shows additional operations in an optimistic transaction before committing, where constraints are not yet checked.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO users (username) VALUES ('steve'),('elizabeth');\n```\n\n----------------------------------------\n\nTITLE: Setting Data Volume for Tables\nDESCRIPTION: This snippet illustrates how to set the data volume for various tables in the Bookshop application when using TiUP. It specifies the number of rows to generate for users, authors, books, orders, and ratings.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-bookshop-schema-design.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup demo bookshop prepare --users=200000 --books=500000 --authors=100000 --ratings=1000000 --orders=1000000 --drop-tables\n```\n\n----------------------------------------\n\nTITLE: Basic Table Route Configuration in TOML\nDESCRIPTION: Basic configuration example showing how to set up data source connections and route rules for comparing tables with different names between MySQL and TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/route-diff.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n######################### Datasource config #########################\n[data-sources.mysql1]\n    host = \"127.0.0.1\"\n    port = 3306\n    user = \"root\"\n    password = \"\"\n    route-rules = [\"rule1\"]\n\n[data-sources.tidb0]\n    host = \"127.0.0.1\"\n    port = 4000\n    user = \"root\"\n    password = \"\"\n########################### Routes ###########################\n[routes.rule1]\nschema-pattern = \"test_1\"      # Matches the schema name of the data source. Supports the wildcards \"*\" and \"?\"\ntable-pattern = \"t_1\"          # Matches the table name of the data source. Supports the wildcards \"*\" and \"?\"\ntarget-schema = \"test_2\"       # The name of the schema in the target database\ntarget-table = \"t_2\"           # The name of the target table\n```\n\n----------------------------------------\n\nTITLE: Get TiCDC Node Status Example\nDESCRIPTION: Example curl request and JSON response for getting status information of a TiCDC node including version, process details and owner status.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v2/status\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"version\": \"v8.5.0\",\n  \"git_hash\": \"10413bded1bdb2850aa6d7b94eb375102e9c44dc\",\n  \"id\": \"d2912e63-3349-447c-90ba-72a4e04b5e9e\",\n  \"pid\": 1447,\n  \"is_owner\": true,\n  \"liveness\": 0\n}\n```\n\n----------------------------------------\n\nTITLE: Upgrading TiDB Cluster Offline\nDESCRIPTION: Command to upgrade TiDB cluster without restart, only updating files using TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash-upgrade-guide.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster upgrade <cluster-name> <version> --offline\n```\n\n----------------------------------------\n\nTITLE: TiDB Lightning Scheduling Configuration\nDESCRIPTION: Enhanced configuration for global scheduling control in TiDB Lightning. Introduces new parameter `pause-pd-scheduler-scope` with version-specific behaviors and compatibility considerations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.1.0.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n* TiDB Lightning in TiDB versions from v6.2.0 to v7.0.0 decides whether to pause global scheduling based on the TiDB cluster version.\n```\n\n----------------------------------------\n\nTITLE: Connect to TiDB Cluster\nDESCRIPTION: Command to connect to a local TiDB cluster using TiUP client component.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntiup client\n```\n\n----------------------------------------\n\nTITLE: Displaying Resume Task Help Command\nDESCRIPTION: Shows the help information for the resume-task command including usage and available flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-resume-task.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhelp resume-task\n```\n\n----------------------------------------\n\nTITLE: Official Canal Update Event Message Structure\nDESCRIPTION: JSON representation of an update event message in the official Canal, showing only modified column data in the 'old' field\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\\n    \"id\": 0,\\n    \"type\": \"UPDATE\",\\n    \"data\": [\\n        {\\n            \"c_bigint\": \"9223372036854775807\",\\n            \"c_int\": \"0\",\\n            \"c_mediumint\": \"8388607\",\\n            \"c_smallint\": \"32767\",\\n            \"c_tinyint\": \"0\",\\n            \"id\": \"2\"\\n        }\\n    ],\\n    \"old\": [\\n        {\\n            \"c_int\": \"2147483647\",\\n            \"c_tinyint\": \"127\"\\n        }\\n    ]\\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Index with Batch Size 1024\nDESCRIPTION: Performance test configuration using tidb_ddl_reorg_batch_size=1024 with varying worker counts. Shows improved index creation speed with moderate impact on performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/online-workloads-and-add-index-operations.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\ntidb_ddl_reorg_batch_size = 1024\n```\n\n----------------------------------------\n\nTITLE: Truncate Values in TiDB\nDESCRIPTION: Demonstrates truncating numeric values in both Oracle and TiDB, showing precision preservation without rounding.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nTRUNC(2.136) = 2\nTRUNC(2.136,2) = 2.13\n```\n\nLANGUAGE: sql\nCODE:\n```\nTRUNCATE(2.136,0) = 2\nTRUNCATE(2.136,2) = 2.13\n```\n\n----------------------------------------\n\nTITLE: Resource Usage Alerts Table in Markdown\nDESCRIPTION: Markdown table showing resource usage alert conditions and recommended actions for TiDB Cloud monitoring\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/monitor-built-in-alerting.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Condition | Recommended Action |\n|:--- |:--- |\n| Total TiDB node memory utilization across cluster exceeded 70% for 10 minutes | Consider increasing the node number or node size for TiDB to reduce the memory usage percentage of the current workload.|\n| Total TiKV node memory utilization across cluster exceeded 70% for 10 minutes | Consider increasing the node number or node size for TiKV to reduce the memory usage percentage of the current workload. |\n```\n\n----------------------------------------\n\nTITLE: Using TIDB_PARSE_TSO_LOGICAL to Extract Logical Component\nDESCRIPTION: Demonstrates using TIDB_PARSE_TSO_LOGICAL function to extract the logical counter component from a TSO timestamp. This example shows the logical part of a specified TSO value.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_PARSE_TSO_LOGICAL(450456244814610433);\n```\n\n----------------------------------------\n\nTITLE: IndexJoin Example in Static Mode\nDESCRIPTION: Shows how IndexJoin works in static mode with partitioned tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_77\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t1 (id int, age int, key(id)) partition by range(id)\n    (partition p0 values less than (100),\n     partition p1 values less than (200),\n     partition p2 values less than (300),\n     partition p3 values less than (400));\ncreate table t2 (id int, code int);\nset @@tidb_partition_prune_mode = 'static';\nexplain select /*+ TIDB_INLJ(t1, t2) */ t1.* from t1, t2 where t2.code = 0 and t2.id = t1.id;\n```\n\n----------------------------------------\n\nTITLE: Configuring Pump GC Strategy in TiDB Ansible\nDESCRIPTION: Sets the 'stop-write-at-available-space' parameter in Pump to stop writing binlog files when available disk space is low. This helps prevent resource exhaustion.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.1.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nstop-write-at-available-space: 10GiB\n```\n\n----------------------------------------\n\nTITLE: TiFlash Version Log Example\nDESCRIPTION: Example of TiFlash version information as it appears in the log files. Shows the version number and build details.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/maintain-tiflash.md#2025-04-18_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n<information>: TiFlash version: TiFlash 0.2.0 master-375035282451103999f3863c691e2fc2\n```\n\n----------------------------------------\n\nTITLE: Showing Regions of a Table in SQL\nDESCRIPTION: This SQL snippet retrieves and displays the regions of the partitioned table 't', providing details like region ID, start and end keys, leader ID, and more for each region.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLE t REGIONS;\n```\n\n----------------------------------------\n\nTITLE: Status Code 401 Response Example\nDESCRIPTION: This code snippet shows a Data Service response with an HTTP status code of 401, signifying authentication failure due to insufficient permissions.  The `result.code` is also 401, and the `message` field contains \"auth failed\". This response indicates that the request lacks the necessary credentials to access the requested resource.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"sql_endpoint\",\n    \"data\": {\n        \"columns\": [],\n        \"rows\": [],\n        \"result\": {\n            \"code\": 401,\n            \"message\": \"auth failed\",\n            \"start_ms\": \"\",\n            \"end_ms\": \"\",\n            \"latency\": \"\",\n            \"row_count\": 0,\n            \"row_affect\": 0,\n            \"limit\": 0\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: MyBatis Stream Reading XML Configuration\nDESCRIPTION: XML configuration for enabling streaming result sets in MyBatis using fetchSize parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_10\n\nLANGUAGE: xml\nCODE:\n```\n<select id=\"getAll\" resultMap=\"postResultMap\" fetchSize=\"-2147483648\">\n  select * from post;\n</select>\n```\n\n----------------------------------------\n\nTITLE: Encoding DML Event Key Format - JSON\nDESCRIPTION: This JSON structure represents the key format for a DML event in TiCDC, including schema information about primary key or unique index columns. The schema includes fields such as `tiny`, which is an optional int16 type column.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-debezium.md#2025-04-18_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"payload\": {\n        \"tiny\": 1\n    },\n    \"schema\": {\n        \"fields\": [\n        {\n            \"field\":\"tiny\",\n            \"optional\":true,\n            \"type\":\"int16\"\n        }\n        ],\n        \"name\": \"test_cluster.test.table1.Key\",\n        \"optional\": false,\n        \"type\":\"struct\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Index Definition in TiCDC Simple Protocol\nDESCRIPTION: JSON representation of an Index object in TiCDC Simple Protocol. It contains index name, uniqueness flag, primary key flag, nullability, and the columns included in the index.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-simple-protocol.md#2025-04-18_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n        \"name\":\"primary\",\n        \"unique\":true,\n        \"primary\":true,\n        \"nullable\":false,\n        \"columns\":[\n            \"id\"\n        ]\n}\n```\n\n----------------------------------------\n\nTITLE: JSON Attribute Functions\nDESCRIPTION: Functions that return attributes of JSON values such as depth, length, type, and validity.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nJSON_DEPTH()\nJSON_LENGTH()\nJSON_TYPE()\nJSON_VALID()\n```\n\n----------------------------------------\n\nTITLE: Configuring Log Redaction in Security Settings\nDESCRIPTION: Controls whether log redaction is enabled to protect sensitive information, with specific options for redaction behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_9\n\nLANGUAGE: TOML\nCODE:\n```\n\"security.redact-info-log = true\"\n```\n\n----------------------------------------\n\nTITLE: Analyzing Hot Region Distribution by Store in SQL\nDESCRIPTION: This SQL query counts hot regions grouped by store_id for a specific table and time range. It helps analyze the distribution of hot regions across different stores.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-hot-regions-history.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT count(region_id) cnt, store_id FROM INFORMATION_SCHEMA.TIDB_HOT_REGIONS_HISTORY WHERE update_time >'2021-08-18 21:40:00' and update_time <'2021-09-19 00:00:00' and table_name = 'table_name' GROUP BY STORE_ID ORDER BY cnt DESC;\n```\n\n----------------------------------------\n\nTITLE: Normalization IN Predicate Binding Example\nDESCRIPTION: This example demonstrates how a binding can be created to apply to `IN` predicates of different lengths due to the normalization process. It shows that after creating the binding, both `SELECT * FROM t WHERE a IN (1)` and `SELECT * FROM t WHERE a IN (1, 2, 3)` will use the created binding.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a INT, KEY(a));\nCREATE BINDING FOR SELECT * FROM t WHERE a IN (?) USING SELECT /*+ use_index(t, idx_a) */ * FROM t WHERE a in (?);\n\nSELECT * FROM t WHERE a IN (1);\nSELECT @@LAST_PLAN_FROM_BINDING;\n+--------------------------+\n| @@LAST_PLAN_FROM_BINDING |\n+--------------------------+\n|                        1 |\n+--------------------------+\n\nSELECT * FROM t WHERE a IN (1, 2, 3);\nSELECT @@LAST_PLAN_FROM_BINDING;\n+--------------------------+\n| @@LAST_PLAN_FROM_BINDING |\n+--------------------------+\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in TiDB\nDESCRIPTION: This SQL snippet creates a table named 't' with a single integer column 'c'. It sets up the database for further operations. No external dependencies are required.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-external-ts.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (c INT);\n```\n\n----------------------------------------\n\nTITLE: Modifying TiCDC Configuration in a Server Config File\nDESCRIPTION: YAML configuration showing how to modify TiCDC settings in the server_configs section, specifically changing the gc-ttl parameter from the default 86400 to 172800 seconds (48 hours).\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/deploy-ticdc.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nserver_configs:\n  tidb: {}\n  tikv: {}\n  pd: {}\n  tiflash: {}\n  tiflash-learner: {}\n  cdc:\n    gc-ttl: 172800\n```\n\n----------------------------------------\n\nTITLE: Listing All Data Sources in TiDB Data Migration\nDESCRIPTION: This example shows how to list all configured data sources in TiDB Data Migration. It uses the operate-source show command to display information about all sources and their associated workers.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-manage-source.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\noperate-source show\n```\n\n----------------------------------------\n\nTITLE: Setting Default Role to All for a User in TiDB\nDESCRIPTION: This snippet shows how to set the default role to ALL for the user `rw_user1'@'localhost`, meaning all roles granted to that user will be enabled by default upon login.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nSET DEFAULT ROLE ALL TO 'rw_user1'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_max_dist_task_nodes for Distributed Execution\nDESCRIPTION: Defines the maximum number of TiDB nodes that Distributed eXecution Framework (DXF) tasks can use. The default -1 enables automatic mode, calculating based on TiKV nodes in the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_48\n\nLANGUAGE: SQL\nCODE:\n```\nSET [SESSION | GLOBAL] tidb_max_dist_task_nodes = <value>;\n```\n\n----------------------------------------\n\nTITLE: Scheduling Table to Different Node using TiCDC API\nDESCRIPTION: cURL command to move a table (ID: 49) to a specific capture node in a TiCDC changefeed. Uses POST request to the move_table endpoint with JSON payload containing capture_id and table_id.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST -H \"'Content-type':'application/json'\" http://127.0.0.1:8300/api/v1/changefeeds/changefeed-test1/tables/move_table -d '{\"capture_id\":\"6f19a6d9-0f8c-4dc9-b299-3ba7c0f216f5\",\"table_id\":49}'\n```\n\n----------------------------------------\n\nTITLE: Running Airbyte Docker Containers\nDESCRIPTION: Start the Airbyte application using Docker Compose.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-airbyte.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker-compose up\n```\n\n----------------------------------------\n\nTITLE: CHECK_CONSTRAINTS Table Structure Output\nDESCRIPTION: Displays the field definitions of the CHECK_CONSTRAINTS table, showing column names, data types, and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-check-constraints.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------+-------------+------+-----+---------+-------+\n| Field              | Type        | Null | Key | Default | Extra |\n+--------------------+-------------+------+-----+---------+-------+\n| CONSTRAINT_CATALOG | varchar(64) | NO   |     | NULL    |       |\n| CONSTRAINT_SCHEMA  | varchar(64) | NO   |     | NULL    |       |\n| CONSTRAINT_NAME    | varchar(64) | NO   |     | NULL    |       |\n| CHECK_CLAUSE       | longtext    | NO   |     | NULL    |       |\n+--------------------+-------------+------+-----+---------+-------+\n4 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Basic PITR Restore Command Example\nDESCRIPTION: Demonstrates a basic PITR restore operation using BR tool with S3 storage for both log backup and full backup data.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore point --pd=\"${PD_IP}:2379\" \n--storage='s3://backup-101/logbackup?access-key=${access-key}&secret-access-key=${secret-access-key}' \n--full-backup-storage='s3://backup-101/snapshot-202205120000?access-key=${access-key}&secret-access-key=${secret-access-key}'\n```\n\n----------------------------------------\n\nTITLE: Connecting as User Jennifer\nDESCRIPTION: Shell command to connect to TiDB as the newly created jennifer user.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-default-role.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 127.0.0.1 -P 4000 -u jennifer\n```\n\n----------------------------------------\n\nTITLE: Configuring OAuth2 Authentication Parameters for Pulsar in TiCDC\nDESCRIPTION: This TOML snippet demonstrates configuring the OAuth2 authentication parameters for Pulsar in TiCDC. It includes the issuer URL, audience, private key path, client ID, and scope.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_15\n\nLANGUAGE: toml\nCODE:\n```\n[sink.pulsar-config]\n# Pulsar oauth2 issuer-url. For more information, see the Pulsar website: https://pulsar.apache.org/docs/2.10.x/client-libraries-go/#oauth2-authentication\noauth2.oauth2-issuer-url=\"https://xxxx.auth0.com\"\n# Pulsar oauth2 audience\noauth2.oauth2-audience=\"https://xxxx.auth0.com/api/v2/\"\n# Pulsar oauth2 private-key\noauth2.oauth2-private-key=\"/data/pulsar/privateKey\"\n# Pulsar oauth2 client-id\noauth2.oauth2-client-id=\"0Xx...Yyxeny\"\n# Pulsar oauth2 oauth2-scope\noauth2.oauth2-scope=\"xxxx\"\n```\n\n----------------------------------------\n\nTITLE: Decoding Column Flag Example 1 (Binary Representation)\nDESCRIPTION: Example showing how to decode a column flag value of 85 into its component flags using binary representation. The example demonstrates that such a column is a nullable column, a unique index column, a generated column, and a binary-encoded column.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_10\n\nLANGUAGE: plaintext\nCODE:\n```\n85 == 0b_101_0101\n   == NullableFlag | UniqueKeyFlag | GeneratedColumnFlag | BinaryFlag\n```\n\n----------------------------------------\n\nTITLE: Searching Documents Within a Distance Threshold\nDESCRIPTION: Python code for finding documents whose embeddings are within a specified cosine distance threshold from a query vector. Returns documents with a distance less than 0.2.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-peewee.md#2025-04-18_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndistance_expression = Document.embedding.cosine_distance([1, 2, 3])\ndistance = distance_expression.alias('distance')\nresults = Document.select(Document, distance).where(distance_expression < 0.2).order_by(distance).limit(3)\n```\n\n----------------------------------------\n\nTITLE: Using jstack Command\nDESCRIPTION: Command to output thread IDs and stack information of all threads in a Java process. The -m option can be added to include C++ stack information from the JVM.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\njstack pid\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Comment in TiDB SQL\nDESCRIPTION: SQL statements to create a new user 'newuser6' with a comment and verify the comment in the information_schema in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser6'@'%' COMMENT 'This user is created only for test';\nSELECT * FROM information_schema.user_attributes;\n```\n\n----------------------------------------\n\nTITLE: Updating TiDB Cloud CLI using Shell\nDESCRIPTION: This shell snippet demonstrates how to update the TiDB Cloud CLI to the latest version by using the 'ticloud update' command. The command can accept various flags such as '-h' for help. This operation requires no additional dependencies and outputs the updated state of the CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-update.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud update [flags]\n```\n\n----------------------------------------\n\nTITLE: Resolving INFORMATION_SCHEMA.PROCESSLIST Query Panic in TiDB\nDESCRIPTION: Addresses a potential panic when executing SELECT * FROM INFORMATION_SCHEMA.PROCESSLIST in certain cases.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_21\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.PROCESSLIST\n```\n\n----------------------------------------\n\nTITLE: Stopping and Removing MySQL on CentOS\nDESCRIPTION: This snippet contains commands to stop the MySQL service and remove it from a CentOS system, ensuring that the database is cleaned up after testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nsudo systemctl stop mysqld\n sudo yum remove -y mysql-community-server\n```\n\n----------------------------------------\n\nTITLE: Customizing Minimum Password Length in TiDB\nDESCRIPTION: This SQL command modifies the minimum required password length in TiDB to 10 characters, ensuring that all future passwords meet this basic length requirement to enhance security.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL validate_password.length = 10;\n```\n\n----------------------------------------\n\nTITLE: Configuring Firewall Rules for TiDB Server\nDESCRIPTION: Commands to set up firewall rules for the TiDB component, opening ports 4000/tcp and 10080/tcp.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nfirewall-cmd --permanent --new-service tidb\nfirewall-cmd --permanent --service tidb --set-description=\"TiDB Server\"\nfirewall-cmd --permanent --service tidb --set-short=\"TiDB\"\nfirewall-cmd --permanent --service tidb --add-port=4000/tcp\nfirewall-cmd --permanent --service tidb --add-port=10080/tcp\nfirewall-cmd --permanent --zone=public --add-service=tidb\n```\n\n----------------------------------------\n\nTITLE: CREATE TABLE LIKE Syntax in EBNF Format\nDESCRIPTION: The formal EBNF syntax diagram for the CREATE TABLE LIKE statement in TiDB, showing the grammar structure including optional temporary tables and if-not-exists conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-table-like.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCreateTableLikeStmt ::=\n    'CREATE' OptTemporary 'TABLE' IfNotExists TableName LikeTableWithOrWithoutParen OnCommitOpt\n\nOptTemporary ::=\n    ( 'TEMPORARY' | ('GLOBAL' 'TEMPORARY') )?\n\nLikeTableWithOrWithoutParen ::=\n    'LIKE' TableName\n|   '(' 'LIKE' TableName ')'\n\nOnCommitOpt ::=\n    ('ON' 'COMMIT' 'DELETE' 'ROWS')?\n```\n\n----------------------------------------\n\nTITLE: Configuring Token Authentication for Pulsar in TiCDC\nDESCRIPTION: This snippet shows how to configure token authentication for Pulsar in TiCDC using the `authentication-token` parameter. The token is directly included in the configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"pulsar://127.0.0.1:6650/persistent://public/default/yktest?protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: Calculating User Response Time in TiDB Cloud\nDESCRIPTION: This snippet presents a formula to calculate total user response time within a specified time range. It uses average TPS and average user response time to determine the total response time, which is crucial for performance analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tune-performance-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nTotal user response time in `ΔT` = Average TPS (Transactions Per Second) x Average user response time x `ΔT`.\n```\n\n----------------------------------------\n\nTITLE: DM Relay Log Restart Commands\nDESCRIPTION: Commands to restart relay log processing in DM to resolve metadata issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-faq.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n» stop-relay -s sourceID workerName\n» start-relay -s sourceID workerName\n```\n\n----------------------------------------\n\nTITLE: Configuring DM Safe Mode in Task Configuration\nDESCRIPTION: Example of how to enable safe mode in the DM task configuration file. The 'safe-mode' parameter is set to true in the syncer configuration to enable safe mode for the entire incremental replication process.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-safe-mode.md#2025-04-18_snippet_1\n\nLANGUAGE: YAML\nCODE:\n```\nsyncers:\n  global:\n    safe-mode: true\nmysql-instances:\n  -\n    source-id: \"mysql-replica-01\"\n    syncer-config-name: \"global\"\n```\n\n----------------------------------------\n\nTITLE: Resolve Error Rows Command in DM\nDESCRIPTION: Command syntax for marking error rows as resolved after manual handling. Supports resolving specific error IDs or all errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-continuous-data-validation.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nUsage:\n  dmctl validation resolve-error <task-name> <error-id|--all> [flags]\n\nFlags:\n      --all    all errors\n      -h, --help   help for resolve-error\n```\n\n----------------------------------------\n\nTITLE: Locating Errors by Byte Position in Shell\nDESCRIPTION: Shell commands to jump to specific byte positions in a file to locate errors reported by TiDB Lightning. These commands help find error locations when only byte offsets (not line numbers) are provided.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nhead -c 183 file.csv | tail\n```\n\nLANGUAGE: shell\nCODE:\n```\ntail -c +183 file.csv | head\n```\n\n----------------------------------------\n\nTITLE: Lock Keys Operation Execution Information\nDESCRIPTION: Performance metrics for lock keys operations in pessimistic transactions, tracking time, regions, keys, and RPC interactions\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n\"lock_keys\": {\"time\":\"94.096168ms\", \"region\":6, \"keys\":8, \"lock_rpc\":\"274.503214ms\", \"rpc_count\":6}\n```\n\n----------------------------------------\n\nTITLE: Log Configuration Parameters\nDESCRIPTION: Configuration settings for log file management including size limits, retention period, and backup counts.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-configuration-file.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nmax-size: 300 # Maximum size of single log file in MiB\nmax-days: 0   # Maximum days to keep logs\nmax-backups: 0 # Maximum number of log files to keep\n```\n\n----------------------------------------\n\nTITLE: Handling SPLIT TABLE Statements (SQL)\nDESCRIPTION: Improves SPLIT TABLE statements to return progress information instead of errors when Region scatter scheduling is not completed within the timeout period.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.16.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSPLIT TABLE table_name BETWEEN (1) AND (100000) REGIONS 16;\n```\n\n----------------------------------------\n\nTITLE: Generating Data Summary with TiDB Cloud Chat2Query API in Bash\nDESCRIPTION: Example of calling the /v3/dataSummaries endpoint to analyze a database and generate a data summary. This request includes the cluster ID, database name, description, and reuse settings for the data summary.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user ${PUBLIC_KEY}:${PRIVATE_KEY} --request POST 'https://<region>.data.tidbcloud.com/api/v1beta/app/chat2query-<ID>/endpoint/v3/dataSummaries'\\\n --header 'content-type: application/json'\\\n --data-raw '{\n    \"cluster_id\": \"10140100115280519574\",\n    \"database\": \"sp500insight\",\n    \"description\": \"Data summary for SP500 Insight\",\n    \"reuse\": false\n}'\n```\n\n----------------------------------------\n\nTITLE: Creating Multi-Valued Index with JSON CAST\nDESCRIPTION: Illustrates creating a multi-valued index by casting JSON array values to unsigned integers, with sample data insertion and query explanation\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/cast-functions-and-operators.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (\n    id INT PRIMARY KEY,\n    j JSON,\n    INDEX idx_a ((CAST(j->'$.a' AS UNSIGNED ARRAY)))\n);\nINSERT INTO t VALUES (1, JSON_OBJECT('a',JSON_ARRAY(1,2,3)));\nINSERT INTO t VALUES (2, JSON_OBJECT('a',JSON_ARRAY(4,5,6)));\nINSERT INTO t VALUES (3, JSON_OBJECT('a',JSON_ARRAY(7,8,9)));\nANALYZE TABLE t;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning for TPC-H DBGEN Import in TOML\nDESCRIPTION: This TOML configuration snippet modifies the CSV section of TiDB Lightning's configuration to handle TPC-H DBGEN formatted files. It sets the pipe separator, no delimiter, and other format-specific options.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-csv-files-to-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: TOML\nCODE:\n```\n[mydumper.csv]\nseparator = '|'\ndelimiter = ''\nheader = false\nnot-null = true\nbackslash-escape = false\ntrim-last-separator = true\n```\n\n----------------------------------------\n\nTITLE: NGINX Configuration Reload\nDESCRIPTION: Command to reload NGINX configuration after making changes\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nsudo nginx -s reload\n```\n\n----------------------------------------\n\nTITLE: DM Task Status Query Result\nDESCRIPTION: Example output of the query-status command showing task information including source status, relay status, and syncer status with GTID details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-faq.md#2025-04-18_snippet_3\n\nLANGUAGE: json\nCODE:\n```\nquery-status test\n{\n    \"sources\": [\n        {\n            \"sourceStatus\": {\n                \"source\": \"mysql1\",\n                \"relayStatus\": {\n                    \"masterBinlog\": \"(mysql-bin.000006, 744)\",\n                    \"masterBinlogGtid\": \"f8004e25-6067-11eb-9fa3-0242ac110003:1-50\"\n                }\n            },\n            \"subTaskStatus\": [\n                {\n                    \"sync\": {\n                        \"masterBinlog\": \"(mysql-bin.000006, 744)\",\n                        \"masterBinlogGtid\": \"f8004e25-6067-11eb-9fa3-0242ac110003:1-50\",\n                        \"syncerBinlog\": \"(mysql-bin|000001.000006, 738)\",\n                        \"syncerBinlogGtid\": \"f8004e25-6067-11eb-9fa3-0242ac110003:1-20:40-49\",\n                        \"synced\": false,\n                        \"binlogType\": \"local\"\n                    }\n                }\n            ]\n        },\n        {\n            \"sourceStatus\": {\n                \"source\": \"mysql2\",\n                \"relayStatus\": {\n                    \"masterBinlog\": \"(mysql-bin.000007, 1979)\",\n                    \"masterBinlogGtid\": \"ddb8974e-6064-11eb-8357-0242ac110002:1-25\"\n                }\n            },\n            \"subTaskStatus\": [\n                {\n                    \"sync\": {\n                        \"masterBinlog\": \"(mysql-bin.000007, 1979)\",\n                        \"masterBinlogGtid\": \"ddb8974e-6064-11eb-8357-0242ac110002:1-25\",\n                        \"syncerBinlog\": \"(mysql-bin|000001.000008, 1979)\",\n                        \"syncerBinlogGtid\": \"ddb8974e-6064-11eb-8357-0242ac110002:1-25\",\n                        \"synced\": true,\n                        \"binlogType\": \"local\"\n                    }\n                }\n            ]\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Partitions in SQL\nDESCRIPTION: SQL statements to add new partitions to existing RANGE and LIST partitioned tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_38\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE members ADD PARTITION (PARTITION `p1990to2010` VALUES LESS THAN (2010));\n\nALTER TABLE member_level ADD PARTITION (PARTITION l5_6 VALUES IN (5,6));\n```\n\n----------------------------------------\n\nTITLE: IN Condition Partition Pruning\nDESCRIPTION: Shows how partition pruning works with IN conditions, accessing only the relevant partitions that contain the specified values.\nSOURCE: https://github.com/pingcap/docs/blob/master/partition-pruning.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (x int) partition by range (x) (\n    partition p0 values less than (5),\n    partition p1 values less than (10),\n    partition p2 values less than (15)\n    );\nexplain select * from t where x in(1,13);\n```\n\n----------------------------------------\n\nTITLE: Executing TRACE with Log Format in TiDB SQL\nDESCRIPTION: Example of using the TRACE statement with 'log' format to analyze a SELECT query execution on the mysql.user table. The output provides a detailed log of events, timestamps, and span information.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-trace.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nTRACE FORMAT='log' SELECT * FROM mysql.user;\n```\n\n----------------------------------------\n\nTITLE: Creating a TiCDC Changefeed Task via CLI\nDESCRIPTION: Example of using the TiCDC CLI to create a replication task with a specified sink URI and changefeed ID. This command sets up a replication from the TiCDC server to a MySQL database.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-changefeed-config.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://10.0.10.25:8300 --sink-uri=\"mysql://root:123456@127.0.0.1:3306/\" --changefeed-id=\"simple-replication-task\"\n```\n\n----------------------------------------\n\nTITLE: Setting API credentials as environment variables\nDESCRIPTION: Shell commands for setting TiDB Cloud API credentials as environment variables, which is an alternative to hardcoding them in the Terraform configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-get-tidbcloud-provider.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nexport TIDBCLOUD_PUBLIC_KEY=${public_key}\nexport TIDBCLOUD_PRIVATE_KEY=${private_key}\n```\n\n----------------------------------------\n\nTITLE: Enabling GC Compaction Filter in TiKV Configuration\nDESCRIPTION: Enables the experimental GC Compaction Filter feature in TiKV to combine garbage collection and data compaction tasks, reducing I/O usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0-rc.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\ngc.enable-compaction-filter = true\n```\n\n----------------------------------------\n\nTITLE: Executing SLEEP Function with SELECT in SQL\nDESCRIPTION: SQL example demonstrating the use of SELECT with the SLEEP function, which pauses execution for 5 seconds and returns a result set.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-do.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT SLEEP(5);\n```\n\n----------------------------------------\n\nTITLE: TiKV Raftstore CPU Usage Alert Rule\nDESCRIPTION: Monitors CPU usage of Raftstore threads. Alerts when usage exceeds 80% of the configured store-pool-size (1.6 by default).\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_16\n\nLANGUAGE: promql\nCODE:\n```\nsum(rate(tikv_thread_cpu_seconds_total{name=~\"raftstore_.*\"}[1m])) by (instance) > 1.6\n```\n\n----------------------------------------\n\nTITLE: Filtering Plugins with LIKE in TiDB\nDESCRIPTION: This SQL example demonstrates how to use the `SHOW PLUGINS` statement with a `LIKE` clause to filter plugins based on their names. In this case, it retrieves plugins with names that start with 'a'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-plugins.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n\"SHOW PLUGINS LIKE 'a%';\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Cron for Background Actions in TiDB\nDESCRIPTION: Sets the timing for periodic background actions within TiDB, allowing for scheduled operations to enhance performance and maintenance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_24\n\nLANGUAGE: markdown\nCODE:\n```\nSupported units: h (hour), m (minute), s (second).\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Message Size\nDESCRIPTION: Add these configuration lines to your Kafka server settings to control and increase the size limits for messages. Necessary when using TiCDC versions v4.0.8 or earlier to ensure large messages from replication tasks are processed without error.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/troubleshoot-ticdc.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n# The maximum byte number of a message that the broker receives\nmessage.max.bytes=2147483648\n# The maximum byte number of a message that the broker copies\nreplica.fetch.max.bytes=2147483648\n# The maximum message byte number that the consumer side reads\nfetch.message.max.bytes=2147483648\n```\n\n----------------------------------------\n\nTITLE: Setting tidb_max_delta_schema_count for Schema Version Caching\nDESCRIPTION: Determines the maximum number of schema versions (modified table IDs) that can be cached. This global variable affects schema management across the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_47\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_max_delta_schema_count = <value>;\n```\n\n----------------------------------------\n\nTITLE: Table Structure Output Display\nDESCRIPTION: Shows the output of the DESC command displaying the three columns (object_schema, object_name, index_name) with their respective properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/sys-schema/sys-schema-unused-indexes.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+---------------+-------------+------+------+---------+-------+\n| Field         | Type        | Null | Key  | Default | Extra |\n+---------------+-------------+------+------+---------+-------+\n| object_schema | varchar(64) | YES  |      | NULL    |       |\n| object_name   | varchar(64) | YES  |      | NULL    |       |\n| index_name    | varchar(64) | YES  |      | NULL    |       |\n+---------------+-------------+------+------+---------+-------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a Partitioned Table in TiDB\nDESCRIPTION: This SQL snippet demonstrates how to create a simple hash-partitioned table in TiDB. It's used to illustrate the LOAD DATA compatibility issue with partition selection.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_67\n\nLANGUAGE: SQL\nCODE:\n```\ncreate table t (id int, val int) partition by hash(id) partitions 4;\n```\n\n----------------------------------------\n\nTITLE: Enabling Top SQL via SQL System Variable\nDESCRIPTION: Enable Top SQL feature by setting the global TiDB system variable to activate real-time SQL performance monitoring\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/top-sql.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_top_sql = 1;\n```\n\n----------------------------------------\n\nTITLE: Basic gh-ost command structure with required parameters\nDESCRIPTION: Example of a minimal gh-ost command that specifies connection details and the ALTER TABLE statement to be executed.\nSOURCE: https://github.com/pingcap/docs/blob/master/styles/config/vocabularies/PingCAP/accept.txt#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngh-ost \\\n  --user=root \\\n  --password=123456 \\\n  --host=192.168.16.221 \\\n  --port=4000 \\\n  --database=test \\\n  --table=person \\\n  --alter=\"add column age int\" \\\n  --execute\n```\n\n----------------------------------------\n\nTITLE: Snapshot File Structure in JSON\nDESCRIPTION: The snapshot file records the version number of each metadata file, including signatures, file references, and versioning details. It provides a point-in-time record of all metadata file versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror-reference.md#2025-04-18_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"signatures\": [                                             # The file's signature.\n        {\n            \"keyid\": \"{id-of-index-key-1}\",                     # The ID of the first private key that participates in the signature.\n            \"sig\": \"{signature-by-index-key-1}\",                # The signed part of this file by this private key.\n        },\n        ...\n        {\n            \"keyid\": \"{id-of-root-key-N}\",                      # The ID of the Nth private key that participates in the signature.\n            \"sig\": \"{signature-by-root-key-N}\"                  # The signed part of this file by this private key.\n        }\n    ],\n    \"signed\": {\n        \"_type\": \"snapshot\",                                    # The file type.\n        \"expires\": \"{expiration-date-of-this-file}\",            # The expiration time of the file. If the file expires, the client rejects the file.\n        \"meta\": {                                               # Other metadata files' information.\n            \"/root.json\": {\n                \"length\": {length-of-json-file},                # The length of root.json\n                \"version\": {version-of-json-file}               # The version of root.json\n            },\n            \"/index.json\": {\n                \"length\": {length-of-json-file},\n                \"version\": {version-of-json-file}\n            },\n            \"/{component-1}.json\": {\n                \"length\": {length-of-json-file},\n                \"version\": {version-of-json-file}\n            },\n            ...\n            \"/{component-N}.json\": {\n                ...\n            }\n        },\n        \"spec_version\": \"0.1.0\",                                # The specified version followed by this file. If the file structure is changed in the future, the version number needs to be upgraded. The current version number is 0.1.0.\n        \"version\": 0                                            # The version number of this file, which is fixed as 0.\n    }\n```\n\n----------------------------------------\n\nTITLE: Querying Time Zone Settings in TiDB\nDESCRIPTION: SQL query to view the current global, session, and system time zone settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-time-zone.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@global.time_zone, @@session.time_zone, @@global.system_time_zone;\n```\n\n----------------------------------------\n\nTITLE: Getting Export Information in Interactive Mode using Shell Command\nDESCRIPTION: This snippet demonstrates how to retrieve export information from a TiDB Cloud Serverless cluster in interactive mode. It prompts the user for input as necessary.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-describe.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export describe\n```\n\n----------------------------------------\n\nTITLE: Handling Checkpoint Errors in TiDB Lightning with Shell\nDESCRIPTION: These shell commands demonstrate controlling checkpoints after errors occur in TiDB Lightning, including restarting imports from scratch, ignoring past errors, and removing records. These tools help manage table-specific checkpoint operations during import errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-checkpoints.md#2025-04-18_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ntidb-lightning-ctl --checkpoint-error-destroy='`schema`.`table`'\n```\n\nLANGUAGE: sh\nCODE:\n```\ntidb-lightning-ctl --checkpoint-error-destroy=all\n```\n\n----------------------------------------\n\nTITLE: Checking the Currently Enabled Role in TiDB\nDESCRIPTION: This snippet demonstrates how to check the currently enabled role using the `CURRENT_ROLE()` function. After `rw_user1@localhost` logs in, this statement shows the roles that are currently active.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_ROLE();\n```\n\n----------------------------------------\n\nTITLE: Updating Data in TiDB with mysqlclient in Python\nDESCRIPTION: This code snippet demonstrates how to update data in a TiDB table using mysqlclient. It uses a parameterized query to safely update values based on a condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-mysqlclient.md#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith get_mysqlclient_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        player_id, amount, price=\"1\", 10, 500\n        cursor.execute(\n            \"UPDATE players SET goods = goods + %s, coins = coins + %s WHERE id = %s\",\n            (-amount, price, player_id),\n        )\n```\n\n----------------------------------------\n\nTITLE: Restoring Data in TiDB\nDESCRIPTION: This SQL command restores a previously backed-up database from S3 storage to the downstream TiDB cluster, allowing replicated data to be accessed from the new environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nmysql> RESTORE DATABASE * FROM 's3://backup?access-key=minio&secret-access-key=miniostorage&endpoint=http://${HOST_IP}:6060&force-path-style=true';\n\n```\n+--------------+-----------+--------------------+---------------------+---------------------+\n| Destination  | Size      | BackupTS           | Queue Time          | Execution Time      |\n+--------------+-----------+--------------------+---------------------+---------------------+\n| s3://backup  | 10315858  | 431434141450371074 | 2022-02-25 20:03:59 | 2022-02-25 20:03:59 |\n+--------------+-----------+--------------------+---------------------+---------------------+\n1 row in set (41.85 sec)\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Existing Rails Projects\nDESCRIPTION: Command to add the mysql2 and dotenv gems to an existing Rails project for TiDB connectivity.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbundle add mysql2 dotenv\n```\n\n----------------------------------------\n\nTITLE: Splitting Table Regions in TiDB SQL\nDESCRIPTION: Adds syntax to split table regions between specified values, supporting Region presplit to address hotspot issues in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.13.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSPLIT TABLE [table_name] BETWEEN (min_value...) AND (max_value...) REGIONS [region_num]\n```\n\n----------------------------------------\n\nTITLE: Querying Table Schema in MySQL\nDESCRIPTION: SQL command to show the create table statement for a table named 'test' in MySQL. This demonstrates how MySQL handles timestamp default values differently from TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nmysql root@127.0.0.1:test> show create table test;\n+-------+----------------------------------------------------------------------------------+\n| Table | Create Table                                                                     |\n+-------+----------------------------------------------------------------------------------+\n| test  | CREATE TABLE `test` (                                                            |\n|       |   `id` int NOT NULL,                                                         |\n|       |   `ts` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, |\n|       |   PRIMARY KEY (`id`)                                                             |\n|       | ) ENGINE=InnoDB DEFAULT CHARSET=latin1                                           |\n+-------+----------------------------------------------------------------------------------+\n1 row in set\n```\n\n----------------------------------------\n\nTITLE: Using Optimizer Hints in TiDB SQL\nDESCRIPTION: Demonstrates the syntax for including optimizer hints in TiDB SQL queries. These special comments with the /*+ prefix provide instructions to the query optimizer about how to execute the query.\nSOURCE: https://github.com/pingcap/docs/blob/master/comment-syntax.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ hint */ FROM ...;\n```\n\n----------------------------------------\n\nTITLE: Configuring Gitpod Workspace for TiDB Development\nDESCRIPTION: This YAML configuration file sets up the Gitpod workspace for TiDB development. It defines tasks for initializing the TiUP playground, opening target files, and running test cases based on different application modes.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-playground-gitpod.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntasks:\n  - name: Open Target File\n    command: |\n      if [ -n \"$targetFile\" ]; then code ${targetFile//[_]//};  fi\n  - name: TiUP init playground\n    command: |\n      $HOME/.tiup/bin/tiup playground\n  - name: Test Case\n    openMode: split-right\n    init: echo \"*** Waiting for TiUP Playground Ready! ***\"\n    command: |\n      gp await-port 3930\n      if [ \"$targetMode\" == \"plain-java-jdbc\" ]\n      then\n        cd plain-java-jdbc\n        code src/main/resources/dbinit.sql\n        code src/main/java/com/pingcap/JDBCExample.java\n        make mysql\n      elif [ \"$targetMode\" == \"plain-java-hibernate\" ]\n      then\n        cd plain-java-hibernate\n        make\n      elif [ \"$targetMode\" == \"spring-jpa-hibernate\" ]\n      then\n        cd spring-jpa-hibernate\n        make\n      fi\nports:\n  - port: 8080\n    visibility: public\n  - port: 4000\n    visibility: public\n  - port: 2379-36663\n    onOpen: ignore\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW TABLE NEXT_ROW_ID Syntax in EBNF\nDESCRIPTION: This snippet provides the formal syntax definition for the SHOW TABLE NEXT_ROW_ID statement using EBNF. It specifies the statement structure for displaying the next row ID for a table in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-next-rowid.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowTableNextRowIDStmt ::= \"SHOW\" \"TABLE\" (SchemaName \".\")? TableName \"NEXT_ROW_ID\"\n```\n\n----------------------------------------\n\nTITLE: Example Error Message for Same Upstream/Downstream Cluster\nDESCRIPTION: This is the error message that TiCDC returns when attempting to create a changefeed with the same TiDB cluster as both the source and the target. The error code `CDC:ErrSameUpstreamDownstream` indicates the issue.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nError: [CDC:ErrSameUpstreamDownstream]TiCDC does not support creating a changefeed with the same TiDB cluster as both the source and the target for the changefeed.\n```\n\n----------------------------------------\n\nTITLE: Analyzing Table Partition\nDESCRIPTION: Triggers manual analysis of a specific table partition to collect global statistics required for dynamic pruning mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_73\n\nLANGUAGE: sql\nCODE:\n```\nanalyze table t partition p1;\nshow stats_meta where table_name like \"t\";\n```\n\n----------------------------------------\n\nTITLE: Modifying an Existing Placement Policy SQL\nDESCRIPTION: The SQL statement alters a placement policy, indicating configuration for additional Raft Followers, thus affecting attached objects.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nALTER PLACEMENT POLICY myplacementpolicy FOLLOWERS=4;\n```\n\n----------------------------------------\n\nTITLE: Decoding TiDB Execution Plans with TIDB_DECODE_PLAN in SQL\nDESCRIPTION: This snippet demonstrates how to use the TIDB_DECODE_PLAN function to decode encoded execution plans from the slow query log. This function is useful for analyzing plans captured at the time of statement execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT tidb_decode_plan('8QIYMAkzMV83CQEH8E85LjA0CWRhdGE6U2VsZWN0aW9uXzYJOTYwCXRpbWU6NzEzLjHCtXMsIGxvb3BzOjIsIGNvcF90YXNrOiB7bnVtOiAxLCBtYXg6IDU2OC41wgErRHByb2Nfa2V5czogMCwgcnBjXxEpAQwFWBAgNTQ5LglZyGNvcHJfY2FjaGVfaGl0X3JhdGlvOiAwLjAwfQkzLjk5IEtCCU4vQQoxCTFfNgkxXzAJMwm2SGx0KHRlc3QudC5hLCAxMDAwMCkNuQRrdgmiAHsFbBQzMTMuOMIBmQnEDDk2MH0BUgEEGAoyCTQzXzUFVwX1oGFibGU6dCwga2VlcCBvcmRlcjpmYWxzZSwgc3RhdHM6cHNldWRvCTk2ISE2aAAIMTUzXmYA')\\G\n```\n\n----------------------------------------\n\nTITLE: Querying TiCloud AI in Non-Interactive Mode\nDESCRIPTION: Example of using the 'ticloud ai' command in non-interactive mode. This mode allows users to send a single query to the TiDB Bot using the -q flag.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-ai.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud ai -q \"How to create a cluster?\"\n```\n\n----------------------------------------\n\nTITLE: Altering User Password Reuse Interval in SQL\nDESCRIPTION: SQL command to modify an existing user's password reuse policy to prohibit reusing passwords used within the last 365 days.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_25\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER 'test'@'localhost' PASSWORD REUSE INTERVAL 365 DAY;\n```\n\n----------------------------------------\n\nTITLE: Analyzing IndexHashJoin Operator Execution in TiDB\nDESCRIPTION: This snippet shows the execution information for the `IndexHashJoin` operator in TiDB. It provides details on the time consumed by the inner worker (total, concurrency, task count, construct, fetch, build, and join). Analyzing these metrics aids in identifying performance bottlenecks during index hash join operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n\"inner:{total:4.429220003s, concurrency:5, task:17, construct:96.207725ms, fetch:4.239324006s, build:24.567801ms, join:93.607362ms}\"\n```\n\n----------------------------------------\n\nTITLE: Checking Current Timestamp in SQL\nDESCRIPTION: SQL query to retrieve the current system timestamp, which will be used as a reference point for stale read operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nselect now();\n```\n\n----------------------------------------\n\nTITLE: Defining Data Change Record Path - Shell\nDESCRIPTION: This shell snippet outlines the structure for storing data change records with placeholders for key parameters such as scheme, prefix, schema, table, and others. It's crucial for identifying file locations.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n{scheme}://{prefix}/{schema}/{table}/{table-version-separator}/{partition-separator}/{date-separator}/CDC{num}.{extension}\n```\n\n----------------------------------------\n\nTITLE: Setting limit push down threshold in TiDB 5.2\nDESCRIPTION: Sets the threshold that determines whether to push the Limit or TopN operator down to TiKV. The default value is 100.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.2.0.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_opt_limit_push_down_threshold = 100;\n```\n\n----------------------------------------\n\nTITLE: Querying TTL Table Status\nDESCRIPTION: This SQL snippet retrieves the status of the currently executed or previously executed TTL jobs for all tables. It provides information such as table ID, job timings, and execution summary.\nSOURCE: https://github.com/pingcap/docs/blob/master/time-to-live.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nTABLE mysql.tidb_ttl_table_status LIMIT 1\\G\n\n```\n\n----------------------------------------\n\nTITLE: Publishing Cloudflare Worker\nDESCRIPTION: Command to publish the Cloudflare Worker project using Wrangler CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-cloudflare.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpx wrangler publish\n```\n\n----------------------------------------\n\nTITLE: Enabling Titan by Directly Editing TiKV Configuration File\nDESCRIPTION: This snippet demonstrates how to enable Titan by directly editing the TiKV configuration file. This method is not recommended for production environments.\nSOURCE: https://github.com/pingcap/docs/blob/master/storage-engine/titan-configuration.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[rocksdb.titan]\nenabled = true\n```\n\n----------------------------------------\n\nTITLE: Incorrect Table Structure Examples\nDESCRIPTION: Examples of incorrect table structures that would cause issues with source information extraction.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-table-routing.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `test`.`t` (\n    c_table varchar(10) DEFAULT NULL,\n    a int PRIMARY KEY,\n    c_schema varchar(10) DEFAULT NULL,\n    c_source varchar(10) DEFAULT NULL\n);\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `test`.`t` (\n    a int PRIMARY KEY,\n    c_table varchar(10) DEFAULT NULL,\n    c_schema varchar(10) DEFAULT NULL,\n);\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `test`.`t` (\n    a int PRIMARY KEY,\n    c_table varchar(10) DEFAULT NULL,\n    c_schema int DEFAULT NULL,\n    c_source varchar(10) DEFAULT NULL,\n);\n```\n\n----------------------------------------\n\nTITLE: Store State Protocol Definition Reference\nDESCRIPTION: Reference to the StoreState protocol buffer definition used for TiKV store heartbeat reporting.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-scheduling.md#2025-04-18_snippet_0\n\nLANGUAGE: protobuf\nCODE:\n```\nStoreState\n```\n\n----------------------------------------\n\nTITLE: Converting HEX Literal to CHAR using CAST\nDESCRIPTION: Demonstrates converting a binary hex literal to a character string using the CAST function in TiDB\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/cast-functions-and-operators.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CAST(0x54694442 AS CHAR);\n```\n\n----------------------------------------\n\nTITLE: Configuring PD Location Labels\nDESCRIPTION: PD configuration for topology awareness and replica scheduling across different physical locations.\nSOURCE: https://github.com/pingcap/docs/blob/master/geo-distributed-deployment-topology.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nreplication.location-labels: [\"zone\",\"dc\",\"rack\",\"host\"]\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP Cluster Component\nDESCRIPTION: Installs the cluster management component for TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Cloud Restore Resource in Terraform\nDESCRIPTION: A Terraform configuration file that defines a restore task for a TiDB Cloud Dedicated cluster. It specifies provider requirements, authentication keys, and restore configuration including cluster specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-restore-resource.md#2025-04-18_snippet_0\n\nLANGUAGE: terraform\nCODE:\n```\nterraform {\n required_providers {\n   tidbcloud = {\n     source = \"tidbcloud/tidbcloud\"\n   }\n }\n}\n\nprovider \"tidbcloud\" {\n public_key = \"your_public_key\"\n private_key = \"your_private_key\"\n}\n resource \"tidbcloud_restore\" \"example_restore\" {\n  project_id = tidbcloud_cluster.example_cluster.project_id\n  backup_id  = tidbcloud_backup.example_backup.id\n  name       = \"restoreCluster\"\n  config = {\n    root_password = \"Your_root_password1.\"\n    port          = 4000\n    components = {\n      tidb = {\n        node_size : \"8C16G\"\n        node_quantity : 2\n      }\n      tikv = {\n        node_size : \"8C32G\"\n        storage_size_gib : 500\n        node_quantity : 6\n      }\n      tiflash = {\n        node_size : \"8C64G\"\n        storage_size_gib : 500\n        node_quantity : 2\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Importing TPC-C Data to TiDB\nDESCRIPTION: This shell command is used to prepare the TPC-C test by importing 1,000 warehouses into the 'tpcc' database. The command requires host, thread count, and password specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ngo-tpc tpcc --host ${HOST} --warehouses 1000 prepare -P 4000 -D tpcc -T ${THREAD} --time 2h0m0s -p ${PASSWORD} --ignore-error\n```\n\n----------------------------------------\n\nTITLE: Defining Vitess-compatible Hash Function in TiDB\nDESCRIPTION: TiDB introduces the VITESS_HASH() function to facilitate data migration from Vitess. This function returns a hash of a string that is compatible with Vitess' HASH function.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-vitess.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`VITESS_HASH()`\n```\n\n----------------------------------------\n\nTITLE: Traffic Capture Jobs Output Example\nDESCRIPTION: Example output showing two TiProxy instances capturing traffic with 45% progress. Illustrates the columns and information returned by the SHOW TRAFFIC JOBS command for capture jobs.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-traffic-jobs.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------+----------+----------------+---------+----------+---------+-------------+----------------------------------------------------------------------------+\n| START_TIME                 | END_TIME | INSTANCE       | TYPE    | PROGRESS | STATUS  | FAIL_REASON | PARAMS                                                                     |\n+----------------------------+----------+----------------+---------+----------+---------+-------------+----------------------------------------------------------------------------+\n| 2024-12-17 10:54:41.000000 |          | 10.1.0.10:3080 | capture | 45%      | running |             | OUTPUT=\"/tmp/traffic\", DURATION=\"90m\", COMPRESS=true, ENCRYPTION_METHOD=\"\" |\n| 2024-12-17 10:54:41.000000 |          | 10.1.0.11:3080 | capture | 45%      | running |             | OUTPUT=\"/tmp/traffic\", DURATION=\"90m\", COMPRESS=true, ENCRYPTION_METHOD=\"\" |\n+----------------------------+----------+----------------+---------+----------+---------+-------------+----------------------------------------------------------------------------+\n2 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Enabling Log Redaction in TiDB\nDESCRIPTION: This SQL command sets the global variable tidb_redact_log to ON, enabling log redaction for all new sessions in TiDB. When enabled, sensitive data in logs is replaced with a '?' character.\nSOURCE: https://github.com/pingcap/docs/blob/master/log-redaction.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nset @@global.tidb_redact_log = ON;\n```\n\n----------------------------------------\n\nTITLE: View Log Backup Metadata Help Command\nDESCRIPTION: Shows help information for viewing log backup metadata including available flags and global options.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log metadata --help\nget the metadata of log backup storage\n\nUsage:\n  br log metadata [flags]\n\nFlags:\n  -h, --help       help for metadata\n\nGlobal Flags:\n  -s, --storage string         specify the url where backup storage, eg, \"s3://bucket/path/prefix\"\n```\n\n----------------------------------------\n\nTITLE: Storage Service URI Format\nDESCRIPTION: Generic URI format for external storage services showing scheme, host, path, and parameter structure.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n[scheme]://[host]/[path]?[parameters]\n```\n\n----------------------------------------\n\nTITLE: INSERT Statement EBNF Syntax in TiDB\nDESCRIPTION: Extended Backus-Naur form (EBNF) syntax definition for the INSERT statement in TiDB. It shows the complete structure including table hints, priority options, partition specifications, and various forms of value insertion including direct values, SELECT statements, and ON DUPLICATE KEY UPDATE clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-insert.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nInsertIntoStmt ::=\n    'INSERT' TableOptimizerHints PriorityOpt IgnoreOptional IntoOpt TableName PartitionNameListOpt InsertValues OnDuplicateKeyUpdate\n\nTableOptimizerHints ::=\n    hintComment?\n\nPriorityOpt ::=\n    ( 'LOW_PRIORITY' | 'HIGH_PRIORITY' | 'DELAYED' )?\n\nIgnoreOptional ::=\n    'IGNORE'?\n\nIntoOpt  ::= 'INTO'?\n\nTableName ::=\n    Identifier ( '.' Identifier )?\n\nPartitionNameListOpt ::=\n    ( 'PARTITION' '(' Identifier ( ',' Identifier )* ')' )?\n\nInsertValues ::=\n    '(' ( ColumnNameListOpt ')' ( ValueSym ValuesList | SelectStmt | '(' SelectStmt ')' | UnionStmt ) | SelectStmt ')' )\n|   ValueSym ValuesList\n|   SelectStmt\n|   UnionStmt\n|   'SET' ColumnSetValue? ( ',' ColumnSetValue )*\n\nOnDuplicateKeyUpdate ::=\n    ( 'ON' 'DUPLICATE' 'KEY' 'UPDATE' AssignmentList )?\n```\n\n----------------------------------------\n\nTITLE: Using SETVAL() Function in TiDB\nDESCRIPTION: This snippet shows how to use the SETVAL() function to set the current value of sequence 's1' to 10.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/sequence-functions.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT SETVAL(s1, 10);\n```\n\n----------------------------------------\n\nTITLE: Skipping UTF-8 Check in TiDB v2.1.2\nDESCRIPTION: Session-level configuration to bypass UTF-8 encoding validation\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/upgrade-faq.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nset @@session.tidb_skip_utf8_check=1;\n```\n\n----------------------------------------\n\nTITLE: Using GCS Wildcard Pattern for Multiple Character Matching\nDESCRIPTION: Demonstrates how to use the asterisk wildcard in GCS URIs to match any number of characters in filenames during import.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-parquet-files.md#2025-04-18_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\ngs://[bucket_name]/[data_source_folder]/my-data*.parquet\n```\n\n----------------------------------------\n\nTITLE: Modifying Background Options for Default Resource Group in TiDB\nDESCRIPTION: SQL example showing how to modify the BACKGROUND option for the 'default' resource group and verify the changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-resource-group.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nALTER RESOURCE GROUP default BACKGROUND = (TASK_TYPES = \"br,ddl\", UTILIZATION_LIMIT=30);\n\nSELECT * FROM information_schema.resource_groups WHERE NAME ='default';\n```\n\n----------------------------------------\n\nTITLE: Creating a Branch in Non-Interactive Mode\nDESCRIPTION: Example of creating a branch for a TiDB Cloud Serverless cluster in non-interactive mode. This requires specifying the cluster ID and branch name as command flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-create.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch create --cluster-id <cluster-id> --display-name <branch-name>\n```\n\n----------------------------------------\n\nTITLE: Creating TIDB_TEST_ITEM Table in Snowflake - SQL\nDESCRIPTION: Creates the `TIDB_TEST_ITEM` table in Snowflake, designed to store change logs of TiDB data. The table consists of `RECORD_METADATA` and `RECORD_CONTENT` of type VARIANT.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\ncreate or replace TABLE TIDB_TEST_ITEM (\n        RECORD_METADATA VARIANT,\n        RECORD_CONTENT VARIANT\n);\n```\n\n----------------------------------------\n\nTITLE: Locking User Accounts in Old Cluster - SQL\nDESCRIPTION: SQL command to lock user accounts in the old cluster, preventing them from handling business traffic. Requires user account access rights in the database. This step is part of preparing for switchover.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nALTER USER ACCOUNT LOCK;\n```\n\n----------------------------------------\n\nTITLE: Starting DM Cluster\nDESCRIPTION: Command to start a deployed DM cluster\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm start prod-cluster\n```\n\n----------------------------------------\n\nTITLE: Filtering DDL Job Information with WHERE Clause and Row Limit\nDESCRIPTION: This command allows limiting the number of rows and applying filter conditions to restrict the DDL job information displayed. It's useful when working with databases that have many DDL operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW DDL JOBS [NUM] [WHERE where_condition];\n```\n\n----------------------------------------\n\nTITLE: DM Source Configuration\nDESCRIPTION: YAML configuration for connecting TiDB DM to the source MySQL database.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nsource-id: \"mysql-01\"\nfrom:\n  host: \"127.0.0.1\"\n  user: \"tidb-dm\"\n  password: \"MyPassw0rd!\"\n  port: 3306\n```\n\n----------------------------------------\n\nTITLE: Using FLASHBACK CLUSTER to Recover to a Specific TSO - SQL\nDESCRIPTION: This SQL command is used in TiDB v7.6.0 to roll back a database cluster to a specified historical TSO (Timestamp Oracle). This feature enhances data recovery options, particularly useful when testing data stability in ongoing migrations or data replications with TiCDC.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.6.0.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nFLASHBACK CLUSTER TO TSO 445494839813079041;\n```\n\n----------------------------------------\n\nTITLE: Exploring TiDB BR Log Command Options in Shell\nDESCRIPTION: Shows the available subcommands for the tiup br log command, which is used for backing up stream logs from TiDB/TiKV clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log --help\n\nbackup stream log from TiDB/TiKV cluster\n\nUsage:\n  br log [command]\n\nAvailable Commands:\n  metadata   get the metadata of log dir\n  pause      pause a log backup task\n  resume     resume a log backup task\n  start      start a log backup task\n  status     get status for the log backup task\n  stop       stop a log backup task\n  truncate   truncate the log data until sometime\n```\n\n----------------------------------------\n\nTITLE: Using Zero Index Selectivity Ratio in TiDB SQL\nDESCRIPTION: Example showing query execution with a value of 0 for tidb_opt_ordering_index_selectivity_ratio. This assumes that 0% of rows will be scanned before qualifying rows are found, resulting in a highly optimistic estimation.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_57\n\nLANGUAGE: sql\nCODE:\n```\n> SET SESSION tidb_opt_ordering_index_selectivity_ratio = 0;\n\n> EXPLAIN SELECT * FROM t USE INDEX (ia) WHERE b <= 9000 ORDER BY a LIMIT 1;\n+-----------------------------------+---------+-----------+-----------------------+---------------------------------+\n| id                                | estRows | task      | access object         | operator info                   |\n+-----------------------------------+---------+-----------+-----------------------+---------------------------------+\n| Limit_12                          | 1.00    | root      |                       | offset:0, count:1               |\n| └─Projection_22                   | 1.00    | root      |                       | test.t.a, test.t.b, test.t.c    |\n|   └─IndexLookUp_21                | 1.00    | root      |                       |                                 |\n|     ├─IndexFullScan_18(Build)     | 1.00    | cop[tikv] | table:t, index:ia(a)  | keep order:true                 |\n|     └─Selection_20(Probe)         | 1.00    | cop[tikv] |                       | le(test.t.b, 9000)              |\n|       └─TableRowIDScan_19         | 1.00    | cop[tikv] | table:t               | keep order:false                |\n+-----------------------------------+---------+-----------+-----------------------+---------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Delete Event Structure Before and After v5.4.0 in JSON\nDESCRIPTION: This JSON snippet contrasts the structure of Delete events in TiCDC before and after version 5.4.0. It highlights that the 'old' field, previously identical to 'data', is now set to null in later versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"id\": 0,\n    \"database\": \"test\",\n    ...\n    \"type\": \"DELETE\",\n    ...\n    \"sqlType\": {\n        ...\n    },\n    \"mysqlType\": {\n        ...\n    },\n    \"data\": [\n        {\n            \"c_bigint\": \"9223372036854775807\",\n            \"c_int\": \"0\",\n            \"c_mediumint\": \"8388607\",\n            \"c_smallint\": \"32767\",\n            \"c_tinyint\": \"0\",\n            \"id\": \"2\"\n        }\n    ],\n    \"old\": null,\n    // The following is an example before v5.4.0. The `old` field contains the same content as the \"data\" field.\n    \"old\": [\n        {\n            \"c_bigint\": \"9223372036854775807\",\n            \"c_int\": \"0\",\n            \"c_mediumint\": \"8388607\",\n            \"c_smallint\": \"32767\",\n            \"c_tinyint\": \"0\",\n            \"id\": \"2\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_inl_join_inner_multi_pattern in TiDB\nDESCRIPTION: This variable determines the support for Index Join when the inner table employs Selection, Aggregation, or Projection operations. The default is ON, but set to OFF for v8.3.0 and earlier versions, which could affect query performance post-upgrade.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_31\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): Yes\n- Type: Boolean\n- Default value: `ON`. The default value is `OFF` for v8.3.0 and earlier versions.\n- This variable controls whether Index Join is supported when the inner table has `Selection`, `Aggregation`, or `Projection` operators on it.\n```\n\n----------------------------------------\n\nTITLE: Copying Environment File in Windows PowerShell\nDESCRIPTION: Command to copy the .env.example file to .env in a Windows PowerShell environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nextjs.md#2025-04-18_snippet_3\n\nLANGUAGE: powershell\nCODE:\n```\nCopy-Item \".env.example\" -Destination \".env\"\n```\n\n----------------------------------------\n\nTITLE: Correcting 'not null' flag in Join operations\nDESCRIPTION: Fixes incorrect results by properly resetting the 'not null' flag when using the USING clause in Natural Outer Join and Outer Join.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.7.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\n[#13739](https://github.com/pingcap/tidb/pull/13739)\n```\n\n----------------------------------------\n\nTITLE: Server Configurations Example for DM Cluster using TiUP\nDESCRIPTION: Example configuration for the server_configs section of a DM cluster topology file. This demonstrates how to set specific configurations for master and worker components, such as log levels and RPC settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-dm-topology-reference.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  master:\n    log-level: info\n    rpc-timeout: \"30s\"\n    rpc-rate-limit: 10.0\n    rpc-rate-burst: 40\n  worker:\n    log-level: info\n```\n\n----------------------------------------\n\nTITLE: Configuration Update in TOML File\nDESCRIPTION: Shows the correction of the check-mb4-value-in-utf8 configuration item position in the config.example.toml file\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.7.md#2025-04-18_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\ncheck-mb4-value-in-utf8 = true\n```\n\n----------------------------------------\n\nTITLE: Configuration Table in Markdown\nDESCRIPTION: Markdown table documenting configuration parameter changes across different TiDB components including new additions, modifications, and deprecations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_11\n\nLANGUAGE: markdown\nCODE:\n```\n| Configuration file | Configuration parameter | Change type | Description |\n| -------- | -------- | -------- | -------- |\n| TiDB | [`instance.tidb_enable_collect_execution_info`](/tidb-configuration-file.md#tidb_enable_collect_execution_info) | Modified | Adds a control to whether to record the [usage statistics of indexes](/information-schema/information-schema-tidb-index-usage.md). The default value is `true`. |\n```\n\n----------------------------------------\n\nTITLE: Connecting to Target TiDB Database using MySQL Client\nDESCRIPTION: This snippet illustrates how to connect to the target TiDB database using the MySQL client. The connection is established using the specified host, port, user, and prompt settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nmysql --host 127.0.0.1 --port 4000 -u root --prompt 'tidb> '\n```\n\n----------------------------------------\n\nTITLE: Alias for Deleting TiDB Cloud Serverless Cluster\nDESCRIPTION: This is an alternative command that serves as an alias for deleting a TiDB Cloud Serverless cluster from your project.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-delete.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless rm [flags]\n```\n\n----------------------------------------\n\nTITLE: Defining TLS Objects in the Security Section - TOML\nDESCRIPTION: This snippet defines TLS object configurations within the `[security]` section of a TOML file. The configurations include settings for SQL and server TLS, determining their behavior during operation. It indicates shared fields while highlighting their different applications based on context.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-configuration.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[security]\n    [sql-tls]\n    skip-ca = true\n    [server-tls]\n    auto-certs = true\n```\n\n----------------------------------------\n\nTITLE: Test Summary Results\nDESCRIPTION: Comprehensive summary of the benchmark results showing final statistics for all transaction types and analytical queries, including throughput (TPM), latency metrics, and error counts over the entire test duration.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-ch.md#2025-04-18_snippet_8\n\nLANGUAGE: text\nCODE:\n```\nFinished: 50 OLTP workers, 1 OLAP workers\n[Summary] DELIVERY - Takes(s): 3599.7, Count: 501795, TPM: 8363.9, Sum(ms): 63905178.8, Avg(ms): 127.4, 50th(ms): 125.8, 90th(ms): 167.8, 95th(ms): 184.5, 99th(ms): 226.5, 99.9th(ms): 318.8, Max(ms): 604.0\n[Summary] DELIVERY_ERR - Takes(s): 3599.7, Count: 14, TPM: 0.2, Sum(ms): 1027.7, Avg(ms): 73.4, 50th(ms): 71.3, 90th(ms): 109.1, 95th(ms): 109.1, 99th(ms): 113.2, 99.9th(ms): 113.2, Max(ms): 113.2\n[Summary] NEW_ORDER - Takes(s): 3599.7, Count: 5629221, TPM: 93826.9, Sum(ms): 363758020.7, Avg(ms): 64.6, 50th(ms): 62.9, 90th(ms): 88.1, 95th(ms): 100.7, 99th(ms): 130.0, 99.9th(ms): 184.5, Max(ms): 570.4\n```\n\n----------------------------------------\n\nTITLE: Importing DM 1.0 Cluster to TiUP\nDESCRIPTION: Command to import a DM 1.0 cluster deployed using DM-Ansible into TiUP. It generates a topology file and deploys a new DM 2.0+ cluster based on the imported configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm import --dir=/path/to/dm-ansible --cluster-version ${version}\n```\n\n----------------------------------------\n\nTITLE: Defining Critical Alert Rule for CDC Checkpoint High Delay in YAML\nDESCRIPTION: YAML configuration for a critical alert rule that triggers when the TiCDC owner checkpoint timestamp lag exceeds 600 seconds (10 minutes).\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-alert-rules.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nticdc_owner_checkpoint_ts_lag > 600\n```\n\n----------------------------------------\n\nTITLE: Checking Current Resource Group\nDESCRIPTION: SQL query to view the resource group bound to the current user.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-resource-group.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_RESOURCE_GROUP();\n```\n\n----------------------------------------\n\nTITLE: Sink URI Configuration Example 1\nDESCRIPTION: This code snippet shows an example of a Sink URI configuration for TiCDC to connect to Pulsar.  It specifies the protocol, IP address, port, tenant, namespace, and topic.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"pulsar://127.0.0.1:6650/persistent://abc/def/yktest?protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: Pulling sync-diff-inspector Docker image\nDESCRIPTION: Docker command to download the latest sync-diff-inspector image for TiDB v9.0.0 and later versions\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/sync-diff-inspector-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker pull pingcap/sync-diff-inspector:latest\n```\n\n----------------------------------------\n\nTITLE: Starting a DM Migration Task\nDESCRIPTION: Shell command to start a data migration task using tiup dmctl. This command initiates the migration process according to the configuration specified in the task.yaml file.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} start-task task.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed with Kafka Version\nDESCRIPTION: This command creates a TiCDC changefeed with the correct Kafka version specified in the sink URI. This resolves issues caused by the TiCDC Kafka client using the wrong Kafka API version.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/troubleshoot-ticdc.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n\"cdc cli changefeed create --server=http://127.0.0.1:8300 --sink-uri \\\"kafka://127.0.0.1:9092/test?topic=test&protocol=open-protocol&kafka-version=2.4.0\\\" \"\n```\n\n----------------------------------------\n\nTITLE: Global Flags for TiDB Cloud CLI - Markdown\nDESCRIPTION: This snippet lists the global flags available for the TiDB Cloud CLI, detailing their purpose and required status. Understanding these flags enhances user experience by providing control over the CLI's behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/cli-reference.md#2025-04-18_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n| Flag                 | Description                                             | Required | Note                                                                                                             |\n|----------------------|---------------------------------------------------------|----------|------------------------------------------------------------------------------------------------------------------|\n| --no-color           | Disables color in output.                               | No       | Only works in non-interactive mode. In interactive mode, disabling color might not work with some UI components. |\n| -P, --profile string | Specifies the active user profile used in this command. | No       | Works in both non-interactive and interactive modes.                                                             |\n| -D, --debug          | Enable debug mode                                       | No       | Works in both non-interactive and interactive modes.                                                          |\n```\n\n----------------------------------------\n\nTITLE: INSERT Statement Fix\nDESCRIPTION: Fix for panic occurring during INSERT ... SELECT ... ON DUPLICATE KEY UPDATE statement execution\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.1.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO table_name SELECT * FROM another_table ON DUPLICATE KEY UPDATE column = value\n```\n\n----------------------------------------\n\nTITLE: Setting Warning Log Message\nDESCRIPTION: Warning message that appears when a row size exceeds the configured statement size during data dump.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-error-handling.md#2025-04-18_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nRow bigger than statement_size for xxx\n```\n\n----------------------------------------\n\nTITLE: Output of COLUMNS Table Structure Description\nDESCRIPTION: This shows the output of the DESC COLUMNS command, displaying all fields in the COLUMNS table along with their data types and other attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-columns.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------+---------------+------+------+---------+-------+\n| Field                    | Type          | Null | Key  | Default | Extra |\n+--------------------------+---------------+------+------+---------+-------+\n| TABLE_CATALOG            | varchar(512)  | YES  |      | NULL    |       |\n| TABLE_SCHEMA             | varchar(64)   | YES  |      | NULL    |       |\n| TABLE_NAME               | varchar(64)   | YES  |      | NULL    |       |\n| COLUMN_NAME              | varchar(64)   | YES  |      | NULL    |       |\n| ORDINAL_POSITION         | bigint(64)    | YES  |      | NULL    |       |\n| COLUMN_DEFAULT           | text          | YES  |      | NULL    |       |\n| IS_NULLABLE              | varchar(3)    | YES  |      | NULL    |       |\n| DATA_TYPE                | varchar(64)   | YES  |      | NULL    |       |\n| CHARACTER_MAXIMUM_LENGTH | bigint(21)    | YES  |      | NULL    |       |\n| CHARACTER_OCTET_LENGTH   | bigint(21)    | YES  |      | NULL    |       |\n| NUMERIC_PRECISION        | bigint(21)    | YES  |      | NULL    |       |\n| NUMERIC_SCALE            | bigint(21)    | YES  |      | NULL    |       |\n| DATETIME_PRECISION       | bigint(21)    | YES  |      | NULL    |       |\n| CHARACTER_SET_NAME       | varchar(32)   | YES  |      | NULL    |       |\n| COLLATION_NAME           | varchar(32)   | YES  |      | NULL    |       |\n| COLUMN_TYPE              | text          | YES  |      | NULL    |       |\n| COLUMN_KEY               | varchar(3)    | YES  |      | NULL    |       |\n| EXTRA                    | varchar(30)   | YES  |      | NULL    |       |\n| PRIVILEGES               | varchar(80)   | YES  |      | NULL    |       |\n| COLUMN_COMMENT           | varchar(1024) | YES  |      | NULL    |       |\n| GENERATION_EXPRESSION    | text          | NO   |      | NULL    |       |\n+--------------------------+---------------+------+------+---------+-------+\n21 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Topology Instance Configuration\nDESCRIPTION: Detailed breakdown of instance types, hardware requirements, and network configurations for each component in the TiCDC deployment\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc-deployment-topology.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Instance | Count | Physical machine configuration | IP | Configuration |\n| :-- | :-- | :-- | :-- | :-- |\n| TiDB | 3 | 16 VCore 32GB * 1 | 10.0.1.1 <br/> 10.0.1.2 <br/> 10.0.1.3 | Default port <br/> Global directory configuration |\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Encryption with Google Cloud KMS\nDESCRIPTION: To enable encryption at rest based on Google Cloud KMS, a key needs to be created on Google Cloud and then the `[security.encryption.master-key]` section in the TiKV configuration file must be configured.  This configures TiKV to use Google Cloud KMS for key management, enhancing data security.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n\"[security.encryption.master-key]\"\n```\n\n----------------------------------------\n\nTITLE: Verifying DM-master Certificate\nDESCRIPTION: Optional command to display the contents of the DM-master certificate, including the SAN field.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nopenssl x509 -text -in master-cert.pem -noout\n```\n\n----------------------------------------\n\nTITLE: Starting ProxySQL Service\nDESCRIPTION: This command starts the ProxySQL service using systemctl.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nsystemctl start proxysql\n```\n\n----------------------------------------\n\nTITLE: Removing System Versioning from a MariaDB Table\nDESCRIPTION: SQL command to remove system versioning from a MariaDB table, making it compatible with TiDB migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-mariadb.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t DROP SYSTEM VERSIONING;\n```\n\n----------------------------------------\n\nTITLE: EXPLAIN Output for Partition Pruning Limitation Query in TiDB\nDESCRIPTION: This SQL output shows the execution plan for the query demonstrating the partition pruning limitation. It reveals that both partitions of t1 are scanned, indicating that partition pruning did not occur during query execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/partition-pruning.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------------------+----------+-----------+------------------------+-----------------------------------------------------------+\n| id                                   | estRows  | task      | access object          | operator info                                             |\n+--------------------------------------+----------+-----------+------------------------+-----------------------------------------------------------+\n| Projection_13                        | 9990.00  | root      |                        | test.t2.x                                                 |\n| └─Apply_15                           | 9990.00  | root      |                        | CARTESIAN inner join, other cond:lt(test.t2.x, test.t1.x) |\n|   ├─TableReader_18(Build)            | 9990.00  | root      |                        | data:Selection_17                                         |\n|   │ └─Selection_17                   | 9990.00  | cop[tikv] |                        | not(isnull(test.t2.x))                                    |\n|   │   └─TableFullScan_16             | 10000.00 | cop[tikv] | table:t2               | keep order:false, stats:pseudo                            |\n|   └─Selection_19(Probe)              | 0.80     | root      |                        | not(isnull(test.t1.x))                                    |\n|     └─MaxOneRow_20                   | 1.00     | root      |                        |                                                           |\n|       └─Union_21                     | 2.00     | root      |                        |                                                           |\n|         ├─TableReader_24             | 2.00     | root      |                        | data:Selection_23                                         |\n|         │ └─Selection_23             | 2.00     | cop[tikv] |                        | lt(test.t2.x, 2), lt(test.t2.x, test.t1.x)                |\n|         │   └─TableFullScan_22       | 2.50     | cop[tikv] | table:t1, partition:p0 | keep order:false, stats:pseudo                            |\n|         └─TableReader_27             | 2.00     | root      |                        | data:Selection_26                                         |\n|           └─Selection_26             | 2.00     | cop[tikv] |                        | lt(test.t2.x, 2), lt(test.t2.x, test.t1.x)                |\n|             └─TableFullScan_25       | 2.50     | cop[tikv] | table:t1, partition:p1 | keep order:false, stats:pseudo                            |\n+--------------------------------------+----------+-----------+------------------------+-----------------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Cluster Topology in Two AZs\nDESCRIPTION: YAML configuration example for deploying TiDB cluster across two availability zones, specifying server locations, labels, and component configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/two-data-centers-in-one-city-deployment.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# # Global variables are applied to all deployments and used as the default value of\n# # the deployments if a specific deployment value is missing.\nglobal:\n  user: \"tidb\"\n  ssh_port: 22\n  deploy_dir: \"/data/tidb_cluster/tidb-deploy\"\n  data_dir: \"/data/tidb_cluster/tidb-data\"\nserver_configs:\n  pd:\n    replication.location-labels: [\"az\",\"rack\",\"host\"]\npd_servers:\n  - host: 10.63.10.10\n    name: \"pd-10\"\n  - host: 10.63.10.11\n    name: \"pd-11\"\n  - host: 10.63.10.12\n    name: \"pd-12\"\ntidb_servers:\n  - host: 10.63.10.10\n  - host: 10.63.10.11\n  - host: 10.63.10.12\ntikv_servers:\n  - host: 10.63.10.30\n    config:\n      server.labels: { az: \"east\", rack: \"east-1\", host: \"30\" }\n  - host: 10.63.10.31\n    config:\n      server.labels: { az: \"east\", rack: \"east-2\", host: \"31\" }\n  - host: 10.63.10.32\n    config:\n      server.labels: { az: \"east\", rack: \"east-3\", host: \"32\" }\n  - host: 10.63.10.33\n    config:\n      server.labels: { az: \"west\", rack: \"west-1\", host: \"33\" }\n  - host: 10.63.10.34\n    config:\n      server.labels: { az: \"west\", rack: \"west-2\", host: \"34\" }\n  - host: 10.63.10.35\n    config:\n      server.labels: { az: \"west\", rack: \"west-3\", host: \"35\" }\nmonitoring_servers:\n  - host: 10.63.10.60\ngrafana_servers:\n  - host: 10.63.10.60\nalertmanager_servers:\n  - host: 10.63.10.60\n```\n\n----------------------------------------\n\nTITLE: SHOW PROFILES Syntax Definition\nDESCRIPTION: This EBNF diagram defines the syntax for the `SHOW PROFILES` statement, including optional `LIKE` or `WHERE` clauses for filtering profiles. However, in TiDB, this command always returns an empty result.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-profiles.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\n\"SHOW\" \"PROFILES\" ShowLikeOrWhere?\n\nShowLikeOrWhere ::=\n    \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Clean Up TPC-H Data with TiUP Bench (Bash)\nDESCRIPTION: This command cleans up the data associated with a TPC-H benchmark.  It employs the `cleanup` subcommand of the TiUP bench tpch component to remove the benchmark data from the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench tpch cleanup\n```\n\n----------------------------------------\n\nTITLE: Querying CPU Information from CLUSTER_HARDWARE Table in SQL\nDESCRIPTION: This SQL query retrieves CPU core information for all instances in the cluster from the CLUSTER_HARDWARE table, filtering for CPU device type and core-related data.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-hardware.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM cluster_hardware WHERE device_type='cpu' AND device_name='cpu' AND name LIKE '%cores';\n```\n\n----------------------------------------\n\nTITLE: Executing pause-task Command in TiDB Data Migration\nDESCRIPTION: Demonstrates how to pause a data migration task with optional source specification.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-pause-task.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npause-task [-s \"mysql-replica-01\"] task-name\n```\n\n----------------------------------------\n\nTITLE: Terraform Apply Command for Resuming Cluster\nDESCRIPTION: Similar to pausing a cluster, this command outlines the process of using 'terraform apply' to resume a cluster state. It shows expected output indicating the resource's transition to the 'RESUMING' status.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform apply\n\n# tidbcloud_cluster.example_cluster:\nresource \"tidbcloud_cluster\" \"example_cluster\" {\n    cloud_provider = \"AWS\"\n    cluster_type   = \"DEDICATED\"\n    config         = {\n        components     = {\n            tidb    = {\n                node_quantity = 2\n                node_size     = \"8C16G\"\n            }\n            tiflash = {\n                node_quantity    = 2\n                node_size        = \"8C64G\"\n                storage_size_gib = 500\n            }\n            tikv    = {\n                node_quantity    = 6\n                node_size     = \"8C32G\"\n                storage_size_gib = 500\n            }\n        }\n        ip_access_list = [\n            # (1 unchanged element hidden)\n        ]\n        paused         = false\n        port           = 4000\n        root_password  = \"Your_root_password1.\"\n    }\n    id             = \"1379661944630234067\"\n    name           = \"firstCluster\"\n    project_id     = \"1372813089189561287\"\n    region         = \"eu-central-1\"\n    status         = \"RESUMING\"\n}\n```\n\n----------------------------------------\n\nTITLE: Error Summary Example Output\nDESCRIPTION: Shows the complete output of the error summary example, including the division by zero warning and its corresponding entry in the CLIENT_ERRORS_SUMMARY_GLOBAL table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/client-errors-summary-global.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+-----+\n| 0/0 |\n+-----+\n| NULL |\n+-----+\n1 row in set, 1 warning (0.00 sec)\n\n+--------------+---------------+-------------+---------------+---------------------+---------------------+\n| ERROR_NUMBER | ERROR_MESSAGE | ERROR_COUNT | WARNING_COUNT | FIRST_SEEN          | LAST_SEEN           |\n+--------------+---------------+-------------+---------------+---------------------+---------------------+\n|         1365 | Division by 0 |           0 |             1 | 2021-03-18 13:10:51 | 2021-03-18 13:10:51 |\n+--------------+---------------+-------------+---------------+---------------------+---------------------+\nEmpty set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting Session Variable for Pipelined DML in SQL\nDESCRIPTION: Enables Pipelined DML for the current session by setting the 'tidb_dml_type' system variable to 'bulk'. This configuration is needed to activate Pipelined DML functionality in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/pipelined-dml.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_dml_type = \"bulk\";\n```\n\n----------------------------------------\n\nTITLE: ALTER RESOURCE GROUP Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the ALTER RESOURCE GROUP statement in TiDB. It specifies the structure and allowed options for modifying resource groups.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-resource-group.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nAlterResourceGroupStmt ::=\n   \"ALTER\" \"RESOURCE\" \"GROUP\" IfExists ResourceGroupName ResourceGroupOptionList\n\nIfExists ::=\n    ('IF' 'EXISTS')?\n\nResourceGroupName ::=\n    Identifier\n|   \"DEFAULT\"\n\nResourceGroupOptionList ::=\n    DirectResourceGroupOption\n|   ResourceGroupOptionList DirectResourceGroupOption\n|   ResourceGroupOptionList ',' DirectResourceGroupOption\n\nDirectResourceGroupOption ::=\n    \"RU_PER_SEC\" EqOpt LengthNum\n|   \"PRIORITY\" EqOpt ResourceGroupPriorityOption\n|   \"BURSTABLE\"\n|   \"BURSTABLE\" EqOpt Boolean\n|   \"QUERY_LIMIT\" EqOpt '(' ResourceGroupRunawayOptionList ')'\n|   \"QUERY_LIMIT\" EqOpt '(' ')'\n|   \"QUERY_LIMIT\" EqOpt \"NULL\"\n|   \"BACKGROUND\" EqOpt '(' BackgroundOptionList ')'\n|   \"BACKGROUND\" EqOpt '(' ')'\n|   \"BACKGROUND\" EqOpt \"NULL\"\n\nResourceGroupPriorityOption ::=\n    LOW\n|   MEDIUM\n|   HIGH\n\nResourceGroupRunawayOptionList ::=\n    DirectResourceGroupRunawayOption\n|   ResourceGroupRunawayOptionList DirectResourceGroupRunawayOption\n|   ResourceGroupRunawayOptionList ',' DirectResourceGroupRunawayOption\n\nDirectResourceGroupRunawayOption ::=\n    \"EXEC_ELAPSED\" EqOpt stringLit\n|   \"PROCESSED_KEYS\" EqOpt intLit\n|   \"RU\" EqOpt intLit\n|   \"ACTION\" EqOpt ResourceGroupRunawayActionOption\n|   \"WATCH\" EqOpt ResourceGroupRunawayWatchOption \"DURATION\" EqOpt stringLit\n\nResourceGroupRunawayWatchOption ::=\n    EXACT\n|   SIMILAR\n\nResourceGroupRunawayActionOption ::=\n    DRYRUN\n|   COOLDOWN\n|   KILL\n| \"SWITCH_GROUP\" '(' ResourceGroupName ')'\n\nBackgroundOptionList ::=\n    DirectBackgroundOption\n|   BackgroundOptionList DirectBackgroundOption\n|   BackgroundOptionList ',' DirectBackgroundOption\n\nDirectBackgroundOption ::=\n    \"TASK_TYPES\" EqOpt stringLit\n|   \"UTILIZATION_LIMIT\" EqOpt LengthNum\n```\n\n----------------------------------------\n\nTITLE: TiUP Cluster Check Command Syntax\nDESCRIPTION: Basic command syntax for running system checks using TiUP cluster check\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-check.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster check <topology.yml | cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Configuring Continuous Data Validation in YAML\nDESCRIPTION: This snippet defines the configuration for continuous data validation in DM tasks. It specifies the validation mode, worker count, and error delay time.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/task-configuration-file-full.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nvalidators:\n  global:                # Configuration name.\n    mode: full           # Possible values are \"full\", \"fast\", and \"none\". The default value is \"none\", which does not validate the data.\n    worker-count: 4      # The number of validation workers in the background. The default value is 4.\n    row-error-delay: 30m # If a row cannot pass the validation within the specified time, it will be marked as an error row. The default value is 30m, which means 30 minutes.\n```\n\n----------------------------------------\n\nTITLE: Managing TiKV Service for Azure AD Authentication\nDESCRIPTION: Commands to edit, reload, and restart the TiKV systemd service after configuring Azure AD environment variables for backup and restore operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nsystemctl edit tikv-24000\n```\n\nLANGUAGE: shell\nCODE:\n```\nsystemctl daemon-reload\nsystemctl restart tikv-24000\n```\n\n----------------------------------------\n\nTITLE: Describing TIKV_REGION_PEERS Table Structure in SQL\nDESCRIPTION: This SQL snippet shows how to view the structure of the TIKV_REGION_PEERS table in the INFORMATION_SCHEMA database.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tikv-region-peers.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC TIKV_REGION_PEERS;\n```\n\n----------------------------------------\n\nTITLE: Setting Concurrency Parameters in SQL\nDESCRIPTION: These SQL statements set concurrency parameters to accelerate the collection of statistics. These parameters control the number of concurrent threads used for building statistics and scanning data. Modifying these parameters can reduce the time it takes to collect table statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n\"SET tidb_build_stats_concurrency=16;\\nSET tidb_distsql_scan_concurrency=16;\\nSET tidb_index_serial_scan_concurrency=16;\"\n```\n\n----------------------------------------\n\nTITLE: Validating Import Consistency with Terraform Plan\nDESCRIPTION: This command runs a plan to check for any discrepancies between the Terraform state and configuration, ensuring a successful import and consistency before further operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform apply\n\ntidbcloud_cluster.import_cluster: Refreshing state... [id=1379661944630264072]\n\nNo changes. Your infrastructure matches the configuration.\n\nTerraform has compared your real infrastructure against your configuration and found no differences, so no changes are needed.\n\nApply complete! Resources: 0 added, 0 changed, 0 destroyed.\n```\n\n----------------------------------------\n\nTITLE: Showing Table Schema in SQL\nDESCRIPTION: Displays the schema of the specified table in the upstream database using the SQL command SHOW CREATE TABLE. This command requires access to the database and the relevant table (`db1.tbl1`) to retrieve its schema definition, displaying the table's structure and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE db1.tbl1;\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into a Partitioned Table in TiDB\nDESCRIPTION: This SQL statement inserts sample data into a partitioned table in TiDB. It's used to set up the example for demonstrating result ordering differences.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_69\n\nLANGUAGE: SQL\nCODE:\n```\ninsert into t values (1, 2), (3, 4),(5, 6),(7,8),(9,10);\n```\n\n----------------------------------------\n\nTITLE: Importing S3 Data with Local Permissions - Bash\nDESCRIPTION: This snippet shows how to use TiDB Lightning to import data from an S3 bucket using locally configured permissions. It requires the TiUP tool and specifies the TiDB server connection details along with the S3 data path.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ntiup tidb-lightning --tidb-port=4000 --pd-urls=127.0.0.1:2379 --backend=local --sorted-kv-dir=/tmp/sorted-kvs \\\n    -d 's3://my-bucket/sql-backup'\n```\n\n----------------------------------------\n\nTITLE: Querying TiKV region status in TiDB\nDESCRIPTION: The INFORMATION_SCHEMA.TIKV_REGION_STATUS table in TiDB provides information about TiKV regions. An issue with incorrect results from this table has been fixed in this release.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.4.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.TIKV_REGION_STATUS;\n```\n\n----------------------------------------\n\nTITLE: Getting Help Information for TiUP Mirror Command\nDESCRIPTION: This command displays the help information for TiUP's mirror command, showing all available subcommands and their purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup mirror --help\n```\n\n----------------------------------------\n\nTITLE: Specifying Background Task Type in SQL Session\nDESCRIPTION: This SQL script demonstrates how to specify a task type as background for a session using `tidb_request_source_type`. It includes executing a data load operation after setting the task type for the current session.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-background-tasks.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSET @@tidb_request_source_type=\"background\";\n/* Add background task type */\nALTER RESOURCE GROUP `default` BACKGROUND=(TASK_TYPES=\"background\");\n/* Execute LOAD DATA in the current session */\nLOAD DATA INFILE \"s3://resource-control/Lightning/test.customer.aaaa.csv\"\n```\n\n----------------------------------------\n\nTITLE: Configure branch.autoDestroy in tidbcloud.yml\nDESCRIPTION: This snippet shows configuring the `branch.autoDestroy` property within the `tidbcloud.yml` file. Setting `branch.autoDestroy` to `false` prevents the TiDB Cloud Branching app from deleting the TiDB Cloud Serverless branch when a pull request is closed or merged. The default value is `true`.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/branch-github-integration.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n\"github:\\n    branch:\\n        autoDestroy: true\"\n```\n\n----------------------------------------\n\nTITLE: Viewing Expression Pushdown Blocklist Schema\nDESCRIPTION: SQL command to view the structure of the expression pushdown blocklist table.\nSOURCE: https://github.com/pingcap/docs/blob/master/blocklist-control-plan.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nDESC mysql.expr_pushdown_blacklist;\n```\n\n----------------------------------------\n\nTITLE: Configuring Incremental Data Migration in YAML\nDESCRIPTION: YAML configuration for incremental data migration using binlog positioning. This snippet shows how to configure source databases, block-allow lists, routing rules, and binlog positions for migrating from MySQL instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\n#       syncer-config-name: \"global\"  # Use the syncers configuration below.\n    meta:                             # The position where the binlog replication starts when `task-mode` is `incremental` and the downstream database checkpoint does not exist. If the checkpoint exists, the checkpoint is used. If neither the `meta` configuration item nor the downstream database checkpoint exists, the migration starts from the latest binlog position of the upstream.\n      binlog-name: \"${binlog-name}\"   # The log location recorded in ${data-path}/my_db1/metadata in Step 1. You can either specify binlog-name + binlog-pos or binlog-gtid. When the upstream database service is configured to switch master between different nodes automatically, use binlog GTID here.\n      binlog-pos: ${binlog-position}\n      # binlog-gtid:                  \" For example: 09bec856-ba95-11ea-850a-58f2b4af5188:1-9\"\n  - source-id: \"mysql-02\"             # Data source ID. It is the source-id in source1.yaml.\n    block-allow-list: \"bw-rule-2\"     # Use the block and allow list configuration above. Replicate `my_db2` in instance2.\n    route-rules: [\"route-rule-2\"]     # Use the routing rule configured above.\n\n#       syncer-config-name: \"global\"  # Use the syncers configuration below.\n    meta:                             # The migration starting point of binlog when task-mode is incremental and there is no checkpoint in the downstream database. If there is a checkpoint, the checkpoint will be used.\n      # binlog-name: \"${binlog-name}\"   # The log location recorded in ${data-path}/my_db2/metadata in Step 1. You can either specify binlog-name + binlog-pos or binlog-gtid. When the upstream database service is configured to switch master between different nodes automatically, use binlog GTID here.\n      # binlog-pos: ${binlog-position}\n      binlog-gtid: \"09bec856-ba95-11ea-850a-58f2b4af5188:1-9\"\n# (Optional) If you need to incrementally replicate some data changes that have been covered in the full migration, you need to enable the safe mode to avoid data migration errors during incremental replication.\n# This scenario is common when the fully migrated data is not part of a consistent snapshot of the data source, and the incremental data is replicated from a location earlier than the fully migrated data.\n# syncers:           # The running parameters of the sync processing unit.\n#  global:           # Configuration name.\n# If set to true, DM changes INSERT to REPLACE, and changes UPDATE to a pair of DELETE and REPLACE for data source replication operations.\n# Thus, it can apply DML repeatedly during replication when primary keys or unique indexes exist in the table structure.\n# TiDB DM automatically starts safe mode within 1 minute before starting or resuming an incremental replication task.\n#    safe-mode: true\n```\n\n----------------------------------------\n\nTITLE: Ignoring Plan Cache for Prepared Statements\nDESCRIPTION: Example showing how to disable plan cache for a specific prepared statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_48\n\nLANGUAGE: sql\nCODE:\n```\nprepare stmt from 'select  /*+ IGNORE_PLAN_CACHE() */ * from t where t.id = ?';\n```\n\n----------------------------------------\n\nTITLE: Querying Type Error Table using SQL\nDESCRIPTION: Connects to the MySQL server using the command-line client and executes a `SELECT` statement to retrieve all rows from the `lightning_task_info.type_error_v1` table. This table contains information about type conversion errors encountered during the import process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n\"$ mysql -u root -h 127.0.0.1 -P 4000 -e 'select * from lightning_task_info.type_error_v1;' -E\\n\\n*************************** 1. row ***************************\\n       task_id: 1635888701843303564\\n   create_time: 2021-11-02 21:31:42.620090\\n    table_name: `example`.`t`\\n          path: example.t.1.sql\\n        offset: 46\\n         error: failed to cast value as varchar(12) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin for column `b` (#2): [table:1048]Column 'b' cannot be null\\n      row_data: (0,NULL)\\n\\n*************************** 2. row ***************************\\n       task_id: 1635888701843303564\\n   create_time: 2021-11-02 21:31:42.627496\\n    table_name: `example`.`t`\\n          path: example.t.1.sql\\n        offset: 183\\n         error: failed to cast value as varchar(12) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin for column `b` (#2): [types:1406]Data Too Long, field len 12, data len 13\\n      row_data: (77,'seventy-seven')\\n\\n*************************** 3. row ***************************\\n       task_id: 1635888701843303564\\n   create_time: 2021-11-02 21:31:42.629929\\n    table_name: `example`.`t`\\n          path: example.t.1.sql\\n        offset: 253\\n         error: failed to cast value as tinyint for column `a` (#1): [types:1690]constant 600 overflows tinyint\\n      row_data: (600,'six hundred')\"\n```\n\n----------------------------------------\n\nTITLE: Describing User Profile in TiDB Cloud CLI - Markdown\nDESCRIPTION: This snippet showcases how to describe a user profile to get its properties. It provides an example output of the command, illustrating the expected input and output structure. This command is fundamental for users to verify their profile settings and keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/cli-reference.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\nUse [`ticloud config describe`](/tidb-cloud/ticloud-config-describe.md) to get the properties of a user profile.\n```\n\n----------------------------------------\n\nTITLE: Explaining Query Execution Plan with Default tidb_opt_range_max_size in TiDB\nDESCRIPTION: This SQL query explains the execution plan for a SELECT statement using the default tidb_opt_range_max_size value. It demonstrates how the optimizer builds exact scan ranges within the 64 MiB memory limit.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_69\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t use index (idx) WHERE a IN (10,20,30) AND b IN (40,50,60);\n```\n\n----------------------------------------\n\nTITLE: Using TiDB Lightning with Table Filters\nDESCRIPTION: Example of using table filters with TiDB Lightning tool to import schemas matching 'foo*' and 'bar*' patterns\nSOURCE: https://github.com/pingcap/docs/blob/master/table-filter.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup tidb-lightning -f 'foo*.*' -f 'bar*.*' -d /tmp/data/ --backend tidb\n```\n\n----------------------------------------\n\nTITLE: Configuring Terraform for TiDB Cloud Cluster Creation\nDESCRIPTION: This snippet defines the Terraform configuration for creating a TiDB Cloud Dedicated cluster. It specifies the required provider, authentication details, and cluster specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_2\n\nLANGUAGE: HCL\nCODE:\n```\nterraform {\n  required_providers {\n    tidbcloud = {\n      source = \"tidbcloud/tidbcloud\"\n    }\n  }\n}\n\nprovider \"tidbcloud\" {\n  public_key = \"your_public_key\"\n  private_key = \"your_private_key\"\n  sync = true\n}\n\nresource \"tidbcloud_cluster\" \"example_cluster\" {\n  project_id     = \"1372813089189561287\"\n  name           = \"firstCluster\"\n  cluster_type   = \"DEDICATED\"\n  cloud_provider = \"AWS\"\n  region         = \"eu-central-1\"\n  config = {\n    root_password = \"Your_root_password1.\"\n    port = 4000\n    components = {\n      tidb = {\n        node_size : \"8C16G\"\n        node_quantity : 1\n      }\n      tikv = {\n        node_size : \"8C32G\"\n        storage_size_gib : 500,\n        node_quantity : 3\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying TiKV Compaction Filter Configuration\nDESCRIPTION: SQL command to show the current configuration of the enable-compaction-filter option for all TiKV instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/garbage-collection-configuration.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nshow config where type = 'tikv' and name like '%enable-compaction-filter%';\n```\n\n----------------------------------------\n\nTITLE: Querying PD Server Status - Bash/JSON\nDESCRIPTION: Example of querying the Placement Driver (PD) API to get status information about TiKV stores including capacity, leader counts, and heartbeat details.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-monitoring-api.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:2379/pd/api/v1/stores\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"count\": 1,\n  \"stores\": [\n    {\n      \"store\": {\n        \"id\": 1,\n        \"address\": \"127.0.0.1:20160\",\n        \"version\": \"3.0.0-beta\",\n        \"state_name\": \"Up\"\n      },\n      \"status\": {\n        \"capacity\": \"20 GiB\",\n        \"available\": \"16 GiB\",\n        \"leader_count\": 17,\n        \"leader_weight\": 1,\n        \"leader_score\": 17,\n        \"leader_size\": 17,\n        \"region_count\": 17,\n        \"region_weight\": 1,\n        \"region_score\": 17,\n        \"region_size\": 17,\n        \"start_ts\": \"2019-03-21T14:09:32+08:00\",\n        \"last_heartbeat_ts\": \"2019-03-21T14:14:22.961171958+08:00\",\n        \"uptime\": \"4m50.961171958s\"\n      }\n    }\n  ]\n```\n\n----------------------------------------\n\nTITLE: Generating a Private Key with TiUP\nDESCRIPTION: The command 'tiup mirror genkey' generates a private key for TiUP users based on specified flags such as the key name and options to display or save the public key.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-genkey.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror genkey [flags]\n```\n\n----------------------------------------\n\nTITLE: TiCDC Command-line Username/Password Authentication\nDESCRIPTION: Specify username and password for TiCDC command-line tool using various methods like command-line parameters, environment variables, or shared credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-client-authentication.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncdc cli changefeed list --user test --password password\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport TICDC_USER=test\nexport TICDC_PASSWORD=password\n```\n\n----------------------------------------\n\nTITLE: Example: Checking Compaction State of a Partitioned Table\nDESCRIPTION: Complete example showing how to create a partitioned table with TiFlash replica, insert data, and monitor the compaction state of individual partitions before and after compaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table-compact.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nUSE test;\n\nCREATE TABLE employees\n    (id INT NOT NULL, store_id INT)\n    PARTITION BY LIST (store_id) (\n        PARTITION pNorth VALUES IN (1, 2, 3, 4, 5),\n        PARTITION pEast VALUES IN (6, 7, 8, 9, 10),\n        PARTITION pWest VALUES IN (11, 12, 13, 14, 15),\n        PARTITION pCentral VALUES IN (16, 17, 18, 19, 20)\n    );\n\nALTER TABLE employees SET TIFLASH REPLICA 1;\n\nINSERT INTO employees VALUES (1, 1), (6, 6), (10, 10);\n\nSELECT PARTITION_NAME, TOTAL_DELTA_ROWS, TOTAL_STABLE_ROWS\n    FROM INFORMATION_SCHEMA.TIFLASH_TABLES t, INFORMATION_SCHEMA.PARTITIONS p\n    WHERE t.IS_TOMBSTONE = 0 AND t.TABLE_ID = p.TIDB_PARTITION_ID AND\n    p.TABLE_SCHEMA = \"test\" AND p.TABLE_NAME = \"employees\";\n+----------------+------------------+-------------------+\n| PARTITION_NAME | TOTAL_DELTA_ROWS | TOTAL_STABLE_ROWS |\n+----------------+------------------+-------------------+\n| pNorth         |                1 |                 0 |\n| pEast          |                2 |                 0 |\n| pWest          |                0 |                 0 |\n| pCentral       |                0 |                 0 |\n+----------------+------------------+-------------------+\n-- Some partitions can be compacted\n\nALTER TABLE employees COMPACT TIFLASH REPLICA;\n\nSELECT PARTITION_NAME, TOTAL_DELTA_ROWS, TOTAL_STABLE_ROWS\n    FROM INFORMATION_SCHEMA.TIFLASH_TABLES t, INFORMATION_SCHEMA.PARTITIONS p\n    WHERE t.IS_TOMBSTONE = 0 AND t.TABLE_ID = p.TIDB_PARTITION_ID AND\n    p.TABLE_SCHEMA = \"test\" AND p.TABLE_NAME = \"employees\";\n+----------------+------------------+-------------------+\n| PARTITION_NAME | TOTAL_DELTA_ROWS | TOTAL_STABLE_ROWS |\n+----------------+------------------+-------------------+\n| pNorth         |                0 |                 1 |\n| pEast          |                0 |                 2 |\n| pWest          |                0 |                 0 |\n| pCentral       |                0 |                 0 |\n+----------------+------------------+-------------------+\n-- Data in all partitions is in the best state and no compaction is needed\n```\n\n----------------------------------------\n\nTITLE: Using TIDB_PARSE_TSO_LOGICAL with Another TSO Value\nDESCRIPTION: Demonstrates using TIDB_PARSE_TSO_LOGICAL with a different TSO value to show how the logical counter increments for sequential timestamps issued at the same physical time.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_PARSE_TSO_LOGICAL(450456244814610434);\n```\n\n----------------------------------------\n\nTITLE: Running TiDB Lightning with nohup\nDESCRIPTION: Bash script to run TiDB Lightning using nohup, which allows the process to continue running even after the terminal session ends.\nSOURCE: https://github.com/pingcap/docs/blob/master/get-started-with-tidb-lightning.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n#!/bin/bash\nnohup tiup tidb-lightning -config tidb-lightning.toml > nohup.out &\n```\n\n----------------------------------------\n\nTITLE: Running TiDB Lightning with Shell\nDESCRIPTION: Executes the TiDB Lightning command-line tool, specifying the configuration file. This command initiates the data import process based on the configuration settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup tidb-lightning -c config.toml\"\n```\n\n----------------------------------------\n\nTITLE: Using Aliases in SELECT Statement\nDESCRIPTION: Demonstrate using identifiers and string literals as column aliases in a SELECT statement\nSOURCE: https://github.com/pingcap/docs/blob/master/schema-object-names.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1 AS `identifier`, 2 AS 'string';\n```\n\n----------------------------------------\n\nTITLE: View Region Size\nDESCRIPTION: Command to view the size of a specific region across different column families.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir /path/to/tikv size -r 2\n```\n\n----------------------------------------\n\nTITLE: Using SELECT ... INTO OUTFILE in SQL\nDESCRIPTION: Writes the result of a SQL query to a specified file. This example demonstrates a basic usage of the SELECT ... INTO OUTFILE statement without any additional formatting options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-select.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SELECT * FROM t INTO OUTFILE '/tmp/tmp_file1';\nQuery OK, 3 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Correcting Database Visibility in TiDB\nDESCRIPTION: Resolves an issue where database visibility was incompatible with MySQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW DATABASES\n```\n\n----------------------------------------\n\nTITLE: Creating UTF-8 Table in TiDB Pre-v2.1.1\nDESCRIPTION: Example of creating a table with UTF-8 charset before TiDB v2.1.1, which may cause compatibility issues during upgrade\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/upgrade-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(a varchar(10)) charset=utf8;\n```\n\n----------------------------------------\n\nTITLE: TiUP Cluster Import Command Syntax\nDESCRIPTION: Basic syntax for the TiUP cluster import command used to transfer TiDB clusters from TiDB Ansible to TiUP management.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-import.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster import [flags]\n```\n\n----------------------------------------\n\nTITLE: Complex Set Operation with Precedence\nDESCRIPTION: Demonstrates operator precedence in set operations where INTERSECT has higher precedence than UNION.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/set-operators.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 UNION ALL SELECT * FROM t1 INTERSECT SELECT * FROM t2;\n```\n\n----------------------------------------\n\nTITLE: Creating Table with JSON Default Using Expression\nDESCRIPTION: Example showing how to create a table with a JSON column using JSON_OBJECT() function as the default value.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-default-values.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t4 (\n  id bigint AUTO_RANDOM PRIMARY KEY,\n  j json DEFAULT (JSON_OBJECT(\"a\", 1, \"b\", 2))\n);\n```\n\n----------------------------------------\n\nTITLE: Understanding Table Creation with Indexes\nDESCRIPTION: This SQL snippet provides examples of creating tables with multi-column indexes in TiDB. It highlights the use of JSON columns with casting to signed arrays, which is vital for optimized query performance when using Index Merge.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t5 (a INT, j JSON, b INT, k JSON, INDEX idx(a, (CAST(j AS SIGNED ARRAY))), INDEX idx2(b, (CAST(k as SIGNED ARRAY))));\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t6 (a INT, j JSON, b INT, k JSON, INDEX idx(a, (CAST(j AS SIGNED ARRAY)), b), INDEX idx2(a, (CAST(k as SIGNED ARRAY)), b));\n```\n\n----------------------------------------\n\nTITLE: Splitting a Range in a Specific Partition in SQL\nDESCRIPTION: This SQL snippet splits the data in the partition 'p1' of table 't' in the range [0,10000] into two regions, optimizing data distribution within that specific partition.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_27\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT PARTITION TABLE t PARTITION (p1) BETWEEN (0) AND (10000) REGIONS 2;\n```\n\n----------------------------------------\n\nTITLE: Setting Transaction Characteristics for Historical Reads in SQL\nDESCRIPTION: SQL command to configure the next transaction to read data as it existed at a specific point in time, affecting only the subsequent transaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nset transaction read only as of timestamp '2021-05-26 16:45:26';\n```\n\n----------------------------------------\n\nTITLE: Pessimistic Transaction Unique Constraint Example\nDESCRIPTION: Demonstrates basic unique constraint checking in pessimistic transactions using a users table with a unique username field.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nDROP TABLE IF EXISTS users;\nCREATE TABLE users (\n id INT NOT NULL PRIMARY KEY AUTO_INCREMENT,\n username VARCHAR(60) NOT NULL,\n UNIQUE KEY (username)\n);\nINSERT INTO users (username) VALUES ('dave'), ('sarah'), ('bill');\n\nBEGIN PESSIMISTIC;\nINSERT INTO users (username) VALUES ('jane'), ('chris'), ('bill');\n```\n\n----------------------------------------\n\nTITLE: Example Response for Schema List in JSON\nDESCRIPTION: This JSON represents the response format when retrieving the list of schema names from a data source. It returns an array of database names available in the source.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_23\n\nLANGUAGE: json\nCODE:\n```\n[\n  \"db1\"\n]\n```\n\n----------------------------------------\n\nTITLE: Copying OpenSSL Configuration Template\nDESCRIPTION: Command to copy the OpenSSL configuration template file to the current directory for customization.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncp /usr/lib/ssl/openssl.cnf .\n```\n\n----------------------------------------\n\nTITLE: Starting Prometheus Service\nDESCRIPTION: Command to start the Prometheus service with specific configurations for storage, web interface, and logging\nSOURCE: https://github.com/pingcap/docs/blob/master/deploy-monitoring-services.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./prometheus \\\n    --config.file=\"./prometheus.yml\" \\\n    --web.listen-address=\":9090\" \\\n    --web.external-url=\"http://192.168.199.113:9090/\" \\\n    --web.enable-admin-api \\\n    --log.level=\"info\" \\\n    --storage.tsdb.path=\"./data.metrics\" \\\n    --storage.tsdb.retention=\"15d\" &\n```\n\n----------------------------------------\n\nTITLE: Applying PERCENT_RANK() Window Function in SQL\nDESCRIPTION: This example demonstrates the PERCENT_RANK() function, which calculates the relative rank of a row within a result set. It shows the function's behavior with both ascending and descending order.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/window-functions.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    *,\n    PERCENT_RANK() OVER (ORDER BY n),\n    PERCENT_RANK() OVER (ORDER BY n DESC)\nFROM (\n    SELECT 5 AS 'n'\n    UNION ALL\n    SELECT 8\n    UNION ALL\n    SELECT 5\n    UNION ALL\n    SELECT 30\n    UNION ALL\n    SELECT 31\n    UNION ALL\n    SELECT 32) a;\n```\n\n----------------------------------------\n\nTITLE: Creating Sample Table for CSV Protocol in SQL\nDESCRIPTION: This SQL statement creates a sample 'employee' table in the 'hr' schema. The table includes columns for ID, LastName, FirstName, HireDate, and OfficeLocation, which will be used to demonstrate CSV protocol output.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-csv.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `employee` (\n  `Id` int NOT NULL,\n  `LastName` varchar(20) DEFAULT NULL,\n  `FirstName` varchar(30) DEFAULT NULL,\n  `HireDate` date DEFAULT NULL,\n  `OfficeLocation` varchar(20) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n```\n\n----------------------------------------\n\nTITLE: Displaying HAProxy Help Information\nDESCRIPTION: Command to display HAProxy command-line options and usage information.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/haproxy-best-practices.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nhaproxy --help\n```\n\n----------------------------------------\n\nTITLE: Specifying Switch Mode Duration in TiDB\nDESCRIPTION: Indicates the duration for which TiDB Lightning automatically refreshes the import mode status, ensuring synchronization with TiKV settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_25\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- Example: `\"5m\"` -->\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Data Migration (DM) using TiUP\nDESCRIPTION: This shell command installs TiDB Data Migration (DM) and its command-line tool dmctl using the TiUP package manager. It first downloads and runs the TiUP installation script, then uses TiUP to install DM and dmctl.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\ntiup install dm dmctl\n```\n\n----------------------------------------\n\nTITLE: System Variable Code Reference\nDESCRIPTION: Reference to timeout configuration value for downstream Kafka connection\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_21\n\nLANGUAGE: plaintext\nCODE:\n```\n10s\n```\n\n----------------------------------------\n\nTITLE: Resource Capacity Estimation Error - CPU Quota\nDESCRIPTION: Error message shown when CPU quota metrics data is missing during capacity estimation.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-resource-manager.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nError 1105 (HY000): There is no CPU quota metrics, metrics 'tikv_cpu_quota' is empty\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for Show Table Regions\nDESCRIPTION: Formal grammar definition for the SHOW TABLE REGIONS statement, specifying the structure and components of the SQL command.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-regions.md#2025-04-18_snippet_1\n\nLANGUAGE: ebnf\nCODE:\n```\nShowTableRegionStmt ::=\n    \"SHOW\" \"TABLE\" TableName PartitionNameList? (\"INDEX\" IndexName)? \"REGIONS\" (\"WHERE\" Expression)?\n\nTableName ::=\n    (SchemaName \".\"?)? Identifier\n```\n\n----------------------------------------\n\nTITLE: Copying Environment File in Linux\nDESCRIPTION: Command to copy the .env.example file to .env in a Linux environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nextjs.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Creating User with Password Expiration in SQL\nDESCRIPTION: SQL commands to create a new user with a password that expires every 90 days. This sets an account-level password expiration policy.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_14\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE USER 'test'@'localhost' PASSWORD EXPIRE INTERVAL 90 DAY;\n```\n\n----------------------------------------\n\nTITLE: Redeclaring Global Environment Variables\nDESCRIPTION: This command sources the .bash_profile to update environment variables after installing TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup-offline.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsource .bash_profile\n```\n\n----------------------------------------\n\nTITLE: TiFlash File-based Master Key Configuration\nDESCRIPTION: Configuration for using a file-based master key, specifying the key file path.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_12\n\nLANGUAGE: toml\nCODE:\n```\n[security.encryption.master-key]\ntype = \"file\"\npath = \"/path/to/key/file\"\n```\n\n----------------------------------------\n\nTITLE: Using Placeholders in SQL Queries\nDESCRIPTION: TiDB now supports using ? placeholders in ORDER BY, GROUP BY, and LIMIT OFFSET clauses of SQL queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.18.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM table ORDER BY ? LIMIT ? OFFSET ?;\n```\n\n----------------------------------------\n\nTITLE: Canceling Import Task in Interactive Mode\nDESCRIPTION: This example demonstrates how to cancel an import task using the TiDB Cloud CLI in interactive mode. In this mode, the user will be prompted for necessary information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-cancel.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import cancel\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Source in YAML\nDESCRIPTION: This YAML snippet configures a data source for DM, defining connection parameters for an upstream MySQL instance. It includes the source ID, GTID enablement, host, user, password, and port. The host and password are parameterized, requiring actual values during deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-shards-to-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n\"# Configuration.\nsource-id: \\\"mysql-01\\\" # Must be unique.\n# Specifies whether DM-worker pulls binlogs with GTID (Global Transaction Identifier).\n# The prerequisite is that you have already enabled GTID in the upstream MySQL.\n# If you have configured the upstream database service to switch master between different nodes automatically, you must enable GTID.\nenable-gtid: true\nfrom:\n  host: \\\"${host}\\\"           # For example: 172.16.10.81\n  user: \\\"root\\\"\n  password: \\\"${password}\\\"   # Plaintext passwords are supported but not recommended. It is recommended that you use dmctl encrypt to encrypt plaintext passwords.\n  port: ${port}             # For example: 3306\"\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Vector Client in Python\nDESCRIPTION: Command to install TiDB Vector Client Python package for vector search functionality\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integration-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install tidb-vector[client]\n```\n\n----------------------------------------\n\nTITLE: Vector Comparison in SQL\nDESCRIPTION: Shows how to compare vector data types using comparison operators and functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-data-types.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT VEC_FROM_TEXT('[12.0]') < VEC_FROM_TEXT('[4.0]');\n```\n\n----------------------------------------\n\nTITLE: Rewritable INSERT Statements with VALUES Function\nDESCRIPTION: Modified INSERT statements with ON DUPLICATE KEY UPDATE clauses that can be rewritten because they use the VALUES function, making them uniform enough for batch rewriting.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO `t` (`a`) VALUES (10) ON DUPLICATE KEY UPDATE `a` = VALUES(`a`);\nINSERT INTO `t` (`a`) VALUES (11) ON DUPLICATE KEY UPDATE `a` = VALUES(`a`);\nINSERT INTO `t` (`a`) VALUES (12) ON DUPLICATE KEY UPDATE `a` = VALUES(`a`);\n```\n\n----------------------------------------\n\nTITLE: Creating TiFlash Database Replicas\nDESCRIPTION: SQL command to set up TiFlash replicas for the tpcc database, enabling real-time data replication from TiKV to TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-ch.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER DATABASE tpcc SET tiflash replica 2;\n```\n\n----------------------------------------\n\nTITLE: Creating Data Stream in Snowflake - SQL\nDESCRIPTION: Defines a stream named `TEST_ITEM_STREAM` on `TIDB_TEST_ITEM`. This stream is `append_only`, capturing only INSERT events in real-time.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\ncreate or replace stream TEST_ITEM_STREAM on table TIDB_TEST_ITEM append_only=true;\n```\n\n----------------------------------------\n\nTITLE: Configuring Package.json for ES Modules\nDESCRIPTION: Configure package.json to use ES modules by adding the \"type\": \"module\" field.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-kysely-example.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"module\",\n  \"dependencies\": {\n    \"@tidbcloud/kysely\": \"^0.0.4\",\n    \"@tidbcloud/serverless\": \"^0.0.7\",\n    \"kysely\": \"^0.26.3\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: New System Table Query\nDESCRIPTION: Demonstrates the addition of tidb_table_id column in infoschema.tables and new tidb_indexes system table for managing Table and Index relationships\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.7.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT tidb_table_id FROM infoschema.tables;\n```\n\n----------------------------------------\n\nTITLE: Updating DM Cluster Configuration with TiUP\nDESCRIPTION: Commands to edit and reload the configuration of a DM cluster using TiUP. It opens the configuration file in an editor and applies changes after editing.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm edit-config prod-cluster\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm reload prod-cluster\n```\n\n----------------------------------------\n\nTITLE: Setting MySQL Path in Git Bash on Windows\nDESCRIPTION: Commands to add MySQL bin folder to PATH in Git Bash on Windows.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\necho 'export PATH=\"/c/Program Files (x86)/mysql-8.0.31-winx64/bin\":$PATH' >>~/.bash_profile\nsource ~/.bash_profile\n```\n\n----------------------------------------\n\nTITLE: Example DDL Status Output\nDESCRIPTION: Sample output from ADMIN SHOW DDL command showing schema version, owner ID, address, running jobs, and self ID information.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n*************************** 1. row ***************************\n   SCHEMA_VER: 26\n     OWNER_ID: 2d1982af-fa63-43ad-a3d5-73710683cc63\nOWNER_ADDRESS: 0.0.0.0:4000\n RUNNING_JOBS:\n      SELF_ID: 2d1982af-fa63-43ad-a3d5-73710683cc63\n        QUERY:\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Retrieving View Metadata via HTTP API in cURL\nDESCRIPTION: This cURL command demonstrates how to retrieve metadata for a view named 'v' in the 'test' database using TiDB's HTTP API. It returns a JSON object with detailed view information.\nSOURCE: https://github.com/pingcap/docs/blob/master/views.md#2025-04-18_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\ncurl http://127.0.0.1:10080/schema/test/v\n```\n\n----------------------------------------\n\nTITLE: Querying Failed SQL Statements from TiProxy Traffic Replay Database - SQL\nDESCRIPTION: This SQL query fetches the first row from the `fail` table in the `tiproxy_traffic_replay` database. It can help in debugging failed SQL executions during replay.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-traffic-replay.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM tiproxy_traffic_replay.fail LIMIT 1\\G\n```\n\n----------------------------------------\n\nTITLE: Splitting Table Index in TiDB SQL\nDESCRIPTION: Adds syntax to split a table index, supporting Region presplit to solve hotspot issues in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.13.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSPLIT TABLE table_name INDEX index_name\n```\n\n----------------------------------------\n\nTITLE: Cloning the Sample App Repository in Bash\nDESCRIPTION: Commands to clone the sample code repository and navigate to the project directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nextjs.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:tidb-samples/tidb-nextjs-vercel-quickstart.git\ncd tidb-nextjs-vercel-quickstart\n```\n\n----------------------------------------\n\nTITLE: Prisma Connection String Format for TiDB Cloud\nDESCRIPTION: The Prisma connection string format returned by TiDB Cloud CLI that will be used to connect the Netlify application to the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndatasource db {\nprovider = \"mysql\"\nurl      = \"mysql://<User>:<Password>@<Endpoint>:<Port>/<Database>?sslaccept=strict\"\n}\n```\n\n----------------------------------------\n\nTITLE: Running TiDB Lightning Import\nDESCRIPTION: Executes TiDB Lightning with the specified configuration file to perform the schema migration\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-faq.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ntiup tidb-lightning -config /tmp/tidb-lightning.toml\n```\n\n----------------------------------------\n\nTITLE: Package.json Configuration for ES Modules\nDESCRIPTION: JSON configuration for package.json to enable ES modules and specify project dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-drizzle-example.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"module\",\n  \"dependencies\": {\n    \"@tidbcloud/serverless\": \"^0.1.1\",\n    \"drizzle-orm\": \"^0.31.2\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Conditional Column Selection in SQL\nDESCRIPTION: Illustrates a SELECT statement with a conditional IF clause. This query selects a column based on a condition, which can lead to unexpected column naming in the result set.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.2.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT IF(1,c,c) FROM t\n```\n\n----------------------------------------\n\nTITLE: FLUSH TABLES Syntax Definition in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the FLUSH TABLES statement in TiDB, showing all possible variations of the command including options for binlog writing, table specifications, and locking options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flush-tables.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nFlushStmt ::=\n    'FLUSH' NoWriteToBinLogAliasOpt FlushOption\n\nNoWriteToBinLogAliasOpt ::=\n    ( 'NO_WRITE_TO_BINLOG' | 'LOCAL' )?\n\nFlushOption ::=\n    'PRIVILEGES'\n|   'STATUS'\n|    'TIDB' 'PLUGINS' PluginNameList\n|    'HOSTS'\n|    LogTypeOpt 'LOGS'\n|    TableOrTables TableNameListOpt WithReadLockOpt\n\nLogTypeOpt ::=\n    ( 'BINARY' | 'ENGINE' | 'ERROR' | 'GENERAL' | 'SLOW' )?\n\nTableOrTables ::=\n    'TABLE'\n|   'TABLES'\n\nTableNameListOpt ::=\n    TableNameList?\n\nWithReadLockOpt ::=\n    ( 'WITH' 'READ' 'LOCK' )?\n```\n\n----------------------------------------\n\nTITLE: TiDB Cloud Documentation Navigation Structure in Markdown\nDESCRIPTION: Hierarchical markdown navigation menu for TiDB Cloud documentation, including HTML comments for markdown linting configuration and nested documentation sections with links.\nSOURCE: https://github.com/pingcap/docs/blob/master/TOC-tidb-cloud.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- markdownlint-disable MD007 -->\n<!-- markdownlint-disable MD041 -->\n\n- [Docs Home](https://docs.pingcap.com/)\n- About TiDB Cloud\n  - [What is TiDB Cloud](/tidb-cloud/tidb-cloud-intro.md)\n  - [Architecture](/tidb-cloud/tidb-cloud-intro.md#architecture)\n  - [High Availability](/tidb-cloud/high-availability-with-multi-az.md)\n  - [MySQL Compatibility](/mysql-compatibility.md)\n  - [Roadmap](/tidb-cloud/tidb-cloud-roadmap.md)\n```\n\n----------------------------------------\n\nTITLE: Checking CPU Frequency Policy\nDESCRIPTION: Command to check the current CPU frequency scaling governor configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_28\n\nLANGUAGE: bash\nCODE:\n```\ncpupower frequency-info --policy\n```\n\n----------------------------------------\n\nTITLE: Defining ADMIN RECOVER INDEX Syntax in EBNF\nDESCRIPTION: This EBNF diagram defines the syntax for the ADMIN RECOVER INDEX statement in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-recover.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nAdminRecoverStmt ::=\n    'ADMIN' 'RECOVER' 'INDEX' TableName IndexName\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Expired Password in TiDB SQL\nDESCRIPTION: SQL statement to create a new user 'newuser9' with a manually expired password in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-user.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'newuser9'@'%' PASSWORD EXPIRE;\n```\n\n----------------------------------------\n\nTITLE: Querying Metrics Summary by Label\nDESCRIPTION: Shows how to query the metrics_summary_by_label table to get detailed monitoring data with label information.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-metrics-summary.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ time_range('2020-03-08 13:23:00','2020-03-08 13:33:00') */ *\nFROM information_schema.metrics_summary_by_label\nWHERE metrics_name LIKE 'tidb%duration'\n AND avg_value > 0\n AND quantile = 0.99\nORDER BY avg_value DESC\nLIMIT 10\\G\n```\n\n----------------------------------------\n\nTITLE: Showing BDR Role Status\nDESCRIPTION: SQL commands demonstrating how to check the current BDR role of a TiDB cluster and its output format.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-bdr-role.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW BDR ROLE;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+------------+\n| BDR_ROLE   |\n+------------+\n|            |\n+------------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Listing Branches for Specific Cluster in Non-Interactive Mode\nDESCRIPTION: This command lists all branches for a specific TiDB Cloud Serverless cluster in non-interactive mode. It requires the cluster ID to be specified using the -c flag.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-list.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch list -c <cluster-id>\n```\n\n----------------------------------------\n\nTITLE: Deleting a TiDB Cloud Cluster with Terraform\nDESCRIPTION: This snippet provides the command for deleting a TiDB Cloud cluster using Terraform, explaining the user confirmation required to proceed with the destruction of all resources.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform destroy\n\nPlan: 0 to add, 0 to change, 1 to destroy.\n\nDo you really want to destroy all resources?\nTerraform will destroy all your managed infrastructure, as shown above.\nThere is no undo. Only 'yes' will be accepted to confirm.\n\nEnter a value: yes\n```\n\n----------------------------------------\n\nTITLE: Checking Storage Engines Used in MariaDB\nDESCRIPTION: SQL query to identify the storage engines used in MariaDB tables. This helps in planning the migration strategy, especially for engines not directly supported by TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-mariadb.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n  ENGINE,\n  COUNT(*)\nFROM\n  information_schema.tables\nGROUP BY\n  ENGINE;\n```\n\n----------------------------------------\n\nTITLE: Creating a Range Partitioned Table for Partition Pruning in SQL\nDESCRIPTION: This SQL snippet creates a Range partitioned table 't1' with four partitions based on the 'region_code' column, used to demonstrate partition pruning.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_49\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n    fname VARCHAR(50) NOT NULL,\n    lname VARCHAR(50) NOT NULL,\n    region_code TINYINT UNSIGNED NOT NULL,\n    dob DATE NOT NULL\n)\n\nPARTITION BY RANGE( region_code ) (\n    PARTITION p0 VALUES LESS THAN (64),\n    PARTITION p1 VALUES LESS THAN (128),\n    PARTITION p2 VALUES LESS THAN (192),\n    PARTITION p3 VALUES LESS THAN MAXVALUE\n);\n```\n\n----------------------------------------\n\nTITLE: Showing Resource Group Definition\nDESCRIPTION: Demonstrates how to view the creation statement for a specific resource group.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-resource-groups.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE RESOURCE GROUP rg1;\n```\n\n----------------------------------------\n\nTITLE: Resource Capacity Estimation Error - Low Workload\nDESCRIPTION: Error message displayed when workload is too low or required monitoring data is missing for capacity estimation.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-resource-manager.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nError 1105 (HY000): The workload in selected time window is too low, with which TiDB is unable to reach a capacity estimation; please select another time window with higher workload, or calibrate resource by hardware instead\n```\n\n----------------------------------------\n\nTITLE: JDBC Connection Error Example\nDESCRIPTION: Example of a common JDBC connection error message that occurs when connection timeouts or failures happen. This helps in diagnosing connection pool issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nThe last packet sent successfully to the server was 3600000 milliseconds ago. The driver has not received any packets from the server. com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure\n```\n\n----------------------------------------\n\nTITLE: Changing Binding Status Using SQL Digest in TiDB\nDESCRIPTION: SQL command to change the binding status using a SQL digest instead of a SQL statement. The binding can be set to ENABLED or DISABLED.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSET BINDING [ENABLED | DISABLED] FOR SQL DIGEST 'sql_digest';\n```\n\n----------------------------------------\n\nTITLE: Getting Help for 'serveless create' Command in Shell\nDESCRIPTION: This example shows how to retrieve help information for the 'serveless create' command in TiDB Cloud CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-help.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud help serveless create\n```\n\n----------------------------------------\n\nTITLE: Displaying Stats Healthy\nDESCRIPTION: This SQL snippet displays the output of the `SHOW STATS_HEALTHY` command, showing the database name, table name, partition name, and health percentage.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-healthy.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n\"...\\nmysql> SHOW STATS_HEALTHY;\\n+---------+------------+----------------+---------+\\n| Db_name | Table_name | Partition_name | Healthy |\\n+---------+------------+----------------+---------+\\n| test    | t1         |                |     100 |\\n+---------+------------+----------------+---------+\\n1 row in set (0.00 sec)\\n\"\n```\n\n----------------------------------------\n\nTITLE: Querying with mixed AND conditions in TiDB\nDESCRIPTION: Execution plan showing how TiDB handles a mix of conditions with AND operators. The json_contains conditions use IndexMerge, while the json_length condition is applied as a Selection filter.\nSOURCE: https://github.com/pingcap/docs/blob/master/choose-index.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ use_index_merge(t4, mvi1) */ * FROM t4 WHERE json_contains(j->'$.a', '[1, 2]') AND json_contains(j->'$.a', '[3, 4]') AND json_length(j->'$.a') = 2;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------+----------------------------------------------------+\n| id                            | estRows | task      | access object                                                               | operator info                                      |\n+-------------------------------+---------+-----------+-----------------------------------------------------------------------------+----------------------------------------------------+\n| IndexMerge_11                 | 0.00    | root      |                                                                             | type: intersection                                 |\n| ├─IndexRangeScan_5(Build)     | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[1,1], keep order:false, stats:pseudo        |\n| ├─IndexRangeScan_6(Build)     | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[2,2], keep order:false, stats:pseudo        |\n| ├─IndexRangeScan_7(Build)     | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[3,3], keep order:false, stats:pseudo        |\n| ├─IndexRangeScan_8(Build)     | 10.00   | cop[tikv] | table:t4, index:mvi1(cast(json_extract(`j`, _utf8'$.a') as unsigned array)) | range:[4,4], keep order:false, stats:pseudo        |\n| └─Selection_10(Probe)         | 0.00    | cop[tikv] |                                                                             | eq(json_length(json_extract(test.t4.j, \"$.a\")), 2) |\n|   └─TableRowIDScan_9          | 0.00    | cop[tikv] | table:t4                                                                    | keep order:false, stats:pseudo                     |\n```\n\n----------------------------------------\n\nTITLE: Example of Using START TRANSACTION in TiDB\nDESCRIPTION: A practical example showing how to use START TRANSACTION in TiDB to create a table, start a transaction, insert data, and commit the changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-start-transaction.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (a int NOT NULL PRIMARY KEY);\nQuery OK, 0 rows affected (0.12 sec)\n\nmysql> START TRANSACTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> INSERT INTO t1 VALUES (1);\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> COMMIT;\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Python Program for Preventing Overselling Example\nDESCRIPTION: This Python snippet demonstrates executing a script that manages orders and prevents overselling by adjusting parameters for Alice and Bob's purchases.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\nOPTIMISTIC=True ALICE=4 BOB=7 python3 txn_example.py\n```\n\n----------------------------------------\n\nTITLE: Listing Serverless Import Tasks - Basic Command\nDESCRIPTION: Primary command to list data import tasks in interactive mode with default human-readable output\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-list.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import list\n```\n\n----------------------------------------\n\nTITLE: Querying SESSION_VARIABLES Table in SQL\nDESCRIPTION: This SQL query retrieves the first 10 rows from the SESSION_VARIABLES table, ordered by the variable name. It demonstrates how to query session variables and their values.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-session-variables.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM SESSION_VARIABLES ORDER BY variable_name LIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Accessing TiDB pprof Debugging Data\nDESCRIPTION: HTTP endpoint format for accessing pprof debugging data from TiDB server's status port.\nSOURCE: https://github.com/pingcap/docs/blob/master/command-line-flags-for-tidb-configuration.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nhttp://host:status_port/debug/pprof\n```\n\n----------------------------------------\n\nTITLE: Disabling Credential Transfer in BR Backup Command\nDESCRIPTION: Example of using BR backup command with disabled credential transfer to TiKV nodes, useful in cloud environments with IAM Role authorization.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup br backup full -c=0 -u pd-service:2379 --storage 's3://bucket-name/prefix'\n```\n\n----------------------------------------\n\nTITLE: Defining Integer Type in JSON Schema\nDESCRIPTION: This JSON snippet describes how integer types are represented in a schema file, detailing the column name, type, and precision used in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"ColumnName\":\"COL1\",\n    \"ColumnType\":\"{IT} [UNSIGNED]\",\n    \"ColumnPrecision\":\"{M}\"\n}\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration\nDESCRIPTION: YAML frontmatter configuration block defining the document title and summary for the release notes page.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.2.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n---\\ntitle: TiDB 5.3.2 Release Notes\\nsummary: TiDB 5.3.2 was released on June 29, 2022. It is not recommended to use this version due to a known bug, which has been fixed in v5.3.3. The release includes compatibility changes, improvements, and bug fixes for TiDB, PD, TiKV, TiFlash, and various tools like TiDB Data Migration, TiDB Lightning, Backup & Restore, TiCDC, and TiDB Data Migration.\\n---\n```\n\n----------------------------------------\n\nTITLE: Importing S3 Data with IAM Role Keys and Session Tokens - Bash\nDESCRIPTION: This snippet provides a method to import S3 data using a combination of access keys and session tokens for AWS IAM roles with TiDB Lightning. It's beneficial for enhanced security in AWS authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ntiup tidb-lightning --tidb-port=4000 --pd-urls=127.0.0.1:2379 --backend=local --sorted-kv-dir=/tmp/sorted-kvs \\\n    -d 's3://my-bucket/test-data?access_key={my_access_key}&secret_access_key={my_secret_access_key}&session-token={my_session_token}'\n```\n\n----------------------------------------\n\nTITLE: Defining TiDB Query Duration Alert Rule in Prometheus\nDESCRIPTION: Alert rule to monitor request handling latency in TiDB. Triggers when 99th percentile of requests exceeds 1 second.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_5\n\nLANGUAGE: prometheus\nCODE:\n```\nhistogram_quantile(0.99, sum(rate(tidb_server_handle_query_duration_seconds_bucket[1m])) BY (le, instance)) > 1\n```\n\n----------------------------------------\n\nTITLE: Loading statistics from a file in TiDB\nDESCRIPTION: This example shows how to load statistics from a file using the `LOAD STATS` statement in TiDB. The path specified can be absolute or relative to the `tidb-server`'s starting directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-load-stats.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nLOAD STATS '/tmp/stats.json';\n```\n\n----------------------------------------\n\nTITLE: Updating Data for Stale Read Demonstration in SQL\nDESCRIPTION: SQL update command that changes the value of row where c=2 to 22, creating a difference between current and historical data.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nupdate t set c=22 where c=2;\n```\n\n----------------------------------------\n\nTITLE: Cloning the Sample Application Repository\nDESCRIPTION: Command to clone the TiDB Ruby mysql2 quickstart sample repository and navigate to the project directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/tidb-samples/tidb-ruby-mysql2-quickstart.git\ncd tidb-ruby-mysql2-quickstart\n```\n\n----------------------------------------\n\nTITLE: TTL with Auto-Updating Timestamp\nDESCRIPTION: Creates a table with TTL using timestamp that updates on both creation and modification.\nSOURCE: https://github.com/pingcap/docs/blob/master/time-to-live.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n    id int PRIMARY KEY,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP\n) TTL = `created_at` + INTERVAL 3 MONTH;\n```\n\n----------------------------------------\n\nTITLE: Get Day of a Date in TiDB\nDESCRIPTION: This snippet compares getting the day of the current date in Oracle using TRUNC with TiDB's CAST and DATE_FORMAT.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nTRUNC(SYSDATE)\n```\n\nLANGUAGE: sql\nCODE:\n```\nCAST(NOW() AS DATE)\nDATE_FORMAT(NOW(),'%Y-%m-%d')\n```\n\n----------------------------------------\n\nTITLE: Filtering Critical Severity Results from INSPECTION_RESULT in SQL\nDESCRIPTION: SQL query to select only critical severity diagnostic results from the inspection_result table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-result.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nselect * from information_schema.inspection_result where severity='critical';\n```\n\n----------------------------------------\n\nTITLE: Generating Geo-Distributed Deployment Topology Template\nDESCRIPTION: Creates a template for geo-distributed TiDB clusters deployed across multiple data centers. This configuration supports geographical redundancy and disaster recovery scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster template --multi-dc > topology.yaml\n```\n\n----------------------------------------\n\nTITLE: Describing COLLATION_CHARACTER_SET_APPLICABILITY Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the COLLATION_CHARACTER_SET_APPLICABILITY table in the INFORMATION_SCHEMA database, showing the field names, types, and other attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-collation-character-set-applicability.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC COLLATION_CHARACTER_SET_APPLICABILITY;\n```\n\n----------------------------------------\n\nTITLE: Deploying TiDB Cluster with TiUP Playground - Shell\nDESCRIPTION: This shell command uses TiUP to initialize a local TiDB test environment. TiUP is a cluster management tool that simplifies executing a TiDB cluster for testing purposes. This quick start setup is recommended only for test environments and not production use.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-htap.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground\n```\n\n----------------------------------------\n\nTITLE: Updating Data and Checking Health\nDESCRIPTION: This SQL snippet demonstrates how data modifications affect statistics health. It deletes a portion of records from the table `t1` and then checks the statistics health using `SHOW STATS_HEALTHY`.  The expected health percentage decreases after the data modification.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-healthy.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n\"DELETE FROM t1 WHERE id BETWEEN 101010 AND 201010; # delete about 30% of records\\nSHOW STATS_HEALTHY; \"\n```\n\n----------------------------------------\n\nTITLE: Using STR_TO_DATE Function in TiDB\nDESCRIPTION: Fixes the handling of format tokens '%r' and '%h' in the STR_TO_DATE function for proper date string parsing.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.17.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT STR_TO_DATE('string_date', '%r %h');\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Servers with YAML\nDESCRIPTION: Example YAML configuration for TiKV servers showing how to set up multiple hosts with different label configurations. This demonstrates how to configure zone and host labels for two TiKV instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ntikv_servers:\n  - host: 10.0.1.14\n    config:\n      server.labels: { zone: \"zone1\", host: \"host1\" }\n  - host: 10.0.1.15\n    config:\n      server.labels: { zone: \"zone1\", host: \"host2\" }\n```\n\n----------------------------------------\n\nTITLE: TiDB Version Reference - Markdown\nDESCRIPTION: Markdown header and metadata for TiDB 2.0.6 release notes documentation, including page aliases and summary information.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.0.6.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: TiDB 2.0.6 Release Notes\naliases: ['/docs/dev/releases/release-2.0.6/','/docs/dev/releases/206/']\nsummary: TiDB 2.0.6 was released on August 6, 2018, with improvements in system compatibility and stability. The release includes various improvements and bug fixes for TiDB and TiKV. Some notable improvements include reducing transaction conflicts, improving row count estimation accuracy, and adding a recover mechanism for panics during the execution of `ANALYZE TABLE`. Bug fixes address issues such as incompatible `DROP USER` statement behavior, OOM errors for `INSERT`/`LOAD DATA` statements, and incorrect results for prefix index and `DECIMAL` operations. TiKV also sees improvements in scheduler slots, rollback transaction records, and RocksDB log file management, along with a fix for a crash issue during data type conversion.\n---\n```\n\n----------------------------------------\n\nTITLE: Removing TiDB DM Configuration Files\nDESCRIPTION: This shell command snippet shows how to remove the configuration files related to TiDB DM when they are no longer needed, aiding in a clean workspace.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nrm mysql-01.yaml tiup-playground-task.yaml\n```\n\n----------------------------------------\n\nTITLE: Issuing Client Certificate\nDESCRIPTION: Command to issue and generate the final certificate for the client (dmctl), signed by the CA.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nopenssl x509 -req -days 365 -CA ca.pem -CAkey ca-key.pem -CAcreateserial -in client-cert.pem -out client-cert.pem\n```\n\n----------------------------------------\n\nTITLE: Configuring Data App Endpoints in JSON Format\nDESCRIPTION: Example configuration for two endpoints in a Data App's config.json file. This JSON structure defines HTTP endpoints with their methods, parameters, settings, and associated SQL files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-app-config-files.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"name\": \"<Endpoint name1>\",\n    \"description\": \"<Endpoint description1>\",\n    \"method\": \"<HTTP method1>\",\n    \"endpoint\": \"<Endpoint path1>\",\n    \"data_source\": {\n      \"cluster_id\": <Cluster ID1>\n    },\n    \"params\": [],\n    \"settings\": {\n      \"timeout\": <Endpoint timeout>,\n      \"row_limit\": <Maximum rows>,\n      \"enable_pagination\": <0 | 1>,\n      \"cache_enabled\": <0 | 1>,\n      \"cache_ttl\": <time-to-live period>\n    },\n    \"tag\": \"Default\",\n    \"batch_operation\": <0 | 1>,\n    \"sql_file\": \"<SQL file directory1>\",\n    \"type\": \"sql_endpoint\",\n    \"return_type\": \"json\"\n  },\n  {\n    \"name\": \"<Endpoint name2>\",\n    \"description\": \"<Endpoint description2>\",\n    \"method\": \"<HTTP method2>\",\n    \"endpoint\": \"<Endpoint path2>\",\n    \"data_source\": {\n      \"cluster_id\": <Cluster ID2>\n    },\n    \"params\": [\n      {\n        \"name\": \"<Parameter name>\",\n        \"type\": \"<Parameter type>\",\n        \"required\": <0 | 1>,\n        \"default\": \"<Parameter default value>\",\n        \"description\": \"<Parameter description>\",\n        \"is_path_parameter\": <true | false>\n      }\n    ],\n    \"settings\": {\n      \"timeout\": <Endpoint timeout>,\n      \"row_limit\": <Maximum rows>,\n      \"enable_pagination\": <0 | 1>,\n      \"cache_enabled\": <0 | 1>,\n      \"cache_ttl\": <time-to-live period>\n    },\n    \"tag\": \"Default\",\n    \"batch_operation\": <0 | 1>,\n    \"sql_file\": \"<SQL file directory2>\",\n    \"type\": \"sql_endpoint\",\n    \"return_type\": \"json\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Adding TiDB-JDBC with SM3 Authentication Maven Dependencies\nDESCRIPTION: Maven configuration for TiDB-JDBC with additional dependencies required for SM3 authentication support.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-choose-driver-or-orm.md#2025-04-18_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>io.github.lastincisor</groupId>\n  <artifactId>mysql-connector-java</artifactId>\n  <version>8.0.29-tidb-1.0.0</version>\n</dependency>\n<dependency>\n    <groupId>org.bouncycastle</groupId>\n    <artifactId>bcprov-jdk15on</artifactId>\n    <version>1.67</version>\n</dependency>\n<dependency>\n    <groupId>org.bouncycastle</groupId>\n    <artifactId>bcpkix-jdk15on</artifactId>\n    <version>1.67</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Get Node Status API Call\nDESCRIPTION: cURL command to get status information from a TiCDC node.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v1/status\n```\n\n----------------------------------------\n\nTITLE: Enabling Garbage Collection in TiDB using SQL\nDESCRIPTION: These SQL commands enable garbage collection in TiDB and verify the change. This is done after creating a changefeed to allow removal of replicated history data.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-mysql.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_enable=TRUE;\nSELECT @@global.tidb_gc_enable;\n```\n\n----------------------------------------\n\nTITLE: Recovering Inconsistent Index Data in SQL\nDESCRIPTION: This SQL snippet shows how to use the ADMIN RECOVER INDEX statement to recover inconsistent index data for a table named 'tbl' with an index named 'idx'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-recover.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN RECOVER INDEX tbl idx;\n+-------------+------------+\n| ADDED_COUNT | SCAN_COUNT |\n+-------------+------------+\n|           1 |          3 |\n+-------------+------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Describing SLOW_QUERY Table Structure in TiDB\nDESCRIPTION: This SQL query describes the structure of the SLOW_QUERY table in the INFORMATION_SCHEMA database of TiDB. It shows all columns, their data types, and other attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-slow-query.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC SLOW_QUERY;\n```\n\n----------------------------------------\n\nTITLE: Calculating Cosine Distance in TiDB SQL\nDESCRIPTION: VEC_COSINE_DISTANCE function calculates the cosine distance between two vectors. The vectors must have the same dimension.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-functions-and-operators.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VEC_COSINE_DISTANCE('[1, 1]', '[-1, -1]');\n```\n\n----------------------------------------\n\nTITLE: Using TiUP Cluster Help Command\nDESCRIPTION: Command syntax for accessing help information in tiup-cluster. Users can view general help or command-specific help by specifying an optional [command] parameter. Includes a boolean flag -h/--help that prints help information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-help.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster help [command] [flags]\n```\n\n----------------------------------------\n\nTITLE: Creating Project Directory and Installing Dependencies\nDESCRIPTION: Shell commands to create a new project directory and install required npm packages for Drizzle ORM and TiDB Cloud serverless driver.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-drizzle-example.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nmkdir drizzle-node-example\ncd drizzle-node-example\n\nnpm install drizzle-orm @tidbcloud/serverless\n```\n\n----------------------------------------\n\nTITLE: Deleting a Foreign Key Constraint\nDESCRIPTION: This SQL snippet illustrates the process for dropping a foreign key constraint from a table using the ALTER TABLE command.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name DROP FOREIGN KEY fk_identifier;\n```\n\n----------------------------------------\n\nTITLE: Skipping Unsupported DDL Statements in TiDB Data Migration\nDESCRIPTION: A list of SQL patterns for DDL statements that are not supported by DM and are skipped during migration. These include transactions, table maintenance, temporary tables, triggers, procedures, views, functions, tablespaces, events, and account management statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-ddl-compatible.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\n^SAVEPOINT\n^FLUSH\n^OPTIMIZE\\s+TABLE\n^ANALYZE\\s+TABLE\n^REPAIR\\s+TABLE\n^DROP\\s+(\\/\\*\\!40005\\s+)?TEMPORARY\\s+(\\*\\/\\s+)?TABLE\n^CREATE\\s+(DEFINER\\s?=.+?)?TRIGGER\n^DROP\\s+TRIGGER\n^DROP\\s+PROCEDURE\n^CREATE\\s+(DEFINER\\s?=.+?)?PROCEDURE\n^ALTER\\s+PROCEDURE\n^CREATE\\s*(OR REPLACE)?\\s+(ALGORITHM\\s?=.+?)?(DEFINER\\s?=.+?)?\\s+(SQL SECURITY DEFINER)?VIEW\n^DROP\\s+VIEW\n^ALTER\\s+(ALGORITHM\\s?=.+?)?(DEFINER\\s?=.+?)?(SQL SECURITY DEFINER)?VIEW\n^CREATE\\s+(AGGREGATE)?\\s*?FUNCTION\n^CREATE\\s+(DEFINER\\s?=.+?)?FUNCTION\n^ALTER\\s+FUNCTION\n^DROP\\s+FUNCTION\n^CREATE\\s+TABLESPACE\n^ALTER\\s+TABLESPACE\n^DROP\\s+TABLESPACE\n^CREATE\\s+(DEFINER\\s?=.+?)?EVENT\n^ALTER\\s+(DEFINER\\s?=.+?)?EVENT\n^DROP\\s+EVENT\n^GRANT\n^REVOKE\n^CREATE\\s+USER\n^ALTER\\s+USER\n^RENAME\\s+USER\n^DROP\\s+USER\n```\n\n----------------------------------------\n\nTITLE: ALTER DATABASE Execution Result in TiDB SQL\nDESCRIPTION: The expected output when executing the ALTER DATABASE statement to change the character set. It shows a successful execution with no rows affected.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-database.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Installing TPC-C Benchmark Tool via TiUP\nDESCRIPTION: Command to install the bench component using TiUP package manager for TPC-C testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-tpcc.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup install bench\n```\n\n----------------------------------------\n\nTITLE: TiCDC Changefeed Creation Success Response\nDESCRIPTION: Example output after successfully creating a TiCDC changefeed. It shows the created changefeed ID and detailed configuration information including upstream ID, sink URI, timestamps, and other replication settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-changefeed-config.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nCreate changefeed successfully!\nID: simple-replication-task\nInfo: {\"upstream_id\":7178706266519722477,\"namespace\":\"default\",\"id\":\"simple-replication-task\",\"sink_uri\":\"mysql://root:xxxxx@127.0.0.1:4000/?time-zone=\",\"create_time\":\"2024-12-05T15:05:46.679218+08:00\",\"start_ts\":438156275634929669,\"engine\":\"unified\",\"config\":{\"case_sensitive\":false,\"enable_old_value\":true,\"force_replicate\":false,\"ignore_ineligible_table\":false,\"check_gc_safe_point\":true,\"enable_sync_point\":true,\"bdr_mode\":false,\"sync_point_interval\":30000000000,\"sync_point_retention\":3600000000000,\"filter\":{\"rules\":[\"test.*\"],\"event_filters\":null},\"mounter\":{\"worker_num\":16},\"sink\":{\"protocol\":\"\",\"schema_registry\":\"\",\"csv\":{\"delimiter\":\",\",\"quote\":\"\\\"\",\"null\":\"\\\\N\",\"include_commit_ts\":false},\"column_selectors\":null,\"transaction_atomicity\":\"none\",\"encoder_concurrency\":16,\"terminator\":\"\\r\\n\",\"date_separator\":\"none\",\"enable_partition_separator\":false},\"consistent\":{\"level\":\"none\",\"max_log_size\":64,\"flush_interval\":2000,\"storage\":\"\"}},\"state\":\"normal\",\"creator_version\":\"v8.5.0\"}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Last Inserted AUTO_RANDOM ID in TiDB\nDESCRIPTION: Demonstrates how to retrieve the last inserted AUTO_RANDOM primary key value using the LAST_INSERT_ID() function.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-hot-spot-issues.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT LAST_INSERT_ID();\n```\n\n----------------------------------------\n\nTITLE: Setting byte-rate-rank-step-ratio for balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command sets the step rank ratio for byte rate calculations in the hot region scheduler. It affects how ranks are calculated for scheduling decisions.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_38\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-hot-region-scheduler set byte-rate-rank-step-ratio 0.05\n```\n\n----------------------------------------\n\nTITLE: Session Token Migration Configuration\nDESCRIPTION: Configuration for TiProxy session migration using certificates and keys. Must be set identically across all TiDB nodes to enable session migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-configuration-file.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsession-token-signing-cert: \"\"\nsession-token-signing-key: \"\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Scan Preference with tidb_opt_prefer_range_scan in SQL\nDESCRIPTION: This snippet illustrates how the tidb_opt_prefer_range_scan variable influences the optimizer's choice between full table scans and index range scans for tables without statistics or empty tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_62\n\nLANGUAGE: sql\nCODE:\n```\nexplain select * from t where age=5;\n+-------------------------+------------+-----------+---------------+-------------------+\n| id                      | estRows    | task      | access object | operator info     |\n+-------------------------+------------+-----------+---------------+-------------------+\n| TableReader_7           | 1048576.00 | root      |               | data:Selection_6  |\n| └─Selection_6           | 1048576.00 | cop[tikv] |               | eq(test.t.age, 5) |\n|   └─TableFullScan_5     | 1048576.00 | cop[tikv] | table:t       | keep order:false  |\n+-------------------------+------------+-----------+---------------+-------------------+\n3 rows in set (0.00 sec)\n\nset session tidb_opt_prefer_range_scan = 1;\n\nexplain select * from t where age=5;\n+-------------------------------+------------+-----------+-----------------------------+-------------------------------+\n| id                            | estRows    | task      | access object               | operator info                 |\n+-------------------------------+------------+-----------+-----------------------------+-------------------------------+\n| IndexLookUp_7                 | 1048576.00 | root      |                             |                               |\n| ├─IndexRangeScan_5(Build)     | 1048576.00 | cop[tikv] | table:t, index:idx_age(age) | range:[5,5], keep order:false |\n| └─TableRowIDScan_6(Probe)     | 1048576.00 | cop[tikv] | table:t                     | keep order:false              |\n+-------------------------------+------------+-----------+-----------------------------+-------------------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuration Parameters Table in Markdown\nDESCRIPTION: Markdown table listing configuration parameter changes across different TiDB components. Includes parameter names, change types (Modified, Deleted, Newly added), and descriptions of the changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.0.0.md#2025-04-18_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n| Configuration file | Configuration parameter | Change type | Description |\n| -------- | -------- | -------- | -------- |\n| TiKV | `server.snap-max-write-bytes-per-sec` | Deleted | This parameter is renamed to [`server.snap-io-max-bytes-per-sec`](/tikv-configuration-file.md#snap-io-max-bytes-per-sec). |\n| TiKV | [`raft-engine.enable-log-recycle`](/tikv-configuration-file.md#enable-log-recycle-new-in-v630) | Modified | The default value changes from `false` to `true`. |\n```\n\n----------------------------------------\n\nTITLE: System Variables for Deprecated Batch-DML\nDESCRIPTION: Legacy system variables that controlled the now-deprecated batch-DML feature in TiDB versions prior to v4.0. These variables are no longer recommended due to potential data corruption risks.\nSOURCE: https://github.com/pingcap/docs/blob/master/batch-processing.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ntidb_batch_insert\ntidb_batch_delete\ntidb_batch_commit\ntidb_enable_batch_dml\ntidb_dml_batch_size\n```\n\n----------------------------------------\n\nTITLE: Signing Client Certificate with CA for TiDB Authentication\nDESCRIPTION: Command to sign the client certificate request with the CA key and certificate. This creates a client certificate that the TiDB server can verify using the CA certificate.\nSOURCE: https://github.com/pingcap/docs/blob/master/certificate-authentication.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nsudo openssl x509 -req -in client-req.pem -days 365000 -CA ca-cert.pem -CAkey ca-key.pem -set_serial 01 -out client-cert.pem\n```\n\n----------------------------------------\n\nTITLE: Traffic Replay Command Example\nDESCRIPTION: Example of replaying captured traffic using specific credentials and speed multiplier\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-command-line-flags.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiproxyctl traffic replay --host 10.0.1.10 --port 3080 --username=\"u1\" --password=\"123456\" --input=\"/tmp/traffic\" --speed=2\n```\n\n----------------------------------------\n\nTITLE: Viewing Store Information in TiDB Cluster\nDESCRIPTION: This command uses pd-ctl to view the store information in a TiDB cluster, which is useful for manually removing a TiFlash node.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_23\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd -u http://<pd_ip>:<pd_port> store\n```\n\n----------------------------------------\n\nTITLE: MEMORY_USAGE_OPS_HISTORY Table Structure in TiDB\nDESCRIPTION: Output showing the column structure of the MEMORY_USAGE_OPS_HISTORY table, including field names, data types, and properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-memory-usage-ops-history.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+----------------+---------------------+------+------+---------+-------+\n| Field          | Type                | Null | Key  | Default | Extra |\n+----------------+---------------------+------+------+---------+-------+\n| TIME           | datetime            | NO   |      | NULL    |       |\n| OPS            | varchar(20)         | NO   |      | NULL    |       |\n| MEMORY_LIMIT   | bigint(21)          | NO   |      | NULL    |       |\n| MEMORY_CURRENT | bigint(21)          | NO   |      | NULL    |       |\n| PROCESSID      | bigint(21) unsigned | YES  |      | NULL    |       |\n| MEM            | bigint(21) unsigned | YES  |      | NULL    |       |\n| DISK           | bigint(21) unsigned | YES  |      | NULL    |       |\n| CLIENT         | varchar(64)         | YES  |      | NULL    |       |\n| DB             | varchar(64)         | YES  |      | NULL    |       |\n| USER           | varchar(16)         | YES  |      | NULL    |       |\n| SQL_DIGEST     | varchar(64)         | YES  |      | NULL    |       |\n| SQL_TEXT       | varchar(256)        | YES  |      | NULL    |       |\n+----------------+---------------------+------+------+---------+-------+\n12 rows in set (0.000 sec)\n```\n\n----------------------------------------\n\nTITLE: Updating Configuration Post-Import\nDESCRIPTION: Post-import, this snippet shows the necessary adjustments to the configuration to manage the imported cluster effectively with Terraform, emphasizing the removal of certain attributes which are auto-managed by Terraform.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_18\n\nLANGUAGE: hcl\nCODE:\n```\nresource \"tidbcloud_cluster\" \"import_cluster\" {\n    cloud_provider = \"AWS\"\n    cluster_type   = \"DEDICATED\"\n    config         = {\n        components = {\n            tidb    = {\n                node_quantity = 2\n                node_size     = \"8C16G\"\n            }\n            tiflash = {\n                node_quantity    = 2\n                node_size        = \"8C64G\"\n                storage_size_gib = 500\n            }\n            tikv    = {\n                node_quantity    = 6\n                node_size     = \"8C32G\"\n                storage_size_gib = 500\n            }\n        }\n        port       = 4000\n    }\n    name           = \"restoreCluster\"\n    project_id     = \"1372813089189561287\"\n    region         = \"eu-central-1\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating and Showing a New User in TiDB\nDESCRIPTION: Example of creating a new user 'newuser' with a password and then showing the creation statement for that user. This demonstrates the basic user creation and verification process in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> CREATE USER 'newuser' IDENTIFIED BY 'newuserpassword';\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> SHOW CREATE USER 'newuser';\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| CREATE USER for newuser@%                                                                                                                                            |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| CREATE USER 'newuser'@'%' IDENTIFIED WITH 'mysql_native_password' AS '*5806E04BBEE79E1899964C6A04D68BCA69B1A879' REQUIRE NONE PASSWORD EXPIRE DEFAULT ACCOUNT UNLOCK |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Executing ticloud config edit Command in Shell\nDESCRIPTION: Opens the profile configuration file with the default text editor on macOS or Linux. On Windows, it prints the path of the configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-edit.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud config edit [flags]\n```\n\n----------------------------------------\n\nTITLE: Enabling Partitioned Raft KV Configuration\nDESCRIPTION: Configuration settings to enable the Partitioned Raft KV feature when creating a TiKV cluster. Requires setting the storage engine and optional memory management parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-raft-kv.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nstorage:\n  engine: \"partitioned-raft-kv\"\n\nrocksdb:\n  write-buffer-flush-oldest-first: true\n  write-buffer-limit: <value>\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Sources for DM Task in YAML\nDESCRIPTION: This YAML snippet shows how to configure data sources to be migrated for a DM task. It specifies the task name and lists the source IDs of MySQL instances to migrate from.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-task-configuration-guide.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n\n## ********* Basic configuration *********\nname: test             # The name of the task. Should be globally unique.\n\n## ******** Data source configuration **********\nmysql-instances:\n  - source-id: \"mysql-replica-01\"  # Migrate data from the data source whose `source-id` is `mysql-replica-01`.\n  - source-id: \"mysql-replica-02\"  # Migrate data from the data source whose `source-id` is `mysql-replica-02`.\n```\n\n----------------------------------------\n\nTITLE: Confirming TiUP Installation\nDESCRIPTION: This command checks if TiUP is correctly installed by displaying its location.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup-offline.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nwhich tiup\n```\n\n----------------------------------------\n\nTITLE: Configuring Block-Allow List in YAML\nDESCRIPTION: YAML configuration example showing how to set up block and allow lists for database migration filtering. Demonstrates configuring allowed databases using wildcards.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-shards-to-tidb.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nblock-allow-list:           # filter or only migrate all operations of some databases or some tables.\n  log-bak-ignored:          # Rule name.\n    do-dbs: [\"store_*\"]     # The allow list of the schemas to be migrated, similar to replicate-do-db in MySQL.\n```\n\n----------------------------------------\n\nTITLE: Running DM Task Check Command\nDESCRIPTION: Shell command for checking DM task configuration validity before starting migration. Uses tiup dmctl to validate the task configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-shards-to-tidb.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} check-task task.yaml\n```\n\n----------------------------------------\n\nTITLE: Defining UnlockStatsStmt Syntax for TiDB Database - EBNF\nDESCRIPTION: Defines the syntax structure for the UNLOCK STATS command, describing how to specify table names and partition names using EBNF notation. The command allows unlocking statistics either for a list of tables or specific partitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-unlock-stats.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nUnlockStatsStmt ::=\n    'UNLOCK' 'STATS' (TableNameList | TableName 'PARTITION' PartitionNameList)\n\nTableNameList ::=\n    TableName (',' TableName)*\n\nTableName ::=\n    Identifier ( '.' Identifier )?\n\nPartitionNameList ::=\n    Identifier ( ',' Identifier )*\n```\n\n----------------------------------------\n\nTITLE: Schedule Configuration Parameters\nDESCRIPTION: Detailed scheduling parameters for Region management, including merge limits, patrol intervals, and various operational thresholds.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-configuration-file.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nschedule:\n  max-merge-region-size: 54\n  max-merge-region-keys: 540000\n  patrol-region-interval: \"10ms\"\n  patrol-region-worker-count: 1\n  split-merge-interval: \"1h\"\n  max-snapshot-count: 64\n  max-pending-peer-count: 64\n  max-store-down-time: \"30m\"\n  max-store-preparing-time: \"48h\"\n  leader-schedule-limit: 4\n  region-schedule-limit: 2048\n  enable-diagnostic: true\n```\n\n----------------------------------------\n\nTITLE: Creating Composite Index and Comparing EXPLAIN Results in TiDB\nDESCRIPTION: This snippet creates a composite index on bike_number and duration columns, then demonstrates how TiDB uses this index differently when querying through the view versus directly from the table with conditions matching parts of the index.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-views.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE trips ADD INDEX (bike_number, duration);\nEXPLAIN SELECT * FROM long_trips WHERE bike_number = 'W00950';\nEXPLAIN SELECT * FROM trips WHERE bike_number = 'W00950';\n```\n\n----------------------------------------\n\nTITLE: Implementing TiDB Transaction Toolkit in Golang\nDESCRIPTION: A utility package that provides transaction management for TiDB, supporting both optimistic and pessimistic transaction modes. It wraps sql.DB functionality with TiDB-specific transaction handling.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_0\n\nLANGUAGE: go\nCODE:\n```\npackage util\n\nimport (\n    \"context\"\n    \"database/sql\"\n)\n\ntype TiDBSqlTx struct {\n    *sql.Tx\n    conn        *sql.Conn\n    pessimistic bool\n}\n\nfunc TiDBSqlBegin(db *sql.DB, pessimistic bool) (*TiDBSqlTx, error) {\n    ctx := context.Background()\n    conn, err := db.Conn(ctx)\n    if err != nil {\n        return nil, err\n    }\n    if pessimistic {\n        _, err = conn.ExecContext(ctx, \"set @@tidb_txn_mode=?\", \"pessimistic\")\n    } else {\n        _, err = conn.ExecContext(ctx, \"set @@tidb_txn_mode=?\", \"optimistic\")\n    }\n    if err != nil {\n        return nil, err\n    }\n    tx, err := conn.BeginTx(ctx, nil)\n    if err != nil {\n        return nil, err\n    }\n    return &TiDBSqlTx{\n        conn:        conn,\n        Tx:          tx,\n        pessimistic: pessimistic,\n    }, nil\n}\n\nfunc (tx *TiDBSqlTx) Commit() error {\n    defer tx.conn.Close()\n    return tx.Tx.Commit()\n}\n\nfunc (tx *TiDBSqlTx) Rollback() error {\n    defer tx.conn.Close()\n    return tx.Tx.Rollback()\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Sign-out Redirect URI for SSO\nDESCRIPTION: URI format for configuring the sign-out redirect in SSO providers. Replace DASHBOARD_IP:PORT with actual TiDB Dashboard access details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-session-sso.md#2025-04-18_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nhttp://DASHBOARD_IP:PORT/dashboard/\n```\n\n----------------------------------------\n\nTITLE: Adding Admin Command to Show Next Row ID in TiDB\nDESCRIPTION: Implements the 'admin show next_row_id' command to return the next available row ID. This feature aids in database administration and troubleshooting.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1-rc.5.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW NEXT_ROW_ID;\n```\n\n----------------------------------------\n\nTITLE: Updating TiDB Cloud Serverless Cluster name\nDESCRIPTION: This command demonstrates updating the name of a TiDB Cloud Serverless cluster in non-interactive mode using the cluster ID and the new display name.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-update.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless update -c <cluster-id> --display-name <new-display-mame>\n```\n\n----------------------------------------\n\nTITLE: Describing INSPECTION_SUMMARY Table Structure\nDESCRIPTION: Shows the structure and field definitions of the inspection_summary table in the information_schema database\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-summary.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC inspection_summary;\n```\n\n----------------------------------------\n\nTITLE: Cancelling Current Traffic Jobs with tiproxyctl - Shell\nDESCRIPTION: This command cancels the current traffic capture or replay jobs using `tiproxyctl`, which requires user permission for execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-traffic-replay.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiproxyctl traffic cancel --host 10.0.1.10 --port 3080\n```\n\n----------------------------------------\n\nTITLE: Logging Behavior - TiDB Binlog Removal (Markdown)\nDESCRIPTION: Specifies the deletion of the `log_bin` and `sql_log_bin` variables in version 8.4.0, indicating that TiDB Binlog support is removed.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.4.0.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| `log_bin` | Deleted | In v8.4.0, [TiDB Binlog](https://docs.pingcap.com/tidb/v8.3/tidb-binlog-overview) is removed. This variable indicates whether TiDB Binlog is used, and is deleted starting from v8.4.0. |\n| `sql_log_bin` | Deleted | In v8.4.0, [TiDB Binlog](https://docs.pingcap.com/tidb/v8.3/tidb-binlog-overview) is removed. This variable indicates whether to write changes to TiDB Binlog or not, and is deleted starting from v8.4.0. |\n```\n\n----------------------------------------\n\nTITLE: Cloning TiDB AWS Lambda Quickstart Repository\nDESCRIPTION: Git commands to clone the sample code repository for the TiDB AWS Lambda quickstart project.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:tidb-samples/tidb-aws-lambda-quickstart.git\ncd tidb-aws-lambda-quickstart\n```\n\n----------------------------------------\n\nTITLE: Transaction Read Only Setting\nDESCRIPTION: SQL command affecting tx_read_only variable through set transaction statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-1.0.5.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET TRANSACTION READ ONLY;\n```\n\n----------------------------------------\n\nTITLE: Alternative Syntax for Adding a Default Partition in SQL\nDESCRIPTION: Alternative syntax for adding a default partition to a List partitioned table using the VALUES IN (DEFAULT) clause. This achieves the same result as using the DEFAULT keyword directly.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t ADD PARTITION (PARTITION pDef VALUES IN (DEFAULT));\n```\n\n----------------------------------------\n\nTITLE: Generate TPC-C CSV Data with TiUP Bench (Bash)\nDESCRIPTION: This command generates TPC-C data in CSV format for 4 warehouses, placing the output in the `data` directory. It uses the `prepare` subcommand with the `--output-dir` and `--output-type` flags to specify the output format and location.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench tpcc --warehouses 4 prepare --output-dir data --output-type=csv\n```\n\n----------------------------------------\n\nTITLE: Analyzing TiDB MPP Query Execution Plan with TableReader and HashAgg Operations\nDESCRIPTION: This execution plan shows a distributed query in TiDB using the MPP (Massively Parallel Processing) architecture with TiFlash. The query performs a full table scan on table 't', followed by hash aggregation operations and data exchanges between nodes, finally returning 20 rows through the TableReader component.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------------------+--------------+-----------+--------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+--------+------+\n| TableReader_44                       | 20.00        | 20        | root         |               | time:357.7ms, loops:2, cop_task: {num: 19, max: 0s, min: 0s, avg: 0s, p95: 0s, copr_cache_hit_ratio: 0.00}                                                                                                                                                                                                                                 | data:ExchangeSender_43                                                                                                        | N/A    | N/A  |\n| └─ExchangeSender_43                  | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:355.3ms, min:354.6ms, avg: 355ms, p80:355.3ms, p95:355.3ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                          | ExchangeType: PassThrough                                                                                                     | N/A    | N/A  |\n|   └─Projection_5                     | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:354.3ms, min:353.6ms, avg: 354ms, p80:354.3ms, p95:354.3ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                          | test.t.a, Column#22                                                                                                           | N/A    | N/A  |\n|     └─Projection_39                  | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:354.3ms, min:353.6ms, avg: 354ms, p80:354.3ms, p95:354.3ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                          | Column#22, test.t.a                                                                                                           | N/A    | N/A  |\n|       └─HashAgg_40                   | 20.00        | 20        | mpp[tiflash] |               | tiflash_task:{proc max:354.3ms, min:353.6ms, avg: 354ms, p80:354.3ms, p95:354.3ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                          | group by:test.t.a, funcs:sum(Column#29)->Column#22, funcs:firstrow(test.t.a)->test.t.a, stream_count: 20                      | N/A    | N/A  |\n|         └─ExchangeReceiver_42        | 20.00        | 60        | mpp[tiflash] |               | tiflash_task:{proc max:354.3ms, min:353.6ms, avg: 354ms, p80:354.3ms, p95:354.3ms, iters:16, tasks:3, threads:60}                                                                                                                                                                                                                          | stream_count: 20                                                                                                              | N/A    | N/A  |\n|           └─ExchangeSender_41        | 20.00        | 60        | mpp[tiflash] |               | tiflash_task:{proc max:349.6ms, min:0s, avg: 116.5ms, p80:349.6ms, p95:349.6ms, iters:3, tasks:3, threads:60}                                                                                                                                                                                                                              | ExchangeType: HashPartition, Hash Cols: [name: test.t.a, collate: binary], stream_count: 20                                   | N/A    | N/A  |\n|             └─HashAgg_37             | 20.00        | 60        | mpp[tiflash] |               | tiflash_task:{proc max:347.6ms, min:0s, avg: 115.9ms, p80:347.6ms, p95:347.6ms, iters:3, tasks:3, threads:60}                                                                                                                                                                                                                              | group by:test.t.a, funcs:count(1)->Column#29                                                                                  | N/A    | N/A  |\n|               └─TableFullScan_26     | 600000000.00 | 600000000 | mpp[tiflash] | table:t       | tiflash_task:{proc max:36.6ms, min:0s, avg: 12.2ms, p80:36.6ms, p95:36.6ms, iters:9389, tasks:3, threads:60}, tiflash_scan:{dtfile:{total_scanned_packs:73833, total_skipped_packs:418, total_scanned_rows:600001386, total_skipped_rows:3381854, total_rs_index_load_time: 10ms, total_read_time: 61ms}, total_create_snapshot_time: 0ms} | keep order:false                                                                                                              | N/A    | N/A  |\n+--------------------------------------+--------------+-----------+--------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+--------+------+\n```\n\n----------------------------------------\n\nTITLE: Creating User Profile in TiDB Cloud CLI - Markdown\nDESCRIPTION: This snippet describes the process of creating a user profile using the TiDB Cloud CLI with an API key or OAuth token. It details commands that provide the functionality to create and manage user profiles needed to interact with TiDB Cloud systems. The commands require proper configuration of API tokens or OAuth tokens to function correctly.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/cli-reference.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nUse [`ticloud config create`](/tidb-cloud/ticloud-config-create.md) to create a user profile.\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Kysely with TiDB Cloud\nDESCRIPTION: Install the required npm packages for using Kysely with TiDB Cloud serverless driver.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-kysely-example.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install kysely @tidbcloud/kysely @tidbcloud/serverless\n```\n\n----------------------------------------\n\nTITLE: Query Analysis After Thread Configuration\nDESCRIPTION: Shows the execution plan and performance metrics of the same GROUP BY query after increasing thread concurrency to 20 per instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain analyze select a, count(*) from t group by a;\n```\n\n----------------------------------------\n\nTITLE: Chat2Data Endpoint Response Example\nDESCRIPTION: This code snippet demonstrates a response from a Chat2Data endpoint in TiDB Cloud Data Service. It showcases the structure of the JSON response, including the `columns` array defining the schema and the `rows` array containing the query results. The `result` object provides metadata about the query execution, such as code, message, latency, and the executed SQL statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"chat2data_endpoint\",\n  \"data\": {\n    \"columns\": [\n      {\n        \"col\": \"id\",\n        \"data_type\": \"BIGINT\",\n        \"nullable\": false\n      },\n      {\n        \"col\": \"type\",\n        \"data_type\": \"VARCHAR\",\n        \"nullable\": false\n      }\n    ],\n    \"rows\": [\n      {\n        \"id\": \"20008295419\",\n        \"type\": \"CreateEvent\"\n      }\n    ],\n    \"result\": {\n      \"code\": 200,\n      \"message\": \"Query OK!\",\n      \"start_ms\": 1678965476709,\n      \"end_ms\": 1678965476839,\n      \"latency\": \"130ms\",\n      \"row_count\": 1,\n      \"row_affect\": 0,\n      \"limit\": 50\n      \"sql\": \"select id,type from sample_data.github_events limit 1;\",\n      \"ai_latency\": \"30ms\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Specifying a Master Key Stored in a File - INI\nDESCRIPTION: This snippet shows how to configure a master key stored in a file for use by TiKV. The configuration specifies the path to the key file and the expected format of the key.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_6\n\nLANGUAGE: ini\nCODE:\n```\n[security.encryption.master-key]\ntype = \"file\"\npath = \"/path/to/key/file\"\n```\n\n----------------------------------------\n\nTITLE: Dropping a Role in TiDB\nDESCRIPTION: SQL command to remove a previously created role from the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-role.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nDROP ROLE analyticsteam;\n```\n\n----------------------------------------\n\nTITLE: Deploying with SSH Authentication\nDESCRIPTION: Command for deploying TiUP cluster with SSH private key authentication\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-troubleshooting-guide.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster deploy -i identity_file\n```\n\n----------------------------------------\n\nTITLE: Getting TiDB Dashboard Address using TiUP\nDESCRIPTION: Command to retrieve the actual TiDB Dashboard address when using TiUP deployment tool\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster display CLUSTER_NAME --dashboard\n```\n\n----------------------------------------\n\nTITLE: Taking a TiCDC Node Offline using TiUP\nDESCRIPTION: This command removes the TiCDC node from the specified host (10.0.1.4:8300) using the TiUP cluster scale-in operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_25\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster scale-in <cluster-name> --node 10.0.1.4:8300\n```\n\n----------------------------------------\n\nTITLE: Running the Netlify Development Server in Shell\nDESCRIPTION: Command to start a local development server for previewing your Netlify site before deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nnetlify dev\n```\n\n----------------------------------------\n\nTITLE: Verifying Deletion Success with Terraform Show\nDESCRIPTION: This command demonstrates how to verify successful deletion of a cluster by running 'terraform show' which should return no resources after the destruction process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform show\n```\n\n----------------------------------------\n\nTITLE: Accurate Varchar Type Index Splitting in SQL\nDESCRIPTION: This SQL statement offers a more precise split of index 'idx1' into 26 Regions, utilizing the character '{' as the upper bound to account for values starting with 'z'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT TABLE t INDEX idx1 BETWEEN (\"a\") AND (\"{\") REGIONS 26;\n```\n\n----------------------------------------\n\nTITLE: Accessing TiProxy API Endpoint in Bash\nDESCRIPTION: Demonstrates how to make a GET request to the TiProxy API using curl. This example retrieves the TiProxy configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-api.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:3080/api/admin/config/\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Index Selection with tidb_opt_ordering_index_selectivity_threshold in SQL\nDESCRIPTION: This snippet shows how the tidb_opt_ordering_index_selectivity_threshold variable affects index selection for queries with ORDER BY and LIMIT clauses. It compares the execution plan before and after setting the variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_61\n\nLANGUAGE: sql\nCODE:\n```\n> EXPLAIN SELECT * FROM t WHERE b <= 9000 ORDER BY a LIMIT 1;\n+-----------------------------------+---------+-----------+----------------------+--------------------+\n| id                                | estRows | task      | access object        | operator info      |\n+-----------------------------------+---------+-----------+----------------------+--------------------+\n| Limit_12                          | 1.00    | root      |                      | offset:0, count:1  |\n| └─Projection_25                   | 1.00    | root      |                      | test.t.a, test.t.b |\n|   └─IndexLookUp_24                | 1.00    | root      |                      |                    |\n|     ├─IndexFullScan_21(Build)     | 114.30  | cop[tikv] | table:t, index:ia(a) | keep order:true    |\n|     └─Selection_23(Probe)         | 1.00    | cop[tikv] |                      | le(test.t.b, 9000) |\n|       └─TableRowIDScan_22         | 114.30  | cop[tikv] | table:t              | keep order:false   |\n+-----------------------------------+---------+-----------+----------------------+--------------------+\n\n> SET SESSION tidb_opt_ordering_index_selectivity_threshold = 0.01;\n\n> EXPLAIN SELECT * FROM t WHERE b <= 9000 ORDER BY a LIMIT 1;\n+----------------------------------+---------+-----------+----------------------+-------------------------------------+\n| id                               | estRows | task      | access object        | operator info                       |\n+----------------------------------+---------+-----------+----------------------+-------------------------------------+\n| TopN_9                           | 1.00    | root      |                      | test.t.a, offset:0, count:1         |\n| └─IndexLookUp_20                 | 1.00    | root      |                      |                                     |\n|   ├─IndexRangeScan_17(Build)     | 8748.62 | cop[tikv] | table:t, index:ib(b) | range:[-inf,9000], keep order:false |\n|   └─TopN_19(Probe)               | 1.00    | cop[tikv] |                      | test.t.a, offset:0, count:1         |\n|     └─TableRowIDScan_18          | 8748.62 | cop[tikv] | table:t              | keep order:false                    |\n+----------------------------------+---------+-----------+----------------------+-------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Checking TiUP Version\nDESCRIPTION: Command to verify the installed TiUP cluster version for NgMonitoring compatibility.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-faq.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster --version\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Lightning using TiUP\nDESCRIPTION: Command to install the latest version of TiDB Lightning, a tool for fast data import into TiDB, using the TiUP package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/get-started-with-tidb-lightning.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup install tidb-lightning\n```\n\n----------------------------------------\n\nTITLE: Removing TiFlash Replication Rules\nDESCRIPTION: This command removes a specific data replication rule related to TiFlash from the PD instance, identified by its `id`. This is useful when removing TiFlash nodes and replication rules are preventing successful node removal, especially after dropping tables or databases with TiFlash replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n```shell\ncurl -v -X DELETE http://<pd_ip>:<pd_port>/pd/api/v1/config/rule/tiflash/table-45-r\n```\n```\n\n----------------------------------------\n\nTITLE: TiDB JSON Type Conversion Example\nDESCRIPTION: Example showing invalid JSON type conversion in TiDB from ENUM type, which demonstrates TiDB's strict JSON format validation.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-json.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(e ENUM('a'));\nINSERT INTO t VALUES ('a');\nSELECT CAST(e AS JSON) FROM t;\n```\n\n----------------------------------------\n\nTITLE: Adding ISO 8601 and Timezone Support for Temporal String Literals in TiDB\nDESCRIPTION: Enhances support for ISO 8601 format and timezone handling in temporal string literals, improving date and time handling in SQL queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.8.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT '2020-10-30T12:00:00+08:00'::TIMESTAMP;\n```\n\n----------------------------------------\n\nTITLE: Checking TiFlash Replication Progress in TiDB Cloud Using SQL\nDESCRIPTION: This SQL snippet checks the progress and availability of TiFlash replicas for a table in TiDB Cloud. It requires specifying the relevant table's schema and name, and it outputs details such as the number of replicas and the progress percentage. The command should be executed in a MySQL client connected to your TiDB Cloud instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-htap-quickstart.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TABLE_SCHEMA, TABLE_NAME, TABLE_ID, REPLICA_COUNT, LOCATION_LABELS, AVAILABLE, PROGRESS FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = 'game' and TABLE_NAME = 'games';\n```\n\n----------------------------------------\n\nTITLE: Resetting Garbage Collection Lifetime - SQL\nDESCRIPTION: SQL command to reset the global garbage collection lifecycle time to its original default, typically after removing an old cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_life_time=10m;\n```\n\n----------------------------------------\n\nTITLE: Configuring Master Key in TiKV for Azure KMS - INI\nDESCRIPTION: This snippet shows how to specify the master key in the TiKV configuration file when using Azure KMS. It outlines necessary fields such as key-id and vendor, alongside optional authentication fields.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_5\n\nLANGUAGE: ini\nCODE:\n```\n[security.encryption.master-key]\ntype = 'kms'\nkey-id = 'your-kms-key-id'\nregion = 'region-name'\nendpoint = 'endpoint'\nvendor = 'azure'\n\n[security.encryption.master-key.azure]\ntenant-id = 'tenant_id'\nclient-id = 'client_id'\nkeyvault-url = 'keyvault_url'\nhsm-name = 'hsm_name'\nhsm-url = 'hsm_url'\nclient_certificate = \"\"\nclient_certificate_path = \"\"\nclient_certificate_password = \"\"\nclient_secret = \"\"\n```\n\n----------------------------------------\n\nTITLE: Dropping Existing Index in SQL\nDESCRIPTION: This SQL statement drops the existing 'title_idx' index to prepare for creating a new covering index.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimize-sql.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE books DROP INDEX title_idx;\n```\n\n----------------------------------------\n\nTITLE: Verifying Blocked Pushdown\nDESCRIPTION: SQL query to verify that operators added to blocklist are no longer pushed down to TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/blocklist-control-plan.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t WHERE a < 2 and a > 2;\n```\n\n----------------------------------------\n\nTITLE: Querying Kernel Versions for All Cluster Servers in SQL\nDESCRIPTION: This SQL query demonstrates how to use the CLUSTER_SYSTEMINFO table to retrieve the kernel version information for all servers in the TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-systeminfo.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM cluster_systeminfo WHERE name LIKE '%kernel.osrelease%'\n```\n\n----------------------------------------\n\nTITLE: Configuring Logical Import Mode in TiDB Lightning\nDESCRIPTION: Configuration file for setting up TiDB Lightning in logical import mode, including log settings, data source directory, backend mode, and target cluster connection details\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-logical-import-mode-usage.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\n# log\nlevel = \"info\"\nfile = \"tidb-lightning.log\"\nmax-size = 128 # MB\nmax-days = 28\nmax-backups = 14\n\n# Checks the cluster minimum requirements before start.\ncheck-requirements = true\n\n[mydumper]\n# The local data source directory or the URI of the external storage.\ndata-source-dir = \"/data/my_database\"\n\n[tikv-importer]\n# Import mode. \"tidb\" means using the logical import mode.\nbackend = \"tidb\"\n\n[tidb]\n# The information of the target cluster. The address of any tidb-server from the cluster.\nhost = \"172.16.31.1\"\nport = 4000\nuser = \"root\"\n# Configure the password to connect to TiDB. Either plaintext or Base64 encoded.\npassword = \"\"\n# tidb-lightning imports the TiDB library, and generates some logs.\n# Set the log level of the TiDB library.\nlog-level = \"error\"\n```\n\n----------------------------------------\n\nTITLE: SQL Query with Parameter\nDESCRIPTION: SQL statement demonstrating how to use parameters as variable placeholders in queries. Parameters are defined with the syntax ${PARAMETER_NAME} and can be configured in the Params tab.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-manage-endpoint.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM table_name WHERE id = ${ID}\n```\n\n----------------------------------------\n\nTITLE: Using ticloud serverless branch shell command syntax\nDESCRIPTION: The basic syntax for the command to connect to a branch of a TiDB Cloud Serverless cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-shell.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch shell [flags]\n```\n\n----------------------------------------\n\nTITLE: Executing Terraform State Show\nDESCRIPTION: This snippet displays the use of 'terraform state show' to view the status of specified resources. It lists vital configuration and status details for a 'tidbcloud_cluster'. The command requires the resource name and that Terraform is correctly set up and authorized.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_8\n\nLANGUAGE: Shell\nCODE:\n```\n$ terraform state show tidbcloud_cluster.example_cluster\n\n# tidbcloud_cluster.example_cluster:\nresource \"tidbcloud_cluster\" \"example_cluster\" {\n    cloud_provider = \"AWS\"\n    cluster_type   = \"DEDICATED\"\n    config         = {\n        components     = {\n            tidb    = {\n                node_quantity = 1\n                node_size     = \"8C16G\"\n            }\n            tiflash = {\n                node_quantity    = 1\n                node_size        = \"8C64G\"\n                storage_size_gib = 500\n            }\n            tikv    = {\n                node_quantity    = 3\n                node_size        = \"8C32G\"\n                storage_size_gib = 500\n            }\n        }\n        ip_access_list = [\n            # (1 unchanged element hidden)\n        ]\n        port           = 4000\n        root_password  = \"Your_root_password1.\"\n    }\n    id             = \"1379661944630234067\"\n    name           = \"firstCluster\"\n    project_id     = \"1372813089189561287\"\n    region         = \"eu-central-1\"\n    status         = \"MODIFYING\"\n}\n\n```\n\n----------------------------------------\n\nTITLE: Getting User Profile in TiCloud CLI - Shell\nDESCRIPTION: This snippet presents an alias command to 'ticloud config describe', allowing the user to fetch user profile information using a shorter command. It shares similar parameters and flags with the main command.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-describe.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud config get <profile-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Dynamically Update Memory Limits for Pessimistic Locks\nDESCRIPTION: SQL commands to dynamically modify memory limits for in-memory pessimistic locks.\nSOURCE: https://github.com/pingcap/docs/blob/master/pessimistic-transaction.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSET CONFIG tikv `pessimistic-txn.in-memory-peer-size-limit`=\"512KiB\";\nSET CONFIG tikv `pessimistic-txn.in-memory-instance-size-limit`=\"100MiB\";\n```\n\n----------------------------------------\n\nTITLE: Calling a Draft Endpoint with Digest Authentication in TiDB Cloud Data Service\nDESCRIPTION: This curl command demonstrates how to call a draft version of an endpoint using Digest Authentication in the Test Environment. It includes the required authentication headers and shows how to structure a POST request with batch operation data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-manage-endpoint.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user '<Public Key>:<Private Key>' \\\n --request POST 'https://<region>.data.tidbcloud.com/api/v1beta/app/<App ID>/endpoint/<Endpoint Path>' \\\n --header 'content-type: application/json'\\\n --header 'endpoint-type: draft'\n --data-raw '{\n  \"items\": [\n    {\n      \"age\": \"${age}\",\n      \"career\": \"${career}\"\n    }\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Querying TiKV Server Processes using `ps aux` command in Linux\nDESCRIPTION: This snippet demonstrates how to use the `ps aux` command in Linux to query the running `tikv-server` processes. The output provides information about the user running the process, the process ID, and the command-line arguments used to start the server, which are crucial for troubleshooting permission issues related to backup and restore operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\n\n    ps aux | grep tikv-server\n    \n```\n\nLANGUAGE: shell\nCODE:\n```\nps aux | grep tikv-server | awk '{print $1}'\n    \n```\n\n----------------------------------------\n\nTITLE: Correcting timezone parsing in TiDB\nDESCRIPTION: Fixes incorrect timezone after parsing date from strings using gotime.Local.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.7.md#2025-04-18_snippet_1\n\nLANGUAGE: Go\nCODE:\n```\n[#13793](https://github.com/pingcap/tidb/pull/13793)\n```\n\n----------------------------------------\n\nTITLE: Example Output of TiCDC Syncpoint Query - SQL\nDESCRIPTION: Presents a sample SQL result of querying the syncpoint table in TiDB, which helps to verify the replication progress by showing timestamps and TSO values for upstream and downstream synchronization.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n+------------------+------------+--------------------+--------------------+---------------------+\n| ticdc_cluster_id | changefeed | primary_ts         | secondary_ts       | created_at          |\n+------------------+------------+--------------------+--------------------+---------------------+\n| default          | syncpoint  | 453879870259200000 | 453879870545461257 | 2024-11-12 20:25:01 |\n| default          | syncpoint  | 453879948902400000 | 453879949214351361 | 2024-11-12 20:30:01 |\n| default          | syncpoint  | 453880027545600000 | 453880027751907329 | 2024-11-12 20:35:00 |\n+------------------+------------+--------------------+--------------------+---------------------+\n```\n\n----------------------------------------\n\nTITLE: Exporting AWS Credentials in Shell\nDESCRIPTION: Shell commands to set AWS access credentials as environment variables\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n[root@localhost ~]# export AWS_ACCESS_KEY_ID={your_aws_access_key_id}\n[root@localhost ~]# export AWS_SECRET_ACCESS_KEY= {your_aws_secret_access_key}\n```\n\n----------------------------------------\n\nTITLE: Kill TiDB Query\nDESCRIPTION: This SQL statement cancels a running backup or restore task in TiDB. It utilizes the connection ID obtained from the SHOW BACKUPS or SHOW RESTORES command to identify the specific task to terminate.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-backups.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nKILL TIDB QUERY 4;\n```\n\n----------------------------------------\n\nTITLE: Describing TIKV_STORE_STATUS Table Structure\nDESCRIPTION: SQL command to show the structure of the TIKV_STORE_STATUS table in INFORMATION_SCHEMA, displaying column names, data types, and properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tikv-store-status.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC TIKV_STORE_STATUS;\n```\n\n----------------------------------------\n\nTITLE: Modifying Table TTL Settings\nDESCRIPTION: Set of commands to modify TTL attributes on existing tables including changing interval and removing TTL.\nSOURCE: https://github.com/pingcap/docs/blob/master/time-to-live.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t1 TTL = `created_at` + INTERVAL 1 MONTH;\nALTER TABLE t1 TTL_ENABLE = 'OFF';\nALTER TABLE t1 REMOVE TTL;\n```\n\n----------------------------------------\n\nTITLE: Finding Top-N Slow Queries from User Workloads\nDESCRIPTION: SQL query to identify the top 2 slowest user queries by execution time, excluding internal TiDB queries by filtering with is_internal=false.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nselect query_time, query\nfrom information_schema.slow_query\nwhere is_internal = false\norder by query_time desc\nlimit 2;\n```\n\n----------------------------------------\n\nTITLE: Configuring DM Validation in YAML\nDESCRIPTION: YAML configuration block for enabling continuous data validation in DM task configuration file. Includes settings for validation mode, worker count, and error handling.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-continuous-data-validation.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmysql-instances:\n  - source-id: \"mysql1\"\n    block-allow-list: \"bw-rule-1\"\n    validator-config-name: \"global\"\nvalidators:\n  global:\n    mode: full\n    worker-count: 4\n    row-error-delay: 30m\n```\n\n----------------------------------------\n\nTITLE: Correlated Subquery Example in SQL\nDESCRIPTION: Example showing a correlated subquery before optimization, where t1.a is compared with an aggregate of t2.a values where t2.b matches t1.b.\nSOURCE: https://github.com/pingcap/docs/blob/master/correlated-subquery-optimization.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nselect * from t1 where t1.a < (select sum(t2.a) from t2 where t2.b = t1.b)\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW DATABASES Statement in SQL\nDESCRIPTION: Example usage of SHOW DATABASES in SQL to display available databases in TiDB. It demonstrates both the initial listing and the result after creating a new database.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-databases.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| INFORMATION_SCHEMA |\n| PERFORMANCE_SCHEMA |\n| mysql              |\n| test               |\n+--------------------+\n4 rows in set (0.00 sec)\n\nmysql> CREATE DATABASE mynewdb;\nQuery OK, 0 rows affected (0.10 sec)\n\nmysql> SHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| INFORMATION_SCHEMA |\n| PERFORMANCE_SCHEMA |\n| mynewdb            |\n| mysql              |\n| test               |\n+--------------------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining Resolved Event Key Format in JSON\nDESCRIPTION: Specifies the key format for Resolved Events in the TiCDC Open Protocol. It includes the resolved timestamp and event type identifier.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"ts\":<TS>,\n    \"t\":3\n}\n```\n\n----------------------------------------\n\nTITLE: Executing tiup cluster audit Command in Shell\nDESCRIPTION: This command allows users to view the command execution history for all clusters. It supports an optional audit-id to retrieve specific logs. The command outputs a table or a specific log based on the presence of the audit-id.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-audit.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster audit [audit-id] [flags]\n```\n\n----------------------------------------\n\nTITLE: TiDB Cloud Connection String Format for Console Method\nDESCRIPTION: The connection string format to use when getting connection parameters from the TiDB Cloud console.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nmysql://<User>:<Password>@<Host>:<Port>/<Database>?sslaccept=strict\n```\n\n----------------------------------------\n\nTITLE: Installing NUMA Tools Using TiUP\nDESCRIPTION: Commands to deploy a TiDB cluster and install NUMA tools on all nodes using TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_37\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster deploy tidb-test v6.1.0 ./topology.yaml --user root [-p] [-i /home/root/.ssh/gcp_rsa]\ntiup cluster exec tidb-test --sudo --command \"yum -y install numactl\"\n```\n\n----------------------------------------\n\nTITLE: DROP INDEX Example in TiDB SQL\nDESCRIPTION: A comprehensive example demonstrating the creation of a table, inserting data, executing queries with and without an index to show performance differences, and finally dropping the index. The example includes EXPLAIN output showing query plan changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-index.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\nQuery OK, 0 rows affected (0.10 sec)\n\nmysql> INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5);\nQuery OK, 5 rows affected (0.02 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n\nmysql> EXPLAIN SELECT * FROM t1 WHERE c1 = 3;\n+-------------------------+----------+-----------+---------------+--------------------------------+\n| id                      | estRows  | task      | access object | operator info                  |\n+-------------------------+----------+-----------+---------------+--------------------------------+\n| TableReader_7           | 10.00    | root      |               | data:Selection_6               |\n| └─Selection_6           | 10.00    | cop[tikv] |               | eq(test.t1.c1, 3)              |\n|   └─TableFullScan_5     | 10000.00 | cop[tikv] | table:t1      | keep order:false, stats:pseudo |\n+-------------------------+----------+-----------+---------------+--------------------------------+\n3 rows in set (0.00 sec)\n\nmysql> CREATE INDEX c1 ON t1 (c1);\nQuery OK, 0 rows affected (0.30 sec)\n\nmysql> EXPLAIN SELECT * FROM t1 WHERE c1 = 3;\n+------------------------+---------+-----------+------------------------+---------------------------------------------+\n| id                     | estRows | task      | access object          | operator info                               |\n+------------------------+---------+-----------+------------------------+---------------------------------------------+\n| IndexReader_6          | 0.01    | root      |                        | index:IndexRangeScan_5                      |\n| └─IndexRangeScan_5     | 0.01    | cop[tikv] | table:t1, index:c1(c1) | range:[3,3], keep order:false, stats:pseudo |\n+------------------------+---------+-----------+------------------------+---------------------------------------------+\n2 rows in set (0.00 sec)\n\nmysql> DROP INDEX c1 ON t1;\nQuery OK, 0 rows affected (0.30 sec)\n```\n\n----------------------------------------\n\nTITLE: Example SHOW GRANTS SQL Command\nDESCRIPTION: Demonstrates the usage of the SHOW GRANTS command to display privileges associated with a user in TiDB, with checks for existing grants.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-grants.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW GRANTS;\n+-------------------------------------------+\n| Grants for User                           |\n+-------------------------------------------+\n| GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' |\n+-------------------------------------------+\n1 row in set (0.00 sec)\n\nmysql> SHOW GRANTS FOR 'u1';\nERROR 1141 (42000): There is no such grant defined for user 'u1' on host '%'\nmysql> CREATE USER u1;\nQuery OK, 1 row affected (0.04 sec)\n\nmysql> GRANT SELECT ON test.* TO u1;\nQuery OK, 0 rows affected (0.04 sec)\n\nmysql> SHOW GRANTS FOR u1;\n+------------------------------------+\n| Grants for u1@%                    |\n+------------------------------------+\n| GRANT USAGE ON *.* TO 'u1'@'%'     |\n| GRANT Select ON test.* TO 'u1'@'%' |\n+------------------------------------+\n2 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: TiKV Command Line Tool Fix\nDESCRIPTION: Fix for the tikv-ctl recover-mvcc command that addresses invalid pessimistic locks removal issue\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.2.md#2025-04-18_snippet_4\n\nLANGUAGE: Shell\nCODE:\n```\ntikv-ctl recover-mvcc\n```\n\n----------------------------------------\n\nTITLE: Using tiup cluster clean Command in Shell\nDESCRIPTION: The basic syntax for the tiup cluster clean command. This command stops the specified cluster and cleans its data and/or logs based on the provided flags. The command requires a cluster name and at least one flag specifying what to clean.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-clean.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster clean <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: TiKV Memory Usage Alert Query\nDESCRIPTION: PromQL query to monitor rapid memory usage increase in TiKV nodes\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_12\n\nLANGUAGE: promql\nCODE:\n```\nprocess_resident_memory_bytes{job=~\"tikv\",instance=~\".*\"} - (process_resident_memory_bytes{job=~\"tikv\",instance=~\".*\"} offset 5m) > 5*1024*1024*1024\n```\n\n----------------------------------------\n\nTITLE: Encoding Key-Value Pairs for Index Data in TiDB\nDESCRIPTION: Shows how TiDB encodes index data as key-value pairs, using tableID, indexID, and indexed column values to construct keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-hot-spot-issues.md#2025-04-18_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nKey: tablePrefix{tableID}_indexPrefixSep{indexID}_indexedColumnsValue\nValue: rowID\n```\n\n----------------------------------------\n\nTITLE: Configuring Password Expiration Behavior in TOML\nDESCRIPTION: TOML configuration to control TiDB server behavior when encountering expired passwords. When set to true, the server disconnects clients with expired passwords.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_20\n\nLANGUAGE: TOML\nCODE:\n```\n[security]\ndisconnect-on-expired-password = true\n```\n\n----------------------------------------\n\nTITLE: TiDB Ansible Configuration Update Reference\nDESCRIPTION: Git commit reference for TiDB Lightning configuration update in TiDB Ansible\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.10.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n[#d3a4a368](https://github.com/pingcap/tidb-ansible/commit/d3a4a368810a421c49980899a286cf010569b4c7)\n```\n\n----------------------------------------\n\nTITLE: Loading Data Source Configuration into DM\nDESCRIPTION: This shell command loads the data source configuration specified in the source1.yaml file into the DM cluster. It requires the address of a DM-master node for the operation and illustrates how to use the `tiup dmctl` command.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} operate-source create source1.yaml\n```\n\n----------------------------------------\n\nTITLE: Downloading exported data from TiDB Cloud Serverless (non-interactive)\nDESCRIPTION: Downloads exported data from TiDB Cloud Serverless in non-interactive mode. Requires specifying the cluster ID and export ID using flags. An example is provided.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-download.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export download -c <cluster-id> -e <export-id>\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning Conflict Strategy\nDESCRIPTION: The `conflict.strategy` parameter in TiDB Lightning's configuration is used to control the conflict detection strategy for both logical and physical import modes. Starting from v8.0.0, this parameter simplifies conflict resolution configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n\"`conflict.strategy`\"\n```\n\n----------------------------------------\n\nTITLE: Run Docker Container for PDF Building\nDESCRIPTION: This command runs a Docker container using the specified image, mounting the local documentation directory to the container's `/opt/data` directory. This allows the scripts within the container to access and modify the documentation files for PDF generation. `${doc-path}` needs to be replaced with the absolute path of the documentation.\nSOURCE: https://github.com/pingcap/docs/blob/master/resources/tidb-pdf-generation-tutorial.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it -v ${doc-path}:/opt/data andelf/doc-build:0.1.9\n```\n\n----------------------------------------\n\nTITLE: Rewriting DDL Statements in TiDB Data Migration\nDESCRIPTION: A set of DDL statements that are rewritten by DM before being replicated to the downstream. These modifications add 'IF NOT EXISTS' or 'IF EXISTS' clauses to CREATE and DROP statements for databases, tables, and indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-ddl-compatible.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\n^CREATE DATABASE... -> ^CREATE DATABASE...IF NOT EXISTS\n^CREATE TABLE... -> ^CREATE TABLE..IF NOT EXISTS\n^DROP DATABASE... -> ^DROP DATABASE...IF EXISTS\n^DROP TABLE... -> ^DROP TABLE...IF EXISTS\n^DROP INDEX... -> ^DROP INDEX...IF EXISTS\n```\n\n----------------------------------------\n\nTITLE: Markdown Header Structure\nDESCRIPTION: Defines the document metadata including title, summary and aliases for the PD monitoring metrics documentation\nSOURCE: https://github.com/pingcap/docs/blob/master/grafana-pd-dashboard.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: Key Monitoring Metrics of PD\nsummary: Learn some key metrics displayed on the Grafana PD dashboard.\naliases: ['/docs/dev/grafana-pd-dashboard/','/docs/dev/reference/key-monitoring-metrics/pd-dashboard/']\n---\n```\n\n----------------------------------------\n\nTITLE: Installing OpenSSL on RedHat/CentOS\nDESCRIPTION: Command to install OpenSSL on RedHat or CentOS operating systems using the yum package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nyum install openssl\n```\n\n----------------------------------------\n\nTITLE: Monitoring Metrics Field Descriptions\nDESCRIPTION: Table field definitions for the Time Consumed by Each Component monitoring table, explaining metrics like METRIC_NAME, Label, TIME_RATIO, and various percentile measurements.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-diagnostics-report.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n* `METRIC_NAME`: The name of the monitoring metric.\n* `Label`: The label information for the monitoring metric.\n* `TIME_RATIO`: The ratio of the total time consumed by this monitoring metric to the total time.\n* `TOTAL_TIME`: The total time consumed by this monitoring metric.\n* `TOTAL_COUNT`: The total number of times this monitoring metric is executed.\n* `P999`: The maximum P999 time of this monitoring metric.\n* `P99`: The maximum P99 time of this monitoring metric.\n* `P90`: The maximum P90 time of this monitoring metric.\n* `P80`: The maximum P80 time of this monitoring metric.\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB and TiKV Parameters for Three-Node Hybrid Deployment\nDESCRIPTION: This YAML configuration adjusts various parameters for TiKV and TiDB in a three-node hybrid deployment scenario. It limits thread pool sizes, controls background task resource usage, and optimizes processing capacity to improve cluster stability when resources are shared among components.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/three-nodes-hybrid-deployment.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntikv:\n    readpool.unified.max-thread-count: 6\n    server.grpc-concurrency: 2\n    storage.scheduler-worker-pool-size: 2\n    gc.max-write-bytes-per-sec: 300K\n    rocksdb.max-background-jobs: 3\n    rocksdb.max-sub-compactions: 1\n    rocksdb.rate-bytes-per-sec: \"200M\"\n\n  tidb:\n    performance.max-procs: 8\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for TiDB Self-Managed\nDESCRIPTION: Example .env file configuration for connecting to a self-managed TiDB cluster. Contains basic connection parameters for a local or self-hosted TiDB instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-peewee.md#2025-04-18_snippet_4\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_HOST=127.0.0.1\nTIDB_PORT=4000\nTIDB_USERNAME=root\nTIDB_PASSWORD=\nTIDB_DATABASE=test\n```\n\n----------------------------------------\n\nTITLE: Downloading Component Package\nDESCRIPTION: Command to download a specific component package based on version, OS, and architecture variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-patch.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nwget https://tiup-mirrors.pingcap.com/${component}-${version}-${os}-${arch}.tar.gz -O /tmp/${component}-${version}-${os}-${arch}.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Scaling In DM Cluster\nDESCRIPTION: Command to remove a worker node from the DM cluster\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm scale-in prod-cluster -N 172.16.5.140:8262\n```\n\n----------------------------------------\n\nTITLE: Status Code 200 Response Example\nDESCRIPTION: This code snippet illustrates the structure of a Data Service response when the HTTP status code and the `data.result.code` are both 200, but an error occurred during SQL execution (table not found). It highlights that even with a 200 HTTP status, the `result.code` field can indicate an error, requiring developers to inspect this field for accurate error handling.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"sql_endpoint\",\n    \"data\": {\n        \"columns\": [],\n        \"rows\": [],\n        \"result\": {\n            \"code\": 1146,\n            \"message\": \"table not found\",\n            \"start_ms\": \"\",\n            \"end_ms\": \"\",\n            \"latency\": \"\",\n            \"row_count\": 0,\n            \"row_affect\": 0,\n            \"limit\": 0\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using TiUP DM Scale-Out Command\nDESCRIPTION: Basic syntax for the tiup dm scale-out command. Requires cluster name and topology file as arguments. The topology file should only contain configuration for new nodes being added to the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-scale-out.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm scale-out <cluster-name> <topology.yaml> [flags]\n```\n\n----------------------------------------\n\nTITLE: Describing CLIENT_ERRORS_SUMMARY_BY_USER Table Structure\nDESCRIPTION: Shows the structure of the CLIENT_ERRORS_SUMMARY_BY_USER table including field names, data types, and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/client-errors-summary-by-user.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC CLIENT_ERRORS_SUMMARY_BY_USER;\n```\n\n----------------------------------------\n\nTITLE: Using fetch Polyfill with TiDB Cloud Serverless Driver\nDESCRIPTION: JavaScript code showing how to import and use a fetch polyfill with the TiDB Cloud serverless driver for compatibility with older Node.js versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-node-example.md#2025-04-18_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nimport { connect } from '@tidbcloud/serverless'\nimport { fetch } from 'undici'\n\nconst conn = connect({url: 'mysql://[username]:[password]@[host]/[database]',fetch})\n```\n\n----------------------------------------\n\nTITLE: Disabling Relay Log in DM v2.0.2-v5.3.0\nDESCRIPTION: Command to disable relay log for a data source and specified workers in DM versions between v2.0.2 and v5.3.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/relay-log.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nstop-relay -s mysql-replica-01 worker1 worker2\n```\n\n----------------------------------------\n\nTITLE: Getting Found Rows (SQL)\nDESCRIPTION: The `FOUND_ROWS()` function gives the count of rows available in the last `SELECT` operation, even if a `LIMIT` clause was applied, essential for pagination.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/information-functions.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1 UNION ALL SELECT 2;\n```\n+------+\n| 1    |\n+------+\n|    2 |\n|    1 |\n+------+\n2 rows in set (0.01 sec)\n\nSELECT FOUND_ROWS();\n```\n+--------------+\n| FOUND_ROWS() |\n+--------------+\n|            2 |\n+--------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Time-based Sampling Interval\nDESCRIPTION: SQL command to set the time-based sampling interval to 20 seconds.\nSOURCE: https://github.com/pingcap/docs/blob/master/workload-repository.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_workload_repository_active_sampling_interval = 20;\n```\n\n----------------------------------------\n\nTITLE: Building and Migrating the Next.js App in Shell\nDESCRIPTION: Commands to install dependencies and build the Next.js application before deploying it to Netlify.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nnpm install .\nnpm run netlify-build\n```\n\n----------------------------------------\n\nTITLE: Showing User Account Definition in TiDB\nDESCRIPTION: Display the complete account definition for a user using the SHOW CREATE USER statement, including authentication method and password policies.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE USER 'admin'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Index Key Format in TiDB Storage\nDESCRIPTION: Example of how index data keys are encoded in TiDB storage using table_id, index_id, and index value, which is needed for index region splitting.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_9\n\nLANGUAGE: Go\nCODE:\n```\nt[table_id]_i[index_id][index_value]\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for DROP BINDING Statement in TiDB\nDESCRIPTION: This EBNF diagram defines the syntax for the DROP BINDING statement in TiDB. It shows how to remove bindings at global or session scope, either by specifying the bindable statement or by using a SQL digest.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-binding.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDropBindingStmt ::=\n    'DROP' GlobalScope 'BINDING' 'FOR' ( BindableStmt ( 'USING' BindableStmt )?\n|   'SQL' 'DIGEST' StringLiteralOrUserVariableList )\n\nGlobalScope ::=\n    ( 'GLOBAL' | 'SESSION' )?\n\nBindableStmt ::=\n    ( SelectStmt | UpdateStmt | InsertIntoStmt | ReplaceIntoStmt | DeleteStmt )\n\nStringLiteralOrUserVariableList ::=\n    ( StringLitOrUserVariable | StringLiteralOrUserVariableList ',' StringLitOrUserVariable )\n\nStringLiteralOrUserVariable ::=\n    ( stringLiteral | UserVariable )\n```\n\n----------------------------------------\n\nTITLE: Modification of System Variables in TiDB (Markdown)\nDESCRIPTION: Details on modifications made to certain system variables including value changes and default settings as of version 8.4.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.4.0.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n| [`tidb_analyze_partition_concurrency`](/system-variables.md#tidb_analyze_partition_concurrency) | Modified | Changes the value range from `[1, 18446744073709551615]` to `[1, 128]`. |\n| [`tidb_enable_inl_join_inner_multi_pattern`](/system-variables.md#tidb_enable_inl_join_inner_multi_pattern-new-in-v700) | Modified | Changes the default value from `OFF` to `ON`. Starting from v8.4.0, Index Join is supported by default when the inner table has `Selection`, `Aggregation`, or `Projection` operators on it. |\n| [`tidb_opt_prefer_range_scan`](/system-variables.md#tidb_opt_prefer_range_scan-new-in-v50) | Modified | Changes the default value from `OFF` to `ON`. For tables with no statistics (pseudo-statistics) or empty tables (zero statistics), the optimizer prefers interval scans over full table scans. |\n| [`tidb_scatter_region`](/system-variables.md#tidb_scatter_region) | Modified | Before v8.4.0, its type is boolean, it only supports `ON` and `OFF`, and the Region of the newly created table only supports table level scattering after it is enabled. Starting from v8.4.0, the `SESSION` scope is added, the type is changed from boolean to enumeration, the default value is changed from `OFF` to null, and the optional values `TABLE` and `GLOBAL` are added. In addition, it now supports cluster-level scattering policy to avoid the TiKV OOM issues caused by uneven distribution of regions during fast table creation in batches. |\n| [`tidb_schema_cache_size`](/system-variables.md#tidb_schema_cache_size-new-in-v800) | Modified | Changes the default value from `0` to `536870912` (512 MiB), indicating that this feature is enabled by default. The minimum value allowed is set to `67108864` (64 MiB). |\n```\n\n----------------------------------------\n\nTITLE: Generate PDF Documentation with Bash Script\nDESCRIPTION: This command executes a bash script named `generate_pdf.sh`, which generates the PDF documentation. It utilizes the previously generated `doc.md` file and other configuration files to produce the final PDF output named `output.pdf` in the same folder as the documentation.\nSOURCE: https://github.com/pingcap/docs/blob/master/resources/tidb-pdf-generation-tutorial.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nbash scripts/generate_pdf.sh\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for an Existing Project\nDESCRIPTION: Command to install Prisma and related packages for an existing Node.js project.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nnpm install prisma typescript ts-node @types/node --save-dev\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning's block-size Parameter for Physical Import\nDESCRIPTION: Controls the I/O block size for sorting local files in Physical Import Mode. Increasing this value can improve performance when disk IOPS is a bottleneck. The value must be at least 1B, with a default of \"16KiB\".\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ntikv-importer:\n  block-size: \"16KiB\"\n```\n\n----------------------------------------\n\nTITLE: Embedding Text Data and Storing Vectors in TiDB\nDESCRIPTION: Prepares sample documents, transforms them into vector embeddings, and inserts them into the TiDB vector store.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-python.md#2025-04-18_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndocuments = [\n    {\n        \"id\": \"f8e7dee2-63b6-42f1-8b60-2d46710c1971\",\n        \"text\": \"dog\",\n        \"embedding\": text_to_embedding(\"dog\"),\n        \"metadata\": {\"category\": \"animal\"},\n    },\n    {\n        \"id\": \"8dde1fbc-2522-4ca2-aedf-5dcb2966d1c6\",\n        \"text\": \"fish\",\n        \"embedding\": text_to_embedding(\"fish\"),\n        \"metadata\": {\"category\": \"animal\"},\n    },\n    {\n        \"id\": \"e4991349-d00b-485c-a481-f61695f2b5ae\",\n        \"text\": \"tree\",\n        \"embedding\": text_to_embedding(\"tree\"),\n        \"metadata\": {\"category\": \"plant\"},\n    },\n]\n\nvector_store.insert(\n    ids=[doc[\"id\"] for doc in documents],\n    texts=[doc[\"text\"] for doc in documents],\n    embeddings=[doc[\"embedding\"] for doc in documents],\n    metadatas=[doc[\"metadata\"] for doc in documents],\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring OAuth2 Authentication for Pulsar in TiCDC\nDESCRIPTION: This snippet shows the sink URI configuration used when configuring OAuth2 authentication for Pulsar in TiCDC.  It uses the standard `pulsar` protocol.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"pulsar://127.0.0.1:6650/persistent://public/default/yktest?protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Setting Up Environment (Shell)\nDESCRIPTION: Commands for cloning the repository, creating virtual environment and installing dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-jinaai-embedding.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/pingcap/tidb-vector-python.git\ncd tidb-vector-python/examples/jina-ai-embeddings-demo\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Cloud Serverless Driver\nDESCRIPTION: Command to install the TiDB Cloud serverless driver using npm within the project directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-cloudflare.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @tidbcloud/serverless\n```\n\n----------------------------------------\n\nTITLE: Getting Help for 'auth' Command in Shell\nDESCRIPTION: This example demonstrates how to get help information specifically for the 'auth' command in TiDB Cloud CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-help.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud help auth\n```\n\n----------------------------------------\n\nTITLE: Configuring dmctl Command-line Flags\nDESCRIPTION: These flags are used to configure dmctl, the command-line tool for interacting with DM-master nodes in the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-command-line-flags.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n### `--config`\n\n- The configuration file path of dmctl\n- The default value is `\"\"`\n- Optional flag\n\n### `--master-addr`\n\n- The `{advertise-addr}` of any DM-master node in the cluster to be connected by dmctl\n- The default value is `\"\"`\n- It is a required flag when dmctl interacts with DM-master\n```\n\n----------------------------------------\n\nTITLE: Viewing SQL Bindings in TiDB\nDESCRIPTION: SQL command to show execution plan bindings at either GLOBAL or SESSION level. Results are ordered by binding update time from latest to earliest.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nSHOW [GLOBAL | SESSION] BINDINGS [ShowLikeOrWhere]\n```\n\n----------------------------------------\n\nTITLE: Querying Changefeed Status in TiDB\nDESCRIPTION: This shell command queries the status of a changefeed task in TiDB clusters, providing task details, state, and checkpoint information which help in monitoring data replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc cli changefeed query -s --server=http://10.1.1.9:8300 --changefeed-id=\"dr-primary-to-secondary\"\n```\n\nLANGUAGE: shell\nCODE:\n```\n{\n\"state\": \"normal\",\n\"tso\": 431434047157998561,  # The TSO to which the changefeed has been replicated\n\"checkpoint\": \"2020-08-27 10:12:19.579\", # The physical time corresponding to the TSO\n\"error\": null\n}\n```\n\n----------------------------------------\n\nTITLE: Viewing table schema SQL file in Shell\nDESCRIPTION: Displays the table creation SQL file which defines the structure of a table including columns, engine type, and character set.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncat test.t1-schema.sql\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `t1` (\n  `id` int DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\n```\n\n----------------------------------------\n\nTITLE: Configuring Hot Region Scheduling in PD\nDESCRIPTION: Two new configuration items were added to control hot region scheduling: hot-region-schedule-limit sets the maximum number of concurrent hotspot scheduling tasks, and hot-region-cache-hits-threshold is used to identify a hot region.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.11.md#2025-04-18_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\nhot-region-schedule-limit: 4\nhot-region-cache-hits-threshold: 3\n```\n\n----------------------------------------\n\nTITLE: Using TiDB Server Log Redaction Command\nDESCRIPTION: Command syntax for using the --redact flag to desensitize or restore log files in TiDB server. The command processes an input log file and outputs the modified version based on the redact setting.\nSOURCE: https://github.com/pingcap/docs/blob/master/command-line-flags-for-tidb-configuration.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n./tidb-server --redact=xxx collect-log <input> <output>\n```\n\n----------------------------------------\n\nTITLE: Basic SHOW COLLATION Query\nDESCRIPTION: Simple example of using SHOW COLLATION to display all available collations in TiDB with the new collation framework enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-collation.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLLATION;\n```\n\n----------------------------------------\n\nTITLE: Selecting TiFlash max_threads Variable Result\nDESCRIPTION: This SQL statement is the response to the previous SELECT query.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------------+\n| @@tidb_max_tiflash_threads |\n+----------------------------+\n| 10                         |\n+----------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating UTF-8 Table with Varchar Column\nDESCRIPTION: SQL command to create a table with a UTF-8 varchar column in TiDB v2.1.1 and earlier versions\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/upgrade-faq.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(a varchar(100) charset utf8);\n```\n\n----------------------------------------\n\nTITLE: Resolving PAM Systemd Configuration Issue\nDESCRIPTION: Add pam_systemd.so module to system-auth configuration to resolve user instance startup problems\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-no-sudo-mode.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ngrep 'pam_systemd.so' /etc/pam.d/system-auth.ued || echo 'session     optional      pam_systemd.so' >> /etc/pam.d/system-auth.ued\n```\n\n----------------------------------------\n\nTITLE: Scale-Out Configuration for PD Servers\nDESCRIPTION: This INI configuration defines the settings for a new PD server, including the host, SSH port, name, client port, peer port, deployment directory, data directory, and log directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_4\n\nLANGUAGE: ini\nCODE:\n```\n\"pd_servers:\\n- host: 10.0.1.5\\n  ssh_port: 22\\n  name: pd-1\\n  client_port: 2379\\n  peer_port: 2380\\n  deploy_dir: /tidb-deploy/pd-2379\\n  data_dir: /tidb-data/pd-2379\\n  log_dir: /tidb-deploy/pd-2379/log\"\n```\n\n----------------------------------------\n\nTITLE: Installing MySQL Client\nDESCRIPTION: Installs MySQL client using yum package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\nyum -y install mysql\n```\n\n----------------------------------------\n\nTITLE: Using LIKE Clause with ADMIN SHOW DDL JOBS\nDESCRIPTION: Demonstrates how to use the LIKE clause for conditional filtering in ADMIN SHOW DDL JOBS command.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-beta.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW DDL JOBS LIKE '%index%';\n```\n\n----------------------------------------\n\nTITLE: SQL Configuration to Disable Transaction Assertion Level\nDESCRIPTION: SQL command to disable transaction assertion level checks. This configuration bypasses checks for error 8141 related to key existence assertions during transaction commits.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-data-inconsistency-errors.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_txn_assertion_level=OFF\n```\n\n----------------------------------------\n\nTITLE: Configuring NIC Interrupt Coalescing\nDESCRIPTION: Command to enable or modify interrupt coalescing settings on a network interface using ethtool.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nethtool -C ${NIC_DEV_NAME}\n```\n\n----------------------------------------\n\nTITLE: LIKE Operator with Literal Values in SQL\nDESCRIPTION: Shows a query using the LIKE operator with a literal integer and string. This example highlights a case where implicit type conversion can lead to unexpected results.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.2.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT 0 LIKE 'a string'\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Backtick in Name\nDESCRIPTION: Show how to create a table with a backtick character in its name by repeating the backtick twice\nSOURCE: https://github.com/pingcap/docs/blob/master/schema-object-names.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `a``b` (a int);\n```\n\n----------------------------------------\n\nTITLE: Querying Task Status in Shell\nDESCRIPTION: Checks the status of a specified migration task using the query-status command. It is used to verify the successful execution of replacement DDL statements and requires the task name (`test`) along with access permissions to check the task status via the shell.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n» query-status test\n```\n\n----------------------------------------\n\nTITLE: Multi-Table Join Query Example in SQL\nDESCRIPTION: Example SQL query demonstrating a three-table join operation where tables t1, t2, and t3 are joined using equality conditions on column 'a'.\nSOURCE: https://github.com/pingcap/docs/blob/master/join-reorder.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1, t2, t3 WHERE t1.a=t2.a AND t3.a=t2.a;\n```\n\n----------------------------------------\n\nTITLE: Exporting Data to Amazon S3 in Non-Interactive Mode\nDESCRIPTION: This command exports data to an Amazon S3 bucket. It requires the cluster ID, S3 bucket URI, access key ID, and secret access key to be specified as flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-create.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export create -c <cluster-id> --s3.bucket-uri <bucket-uri> --s3.access-key-id <access-key-id> --s3.secret-access-key <secret-access-key>\n```\n\n----------------------------------------\n\nTITLE: Creating a Table for Stale Read Examples in SQL\nDESCRIPTION: SQL command to create a simple table named 't' with a single integer column 'c' for demonstrating stale read functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (c int);\n```\n\n----------------------------------------\n\nTITLE: Accessing TiDB Cloud Console in Markdown\nDESCRIPTION: Instructions for logging into the TiDB Cloud console and navigating to the Project Settings page to view or modify third-party integrations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/third-party-monitoring-integrations.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n1. Log in to the [TiDB Cloud console](https://tidbcloud.com).\n2. Click <MDSvgIcon name=\"icon-left-projects\" /> in the lower-left corner, switch to the target project if you have multiple projects, and then click **Project Settings**.\n3. On the **Project Settings** page of your project, click **Integrations** in the left navigation pane.\n```\n\n----------------------------------------\n\nTITLE: Using br for Full Backup in TiDB\nDESCRIPTION: This command demonstrates how to perform a full backup of a TiDB cluster using the br tool. It specifies the PD (Placement Driver) service endpoint and an S3 storage location where the backup files will be stored.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/use-br-command-line-tool.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd \"${PD_IP}:2379\" \\\n--storage \"s3://backup-data/snapshot-202209081330/\"\n```\n\n----------------------------------------\n\nTITLE: Listing Serverless Clusters with JSON Output\nDESCRIPTION: Example of listing all TiDB Cloud Serverless clusters in a specified project with JSON formatted output in non-interactive mode. This provides a complete result set.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-list.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless list -p <project-id> -o json\n```\n\n----------------------------------------\n\nTITLE: Implementing Aggregate Query in Java for TiDB\nDESCRIPTION: This Java code implements the same aggregate query as the SQL example. It creates a JDBC connection, executes the query to group authors by birth year, and maps the results to a list of AuthorCount objects.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_10\n\nLANGUAGE: java\nCODE:\n```\npublic class AuthorCount {\n    private Short birthYear;\n    private Integer authorCount;\n\n    public AuthorCount() {}\n\n     // Skip the getters and setters.\n}\n\npublic List<AuthorCount> getAuthorCountsByBirthYear() throws SQLException {\n    List<AuthorCount> authorCounts = new ArrayList<>();\n    try (Connection conn = ds.getConnection()) {\n        Statement stmt = conn.createStatement();\n        ResultSet rs = stmt.executeQuery(\"\"\"\n            SELECT birth_year, COUNT(DISTINCT id) AS author_count\n            FROM authors\n            GROUP BY birth_year\n            ORDER BY author_count DESC;\n            \"\"\");\n\n        while (rs.next()) {\n            AuthorCount authorCount = new AuthorCount();\n            authorCount.setBirthYear(rs.getShort(\"birth_year\"));\n            authorCount.setAuthorCount(rs.getInt(\"author_count\"));\n            authorCounts.add(authorCount);\n        }\n    }\n    return authorCount;\n}\n```\n\n----------------------------------------\n\nTITLE: Non-Transactional DELETE statement in SQL\nDESCRIPTION: This SQL snippet demonstrates a non-transactional DELETE statement in TiDB.  It deletes rows from the 't' table where the value in column 'v' is less than 6, sharding by the 'id' column and using a batch size of 2.  This query sacrifices atomicity and isolation for performance in large data processing scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n\"BATCH ON id LIMIT 2 DELETE FROM t WHERE v < 6;\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"+----------------+---------------+\\n| number of jobs | job status    |\\n+----------------+---------------+\\n| 2              | all succeeded |\\n+-------------------------------+\\n1 row in set\"\n```\n\n----------------------------------------\n\nTITLE: Describing PLACEMENT_POLICIES Table Structure in TiDB\nDESCRIPTION: This SQL query shows the structure of the PLACEMENT_POLICIES table in the information_schema database, displaying all columns and their data types that store placement policy information.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-placement-policies.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC placement_policies;\n```\n\n----------------------------------------\n\nTITLE: Show Errors Usage Example\nDESCRIPTION: This SQL example demonstrates the usage of the `SHOW ERRORS` statement. It first executes invalid SQL statements that generate errors. Then, it uses `SHOW ERRORS` to display the recorded errors. Finally, a successful statement is executed, which clears the error buffer, and a subsequent `SHOW ERRORS` returns an empty set.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-errors.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"mysql> select invalid;\\nERROR 1054 (42S22): Unknown column 'invalid' in 'field list'\\nmysql> create invalid;\\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your TiDB version for the right syntax to use line 1 column 14 near \\\"invalid\\\"\\nmysql> SHOW ERRORS;\\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\\n| Level | Code | Message                                                                                                                                                   |\\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\\n| Error | 1054 | Unknown column 'invalid' in 'field list'                                                                                                                  |\\n| Error | 1064 | You have an error in your SQL syntax; check the manual that corresponds to your TiDB version for the right syntax to use line 1 column 14 near \\\"invalid\\\"  |\\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\\n2 rows in set (0.00 sec)\\n\\nmysql> CREATE invalid2;\\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your TiDB version for the right syntax to use line 1 column 15 near \\\"invalid2\\\"\\nmysql> SELECT 1;\\n+------+\\n| 1    |\\n+------+\\n|    1 |\\n+------+\\n1 row in set (0.00 sec)\\n\\nmysql> SHOW ERRORS;\\nEmpty set (0.00 sec)\"\n```\n\n----------------------------------------\n\nTITLE: Finding Index Name from indexID\nDESCRIPTION: SQL query to retrieve index information by querying the INFORMATION_SCHEMA.TIDB_INDEXES table, helping identify which index is involved in a write conflict.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-write-conflicts.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.TIDB_INDEXES WHERE TABLE_SCHEMA='{db_name}' AND TABLE_NAME='{table_name}' AND INDEX_ID={indexID};\n```\n\n----------------------------------------\n\nTITLE: Defining SET Variable Statement Syntax in EBNF\nDESCRIPTION: EBNF syntax definition for the SET variable statement in TiDB, showing the structure for setting global, session, and user variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-variable.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nSetVariableStmt ::=\n    \"SET\" Variable \"=\" Expression (\",\" Variable \"=\" Expression )*\n\nVariable ::=\n    (\"GLOBAL\" | \"SESSION\") SystemVariable\n|   UserVariable\n```\n\n----------------------------------------\n\nTITLE: Creating a Hash Partitioned Table to Handle NULL in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Hash partitioned table and shows how NULL values are handled in Hash partitioning.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_34\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE th (\n    c1 INT,\n    c2 VARCHAR(20)\n)\n\nPARTITION BY HASH(c1)\nPARTITIONS 2;\n```\n\n----------------------------------------\n\nTITLE: Describing TIDB_CHECK_CONSTRAINTS Table Structure\nDESCRIPTION: Shows the structure and field definitions of the TIDB_CHECK_CONSTRAINTS system table using the DESC command.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-check-constraints.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC TIDB_CHECK_CONSTRAINTS;\n```\n\n----------------------------------------\n\nTITLE: Clearing AUTO_RANDOM Cache\nDESCRIPTION: Example of using ALTER TABLE to clear the auto-increment ID cache by setting AUTO_RANDOM_BASE to 0.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-random.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t AUTO_RANDOM_BASE=0;\n```\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected, 1 warning (0.52 sec)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW WARNINGS;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+---------+------+-------------------------------------------------------------------------+\n| Level   | Code | Message                                                                 |\n+---------+------+-------------------------------------------------------------------------+\n| Warning | 1105 | Can't reset AUTO_INCREMENT to 0 without FORCE option, using 101 instead |\n+---------+------+-------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Prisma Database Connection\nDESCRIPTION: Prisma schema configuration for connecting to a TiDB database using the DATABASE_URL environment variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_4\n\nLANGUAGE: prisma\nCODE:\n```\ndatasource db {\n  provider = \"mysql\"\n  url      = env(\"DATABASE_URL\")\n}\n```\n\n----------------------------------------\n\nTITLE: Kafka Sink URI Configuration\nDESCRIPTION: This snippet shows how to configure the sink URI to use Kafka with TiCDC. It specifies the Kafka broker address, topic name, and Kafka version. This configuration is crucial for routing the change data capture stream to the correct Kafka topic.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-simple-protocol.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri = \"kafka://127.0.0.1:9092/topic-name?kafka-version=2.4.0\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS for TiDB\nDESCRIPTION: This code snippet shows how to configure TLS settings in the TiDB configuration file. It specifies the paths to the CA certificate, server certificate, and server key, enabling secure communication with other TiDB cluster components.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n\t\t```toml\n        [security]\n        # Path of the file that contains list of trusted SSL CAs for connection with cluster components.\n        cluster-ssl-ca = \"/path/to/ca.pem\"\n        # Path of the file that contains X509 certificate in PEM format for connection with cluster components.\n        cluster-ssl-cert = \"/path/to/tidb-server.pem\"\n        # Path of the file that contains X509 key in PEM format for connection with cluster components.\n        cluster-ssl-key = \"/path/to/tidb-server-key.pem\"\n        ```\n```\n\n----------------------------------------\n\nTITLE: Explain Output with Pre-Executed Subquery\nDESCRIPTION: Output from EXPLAIN showing that TiDB has pre-executed the subquery and replaced it with the constant value '1'.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------+----------+-----------+---------------+--------------------------------+\n| id                       | estRows  | task      | access object | operator info                  |\n+--------------------------+----------+-----------+---------------+--------------------------------+\n| TableReader_14           | 10.00    | root      |               | data:Selection_13              |\n| └─Selection_13           | 10.00    | cop[tikv] |               | eq(test.t2.a, 1)               |\n|   └─TableFullScan_12     | 10000.00 | cop[tikv] | table:t2      | keep order:false, stats:pseudo |\n+--------------------------+----------+-----------+---------------+--------------------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Handle Key Only Option for Large Messages in TiCDC Kafka Sink (TOML)\nDESCRIPTION: This configuration snippet demonstrates how to set up TiCDC Kafka sink to send only handle keys when messages exceed the size limit. This feature, introduced in v7.3.0, can significantly reduce message size and prevent changefeed errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_16\n\nLANGUAGE: TOML\nCODE:\n```\n[sink.kafka-config.large-message-handle]\nlarge-message-handle-option = \"claim-check\"\n```\n\n----------------------------------------\n\nTITLE: Describing CLUSTER_DEADLOCKS Table in SQL\nDESCRIPTION: This SQL command describes the structure of the INFORMATION_SCHEMA.CLUSTER_DEADLOCKS table, showing its columns and their properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-deadlocks.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC CLUSTER_DEADLOCKS;\n```\n\n----------------------------------------\n\nTITLE: Querying COLLATION_CHARACTER_SET_APPLICABILITY for UTF8MB4 in SQL\nDESCRIPTION: This SQL query retrieves all entries from the COLLATION_CHARACTER_SET_APPLICABILITY table where the character set name is 'utf8mb4', showing the collation names and their corresponding character set.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-collation-character-set-applicability.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM COLLATION_CHARACTER_SET_APPLICABILITY WHERE character_set_name='utf8mb4';\n```\n\n----------------------------------------\n\nTITLE: Configuring Large Message Compression in TiCDC Kafka Sink (TOML)\nDESCRIPTION: This snippet shows how to configure compression for large messages in TiCDC Kafka sink. It sets the compression algorithm to 'none', which is the default value. Other possible values are 'lz4' and 'snappy'.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_15\n\nLANGUAGE: TOML\nCODE:\n```\nlarge-message-handle-compression = \"none\"\n```\n\n----------------------------------------\n\nTITLE: Using Stale Read with MPP Mode in TiDB\nDESCRIPTION: SQL commands to enable MPP (Massively Parallel Processing) mode and perform a Stale Read query that retrieves data from one minute ago, which may cause errors if DDL operations occurred after the read timestamp.\nSOURCE: https://github.com/pingcap/docs/blob/master/stale-read.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nset @@session.tidb_enforce_mpp=1;\nselect * from t1 as of timestamp NOW() - INTERVAL 1 minute;\n```\n\n----------------------------------------\n\nTITLE: Reloading TiDB Cluster Configuration in Shell\nDESCRIPTION: This shell command reloads the TiDB cluster configuration to apply the changes made to the configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-disaggregated-and-s3.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster reload mycluster -R tidb\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into a Table in SQL\nDESCRIPTION: This SQL snippet demonstrates how to insert multiple rows of data into the 't' table created previously.  The inserted values are sample data used in later examples to illustrate non-transactional DML usage. The \"Query OK\" output indicates successful execution of the insert statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"INSERT INTO t VALUES (1, 2), (2, 3), (3, 4), (4, 5), (5, 6);\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"Query OK, 5 rows affected\"\n```\n\n----------------------------------------\n\nTITLE: TIKV_STORE_STATUS Table Schema Output\nDESCRIPTION: Detailed output showing the complete table structure with 19 columns including store metrics, status information, and timestamps. Each column is shown with its data type, nullability, and other properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tikv-store-status.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------+-------------+------+------+---------+-------+\n| Field             | Type        | Null | Key  | Default | Extra |\n+-------------------+-------------+------+------+---------+-------+\n| STORE_ID          | bigint(21)  | YES  |      | NULL    |       |\n| ADDRESS           | varchar(64) | YES  |      | NULL    |       |\n| STORE_STATE       | bigint(21)  | YES  |      | NULL    |       |\n| STORE_STATE_NAME  | varchar(64) | YES  |      | NULL    |       |\n| LABEL             | json        | YES  |      | NULL    |       |\n| VERSION           | varchar(64) | YES  |      | NULL    |       |\n| CAPACITY          | varchar(64) | YES  |      | NULL    |       |\n| AVAILABLE         | varchar(64) | YES  |      | NULL    |       |\n| LEADER_COUNT      | bigint(21)  | YES  |      | NULL    |       |\n| LEADER_WEIGHT     | double      | YES  |      | NULL    |       |\n| LEADER_SCORE      | double      | YES  |      | NULL    |       |\n| LEADER_SIZE       | bigint(21)  | YES  |      | NULL    |       |\n| REGION_COUNT      | bigint(21)  | YES  |      | NULL    |       |\n| REGION_WEIGHT     | double      | YES  |      | NULL    |       |\n| REGION_SCORE      | double      | YES  |      | NULL    |       |\n| REGION_SIZE       | bigint(21)  | YES  |      | NULL    |       |\n| START_TS          | datetime    | YES  |      | NULL    |       |\n| LAST_HEARTBEAT_TS | datetime    | YES  |      | NULL    |       |\n| UPTIME            | varchar(64) | YES  |      | NULL    |       |\n+-------------------+-------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Configuring TiProxy High Availability with YAML\nDESCRIPTION: This YAML configuration provides high availability setup for TiProxy by specifying a virtual IP and interface. It utilizes a virtual IP to ensure traffic can be routed to any available TiProxy instance. Requires at least two deployed TiProxy instances with availability on specified network interfaces.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-overview.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  tiproxy:\n    ha.virtual-ip: \"10.0.1.10/24\"\n    ha.interface: \"eth0\"\n```\n\n----------------------------------------\n\nTITLE: Recovering Dropped Table Example\nDESCRIPTION: Example showing how to recover a table that was dropped using the DROP TABLE command.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-table.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP TABLE t;\nFLASHBACK TABLE t;\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud Serverless Cluster using MySQL Client\nDESCRIPTION: This command demonstrates how to connect to a TiDB Cloud Serverless cluster using the MySQL client. It includes the user name prefix, host, port, database, and SSL configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/select-cluster-tier.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nmysql -u '3pTAoNNegb47Uc8.root' -h <host> -P 4000 -D test --ssl-mode=VERIFY_IDENTITY --ssl-ca=<CA_root_path> -p\n```\n\n----------------------------------------\n\nTITLE: Hash Partitioned Tables: Applicable Partition Pruning in SQL\nDESCRIPTION: This SQL snippet shows partition pruning applied in hash partitioned tables with an equality query condition. The table is partitioned by the hash of column `x` and queried with `x = 1`. Only the relevant partition is accessed, improving query efficiency.\nSOURCE: https://github.com/pingcap/docs/blob/master/partition-pruning.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (x int) partition by hash(x) partitions 4;\nexplain select * from t where x = 1;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------+----------+-----------+-----------------------+--------------------------------+\n| id                      | estRows  | task      | access object         | operator info                  |\n+-------------------------+----------+-----------+-----------------------+--------------------------------+\n| TableReader_8           | 10.00    | root      |                       | data:Selection_7               |\n| └─Selection_7           | 10.00    | cop[tikv] |                       | eq(test.t.x, 1)                |\n|   └─TableFullScan_6     | 10000.00 | cop[tikv] | table:t, partition:p1 | keep order:false, stats:pseudo |\n+-------------------------+----------+-----------+-----------------------+--------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Setting read-priorities for balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command sets the priority dimensions for scheduling hot regions of the read type. It controls which metrics (query, byte, key) the scheduler prioritizes.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_40\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-hot-region-scheduler set read-priorities query,byte\n```\n\n----------------------------------------\n\nTITLE: TiDB Dashboard Continuous Profiling URL Access\nDESCRIPTION: HTTP URL pattern for accessing the Continuous Profiling interface through a web browser. The URL needs to be modified with the actual PD instance address and port.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/continuous-profiling.md#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nhttp://127.0.0.1:2379/dashboard/#/continuous_profiling\n```\n\n----------------------------------------\n\nTITLE: Performing Point-in-Time Recovery (PITR) in TiDB\nDESCRIPTION: Command to restore a TiDB cluster to a specific point in time (May 15, 2022 at 18:00:00) using both snapshot and log backup data.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-use-cases.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore point --pd=\"${PD_IP}:2379\" \\\n--storage='s3://tidb-pitr-bucket/backup-data/log-backup' \\\n--full-backup-storage='s3://tidb-pitr-bucket/backup-data/snapshot-20220514000000' \\\n--restored-ts '2022-05-15 18:00:00+0800'\n```\n\n----------------------------------------\n\nTITLE: Loading Data Source Configuration with tiup dmctl\nDESCRIPTION: Command to load a data source configuration into the DM cluster using tiup dmctl\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} operate-source create source1.yaml\n```\n\n----------------------------------------\n\nTITLE: Resource Capacity Estimation Error - Duration\nDESCRIPTION: Error message displayed when the time window for capacity estimation is invalid. The duration must be between 10 minutes and 24 hours.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-resource-manager.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nERROR 1105 (HY000): the duration of calibration is too short, which could lead to inaccurate output. Please make the duration between 10m0s and 24h0m0s\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration\nDESCRIPTION: YAML configuration block defining the title and summary of the release notes document.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.2.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: TiDB 5.0.2 Release Notes\nsummary: TiDB 5.0.2 was released on June 10, 2021. The new version includes compatibility changes, new features, improvements, bug fixes, and updates to various tools such as TiKV, TiFlash, PD, TiCDC, Backup & Restore (BR), and TiDB Lightning. Some notable changes include the deprecation of `--sort-dir` in TiCDC, enabling the Hibernate Region feature in TiKV, and various bug fixes in TiDB, TiKV, PD, TiFlash, and tools like TiCDC, BR, and TiDB Lightning.\n---\n```\n\n----------------------------------------\n\nTITLE: TiDB Documentation Navigation Structure\nDESCRIPTION: Markdown navigation structure showing the organization of TiDB's SQL documentation including statements, data types, and functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/TOC.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- [`FLUSH TABLES`](/sql-statements/sql-statement-flush-tables.md)\n- [`GRANT <privileges>`](/sql-statements/sql-statement-grant-privileges.md)\n- [`GRANT <role>`](/sql-statements/sql-statement-grant-role.md)\n[...additional navigation items...]\n```\n\n----------------------------------------\n\nTITLE: Describing DATA_LOCK_WAITS Table Structure in SQL\nDESCRIPTION: This SQL snippet shows how to view the structure of the DATA_LOCK_WAITS table in the information_schema database.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-data-lock-waits.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE information_schema;\nDESC data_lock_waits;\n```\n\n----------------------------------------\n\nTITLE: Explaining TiUP Mirror Root Certificate JSON Structure\nDESCRIPTION: Shows the JSON format of a root certificate file in a TiUP mirror. The root certificate stores public keys used to verify other metadata files and includes signatures, roles, and versioning information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror-reference.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"signatures\": [                                             # Each metadata file has some signatures which are signed by several private keys corresponding to the file.\n        {\n            \"keyid\": \"{id-of-root-key-1}\",                      # The ID of the first private key that participates in the signature. This ID is obtained by hashing the content of the public key that corresponds to the private key.\n            \"sig\": \"{signature-by-root-key-1}\"                  # The signed part of this file by this private key.\n        },\n        ...\n        {\n            \"keyid\": \"{id-of-root-key-N}\",                      # The ID of the Nth private key that participates in the signature.\n            \"sig\": \"{signature-by-root-key-N}\"                  # The signed part of this file by this private key.\n        }\n    ],\n    \"signed\": {                                                 # The signed part.\n        \"_type\": \"root\",                                        # The type of this file. root.json's type is root.\n        \"expires\": \"{expiration-date-of-this-file}\",            # The expiration time of the file. If the file expires, the client rejects the file.\n        \"roles\": {                                              # Records the keys used to sign each metadata file.\n            \"{role:index,root,snapshot,timestamp}\": {           # Each involved metadata file includes index, root, snapshot, and timestamp.\n                \"keys\": {                                       # Only the key's signature recorded in `keys` is valid.\n                    \"{id-of-the-key-1}\": {                      # The ID of the first key used to sign {role}.\n                        \"keytype\": \"rsa\",                       # The key's type. Currently, the key type is fixed as rsa.\n                        \"keyval\": {                             # The key's payload.\n                            \"public\": \"{public-key-content}\"    # The public key's content.\n                        },\n                        \"scheme\": \"rsassa-pss-sha256\"           # Currently, the scheme is fixed as rsassa-pss-sha256.\n                    },\n                    \"{id-of-the-key-N}\": {                      # The ID of the Nth key used to sign {role}.\n                        \"keytype\": \"rsa\",\n                        \"keyval\": {\n                            \"public\": \"{public-key-content}\"\n                        },\n                        \"scheme\": \"rsassa-pss-sha256\"\n                    }\n                },\n                \"threshold\": {N},                               # Indicates that the metadata file needs at least N key signatures.\n                \"url\": \"/{role}.json\"                           # The address from which the file can be obtained. For index files, prefix it with the version number (for example, /{N}.index.json).\n            }\n        },\n        \"spec_version\": \"0.1.0\",                                # The specified version followed by this file. If the file structure is changed in the future, the version number needs to be upgraded. The current version number is 0.1.0.\n        \"version\": {N}                                          # The version number of this file. You need to create a new {N+1}.root.json every time you update the file, and set its version to N + 1.\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Prohibiting `require_secure_transport` in SEM\nDESCRIPTION: The system variable [`require_secure_transport`](/system-variables.md#require_secure_transport-new-in-v610) cannot be set to `ON` in Security Enhanced Mode (SEM) to prevent potential connectivity issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n\"`require_secure_transport`\"\n```\n\n----------------------------------------\n\nTITLE: Defining Warning Alert Rule for CDC No Owner in YAML\nDESCRIPTION: YAML configuration for a warning alert rule that triggers when there is no owner in the TiCDC cluster for more than 10 minutes.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-alert-rules.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nsum(rate(ticdc_owner_ownership_counter[240s])) < 0.5\n```\n\n----------------------------------------\n\nTITLE: TiUP DM Cluster Upgrade Command Syntax\nDESCRIPTION: Shell command syntax for upgrading a DM cluster to a specific version. Requires cluster name and target version parameters. Only supports upgrading to later versions, with no downgrade support. Nightly version upgrades are not allowed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-upgrade.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm upgrade <cluster-name> <version> [flags]\n```\n\n----------------------------------------\n\nTITLE: Filter Out All Sharding Deletion Operations - YAML\nDESCRIPTION: This snippet illustrates how to configure filters to ignore all deletion operations on specified schemas and tables. It includes the configuration for both table-level and schema-level filters.\nSOURCE: https://github.com/pingcap/docs/blob/master/filter-binlog-event.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nfilters:\n  filter-table-rule:\n    schema-pattern: \"test_*\"\n    table-pattern: \"t_*\"\n    events: [\"truncate table\", \"drop table\", \"delete\"]\n    action: Ignore\n  filter-schema-rule:\n    schema-pattern: \"test_*\"\n    events: [\"drop database\"]\n    action: Ignore\n```\n\n----------------------------------------\n\nTITLE: Querying a Specific Replication Task - TiCDC - Shell\nDESCRIPTION: This example demonstrates how to query the detailed information of a specific replication task by its ID using a GET request. The `changefeed_id` is used as a path parameter to identify the target replication task.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v1/changefeeds/test1\n```\n\n----------------------------------------\n\nTITLE: BDR Role Command Syntax Definition in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for BDR role administrative commands including SHOW, SET, and UNSET operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-bdr-role.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAdminShowBDRRoleStmt ::=\n    'ADMIN' 'SHOW' 'BDR' 'ROLE'\n\nAdminSetBDRRoleStmt ::=\n    'ADMIN' 'SET' 'BDR' 'ROLE' ('PRIMARY' | 'SECONDARY')\n\nAdminUnsetBDRRoleStmt ::=\n    'ADMIN' 'UNSET' 'BDR' 'ROLE'\n```\n\n----------------------------------------\n\nTITLE: Installing Prerequisites on macOS\nDESCRIPTION: Commands to install Python and mysql-client on macOS using Homebrew.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nbrew install python mysql-client\n```\n\n----------------------------------------\n\nTITLE: TiDB Lightning Configuration for Schema Migration\nDESCRIPTION: Configuration file for TiDB Lightning that specifies connection details and mapping rules for importing data into a new schema. Includes pattern matching for both SQL files and schema files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-faq.md#2025-04-18_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\n[tidb]\nhost = \"127.0.0.1\"\nport = 4000\nuser = \"root\"\n\n[tikv-importer]\nbackend = \"tidb\"\n\n[mydumper]\ndata-source-dir = \"/tmp/bck1\"\n\n[[mydumper.files]]\npattern = '^[a-z]*\\.(.*)\\.\\[0-9]*\\.sql$'\nschema = 'test2'\ntable = '$1'\ntype = 'sql'\n\n[[mydumper.files]]\npattern = '^[a-z]*\\.(.*)-schema\\.sql$'\nschema = 'test2'\ntable = '$1'\ntype = 'table-schema'\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning Import Concurrency Settings (TOML)\nDESCRIPTION: This snippet configures concurrency settings for TiDB Lightning's import functionality, controlling the maximum number of concurrent engine files for index and table processing. It includes settings for index-concurrency, table-concurrency, and io-concurrency to optimize resource utilization during data import.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-physical-import-mode-usage.md#2025-04-18_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\n# The maximum concurrency of engine files.\n# Each table is split into one \"index engine\" to store indices, and multiple\n# \"data engines\" to store row data. These settings control the maximum\n# concurrent number for each type of engines.\n# The two settings controls the maximum concurrency of the two engine files.\nindex-concurrency = 2\ntable-concurrency = 6\n\n# The concurrency of data. The default value is the number of logical CPUs.\nregion-concurrency = \n\n# The maximum concurrency of I/O. When the concurrency is too high, the disk\n# cache may be frequently refreshed, causing the cache miss and read speed\n# to slow down. For different storage mediums, this parameter may need to be\n# adjusted to achieve the best performance.\nio-concurrency = 5\n```\n\n----------------------------------------\n\nTITLE: Reloading Optimization Rules Blocklist\nDESCRIPTION: Command to make optimization rule blocklist changes take effect immediately across all connections.\nSOURCE: https://github.com/pingcap/docs/blob/master/blocklist-control-plan.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nadmin reload opt_rule_blacklist;\n```\n\n----------------------------------------\n\nTITLE: Getting TiSpark Version Information\nDESCRIPTION: This snippet retrieves the version information of TiSpark by executing a SQL command within the Spark shell.\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: scala\nCODE:\n```\n```\nspark.sql(\"select ti_version(){}\").collect\n```\n```\n\n----------------------------------------\n\nTITLE: Verifying Data Migration Task Status\nDESCRIPTION: This snippet shows the command to verify the success of the data migration task after starting it again. This is important to confirm that no data has been lost during the DROP TABLE operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/shard-merge-best-practices.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nquery-status;\n```\n\n----------------------------------------\n\nTITLE: Email Subscription Component\nDESCRIPTION: This snippet includes the EmailSubscriptionWrapper component. This component allows users to subscribe to email updates related to TiDB releases.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-notes.md#2025-04-18_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\n\"<EmailSubscriptionWrapper />\"\n```\n\n----------------------------------------\n\nTITLE: Upgrading DM Cluster\nDESCRIPTION: Command to perform a rolling upgrade of the DM cluster to a specific version\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm upgrade prod-cluster ${version}\n```\n\n----------------------------------------\n\nTITLE: TiKV Async Write Duration Alert Rule\nDESCRIPTION: Prometheus alert rule that monitors the 99th percentile of TiKV async write request duration. Triggers when write operations take longer than 1 second.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_14\n\nLANGUAGE: promql\nCODE:\n```\nhistogram_quantile(0.99, sum(rate(tikv_storage_engine_async_request_duration_seconds_bucket{type=\"write\"}[1m])) by (le, instance, type)) > 1\n```\n\n----------------------------------------\n\nTITLE: TiCDC Topology Configuration Template\nDESCRIPTION: Configuration template for deploying TiCDC with minimal cluster topology, including instance types, hardware specifications, and IP addresses\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc-deployment-topology.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# Simple TiCDC topology configuration template\n# Instances: TiDB, PD, TiKV, CDC, Monitoring\n# Total of 12 nodes with specific hardware and network configurations\n```\n\n----------------------------------------\n\nTITLE: TiKV Coprocessor Request Wait Alert Rule\nDESCRIPTION: Alert rule monitoring the 99.99th percentile of Coprocessor request wait time. Triggers when requests wait longer than 10 seconds.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_15\n\nLANGUAGE: promql\nCODE:\n```\nhistogram_quantile(0.9999, sum(rate(tikv_coprocessor_request_wait_seconds_bucket[1m])) by (le, instance, req)) > 10\n```\n\n----------------------------------------\n\nTITLE: Showing Updated Regions of a Table in SQL\nDESCRIPTION: This SQL snippet is used to display the updated regions of the partitioned table 't' after splitting, showing the new distribution of regions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLE t REGIONS;\n```\n\n----------------------------------------\n\nTITLE: Enabling Placement Rules with pd-ctl\nDESCRIPTION: Command to dynamically enable Placement Rules in a running TiDB cluster using pd-ctl. This generates default rules based on existing configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-placement-rules.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules enable\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into a Global Temporary Table in TiDB - SQL\nDESCRIPTION: This snippet illustrates how to insert a record into the 'users' global temporary table during an active transaction. It shows the visibility of inserted data within the same transaction until it is committed.\nSOURCE: https://github.com/pingcap/docs/blob/master/temporary-tables.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO users(id, name, city) VALUES(1001, 'Davis', 'LosAngeles');\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Error Summary Usage\nDESCRIPTION: Example showing how to generate a warning with division by zero, view the error summary, flush it, and verify the reset. Demonstrates the practical usage of the CLIENT_ERRORS_SUMMARY_GLOBAL table.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/client-errors-summary-global.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 0/0;\nSELECT * FROM CLIENT_ERRORS_SUMMARY_GLOBAL;\nFLUSH CLIENT_ERRORS_SUMMARY;\nSELECT * FROM CLIENT_ERRORS_SUMMARY_GLOBAL;\n```\n\n----------------------------------------\n\nTITLE: Updating TiUP Components\nDESCRIPTION: Command to update all TiUP components to their latest versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-faq.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup update --all\n```\n\n----------------------------------------\n\nTITLE: Invalid JSON Default Value Example\nDESCRIPTION: Example showing an invalid way to set a JSON default value using a literal instead of an expression, which is not allowed in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-default-values.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t5 (\n  id bigint AUTO_RANDOM PRIMARY KEY,\n  j json DEFAULT ('{\"a\": 1, \"b\": 2}')\n);\n```\n\n----------------------------------------\n\nTITLE: Applying Terraform Configuration for TiDB Cloud Cluster\nDESCRIPTION: This shell command applies the Terraform configuration to create the TiDB Cloud cluster. It shows the execution plan and prompts for confirmation before making changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_3\n\nLANGUAGE: Shell\nCODE:\n```\n$ terraform apply\n```\n\n----------------------------------------\n\nTITLE: Getting TiDB Cloud Connection String via CLI in Shell\nDESCRIPTION: Using TiDB Cloud CLI to interactively retrieve the connection string for a TiDB Cloud cluster to use with Prisma.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud cluster connect-info\n```\n\n----------------------------------------\n\nTITLE: Enabling Execution Info Collection in TiDB SQL\nDESCRIPTION: Configuration and session variable to control the collection of execution information for each operator, which is then recorded in the slow query log.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.2.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL enable-collect-execution-info = ON;\nSET SESSION tidb_enable_collect_execution_info = 1;\n```\n\n----------------------------------------\n\nTITLE: Pruning TiDB Cluster after Node Removal\nDESCRIPTION: This command cleans up the related data files of the removed node from the TiUP topology.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster prune <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Using DESCRIBE as EXPLAIN Alias in TiDB\nDESCRIPTION: DESCRIBE is a SQL command that functions as a direct alias to the EXPLAIN statement in TiDB. It is implemented to maintain compatibility with MySQL syntax and conventions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-describe.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDESCRIBE\n```\n\n----------------------------------------\n\nTITLE: Using Primary Key Index in TiDB 2.0.7\nDESCRIPTION: TiDB 2.0.7 fixes an issue where USE INDEX(PRIMARY) could not be used on tables with an integer primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.0.7.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM table_name USE INDEX(PRIMARY) WHERE id = 1;\n```\n\n----------------------------------------\n\nTITLE: Disabling Top SQL via SQL System Variable\nDESCRIPTION: Disable Top SQL feature by setting the global TiDB system variable to turn off performance monitoring\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/top-sql.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_top_sql = 0;\n```\n\n----------------------------------------\n\nTITLE: Retrieve Current TSO - SQL\nDESCRIPTION: SQL command to obtain the current transaction status object (TSO) timestamp, used for monitoring sync status in cluster replication. This should follow setting a cluster to read-only mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nSELECT tidb_current_ts();\n```\n\n----------------------------------------\n\nTITLE: Setting Memory Quota for Queries\nDESCRIPTION: Example demonstrating how to set memory usage limit to 1024 MB for a query using MEMORY_QUOTA hint.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_46\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ MEMORY_QUOTA(1024 MB) */ * from t;\n```\n\n----------------------------------------\n\nTITLE: Setting Full Data Import Options in YAML\nDESCRIPTION: This YAML configuration snippet demonstrates how to set the pool size for full data import in DM, which determines the number of import threads.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-tune-configuration.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nloaders:\n  pool-size: 16\n```\n\n----------------------------------------\n\nTITLE: Example Usage of ticloud config edit Command\nDESCRIPTION: Demonstrates how to edit the profile configuration file using the ticloud config edit command.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-edit.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud config edit\n```\n\n----------------------------------------\n\nTITLE: Setting rank-formula-version for balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command sets the algorithm version used for hot region scheduling. Version 'v2' is an improved algorithm introduced in TiDB v6.3.0 and made GA in v6.4.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_42\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config balance-hot-region-scheduler set rank-formula-version v2\n```\n\n----------------------------------------\n\nTITLE: IdentListWithParenOpt EBNF Syntax Definition\nDESCRIPTION: The EBNF syntax definition for an optional identifier list with parentheses, used to name columns in a Common Table Expression.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-with.md#2025-04-18_snippet_3\n\nLANGUAGE: ebnf\nCODE:\n```\nIdentListWithParenOpt ::=\n( '(' IdentList ')' )?\n```\n\n----------------------------------------\n\nTITLE: Querying Runaway Watches List in SQL\nDESCRIPTION: This SQL query retrieves all entries from the RUNAWAY_WATCHES table, ordered by ID, providing a comprehensive view of the watch list for runaway queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-runaway-watches.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.RUNAWAY_WATCHES ORDER BY id\\G\n```\n\n----------------------------------------\n\nTITLE: Creating a Session Binding\nDESCRIPTION: This SQL snippet illustrates how to create a session binding in TiDB for a specific SQL statement to leverage an optimized execution plan.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-bindings.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE SESSION BINDING FOR\n         SELECT * FROM t1 WHERE b = 123\n        USING\n         SELECT * FROM t1 IGNORE INDEX (b) WHERE b = 123;\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Displaying warnings after EXPLAIN in TiDB\nDESCRIPTION: This SQL snippet uses `SHOW warnings;` to display any warnings generated by the previous `EXPLAIN FORMAT='plan_cache'` statement. This is useful for diagnosing why a query might not be hitting the plan cache.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-non-prepared-plan-cache.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSHOW warnings;\n```\n\n----------------------------------------\n\nTITLE: Data Migration with gh-ost in MySQL\nDESCRIPTION: SQL statements for inserting control data and copying original table data to ghost table. DM ignores these non-realtable DML operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nINSERT /* gh-ost */ INTO `test`.`_test4_ghc` VALUES (......);\nINSERT /* gh-ost `test`.`test4` */ ignore INTO `test`.`_test4_gho` (`id`, `date`, `account_id`, `conversion_price`, `ocpc_matched_conversions`, `ad_cost`, `cl2`)\n      (SELECT `id`, `date`, `account_id`, `conversion_price`, `ocpc_matched_conversions`, `ad_cost`, `cl2` FROM `test`.`test4` FORCE INDEX (`PRIMARY`)\n        WHERE (((`id` > _binary'1') OR ((`id` = _binary'1'))) AND ((`id` < _binary'2') OR ((`id` = _binary'2')))) lock IN share mode\n      )   ;\n```\n\n----------------------------------------\n\nTITLE: Even Split Syntax Example for TiDB Tables\nDESCRIPTION: SQL syntax example for evenly splitting a table region into multiple regions between specified boundaries in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSPLIT TABLE table_name [INDEX index_name] BETWEEN (lower_value) AND (upper_value) REGIONS region_num\n```\n\n----------------------------------------\n\nTITLE: Cloning the Sample Repository\nDESCRIPTION: Git commands to clone the sample code repository for the TiDB Python Django quickstart project.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/tidb-samples/tidb-python-django-quickstart.git\ncd tidb-python-django-quickstart\n```\n\n----------------------------------------\n\nTITLE: Deleting a Branch in Interactive Mode in Shell\nDESCRIPTION: Example of deleting a TiDB Cloud Serverless branch in interactive mode. This command will prompt the user for required information such as branch ID and cluster ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-delete.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch delete\n```\n\n----------------------------------------\n\nTITLE: Canceling store deletion in TiDB PD\nDESCRIPTION: This command cancels the deletion of an 'Offline' store, changing its state back to 'Up'. It cannot be used on 'Tombstone' state stores.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_50\n\nLANGUAGE: bash\nCODE:\n```\nstore cancel-delete 1\n```\n\n----------------------------------------\n\nTITLE: Querying DM Task Status\nDESCRIPTION: Shell command for checking the status of a running DM migration task. Allows monitoring of task progress and troubleshooting issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-shards-to-tidb.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} query-status ${task-name}\n```\n\n----------------------------------------\n\nTITLE: Installing MySQL Client on RPM-based distros\nDESCRIPTION: This snippet provides the command to install the MySQL command-line client on RPM-based Linux distributions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nsudo yum install mysql\n```\n\n----------------------------------------\n\nTITLE: TiDB DDL Owner Deletion Command\nDESCRIPTION: Command to delete DDL owner from etcd cluster when TiDB server is inaccessible\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntidb-ctl etcd delowner [LeaseID] [flags] + ownerKey\n```\n\n----------------------------------------\n\nTITLE: Switch TiDB Dashboard Serving Instance\nDESCRIPTION: Command to change which PD instance serves the TiDB Dashboard using the PD control tool.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-deploy.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd -u http://127.0.0.1:2379 config set dashboard-address http://9.9.9.9:2379\n```\n\n----------------------------------------\n\nTITLE: Installing Dumpling via TiUP\nDESCRIPTION: Commands to install Dumpling using TiUP package manager and set up the environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\nsource ~/.bash_profile\ntiup install dumpling\n```\n\n----------------------------------------\n\nTITLE: Using SHOW STATS_LOCKED with EBNF Syntax\nDESCRIPTION: This snippet shows the EBNF diagram for the SHOW STATS_LOCKED command, which lists tables with locked statistics. Dependencies include TiDB version compatibility. Key parameters include optional LIKE or WHERE clauses to filter results.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-locked.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\nShowStatsLockedStmt ::= 'SHOW' 'STATS_LOCKED' ShowLikeOrWhereOpt\n\nShowLikeOrWhereOpt ::= 'LIKE' SimpleExpr | 'WHERE' Expression\n```\n\n----------------------------------------\n\nTITLE: Filtering Character Sets with WHERE Clause in TiDB\nDESCRIPTION: SQL example illustrating the use of the WHERE clause with SHOW CHARACTER SET to filter results based on the Description column.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-character-set.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CHARACTER SET WHERE Description='UTF-8 Unicode';\n```\n\n----------------------------------------\n\nTITLE: Query Processor List using CDC CLI\nDESCRIPTION: This command queries the list of processors in a TiCDC cluster using the `cdc cli` tool. It requires the address of the TiCDC server.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli processor list --server=http://10.0.10.25:8300\n```\n\n----------------------------------------\n\nTITLE: Listing TiDB Clusters Command Syntax\nDESCRIPTION: Basic command syntax for listing all TiDB clusters deployed by the current user. The command shows cluster name, deployment user, version, path, and SSH private key information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-list.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster list [flags]\n```\n\n----------------------------------------\n\nTITLE: Sample Table Schema - JSON\nDESCRIPTION: This JSON snippet provides an example schema structure for a table, including details about columns, types, and constraints, used when a DDL event occurs at the table level.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Table\":\"table1\",\n    \"Schema\":\"test\",\n    \"Version\":1,\n    \"TableVersion\":441349361156227074,\n    \"Query\":\"ALTER TABLE test.table1 ADD OfficeLocation blob(20)\",\n    \"Type\":5,\n    \"TableColumns\":[\n        {\n            \"ColumnName\":\"Id\",\n            \"ColumnType\":\"INT\",\n            \"ColumnNullable\":\"false\",\n            \"ColumnIsPk\":\"true\"\n        },\n        {\n            \"ColumnName\":\"LastName\",\n            \"ColumnType\":\"CHAR\",\n            \"ColumnLength\":\"20\"\n        },\n        {\n            \"ColumnName\":\"FirstName\",\n            \"ColumnType\":\"VARCHAR\",\n            \"ColumnLength\":\"30\"\n        },\n        {\n            \"ColumnName\":\"HireDate\",\n            \"ColumnType\":\"DATETIME\"\n        },\n        {\n            \"ColumnName\":\"OfficeLocation\",\n            \"ColumnType\":\"BLOB\",\n            \"ColumnLength\":\"20\"\n        }\n    ],\n    \"TableColumnsTotal\":\"5\"\n}\n```\n\n----------------------------------------\n\nTITLE: Disabling Both Operator-level and Query-level Spilling in SQL\nDESCRIPTION: These SQL statements demonstrate disabling both operator-level and query-level spilling mechanisms by setting all related thresholds to 0, resulting in a memory-intensive query that consumes 29.55 GiB.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-spill-disk.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_max_bytes_before_tiflash_external_group_by = 0;\nSET tiflash_mem_quota_query_per_node = 0;\nSET tiflash_query_spill_ratio = 0;\nSELECT\n  l_orderkey,\n  MAX(L_COMMENT),\n  MAX(L_SHIPMODE),\n  MAX(L_SHIPINSTRUCT),\n  MAX(L_SHIPDATE),\n  MAX(L_EXTENDEDPRICE)\nFROM lineitem\nGROUP BY l_orderkey\nHAVING SUM(l_quantity) > 314;\n```\n\n----------------------------------------\n\nTITLE: Updating All TiUP Components\nDESCRIPTION: Update all installed TiUP components using the --all flag, which is required when no specific component is specified\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-update.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup update --all\n```\n\n----------------------------------------\n\nTITLE: Enabling OpenAPI in TiUP Topology File (YAML)\nDESCRIPTION: Configuration snippet to enable OpenAPI in the topology file when deploying DM using TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  master:\n    openapi: true\n```\n\n----------------------------------------\n\nTITLE: Adding ProxySQL YUM Repository for CentOS\nDESCRIPTION: This bash script adds the ProxySQL YUM repository to the system, enabling easy installation of ProxySQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ncat > /etc/yum.repos.d/proxysql.repo << EOF\n[proxysql]\nname=ProxySQL YUM repository\nbaseurl=https://repo.proxysql.com/ProxySQL/proxysql-2.4.x/centos/\\$releasever\ngpgcheck=1\ngpgkey=https://repo.proxysql.com/ProxySQL/proxysql-2.4.x/repo_pub_key\nEOF\n```\n\n----------------------------------------\n\nTITLE: Configuring Scheduler Concurrency for TiDB Conflict Detection - Toml\nDESCRIPTION: This snippet configures the number of slots in the TiDB scheduler, which affects conflict detection in the TiKV layer during optimistic transactions. Adjusting this setting can help manage performance under contention scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimistic-transaction.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n# Controls the number of slots. (\"2048000\" by default）\nscheduler-concurrency = 2048000\n```\n\n----------------------------------------\n\nTITLE: Configure Maximum Raft Replicas\nDESCRIPTION: This code snippet uses the `tiup ctl:v{CLUSTER_VERSION} pd` tool to set the maximum number of Raft replicas for the cluster. Setting the correct number of replicas is crucial for data redundancy and fault tolerance.\nSOURCE: https://github.com/pingcap/docs/blob/master/three-data-centers-in-two-cities-deployment.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n\"config set max-replicas 5\"\n```\n\n----------------------------------------\n\nTITLE: Example of -- Without Required Whitespace in TiDB\nDESCRIPTION: Demonstrates that double dashes without a following whitespace are not treated as comments but as part of the SQL operation, resulting in a subtraction operation rather than a comment.\nSOURCE: https://github.com/pingcap/docs/blob/master/comment-syntax.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1+1--1;\n```\n\n----------------------------------------\n\nTITLE: Service Availability Alert Rule\nDESCRIPTION: PromQL query to monitor various service endpoints (TiDB, TiKV, PD, etc.) availability\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_23\n\nLANGUAGE: promql\nCODE:\n```\nprobe_success{group=\"tidb\"} == 0\n```\n\n----------------------------------------\n\nTITLE: Executing queries to utilize plan cache in TiDB\nDESCRIPTION: These SQL snippets execute two `SELECT` queries against the table `t`. The intention is for the second query to potentially reuse the execution plan cached from the first query, demonstrating the functionality of the non-prepared plan cache.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-non-prepared-plan-cache.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t WHERE b < 10 AND a = 1;\nSELECT * FROM t WHERE b < 5 AND a = 2;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Client TLS with X.509 Certificates\nDESCRIPTION: Example configuration for enabling TLS in TiKV Client using X.509 certificates. This setup requires specifying the trust certificate collection, key certificate chain, and key file paths.\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_7\n\nLANGUAGE: properties\nCODE:\n```\nspark.tispark.tikv.tls_enable                                  true\nspark.tispark.tikv.trust_cert_collection                       /home/tispark/root.pem\nspark.tispark.tikv.key_cert_chain                              /home/tispark/client.pem\nspark.tispark.tikv.key_file                                    /home/tispark/client.key\n```\n\n----------------------------------------\n\nTITLE: Task Metrics Table in Markdown\nDESCRIPTION: Table defining task-related metrics for migration monitoring, including task state, load progress, and binlog synchronization status with their alert conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/monitor-a-dm-cluster.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n| Metric name | Description | Alert | Severity level |\n|:----|:------------|:----|:----|\n| task state | The state of subtasks for migration | An alert occurs when the subtask has been paused for more than 10 minutes | critical |\n| load progress | The percentage of the completed loading process of the load unit. The value range is 0%~100% | N/A | N/A |\n```\n\n----------------------------------------\n\nTITLE: Querying Connection ID in TiDB SQL\nDESCRIPTION: The SELECT CONNECTION_ID() function returns a 64-bit integer in TiDB, unlike MySQL which returns a 32-bit integer. This can cause data overflow issues if not handled properly in applications.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-third-party-tools-compatibility.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT CONNECTION_ID()\n```\n\n----------------------------------------\n\nTITLE: TiDB Cloud Maintenance Links in Markdown\nDESCRIPTION: Markdown formatted list of maintenance notification links with dates and descriptions, organized in reverse chronological order from 2024 to 2023.\nSOURCE: https://github.com/pingcap/docs/blob/master/TOC-tidb-cloud.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n  - [[2024-04-09] TiDB Cloud Monitoring Features Maintenance Notification](/tidb-cloud/notification-2024-04-09-monitoring-features-maintenance.md)\n  - [[2023-11-14] TiDB Cloud Dedicated Scale Feature Maintenance Notification](/tidb-cloud/notification-2023-11-14-scale-feature-maintenance.md)\n  - [[2023-09-26] TiDB Cloud Console Maintenance Notification](/tidb-cloud/notification-2023-09-26-console-maintenance.md)\n  - [[2023-08-31] TiDB Cloud Console Maintenance Notification](/tidb-cloud/notification-2023-08-31-console-maintenance.md)\n```\n\n----------------------------------------\n\nTITLE: Listing TiDB Clusters Managed by TiUP\nDESCRIPTION: Lists all TiDB clusters currently managed by TiUP, showing their names, versions, and status. This helps administrators keep track of all clusters in their environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster list\n```\n\n----------------------------------------\n\nTITLE: Binlog Replace Command for Second Shard Table 2\nDESCRIPTION: Command to replace the problematic DDL with two equivalent statements for the second MySQL instance's shard_table_2.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nbinlog replace test -s mysql-replica-02 \"ALTER TABLE `shard_db_2`.`shard_table_2` ADD COLUMN `new_col` INT;ALTER TABLE `shard_db_2`.`shard_table_2` ADD UNIQUE(`new_col`)\"\n```\n\n----------------------------------------\n\nTITLE: Sample CLUSTER_LOG Table Output\nDESCRIPTION: Displays the table structure with fields for time, type, instance, level and message columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-log.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+----------+------------------+------+------+---------+-------+\n| Field    | Type             | Null | Key  | Default | Extra |\n+----------+------------------+------+------+---------+-------+\n| TIME     | varchar(32)      | YES  |      | NULL    |       |\n| TYPE     | varchar(64)      | YES  |      | NULL    |       |\n| INSTANCE | varchar(64)      | YES  |      | NULL    |       |\n| LEVEL    | varchar(8)       | YES  |      | NULL    |       |\n| MESSAGE  | var_string(1024) | YES  |      | NULL    |       |\n+----------+------------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Generating CA Key for TiDB Data Migration\nDESCRIPTION: Command to generate a 4096-bit RSA private key for the Certificate Authority (CA) using OpenSSL.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nopenssl genrsa -out ca-key.pem 4096\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with npm\nDESCRIPTION: Command to install the required packages for the sample app using npm.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nextjs.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Configuring CSV Parsing Options in TOML for TiDB Lightning\nDESCRIPTION: TOML configuration for CSV parsing options in TiDB Lightning, including separator, delimiter, header, null handling, and backslash escaping.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[mydumper.csv]\nseparator = ','\ndelimiter = '\"'\nheader = true\nnot-null = false\nnull = '\\N'\nbackslash-escape = true\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP Cluster Commands in Shell\nDESCRIPTION: The general syntax for using TiUP Cluster commands. Replace [command] with a specific command from the supported list, and [flags] with any applicable options.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster [command] [flags]\n```\n\n----------------------------------------\n\nTITLE: MySQL View Creation Syntax\nDESCRIPTION: Fixed parsing support for CREATE VIEW statements to allow creation of database views\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.0-rc.4.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE VIEW\n```\n\n----------------------------------------\n\nTITLE: Creating Triggers for Data Synchronization in pt-osc\nDESCRIPTION: SQL statements used by pt-osc to create triggers that ensure data consistency by replicating changes from the original table to the '_new' table. DM doesn't execute these as triggers aren't supported in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TRIGGER `pt_osc_test_test4_del` AFTER DELETE ON `test`.`test4` ...... ;\nCREATE TRIGGER `pt_osc_test_test4_upd` AFTER UPDATE ON `test`.`test4` ...... ;\nCREATE TRIGGER `pt_osc_test_test4_ins` AFTER INSERT ON `test`.`test4` ...... ;\n```\n\n----------------------------------------\n\nTITLE: Starting Django Development Server\nDESCRIPTION: Command to run the Django development server to test the TiDB Vector Search integration.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython manage.py runserver\n```\n\n----------------------------------------\n\nTITLE: Basic TIME Type Declaration\nDESCRIPTION: Syntax for declaring TIME type with optional fractional seconds precision parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nTIME[(fsp)]\n```\n\n----------------------------------------\n\nTITLE: Example of Sleep Function Query in TiDB\nDESCRIPTION: Example of a query containing the SLEEP function that had issues with column pruning during execution, causing invalid behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.4.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nselect 1 from (select sleep(1)) t;\n```\n\n----------------------------------------\n\nTITLE: Querying Data after Import with Reserved Keywords in TiDB\nDESCRIPTION: When a column name is a reserved keyword in TiDB, TiDB Cloud automatically adds backticks to enclose the column name during the import process. This code snippet shows how to query such columns by enclosing the column name with backticks.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-import-local-files.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n\"`order`\"\n```\n\n----------------------------------------\n\nTITLE: Change Directory in Docker Container\nDESCRIPTION: This command navigates to the `/opt/data` directory within the Docker container.  This directory contains the mounted documentation files from the host machine and is where the PDF generation scripts will be executed.\nSOURCE: https://github.com/pingcap/docs/blob/master/resources/tidb-pdf-generation-tutorial.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncd /opt/data\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW PLACEMENT FOR Syntax in EBNF\nDESCRIPTION: This snippet defines the syntax of the SHOW PLACEMENT FOR statement using Extended Backus-Naur Form (EBNF) notation. It breaks down the segments of the statement into clear grammatical constructs for better understanding.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-placement-for.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\nShowStmt ::=\n    \"SHOW\" \"PLACEMENT\" \"FOR\" ShowPlacementTarget\n\nShowPlacementTarget ::=\n    DatabaseSym DBName\n|   \"TABLE\" TableName\n|   \"TABLE\" TableName \"PARTITION\" Identifier\n```\n\n----------------------------------------\n\nTITLE: Applying TiDB Cloud Backup Configuration with Terraform\nDESCRIPTION: Terminal output showing the execution of terraform apply command which displays the execution plan and creates the backup resource after confirmation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-backup-resource.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform apply\n\ntidbcloud_cluster.example_cluster: Refreshing state... [id=1379661944630234067]\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # tidbcloud_backup.example_backup will be created\n  + resource \"tidbcloud_backup\" \"example_backup\" {\n      + cluster_id       = \"1379661944630234067\"\n      + create_timestamp = (known after apply)\n      + description      = \"create by terraform\"\n      + id               = (known after apply)\n      + name             = \"firstBackup\"\n      + project_id       = \"1372813089189561287\"\n      + size             = (known after apply)\n      + status           = (known after apply)\n      + type             = (known after apply)\n    }\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\nDo you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only 'yes' will be accepted to approve.\n\n  Enter a value:\n```\n\n----------------------------------------\n\nTITLE: Handling `checksum failed: checksum mismatched remote vs local` error\nDESCRIPTION: This snippet discusses the potential causes for the `checksum failed: checksum mismatched remote vs local` error during TiDB Lightning operations, and advises on how to resolve them.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_15\n\nLANGUAGE: markdown\nCODE:\n```\n- Cause 1: The table might already have data. These old data can affect the final checksum.\n\n    - Cause 2: If the checksum of the target database is 0, which means nothing is imported, it is possible that the cluster is too hot and fails to take in any data.\n\n    - Cause 3: If the data source is generated by the machine and not backed up by [Dumpling](/dumpling-overview.md), ensure it respects the constraints of the table. For example:\n\n       - `AUTO_INCREMENT` columns need to be positive, and do not contain the value \"0\".\n       - UNIQUE and PRIMARY KEYs must not have duplicate entries.\n\n    - Solution: See [Troubleshooting Solution](/tidb-lightning/troubleshoot-tidb-lightning.md#checksum-failed-checksum-mismatched-remote-vs-local).\n```\n\n----------------------------------------\n\nTITLE: SQL Table Option for auto_rand_base\nDESCRIPTION: New table option added for auto_rand_base functionality in TiDB 3.1.1. This feature allows configuration of the base value for auto-random feature.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.1.1.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nauto_rand_base\n```\n\n----------------------------------------\n\nTITLE: Installing libnsl on RedHat Enterprise Linux 8\nDESCRIPTION: This command installs the `libnsl` library on RedHat Enterprise Linux 8, which is a necessary dependency for TiFlash to start correctly. It uses the `dnf` package manager to install the library.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n```shell\ndnf install libnsl\n```\n```\n\n----------------------------------------\n\nTITLE: Setting tidb_opt_range_max_size to 1500 Bytes in TiDB\nDESCRIPTION: This SQL statement sets the tidb_opt_range_max_size variable to 1500 bytes, limiting the memory usage for the optimizer to build scan ranges.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_70\n\nLANGUAGE: sql\nCODE:\n```\nSET @@tidb_opt_range_max_size = 1500;\n```\n\n----------------------------------------\n\nTITLE: Backing up TiDB Database to S3\nDESCRIPTION: SQL command to backup entire database to S3 storage with rate limiting.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP DATABASE * TO 's3://backup?access-key=minio&secret-access-key=miniostorage&endpoint=http://${HOST_IP}:6060&force-path-style=true' RATE_LIMIT = 120 MB/SECOND;\n```\n\n----------------------------------------\n\nTITLE: Logging in to TiDB After Resetting Root Password\nDESCRIPTION: Connect to TiDB with the root user after configuring skip-grant-table, allowing password reset for the root account.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 127.0.0.1 -P 4000 -u root\n```\n\n----------------------------------------\n\nTITLE: JSON_UNQUOTE() Result Example\nDESCRIPTION: The output shows how JSON_UNQUOTE() removes the quotes from the string \"foo\" to return just foo.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-modify.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\n+-----------------------+\n| JSON_UNQUOTE('\"foo\"') |\n+-----------------------+\n| foo                   |\n+-----------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: SHOW CONFIG Syntax\nDESCRIPTION: This EBNF diagram shows the syntax of the `SHOW CONFIG` statement in TiDB, including the optional `LIKE` or `WHERE` clauses for filtering the configuration information.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-config.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\n\"ShowConfigStmt ::= \\n    \\\"SHOW\\\" \\\"CONFIG\\\" ShowLikeOrWhere?\\n\\nShowLikeOrWhere ::= \\n    \\\"LIKE\\\" SimpleExpr\\n|   \\\"WHERE\\\" Expression\"\n```\n\n----------------------------------------\n\nTITLE: Querying Initial Data in SQL\nDESCRIPTION: SQL query to view all data in the table 't' before any modifications, showing the initial state for stale read comparison.\nSOURCE: https://github.com/pingcap/docs/blob/master/as-of-timestamp.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nselect * from t;\n```\n\n----------------------------------------\n\nTITLE: Describing USER_ATTRIBUTES Table Structure in TiDB\nDESCRIPTION: This SQL query describes the structure of the USER_ATTRIBUTES table in the INFORMATION_SCHEMA database. It shows the fields, their types, and other properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-user-attributes.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC user_attributes;\n```\n\n----------------------------------------\n\nTITLE: Running TiDB Lightning with nohup\nDESCRIPTION: Shell command to run TiDB Lightning using nohup, which prevents the process from exiting unexpectedly after receiving a SIGHUP signal.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-parquet-files-to-tidb.md#2025-04-18_snippet_5\n\nLANGUAGE: Shell\nCODE:\n```\nnohup tiup tidb-lightning -config tidb-lightning.toml > nohup.out 2>&1 &\n```\n\n----------------------------------------\n\nTITLE: Cloning the TiDB Vector Python Repository\nDESCRIPTION: Command to clone the tidb-vector-python repository which contains examples for integrating TiDB Vector Search with Python applications.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/pingcap/tidb-vector-python.git\n```\n\n----------------------------------------\n\nTITLE: Editing TiDB Cluster Configuration in Shell\nDESCRIPTION: This shell command opens the TiDB cluster configuration file in edit mode using TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-disaggregated-and-s3.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster edit-config mycluster\n```\n\n----------------------------------------\n\nTITLE: Creating Test Table in TiDB\nDESCRIPTION: Creates a simple table 't' with a single integer column 'a' for testing the plan cache.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-non-prepared-plan-cache.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a int);\n```\n\n----------------------------------------\n\nTITLE: Setting tidb_mem_oom_action for Memory Quota Handling\nDESCRIPTION: Specifies the action TiDB takes when a SQL statement exceeds the memory quota and cannot spill to disk. Options are CANCEL (default) or LOG.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_51\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_mem_oom_action = 'CANCEL' | 'LOG';\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for TiDB-Sequelize Node.js Application\nDESCRIPTION: This command installs the required packages, including Sequelize, for the sample application that connects to TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-sequelize.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: JDBC Connection URL Parameter for Server-Side Prepared Statements\nDESCRIPTION: Enable server-side statement preprocessing in TiDB by setting useServerPrepStmts parameter in JDBC connection URL.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nuseServerPrepStmts=true\n```\n\n----------------------------------------\n\nTITLE: Restoring Full TiDB Cluster Snapshot\nDESCRIPTION: Command to restore a complete TiDB cluster snapshot using BR. Includes system tables and allows rate limiting of the restore process.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full \\\n    --pd \"${PD_IP}:2379\" \\\n    --with-sys-table \\\n    --storage \"s3://${backup_collection_addr}/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --ratelimit 128 \\\n    --log-file restorefull.log\n```\n\n----------------------------------------\n\nTITLE: CANCEL IMPORT EBNF Syntax Definition\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the CANCEL IMPORT statement in TiDB. Shows that the statement requires the CANCEL IMPORT JOB keywords followed by a JobID.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-cancel-import-job.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCancelImportJobsStmt ::=\n    'CANCEL' 'IMPORT' 'JOB' JobID\n```\n\n----------------------------------------\n\nTITLE: Creating a Resource Group in TiDB SQL\nDESCRIPTION: SQL example demonstrating how to create a resource group named 'rg1' with a specified RU_PER_SEC value of 100.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-resource-group.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE RESOURCE GROUP rg1 RU_PER_SEC=100;\n```\n\n----------------------------------------\n\nTITLE: Checking Timezone in TiDB\nDESCRIPTION: This SQL query retrieves the current global timezone setting in the TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@global.time_zone;\n```\n\n----------------------------------------\n\nTITLE: Configuring balance-hot-region-scheduler in TiDB PD\nDESCRIPTION: This command displays all configuration options for the balance-hot-region scheduler in TiDB's Placement Driver. It shows various parameters that control hot region balancing behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_32\n\nLANGUAGE: bash\nCODE:\n```\n>> scheduler config balance-hot-region-scheduler  // Display all configuration of the balance-hot-region scheduler\n```\n\n----------------------------------------\n\nTITLE: Convert String to Date in TiDB\nDESCRIPTION: This snippet demonstrates how to convert a string to a date format in TiDB using STR_TO_DATE, in contrast to Oracle's TO_DATE function.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nTO_DATE('2021-05-28 17:31:37','yyyy-MM-dd hh24:mi:ss')\nTO_DATE('2021-05-28','yyyy-MM-dd hh24:mi:ss')\n```\n\nLANGUAGE: sql\nCODE:\n```\nSTR_TO_DATE('2021-05-28 17:31:37','%Y-%m-%d %H:%i:%s')\nSTR_TO_DATE('2021-05-28','%Y-%m-%d%T')\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Existing Projects\nDESCRIPTION: Alternative command to add mysql2 and dotenv gems to an existing Ruby project using bundler.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbundle add mysql2 dotenv\n```\n\n----------------------------------------\n\nTITLE: Running Python Optimistic Transaction Example\nDESCRIPTION: This snippet illustrates how to execute a Python script that performs optimistic transactions. The script is run with parameters indicating the number of books Alice and Bob are purchasing.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\nOPTIMISTIC=True ALICE=4 BOB=6 python3 txn_example.py\n```\n\n----------------------------------------\n\nTITLE: Deleting Data from TiDB with mysqlclient in Python\nDESCRIPTION: This code snippet shows how to delete data from a TiDB table using mysqlclient. It uses a parameterized query to safely delete a record based on a condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-mysqlclient.md#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith get_mysqlclient_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        player_id = \"1\"\n        cursor.execute(\"DELETE FROM players WHERE id = %s\", (player_id,))\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Intersection-Type Index Merge in TiDB\nDESCRIPTION: Shows two query execution plans for AND conditions: one without index merge and one using intersection-type index merge. The second plan uses the USE_INDEX_MERGE hint to combine results from multiple indexes using intersection logic.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-index-merge.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ NO_INDEX_MERGE() */ * FROM t WHERE a > 1 AND b > 1 AND c = 1;  -- Does not use index merge\n\n+--------------------------------+---------+-----------+-------------------------+---------------------------------------------+\n| id                             | estRows | task      | access object           | operator info                               |\n+--------------------------------+---------+-----------+-------------------------+---------------------------------------------+\n| IndexLookUp_19                 | 1.11    | root      |                         |                                             |\n| ├─IndexRangeScan_16(Build)     | 10.00   | cop[tikv] | table:t, index:idx_c(c) | range:[1,1], keep order:false, stats:pseudo |\n| └─Selection_18(Probe)          | 1.11    | cop[tikv] |                         | gt(test.t.a, 1), gt(test.t.b, 1)            |\n|   └─TableRowIDScan_17          | 10.00   | cop[tikv] | table:t                 | keep order:false, stats:pseudo              |\n+--------------------------------+---------+-----------+-------------------------+---------------------------------------------+\n\nEXPLAIN SELECT /*+ USE_INDEX_MERGE(t, idx_a, idx_b, idx_c) */ * FROM t WHERE a > 1 AND b > 1 AND c = 1;  -- Uses index merge\n+-------------------------------+---------+-----------+-------------------------+------------------------------------------------+\n| id                            | estRows | task      | access object           | operator info                                  |\n+-------------------------------+---------+-----------+-------------------------+------------------------------------------------+\n| IndexMerge_9                  | 1.11    | root      |                         | type: intersection                             |\n| ├─IndexRangeScan_5(Build)     | 3333.33 | cop[tikv] | table:t, index:idx_a(a) | range:(1,+inf], keep order:false, stats:pseudo |\n| ├─IndexRangeScan_6(Build)     | 3333.33 | cop[tikv] | table:t, index:idx_b(b) | range:(1,+inf], keep order:false, stats:pseudo |\n| ├─IndexRangeScan_7(Build)     | 10.00   | cop[tikv] | table:t, index:idx_c(c) | range:[1,1], keep order:false, stats:pseudo    |\n| └─TableRowIDScan_8(Probe)     | 1.11    | cop[tikv] | table:t                 | keep order:false, stats:pseudo                 |\n+-------------------------------+---------+-----------+-------------------------+------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Configuring gh-ost in TiDB DM pre-v2.0.5\nDESCRIPTION: Configuration setting for enabling gh-ost tool support in TiDB Data Migration versions before 2.0.5. Uses the deprecated online-ddl-scheme parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-online-ddl-tool-support.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nonline-ddl-scheme: \"gh-ost\"\n```\n\n----------------------------------------\n\nTITLE: Querying a Data Source (Shell/JSON)\nDESCRIPTION: Example of using curl to query a data source via the API and the expected JSON response.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/sources/source-1?with_status=true' \\\n  -H 'accept: application/json'\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"source_name\": \"mysql-01\",\n  \"host\": \"127.0.0.1\",\n  \"port\": 3306,\n  \"user\": \"root\",\n  \"password\": \"123456\",\n  \"enable_gtid\": false,\n  \"enable\": false,\n  \"flavor\": \"mysql\",\n  \"task_name_list\": [\n    \"task1\"\n  ],\n  \"security\": {\n    \"ssl_ca_content\": \"\",\n    \"ssl_cert_content\": \"\",\n    \"ssl_key_content\": \"\",\n    \"cert_allowed_cn\": [\n      \"string\"\n    ]\n  },\n  \"purge\": {\n    \"interval\": 3600,\n    \"expires\": 0,\n    \"remain_space\": 15\n  },\n  \"status_list\": [\n    {\n      \"source_name\": \"mysql-replica-01\",\n      \"worker_name\": \"worker-1\",\n      \"relay_status\": {\n        \"master_binlog\": \"(mysql-bin.000001, 1979)\",\n        \"master_binlog_gtid\": \"e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849\",\n        \"relay_dir\": \"./sub_dir\",\n        \"relay_binlog_gtid\": \"e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849\",\n        \"relay_catch_up_master\": true,\n        \"stage\": \"Running\"\n      },\n      \"error_msg\": \"string\"\n    }\n  ],\n  \"relay_config\": {\n    \"enable_relay\": true,\n    \"relay_binlog_name\": \"mysql-bin.000002\",\n    \"relay_binlog_gtid\": \"e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849\",\n    \"relay_dir\": \"./relay_log\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud using MyCLI\nDESCRIPTION: This snippet demonstrates how to connect to a TiDB Cloud Dedicated cluster using MyCLI with TLS enabled. It requires specifying the path to the CA certificate (`ssl-ca`) and verifying the server certificate (`ssl-verify-server-cert`). MyCLI automatically enables TLS when TLS related parameters are used.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tls-connect-to-dedicated.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmycli --ssl-ca=ca.pem --ssl-verify-server-cert -u root -h tidb.eqlfbdgthh8.clusters.staging.tidb-cloud.com -P 4000 -D test\n```\n\n----------------------------------------\n\nTITLE: Querying Current TSO in TiDB SQL Transaction\nDESCRIPTION: This snippet shows how to query the current TimeStamp Oracle (TSO) within a transaction using both the TIDB_CURRENT_TSO() function and the tidb_current_ts system variable in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN;\nSELECT TIDB_CURRENT_TSO();\nSELECT @@tidb_current_ts;\n```\n\n----------------------------------------\n\nTITLE: Implementing Follower Read Helper in Java\nDESCRIPTION: Defines a FollowerReadHelper class with methods to set session and global replica read modes in TiDB using JDBC.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-follower-read.md#2025-04-18_snippet_1\n\nLANGUAGE: java\nCODE:\n```\npublic enum FollowReadMode {\n    LEADER(\"leader\"),\n    FOLLOWER(\"follower\"),\n    LEADER_AND_FOLLOWER(\"leader-and-follower\"),\n    CLOSEST_REPLICA(\"closest-replica\"),\n    CLOSEST_ADAPTIVE(\"closest-adaptive\"),\n    PREFER_LEADER(\"prefer-leader\");\n\n    private final String mode;\n\n    FollowReadMode(String mode) {\n        this.mode = mode;\n    }\n\n    public String getMode() {\n        return mode;\n    }\n}\n\npublic class FollowerReadHelper {\n\n    public static void setSessionReplicaRead(Connection conn, FollowReadMode mode) throws SQLException {\n        if (mode == null) mode = FollowReadMode.LEADER;\n        PreparedStatement stmt = conn.prepareStatement(\n            \"SET @@tidb_replica_read = ?;\"\n        );\n        stmt.setString(1, mode.getMode());\n        stmt.execute();\n    }\n\n    public static void setGlobalReplicaRead(Connection conn, FollowReadMode mode) throws SQLException {\n        if (mode == null) mode = FollowReadMode.LEADER;\n        PreparedStatement stmt = conn.prepareStatement(\n            \"SET GLOBAL @@tidb_replica_read = ?;\"\n        );\n        stmt.setString(1, mode.getMode());\n        stmt.execute();\n    }\n\n}\n```\n\n----------------------------------------\n\nTITLE: Querying PROCESSLIST in TiDB 2.0.7\nDESCRIPTION: TiDB 2.0.7 adds the PROCESSLIST table to the information_schema, allowing users to query information about currently executing processes.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.0.7.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.PROCESSLIST;\n```\n\n----------------------------------------\n\nTITLE: Starting a Transaction with Causal Consistency in TiDB\nDESCRIPTION: SQL command to initiate a transaction with causal consistency enabled. This reduces commit latency by not requiring timestamp fetching from PD, but provides weaker consistency guarantees than the default linear consistency.\nSOURCE: https://github.com/pingcap/docs/blob/master/transaction-overview.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSTART TRANSACTION WITH CAUSAL CONSISTENCY ONLY;\n```\n\n----------------------------------------\n\nTITLE: Adding Column to Table\nDESCRIPTION: This SQL statement adds a column named `Level` of type `INT` to the `tbl02` table. It showcases adding columns to all sharded tables incrementally.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-shard-merge-optimistic.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER TABLE `tbl02` ADD COLUMN `Level` INT;\n```\n```\n\n----------------------------------------\n\nTITLE: Initializing Database Schema with Prisma Migrate\nDESCRIPTION: Command to run Prisma Migrate for initializing the database schema based on the Prisma schema file.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nnpx prisma migrate dev\n```\n\n----------------------------------------\n\nTITLE: Querying DDL Job Details in TiDB 4.0 RC\nDESCRIPTION: TiDB 4.0 RC introduces the DDLJobs system table, allowing users to query details of DDL jobs. This feature provides better visibility into schema change operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-rc.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\n-- Example of querying DDL job details\nSELECT * FROM mysql.tidb_ddl_jobs;\n```\n\n----------------------------------------\n\nTITLE: Querying Non-Up Nodes in TiKV\nDESCRIPTION: This command finds all nodes whose status is not 'Up', using Jq for filtering.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_63\n\nLANGUAGE: bash\nCODE:\n```\nstore --jq='.stores[].store | select(.state_name!=\"Up\") | {id, address, state_name}'\n```\n\n----------------------------------------\n\nTITLE: Sample JSON Document Definition\nDESCRIPTION: Example JSON document containing arrays of fruits and vegetables used for validation examples\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-validate.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"fruits\": [\n        \"orange\",\n        \"apple\",\n        \"pear\"\n    ],\n    \"vegetables\": [\n        \"carrot\",\n        \"pepper\",\n        \"kale\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed for Incremental Replication in TiDB\nDESCRIPTION: This command creates a TiCDC changefeed to replicate incremental data from an upstream TiDB cluster to a downstream TiDB Cloud cluster. It specifies the PD address, sink URI, changefeed ID, and start timestamp.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc cli changefeed create \\\n--pd=http://172.16.6.122:2379  \\\n--sink-uri=\"tidb://root:123456@172.16.6.125:4000\"  \\\n--changefeed-id=\"upstream-to-downstream\"  \\\n--start-ts=\"431434047157698561\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB connection parameters\nDESCRIPTION: Example of environment variables setup in the .env file for connecting to TiDB, including host, port, user, password, and SSL settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysqljs.md#2025-04-18_snippet_4\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_HOST={host}\nTIDB_PORT=4000\nTIDB_USER={user}\nTIDB_PASSWORD={password}\nTIDB_DATABASE=test\nTIDB_ENABLE_SSL=true\nTIDB_CA_PATH={downloaded_ssl_ca_path}\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW COLUMNS in SQL\nDESCRIPTION: This SQL example demonstrates the execution of the SHOW COLUMNS FROM statement in TiDB. It retrieves and displays a table's column details in a tabular format. The examples include creating a view and using various aliases of the statement to retrieve information. No specific prerequisites are needed, but the user should have access to the described tables or views.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-columns-from.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"mysql> CREATE VIEW v1 AS SELECT 1;\\nQuery OK, 0 rows affected (0.11 sec)\\n\\nmysql> SHOW COLUMNS FROM v1;\\n+-------+--------+------+------+---------+-------+\\n| Field | Type   | Null | Key  | Default | Extra |\\n+-------+--------+------+------+---------+-------+\\n| 1     | bigint | YES  |      | NULL    |       |\\n+-------+--------+------+------+---------+-------+\\n1 row in set (0.00 sec)\\n\\nmysql> DESC v1;\\n+-------+--------+------+------+---------+-------+\\n| Field | Type   | Null | Key  | Default | Extra |\\n+-------+--------+------+------+---------+-------+\\n| 1     | bigint | YES  |      | NULL    |       |\\n+-------+--------+------+------+---------+-------+\\n1 row in set (0.00 sec)\\n\\nmysql> DESCRIBE v1;\\n+-------+--------+------+------+---------+-------+\\n| Field | Type   | Null | Key  | Default | Extra |\\n+-------+--------+------+------+---------+-------+\\n| 1     | bigint | YES  |      | NULL    |       |\\n+-------+-----------+------+------+---------+-------+\\n1 row in set (0.00 sec)\\n\\nmysql> EXPLAIN v1;\\n+-------+--------+------+------+---------+-------+\\n| Field | Type   | Null | Key  | Default | Extra |\\n+-------+--------+------+------+---------+-------+\\n| 1     | bigint | YES  |      | NULL    |       |\\n+-------+--------+------+------+---------+-------+\\n1 row in set (0.00 sec)\\n\\nmysql> SHOW FIELDS FROM v1;\\n+-------+--------+------+------+---------+-------+\\n| Field | Type   | Null | Key  | Default | Extra |\\n+-------+--------+------+------+---------+-------+\\n| 1     | bigint | YES  |      | NULL    |       |\\n+-------+--------+------+------+---------+-------+\\n1 row in set (0.00 sec)\\n\\nmysql> SHOW FULL COLUMNS FROM v1;\\n+-------+--------+-----------+------+------+---------+-------+---------------------------------+---------+\\n| Field | Type   | Collation | Null | Key  | Default | Extra | Privileges                      | Comment |\\n+-------+--------+-----------+------+------+---------+-------+---------------------------------+---------+\\n| 1     | bigint | NULL      | YES  |      | NULL    |       | select,insert,update,references |         |\\n+-------+--------+-----------+------+------+---------+-------+---------------------------------+---------+\\n1 row in set (0.00 sec)\\n\\nmysql> SHOW FULL COLUMNS FROM mysql.user;\\n+------------------------+---------------+-------------+------+------+---------+-------+---------------------------------+---------+\\n| Field                  | Type          | Collation   | Null | Key  | Default | Extra | Privileges                      | Comment |\\n+------------------------+---------------+-------------+------+------+---------+-------+---------------------------------+---------+\\n| Host                   | char(255)     | utf8mb4_bin | NO   | PRI  | NULL    |       | select,insert,update,references |         |\\n| User                   | char(32)      | utf8mb4_bin | NO   | PRI  | NULL    |       | select,insert,update,references |         |\\n| authentication_string  | text          | utf8mb4_bin | YES  |      | NULL    |       | select,insert,update,references |         |\\n| plugin                 | char(64)      | utf8mb4_bin | YES  |      | NULL    |       | select,insert,update,references |         |\\n| Select_priv            | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Insert_priv            | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Update_priv            | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Delete_priv            | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Create_priv            | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Drop_priv              | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Process_priv           | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Grant_priv             | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| References_priv        | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Alter_priv             | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Show_db_priv           | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Super_priv             | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Create_tmp_table_priv  | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Lock_tables_priv       | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Execute_priv           | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Create_view_priv       | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Show_view_priv         | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Create_routine_priv    | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Alter_routine_priv     | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Index_priv             | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Create_user_priv       | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Event_priv             | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Repl_slave_priv        | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Repl_client_priv       | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Trigger_priv           | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Create_role_priv       | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Drop_role_priv         | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Account_locked         | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Shutdown_priv          | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Reload_priv            | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| FILE_priv              | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Config_priv            | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| Create_Tablespace_Priv | enum('N','Y') | utf8mb4_bin | NO   |      | N       |       | select,insert,update,references |         |\\n| User_attributes        | json          | NULL        | YES  |      | NULL    |       | select,insert,update,references |         |\\n+------------------------+---------------+-------------+------+------+---------+-------+---------------------------------+---------+\\n38 rows in set (0.00 sec)\"\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with Sequelize ORM in TypeScript\nDESCRIPTION: This code creates a new player record in the Players table with specified ID, coins, and goods values using Sequelize's create method. It logs the creation process and the resulting object.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-sequelize.md#2025-04-18_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nlogger.info('Creating a new player...');\nconst newPlayer = await playersModel.create({\n  id: 6,\n  coins: 600,\n  goods: 600,\n});\nlogger.info('Created a new player.');\nlogger.info(newPlayer.toJSON());\n```\n\n----------------------------------------\n\nTITLE: MySQL FLUSH TABLES Command\nDESCRIPTION: SQL command referenced for adding a global read lock during full data backup in MySQL\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-best-practices.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nFLUSH TABLES WITH READ LOCK\n```\n\n----------------------------------------\n\nTITLE: Configuring Mutual TLS for Pulsar in TiCDC\nDESCRIPTION: This TOML snippet demonstrates how to configure mutual TLS (mTLS) authentication for Pulsar in TiCDC, requiring both the client (TiCDC) and the server (Pulsar) to authenticate each other using certificates. It includes paths to the TLS trust certificates file, certificate file, and key file.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n[sink.pulsar-config]\ntls-trust-certs-file-path=\"/data/pulsar/tls-trust-certs-file\"\ntls-certificate-file=\"/data/pulsar/tls-certificate-file\"\ntls-key-file-path=\"/data/pulsar/tls-key-file\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Prisma Client with TiDB Cloud Adapter\nDESCRIPTION: Set up Prisma Client using @tidbcloud/prisma-adapter and @tidbcloud/serverless for connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-prisma-example.md#2025-04-18_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nimport { connect } from '@tidbcloud/serverless';\nimport { PrismaTiDBCloud } from '@tidbcloud/prisma-adapter';\nimport { PrismaClient } from '@prisma/client';\n\n// Initialize Prisma Client\nconst connection = connect({ url: ${DATABASE_URL} });\nconst adapter = new PrismaTiDBCloud(connection);\nconst prisma = new PrismaClient({ adapter });\n```\n\n----------------------------------------\n\nTITLE: Backing Up Specific Table to S3\nDESCRIPTION: Command to back up a single table from a TiDB cluster to Amazon S3 storage using the BR tool. It specifies the database name, table name, storage location, rate limit, and log file.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup table \\\n    --pd \"${PD_IP}:2379\" \\\n    --db test \\\n    --table usertable \\\n    --storage \"s3://${backup_collection_addr}/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --ratelimit 128 \\\n    --log-file backuptable.log\n```\n\n----------------------------------------\n\nTITLE: Disable telemetry configuration\nDESCRIPTION: This snippet illustrates the change in default values for telemetry-related configuration items in TiDB and PD. The telemetry feature is disabled by default in new deployments to enhance user privacy.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.5.md#2025-04-18_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n\n    - The default value of the [`tidb_enable_telemetry`](/system-variables.md#tidb_enable_telemetry-new-in-v402-and-deprecated-in-v810) system variable is changed from `ON` to `OFF`.\n    - The default value of the TiDB [`enable-telemetry`](/tidb-configuration-file.md#enable-telemetry-new-in-v402-and-deprecated-in-v810) configuration item is changed from `true` to `false`.\n    - The default value of the PD [`enable-telemetry`](/pd-configuration-file.md#enable-telemetry) configuration item is changed from `true` to `false`.\n\n```\n\n----------------------------------------\n\nTITLE: Enabling Garbage Collection in TiDB\nDESCRIPTION: This SQL command enables the garbage collection mechanism in the TiDB cluster. It sets the global variable tidb_gc_enable to TRUE.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_enable = TRUE;\n```\n\n----------------------------------------\n\nTITLE: Removing a SQL Binding Using SQL Digest in TiDB\nDESCRIPTION: SQL command to remove an execution plan binding according to SQL Digest at either GLOBAL or SESSION level. The SQL Digest can be obtained from viewing bindings.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nDROP [GLOBAL | SESSION] BINDING FOR SQL DIGEST StringLiteralOrUserVariableList;\n```\n\n----------------------------------------\n\nTITLE: Configuring DM-worker Command-line Flags\nDESCRIPTION: These flags are used to configure DM-worker settings, including network addresses, cluster registration, and logging options.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-command-line-flags.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n### `--advertise-addr`\n\n- The external address of DM-worker used to receive client requests\n- The default value is `\"{worker-addr}\"`\n- Optional flag. It can be in the form of `\"domain-name:port\"`\n\n### `--config`\n\n- The configuration file path of DM-worker\n- The default value is `\"\"`\n- Optional flag\n\n### `--join`\n\n- The `{advertise-addr}` list of DM-master nodes in a cluster when a DM-worker registers to this cluster\n- The default value is `\"\"`\n- Required flag. A configuration example of 3-node (DM-master node) cluster is `\"172.16.15.11:8261,172.16.15.12:8261,172.16.15.13:8261\"`\n\n### `--log-file`\n\n- The output file name of the log\n- The default value is `\"\"`\n- Optional flag\n\n### `-L`\n\n- The log level\n- The default value is `\"info\"`\n- Optional flag\n\n### `--name`\n\n- The name of a DM-worker node\n- The default value is `\"{advertise-addr}\"`\n- Required flag\n\n### `--worker-addr`\n\n- The address on which DM-worker listens to the client's requests\n- The default value is `\"\"`\n- Required flag\n```\n\n----------------------------------------\n\nTITLE: Splitting Another Range in a Specific Partition in SQL\nDESCRIPTION: This SQL snippet splits the data in the partition 'p2' of table 't' in the range [10000,20000] into two regions, aiding in managing data effectively within that partition.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT PARTITION TABLE t PARTITION (p2) BETWEEN (10000) AND (20000) REGIONS 2;\n```\n\n----------------------------------------\n\nTITLE: Running go-tpc tpcc command to import data using Shell\nDESCRIPTION: This shell command runs the `go-tpc tpcc` command to import 1,000 warehouses to the `tpcc` database. It takes parameters such as host, thread count, password, and database name. The command is executed on the benchmark executor after downloading the go-tpc tool.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n\"go-tpc tpcc --host ${HOST} --warehouses 1000 prepare -P 4000 -D tpcc -T ${THREAD} --time 2h0m0s -p ${PASSWORD} --ignore-error\"\n```\n\n----------------------------------------\n\nTITLE: EXCEPT Operation in TiDB\nDESCRIPTION: Demonstrates the EXCEPT operation which returns elements present in first set but not in second set.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/set-operators.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 EXCEPT SELECT * FROM t2;\n```\n\n----------------------------------------\n\nTITLE: Querying Captures List - Shell and JSON\nDESCRIPTION: Example of how to retrieve a list of all captures using GET /api/v2/captures. Returns information about TiCDC service processes.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v2/captures\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"total\": 1,\n  \"items\": [\n    {\n      \"id\": \"d2912e63-3349-447c-90ba-72a4e04b5e9e\",\n      \"is_owner\": true,\n      \"address\": \"127.0.0.1:8300\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Historical Data from a Specific Timestamp in SQL\nDESCRIPTION: This snippet shows how to import historical data as it existed at a specific point in time into a target table in TiDB. It uses the AS OF TIMESTAMP clause to specify the exact date and time for the historical data snapshot.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t FROM SELECT * FROM src AS OF TIMESTAMP '2024-02-27 11:38:00';\n```\n\n----------------------------------------\n\nTITLE: Deleting Data with Hibernate in Java\nDESCRIPTION: This snippet shows how to delete data from TiDB using Hibernate ORM. It opens a session and removes a PlayerBean object with specified ID, level, and score.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-hibernate.md#2025-04-18_snippet_4\n\nLANGUAGE: java\nCODE:\n```\ntry (Session session = sessionFactory.openSession()) {\n    session.remove(new PlayerBean(\"id\", 1, 1));\n}\n```\n\n----------------------------------------\n\nTITLE: TiDB Show Config Command\nDESCRIPTION: Example of SHOW CONFIG command mentioned in fixes\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.5.2.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CONFIG\n```\n\n----------------------------------------\n\nTITLE: Configuring Prisma Schema with Driver Adapters\nDESCRIPTION: Enable the driverAdapters feature in the schema.prisma file and set up the datasource.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-prisma-example.md#2025-04-18_snippet_1\n\nLANGUAGE: prisma\nCODE:\n```\ngenerator client {\n  provider        = \"prisma-client-js\"\n  previewFeatures = [\"driverAdapters\"]\n}\n\ndatasource db {\n  provider     = \"mysql\"\n  url          = env(\"DATABASE_URL\")\n}\n```\n\n----------------------------------------\n\nTITLE: Decoding Column Flag Example 2 (Binary Representation)\nDESCRIPTION: Example showing how to decode a column flag value of 46 into its component flags using binary representation. The example demonstrates that such a column is a composite index column, a primary key column, a generated column, and a Handle key column.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_11\n\nLANGUAGE: plaintext\nCODE:\n```\n46 == 0b_010_1110\n   == MultipleKeyFlag | PrimaryKeyFlag | GeneratedColumnFlag | HandleKeyFlag\n```\n\n----------------------------------------\n\nTITLE: Defining Update Event Value Format in JSON\nDESCRIPTION: Specifies the value format for Update events in Row Changed Events. It includes both the updated row data and the previous row data.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"u\":{\n        <Column Name>:{\n            \"t\":<Column Type>,\n            \"h\":<Where Handle>,\n            \"f\":<Flag>,\n            \"v\":<Column Value>\n        },\n        <Column Name>:{\n            \"t\":<Column Type>,\n            \"h\":<Where Handle>,\n            \"f\":<Flag>,\n            \"v\":<Column Value>\n        }\n    },\n    \"p\":{\n        <Column Name>:{\n            \"t\":<Column Type>,\n            \"h\":<Where Handle>,\n            \"f\":<Flag>,\n            \"v\":<Column Value>\n        },\n        <Column Name>:{\n            \"t\":<Column Type>,\n            \"h\":<Where Handle>,\n            \"f\":<Flag>,\n            \"v\":<Column Value>\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: MySQL Function Bug Fix - date_format\nDESCRIPTION: Fix for date_format function to handle '\\n' character in a MySQL-compatible way\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.1.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\ndate_format('some_date', '%Y-%m-%d\\n%H:%i:%s')\n```\n\n----------------------------------------\n\nTITLE: Generating Client Certificate Signing Request\nDESCRIPTION: Command to generate a certificate signing request (CSR) for client certificates.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nopenssl req -new -key client.key -out client.csr\n```\n\n----------------------------------------\n\nTITLE: Preparing Sysbench Data using Shell Command\nDESCRIPTION: This shell command prepares the Sysbench data in the `sbtest` database. It imports 32 tables and 10,000,000 rows using the `sysbench prepare` command. The command requires replacing placeholders such as `${HOST}`, `${PORT}`, `${THREAD}`, and `${PASSWORD}` with actual values.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.5-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_3\n\nLANGUAGE: Shell\nCODE:\n```\n\"sysbench oltp_common \\\n   --threads=${THREAD} \\\n   --db-driver=mysql \\\n   --mysql-db=sbtest \\\n   --mysql-host=${HOST} \\\n   --mysql-port=${PORT} \\\n   --mysql-user=root \\\n   --mysql-password=${PASSWORD} \\\n   prepare --tables=32 --table-size=10000000\"\n```\n\n----------------------------------------\n\nTITLE: Fixing Hash Partition Table Creation in TiDB\nDESCRIPTION: Resolves an out-of-memory issue caused by specifying an extremely large number of partitions when creating a hash partition table.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_22\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE table_name (id INT)\nPARTITION BY HASH(id)\nPARTITIONS 9999999999999\n```\n\n----------------------------------------\n\nTITLE: Markdown Table - Cluster Status Definitions\nDESCRIPTION: A markdown table defining various cluster status states and their descriptions for TiDB Cloud clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/monitor-tidb-cluster.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Cluster status | Description |\n|:--|:--|\n| **Available** | The cluster is healthy and available. |\n| **Creating** | The cluster is being created. The cluster is inaccessible while it is being created. |\n| **Importing** | Importing data into the cluster. |\n| **Maintaining** | The cluster is in maintenance. |\n| **Modifying** | The cluster is being modified. |\n| **Unavailable** | The cluster has failed and TiDB cannot recover it. |\n| **Pausing** | The cluster is being paused. |\n| **Paused** | The cluster is paused. |\n| **Resuming** | The cluster is being resumed from a pause. |\n| **Restoring** | The cluster is currently being restored from a backup. |\n```\n\n----------------------------------------\n\nTITLE: Accessing Uninitialized User-Defined Variables\nDESCRIPTION: Demonstrates that uninitialized user-defined variables in TiDB have a NULL value and string type by default.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @not_exist;\n```\n\n----------------------------------------\n\nTITLE: Calculating Table Checksum in TiDB\nDESCRIPTION: SQL statement to calculate the CRC64 checksum for table t1.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-checksum-table.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nADMIN CHECKSUM TABLE t1;\n```\n\n----------------------------------------\n\nTITLE: DROP SEQUENCE EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the DROP SEQUENCE statement, showing the grammar rules for dropping one or multiple sequence objects with optional IF EXISTS clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-sequence.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDropSequenceStmt ::=\n    'DROP' 'SEQUENCE' IfExists TableNameList\n\nIfExists ::= ( 'IF' 'EXISTS' )?\n\nTableNameList ::=\n    TableName ( ',' TableName )*\n\nTableName ::=\n    Identifier ('.' Identifier)?\n```\n\n----------------------------------------\n\nTITLE: Setting Up Python Virtual Environment\nDESCRIPTION: Commands to create and activate a Python virtual environment for the project to isolate dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd tidb-vector-python/examples/orm-sqlalchemy-quickstart\npython3 -m venv .venv\nsource .venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Maximum Delta Schema Count\nDESCRIPTION: Adjusts the number of times TiDB caches schema changes and corresponding changed table information from 100 to 1024. This can be modified using the tidb_max_delta_schema_count system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.18.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_max_delta_schema_count = 1024;\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation Structure\nDESCRIPTION: Markdown formatted documentation detailing TiDB monitoring metrics and their descriptions across different categories like Query Summary, Query Detail, Server metrics, Transaction metrics, Executor metrics, and Distsql metrics.\nSOURCE: https://github.com/pingcap/docs/blob/master/grafana-tidb-dashboard.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: TiDB Monitoring Metrics\nsummary: Learn some key metrics displayed on the Grafana TiDB dashboard.\naliases: ['/docs/dev/grafana-tidb-dashboard/','/docs/dev/reference/key-monitoring-metrics/tidb-dashboard/']\n---\n```\n\n----------------------------------------\n\nTITLE: Retrieving Table Statistics Metadata in TiDB\nDESCRIPTION: Shows the basic SHOW STATS_META command to display statistical metadata for all tables in the current database, including database name, table name, partition name, update time, modification count, and total row count\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-meta.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW STATS_META;\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW TABLE STATUS Syntax in EBNF\nDESCRIPTION: This snippet defines the syntax for the SHOW TABLE STATUS SQL command in Extended Backus-Naur Form (EBNF), illustrating how the command can be structured with optional parameters such as 'FROM' and 'LIKE'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-status.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowTableStatusStmt ::=\n    \"SHOW\" \"TABLE\" \"STATUS\" (\"FROM\" Identifier | \"IN\" Identifier )? ShowLikeOrWhere?\n\nShowLikeOrWhere ::=\n    \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Displaying Active Processes in TiDB with SQL\nDESCRIPTION: This SQL command shows the list of currently running processes in TiDB, including their IDs, users, hosts, databases, and the SQL statements being executed. It's useful for identifying long-running or problematic queries that may be causing stale read issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-stale-read.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n+---------------------+------+---------------------+--------+---------+------+------------+---------------------------+\n| Id                  | User | Host                | db     | Command | Time | State      | Info                      |\n+---------------------+------+---------------------+--------+---------+------+------------+---------------------------+\n| 2826881778407440457 | root | 192.168.31.43:58641 | test   | Query   | 48   | autocommit | update t set b = b + 1    |\n| 2826881778407440613 | root | 127.0.0.1:45952     | test   | Execute | 0    | autocommit | select * from t where a=? |\n| 2826881778407440619 | root | 192.168.31.43:60428 | <null> | Query   | 0    | autocommit | show processlist          |\n+---------------------+------+---------------------+--------+---------+------+------------+---------------------------+\n```\n\n----------------------------------------\n\nTITLE: Installing gh-ost from source on Linux\nDESCRIPTION: Series of commands to compile and install gh-ost from source code on a Linux system, including cloning the repository, building with Go, and moving the binary to a system path.\nSOURCE: https://github.com/pingcap/docs/blob/master/styles/config/vocabularies/PingCAP/accept.txt#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/github/gh-ost.git\ncd gh-ost\ngo build\nmv gh-ost /usr/local/bin/\n```\n\n----------------------------------------\n\nTITLE: Resume Task Help Output\nDESCRIPTION: Displays the complete help output showing command usage, flags, and global options for resuming tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-resume-task.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nresume a specified paused task\n\nUsage:\n dmctl resume-task [-s source ...] <task-name | task-file> [flags]\n\nFlags:\n -h, --help   help for resume-task\n\nGlobal Flags:\n -s, --source strings   MySQL Source ID\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW ENGINES in SQL\nDESCRIPTION: An example SQL execution of 'SHOW ENGINES', which displays a table of supported storage engines. TiDB always returns InnoDB as the supported engine, aligning with MySQL's compatibility while typically using TiKV as the underlying storage engine.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-engines.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW ENGINES;\n+--------+---------+------------------------------------------------------------+--------------+------+------------+\n| Engine | Support | Comment                                                    | Transactions | XA   | Savepoints |\n+--------+---------+------------------------------------------------------------+--------------+------+------------+\n| InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES          | YES  | YES        |\n+--------+---------+------------------------------------------------------------+--------------+------+------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Unsetting BDR Role\nDESCRIPTION: SQL commands demonstrating how to remove the BDR role from a cluster and verify the change.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-bdr-role.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nADMIN UNSET BDR ROLE;\n```\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.01 sec)\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW BDR ROLE;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+----------+\n| BDR_ROLE |\n+----------+\n|          |\n+----------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Running Node.js Project with TiDB Cloud Serverless Driver\nDESCRIPTION: Shell command to execute the Node.js script that uses the TiDB Cloud serverless driver.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-node-example.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nnode index.js\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Labels for High Availability\nDESCRIPTION: Configuration file defining server labels for a distributed TiKV cluster across multiple zones and availability zones. Provides a hierarchical labeling strategy for replica isolation and disaster recovery.\nSOURCE: https://github.com/pingcap/docs/blob/master/multi-data-centers-in-one-city-deployment.md#2025-04-18_snippet_1\n\nLANGUAGE: ini\nCODE:\n```\nserver_configs:\n  pd:\n    replication.location-labels: [\"zone\",\"az\",\"rack\",\"host\"]\n\ntikv_servers:\n  - host: 10.63.10.30\n    config:\n      server.labels: { zone: \"z1\", az: \"az1\", rack: \"r1\", host: \"30\" }\n  - host: 10.63.10.31\n    config:\n      server.labels: { zone: \"z1\", az: \"az1\", rack: \"r1\", host: \"31\" }\n  - host: 10.63.10.32\n    config:\n      server.labels: { zone: \"z1\", az: \"az1\", rack: \"r2\", host: \"32\" }\n  - host: 10.63.10.33\n    config:\n      server.labels: { zone: \"z1\", az: \"az1\", rack: \"r2\", host: \"33\" }\n```\n\n----------------------------------------\n\nTITLE: Example of Simple Topology File\nDESCRIPTION: This snippet provides an example of a minimal topology file necessary for deploying the TiDB cluster. It outlines the format and structure expected.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n---\n\npd_servers:\n  - host: 172.16.5.134\n    name: pd-134\n  - host: 172.16.5.139\n    name: pd-139\n  - host: 172.16.5.140\n    name: pd-140\n\ntidb_servers:\n  - host: 172.16.5.134\n  - host: 172.16.5.139\n  - host: 172.16.5.140\n\ntikv_servers:\n  - host: 172.16.5.134\n  - host: 172.16.5.139\n  - host: 172.16.5.140\n\ntiflash_servers:\n  - host: 172.16.5.141\n  - host: 172.16.5.142\n  - host: 172.16.5.143\n\ntiproxy_servers:\n  - host: 172.16.5.144\n\ngrafana_servers:\n  - host: 172.16.5.134\n\nmonitoring_servers:\n  - host: 172.16.5.134\n```\n\n----------------------------------------\n\nTITLE: Configuring PD Servers in YAML\nDESCRIPTION: This YAML snippet outlines the configuration settings for PD servers in a TiDB cluster, specifying necessary fields like `host`, `client_port`, and any additional settings in the `config` field.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n\"pd_servers:\\n  - host: 10.0.1.11\\n    config:\\n      schedule.max-merge-region-size: 20\\n      schedule.max-merge-region-keys: 200000\\n  - host: 10.0.1.12\"\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with Log Redaction Enabled\nDESCRIPTION: This SQL snippet demonstrates inserting data into a table with a unique key constraint when log redaction is enabled. The error message in the log will have sensitive data redacted.\nSOURCE: https://github.com/pingcap/docs/blob/master/log-redaction.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (a int, unique key (a));\ninsert into t values (1),(1);\n```\n\n----------------------------------------\n\nTITLE: Example Response for Table List in JSON\nDESCRIPTION: This JSON represents the response format when retrieving the list of table names from a specific schema in a data source. It returns an array of table names within the specified database.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_25\n\nLANGUAGE: json\nCODE:\n```\n[\n  \"table1\"\n]\n```\n\n----------------------------------------\n\nTITLE: Amazon S3 IAM Policy Configuration\nDESCRIPTION: YAML configuration for Amazon S3 access policy with required permissions\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n{\n   \"Version\": \"2012-10-17\",\n   \"Statement\": [\n       {\n           \"Sid\": \"VisualEditor0\",\n           \"Effect\": \"Allow\",\n           \"Action\": [\n               \"s3:GetObject\",\n               \"s3:GetObjectVersion\"\n           ],\n           \"Resource\": [\n               \"arn:aws:s3:::dumpling-s3/*\"\n           ]\n       },\n       {\n           \"Sid\": \"VisualEditor1\",\n           \"Effect\": \"Allow\",\n           \"Action\": [\n               \"s3:ListBucket\",\n               \"s3:GetBucketLocation\"\n           ],\n\n           \"Resource\": \"arn:aws:s3:::dumpling-s3\"\n       }\n   ]\n}\n```\n\n----------------------------------------\n\nTITLE: Key Visualizer Access URL Format\nDESCRIPTION: Example URL format for accessing the Key Visualizer page directly through a browser, where the IP and port should be replaced with actual PD instance details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-key-visualizer.md#2025-04-18_snippet_0\n\nLANGUAGE: url\nCODE:\n```\nhttp://127.0.0.1:2379/dashboard/#/keyviz\n```\n\n----------------------------------------\n\nTITLE: Creating Database in TiDB Cloud\nDESCRIPTION: The SQL code creates a database named 'sbtest' in the newly created TiDB Cloud Dedicated cluster. No pre-existing databases or schemas need to be in place for its execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.1-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE sbtest;\n```\n\n----------------------------------------\n\nTITLE: TiFlash System Variable Reference\nDESCRIPTION: Reference to the TiFlash pipeline model configuration variable that controls the feature in v7.2.0 and v7.3.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-pipeline-model.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ntidb_enable_tiflash_pipeline_model\n```\n\n----------------------------------------\n\nTITLE: Converting Binary-deployed DM-worker Configuration to v2.0+ Source Configuration\nDESCRIPTION: This snippet shows how to convert a DM-worker configuration file from TOML format in v1.0.x to a source configuration file in YAML format for v2.0+.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/manually-upgrade-dm-1.0-to-2.0.md#2025-04-18_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\nlog-level = \"info\"\nlog-file = \"dm-worker.log\"\nworker-addr = \":8262\"\nserver-id = 101\nsource-id = \"mysql-replica-01\"\nflavor = \"mysql\"\n[from]\nhost = \"172.16.10.81\"\nuser = \"root\"\npassword = \"VjX8cEeTX+qcvZ3bPaO4h0C80pe/1aU=\"\nport = 3306\n```\n\nLANGUAGE: YAML\nCODE:\n```\nserver-id: 101\nsource-id: \"mysql-replica-01\"\nflavor: \"mysql\"\nfrom:\n  host: \"172.16.10.81\"\n  port: 3306\n  user: \"root\"\n  password: \"VjX8cEeTX+qcvZ3bPaO4h0C80pe/1aU=\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Firewall Rules for Prometheus\nDESCRIPTION: Commands to set up firewall rules for Prometheus monitoring, opening port 12020/tcp.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nfirewall-cmd --permanent --zone=public --add-service=prometheus\nfirewall-cmd --permanent --service=prometheus --add-port=12020/tcp\n```\n\n----------------------------------------\n\nTITLE: Listing Branches in JSON Format\nDESCRIPTION: This example shows how to list all branches for a specific TiDB Cloud Serverless cluster and output the result in JSON format. This is useful for getting a complete result set.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-list.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch list <cluster-id> -o json\n```\n\n----------------------------------------\n\nTITLE: Disabling Row-Level Checksum in TiDB (SQL)\nDESCRIPTION: SQL command to disable the checksum integrity validation feature for single-row data in the upstream TiDB cluster by setting the tidb_enable_row_level_checksum system variable to OFF.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-integrity-check.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_enable_row_level_checksum = OFF;\n```\n\n----------------------------------------\n\nTITLE: Using System's Native SSH Client with TiUP DM\nDESCRIPTION: Commands to use the system's native SSH client for TiUP DM operations instead of the built-in SSH client. It covers various cluster operations and setting environment variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm deploy <cluster-name> <version> <topo> --native-ssh\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm start <cluster-name> --native-ssh\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm upgrade ... --native-ssh\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport TIUP_NATIVE_SSH=true\n```\n\n----------------------------------------\n\nTITLE: Get Random Value in TiDB\nDESCRIPTION: This snippet compares generating random values using SYS_GUID in Oracle and UUID in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nSYS_GUID()\n```\n\nLANGUAGE: sql\nCODE:\n```\nUUID()\n```\n\n----------------------------------------\n\nTITLE: Showing CREATE USER syntax in TiDB using EBNF\nDESCRIPTION: This EBNF diagram defines the syntax for the `SHOW CREATE USER` statement in TiDB. It specifies the required keywords (`SHOW`, `CREATE`, `USER`) and the options for specifying the user to display (either by username and hostname or using `CURRENT_USER`).\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-user.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\n\"SHOW\" \"CREATE\" \"USER\" (Username (\"@\" Hostname)? | \"CURRENT_USER\" ( \"(\" \")\" )? )\n```\n\n----------------------------------------\n\nTITLE: SHOW CREATE TABLE Usage Example\nDESCRIPTION: Example demonstrating how to create a table and then use SHOW CREATE TABLE to display its creation statement. Shows both the table creation and the resulting output.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-table.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (a INT);\nQuery OK, 0 rows affected (0.12 sec)\n\nmysql> SHOW CREATE TABLE t1\\G\n*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `a` int DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Dropping Local Temporary Table in SQL\nDESCRIPTION: SQL statement to manually drop a local temporary table.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nDROP TEMPORARY TABLE top_50_eldest_authors;\n```\n\n----------------------------------------\n\nTITLE: DEFAULT Function Usage in TiDB\nDESCRIPTION: Demonstrates the DEFAULT() function to get and use default column values in table operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id INT PRIMARY KEY, c1 INT DEFAULT 5);\n\nINSERT INTO t1 VALUES (1, 1);\n\nUPDATE t1 SET c1=DEFAULT(c1)+3;\n```\n\n----------------------------------------\n\nTITLE: Establishing Connection to TiDB with MySQL Connector/Python\nDESCRIPTION: This function creates a connection to a TiDB database using MySQL Connector/Python. It configures the connection parameters including host, port, user, password, and database name. If an SSL CA path is provided, it also sets up SSL verification.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-mysql-connector.md#2025-04-18_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ndef get_connection(autocommit: bool = True) -> MySQLConnection:\n    config = Config()\n    db_conf = {\n        \"host\": ${tidb_host},\n        \"port\": ${tidb_port},\n        \"user\": ${tidb_user},\n        \"password\": ${tidb_password},\n        \"database\": ${tidb_db_name},\n        \"autocommit\": autocommit,\n        \"use_pure\": True,\n    }\n\n    if ${ca_path}:\n        db_conf[\"ssl_verify_cert\"] = True\n        db_conf[\"ssl_verify_identity\"] = True\n        db_conf[\"ssl_ca\"] = ${ca_path}\n    return mysql.connector.connect(**db_conf)\n```\n\n----------------------------------------\n\nTITLE: Using Markdown Custom Content Tags in TiDB Documentation\nDESCRIPTION: Example of how to use CustomContent tags to show content dedicated to either TiDB or TiDB Cloud in documentation files that are shared between both products.\nSOURCE: https://github.com/pingcap/docs/blob/master/CONTRIBUTING.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```Markdown\n\n\n```\n\n----------------------------------------\n\nTITLE: Fixing ODBC-style Constant Usage in TiDB SQL Expressions\nDESCRIPTION: This fix addresses an issue where ODBC-styled constants (e.g., {d '2020-01-01'}) could not be used as expressions in TiDB SQL queries. The fix allows for proper parsing and execution of queries containing such constants.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.3.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\n{d '2020-01-01'}\n```\n\n----------------------------------------\n\nTITLE: Skipping Isolation Level Check in TiDB SQL\nDESCRIPTION: Sets the tidb_skip_isolation_level_check variable to prevent TiDB from reporting errors when setting the transaction isolation level to SERIALIZABLE.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.0-rc.1.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_skip_isolation_level_check = 1;\n```\n\n----------------------------------------\n\nTITLE: Defining CHAR Column in TiDB\nDESCRIPTION: Syntax for creating a CHAR column with optional character set and collation specifications. CHAR is a fixed-length string type with maximum length of 255 characters.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n[NATIONAL] CHAR[(M)] [CHARACTER SET charset_name] [COLLATE collation_name]\n```\n\n----------------------------------------\n\nTITLE: Locking a User Account in TiDB\nDESCRIPTION: Example of locking the user account 'newuser' using the ALTER USER statement. This demonstrates how to restrict access to a user account in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'newuser' ACCOUNT LOCK;\nQuery OK, 0 rows affected (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Installing Individual Packages for Django TiDB Integration\nDESCRIPTION: Alternative command to install specific packages needed for the Django TiDB vector search integration.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install Django django-tidb mysqlclient numpy python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Simple SQL Query - Selecting Authors\nDESCRIPTION: Basic SQL query to select author IDs and names from the authors table.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT id, name FROM authors;\n```\n\n----------------------------------------\n\nTITLE: Setting max_user_connections in TiDB\nDESCRIPTION: This variable controls the maximum number of simultaneous connections a single user can establish to the TiDB server. If set to `0`, there is no limit. The value can be adjusted to manage connection resources effectively.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n-- Default value: `0`\n-- Range: `[0, 100000]`\nSET GLOBAL max_user_connections = 0;\n```\n\n----------------------------------------\n\nTITLE: Recovering a Table by Name in TiDB SQL\nDESCRIPTION: This SQL snippet demonstrates how to recover a deleted table using its name after a DROP TABLE command. It shows the standard procedure to follow when attempting to restore a table that has been recently deleted and is still within the GC lifetime.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-recover-table.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nRECOVER TABLE table_name;\n```\n\n----------------------------------------\n\nTITLE: Starting DM Replication Task with dmctl\nDESCRIPTION: Shell command for starting a DM replication task using tiup dmctl. This command initiates the data replication process according to the specified task configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\n[root@localhost ~]# tiup dmctl --master-addr ${advertise-addr}  start-task dm-task.yaml\n```\n\n----------------------------------------\n\nTITLE: Querying Data with TypeORM in TypeScript\nDESCRIPTION: This code shows how to query a single Player record by ID using TypeORM. It returns the Player object if found, or null if no matching record exists.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nconst player: Player | null = await this.dataSource.manager.findOneBy(Player, {\n  id: id\n});\n```\n\n----------------------------------------\n\nTITLE: Verifying TiDB Cluster Version in Shell\nDESCRIPTION: This command displays the current version of the TiDB cluster after an upgrade. It uses the TiUP cluster display command to show cluster information.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster display <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Enabling Active PD Follower Feature in TiDB\nDESCRIPTION: Enable the Active PD Follower feature by setting the system variable 'pd_enable_follower_handle_region' to 'ON'. This distributes Region information requests across all PD servers, reducing CPU pressure on the PD leader.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-region-performance.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL pd_enable_follower_handle_region = 'ON';\n```\n\n----------------------------------------\n\nTITLE: Real-time Test Results Output\nDESCRIPTION: Sample output showing real-time performance metrics for different transaction types including NEW_ORDER, ORDER_STATUS, PAYMENT, STOCK_LEVEL, and analytical queries, displaying TPM, latency percentiles, and other statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-ch.md#2025-04-18_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n[Current] NEW_ORDER - Takes(s): 10.0, Count: 13524, TPM: 81162.0, Sum(ms): 998317.6, Avg(ms): 73.9, 50th(ms): 71.3, 90th(ms): 100.7, 95th(ms): 113.2, 99th(ms): 159.4, 99.9th(ms): 209.7, Max(ms): 243.3\n[Current] ORDER_STATUS - Takes(s): 10.0, Count: 1132, TPM: 6792.7, Sum(ms): 16196.6, Avg(ms): 14.3, 50th(ms): 13.1, 90th(ms): 24.1, 95th(ms): 27.3, 99th(ms): 37.7, 99.9th(ms): 50.3, Max(ms): 52.4\n[Current] PAYMENT - Takes(s): 10.0, Count: 12977, TPM: 77861.1, Sum(ms): 773982.0, Avg(ms): 59.7, 50th(ms): 56.6, 90th(ms): 88.1, 95th(ms): 100.7, 99th(ms): 151.0, 99.9th(ms): 201.3, Max(ms): 243.3\n[Current] STOCK_LEVEL - Takes(s): 10.0, Count: 1134, TPM: 6806.0, Sum(ms): 31220.9, Avg(ms): 27.5, 50th(ms): 25.2, 90th(ms): 37.7, 95th(ms): 44.0, 99th(ms): 71.3, 99.9th(ms): 117.4, Max(ms): 125.8\n[Current] Q11    - Count: 1, Sum(ms): 3682.9, Avg(ms): 3683.6\n[Current] DELIVERY - Takes(s): 10.0, Count: 1167, TPM: 7002.6, Sum(ms): 170712.9, Avg(ms): 146.3, 50th(ms): 142.6, 90th(ms): 192.9, 95th(ms): 209.7, 99th(ms): 251.7, 99.9th(ms): 335.5, Max(ms): 385.9\n```\n\n----------------------------------------\n\nTITLE: Configuring correlation adjustment in TiDB optimizer\nDESCRIPTION: Controls whether the optimizer estimates the number of rows based on column order correlation. The default value is ON.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.2.0.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_opt_enable_correlation_adjustment = ON;\n```\n\n----------------------------------------\n\nTITLE: Addressing checkpoint status issues in TiDB Lightning\nDESCRIPTION: This snippet focuses on error codes related to invalid checkpoint status when starting TiDB Lightning, detailing causes and instructions for resolution.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_16\n\nLANGUAGE: markdown\nCODE:\n```\n- Cause: Checkpoint is enabled, and Lightning/Importer has previously abnormally exited. To prevent accidental data corruption, TiDB Lightning will not start until the error is addressed. The error code is an integer less than 25, with possible values as `0, 3, 6, 9, 12, 14, 15, 17, 18, 20 and 21`. The integer indicates the step where the unexpected exit occurs in the import process. The larger the integer is, the later the exit occurs.\n\n    - Solution: See [Troubleshooting Solution](/tidb-lightning/troubleshoot-tidb-lightning.md#checkpoint-for--has-invalid-status-error-code).\n```\n\n----------------------------------------\n\nTITLE: Configure branch.autoReserved in tidbcloud.yml\nDESCRIPTION: This snippet demonstrates configuring the `branch.autoReserved` property in `tidbcloud.yml`. When set to `true`, the TiDB Cloud Branching app retains the created TiDB Cloud Serverless branch from previous commits, preventing deletion on new commits. The default value is `false`.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/branch-github-integration.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n\"github:\\n    branch:\\n        autoReserved: false\"\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Clustered Primary Key and SHARD_ROW_ID_BITS Error\nDESCRIPTION: Demonstrates the error thrown when attempting to create a table with both clustered primary key and SHARD_ROW_ID_BITS attribute.\nSOURCE: https://github.com/pingcap/docs/blob/master/clustered-indexes.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a VARCHAR(255) PRIMARY KEY CLUSTERED) SHARD_ROW_ID_BITS = 3;\n```\n\n----------------------------------------\n\nTITLE: Scaling Out DM Cluster\nDESCRIPTION: Command to add new nodes to the DM cluster using a configuration file\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm scale-out prod-cluster scale.yaml\n```\n\n----------------------------------------\n\nTITLE: ROLLBACK Statement EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the ROLLBACK statement in TiDB, including optional completion type specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-rollback.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nRollbackStmt ::=\n    'ROLLBACK' CompletionTypeWithinTransaction?\n\nCompletionTypeWithinTransaction ::=\n    'AND' ( 'CHAIN' ( 'NO' 'RELEASE' )? | 'NO' 'CHAIN' ( 'NO'? 'RELEASE' )? )\n|   'NO'? 'RELEASE'\n```\n\n----------------------------------------\n\nTITLE: Creating Database in TiDB Cloud using SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a new database named 'sbtest' in a TiDB Cloud Dedicated cluster. Ensure that you're connected to the cluster before executing this command.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v6.5-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE sbtest;\n```\n\n----------------------------------------\n\nTITLE: Locating OpenSSL Configuration File\nDESCRIPTION: Command to search for the OpenSSL configuration file in the root directory if the location is unknown.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nfind / -name openssl.cnf\n```\n\n----------------------------------------\n\nTITLE: TiDB 2.0.2 Release Notes Header\nDESCRIPTION: Markdown header and metadata for TiDB 2.0.2 release notes, including page title, aliases, and summary information.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.0.2.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: TiDB 2.0.2 Release Notes\naliases: ['/docs/dev/releases/release-2.0.2/','/docs/dev/releases/202/']\nsummary: TiDB 2.0.2 was released on May 21, 2018, with improvements in system stability. The release includes fixes for Decimal division expression, support for `USE INDEX` syntax in `Delete` statement, and timeout mechanism for writing Binlog in TiDB. PD now filters disconnected nodes in balance leader scheduler, modifies transfer leader operator timeout, and fixes scheduling issues. TiKV fixes Raft log printing, supports configuring gRPC parameters, leader election timeout range, and resolves snapshot intermediate file deletion issue.\n---\n```\n\n----------------------------------------\n\nTITLE: Basic YEAR Type Declaration\nDESCRIPTION: Syntax for declaring YEAR type with four-digit format specification.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nYEAR[(4)]\n```\n\n----------------------------------------\n\nTITLE: TiDB System Variables Configuration\nDESCRIPTION: Configuration documentation for TiDB system variables including tidb_enable_extended_stats, tidb_enable_external_ts_read, tidb_external_ts, and other system variables. Each variable is documented with its scope, persistence settings, type, default value, and detailed functionality description.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_29\n\nLANGUAGE: markdown\nCODE:\n```\n### tidb_enable_extended_stats\n\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): Yes\n- Type: Boolean\n- Default value: `OFF`\n- This variable indicates whether TiDB can collect the extended statistic to guide the optimizer.\n```\n\n----------------------------------------\n\nTITLE: Running the Sample Application\nDESCRIPTION: Command to execute the sample Node.js application that connects to TiDB using Prisma.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nnpm start\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Configuration File\nDESCRIPTION: Command to create a .env file from the example template for configuring database connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Using IMPORT INTO Statement in TiDB\nDESCRIPTION: The IMPORT INTO statement enables fast data import from CSV, SQL, or PARQUET formats into empty TiDB tables. Introduced in v7.2.0 and GA in v7.5.0, it offers extremely fast import speed without requiring separate TiDB Lightning deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/batch-processing.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO\n```\n\n----------------------------------------\n\nTITLE: Configuring Sync-diff-inspector for DM Replication Data Check in TOML\nDESCRIPTION: This configuration example shows how to set up sync-diff-inspector to check data consistency after DM replication. It connects to a DM-master instance, specifies a DM task name, and targets tables for comparison. The configuration enables SQL statement export to fix inconsistencies and automatically matches schemas between upstream and downstream databases.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/dm-diff.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n# Diff Configuration.\n\n######################### Global config #########################\n\n# The number of goroutines created to check data. The number of connections between upstream and downstream databases are slightly greater than this value.\ncheck-thread-count = 4\n\n# If enabled, SQL statements is exported to fix inconsistent tables.\nexport-fix-sql = true\n\n# Only compares the table structure instead of the data.\ncheck-struct-only = false\n\n# The IP address of dm-master and the format is \"http://127.0.0.1:8261\".\ndm-addr = \"http://127.0.0.1:8261\"\n\n# Specifies the `task-name` of DM.\ndm-task = \"test\"\n\n######################### Task config #########################\n[task]\n    output-dir = \"./output\"\n\n    # The tables of downstream databases to be compared. Each table needs to contain the schema name and the table name, separated by '.'\n    target-check-tables = [\"hb_test.*\"]\n```\n\n----------------------------------------\n\nTITLE: DO Statement with Subquery\nDESCRIPTION: Example of using subqueries in DO statements, which is a new feature in this release\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.7.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nDO (SELECT 1);\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW DATABASES Syntax in EBNF\nDESCRIPTION: This EBNF definition outlines the syntax for the SHOW DATABASES SQL statement including optional clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-databases.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowDatabasesStmt ::=\n    \"SHOW\" \"DATABASES\" ShowLikeOrWhere?\n\nShowLikeOrWhere ::=\n    \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Listing Specific Component Versions\nDESCRIPTION: Command to retrieve all versions of a specific TiUP component, showing version details like installation status, release date, and supported platforms.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-list.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup list [component]\n```\n\n----------------------------------------\n\nTITLE: Initializing the Database\nDESCRIPTION: Django command to run database migrations and initialize the database schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\npython manage.py migrate\n```\n\n----------------------------------------\n\nTITLE: Installing fetch Polyfill for Older Node.js Versions\nDESCRIPTION: npm command to install the 'undici' package, which provides a fetch implementation for older Node.js versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-node-example.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nnpm install undici\n```\n\n----------------------------------------\n\nTITLE: Adding LAG Function Instruction to Chat2Query via API Call\nDESCRIPTION: This code snippet demonstrates how to make a POST request to the TiDB Cloud API to add an instruction-type knowledge that guides Chat2Query to use the LAG function with OVER clause for sequential growth rate calculations. The request uses digest authentication with public and private keys and sends JSON data specifying the instruction type and content.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-knowledge.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user ${PUBLIC_KEY}:${PRIVATE_KEY} --request POST 'https://<region>.data.tidbcloud.com/api/v1beta/app/chat2query-<ID>/endpoint/v3/knowledgeBases/<knowledge_base_id>/data'\\\n --header 'content-type: application/json'\\\n --data-raw '{\n    \"type\": \"instruction\",\n    \"meta_data\": {},\n    \"raw_data\": {\n        \"instruction\": \"If the task requires calculating the sequential growth rate, use the LAG function with the OVER clause in SQL\"\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Setting TiFlash Thread Concurrency\nDESCRIPTION: Sets the maximum number of threads TiFlash can use to execute a request using the tidb_max_tiflash_threads variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_max_tiflash_threads = 20;\n```\n\n----------------------------------------\n\nTITLE: Sample Table Schema Definition\nDESCRIPTION: Example of a CREATE TABLE statement used to define a table schema for updating in DM.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-manage-schema.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `t1` (\n    `c1` int NOT NULL,\n    `c2` bigint DEFAULT NULL,\n    PRIMARY KEY (`c1`)\n) ENGINE=InnoDB DEFAULT CHARSET=latin1 COLLATE=latin1_bin\n```\n\n----------------------------------------\n\nTITLE: Correcting IF Function Behavior in TiDB SQL\nDESCRIPTION: Fixes incorrect behavior of IF(not_int, *, *) in SQL statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_13\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT IF(non_integer_column, value1, value2) FROM table\n```\n\n----------------------------------------\n\nTITLE: Listing Regions in JSON Format - Shell\nDESCRIPTION: This command lists all available regions for TiDB Cloud Serverless and specifies the output format as JSON for structured data representation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-region.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless region -o json\n```\n\n----------------------------------------\n\nTITLE: Configuring Master Key in TiKV for Google Cloud KMS - INI\nDESCRIPTION: This snippet provides the configuration for integrating a Google Cloud KMS master key into the TiKV configuration file, including key information and credential file paths.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_4\n\nLANGUAGE: ini\nCODE:\n```\n[security.encryption.master-key]\ntype = \"kms\"\nkey-id = \"projects/project-name/locations/global/keyRings/key-ring-name/cryptoKeys/key-name\"\nvendor = \"gcp\"\n\n[security.encryption.master-key.gcp]\ncredential-file-path = \"/path/to/credential.json\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Optimizer Limit Push Down Threshold\nDESCRIPTION: The tidb_opt_limit_push_down_threshold variable controls the optimizer's behavior of pushing down Limit/TopN, addressing issues where Limit/TopN couldn't be pushed down due to incorrect estimation.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.2.0.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_opt_limit_push_down_threshold = <value>;\n```\n\n----------------------------------------\n\nTITLE: Finding Slow Queries with Changed Execution Plans in SQL\nDESCRIPTION: Two SQL queries to find slow queries where the execution plan has changed, first grouping by digest to find candidates, then querying the specific plans.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nselect count(distinct plan_digest) as count,\n       digest,\n       min(query)\nfrom cluster_slow_query\ngroup by digest\nhaving count > 1\nlimit 3\\G\n```\n\nLANGUAGE: sql\nCODE:\n```\nselect min(plan),\n       plan_digest\nfrom cluster_slow_query\nwhere digest='17b4518fde82e32021877878bec2bb309619d384fca944106fcaf9c93b536e94'\ngroup by plan_digest\\G\n```\n\n----------------------------------------\n\nTITLE: Restarting SSH Service\nDESCRIPTION: Restarts the sshd service after configuration changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nservice sshd restart\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for SHOW COLLATION\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition showing the grammar rules for the SHOW COLLATION statement, including optional LIKE or WHERE clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-collation.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowCollationStmt ::=\n    \"SHOW\" \"COLLATION\" ShowLikeOrWhere?\n\nShowLikeOrWhere ::=\n    \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Utilizing ROW_NUMBER() Window Function in SQL\nDESCRIPTION: This example shows the use of ROW_NUMBER() function to assign unique, sequential numbers to each row in the result set. It uses a recursive CTE to generate a sequence of numbers with increments of 3.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/window-functions.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nWITH RECURSIVE cte(n) AS (\n    SELECT\n        1\n    UNION\n    SELECT\n        n+3\n    FROM\n        cte\n    WHERE\n        n<30\n)\nSELECT\n    n,\n    ROW_NUMBER() OVER ()\nFROM\n    cte;\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_plan_replayer_continuous_capture in TiDB\nDESCRIPTION: Controls the continuous capture functionality for the PLAN REPLAYER feature, with OFF as default suggesting caution in performance monitoring.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_41\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): No\n- Type: Boolean\n- Default value: `OFF`\n- This variable controls whether to enable the `PLAN REPLAYER CONTINUOUS CAPTURE` feature.\n```\n\n----------------------------------------\n\nTITLE: Defining Django Model with Vector Field\nDESCRIPTION: Django model definition for storing documents with vector embeddings, using the VectorField provided by django-tidb.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass Document(models.Model):\n   content = models.TextField()\n   embedding = VectorField(dimensions=3)\n```\n\n----------------------------------------\n\nTITLE: Selecting Data from a Global Temporary Table in TiDB - SQL\nDESCRIPTION: This code snippet retrieves data from the 'users' global temporary table after a record has been inserted, demonstrating its visibility within the transaction scope.\nSOURCE: https://github.com/pingcap/docs/blob/master/temporary-tables.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM users;\n```\n\n----------------------------------------\n\nTITLE: Restoring Deleted Database with FLASHBACK in SQL\nDESCRIPTION: New SQL syntax to restore a database and its data deleted by DROP within the garbage collection lifetime, enabling quick data and metadata restoration.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.4.0.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nFLASHBACK DATABASE\n```\n\n----------------------------------------\n\nTITLE: Creating Database Schema in SQL\nDESCRIPTION: Example of a database schema creation file content used for data import. The file should be named following the pattern ${db_name}-schema-create.sql\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/naming-conventions-for-data-import.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE import_db;\n```\n\n----------------------------------------\n\nTITLE: Configuring Parquet File Matching in TOML for TiDB Lightning\nDESCRIPTION: TOML configuration for matching Parquet files from Amazon Aurora snapshots in S3, using regular expressions to extract schema and table names.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_9\n\nLANGUAGE: toml\nCODE:\n```\n[[mydumper.files]]\npattern = '(?i)^(?:[^/]*/)*([a-z0-9\\-_]+).([a-z0-9\\-_]+)/(?:[^/]*/)*(?:[a-z0-9\\-_.]+\\.(parquet))$'\nschema = '$1'\ntable = '$2'\ntype = '$3'\n```\n\n----------------------------------------\n\nTITLE: Querying Top-N Slow Queries for a Specific User in SQL\nDESCRIPTION: SQL query to find the top 2 slowest queries executed by the 'test' user, ordered by execution time descending.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nselect query_time, query, user\nfrom information_schema.slow_query\nwhere is_internal = false\n  and user = \"test\"\norder by query_time desc\nlimit 2;\n```\n\n----------------------------------------\n\nTITLE: SQL Table Property Reference\nDESCRIPTION: Example of SQL table property referenced in a bug fix for duplicate entry errors with auto_random tables\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-rc.2.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nauto_random\n```\n\n----------------------------------------\n\nTITLE: Available MySQL Functions by Category in TiDB\nDESCRIPTION: Categorized listing of supported MySQL-compatible functions in TiDB including date/time, string manipulation, aggregation, encryption/compression, casting, and window functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/expressions-pushed-down.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Category | Functions |\n| Date and time | DATE(), DATE_FORMAT(), DATEDIFF(), DAYOFMONTH(), DAYOFWEEK(), DAYOFYEAR(), FROM_DAYS(), HOUR(), MAKEDATE(), MAKETIME(), MICROSECOND(), MINUTE(), MONTH(), MONTHNAME(), PERIOD_ADD(), PERIOD_DIFF(), SEC_TO_TIME(), SECOND(), SYSDATE(), TIME_TO_SEC(), TIMEDIFF(), WEEK(), WEEKOFYEAR(), YEAR(), DATE_ADD(), DATE_SUB(), ADDDATE(), SUBDATE(), FROM_UNIXTIME(), TIMESTAMPDIFF(), UNIX_TIMESTAMP() |\n| String | ASCII(), BIT_LENGTH(), CHAR(), CHAR_LENGTH(), CONCAT(), CONCAT_WS(), ELT(), FIELD(), HEX(), LENGTH(), LIKE, LOWER(), LTRIM(), MID(), REGEXP functions, REPLACE(), REVERSE(), RIGHT(), RTRIM(), SPACE(), STRCMP(), SUBSTR(), SUBSTRING(), UPPER() |\n| Aggregation | COUNT(), COUNT(DISTINCT), SUM(), AVG(), MAX(), MIN(), VARIANCE(), VAR_POP(), STD(), STDDEV(), JSON_ARRAYAGG(), JSON_OBJECTAGG() |\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS Authentication in TiDB\nDESCRIPTION: Added support for dynamically updating TLS certificates and forcing secure transport in TiDB. This improves security by allowing certificate updates without restarts and enforcing encrypted connections.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.1.0-rc.md#2025-04-18_snippet_1\n\nLANGUAGE: Go\nCODE:\n```\n// Example configuration\nclusterVerifyCN := \"example.com\"\nrequireSecureTransport := true\n```\n\n----------------------------------------\n\nTITLE: Loading Data Source Configuration into DM Cluster using TiUP\nDESCRIPTION: This shell command uses TiUP to load a data source configuration file into the TiDB Data Migration (DM) cluster. It specifies the DM-master address and the source configuration file to be loaded.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n[root@localhost ~]# tiup dmctl --master-addr ${advertise-addr} operate-source create dm-source1.yaml\n```\n\n----------------------------------------\n\nTITLE: Java DateTime Range Deletion\nDESCRIPTION: Java implementation for deleting data within a specific time range using PreparedStatement\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-delete-data.md#2025-04-18_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\ntry (Connection connection = ds.getConnection()) {\n    String sql = \"DELETE FROM `bookshop`.`ratings` WHERE `rated_at` >= ? AND `rated_at` <= ?\";\n    PreparedStatement preparedStatement = connection.prepareStatement(sql);\n    Calendar calendar = Calendar.getInstance();\n    calendar.set(Calendar.MILLISECOND, 0);\n\n    calendar.set(2022, Calendar.APRIL, 15, 0, 0, 0);\n    preparedStatement.setTimestamp(1, new Timestamp(calendar.getTimeInMillis()));\n\n    calendar.set(2022, Calendar.APRIL, 15, 0, 15, 0);\n    preparedStatement.setTimestamp(2, new Timestamp(calendar.getTimeInMillis()));\n\n    preparedStatement.executeUpdate();\n} catch (SQLException e) {\n    e.printStackTrace();\n}\n```\n\n----------------------------------------\n\nTITLE: Managing Resource Groups with Runaway Query Control\nDESCRIPTION: Experimental feature that allows fine-grained management of query timeout and resource allocation, enabling deprioritization or termination of queries exceeding specified thresholds\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.2.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n-- Resource group configuration for managing runaway queries\nCREATE RESOURCE GROUP IF NOT EXISTS 'high_priority_group'\n    RU_PER_SEC = 1000\n    PRIORITY = HIGH\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Cluster Topology for Three AZs in Two Regions\nDESCRIPTION: YAML configuration file for deploying a TiDB cluster across three availability zones in two regions using TiUP. Includes global settings, server configurations, and component-specific deployment details.\nSOURCE: https://github.com/pingcap/docs/blob/master/three-data-centers-in-two-cities-deployment.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# # Global variables are applied to all deployments and used as the default value of\n# # the deployments if a specific deployment value is missing.\nglobal:\n  user: \"tidb\"\n  ssh_port: 22\n  deploy_dir: \"/data/tidb_cluster/tidb-deploy\"\n  data_dir: \"/data/tidb_cluster/tidb-data\"\n\nserver_configs:\n  tikv:\n    server.grpc-compression-type: gzip\n  pd:\n    replication.location-labels: [\"az\",\"replication zone\",\"rack\",\"host\"]\n\npd_servers:\n  - host: 10.63.10.10\n    name: \"pd-10\"\n  - host: 10.63.10.11\n    name: \"pd-11\"\n  - host: 10.63.10.12\n    name: \"pd-12\"\n  - host: 10.63.10.13\n    name: \"pd-13\"\n  - host: 10.63.10.14\n    name: \"pd-14\"\n\ntidb_servers:\n  - host: 10.63.10.10\n  - host: 10.63.10.11\n  - host: 10.63.10.12\n  - host: 10.63.10.13\n  - host: 10.63.10.14\n\ntikv_servers:\n  - host: 10.63.10.30\n    config:\n      server.labels: { az: \"1\", replication zone: \"1\", rack: \"1\", host: \"30\" }\n  - host: 10.63.10.31\n    config:\n      server.labels: { az: \"1\", replication zone: \"2\", rack: \"2\", host: \"31\" }\n  - host: 10.63.10.32\n    config:\n      server.labels: { az: \"2\", replication zone: \"3\", rack: \"3\", host: \"32\" }\n  - host: 10.63.10.33\n    config:\n      server.labels: { az: \"2\", replication zone: \"4\", rack: \"4\", host: \"33\" }\n  - host: 10.63.10.34\n    config:\n      server.labels: { az: \"3\", replication zone: \"5\", rack: \"5\", host: \"34\" }\n      raftstore.raft-min-election-timeout-ticks: 50\n      raftstore.raft-max-election-timeout-ticks: 60\n\nmonitoring_servers:\n  - host: 10.63.10.60\n\ngrafana_servers:\n  - host: 10.63.10.60\n\nalertmanager_servers:\n  - host: 10.63.10.60\n```\n\n----------------------------------------\n\nTITLE: Querying Imported Data using SQL\nDESCRIPTION: Connects to the MySQL server using the command-line client and executes a `SELECT` statement to retrieve all rows from the `example.t` table. This is used to verify the imported data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n\"$ mysql -u root -h 127.0.0.1 -P 4000 -e 'select * from example.t'\\n+---+-----+\\n| a | b   |\\n+---+-----+\\n| 1 | one |\\n| 2 | two |\\n+---+-----+\"\n```\n\n----------------------------------------\n\nTITLE: Modified Placement Rules for Read-Only Nodes as Learners\nDESCRIPTION: This JSON configuration adds a new rule for read-only nodes. It specifies that one replica of data should be stored as a learner on nodes with the label '$mode: readonly'. This allows read-only access without voting rights.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/readonly-nodes.md#2025-04-18_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"group_id\": \"pd\",\n    \"group_index\": 0,\n    \"group_override\": false,\n    \"rules\": [\n      {\n        \"group_id\": \"pd\",\n        \"id\": \"default\",\n        \"start_key\": \"\",\n        \"end_key\": \"\",\n        \"role\": \"voter\",\n        \"count\": 3\n      },\n      {\n        \"group_id\": \"pd\",\n        \"id\": \"readonly\",\n        \"start_key\": \"\",\n        \"end_key\": \"\",\n        \"role\": \"learner\",\n        \"count\": 1,\n        \"label_constraints\": [\n          {\n            \"key\": \"$mode\",\n            \"op\": \"in\",\n            \"values\": [\n              \"readonly\"\n            ]\n          }\n        ],\n        \"version\": 1\n      }\n    ]\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Starting TiDB Cluster with Standard Start\nDESCRIPTION: Starts a TiDB cluster named 'tidb-test' using the standard start method, which allows root login without password.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster start tidb-test\n```\n\n----------------------------------------\n\nTITLE: Setting Cluster Version in PD\nDESCRIPTION: Sets the version of the cluster to 8.5.1. This controls feature enablement and compatibility handling across the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nconfig set cluster-version 8.5.1\n```\n\n----------------------------------------\n\nTITLE: Truncating Partitions in SQL\nDESCRIPTION: SQL statements to truncate (remove all data from) specific partitions in RANGE and LIST partitioned tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_37\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE members TRUNCATE PARTITION p1980;\n\nALTER TABLE member_level TRUNCATE PARTITION l4;\n```\n\n----------------------------------------\n\nTITLE: Deploy with Custom Binary\nDESCRIPTION: Command to deploy TiDB using a custom binary file instead of the official binary.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground --db.binpath /xx/tidb-server\n```\n\n----------------------------------------\n\nTITLE: Selecting Data From a Table in SQL\nDESCRIPTION: This SQL snippet shows how to select all rows and columns from the table 't'. It is used to verify the results of the non-transactional DELETE statement executed in the previous example. The output shows the remaining data in the table after the deletion operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n\"SELECT * FROM t;\"\n```\n\nLANGUAGE: sql\nCODE:\n```\n\"+----+---+\\n| id | v |\\n+----+---+\\n| 5  | 6 |\\n+----+---+\\n1 row in set\"\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP Package Manager\nDESCRIPTION: This command installs the TiUP tool, which is used to manage TiDB components including DM.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup-offline.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Showing Current Traffic Jobs Status - SQL\nDESCRIPTION: This SQL command retrieves the status of current traffic jobs, indicating progress and failure reasons. It is essential for monitoring active capture and replay jobs.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-traffic-replay.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TRAFFIC JOBS\n```\n\n----------------------------------------\n\nTITLE: Querying DDL Owner Information in TiDB\nDESCRIPTION: SQL command to view the current DDL owner information in a TiDB cluster, showing schema version, owner ID, address, running jobs, and self ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/ddl-introduction.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW DDL;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+------------+--------------------------------------+---------------+--------------+--------------------------------------+-------+\n| SCHEMA_VER | OWNER_ID                             | OWNER_ADDRESS | RUNNING_JOBS | SELF_ID                              | QUERY |\n+------------+--------------------------------------+---------------+--------------+--------------------------------------+-------+\n|         26 | 2d1982af-fa63-43ad-a3d5-73710683cc63 | 0.0.0.0:4000  |              | 2d1982af-fa63-43ad-a3d5-73710683cc63 |       |\n+------------+--------------------------------------+---------------+--------------+--------------------------------------+-------+\n```\n\n----------------------------------------\n\nTITLE: Query Task Status After DDL Error Handling\nDESCRIPTION: This bash command retrieves the status of the specified migration task, allowing users to monitor the success of the migration process after errors have been handled.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n» query-status test\n```\n\n----------------------------------------\n\nTITLE: Calibrate Resource with Start Time and Duration\nDESCRIPTION: SQL example showing how to calibrate resource with a specific start time and duration window of 20 minutes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-calibrate-resource.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCALIBRATE RESOURCE START_TIME '2023-04-18 08:00:00' DURATION '20m';\n```\n\n----------------------------------------\n\nTITLE: Resolving View Column Reference in TiDB\nDESCRIPTION: Fixes the 'Unknown column' error when using a view that is not in the current schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_15\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM view_name WHERE column_name = value\n```\n\n----------------------------------------\n\nTITLE: Viewing Table Next Row ID Details\nDESCRIPTION: Shows the details of special columns in a table, specifically focusing on the next available row ID and auto-increment values.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW t NEXT_ROW_ID;\n```\n\n----------------------------------------\n\nTITLE: Starting HAProxy from Command Line in Bash\nDESCRIPTION: Command for starting HAProxy with a specified configuration file. By default, HAProxy reads from /etc/haproxy/haproxy.cfg.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/haproxy-best-practices.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nhaproxy -f /etc/haproxy/haproxy.cfg\n```\n\n----------------------------------------\n\nTITLE: Starting the Next.js Application\nDESCRIPTION: Command to start the Next.js application in development mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nextjs.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Using SETVAL Function with Sequence\nDESCRIPTION: Illustrates the use of the SETVAL() function to set the current value of a sequence object.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-sequence.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SETVAL(seq, 10);\n```\n\n----------------------------------------\n\nTITLE: Scale-Out Configuration for TiCDC Servers\nDESCRIPTION: This configuration adds TiCDC node information to the `scale-out.yml` file, including host IP, GC TTL, and data directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_14\n\nLANGUAGE: ini\nCODE:\n```\n\"cdc_servers:\\n  - host: 10.0.1.3\\n    gc-ttl: 86400\\n    data_dir: /tidb-data/cdc-8300\\n  - host: 10.0.1.4\\n    gc-ttl: 86400\\n    data_dir: /tidb-data/cdc-8300\"\n```\n\n----------------------------------------\n\nTITLE: TiCDC Command-line Client Certificate Configuration\nDESCRIPTION: Specify client certificates for TiCDC command-line tool using command-line parameters, environment variables, or shared credentials file.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-client-authentication.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncdc cli changefeed list --cert client.crt --key client.key --ca ca.crt\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport TICDC_CERT_PATH=client.crt\nexport TICDC_KEY_PATH=client.key\nexport TICDC_CA_PATH=ca.crt\n```\n\n----------------------------------------\n\nTITLE: Setting TiDB Snapshot for Historical Data Retrieval\nDESCRIPTION: Shows how to set the `tidb_snapshot` system variable to read data from a specific point in time using timestamp or datetime\nSOURCE: https://github.com/pingcap/docs/blob/master/read-historical-data.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_snapshot=\"2016-10-08 16:45:26\";\n```\n\n----------------------------------------\n\nTITLE: Correcting Time String Parsing in TiDB\nDESCRIPTION: Addresses incompatibility with MySQL in parsing time strings.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_16\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT CAST('2020-01-01 12:00:00' AS DATETIME)\n```\n\n----------------------------------------\n\nTITLE: Markdown Release Notes Headers\nDESCRIPTION: Release notes header section containing version information and release date\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.4.1.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# TiDB 5.4.1 Release Notes\n\nRelease Date: May 13, 2022\n\nTiDB version: 5.4.1\n```\n\n----------------------------------------\n\nTITLE: Cancelling Current Traffic Jobs - SQL\nDESCRIPTION: This SQL command cancels active traffic capture or replay jobs. It requires appropriate permissions based on the user's role.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-traffic-replay.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCANCEL TRAFFIC JOBS\n```\n\n----------------------------------------\n\nTITLE: EBNF Grammar Definition for DROP PLACEMENT POLICY\nDESCRIPTION: Formal EBNF syntax definition for the DROP PLACEMENT POLICY statement, showing the grammar rules for dropping a placement policy and policy name specification.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-placement-policy.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDropPolicyStmt ::=\n    \"DROP\" \"PLACEMENT\" \"POLICY\" IfExists PolicyName\n\nPolicyName ::=\n    Identifier\n```\n\n----------------------------------------\n\nTITLE: Upgrading BR using TiUP in TiDB\nDESCRIPTION: Command for upgrading the BR (Backup & Restore) tool to version 8.5.0 using TiUP package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-use-cases.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup update br:v8.5.0\n```\n\n----------------------------------------\n\nTITLE: Executing GET Request with Pagination in TiDB Cloud Data Service\nDESCRIPTION: This snippet demonstrates how to make a GET request to a TiDB Cloud Data Service endpoint with pagination enabled, specifying page number and page size as query parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/release-notes-2023.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user '<Public Key>:<Private Key>' \\\n  --request GET 'https://<region>.data.tidbcloud.com/api/v1beta/app/<App ID>/endpoint/<Endpoint Path>?page=2&page_size=10'\n```\n\n----------------------------------------\n\nTITLE: String Pattern Validation\nDESCRIPTION: SQL query demonstrating string pattern matching validation\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-validate.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SCHEMA_VALID('{\"type\": \"string\", \"pattern\": \"^Ti\"}', '\"TiDB\"')\n```\n\n----------------------------------------\n\nTITLE: Creating New Prometheus Package\nDESCRIPTION: Commands to create a new Prometheus package for TiUP by compressing the modified files\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-monitoring-services.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd prometheus-v{version}-linux-amd64\ntar -zcvf ../prometheus-v{new-version}.tar.gz ./\n```\n\n----------------------------------------\n\nTITLE: Managing Indexes in TiDB\nDESCRIPTION: Commands for creating, displaying, and dropping indexes on tables, including regular and unique indexes using both CREATE INDEX and ALTER TABLE syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/basic-sql-operations.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX person_id ON person (id);\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE person ADD INDEX person_id (id);\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE UNIQUE INDEX person_unique_id ON person (id);\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE person ADD UNIQUE person_unique_id (id);\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW INDEX FROM person;\n```\n\nLANGUAGE: sql\nCODE:\n```\nDROP INDEX person_id ON person;\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE person DROP INDEX person_unique_id;\n```\n\n----------------------------------------\n\nTITLE: Displaying TiUP Mirror Directory Structure\nDESCRIPTION: Shows the typical directory structure of a TiUP mirror, including the root directory, component files, metadata, and key storage locations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror-reference.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n+ <mirror-dir>                                  # Mirror's root directory\n|-- root.json                                   # Mirror's root certificate\n|-- {2..N}.root.json                            # Mirror's root certificate\n|-- {1..N}.index.json                           # Component/user index\n|-- {1..N}.{component}.json                     # Component metadata\n|-- {component}-{version}-{os}-{arch}.tar.gz    # Component binary package\n|-- snapshot.json                               # Mirror's latest snapshot\n|-- timestamp.json                              # Mirror's latest timestamp\n|--+ commits                                    # Mirror's update log (deletable)\n   |--+ commit-{ts1..tsN}\n      |-- {N}.root.json\n      |-- {N}.{component}.json\n      |-- {N}.index.json\n      |-- {component}-{version}-{os}-{arch}.tar.gz\n      |-- snapshot.json\n      |-- timestamp.json\n|--+ keys                                       # Mirror's private key (can be moved to other locations)\n   |-- {hash1..hashN}-root.json                 # Private key of the root certificate\n   |-- {hash}-index.json                        # Private key of the indexes\n   |-- {hash}-snapshot.json                     # Private key of the snapshots\n   |-- {hash}-timestamp.json                    # Private key of the timestamps\n```\n\n----------------------------------------\n\nTITLE: Defining CHANGE COLUMN Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the CHANGE COLUMN statement in TiDB SQL, including AlterTableStmt, ChangeColumnSpec, ColumnType, ColumnOption, and ColumnName.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-change-column.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nAlterTableStmt\n         ::= 'ALTER' 'IGNORE'? 'TABLE' TableName ChangeColumnSpec ( ',' ChangeColumnSpec )*\n\nChangeColumnSpec\n         ::= 'CHANGE' ColumnKeywordOpt 'IF EXISTS' ColumnName ColumnName ColumnType ColumnOption* ( 'FIRST' | 'AFTER' ColumnName )?\n\nColumnType\n         ::= NumericType\n           | StringType\n           | DateAndTimeType\n           | 'SERIAL'\n\nColumnOption\n         ::= 'NOT'? 'NULL'\n           | 'AUTO_INCREMENT'\n           | 'PRIMARY'? 'KEY' ( 'CLUSTERED' | 'NONCLUSTERED' )?\n           | 'UNIQUE' 'KEY'?\n           | 'DEFAULT' ( NowSymOptionFraction | SignedLiteral | NextValueForSequence )\n           | 'SERIAL' 'DEFAULT' 'VALUE'\n           | 'ON' 'UPDATE' NowSymOptionFraction\n           | 'COMMENT' stringLit\n           | ( 'CONSTRAINT' Identifier? )? 'CHECK' '(' Expression ')' ( 'NOT'? ( 'ENFORCED' | 'NULL' ) )?\n           | 'GENERATED' 'ALWAYS' 'AS' '(' Expression ')' ( 'VIRTUAL' | 'STORED' )?\n           | 'REFERENCES' TableName ( '(' IndexPartSpecificationList ')' )? Match? OnDeleteUpdateOpt\n           | 'COLLATE' CollationName\n           | 'COLUMN_FORMAT' ColumnFormat\n           | 'STORAGE' StorageMedia\n           | 'AUTO_RANDOM' ( '(' LengthNum ')' )?\n\nColumnName ::=\n    Identifier ( '.' Identifier ( '.' Identifier )? )?\n```\n\n----------------------------------------\n\nTITLE: Creating Changefeed from Downstream to Upstream\nDESCRIPTION: This shell command creates a changefeed in the opposite direction from downstream to upstream to ensure any new data written to the downstream during the migration period is captured.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc cli changefeed create --server=http://172.16.6.125:8300 --sink-uri=\"mysql://root:@172.16.6.122:4000\" --changefeed-id=\"downstream-to-upstream\"\n\n```\n\n----------------------------------------\n\nTITLE: Creating Database in SQL Server - Shell\nDESCRIPTION: Connects to an SQL Server instance using `sqlcmd` and creates a new database named `tpcc`. Assigns connection details and runs SQL commands through a shell.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\n[ec2-user@ip-172-1-1-1 bin]$ sqlcmd -S 10.61.43.14,1433 -U admin\nPassword:\n1> create database tpcc\n2> go\n1> select name from master.dbo.sysdatabases\n2> go\nname\n----------------------------------------------------------------------\nmaster\ntempdb\nmodel\nmsdb\nrdsadmin\ntpcc\n(6 rows affected)\n```\n\n----------------------------------------\n\nTITLE: Verifying Index Recovery in SQL\nDESCRIPTION: This SQL snippet demonstrates how to verify the successful recovery of index data using the ADMIN CHECK INDEX statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-recover.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN CHECK INDEX tbl idx;\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: TIDB_HOT_REGIONS Table Structure Output in SQL\nDESCRIPTION: This snippet shows the output of the DESC command on the TIDB_HOT_REGIONS table. It lists all columns in the table along with their data types, null constraints, key information, and default values.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-hot-regions.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+----------------+-------------+------+------+---------+-------+\n| Field          | Type        | Null | Key  | Default | Extra |\n+----------------+-------------+------+------+---------+-------+\n| TABLE_ID       | bigint(21)  | YES  |      | NULL    |       |\n| INDEX_ID       | bigint(21)  | YES  |      | NULL    |       |\n| DB_NAME        | varchar(64) | YES  |      | NULL    |       |\n| TABLE_NAME     | varchar(64) | YES  |      | NULL    |       |\n| INDEX_NAME     | varchar(64) | YES  |      | NULL    |       |\n| REGION_ID      | bigint(21)  | YES  |      | NULL    |       |\n| TYPE           | varchar(64) | YES  |      | NULL    |       |\n| MAX_HOT_DEGREE | bigint(21)  | YES  |      | NULL    |       |\n| REGION_COUNT   | bigint(21)  | YES  |      | NULL    |       |\n| FLOW_BYTES     | bigint(21)  | YES  |      | NULL    |       |\n+----------------+-------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Azure Blob Storage Restore Command\nDESCRIPTION: Command for restoring a specific database from Azure Blob Storage using BR with account credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore db --db test -u \"${PD_IP}:2379\" \\\n--storage \"azure://external/backup-20220915account-name=${account-name}&account-key=${account-key}\"\n```\n\n----------------------------------------\n\nTITLE: SET DEFAULT ROLE Syntax Definition - EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the SET DEFAULT ROLE statement in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-default-role.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nSetDefaultRoleStmt ::=\n    \"SET\" \"DEFAULT\" \"ROLE\" ( \"NONE\" | \"ALL\" | Rolename (\",\" Rolename)* ) \"TO\" Username (\",\" Username)*\n```\n\n----------------------------------------\n\nTITLE: Adding TiKV Configuration: track-and-verify-wals-in-manifest\nDESCRIPTION: Adds a new TiKV configuration item named `track-and-verify-wals-in-manifest` for RocksDB. This configuration helps to investigate possible corruption of Write Ahead Log (WAL).\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.5.9.md#2025-04-18_snippet_0\n\nLANGUAGE: N/A\nCODE:\n```\nAdd a TiKV configuration item [`track-and-verify-wals-in-manifest`](https://docs.pingcap.com/tidb/v6.5/tikv-configuration-file#track-and-verify-wals-in-manifest-new-in-v659) for RocksDB, which helps you investigate possible corruption of Write Ahead Log (WAL) [#16549](https://github.com/tikv/tikv/issues/16549) @[v01dstar](https://github.com/v01dstar)\n```\n\n----------------------------------------\n\nTITLE: Filtering data with pattern matching in Dumpling\nDESCRIPTION: Uses the --filter option to selectively export tables matching specified patterns, similar to .gitignore syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup dumpling -u root -P 4000 -h 127.0.0.1 -o /tmp/test -r 200000 --filter \"employees.*\" --filter \"*.WorkOrder\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for TiDB Cloud Connection in Shell\nDESCRIPTION: Commands for setting the DATABASE_URL environment variable in both local and Netlify environments to enable database connectivity.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n# set the environment variable for your own space\nexport DATABASE_URL='mysql://<User>:<Password>@<Endpoint>:<Port>/<Database>?sslaccept=strict'\n\n# set the environment variable for the Netlify space\nnetlify env:set DATABASE_URL 'mysql://<User>:<Password>@<Endpoint>:<Port>/<Database>?sslaccept=strict'\n```\n\n----------------------------------------\n\nTITLE: MEDIUMINT Type Declaration in SQL\nDESCRIPTION: Syntax for declaring MEDIUMINT type with optional display width, unsigned flag and zero-fill option\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-numeric.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nMEDIUMINT[(M)] [UNSIGNED] [ZEROFILL]\n```\n\n----------------------------------------\n\nTITLE: Configuring PD Leader Rejection Rules\nDESCRIPTION: Configuration to prevent remote TiKV Raft replicas from being elected as Leader.\nSOURCE: https://github.com/pingcap/docs/blob/master/geo-distributed-deployment-topology.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nlabel-property:\n      reject-leader:\n        - key: \"dc\"\n          value: \"sha\"\n```\n\n----------------------------------------\n\nTITLE: Counting Affected Rows (SQL)\nDESCRIPTION: The `ROW_COUNT()` function returns the number of rows affected by the last executed statement, facilitating feedback on data manipulation operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/information-functions.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1(id BIGINT UNSIGNED PRIMARY KEY AUTO_RANDOM);\nQuery OK, 0 rows affected, 1 warning (0.16 sec)\n\nINSERT INTO t1() VALUES (),(),();\nQuery OK, 3 rows affected (0.02 sec)\n\nSELECT ROW_COUNT();\n```\n+-------------+\n| ROW_COUNT() |\n+-------------+\n|           3 |\n+-------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Bug Fix - TiDB Query Processing\nDESCRIPTION: Multiple fixes for query processing issues including hex literal handling, collation issues for Enum/Set types, nullif expression behavior, and auto-analysis timing.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.12.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nget /* Fixed hexadecimal literals handling */\nCAST /* Fixed error handling for point get plan */\nNULLIF /* Fixed with is-null usage */\nENUM /* Fixed collation for fast execution */\nSET /* Fixed collation for fast execution */\n```\n\n----------------------------------------\n\nTITLE: Configuring Output Filename Templates in Dumpling\nDESCRIPTION: Examples of using Go templates to customize output filenames for Dumpling exports. Shows how to format index numbers with leading zeros and handle special characters in database and table names through the fn function.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_15\n\nLANGUAGE: golang\nCODE:\n```\n{{fn .Table}}.{{printf \"%09d\" .Index}}\n```\n\nLANGUAGE: golang\nCODE:\n```\n{{define \"table\"}}{{fn .Table}}.$schema{{end}}{{define \"data\"}}{{fn .Table}}.{{printf \"%09d\" .Index}}{{end}}\n```\n\n----------------------------------------\n\nTITLE: Adding Index to a Column in TiDB\nDESCRIPTION: This SQL command adds an index named 'c_idx' to the column 'c' in the table 'sbtest1'. This is the ADD INDEX operation being tested for its interaction with online workloads in the benchmark.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/online-workloads-and-add-index-operations.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nalter table sbtest1 add index c_idx(c)\n```\n\n----------------------------------------\n\nTITLE: Deploy Nightly TiDB Version\nDESCRIPTION: Command to deploy the latest development version of TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground nightly\n```\n\n----------------------------------------\n\nTITLE: GitHub Pull Request References in Release Notes\nDESCRIPTION: List of GitHub pull request references documenting various improvements and fixes across different components of TiDB ecosystem.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.1.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[#8574](https://github.com/pingcap/tidb/pull/8574)\n[#8606](https://github.com/pingcap/tidb/pull/8606)\n[#8652](https://github.com/pingcap/tidb/pull/8652)\n[#8649](https://github.com/pingcap/tidb/pull/8649)\n[#8628](https://github.com/pingcap/tidb/pull/8628)\n[#8660](https://github.com/pingcap/tidb/pull/8660)\n[#8567](https://github.com/pingcap/tidb/pull/8567)\n[#8576](https://github.com/pingcap/tidb/pull/8576)\n[#8638](https://github.com/pingcap/tidb/pull/8638)\n[#8590](https://github.com/pingcap/tidb/pull/8590)\n[#8614](https://github.com/pingcap/tidb/pull/8614)\n[#8611](https://github.com/pingcap/tidb/pull/8611)\n[#8655](https://github.com/pingcap/tidb/pull/8655)\n[#1334](https://github.com/pingcap/pd/pull/1334)\n[#1362](https://github.com/pingcap/pd/pull/1362)\n[#1339](https://github.com/pingcap/pd/pull/1339)\n[#1370](https://github.com/pingcap/pd/pull/1370)\n[#3878](https://github.com/tikv/tikv/pull/3878)\n```\n\n----------------------------------------\n\nTITLE: Inserting After TiDB Server Restart with Cache Loss\nDESCRIPTION: This snippet demonstrates how AUTO_INCREMENT cache doesn't persist across TiDB server restarts, leading to a new range being allocated and a jump in sequence values.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nmysql> INSERT INTO t (a) VALUES (NULL);\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> SELECT * FROM t ORDER BY b;\n+---------+---------------------+\n| a       | b                   |\n+---------+---------------------+\n|       1 | 2020-09-09 20:38:22 |\n|       2 | 2020-09-09 20:38:22 |\n|       3 | 2020-09-09 20:38:22 |\n| 2000001 | 2020-09-09 20:43:43 |\n|       4 | 2020-09-09 20:44:43 |\n| 2030001 | 2020-09-09 20:54:11 |\n+---------+---------------------+\n6 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating Downstream Table Schema\nDESCRIPTION: Defines the schema for a downstream table 'messages' with an additional 'message' column. This is contrasted with the upstream schema, highlighting the added column to address schema mismatch issues during data migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-with-more-columns-downstream.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n# Downstream table schema\nCREATE TABLE `messages` (\n  `id` int NOT NULL,\n  `message` varchar(255) DEFAULT NULL, # This is the additional column that only exists in the downstream table.\n  PRIMARY KEY (`id`)\n)\n```\n\n----------------------------------------\n\nTITLE: Pagination Syntax Differences\nDESCRIPTION: Illustrates how pagination is handled differently between Oracle using OFFSET and TiDB using LIMIT with OFFSET.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_31\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM tables OFFSET 0 ROWS FETCH NEXT 2000 ROWS ONLY\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM tables LIMIT 2000 OFFSET 0\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB\nDESCRIPTION: Connects to TiDB server using MySQL client with default root credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 10.0.1.1 -P 4000 -u root\n```\n\n----------------------------------------\n\nTITLE: Handling Isolation Level Error in TiDB\nDESCRIPTION: Example of how the tidb_skip_isolation_level_check variable affects the behavior when setting an unsupported isolation level. When disabled, attempting to set 'serializable' isolation level produces an error, but when enabled, the command succeeds with a warning.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_75\n\nLANGUAGE: sql\nCODE:\n```\ntidb> set tx_isolation='serializable';\nERROR 8048 (HY000): The isolation level 'serializable' is not supported. Set tidb_skip_isolation_level_check=1 to skip this error\ntidb> set tidb_skip_isolation_level_check=1;\nQuery OK, 0 rows affected (0.00 sec)\n\ntidb> set tx_isolation='serializable';\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a New Index in TiDB\nDESCRIPTION: This SQL command creates a new index on a specified column of a table. This is used to replace a potentially corrupted or inconsistent index.\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name ADD INDEX index_name (column_name);\n```\n\n----------------------------------------\n\nTITLE: Enabling auto-increment in generated columns in TiDB 5.2\nDESCRIPTION: Determines whether to include the AUTO_INCREMENT columns when creating a generated column or an expression index. The default value is OFF.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.2.0.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_enable_auto_increment_in_generated = OFF;\n```\n\n----------------------------------------\n\nTITLE: Batch UPDATE Statements Example\nDESCRIPTION: Shows how multiple UPDATE statements are combined when using batch updates with rewriteBatchedStatements=true enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nupdate t set a = 10 where id = 1; update t set a = 11 where id = 2; update t set a = 12 where id = 3;\n```\n\n----------------------------------------\n\nTITLE: Displaying DM Cluster Status\nDESCRIPTION: Command to show the status of a specific DM cluster, including instance details and running state.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm display dm-test\n```\n\n----------------------------------------\n\nTITLE: Correcting DROP INDEX Execution in TiDB SQL\nDESCRIPTION: Resolves a problem where the DROP INDEX statement failed to execute when the index column contained an auto-increment primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nDROP INDEX\n```\n\n----------------------------------------\n\nTITLE: Selecting All Data from a Partitioned Table in TiDB\nDESCRIPTION: This SQL query selects all data from a partitioned table in TiDB. It's used to show that TiDB returns results in an unordered manner across partitions, unlike MySQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_70\n\nLANGUAGE: SQL\nCODE:\n```\nselect * from t;\n```\n\n----------------------------------------\n\nTITLE: Configuring Downstream TiDB TLS in YAML\nDESCRIPTION: YAML configuration for enabling TLS encryption for connections to the downstream TiDB database.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-enable-tls.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\ntarget-database:\n    security:\n        ssl-ca: \"/path/to/tidb-ca.pem\"\n        ssl-cert: \"/path/to/tidb-client-cert.pem\"\n        ssl-key: \"/path/to/tidb-client-key.pem\"\n```\n\n----------------------------------------\n\nTITLE: Setting Public Key for Active Profile\nDESCRIPTION: This example demonstrates how to set the public key for the active user profile in the TiDB Cloud CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-set.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud config set public-key <public-key>\n```\n\n----------------------------------------\n\nTITLE: Basic String Literal Examples\nDESCRIPTION: Demonstrates basic string literal syntax using single and double quotes.\nSOURCE: https://github.com/pingcap/docs/blob/master/literal-values.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n'example string'\n\"example string\"\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying a Sequence in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a new sequence named 'seq' in the 'test' schema and then query its next value using the NEXTVAL function.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-sequences.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE SEQUENCE test.seq;\nSELECT NEXTVAL(test.seq);\nSELECT * FROM sequences\\G\n```\n\n----------------------------------------\n\nTITLE: Improving ONLY_FULL_GROUP_BY Check for Bracketed Expressions in TiDB\nDESCRIPTION: Enhances the ONLY_FULL_GROUP_BY mode to correctly check expressions with brackets.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_31\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT (complex_expression) FROM table GROUP BY column\n```\n\n----------------------------------------\n\nTITLE: Querying with TiFlash using EXPLAIN ANALYZE\nDESCRIPTION: This SQL snippet uses the `EXPLAIN ANALYZE` statement to examine the execution statistics of a query that automatically uses TiFlash (columnar storage) if available. The query calculates release year, game count, average price, and average playtime from the `games` table, grouped by release year. The statistics output helps determine TiFlash's performance for the specified query.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-htap-quickstart.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n    \"EXPLAIN ANALYZE SELECT\\n      YEAR(`release_date`) AS `release_year`,\\n      COUNT(*) AS `games_released`,\\n      AVG(`price`) AS `average_price`,\\n      AVG(`average_playtime_forever`) AS `average_playtime`\\n    FROM\\n      `games`\\n    GROUP BY\\n      `release_year`\\n    ORDER BY\\n      `release_year` DESC;\"\n```\n\n----------------------------------------\n\nTITLE: Setting Checksum Table Concurrency in TiDB\nDESCRIPTION: Sets the TiDB session variable to increase concurrency for checksum and ANALYZE operations. If 'checksum-via-sql' is true, the parameters 'distsql-scan-concurrency' and 'checksum-table-concurrency' will not affect the execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- Example: `2` -->\n```\n\n----------------------------------------\n\nTITLE: CustomContent Platform Tags Example\nDESCRIPTION: Example showing the use of CustomContent tags to specify documentation content for different platforms (TiDB vs TiDB Cloud).\nSOURCE: https://github.com/pingcap/docs/blob/master/CONTRIBUTING.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n<CustomContent platform=\"tidb\">\n\n</CustomContent>\n\n<CustomContent platform=\"tidb-cloud\">\n\n</CustomContent>\n```\n\n----------------------------------------\n\nTITLE: Using Reserved Keywords with Dot Delimiter in TiDB SQL\nDESCRIPTION: This snippet illustrates a special case where reserved keywords don't require backticks when used with the dot delimiter in TiDB SQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/keywords.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE test.select (BEGIN int, END int);\n```\n\n----------------------------------------\n\nTITLE: Retrieving Specific Range of DDL Job Queries (Using OFFSET Keyword)\nDESCRIPTION: This example shows how to retrieve rows 5-7 from the DDL job history using the LIMIT clause with the OFFSET keyword. This syntax clearly separates the offset and limit values.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_11\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW DDL JOB QUERIES LIMIT 3 OFFSET 4;  # Retrieve rows 5-7\n+--------+----------------------------------------+\n| JOB_ID | QUERY                                  |\n+--------+----------------------------------------+\n|     54 | DROP TABLE IF EXISTS t3                |\n|     53 | ALTER TABLE t1 DROP INDEX index1       |\n|     52 | ALTER TABLE t1 ADD INDEX index1 (col1) |\n+--------+----------------------------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Handling Physical Plan Error with Hints in TiDB\nDESCRIPTION: This SQL snippet demonstrates the occurrence of an error when using specific query hints that restrict available join methods, such as `NO_HASH_JOIN` and `NO_MERGE_JOIN`, in TiDB databases. To resolve such errors, it is important to review and modify the hints or enable necessary join methods.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_60\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t1 (a INT);\\nCREATE TABLE t2 (a INT);\\nEXPLAIN SELECT /*+ NO_HASH_JOIN(t1), NO_MERGE_JOIN(t1) */ * FROM t1, t2 WHERE t1.a=t2.a;\\nERROR 1815 (HY000): Internal : Can't find a proper physical plan for this query\n```\n\n----------------------------------------\n\nTITLE: Creating a Cloudflare Worker Project\nDESCRIPTION: Command to initialize a new Cloudflare Worker project named 'tidb-cloud-cloudflare' using Wrangler.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-cloudflare.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nwrangler init tidb-cloud-cloudflare\n```\n\n----------------------------------------\n\nTITLE: Checking Table Statistics\nDESCRIPTION: Shows statistics metadata for a partitioned table to verify partition-level statistics after enabling dynamic mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_72\n\nLANGUAGE: sql\nCODE:\n```\nset session tidb_partition_prune_mode = 'dynamic';\nshow stats_meta where table_name like \"t\";\n```\n\n----------------------------------------\n\nTITLE: Sample Output of SHOW STATS_HISTOGRAMS Execution\nDESCRIPTION: Demonstrates the output format of executing SHOW STATS_HISTOGRAMS in TiDB. This example shows columns such as Db_name, Table_name, and Correlation, with sample data illustrating statistics like distinct count and memory usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-histograms.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\n+---------+------------+----------------+-------------+----------+---------------------+----------------+------------+--------------+-------------+\\n| Db_name | Table_name | Partition_name | Column_name | Is_index | Update_time         | Distinct_count | Null_count | Avg_col_size | Correlation |\\n+---------+------------+----------------+-------------+----------+---------------------+----------------+------------+--------------+-------------+\\n| test    | t          |                | a           |        0 | 2020-05-25 19:20:00 |              7 |          0 |            1 |           1 |\\n| test    | t2         |                | a           |        0 | 2020-05-25 19:20:01 |              6 |          0 |            8 |           0 |\\n| test    | t2         |                | b           |        0 | 2020-05-25 19:20:01 |              6 |          0 |         1.67 |           1 |\\n+---------+------------+----------------+-------------+----------+---------------------+----------------+------------+--------------+-------------+\\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Multi-Disk Deployment for Older TiDB\nDESCRIPTION: Provides configuration parameters for setting up multi-disk deployment for TiDB versions earlier than v4.0.9, detailing paths for data storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_14\n\nLANGUAGE: TOML\nCODE:\n```\n\"path = \\\"/nvme_ssd_a/data/tiflash,/sata_ssd_b/data/tiflash,/sata_ssd_c/data/tiflash\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Defining ConsumerManager in Golang\nDESCRIPTION: This snippet defines the `ConsumerManager` struct responsible for handling tasks assigned to `TableConsumer` instances, managing checkpoints, and dispatching file processing tasks. It includes comments for understanding the purpose of each variable and method.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-storage-consumer-dev-guide.md#2025-04-18_snippet_1\n\nLANGUAGE: go\nCODE:\n```\ntype ConsumerManager struct {\n  // StorageCheckpoint is recorded in the metadata file, and it can be fetched by calling `StorageReader.ExposeNewFiles()`.  \n  // This checkpoint indicates that the data whose transaction commit time is less than this checkpoint has been stored in storage.\n  StorageCheckpoint int64\n  // This checkpoint indicates where the consumer has consumed.\n  // ConsumerManager periodically collects TableConsumer.Checkpoint,\n  // then Checkpoint is updated to the minimum value of all TableConsumer.Checkpoint.\n  Checkpoint int64\n\n  tableFiles[schema][table]*TableConsumer\n}\n\n// Query newly added files from StorageReader.\n// For a newly created table, create a TableConsumer for it.\n// If any, send new files to the corresponding TableConsumer.\nfunc (c *ConsumerManager) Dispatch() {}\n```\n\n----------------------------------------\n\nTITLE: Invalid LEADING Hint Example\nDESCRIPTION: Demonstrates an invalid use of multiple LEADING hints in a single query, which generates a warning.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_38\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ LEADING(t1, t2) LEADING(t3) */ * FROM t1, t2, t3 WHERE t1.id = t2.id and t2.id = t3.id;\n\nSHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: Calculating Password Hash in SQL\nDESCRIPTION: The `PASSWORD(str)` function generates a deprecated password hash for usage with the `mysql_native_password` authentication method. It is not recommended for future use.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT PASSWORD('secret');\n```\n\n----------------------------------------\n\nTITLE: Configuring Concurrency for Statistics Collection\nDESCRIPTION: These SQL statements configure the concurrency settings for statistics collection in TiDB. Adjusting these settings can accelerate the statistics collection process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_build_stats_concurrency=16;\nSET tidb_distsql_scan_concurrency=16;\nSET tidb_index_serial_scan_concurrency=16;\n```\n\n----------------------------------------\n\nTITLE: Configuring sync-diff-inspector in TOML\nDESCRIPTION: This TOML configuration file sets up the data sources and task parameters for sync-diff-inspector to compare data between upstream and downstream clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-mysql.md#2025-04-18_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n[data-sources]\n[data-sources.upstream]\n        host = \"127.0.0.1\"\n        port = 4000\n        user = \"root\"\n        password = \"\"\n        snapshot = \"434217889191428107\"\n[data-sources.downstream]\n        host = \"127.0.0.1\"\n        port = 3306\n        user = \"root\"\n        password = \"\"\n[task]\n        output-dir = \"./output\"\n        source-instances = [\"upstream\"]\n        target-instance = \"downstream\"\n        target-check-tables = [\"*.*\"]\n```\n\n----------------------------------------\n\nTITLE: Default Placement Rules Configuration\nDESCRIPTION: Default JSON configuration for placement rules with basic voter setup that can be used for rollback.\nSOURCE: https://github.com/pingcap/docs/blob/master/two-data-centers-in-one-city-deployment.md#2025-04-18_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"group_id\": \"pd\",\n    \"group_index\": 0,\n    \"group_override\": false,\n    \"rules\": [\n      {\n        \"group_id\": \"pd\",\n        \"id\": \"default\",\n        \"start_key\": \"\",\n        \"end_key\": \"\",\n        \"role\": \"voter\",\n        \"count\": 5\n      }\n    ]\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Aliased Command for Deleting User Profiles\nDESCRIPTION: An alias for deleting a user profile in TiCloud CLI, which serves as a shorthand for the main delete command. This alias simplifies the command input for users who prefer a shorter notation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-delete.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud config rm <profile-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Backup and Restore Data between TiDB Clusters using BR\nDESCRIPTION: Commands to back up full data from the secondary cluster and restore it to the newly deployed primary cluster using BR (Backup & Restore) tool. The backup is stored in a local ./backup directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\n# Back up full data of the secondary cluster\ntiup br --pd http://172.16.6.124:2379 backup full --storage ./backup\n# Restore full data of the secondary cluster\ntiup br --pd http://172.16.6.123:2379 restore full --storage ./backup\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB using MySQL Client\nDESCRIPTION: Command to connect to TiDB server using MySQL client with basic authentication parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connect-to-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmysql --host <tidb_server_host> --port 4000 -u root -p --comments\n```\n\n----------------------------------------\n\nTITLE: Setting Global Password Reuse Policy in SQL\nDESCRIPTION: SQL commands to establish a global password reuse policy that prohibits reusing the last 6 passwords and any passwords used within the last 365 days.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_21\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL password_history = 6;\nSET GLOBAL password_reuse_interval = 365;\n```\n\n----------------------------------------\n\nTITLE: Configuring Checksum Behavior in TiDB\nDESCRIPTION: Specifies whether to conduct ADMIN CHECKSUM TABLE for data integrity verification after importing, with options for required, optional, or disabled checks.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_21\n\nLANGUAGE: markdown\nCODE:\n```\nValue options:\n    - \"required\": Perform admin checksum. If checksum fails, TiDB Lightning will exit with failure.\n    - \"optional\": Perform admin checksum. If checksum fails, TiDB Lightning will report a WARN log but ignore any error.\n    - \"off\": Do not perform checksum.\n```\n\n----------------------------------------\n\nTITLE: Enabling Partition Selection Algorithm for Hash Partitioned Tables in TiDB\nDESCRIPTION: Addresses an issue where the partition selection algorithm was not taking effect on hash partitioned tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_24\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM hash_partitioned_table WHERE partition_column = value\n```\n\n----------------------------------------\n\nTITLE: Retrieving Migration Targets for a Task and Source (Shell)\nDESCRIPTION: This snippet demonstrates how to use cURL to retrieve migration targets for a specific task and source. It sends a GET request to the API endpoint and expects a JSON response with migration target details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_38\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1/sources/source-1/migrate_targets' \\\n  -H 'accept: application/json'\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"total\": 0,\n  \"data\": [\n    {\n      \"source_schema\": \"db1\",\n      \"source_table\": \"tb1\",\n      \"target_schema\": \"db1\",\n      \"target_table\": \"tb1\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Showing Statistics Health in TiDB\nDESCRIPTION: This SQL statement displays the statistics health of tables in a TiDB database. The `Healthy` column indicates how close the statistics are to the `tidb_auto_analyze_ratio` threshold.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-walkthrough.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n\"SHOW STATS_HEALTHY;\"\n```\n\n----------------------------------------\n\nTITLE: Updating Index Types When Partitioning in SQL\nDESCRIPTION: This SQL snippet demonstrates how to update index types (global or local) when partitioning a non-partitioned table or repartitioning an already partitioned table.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_48\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    UNIQUE KEY uidx12(col1, col2),\n    UNIQUE KEY uidx3(col3)\n);\n\nALTER TABLE t1 PARTITION BY HASH (col1) PARTITIONS 3 UPDATE INDEXES (uidx12 LOCAL, uidx3 GLOBAL);\n```\n\n----------------------------------------\n\nTITLE: List Available TiDB Versions\nDESCRIPTION: Command to check available TiDB versions that can be deployed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup list tidb\n```\n\n----------------------------------------\n\nTITLE: Setting TiDB PROXY Protocol Networks Configuration\nDESCRIPTION: Examples of valid formats for configuring the proxy-protocol-networks option in TiDB, which specifies IP addresses allowed to connect using the PROXY protocol.\nSOURCE: https://github.com/pingcap/docs/blob/master/command-line-flags-for-tidb-configuration.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n192.168.1.50         # Single IP address\n192.168.1.0/24        # CIDR notation\n192.168.1.50,192.168.1.0/24  # Multiple values separated by commas\n*                    # All IP addresses (use with caution)\n```\n\n----------------------------------------\n\nTITLE: Setting Session Variables for Metric Querying in TiDB - SQL\nDESCRIPTION: This SQL snippet sets session variables for TiDB to adjust the time granularity for metric queries. The granularity is set to 30 seconds, which is the minimum supported by Prometheus.\nSOURCE: https://github.com/pingcap/docs/blob/master/metrics-schema.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_metric_query_step=30;\nset @@tidb_metric_query_range_duration=30;\n```\n\n----------------------------------------\n\nTITLE: Identifying System-Versioned Tables in MariaDB\nDESCRIPTION: SQL query to find system-versioned tables in MariaDB, which are not supported in TiDB. This helps identify tables that need special handling during migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-mariadb.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n  TABLE_SCHEMA,\n  TABLE_NAME\nFROM\n  information_schema.tables\nWHERE\n  TABLE_TYPE='SYSTEM VERSIONED';\n```\n\n----------------------------------------\n\nTITLE: Creating User, Resource Groups, and Binding in TiDB SQL\nDESCRIPTION: This snippet demonstrates creating a user, creating resource groups, and binding the user to a resource group in TiDB. It showcases the use of CREATE USER, CREATE RESOURCE GROUP, and ALTER USER statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'user1';\nCREATE RESOURCE GROUP rg1 RU_PER_SEC = 1000;\nCREATE RESOURCE GROUP rg2 RU_PER_SEC = 2000;\nALTER USER 'user1' RESOURCE GROUP `rg1`;\n```\n\n----------------------------------------\n\nTITLE: Converting Thread ID to Hexadecimal\nDESCRIPTION: Command to convert a process ID to hexadecimal format for matching against jstack output.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nprintf \"%x\\n\" pid\n```\n\n----------------------------------------\n\nTITLE: Setting Up Encryption at Rest in TiKV YAML\nDESCRIPTION: YAML configuration for TiKV encryption at rest, including encryption method, key rotation, and master key settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_27\n\nLANGUAGE: yaml\nCODE:\n```\nsecurity.encryption:\n  data-encryption-method: \"plaintext\"\n  data-key-rotation-period: 7d\n  enable-file-dictionary-log: true\n  master-key: \"\"\n  previous-master-key: \"\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Specific Range of DDL Job Queries Example (LIMIT with Offset)\nDESCRIPTION: This example demonstrates how to retrieve rows 7-8 from the DDL job history using the LIMIT clause with an offset. It allows accessing specific portions of the job history.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW DDL JOB QUERIES LIMIT 6, 2;  # Retrieve rows 7-8\n+--------+----------------------------------------------------------------------------+\n| JOB_ID | QUERY                                                                      |\n+--------+----------------------------------------------------------------------------+\n|     52 | ALTER TABLE t1 ADD INDEX index1 (col1)                                     |\n|     51 | CREATE TABLE IF NOT EXISTS t1 (id INT NOT NULL PRIMARY KEY auto_increment) |\n+--------+----------------------------------------------------------------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Enabling Relay-Log for Data Source with cURL in Shell\nDESCRIPTION: This example demonstrates how to enable the relay-log feature for a data source. The request specifies worker assignments, relay binlog name, GTID, and directory for storing relay logs.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'POST' \\\n  'http://127.0.0.1:8261/api/v1/sources/mysql-01/relay/enable' \\\n  -H 'accept: */*' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"worker_name_list\": [\n    \"worker-1\"\n  ],\n  \"relay_binlog_name\": \"mysql-bin.000002\",\n  \"relay_binlog_gtid\": \"e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849\",\n  \"relay_dir\": \"./relay_log\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Enabling Auto Analyze Priority Queue in TiDB\nDESCRIPTION: This code demonstrates the system variable for enabling the priority queue for auto analyze operations, which improves stability when dealing with a massive number of tables in multi-tenant applications.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\ntidb_enable_auto_analyze_priority_queue\n```\n\n----------------------------------------\n\nTITLE: Encrypting Log Backup with AWS KMS in Shell\nDESCRIPTION: Example of starting a log backup task with encryption using a master key managed by AWS Key Management Service (KMS).\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log start \\\n    --task-name=pitr-with-encryption \\\n    --pd ${PD_IP}:2379 \\\n    --storage \"s3://${BACKUP_COLLECTION_ADDR}/snapshot-${DATE}?access-key=${AWS_ACCESS_KEY}&secret-access-key=${AWS_SECRET_ACCESS_KEY}\" \\\n    --master-key-crypter-method aes128-ctr \\\n    --master-key \"aws-kms:///${AWS_KMS_KEY_ID}?AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY}&AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}&REGION=${AWS_REGION}\"\n```\n\n----------------------------------------\n\nTITLE: Stopping a Data Migration Task in DM\nDESCRIPTION: This command demonstrates how to stop a data migration task named 'task-name', optionally specifying a MySQL source 'mysql-replica-01'.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-stop-task.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nstop-task [-s \"mysql-replica-01\"]  task-name\n```\n\n----------------------------------------\n\nTITLE: Creating TiCDC Changefeed with CSV Protocol in Shell\nDESCRIPTION: This command creates a TiCDC changefeed using the CSV protocol to send data to an S3 bucket. It specifies the server, changefeed ID, sink URI, and configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-csv.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://127.0.0.1:8300 --changefeed-id=\"csv-test\" --sink-uri=\"s3://bucket/prefix\" --config changefeed.toml\n```\n\n----------------------------------------\n\nTITLE: Calling a Deployed Endpoint with Digest Authentication in TiDB Cloud Data Service\nDESCRIPTION: This curl command demonstrates how to call a deployed (online) version of an endpoint using Digest Authentication. It shows the proper structure for authentication and the JSON payload format for batch operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-manage-endpoint.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user '<Public Key>:<Private Key>' \\\n --request POST 'https://<region>.data.tidbcloud.com/api/v1beta/app/<App ID>/endpoint/<Endpoint Path>' \\\n --header 'content-type: application/json'\\\n --data-raw '{\n  \"items\": [\n    {\n      \"age\": \"${age}\",\n      \"career\": \"${career}\"\n    }\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Setting Broadcast Join Threshold Size in TiDB\nDESCRIPTION: Sets the threshold size in bytes for using Broadcast Hash Join algorithm. If a table is smaller than this value, TiDB will use Broadcast Hash Join instead of Shuffled Hash Join.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_broadcast_join_threshold_size = 2000000;\n```\n\n----------------------------------------\n\nTITLE: Get Current System Time in TiDB\nDESCRIPTION: This snippet shows how to retrieve the current system time with second precision in TiDB using NOW(), compared to Oracle's SYSDATE.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSYSDATE\n```\n\nLANGUAGE: sql\nCODE:\n```\nNOW()\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_max_tiflash_threads for TiFlash Concurrency\nDESCRIPTION: Sets the maximum concurrency for TiFlash to execute a request. A value of -1 defers to TiFlash configuration, while 0 allows TiFlash to auto-configure the thread count.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_50\n\nLANGUAGE: SQL\nCODE:\n```\nSET [SESSION | GLOBAL] tidb_max_tiflash_threads = <value>;\n```\n\n----------------------------------------\n\nTITLE: Creating a bank profit table with SQL\nDESCRIPTION: This SQL snippet creates a table named 'bank' to store profit data with year, month, day, and profit fields. It also adds a TiFlash replica for MPP mode in TiDB to support advanced query execution features.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/group-by-modifier.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE bank\n(\n    year    INT,\n    month   VARCHAR(32),\n    day     INT,\n    profit  DECIMAL(13, 7)\n);\n\nALTER TABLE bank SET TIFLASH REPLICA 1; -- Add a TiFlash replica for the table in TiFlash MPP mode.\n\nINSERT INTO bank VALUES(2000, \"Jan\", 1, 10.3),(2001, \"Feb\", 2, 22.4),(2000,\"Mar\", 3, 31.6)\n```\n\n----------------------------------------\n\nTITLE: Release 7.5 Event Splitting Configuration\nDESCRIPTION: Documents event splitting compatibility matrix for TiDB version 7.5, showing protocol support and event splitting behavior\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-split-update-behavior.md#2025-04-18_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n| Version | Protocol | Split UK/PK `UPDATE` events | Not split UK/PK `UPDATE` events  | Comments |\n| -- | -- | -- | -- | -- |\n| <= v7.5.2 | ALL | ✓ | ✗ |\n| \\>= v7.5.3 | ALL | ✓ (Default value:`output-raw-change-event = false`) | ✓  (Optional: `output-raw-change-event = true`) | |\n```\n\n----------------------------------------\n\nTITLE: Executing Correlated Subquery With NO_DECORRELATE Hint in SQL\nDESCRIPTION: Uses the NO_DECORRELATE hint to tell the optimizer not to perform decorrelation for the correlated subquery. This forces the query to use the Apply operator which can be more efficient in some scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nexplain select * from t1 where t1.a < (select /*+ NO_DECORRELATE() */ sum(t2.a) from t2 where t2.b = t1.b);\n```\n\n----------------------------------------\n\nTITLE: Creating and Updating Table in SQL\nDESCRIPTION: This SQL snippet creates a table and demonstrates `UPDATE` operations, which TiCDC might split based on certain conditions to maintain data consistency. The snippet involves inserting initial values and updating primary keys within a transaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-split-update-behavior.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t (a INT PRIMARY KEY, b INT);\nINSERT INTO t VALUES (1, 1);\nINSERT INTO t VALUES (2, 2);\n\nBEGIN;\nUPDATE t SET a = 3 WHERE a = 2;\nUPDATE t SET a = 2 WHERE a = 1;\nCOMMIT;\n```\n\n----------------------------------------\n\nTITLE: MySQL Command - Show Current User Grants\nDESCRIPTION: New SQL syntax support for showing grants for the current user\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.0-rc.4.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW GRANTS FOR CURRENT_USER();\n```\n\n----------------------------------------\n\nTITLE: Using tiup dm audit Command in Shell\nDESCRIPTION: The basic syntax for the tiup dm audit command. It can be used with or without an audit-id parameter to either list all operation records or check the execution log of a specific operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-audit.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm audit [audit-id] [flags]\n```\n\n----------------------------------------\n\nTITLE: KILL Statement EBNF Syntax Definition\nDESCRIPTION: EBNF syntax diagram showing the grammar for the KILL statement, including optional TIDB, CONNECTION, and QUERY keywords.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-kill.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nKillStmt ::= 'KILL' 'TIDB'? ( 'CONNECTION' | 'QUERY' )? CONNECTION_ID\n```\n\n----------------------------------------\n\nTITLE: Encoding Key-Value Pairs for Table Data in TiDB\nDESCRIPTION: Demonstrates how TiDB encodes table data as key-value pairs, using tableID and rowID to construct unique keys.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-hot-spot-issues.md#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nKey: tablePrefix{tableID}_recordPrefixSep{rowID}\nValue: [col1, col2, col3, col4]\n```\n\n----------------------------------------\n\nTITLE: Configuring TSO node in scale-out.yml\nDESCRIPTION: This is a configuration example for adding a TSO (Timestamp Oracle) node to the TiDB cluster.  It specifies the host IP address and the port number for the TSO service.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_2\n\nLANGUAGE: ini\nCODE:\n```\n\"tso_servers:\\n  - host: 10.0.1.8\\n    port: 3379\"\n```\n\n----------------------------------------\n\nTITLE: Installing NUMA Tools on CentOS\nDESCRIPTION: Command to install the numactl package on CentOS systems.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_36\n\nLANGUAGE: bash\nCODE:\n```\nsudo yum -y install numactl\n```\n\n----------------------------------------\n\nTITLE: CALIBRATE RESOURCE EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the CALIBRATE RESOURCE command, showing the command structure and workload options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-calibrate-resource.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCalibrateResourceStmt ::= 'CALIBRATE' 'RESOURCE' WorkloadOption\n\nWorkloadOption ::=\n( 'WORKLOAD' ('TPCC' | 'OLTP_READ_WRITE' | 'OLTP_READ_ONLY' | 'OLTP_WRITE_ONLY') )\n| ( 'START_TIME' 'TIMESTAMP' ('DURATION' stringLit | 'END_TIME' 'TIMESTAMP')?)?\n```\n\n----------------------------------------\n\nTITLE: Adding Hibernate Gradle Dependencies\nDESCRIPTION: Gradle configuration for adding Hibernate ORM and MySQL connector dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-choose-driver-or-orm.md#2025-04-18_snippet_4\n\nLANGUAGE: gradle\nCODE:\n```\nimplementation 'org.hibernate:hibernate-core:6.2.3.Final'\nimplementation 'mysql:mysql-connector-java:8.0.33'\n```\n\n----------------------------------------\n\nTITLE: Releasing All Locks with RELEASE_ALL_LOCKS in TiDB SQL\nDESCRIPTION: Releases all locks held by the current session.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/locking-functions.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nRELEASE_ALL_LOCKS()\n```\n\n----------------------------------------\n\nTITLE: Downloading TiDB Community Toolkit\nDESCRIPTION: URL pattern for downloading the TiDB Community Toolkit. The URL requires replacing {version} with the specific TiDB version and {arch} with either amd64 or arm64 based on system architecture.\nSOURCE: https://github.com/pingcap/docs/blob/master/download-ecosystem-tools.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhttps://download.pingcap.org/tidb-community-toolkit-{version}-linux-{arch}.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Querying GC Safe Point in TiDB\nDESCRIPTION: SQL query to check the current garbage collection safe point timestamp in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-table.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM mysql.tidb WHERE variable_name = 'tikv_gc_safe_point';\n```\n\n----------------------------------------\n\nTITLE: Customizing Prometheus Scrape Configurations in TiUP\nDESCRIPTION: This YAML snippet illustrates how to add 'additional_scrape_conf' fields within the 'monitoring_servers' of the topology.yaml file. It customizes the scrape configurations for Prometheus to include specific metric relabeling actions. Suitable for advanced monitoring setups.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/customized-montior-in-tiup-environment.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nmonitoring_servers:\n  - host: xxxxxxx\n    ssh_port: 22\n    port: 9090\n    deploy_dir: /tidb-deploy/prometheus-9090\n    data_dir: /tidb-data/prometheus-9090\n    log_dir: /tidb-deploy/prometheus-9090/log\n    external_alertmanagers: []\n    arch: amd64\n    os: linux\n    additional_scrape_conf:\n      metric_relabel_configs:\n        - source_labels: [__name__]\n          separator: ;\n          regex: tikv_thread_nonvoluntary_context_switches|tikv_thread_voluntary_context_switches|tikv_threads_io_bytes_total\n          action: drop\n        - source_labels: [__name__,name]\n          separator: ;\n          regex: tikv_thread_cpu_seconds_total;(tokio|rocksdb).+\n          action: drop\n```\n\n----------------------------------------\n\nTITLE: Correcting JSON Unmarshaling in Go\nDESCRIPTION: This code snippet corrects the usage of json.Unmarshal in the job.DecodeArgs function to ensure compatibility with future Go versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.16.md#2025-04-18_snippet_1\n\nLANGUAGE: Go\nCODE:\n```\nCorrect the usage of `json.Unmarshal` in `job.DecodeArgs` to be compatible with future Go versions [#17887](https://github.com/pingcap/tidb/pull/17887)\n```\n\n----------------------------------------\n\nTITLE: Downloading go-tpc Test Program\nDESCRIPTION: This shell command downloads the `go-tpc` test program, which is essential for performing the TPC-C performance test. It uses `curl` to fetch the installation script from GitHub and `sh` to execute it.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/pingcap/go-tpc/master/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Importing Schema to TiDB using TiDB Lightning\nDESCRIPTION: This command runs TiDB Lightning to import the schema file from S3 to TiDB using the configuration file created earlier.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\nexport AWS_ACCESS_KEY_ID=${access_key}\nexport AWS_SECRET_ACCESS_KEY=${secret_key}\nnohup tiup tidb-lightning -config tidb-lightning-schema.toml > nohup.out 2>&1 &\n```\n\n----------------------------------------\n\nTITLE: Force NTP Synchronization\nDESCRIPTION: Commands to stop NTP service, force immediate synchronization with NTP server, and restart the service.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl stop ntpd.service && \\\nsudo ntpdate pool.ntp.org && \\\nsudo systemctl start ntpd.service\n```\n\n----------------------------------------\n\nTITLE: Managing TiUP Cluster Metadata\nDESCRIPTION: Commands for backing up and restoring cluster metadata files used in deployment and maintenance operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_27\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster meta backup ${cluster_name}\ntiup cluster meta restore ${cluster_name} ${backup_file}\n```\n\n----------------------------------------\n\nTITLE: Removing store from evict-leader-scheduler in TiDB PD\nDESCRIPTION: This command removes leader eviction scheduling for a specified store from an existing evict-leader-scheduler. If all stores are removed, the scheduler is automatically deleted.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_45\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config evict-leader-scheduler delete-store 2    // Remove leader eviction scheduling for store 2\n```\n\n----------------------------------------\n\nTITLE: Existing Indexes on Orders - SQL\nDESCRIPTION: This snippet lists the current indexes defined on the orders table, which include primary and unique keys, and standard indexes that facilitate lookups based on user_id, label_id, and created_at.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nPRIMARY KEY (`id`),\nUNIQUE KEY `index_orders_on_adjustment_id` (`adjustment_id`),\nKEY `index_orders_on_user_id` (`user_id`),\nKEY `index_orders_on_label_id` (`label_id`),\nKEY `index_orders_on_created_at` (`created_at`)\n```\n\n----------------------------------------\n\nTITLE: Viewing Result from TIDB_ROW_CHECKSUM Function\nDESCRIPTION: Shows the output of TIDB_ROW_CHECKSUM function, which returns a checksum value (3813955661) for the row with id=1. This checksum can be used to verify data integrity.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_26\n\nLANGUAGE: sql\nCODE:\n```\n+----+------+------+---------------------+\n| id | k    | c    | TIDB_ROW_CHECKSUM() |\n+----+------+------+---------------------+\n|  1 |   10 | a    | 3813955661          |\n+----+------+------+---------------------+\n1 row in set (0.000 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining CREATE BINDING Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the CREATE BINDING statement in TiDB. It specifies the structure and components of the statement, including options for global/session scope and binding types.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-binding.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nCreateBindingStmt ::=\n    'CREATE' GlobalScope 'BINDING' ( 'FOR' BindableStmt 'USING' BindableStmt\n|   'FROM' 'HISTORY' 'USING' 'PLAN' 'DIGEST' StringLiteralOrUserVariableList )\n\nGlobalScope ::=\n    ( 'GLOBAL' | 'SESSION' )?\n\nBindableStmt ::=\n    ( SelectStmt | UpdateStmt | InsertIntoStmt | ReplaceIntoStmt | DeleteStmt )\n\nStringLiteralOrUserVariableList ::=\n    ( StringLitOrUserVariable | StringLiteralOrUserVariableList ',' StringLitOrUserVariable )\n\nStringLiteralOrUserVariable ::=\n    ( stringLiteral | UserVariable )\n```\n\n----------------------------------------\n\nTITLE: Setting Default Role\nDESCRIPTION: SQL command to set the default role for user jennifer to automatically enable the analytics team role.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-revoke-role.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSET DEFAULT ROLE analyticsteam TO jennifer;\nQuery OK, 0 rows affected (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Configure branch.blockList in tidbcloud.yml\nDESCRIPTION: This snippet demonstrates how to configure the `branch.blockList` property in the `tidbcloud.yml` file.  `branch.blockList` is an array of strings that specify GitHub branches that the TiDB Cloud Branching app should ignore, even if those branches are in the `allowList`. The example shows how to exclude branches with names ending in \"_doc\" or \"_blackList\".\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/branch-github-integration.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n\"github:\\n    branch:\\n        blockList:\\n            - \".*_doc\"\\n            - \".*_blackList\"\"\n```\n\n----------------------------------------\n\nTITLE: Out-of-memory Error Message in TiDB with Pipelined DML\nDESCRIPTION: This error message appears when a query exceeds the memory limit even with Pipelined DML enabled. It occurs when total memory consumption, including executor overhead, exceeds the TiDB memory limit defined by tidb_mem_quota_query.\nSOURCE: https://github.com/pingcap/docs/blob/master/pipelined-dml.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nThe query has been canceled due to exceeding the memory limit allowed for a single SQL query. Please try to narrow the query scope or increase the tidb_mem_quota_query limit, and then try again.\n```\n\n----------------------------------------\n\nTITLE: Configuring Security Settings in TiKV YAML\nDESCRIPTION: YAML configuration for TiKV security settings, including certificate CN check and log redaction options.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_26\n\nLANGUAGE: yaml\nCODE:\n```\ncert-allowed-cn: []\nredact-info-log: false\n```\n\n----------------------------------------\n\nTITLE: Querying View Metadata in TiDB SQL\nDESCRIPTION: This snippet demonstrates how to query the INFORMATION_SCHEMA.VIEWS table to retrieve metadata about a specific view. It retrieves all columns for the book_with_ratings view.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-views.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.views WHERE TABLE_NAME = 'book_with_ratings'\\G\n```\n\n----------------------------------------\n\nTITLE: Setting Tolerant Size Ratio in PD\nDESCRIPTION: Sets the size of the balance buffer area to about 20 times the average Region Size. This controls when PD considers leaders or Regions to be in balance between stores.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nconfig set tolerant-size-ratio 20\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in TiDB SQL\nDESCRIPTION: This SQL command creates a table 't' with two integer columns 'a' and 'b' and applies indexing on both columns, designed to facilitate performant queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_35\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a INT, b INT, KEY(a), KEY(b));\n```\n\n----------------------------------------\n\nTITLE: Query Regions in Key Range\nDESCRIPTION: Command to find regions within a specified key range.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --host 127.0.0.1:20160 raft region --start 7480000000000000FF4E5F728000000000FF1443770000000000FA --end 7480000000000000FF4E5F728000000000FF21C4420000000000FA\n```\n\n----------------------------------------\n\nTITLE: Status Code 429 Chat2Data Endpoint Response Example\nDESCRIPTION: This code snippet presents a Data Service response from a Chat2Data endpoint with an HTTP status code of 429. The response indicates that the AI request exceeded the daily rate limit (100 requests per day). The `result.code` is 429, and the `message` field includes details about the limit and a link to request more quota.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"chat2data_endpoint\",\n  \"data\": {\n    \"columns\": [],\n    \"rows\": [],\n    \"result\": {\n      \"code\": 429,\n      \"message\": \"The AI request exceeded the limit of 100 times per day. For more quota, please contact us: https://tidb.support.pingcap.com/\",\n      \"start_ms\": \"\",\n      \"end_ms\": \"\",\n      \"latency\": \"\",\n      \"row_count\": 0,\n      \"row_affect\": 0,\n      \"limit\": 0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: FLUSH PRIVILEGES EBNF Syntax Definition in TiDB\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax diagram for the FLUSH statement in TiDB, showing the grammar for FLUSH PRIVILEGES and other FLUSH options. It defines the syntax structure including optional NO_WRITE_TO_BINLOG and LOCAL parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flush-privileges.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nFlushStmt ::=\n    'FLUSH' NoWriteToBinLogAliasOpt FlushOption\n\nNoWriteToBinLogAliasOpt ::=\n    ( 'NO_WRITE_TO_BINLOG' | 'LOCAL' )?\n\nFlushOption ::=\n    'PRIVILEGES'\n|   'STATUS'\n|    'TIDB' 'PLUGINS' PluginNameList\n|    'HOSTS'\n|   LogTypeOpt 'LOGS'\n|   TableOrTables TableNameListOpt WithReadLockOpt\n```\n\n----------------------------------------\n\nTITLE: Exporting Data from MySQL using Dumpling\nDESCRIPTION: Shell command to export data from MySQL using the Dumpling tool. This command exports specific databases and tables to an S3 bucket, with options for controlling file size and export parallelism.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-to-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\ntiup dumpling -h ${ip} -P 3306 -u root -t 16 -r 200000 -F 256MiB -B my_db1 -f 'my_db1.table[12]' -o 's3://my-bucket/sql-backup'\n```\n\n----------------------------------------\n\nTITLE: FLASHBACK DATABASE EBNF Syntax Diagram for TiDB\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the FLASHBACK DATABASE statement in TiDB, showing the complete grammar including the optional TO clause for database renaming.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-database.md#2025-04-18_snippet_2\n\nLANGUAGE: ebnf\nCODE:\n```\nFlashbackDatabaseStmt ::=\n    'FLASHBACK' DatabaseSym DBName FlashbackToNewName\nFlashbackToNewName ::=\n    ( 'TO' Identifier )?\n```\n\n----------------------------------------\n\nTITLE: Pausing DDL Jobs in TiDB\nDESCRIPTION: The ADMIN PAUSE DDL JOBS command is used to pause DDL jobs that are being executed. It can only pause jobs that are in progress or in the queue.\nSOURCE: https://github.com/pingcap/docs/blob/master/ddl-introduction.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN PAUSE DDL JOBS job_id [, job_id]\n```\n\n----------------------------------------\n\nTITLE: Using TiSpark Configuration for Replica Read Label\nDESCRIPTION: Configuration item used to set labels for target TiKV nodes in TiSpark.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.6.0.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\nspark.tispark.replica_read.label\n```\n\n----------------------------------------\n\nTITLE: Creating and Analyzing a Table in TiDB\nDESCRIPTION: SQL commands to create a table, insert data, and analyze it before locking statistics. This demonstrates the normal behavior of ANALYZE without locked statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-lock-stats.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t(a INT, b INT);\nINSERT INTO t VALUES (1,2), (3,4), (5,6), (7,8);\nANALYZE TABLE t;\nSHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: TiKV Control PD Communication Example\nDESCRIPTION: Example showing tikv-ctl communicating with PD for cluster-wide operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --pd 127.0.0.1:2379 compact-cluster\n```\n\n----------------------------------------\n\nTITLE: Viewing All Sequences in SQL\nDESCRIPTION: This SQL query retrieves all information about existing sequences from the SEQUENCES table, displaying the results in a vertical format.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-sequences.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM SEQUENCES\\G\n```\n\n----------------------------------------\n\nTITLE: Load YCSB Data into TiDB (Bash)\nDESCRIPTION: This command loads data into TiDB for a YCSB benchmark. It uses the `load` subcommand of the TiUP bench ycsb component, specifying the TiDB instance and the record count. The `-p` flag is used to set properties for the YCSB benchmark.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench ycsb load tidb -p tidb.instances=\"127.0.0.1:4000\" -p recordcount=10000\n```\n\n----------------------------------------\n\nTITLE: Demonstrating tidb_constraint_check_in_place=ON with Optimistic Transactions in SQL\nDESCRIPTION: This example shows how setting tidb_constraint_check_in_place to ON with optimistic transactions causes uniqueness validation to happen immediately during statement execution rather than at commit time.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\ntidb> set @@tidb_constraint_check_in_place=ON;\ntidb> begin optimistic;\ntidb> insert into t values (1);\nERROR 1062 : Duplicate entry '1' for key 't.PRIMARY'\n```\n\n----------------------------------------\n\nTITLE: Adding tidb-loadbalance Maven Dependencies\nDESCRIPTION: Maven configuration for adding tidb-loadbalance and required MySQL connector dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-choose-driver-or-orm.md#2025-04-18_snippet_7\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>io.github.lastincisor</groupId>\n  <artifactId>mysql-connector-java</artifactId>\n  <version>8.0.29-tidb-1.0.0</version>\n</dependency>\n<dependency>\n  <groupId>io.github.lastincisor</groupId>\n  <artifactId>tidb-loadbalance</artifactId>\n  <version>0.0.5</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: TiDB Query Execution Plan Row Output\nDESCRIPTION: Shows performance metrics for a TableFullScan operation using TiFlash MPP execution. Includes scan statistics, processing times, and resource utilization details for lineitem table scan operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\n└─TableFullScan_31(Probe)        | 600037902.00 | 600037902 | mpp[tiflash] | table:lineitem | tiflash_task:{proc max:57.9ms, min:42.9ms, avg: 51.3ms, p80:57.9ms, p95:57.9ms, iters:9297, tasks:3, threads:60}, tiflash_scan:{dtfile:{total_scanned_packs:73464, total_skipped_packs:12985, total_scanned_rows:600169085, total_skipped_rows:106014866, total_rs_index_load_time: 23ms, total_read_time: 21667ms}, total_create_snapshot_time: 0ms}\n```\n\n----------------------------------------\n\nTITLE: Viewing Partition UUID Information\nDESCRIPTION: Command to display filesystem information including UUID of all disks and partitions. This information is needed to properly configure the fstab file for mounting.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nlsblk -f\n```\n\n----------------------------------------\n\nTITLE: Query Results from Aggregate Query in TiDB\nDESCRIPTION: This snippet shows the output of the aggregate query that groups authors by birth year. It displays the birth year and corresponding author count for each year, ordered by count in descending order.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_11\n\nLANGUAGE: text\nCODE:\n```\n+------------+--------------+\n| birth_year | author_count |\n+------------+--------------+\n|       1932 |          317 |\n|       1947 |          290 |\n|       1939 |          282 |\n|       1935 |          289 |\n|       1968 |          291 |\n|       1962 |          261 |\n|       1961 |          283 |\n|       1986 |          289 |\n|       1994 |          280 |\n...\n|       1972 |          306 |\n+------------+--------------+\n71 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring SQL WHERE Clause Conditions in TOML\nDESCRIPTION: Defines a range condition for filtering data within specified age bounds. No specific dependencies are required for the syntax itself as it complies with SQL standards.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/sync-diff-inspector-overview.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\n\"range = \\\"age > 10 AND age < 20\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Clone TiDB Documentation Repository using Git\nDESCRIPTION: These commands clone the TiDB documentation repository from GitHub to a local directory.  The user needs to replace `$working_dir` with the desired directory and `$user` with their GitHub ID. It also configures the upstream repository for future updates.\nSOURCE: https://github.com/pingcap/docs/blob/master/resources/tidb-pdf-generation-tutorial.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncd $working_dir # Replace `$working_dir` with the directory where you want the repository to be placed. For example, `cd ~/Documents/GitHub`\ngit clone git@github.com:$user/docs.git # Replace `$user` with your GitHub ID\n\ncd $working_dir/docs\ngit remote add upstream git@github.com:pingcap/docs.git # Add upstream repository\ngit remote -v\n```\n\n----------------------------------------\n\nTITLE: Configuring Scale-Out Topology File (scale-out.yml)\nDESCRIPTION: This step involves creating or modifying a YAML file (scale-out.yml) to define the new nodes to be added to the cluster. The configuration includes host IP, SSH port, component-specific ports, and directory paths. It is essential for adding TiDB, TiKV, and PD nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n\"vi scale-out.yml\"\n```\n\n----------------------------------------\n\nTITLE: Setting DATABASE_URL Environment Variable for Netlify (Shell)\nDESCRIPTION: This shell command sets the DATABASE_URL environment variable in Netlify, which is required for the edge function to connect to the TiDB Cloud database. The URL should be obtained from the TiDB Cloud console and includes the username, password, host, and database name.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nnetlify env:set DATABASE_URL 'mysql://<username>:<password>@<host>/<database>'\n```\n\n----------------------------------------\n\nTITLE: Defining Metadata Path - Shell\nDESCRIPTION: This shell snippet specifies the path for saving metadata in a JSON format, which is crucial for tracking transaction timestamps in TiCDC.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n{protocol}://{prefix}/metadata\n```\n\n----------------------------------------\n\nTITLE: Installing MySQL Client on macOS\nDESCRIPTION: This snippet shows how to install the MySQL command-line client using Homebrew on macOS.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nbrew install mysql-client\n```\n\n----------------------------------------\n\nTITLE: Modifying NIC Send Queue Length\nDESCRIPTION: Command to increase the TX queue length for a network interface when TX errors are observed, improving the ability to queue packets before sending.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nip link set dev ${NIC_DEV_NAME} txqueuelen 2000\n```\n\n----------------------------------------\n\nTITLE: Viewing Thread CPU Usage\nDESCRIPTION: Command to view CPU usage by thread ID for a specific process.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ntop -p $PID -H\n```\n\n----------------------------------------\n\nTITLE: Stopping and Starting Data Migration Task\nDESCRIPTION: This snippet includes commands to stop and start a data migration task in DM after ensuring the DROP TABLE operation has been processed correctly. This step is crucial for maintaining data integrity during migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/shard-merge-best-practices.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nstop-task;\nstart-task;\n```\n\n----------------------------------------\n\nTITLE: Analyzing MPP Query Execution Plan in TiDB\nDESCRIPTION: Example SQL query showing an MPP execution plan with version 1 and FAST compression mode. The plan demonstrates a grouped count operation on the lineitem table using hash aggregation and exchange operators.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-mpp.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nmysql > EXPLAIN SELECT COUNT(*) AS count_order FROM lineitem GROUP BY l_returnflag, l_linestatus ORDER BY l_returnflag, l_linestatus;\n```\n\n----------------------------------------\n\nTITLE: Debugging TiUP Telemetry Collection\nDESCRIPTION: Command to view the full content of TiUP usage information shared with PingCAP by enabling debug mode through an environment variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/telemetry.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nTIUP_CLUSTER_DEBUG=enable tiup cluster list\n```\n\n----------------------------------------\n\nTITLE: Precision Loss Example in TiDB SQL Query\nDESCRIPTION: Shows how implicit type conversion between decimal and double types leads to precision loss when using BETWEEN operator. The execution plan reveals type casting that causes incorrect result filtering.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-implicit-type-conversion.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDESC SELECT * FROM `t1` WHERE `a` BETWEEN '12123123' AND '1111222211111111200000';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM `t1` WHERE `a` BETWEEN '12123123' AND '1111222211111111200000';\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV gRPC Compression\nDESCRIPTION: Configuration to enable gzip compression for gRPC communication between geo-distributed nodes to improve transmission speed.\nSOURCE: https://github.com/pingcap/docs/blob/master/geo-distributed-deployment-topology.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nserver.grpc-compression-type: gzip\n```\n\n----------------------------------------\n\nTITLE: Deleting User Profile in TiDB Cloud CLI - Markdown\nDESCRIPTION: This snippet outlines the command for deleting a user profile within the TiDB Cloud CLI. It is crucial for users looking to remove unused or unnecessary profiles and helps in maintaining a clean setup.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/cli-reference.md#2025-04-18_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\nUse [`ticloud config delete`](/tidb-cloud/ticloud-config-delete.md) to delete a user profile.\n```\n\n----------------------------------------\n\nTITLE: Canceling Data Import Task using TiDB Cloud CLI\nDESCRIPTION: This command cancels a data import task in TiDB Cloud. It can be used in both interactive and non-interactive modes. In interactive mode, the user follows CLI prompts, while in non-interactive mode, required flags must be specified manually.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-cancel.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import cancel [flags]\n```\n\n----------------------------------------\n\nTITLE: Updating Data in TiDB with mysql2\nDESCRIPTION: JavaScript code snippet to update a 'Player' record in TiDB, adding coins and goods, using mysql2.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nextjs.md#2025-04-18_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nconst [rsh] = await pool.query(\n    'UPDATE players SET coins = coins + ?, goods = goods + ? WHERE id = ?;',\n    [50, 50, 1]\n);\nconsole.log(rsh.affectedRows);\n```\n\n----------------------------------------\n\nTITLE: Viewing TiFlash Late Materialization Setting in SQL\nDESCRIPTION: SQL commands to check the current session and global settings for the TiFlash late materialization feature using the tidb_opt_enable_late_materialization system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-late-materialization.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW VARIABLES LIKE 'tidb_opt_enable_late_materialization';\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GLOBAL VARIABLES LIKE 'tidb_opt_enable_late_materialization';\n```\n\n----------------------------------------\n\nTITLE: Deleting Data from TiDB with PyMySQL in Python\nDESCRIPTION: This code snippet shows how to delete data from a TiDB database using PyMySQL. It executes a DELETE SQL statement to remove a player record based on the player's ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-pymysql.md#2025-04-18_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nwith get_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        player_id = \"1\"\n        cursor.execute(\"DELETE FROM players WHERE id = %s\", (player_id,))\n```\n\n----------------------------------------\n\nTITLE: Defining DDL Event Key Format in JSON\nDESCRIPTION: Specifies the key format for DDL Events in the TiCDC Open Protocol. It includes timestamp, schema name, table name, and event type identifier.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"ts\":<TS>,\n    \"scm\":<Schema Name>,\n    \"tbl\":<Table Name>,\n    \"t\":2\n}\n```\n\n----------------------------------------\n\nTITLE: Using tiup dm patch Command for DM Clusters\nDESCRIPTION: The basic syntax for the 'tiup dm patch' command which enables applying hotfix patches to a running DM cluster. It requires specifying the cluster name and the path to the binary package for replacement.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-patch.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm patch <cluster-name> <package-path> [flags]\n```\n\n----------------------------------------\n\nTITLE: Enabling List Partitioning System Variable\nDESCRIPTION: SQL command to enable the list partitioning feature in TiDB 5.0 by setting the session variable tidb_enable_list_partition to ON.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_enable_list_partition = 'ON'\n```\n\n----------------------------------------\n\nTITLE: Patching Command Output\nDESCRIPTION: Output of the 'tiup cluster patch --help' command, showing all available options for replacing components in a running TiDB cluster with specified packages.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nReplace the remote package with a specified package and restart the service\n\nUsage:\n  cluster patch <cluster-name> <package-path> [flags]\n\nFlags:\n  -h, --help                    help for patch\n  -N, --node strings            Specify the nodes\n      --offline                 Patch a stopped cluster\n      --overwrite               Use this package in the future scale-out operations\n  -R, --role strings            Specify the roles\n      --transfer-timeout uint   Timeout in seconds when transferring PD and TiKV store leaders, also for TiCDC drain one capture (default 600)\n\nGlobal Flags:\n  -c, --concurrency int     max number of parallel tasks allowed (default 5)\n      --format string       (EXPERIMENTAL) The format of output, available values are [default, json] (default \"default\")\n      --ssh string          (EXPERIMENTAL) The executor type: 'builtin', 'system', 'none'.\n      --ssh-timeout uint    Timeout in seconds to connect host via SSH, ignored for operations that don't need an SSH connection. (default 5)\n      --wait-timeout uint   Timeout in seconds to wait for an operation to complete, ignored for operations that don't fit. (default 120)\n  -y, --yes                 Skip all confirmations and assumes 'yes'\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB in Node.js (TypeScript)\nDESCRIPTION: Establishes a connection pool to TiDB using environment variables for configuration. Includes SSL settings and connection limit optimizations for serverless environments.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n// lib/tidb.ts\nimport mysql from 'mysql2';\n\nlet pool: mysql.Pool | null = null;\n\nfunction connect() {\n  return mysql.createPool({\n    host: process.env.TIDB_HOST, // TiDB host, for example: {gateway-region}.aws.tidbcloud.com\n    port: process.env.TIDB_PORT ? Number(process.env.TIDB_PORT) : 4000, // TiDB port, default: 4000\n    user: process.env.TIDB_USER, // TiDB user, for example: {prefix}.root\n    password: process.env.TIDB_PASSWORD, // TiDB password\n    database: process.env.TIDB_DATABASE || 'test', // TiDB database name, default: test\n    ssl: {\n      minVersion: 'TLSv1.2',\n      rejectUnauthorized: true,\n    },\n    connectionLimit: 1, // Setting connectionLimit to \"1\" in a serverless function environment optimizes resource usage, reduces costs, ensures connection stability, and enables seamless scalability.\n    maxIdle: 1, // max idle connections, the default value is the same as `connectionLimit`\n    enableKeepAlive: true,\n  });\n}\n\nexport function getPool(): mysql.Pool {\n  if (!pool) {\n    pool = connect();\n  }\n  return pool;\n}\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP DM Enable Command in Shell\nDESCRIPTION: This command enables auto-enabling of cluster services after machine restarts. It allows specifying the cluster name and optional flags for node or role selection.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-enable.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm enable <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Status Code 400 Response Example\nDESCRIPTION: This code snippet provides an example of a Data Service response with an HTTP status code of 400, indicating a parameter check failure.  The `result.code` is also 400, and the `message` field provides a general error message, along with space for detailed error information. This response signals that the request parameters did not meet the required criteria.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"sql_endpoint\",\n    \"data\": {\n        \"columns\": [],\n        \"rows\": [],\n        \"result\": {\n            \"code\": 400,\n            \"message\": \"param check failed! {detailed error}\",\n            \"start_ms\": \"\",\n            \"end_ms\": \"\",\n            \"latency\": \"\",\n            \"row_count\": 0,\n            \"row_affect\": 0,\n            \"limit\": 0\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Partitions on NVMe Disk for TiKV\nDESCRIPTION: Commands to create partitions on an NVMe disk using parted. The first example creates a single partition spanning the entire disk, while the second creates multiple partitions for large NVMe devices.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nparted -s -a optimal /dev/nvme0n1 mklabel gpt -- mkpart primary ext4 1 -1\n```\n\nLANGUAGE: bash\nCODE:\n```\nparted -s -a optimal /dev/nvme0n1 mklabel gpt -- mkpart primary ext4 1 2000GB\nparted -s -a optimal /dev/nvme0n1 -- mkpart primary ext4 2000GB -1\n```\n\n----------------------------------------\n\nTITLE: Configuring AutoRandom Primary Key in TiDB\nDESCRIPTION: Demonstrates how to add the AutoRandom keyword to a column attribute in TiDB to automatically assign random integers to the primary key, avoiding write hot spots caused by AUTO_INCREMENT.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.1.0-beta.2.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE example (\n  id INT PRIMARY KEY AutoRandom,\n  name VARCHAR(255)\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring DM Cluster Topology\nDESCRIPTION: This YAML configuration defines the topology of a DM cluster with three master servers, three worker servers, and monitoring components.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup-offline.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n---\nglobal:\n  user: \"tidb\"\n  ssh_port: 22\n  deploy_dir: \"/home/tidb/dm/deploy\"\n  data_dir: \"/home/tidb/dm/data\"\n  # arch: \"amd64\"\n\nmaster_servers:\n  - host: 172.19.0.101\n  - host: 172.19.0.102\n  - host: 172.19.0.103\n\nworker_servers:\n  - host: 172.19.0.101\n  - host: 172.19.0.102\n  - host: 172.19.0.103\n\nmonitoring_servers:\n  - host: 172.19.0.101\n\ngrafana_servers:\n  - host: 172.19.0.101\n\nalertmanager_servers:\n  - host: 172.19.0.101\n```\n\n----------------------------------------\n\nTITLE: Full Table Scan Query in TiDB\nDESCRIPTION: Example of a query that performs a full table scan using TableFullScan operator\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nselect * from t\n```\n\n----------------------------------------\n\nTITLE: ALTER DATABASE Syntax in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the ALTER DATABASE statement in TiDB. It shows the structure of the statement including optional database name and database options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-database.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nAlterDatabaseStmt ::=\n    'ALTER' 'DATABASE' DBName? DatabaseOptionList\n\nDatabaseOption ::=\n    DefaultKwdOpt ( CharsetKw '='? CharsetName | 'COLLATE' '='? CollationName | 'ENCRYPTION' '='? EncryptionOpt )\n```\n\n----------------------------------------\n\nTITLE: Refreshing TiDB Cloud Backup Status\nDESCRIPTION: Terminal output showing how to use terraform refresh to update the backup status and verify when it has completed successfully.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-backup-resource.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform refresh\ntidbcloud_cluster.example_cluster: Refreshing state... [id=1379661944630234067]\ntidbcloud_backup.example_backup: Refreshing state... [id=1350048]\n$ terraform state show tidbcloud_backup.example_backup\n# tidbcloud_backup.example_backup:\nresource \"tidbcloud_backup\" \"example_backup\" {\n    cluster_id       = \"1379661944630234067\"\n    create_timestamp = \"2022-08-26T07:56:10Z\"\n    description      = \"create by terraform\"\n    id               = \"1350048\"\n    name             = \"firstBackup\"\n    project_id       = \"1372813089189561287\"\n    size             = \"198775\"\n    status           = \"SUCCESS\"\n    type             = \"MANUAL\"\n}\n```\n\n----------------------------------------\n\nTITLE: SQL DELETE Example with DateTime Range\nDESCRIPTION: Example of deleting ratings data within a specific time range\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-delete-data.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nDELETE FROM `ratings` WHERE `rated_at` >= \"2022-04-15 00:00:00\" AND `rated_at` <= \"2022-04-15 00:15:00\";\n```\n\n----------------------------------------\n\nTITLE: Querying Default Timestamp in TiDB 2.0.7\nDESCRIPTION: TiDB 2.0.7 fixes an issue where data with a default value of current_timestamp could not be queried using the = condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.0.7.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM table_name WHERE timestamp_column = CURRENT_TIMESTAMP;\n```\n\n----------------------------------------\n\nTITLE: Example TiDB Cluster Version Upgrade\nDESCRIPTION: Example command showing how to upgrade a TiDB cluster to version 5.3.0 using TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash-upgrade-guide.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster upgrade <cluster-name> v5.3.0 --offline\n```\n\n----------------------------------------\n\nTITLE: Example Usage of Describe Command - Shell\nDESCRIPTION: This example shows a practical usage of the 'ticloud config describe' command specifically to describe a user profile by name without additional flags, simplifying the command execution for basic information retrieval.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-describe.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud config describe <profile-name>\n```\n\n----------------------------------------\n\nTITLE: Defining TINYTEXT Column in TiDB\nDESCRIPTION: Syntax for creating a TINYTEXT column with maximum length of 255 bytes and optional character specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nTINYTEXT [CHARACTER SET charset_name] [COLLATE collation_name]\n```\n\n----------------------------------------\n\nTITLE: Execution Plan for Optimized Single Max Function Query in SQL\nDESCRIPTION: Displays the execution plan for the optimized query with a single max function, showing how TiDB uses an index scan and limit to efficiently retrieve the maximum value.\nSOURCE: https://github.com/pingcap/docs/blob/master/max-min-eliminate.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain select max(a) from t;\n+------------------------------+---------+-----------+-------------------------+-------------------------------------+\n| id                           | estRows | task      | access object           | operator info                       |\n+------------------------------+---------+-----------+-------------------------+-------------------------------------+\n| StreamAgg_13                 | 1.00    | root      |                         | funcs:max(test.t.a)->Column#4       |\n| └─Limit_17                   | 1.00    | root      |                         | offset:0, count:1                   |\n|   └─IndexReader_27           | 1.00    | root      |                         | index:Limit_26                      |\n|     └─Limit_26               | 1.00    | cop[tikv] |                         | offset:0, count:1                   |\n|       └─IndexFullScan_25     | 1.00    | cop[tikv] | table:t, index:idx_a(a) | keep order:true, desc, stats:pseudo |\n+------------------------------+---------+-----------+-------------------------+-------------------------------------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Signing Metadata Command Syntax in Shell\nDESCRIPTION: This shell code snippet provides the syntax for using the `tiup mirror sign` command to sign metadata files, highlighting the main parameter, <manifest-file>, which can be a local path or network address. The snippet is crucial for users who need to manually execute metadata signing in a TiUP mirror environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-sign.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror sign <manifest-file> [flags]\n```\n\n----------------------------------------\n\nTITLE: Creating and Entering Package Directory\nDESCRIPTION: Commands to create and navigate to a temporary directory for package preparation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-patch.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nmkdir -p /tmp/package && cd /tmp/package\n```\n\n----------------------------------------\n\nTITLE: Checking for Inconsistent Index Data in SQL\nDESCRIPTION: This SQL snippet demonstrates how to check for inconsistent index data in a table named 'tbl' with an index named 'idx'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-recover.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM tbl;\nERROR 1105 (HY000): inconsistent index idx handle count 2 isn't equal to value count 3\n\nADMIN CHECK INDEX tbl idx ;\nERROR 1105 (HY000): handle &kv.CommonHandle{encoded:[]uint8{0x1, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0xf8}, colEndOffsets:[]uint16{0xa}}, index:types.Datum{k:0x5, decimal:0x0, length:0x0, i:0, collation:\"utf8mb4_bin\", b:[]uint8{0x0}, x:interface {}(nil)} != record:<nil>\n```\n\n----------------------------------------\n\nTITLE: Configuring AWS credentials for Dumpling\nDESCRIPTION: Shell commands to set AWS access key environment variables needed for Dumpling to access the S3 bucket.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nexport AWS_ACCESS_KEY_ID=${AccessKey}\nexport AWS_SECRET_ACCESS_KEY=${SecretKey}\n```\n\n----------------------------------------\n\nTITLE: Executing Subquery in SHOW Statement (SQL)\nDESCRIPTION: Demonstrates support for subqueries within SHOW statements, allowing for more complex query structures.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.16.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW COLUMNS FROM tbl WHERE FIELDS IN (SELECT 'a')\n```\n\n----------------------------------------\n\nTITLE: Lock Tables Example - READ Lock\nDESCRIPTION: This SQL snippet demonstrates the error that occurs when trying to acquire a `READ` lock on a table that is already locked with a `WRITE` lock by another session. It shows the error message and provides context about the session holding the lock.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-lock-tables-and-unlock-tables.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"> LOCK TABLES t1 READ;\\nERROR 8020 (HY000): Table 't1' was locked in WRITE by server: f4799bcb-cad7-4285-8a6d-23d3555173f1_session: 2199023255959\"\n```\n\n----------------------------------------\n\nTITLE: Status Code 500 Response Example - Authentication Failure\nDESCRIPTION: This code snippet shows a Data Service response with an HTTP status code of 500, indicating an internal server error potentially caused by authentication failure.  The `result.code` is 500, and the `message` field provides details about the error, specifically mentioning an issue with the authentication server due to a deadline exceeded error.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"sql_endpoint\",\n    \"data\": {\n        \"columns\": [],\n        \"rows\": [],\n        \"result\": {\n            \"code\": 500,\n            \"message\": \"internal error! defaultPermissionHelper: rpc error: code = DeadlineExceeded desc = context deadline exceeded\",\n            \"start_ms\": \"\",\n            \"end_ms\": \"\",\n            \"latency\": \"\",\n            \"row_count\": 0,\n            \"row_affect\": 0,\n            \"limit\": 0\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Applying Hotfix to Specific Nodes or Roles\nDESCRIPTION: Commands to apply the prepared hotfix packages to specific nodes or roles in the DM cluster. The examples show targeting by node ID or by component role.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-patch.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n# Apply hotfix to a specified node.\ntiup dm patch dm-test dm-master-hotfix-linux-amd64.tar.gz -N 172.16.100.21:8261\ntiup dm patch dm-test dm-worker-hotfix-linux-amd64.tar.gz -N 172.16.100.21:8262\n# Apply hotfix to a specified role.\ntiup dm patch dm-test dm-master-hotfix-linux-amd64.tar.gz -R dm-master\ntiup dm patch dm-test dm-worker-hotfix-linux-amd64.tar.gz -R dm-worker\n```\n\n----------------------------------------\n\nTITLE: Security Certificate Configuration\nDESCRIPTION: Security-related settings for TLS certificates and keys, including paths for CA, certificate, and private key files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_25\n\nLANGUAGE: yaml\nCODE:\n```\nca-path: \"\"\ncert-path: \"\"\nkey-path: \"\"\n```\n\n----------------------------------------\n\nTITLE: Set Table Collation for sync-diff-inspector in TOML\nDESCRIPTION: Defines collation on the table to ensure consistency during comparison. If not specified, default behavior applies, which can be adjusted based on specific encoding requirements.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/sync-diff-inspector-overview.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\n\"collation = \\\"\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TSV Parsing in TOML for TiDB Lightning\nDESCRIPTION: TOML configuration for Tab-Separated Values (TSV) parsing in TiDB Lightning, specifying tab separator and other options.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n[mydumper.csv]\nseparator = \"\\t\"\ndelimiter = ''\nheader = true\nnot-null = false\nnull = 'NULL'\nbackslash-escape = false\n```\n\n----------------------------------------\n\nTITLE: Importing an Existing TiDB Cloud Cluster\nDESCRIPTION: This snippet explains how to import an existing TiDB Cloud cluster that was not created using Terraform, allowing it to be managed through Terraform. It outlines the process to set up the import configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_15\n\nLANGUAGE: hcl\nCODE:\n```\nterraform {\n required_providers {\n   tidbcloud = {\n     source = \"tidbcloud/tidbcloud\"\n   }\n }\n}\nresource \"tidbcloud_cluster\" \"import_cluster\" {}\n```\n\n----------------------------------------\n\nTITLE: Destroying TiDB Cluster\nDESCRIPTION: Command to completely destroy a TiDB cluster, stopping all services and clearing data.\nSOURCE: https://github.com/pingcap/docs/blob/master/maintain-tidb-using-tiup.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster destroy ${cluster-name}\n```\n\n----------------------------------------\n\nTITLE: TiDB System Variables Table\nDESCRIPTION: Markdown table documenting system variable changes including deleted, modified and newly added variables with their descriptions and change types.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.0.0.md#2025-04-18_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n| Variable name  | Change type    | Description |\n|--------|------------------------------|------|\n| `tidb_pessimistic_txn_aggressive_locking` | Deleted | This variable is renamed to [`tidb_pessimistic_txn_fair_locking`](/system-variables.md#tidb_pessimistic_txn_fair_locking-new-in-v700). |\n| [`tidb_enable_non_prepared_plan_cache`](/system-variables.md#tidb_enable_non_prepared_plan_cache) | Modified | Takes effect starting from v7.0.0 and controls whether to enable the [Non-prepared plan cache](/sql-non-prepared-plan-cache.md) feature. |\n| [`tidb_enable_null_aware_anti_join`](/system-variables.md#tidb_enable_null_aware_anti_join-new-in-v630) | Modified | Changes the default value from `OFF` to `ON` after further tests, meaning that TiDB applies Null-Aware Hash Join when Anti Join is generated by subqueries led by special set operators `NOT IN` and `!= ALL` by default. |\n| [`tidb_enable_resource_control`](/system-variables.md#tidb_enable_resource_control-new-in-v660) | Modified | Changes the default value from `OFF` to `ON`, meaning that the cluster isolates resources by resource group by default. Resource Control is enabled by default in v7.0.0, so that you can use this feature whenever you want. |\n```\n\n----------------------------------------\n\nTITLE: Dumping Checkpoint Content in TiDB Lightning with Shell\nDESCRIPTION: This shell command is used primarily for debugging, dumping the checkpoint content from a MySQL driver into a specified directory, useful for technical investigations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-checkpoints.md#2025-04-18_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\ntidb-lightning-ctl --checkpoint-dump=output/directory\n```\n\n----------------------------------------\n\nTITLE: Testing Disk Performance with Fio (Mixed)\nDESCRIPTION: This command utilizes `fio` to conduct a mixed workload test consisting of sequential writes and random reads on a disk. It configures parameters such as the I/O engine (`psync`), block size (`32k`), file synchronization (`fdatasync=1`), read/write pattern (`randrw`), and the proportions of random reads and sequential writes.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/deploy-and-maintain-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n\n./fio -ioengine=psync -bs=32k -fdatasync=1 -thread -rw=randrw -percentage_random=100,0 -size=10G -filename=fio_randread_write_test.txt -name='fio mixed randread and sequential write test' -iodepth=4 -runtime=60 -numjobs=4 -group_reporting --output-format=json --output=fio_randread_write_test.json\n\n```\n\n----------------------------------------\n\nTITLE: SQL Query to View Data Import Status\nDESCRIPTION: This SQL snippet is used to view the number of rows and data size for each table after the import process is complete. The query targets the 'bookshop' schema to retrieve details about the tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-bookshop-schema-design.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    CONCAT(table_schema,'.',table_name) AS 'Table Name',\n    table_rows AS 'Number of Rows',\n    CONCAT(ROUND(data_length/(1024*1024*1024),4),'G') AS 'Data Size',\n    CONCAT(ROUND(index_length/(1024*1024*1024),4),'G') AS 'Index Size',\n    CONCAT(ROUND((data_length+index_length)/(1024*1024*1024),4),'G') AS 'Total'\nFROM\n    information_schema.TABLES\nWHERE table_schema LIKE 'bookshop';\n```\n\n----------------------------------------\n\nTITLE: Configuring Block and Allow Lists for DM Task in YAML\nDESCRIPTION: This YAML snippet shows how to set up block and allow lists for tables in a DM task. It defines rules for including or excluding specific databases and tables using wildcards.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-task-configuration-guide.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nblock-allow-list:\n  bw-rule-1:                           # The name of the block and allow list rule.\n    do-dbs: [\"test.*\", \"user\"]         # The allow list of upstream schemas to be migrated. Wildcard characters (*?) are supported. You only need to configure either `do-dbs` or `ignore-dbs`. If both fields are configured, only `do-dbs` takes effect.\n    # ignore-dbs: [\"mysql\", \"account\"] # The block list of upstream schemas to be migrated. Wildcard characters (*?) are supported.\n    do-tables:                         # The allow list of upstream tables to be migrated. You only need to configure either `do-tables` or `ignore-tables`. If both fields are configured, only `do-tables` takes effect.\n    - db-name: \"test.*\"\n      tbl-name: \"t.*\"\n    - db-name: \"user\"\n      tbl-name: \"information\"\n  bw-rule-2:                          # The name of the block allow list rule.\n    ignore-tables:                    # The block list of data source tables needs to be migrated.\n    - db-name: \"user\"\n      tbl-name: \"log\"\n```\n\n----------------------------------------\n\nTITLE: Viewing exported data SQL file in Shell\nDESCRIPTION: Shows an example of an exported data file containing SQL INSERT statements with the actual table data.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncat test.t1.0.sql\n```\n\nLANGUAGE: sql\nCODE:\n```\n/*!40101 SET NAMES binary*/;\nINSERT INTO `t1` VALUES\n(1);\n```\n\n----------------------------------------\n\nTITLE: Resume Replication Task\nDESCRIPTION: HTTP POST request to resume a specific replication task with optional checkpoint override.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://127.0.0.1:8300/api/v2/changefeeds/test1/resume -d '{}'\n```\n\n----------------------------------------\n\nTITLE: TiKV Control with SSL Configuration\nDESCRIPTION: Example of using tikv-ctl with SSL certificate configuration for secure connections.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --ca-path ca.pem --cert-path client.pem --key-path client-key.pem --host 127.0.0.1:20160 <subcommands>\n```\n\n----------------------------------------\n\nTITLE: Selecting TiDB slow-threshold Variable\nDESCRIPTION: This SQL statement retrieves the current value of the `tidb_slow_log_threshold` system variable. It confirms that the previous `set` command was successful and that the variable now reflects the new value.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nselect @@tidb_slow_log_threshold;\n```\n\n----------------------------------------\n\nTITLE: Decoding Base64 Data with TiDB Control - Shell\nDESCRIPTION: Describes how to use the 'base64decode' command in TiDB Control to decode base64-encoded data into its original format. Provides examples for decoding both handle IDs and row data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-control.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ tidb-ctl base64decode AAAAAAAAAAE=\n```\n\nLANGUAGE: shell\nCODE:\n```\n$ ./tidb-ctl base64decode test.t CAIIAggEAhjlk4jlk4ggaGVsbG8IBgAICAmAgIDwjYuu0Rk=\n```\n\nLANGUAGE: shell\nCODE:\n```\n$ ./tidb-ctl base64decode 60 CAIIAggEAhjlk4jlk4ggaGVsbG8IBgAICAmAgIDwjYuu0Rk=\n```\n\n----------------------------------------\n\nTITLE: Raw Key Scanning with tikv-ctl Shell\nDESCRIPTION: This shell command scans raw keys directly from RocksDB using tikv-ctl. Users can specify the key range with the --from and --to options, and limit the number of keys output using --limit. The command scans a specific column family (cf). Dependencies include having a valid data directory set and the tikv-ctl tool available.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir /var/lib/tikv raw-scan --from 'zt' --limit 2 --cf default\n```\n\nLANGUAGE: shell\nCODE:\n```\nkey: \"zt\\200\\000\\000\\000\\000\\000\\000\\377\\005_r\\200\\000\\000\\000\\000\\377\\000\\000\\001\\000\\000\\000\\000\\000\\372\\372b2,^\\033\\377\\364\", value: \"\\010\\002\\002\\002%\\010\\004\\002\\010root\\010\\006\\002\\000\\010\\010\\t\\002\\010\\n\\t\\002\\010\\014\\t\\002\\010\\016\\t\\002\\010\\020\\t\\002\\010\\022\\t\\002\\010\\024\\t\\002\\010\\026\\t\\002\\010\\030\\t\\002\\010\\032\\t\\002\\010\\034\\t\\002\\010\\036\\t\\002\\010 \\t\\002\\010\"\\022\\t\\002\\010s\\t\\002\\010&\\t\\002\\010(\\t\\002\\010*\\t\\002\\010,\\t\\002\\010.\\t\\002\\0100\\t\\002\\0102\\t\\002\\0104\\t\\002\"\nkey: \"zt\\200\\000\\000\\000\\000\\000\\000\\377\\025_r\\200\\000\\000\\000\\000\\377\\000\\000\\023\\000\\000\\000\\000\\000\\372\\372b2,^\\033\\377\\364\", value: \"\\010\\002\\002&slow_query_log_file\\010\\004\\002P/usr/local/mysql/data/localhost-slow.log\"\n\nTotal scanned keys: 2\n```\n\n----------------------------------------\n\nTITLE: Verifying dbt configuration with debug command\nDESCRIPTION: Command to validate the database and project configuration for the dbt project. This should be run after configuring profiles.yml and dbt_project.yml to ensure connectivity to TiDB Cloud.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ndbt debug\n```\n\n----------------------------------------\n\nTITLE: Verifying Transformation in TiDB Cloud\nDESCRIPTION: SQL commands to verify the transformed data in TiDB Cloud. This shows how to check the tables created and inspect the data in the customer table.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nmysql> USE ANALYTICS;\nmysql> SHOW TABLES;\n+---------------------+\n| Tables_in_analytics |\n+---------------------+\n| customers           |\n| orders              |\n| raw_customers       |\n| raw_orders          |\n| raw_payments        |\n| stg_customers       |\n| stg_orders          |\n| stg_payments        |\n+---------------------+\n8 rows in set (0.00 sec)\n\nmysql> SELECT * FROM customers LIMIT 10;\n+-------------+------------+-----------+-------------+-------------------+------------------+-------------------------+\n| customer_id | first_name | last_name | first_order | most_recent_order | number_of_orders | customer_lifetime_value |\n+-------------+------------+-----------+-------------+-------------------+------------------+-------------------------+\n|           1 | Michael    | P.        | 2018-01-01  | 2018-02-10        |                2 |                 33.0000 |\n|           2 | Shawn      | M.        | 2018-01-11  | 2018-01-11        |                1 |                 23.0000 |\n|           3 | Kathleen   | P.        | 2018-01-02  | 2018-03-11        |                3 |                 65.0000 |\n|           4 | Jimmy      | C.        | NULL        | NULL              |             NULL |                    NULL |\n|           5 | Katherine  | R.        | NULL        | NULL              |             NULL |                    NULL |\n|           6 | Sarah      | R.        | 2018-02-19  | 2018-02-19        |                1 |                  8.0000 |\n|           7 | Martin     | M.        | 2018-01-14  | 2018-01-14        |                1 |                 26.0000 |\n|           8 | Frank      | R.        | 2018-01-29  | 2018-03-12        |                2 |                 45.0000 |\n|           9 | Jennifer   | F.        | 2018-03-17  | 2018-03-17        |                1 |                 30.0000 |\n|          10 | Henry      | W.        | NULL        | NULL              |             NULL |                    NULL |\n+-------------+------------+-----------+-------------+-------------------+------------------+-------------------------+\n10 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: TABLE Statement with LIMIT Clause\nDESCRIPTION: Example of using the TABLE statement with a LIMIT clause to retrieve only the first row from the table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-table.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nTABLE t1 LIMIT 1;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+----+\n| id |\n+----+\n|  1 |\n+----+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Deleting Data with Sequelize ORM in TypeScript\nDESCRIPTION: This code demonstrates how to delete a player record using Sequelize's destroy method. It deletes the previously created player and verifies the deletion by attempting to find the record again, logging the result.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-sequelize.md#2025-04-18_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nlogger.info('Deleting the new player...');\nawait newPlayer.destroy();\nconst deletedNewPlayer = await playersModel.findByPk(6);\nlogger.info('Deleted the new player.');\nlogger.info(deletedNewPlayer?.toJSON());\n```\n\n----------------------------------------\n\nTITLE: JWT Payload Example in JSON\nDESCRIPTION: Demonstrates the structure of a JWT payload with standard claims including issuer, subject, email, and expiration timestamps\nSOURCE: https://github.com/pingcap/docs/blob/master/security-compatibility-with-mysql.md#2025-04-18_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"email\": \"user@pingcap.com\",\n  \"exp\": 1703305494,\n  \"iat\": 1703304594,\n  \"iss\": \"issuer-abc\",\n  \"sub\": \"user@pingcap.com\"\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving TiProxy Configuration in JSON Format using Bash\nDESCRIPTION: Shows how to request the TiProxy configuration in JSON format by specifying the 'format' query parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-api.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"http://127.0.0.1:3080/api/admin/config/?format=json\"\n```\n\n----------------------------------------\n\nTITLE: Creating User with Account Locking Policy in TiDB\nDESCRIPTION: This SQL command creates a new user 'test1'@'localhost' with a password and sets an account locking policy. The account will be locked for 3 days after 3 consecutive failed login attempts.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_30\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE USER 'test1'@'localhost' IDENTIFIED BY 'password' FAILED_LOGIN_ATTEMPTS 3 PASSWORD_LOCK_TIME 3;\n```\n\n----------------------------------------\n\nTITLE: Displaying Table Regions with SQL\nDESCRIPTION: The snippet uses the SHOW TABLE command in SQL to list all Regions associated with table 't', providing details such as REGION_ID, START_KEY, and END_KEY. It is used to verify Region distributions within a table in the TiDB environment. There are no prerequisites other than having the necessary privileges to execute this command. The output is a table containing Region metadata, useful for database optimization and management tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-regions.md#2025-04-18_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\ntest> SHOW TABLE t REGIONS;\n+-----------+-----------------------------+-----------------------------+-----------+-----------------+---------------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n| REGION_ID | START_KEY                   | END_KEY                     | LEADER_ID | LEADER_STORE_ID | PEERS         | SCATTERING | WRITTEN_BYTES | READ_BYTES | APPROXIMATE_SIZE(MB) | APPROXIMATE_KEYS | SCHEDULING_CONSTRAINTS | SCHEDULING_STATE |\n+-----------+-----------------------------+-----------------------------+-----------+-----------------+---------------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n| 102       | t_43_r                      | t_43_r_20000                | 118       | 7               | 105, 118, 119 | 0          | 0             | 0          | 1                    | 0                |                        |                  |\n| 106       | t_43_r_20000                | t_43_r_40000                | 120       | 7               | 108, 120, 126 | 0          | 0             | 0          | 1                    | 0                |                        |                  |\n| 110       | t_43_r_40000                | t_43_r_60000                | 112       | 9               | 112, 113, 121 | 0          | 0             | 0          | 1                    | 0                |                        |                  |\n| 114       | t_43_r_60000                | t_43_r_80000                | 122       | 7               | 115, 122, 123 | 0          | 35            | 0          | 1                    | 0                |                        |                  |\n| 3         | t_43_r_80000                |                             | 93        | 8               | 73, 93, 128   | 0          | 0             | 0          | 1                    | 0                |                        |                  |\n| 135       | t_43_i_1_                   | t_43_i_1_016d80000000000000 | 139       | 2               | 138, 139, 140 | 0          | 35            | 0          | 1                    | 0                |                        |                  |\n| 98        | t_43_i_1_016d80000000000000 | t_43_r                      | 99        | 1               | 99, 100, 101  | 0          | 0             | 0          | 1                    | 0                |                        |                  |\n+-----------+-----------------------------+-----------------------------+-----------+-----------------+---------------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n```\n\n----------------------------------------\n\nTITLE: Deleting Player Data from TiDB using Java and MySQL Connector/J\nDESCRIPTION: This snippet illustrates how to delete player data from a TiDB database using Java and MySQL Connector/J. It establishes a connection, prepares a DELETE statement with a parameter, and executes the delete operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-jdbc.md#2025-04-18_snippet_4\n\nLANGUAGE: java\nCODE:\n```\npublic void deletePlayer(String id) throws SQLException {\n    MysqlDataSource mysqlDataSource = getMysqlDataSourceByEnv();\n    try (Connection connection = mysqlDataSource.getConnection()) {\n        PreparedStatement deleteStatement = connection.prepareStatement(\"DELETE FROM player WHERE id=?\");\n        deleteStatement.setString(1, id);\n        deleteStatement.execute();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Dump Data Encryption Keys\nDESCRIPTION: This command retrieves and displays all data encryption keys used in TiKV. It requests user consent due to the sensitive nature of the information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_26\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --config=./conf.toml encryption-meta dump-key\n```\n\n----------------------------------------\n\nTITLE: TiCDC Changefeed Creation with AWS Glue Schema Registry\nDESCRIPTION: This snippet shows how to create a TiCDC changefeed while integrating with AWS Glue Schema Registry. It includes necessary parameters for AWS configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\n./cdc cli changefeed create --server=127.0.0.1:8300 --changefeed-id=\"kafka-glue-test\" --sink-uri=\"kafka://127.0.0.1:9092/topic-name?&protocol=avro&replication-factor=3\" --config changefeed_glue.toml\n```\n\n----------------------------------------\n\nTITLE: TiCDC Kafka Connection Timeout Configuration Parameters (New)\nDESCRIPTION: New TiCDC parameters that control timeout settings for Kafka connections, including dial-timeout for establishing connections, read-timeout for getting responses, and write-timeout for write operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_20\n\nLANGUAGE: toml\nCODE:\n```\ndial-timeout\nread-timeout\nwrite-timeout\n```\n\n----------------------------------------\n\nTITLE: Creating Tables Without Unique or Primary Keys - SQL\nDESCRIPTION: This snippet discusses creating partitioned tables without unique or primary keys, indicating that the previous restrictions do not apply in such cases and allowing for more flexible definitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_60\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCREATE TABLE t_no_pk (c1 INT, c2 INT)\n    PARTITION BY RANGE(c1) (\n        PARTITION p0 VALUES LESS THAN (10),\n        PARTITION p1 VALUES LESS THAN (20),\n        PARTITION p2 VALUES LESS THAN (30),\n        PARTITION p3 VALUES LESS THAN (40)\n    );\n```\n```\nQuery OK, 0 rows affected (0.12 sec)\n```\n```\n\n----------------------------------------\n\nTITLE: Enabling All Roles Except Specified Ones in TiDB\nDESCRIPTION: This snippet shows how to enable all roles except the specified ones for the current session using the `SET ROLE ALL EXCEPT` statement. In this case, all roles except `app_read` are enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nSET ROLE ALL EXCEPT 'app_read'\n```\n\n----------------------------------------\n\nTITLE: Setting Max Drift for Timestamp Validity Checks\nDESCRIPTION: This snippet specifies the maximum time that a read or write request's timestamp can exceed the cached PD TSO, establishing parameters for invalid requests in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n+ Specifies the maximum time by which the timestamp of a read or write request can exceed the PD TSO cached in TiKV.\n+ If a read or write request uses a timestamp that exceeds **the sum of the PD TSO cached in TiKV and `max-drift`**, TiKV considers it an invalid `max-ts` update request and handles it according to the [`action-on-invalid-update`](#action-on-invalid-update-new-in-v900) configuration.\n+ Default value: `\"60s\"`\n+ It is recommended to set this value to at least three times the value of [`cache-sync-interval`](#cache-sync-interval-new-in-v900).\n```\n\n----------------------------------------\n\nTITLE: Basic Table Creation Syntax in TiDB\nDESCRIPTION: Basic SQL syntax template for creating a table in TiDB, showing the fundamental structure with table name and elements placeholders.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-create-table.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE {table_name} ( {elements} );\n```\n\n----------------------------------------\n\nTITLE: Enabling Cross-Region Merge in PD Configuration\nDESCRIPTION: Enables the cross-Region merge feature in PD to reduce the number of empty Regions, which helps optimize performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0-rc.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nenable-cross-table-merge = true\n```\n\n----------------------------------------\n\nTITLE: Enabling Row-Level Checksum in TiDB (SQL)\nDESCRIPTION: SQL command to enable the checksum integrity validation feature for single-row data in the upstream TiDB cluster by setting the tidb_enable_row_level_checksum system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-integrity-check.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_enable_row_level_checksum = ON;\n```\n\n----------------------------------------\n\nTITLE: Setting AWS Environment Variables\nDESCRIPTION: Bash commands to set AWS environment variables for authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nexport AWS_ACCESS_KEY_ID={your_access_key_id}\nexport AWS_SECRET_ACCESS_KEY={your_secret_access_key}\nexport AWS_SESSION_TOKEN={your_session_token}\n```\n\n----------------------------------------\n\nTITLE: FLASHBACK CLUSTER Potential Issue\nDESCRIPTION: Warning about potential Region persistence during FLASHBACK CLUSTER operation in TiDB v7.1.0. Recommends avoiding the feature and suggests using snapshot backup and restore as an alternative.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.1.0.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nFLASHBACK CLUSTER TO TIMESTAMP\n```\n\n----------------------------------------\n\nTITLE: Compacting TiFlash Replicas of Specified Partitions in SQL\nDESCRIPTION: New SQL syntax to compact TiFlash replicas of specified partitions in a table immediately, helping reduce storage space and improve query performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.4.0.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE table_name COMPACT [PARTITION PartitionNameList] [engine_type REPLICA]\n```\n\n----------------------------------------\n\nTITLE: Status Code 405 Response Example\nDESCRIPTION: This code snippet displays a Data Service response with an HTTP status code of 405, signaling that the request method used is not allowed.  The `result.code` also shows 405, and the `message` field states \"method not allowed\". This response indicates that the Data Service endpoint only supports `GET` and `POST` requests.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"sql_endpoint\",\n    \"data\": {\n        \"columns\": [],\n        \"rows\": [],\n        \"result\": {\n            \"code\": 405,\n            \"message\": \"method not allowed\",\n            \"start_ms\": \"\",\n            \"end_ms\": \"\",\n            \"latency\": \"\",\n            \"row_count\": 0,\n            \"row_affect\": 0,\n            \"limit\": 0\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Coprocessor Task Display Enhancement\nDESCRIPTION: Reference to a feature that adds support for displaying Coprocessor task information in explain statements with dot format.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.1.0-ga.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- Support displaying the information of Coprocessor tasks in `explain format = \"dot\"` [#16125](https://github.com/pingcap/tidb/pull/16125)\n```\n\n----------------------------------------\n\nTITLE: Manually Removing a TiFlash Node in TiDB Cluster\nDESCRIPTION: This command uses pd-ctl to manually remove a TiFlash node from a TiDB cluster by its store ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_24\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd -u http://<pd_ip>:<pd_port> store delete <store_id>\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying a Partitioned Table in TiDB\nDESCRIPTION: Creates a table with HASH partitioning and then queries the PARTITIONS table to retrieve information about the partitions. The example uses the \\G formatter to display results vertically for better readability.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-partitions.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test.t1 (id INT NOT NULL PRIMARY KEY) PARTITION BY HASH (id) PARTITIONS 2;\nSELECT * FROM PARTITIONS WHERE table_schema='test' AND table_name='t1'\\G\n```\n\n----------------------------------------\n\nTITLE: Querying Tables with merge_option Attribute in SQL\nDESCRIPTION: Demonstrates how to find all tables or partitions configured with the merge_option attribute using a SELECT statement with a LIKE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/table-attributes.md#2025-04-18_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.attributes WHERE attributes LIKE '%merge_option%';\n```\n\n----------------------------------------\n\nTITLE: Preventing Region Merging for a Partition in SQL\nDESCRIPTION: Demonstrates how to prevent Regions of a specific partition from merging by setting the merge_option attribute to 'deny'.\nSOURCE: https://github.com/pingcap/docs/blob/master/table-attributes.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t PARTITION p ATTRIBUTES 'merge_option=deny';\n```\n\n----------------------------------------\n\nTITLE: Markdown Headers and Configuration\nDESCRIPTION: YAML frontmatter and markdown headers defining the document structure and metadata for TiDB monitoring documentation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-monitoring-framework.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: TiDB Monitoring Framework Overview\nsummary: Use Prometheus, Grafana, and TiDB Dashboard to build the TiDB monitoring framework.\naliases: ['/docs/dev/tidb-monitoring-framework/','/docs/dev/how-to/monitor/overview/']\n---\n\n# TiDB Monitoring Framework Overview\n```\n\n----------------------------------------\n\nTITLE: Displaying TiUP Mirror Help Output\nDESCRIPTION: Sample output from the tiup mirror --help command showing the available subcommands and usage information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nThe `mirror` command is used to manage a component repository for TiUP, you can use\nit to create a private repository, or to add new component to an existing repository.\nThe repository can be used either online or offline.\nIt also provides some useful utilities to help manage keys, users, and versions\nof components or the repository itself.\n\nUsage:\n  tiup mirror <command> [flags]\n\nAvailable Commands:\n  init        Initialize an empty repository\n  sign        Add signatures to a manifest file\n  genkey      Generate a new key pair\n  clone       Clone a local mirror from a remote mirror and download all selected components\n  merge       Merge two or more offline mirrors\n  publish     Publish a component\n  show        Show the mirror address\n  set         Set mirror address\n  modify      Modify published component\n  renew       Renew the manifest of a published component.\n  grant       grant a new owner\n  rotate      Rotate root.json\n\nGlobal Flags:\n      --help                 Help for this command\n\nUse \"tiup mirror [command] --help\" for more information about a command.\n```\n\n----------------------------------------\n\nTITLE: Example of TiDB Expensive Query Log Entry\nDESCRIPTION: Example log entry showing an expensive query in TiDB that exceeded the threshold. The log includes details about execution time, memory usage, user information, and TiKV Coprocessor task metrics.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-expensive-queries.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n[expensivequery.go:145] [expensive_query] [cost_time=60.021998785s] [cop_time=0.022540151s] [process_time=28.448316643s] [wait_time=0.045507163s] [request_count=430] [total_keys=3538276] [process_keys=3537846] [num_cop_tasks=430] [process_avg_time=0.066158875s] [process_p90_time=0.140427865s] [process_max_time=0.27903656s] [process_max_addr=tikv-1-peer:20160] [wait_avg_time=0.00010583s] [wait_p90_time=0.000358794s] [wait_max_time=0.001218721s] [wait_max_addr=tikv-1-peer:20160] [stats=usertable:451469035823955972] [conn=1621098504] [user=root] [database=test] [table_ids=\"[104]\"] [txn_start_ts=451469037501677571] [mem_max=\"621043469 Bytes (592.3 MB)\"] [sql=\"insert /*+ SET_VAR(tidb_dml_type=bulk) */ into usertable_2 select * from usertable limit 5000000\"] [session_alias=] [\"affected rows\"=3505282]]\n```\n\n----------------------------------------\n\nTITLE: Fixing Collation Operator Panic in TiDB LEFT JOIN\nDESCRIPTION: Resolves a potential panic of the collation operator in LEFT JOIN when a null column exists in the right child node.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_17\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM table1 LEFT JOIN table2 ON table1.column = table2.nullable_column\n```\n\n----------------------------------------\n\nTITLE: Performance CPU Configuration in TiDB\nDESCRIPTION: Controls the number of CPUs used by the TiDB server, with a default of using all available CPUs on the machine.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-configuration-file.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nmax-procs: 0\n```\n\n----------------------------------------\n\nTITLE: Cloning ProxySQL Integration Example Repository\nDESCRIPTION: Git command to clone the TiDB and ProxySQL integration example code repository.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/pingcap-inc/tidb-proxysql-integration.git\n```\n\n----------------------------------------\n\nTITLE: Retrieving CREATE Statement for a Table (Shell)\nDESCRIPTION: This snippet shows how to use cURL to get the CREATE statement for a specific table in a schema associated with a replication task. It sends a GET request to the API endpoint and expects a JSON response containing the schema name, table name, and CREATE SQL statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_41\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1/sources/source-1/schemas/db1/table1' \\\n  -H 'accept: application/json'\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"schema_name\": \"db1\",\n  \"table_name\": \"table1\",\n  \"schema_create_sql\": \"CREATE TABLE `t1` (`id` int NOT NULL AUTO_INCREMENT,PRIMARY KEY (`id`) /*T![clustered_index] CLUSTERED */) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\"\n}\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud using JDBC\nDESCRIPTION: This snippet demonstrates how to connect to a TiDB Cloud Dedicated cluster using JDBC with TLS enabled. It uses the MySQL Connector/J library and requires setting the `sslMode` to `VERIFY_IDENTITY`, specifying the `tlsVersions`, and providing the path and password for a custom truststore. The truststore contains the imported CA certificate.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-tls-connect-to-dedicated.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n/* Be sure to replace the parameters in the following connection string. */\n/* version >= 8.0.28 */\njdbc:mysql://tidb.srgnqxji5bc.clusters.staging.tidb-cloud.com:4000/test?user=root&password=<your_password>&sslMode=VERIFY_IDENTITY&tlsVersions=TLSv1.2&trustCertificateKeyStoreUrl=file:<your_custom_truststore_path>&trustCertificateKeyStorePassword=<your_truststore_password>\n```\n\n----------------------------------------\n\nTITLE: Switching User Profile in TiDB Cloud CLI - Markdown\nDESCRIPTION: This snippet details the command used to switch between user profiles in the TiDB Cloud CLI. The expected output shows the successful change in active profiles, ensuring that users can manage different setups smoothly.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/cli-reference.md#2025-04-18_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\nUse [`ticloud config use`](/tidb-cloud/ticloud-config-use.md) to switch to another user profile.\n```\n\n----------------------------------------\n\nTITLE: Using -- for Line Comments in TiDB SQL\nDESCRIPTION: Shows how to use double dashes (--) to add a single-line comment to a SQL statement. This style requires at least one whitespace after the dashes to be recognized as a comment.\nSOURCE: https://github.com/pingcap/docs/blob/master/comment-syntax.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 1+1;     -- comments\n```\n\n----------------------------------------\n\nTITLE: Selecting from TIDB_TRX Table in SQL\nDESCRIPTION: This SQL snippet queries the TIDB_TRX table to list all ongoing transactions on a TiDB node, returning detailed transaction information such as state, session, and executed SQL digests. There are no special prerequisites other than access to the INFORMATION_SCHEMA.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-trx.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.TIDB_TRX\\G\n```\n\n----------------------------------------\n\nTITLE: Validating Root CA Certificate\nDESCRIPTION: Command to display the contents of the root CA certificate for validation purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nopenssl x509 -text -in root.crt -noout\n```\n\n----------------------------------------\n\nTITLE: Analyzing Insert Operator Execution in TiDB\nDESCRIPTION: This snippet shows the execution information for the `Insert` operator in TiDB. It includes metrics for prepare time, check insert time (including total time, memory insert time, prefetch time, and RPC time with BatchGet and Get), and backoff details. Understanding these metrics helps in identifying performance bottlenecks during insert operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_5\n\nLANGUAGE: None\nCODE:\n```\n\"prepare:109.616µs, check_insert:{total_time:1.431678ms, mem_insert_time:667.878µs, prefetch:763.8µs, rpc:{BatchGet:{num_rpc:1, total_time:699.166µs},Get:{num_rpc:1, total_time:378.276µs }}}\n```\n\n----------------------------------------\n\nTITLE: Loading TPC-H Additional Tables\nDESCRIPTION: Command to prepare additional tables and views required for TPC-H testing, including nation, region, supplier tables and revenue view.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-ch.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup bench ch -H 172.16.5.140 -P 4000 -D tpcc prepare\n```\n\n----------------------------------------\n\nTITLE: Editing TiDB Cluster Configuration\nDESCRIPTION: Command to open and edit the configuration file for a TiDB production cluster using TiUP's edit-config functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster edit-config prod-cluster\n```\n\n----------------------------------------\n\nTITLE: Column Data Format (Nullable)\nDESCRIPTION: Illustrates the structure of a column that can be NULL. It includes a `default` field set to null and a type that is an array containing \"null\" and the actual type information. `{{ColumnName}}` is the column name, `{{TIDB_TYPE}}` is the TiDB type, and `{{AVRO_TYPE}}` represents the Avro type.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-protocol.md#2025-04-18_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"default\":null,\n    \"name\":\"{{ColumnName}}\",\n    \"type\":[\n        \"null\",\n        {\n            \"connect.parameters\":{\n                \"tidb_type\":\"{{TIDB_TYPE}}\"\n            },\n            \"type\":\"{{AVRO_TYPE}}\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Changefeed for TiDB\nDESCRIPTION: This TOML configuration file snippet outlines settings for creating a changefeed that ensures eventual consistency with the use of redo logs in disaster scenarios. It specifies log size, flush interval, and storage location.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[consistent]\n# eventual consistency: redo logs are used to ensure eventual consistency in disaster scenarios.\nlevel = \"eventual\"\n# The size of a single redo log, in MiB. The default value is 64, and the recommended value is less than 128.\nmax-log-size = 64\n# The interval for refreshing or uploading redo logs to Amazon S3, in milliseconds. The default value is 1000, and the recommended value range is 500-2000.\nflush-interval = 2000\n# The path where redo logs are saved.\nstorage = \"s3://redo?access-key=minio&secret-access-key=miniostorage&endpoint=http://10.0.1.10:6060&force-path-style=true\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Basic TiFlash Encryption in TOML\nDESCRIPTION: Basic encryption configuration for TiFlash specifying encryption method and key rotation period in tiflash-learner.toml file.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\n[security.encryption]\ndata-encryption-method = \"aes128-ctr\"\ndata-key-rotation-period = \"168h\" # 7 days\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS for TiKV\nDESCRIPTION: This code snippet illustrates how to configure TLS settings in the TiKV configuration file, including the paths to the CA certificate, server certificate, and server key. Setting these parameters enables secure communication between TiKV and other components, ensuring data transmission is encrypted.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n\t\t```toml\n        [security]\n        ## The path for certificates. An empty string means that secure connections are disabled.\n        # Path of the file that contains a list of trusted SSL CAs. If it is set, the following settings `cert_path` and `key_path` are also needed.\n        ca-path = \"/path/to/ca.pem\"\n        # Path of the file that contains X509 certificate in PEM format.\n        cert-path = \"/path/to/tikv-server.pem\"\n        # Path of the file that contains X509 key in PEM format.\n        key-path = \"/path/to/tikv-server-key.pem\"\n        ```\n```\n\n----------------------------------------\n\nTITLE: Querying First and Last Batch Statements SQL\nDESCRIPTION: This code snippet is used to query the SQL DML statements of the first and the last batches within non-transactional DML operations in TiDB. Adding 'DRY RUN' directs the query to retrieve the batch split statements without executing them. Dependencies: TiDB environment configured correctly. Parameters include specifying 'BATCH ON' to define the batch size. Output includes SQL statements for the initial and final batches for further inspection.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nBATCH ON id LIMIT 2 DRY RUN DELETE FROM t WHERE v < 6;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------------------------------------------------+\n| split statement examples                                          |\n+-------------------------------------------------------------------+\n| DELETE FROM `test`.`t` WHERE (`id` BETWEEN 1 AND 2 AND (`v` < 6)) |\n| DELETE FROM `test`.`t` WHERE (`id` BETWEEN 3 AND 4 AND (`v` < 6)) |\n+-------------------------------------------------------------------+\n2 rows in set\n```\n\n----------------------------------------\n\nTITLE: Basic TiDB Cluster Topology Configuration\nDESCRIPTION: Sample YAML configuration defining a basic TiDB cluster topology with PD, TiDB, TiKV, and monitoring components. This template specifies host addresses, deployment directories, and user configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\nglobal:\n  user: \"tidb\"\n  ssh_port: 22\n  deploy_dir: \"/tidb-deploy\"\n  data_dir: \"/tidb-data\"\nserver_configs: {}\npd_servers:\n  - host: 10.0.1.4\n  - host: 10.0.1.5\n  - host: 10.0.1.6\ntidb_servers:\n  - host: 10.0.1.7\n  - host: 10.0.1.8\n  - host: 10.0.1.9\ntikv_servers:\n  - host: 10.0.1.1\n  - host: 10.0.1.2\n  - host: 10.0.1.3\nmonitoring_servers:\n  - host: 10.0.1.4\ngrafana_servers:\n  - host: 10.0.1.4\nalertmanager_servers:\n  - host: 10.0.1.4\n```\n\n----------------------------------------\n\nTITLE: Using TiDB Cloud CLI via TiUP\nDESCRIPTION: This snippet shows how to run the TiDB Cloud CLI through TiUP, including a command to view available subcommands.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntiup cloud --help\n```\n\n----------------------------------------\n\nTITLE: Using USE_INDEX and FORCE_INDEX Hints in TiDB SQL\nDESCRIPTION: Four equivalent ways to specify that a query should use a specific index in TiDB, using both hint-style and traditional SQL syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ USE_INDEX(t, idx1) */ * FROM t;\nSELECT /*+ FORCE_INDEX(t, idx1) */ * FROM t;\nSELECT * FROM t use index(idx1);\nSELECT * FROM t force index(idx1);\n```\n\n----------------------------------------\n\nTITLE: Loading Data with Sysbench to TiDB\nDESCRIPTION: This shell script uses Sysbench to import data into the 'sbtest' database, preparing it by creating 32 tables with 10 million rows each. The script requires configuring host, port, user thread, and password parameters to execute.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.1-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nsysbench oltp_common \\\n   --threads=${THREAD} \\\n   --db-driver=mysql \\\n   --mysql-db=sbtest \\\n   --mysql-host=${HOST} \\\n   --mysql-port=${PORT} \\\n   --mysql-user=root \\\n   --mysql-password=${PASSWORD} \\\n   prepare --tables=32 --table-size=10000000\n```\n\n----------------------------------------\n\nTITLE: JSON_SET() Result Example\nDESCRIPTION: The output shows the JSON document after applying JSON_SET() to update the 'version' value to 1.2.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-modify.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+-----------------------------------------------------------------+\n| JSON_SET('{\"version\": 1.1, \"name\": \"example\"}','$.version',1.2) |\n+-----------------------------------------------------------------+\n| {\"name\": \"example\", \"version\": 1.2}                             |\n+-----------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Database Configuration Changes for TiDB v6.6.0\nDESCRIPTION: Summary of configuration parameter updates including deletions, modifications and additions across various TiDB components. Key changes include RocksDB statistics enablement, block cache updates, telemetry defaults, and new parameters for resource control and memory management.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.6.0.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n# Deleted Parameters\nrocksdb.enable-statistics: true  # Now enabled by default\nraftdb.enable-statistics: true   # Now enabled by default\nstorage.block-cache.shared: true # Now enabled by default\non-duplicate: replace          # Replaced by on-duplicate-logical/physical\n\n# Modified Parameters\nenable-telemetry: false         # Changed default from true\nrocksdb.defaultcf.block-size: 32K  # Changed from 64K\nimport-mode: \"logical\"         # Changed values to logical/physical\n\n# New Parameters\ninitialize-sql-file: \"\"       # SQL script for first cluster start\nresource-control.enabled: false # RU-based scheduling control\nstorage.engine: \"raft-kv\"      # Storage engine type\nscheduler.region-per-span: 50000 # Region-based table splitting\n```\n\n----------------------------------------\n\nTITLE: Splitting Index Regions Across Multiple Partitions in SQL\nDESCRIPTION: This SQL snippet splits the index 'idx' of the partitions 'p1' and 'p2' of table 't' in the range [0,20000] into two regions, facilitating better index management.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_30\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT PARTITION TABLE t PARTITION (p1,p2) INDEX idx BETWEEN (0) AND (20000) REGIONS 2;\n```\n\n----------------------------------------\n\nTITLE: Exporting Data to SQL Files with Dumpling\nDESCRIPTION: Command to export data to SQL files using Dumpling with custom thread count, output directory, chunk size and file size specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup dumpling -u root -P 4000 -h 127.0.0.1 --filetype sql -t 8 -o /tmp/test -r 200000 -F 256MiB\n```\n\n----------------------------------------\n\nTITLE: Query DM Migration Task Status\nDESCRIPTION: This shell command uses `tiup dmctl` to query the status of the specified DM migration task (`${task-name}`). It connects to the DM-master at the specified address and executes the `query-status` command.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-small-mysql-to-tidb.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup dmctl --master-addr ${advertise-addr} query-status ${task-name}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Full Data Export Options in YAML\nDESCRIPTION: This snippet shows the YAML configuration for optimizing full data export in DM. It includes options for concurrent table export and chunk file size control.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-tune-configuration.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmydumpers:\n  rows: 10000\n  threads: 4\n  chunk-filesize: 64\n```\n\n----------------------------------------\n\nTITLE: Querying Cluster-wide Process Information\nDESCRIPTION: Shows how to query the CLUSTER_PROCESSLIST table which provides process information across all TiDB nodes in the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-processlist.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.cluster_processlist;\n```\n\n----------------------------------------\n\nTITLE: Creating TiDB User and Setting Password\nDESCRIPTION: Commands to create a new tidb user and set its password.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_34\n\nLANGUAGE: bash\nCODE:\n```\nuseradd tidb && \\\npasswd tidb\n```\n\n----------------------------------------\n\nTITLE: Creating Test Table for EXPLAIN ANALYZE Example\nDESCRIPTION: SQL statement to create a table named t1 with an auto-increment primary key and an integer column for testing EXPLAIN ANALYZE functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, c1 INT NOT NULL);\n```\n\n----------------------------------------\n\nTITLE: Exporting Data to Local Storage in Non-Interactive Mode\nDESCRIPTION: This command exports data from a specified cluster and database to local storage without interactive prompts. The cluster ID and database name must be provided.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-create.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export create -c <cluster-id> --database <database>\n```\n\n----------------------------------------\n\nTITLE: Describing USER_PRIVILEGES Table Structure in TiDB\nDESCRIPTION: Shows the schema structure of the USER_PRIVILEGES table including field names, data types, and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-user-privileges.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC USER_PRIVILEGES;\n```\n\n----------------------------------------\n\nTITLE: Example of FLASHBACK CLUSTER Usage in TiDB\nDESCRIPTION: Comprehensive example demonstrating the usage of FLASHBACK CLUSTER to restore newly inserted data to a previous state.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-cluster.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t(a INT);\n\nSELECT * FROM t;\n\nSELECT now();\n\nINSERT INTO t VALUES (1);\n\nSELECT * FROM t;\n\nFLASHBACK CLUSTER TO TIMESTAMP '2022-09-28 17:24:16';\n\nSELECT * FROM t;\n```\n\n----------------------------------------\n\nTITLE: Viewing Result from TIDB_PARSE_TSO_LOGICAL Function\nDESCRIPTION: Shows the output of TIDB_PARSE_TSO_LOGICAL which returns the logical component (1) of the provided TSO value.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------------------------+\n| TIDB_PARSE_TSO_LOGICAL(450456244814610433) |\n+--------------------------------------------+\n|                                          1 |\n+--------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying NIC RX Buffer Size\nDESCRIPTION: Command to check the current receive buffer size configuration of a network interface using ethtool.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nethtool -g ${NIC_DEV_NAME}\n```\n\n----------------------------------------\n\nTITLE: Deleting a Branch Using the Primary Command Syntax in Shell\nDESCRIPTION: The primary command syntax for deleting a branch from a TiDB Cloud Serverless cluster. This command initiates the branch deletion process with optional flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-delete.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch delete [flags]\n```\n\n----------------------------------------\n\nTITLE: Retrieving Full Backup Timestamp\nDESCRIPTION: Gets the timestamp of the last full backup for use in cleanup operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-guide.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nFULL_BACKUP_TS=`tiup br validate decode --field=\"end-version\" --storage \"s3://backup-101/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\"| tail -n1`\n```\n\n----------------------------------------\n\nTITLE: Query Normal State Replication Tasks\nDESCRIPTION: HTTP GET request to retrieve all replication tasks in normal state with example response showing task details including ID, state, checkpoint info.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v2/changefeeds?state=normal\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"total\": 2,\n  \"items\": [\n    {\n      \"id\": \"test\",\n      \"state\": \"normal\",\n      \"checkpoint_tso\": 439749918821711874,\n      \"checkpoint_time\": \"2023-02-27 23:46:52.888\",\n      \"error\": null\n    },\n    {\n      \"id\": \"test2\",\n      \"state\": \"normal\",\n      \"checkpoint_tso\": 439749918821711874,\n      \"checkpoint_time\": \"2023-02-27 23:46:52.888\",\n      \"error\": null\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: System Query Endpoint Configuration\nDESCRIPTION: Adding and configuring the predefined system `/system/query` endpoint that allows executing arbitrary SQL statements via an API endpoint\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-manage-endpoint.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n1. Navigate to Data Service page\n2. Select Data App\n3. Click \"Manage Endpoint Library\"\n4. Toggle \"Execute Query\" switch\n5. Save configuration\n6. Configure timeout and max rows\n7. Write dynamic SQL statements\n```\n\n----------------------------------------\n\nTITLE: Query Task Completion Status\nDESCRIPTION: HTTP GET request to check if a specific replication task is completed, with example responses for different states.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v2/changefeeds/test1/synced\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"synced\": true,\n  \"sink_checkpoint_ts\": \"2023-11-30 15:14:11.015\",\n  \"puller_resolved_ts\": \"2023-11-30 15:14:12.215\",\n  \"last_synced_ts\": \"2023-11-30 15:08:35.510\",\n  \"now_ts\": \"2023-11-30 15:14:11.511\",\n  \"info\": \"Data syncing is finished\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining TableVersionConsumer in Golang\nDESCRIPTION: This snippet defines the `TableVersionConsumer` struct that processes data for specific versions of a table including its own checkpoint management. The `ExecuteDML` method is responsible for data handling and validation against the checkpoint.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-storage-consumer-dev-guide.md#2025-04-18_snippet_3\n\nLANGUAGE: go\nCODE:\n```\ntype TableVersionConsumer struct {\n  // This checkpoint indicates where the TableVersionConsumer has consumed.\n  // Its initial value is TableConsumer.Checkpoint.\n  Checkpoint int64\n\n  schema,table,version string\n  // For the same table version, data in different partitions can be consumed concurrently.\n  # partitionNum int64\n  // Must be consumed sequentially according to the data file number.\n  fileSet map[filename string]*TableVersionConsumer\n  currentVersion\n}\n// If data commit ts is less than TableConsumer.Checkpoint\n// or bigger than ConsumerManager.StorageCheckpoint,\n// - ignore this data.\n// Otherwise,\n// - process this data and write it to MySQL.\nfunc (tc *TableVersionConsumer) ExecuteDML() {}\n```\n\n----------------------------------------\n\nTITLE: Simulating Write Skew in Doctor Shift Management (Go)\nDESCRIPTION: This Go code demonstrates a write skew scenario in a doctor shift management system using TiDB. It simulates two doctors attempting to take sick leave simultaneously, potentially violating the constraint of having at least one doctor on call.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-restraints.md#2025-04-18_snippet_1\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n    \"database/sql\"\n    \"fmt\"\n    \"sync\"\n\n    \"github.com/pingcap-inc/tidb-example-golang/util\"\n\n    _ \"github.com/go-sql-driver/mysql\"\n)\n\nfunc main() {\n    openDB(\"mysql\", \"root:@tcp(127.0.0.1:4000)/test\", func(db *sql.DB) {\n        writeSkew(db)\n    })\n}\n\nfunc openDB(driverName, dataSourceName string, runnable func(db *sql.DB)) {\n    db, err := sql.Open(driverName, dataSourceName)\n    if err != nil {\n        panic(err)\n    }\n    defer db.Close()\n\n    runnable(db)\n}\n\nfunc writeSkew(db *sql.DB) {\n    err := prepareData(db)\n    if err != nil {\n        panic(err)\n    }\n\n    waitingChan, waitGroup := make(chan bool), sync.WaitGroup{}\n\n    waitGroup.Add(1)\n    go func() {\n        defer waitGroup.Done()\n        err = askForLeave(db, waitingChan, 1, 1)\n        if err != nil {\n            panic(err)\n        }\n    }()\n\n    waitGroup.Add(1)\n    go func() {\n        defer waitGroup.Done()\n        err = askForLeave(db, waitingChan, 2, 2)\n        if err != nil {\n            panic(err)\n        }\n    }()\n\n    waitGroup.Wait()\n}\n\nfunc askForLeave(db *sql.DB, waitingChan chan bool, goroutineID, doctorID int) error {\n    txnComment := fmt.Sprintf(\"/* txn %d */ \", goroutineID)\n    if goroutineID != 1 {\n        txnComment = \"\\t\" + txnComment\n    }\n\n    txn, err := util.TiDBSqlBegin(db, true)\n    if err != nil {\n        return err\n    }\n    fmt.Println(txnComment + \"start txn\")\n\n    // Txn 1 should be waiting until txn 2 is done.\n    if goroutineID == 1 {\n        <-waitingChan\n    }\n\n    txnFunc := func() error {\n        queryCurrentOnCall := \"SELECT COUNT(*) AS `count` FROM `doctors` WHERE `on_call` = ? AND `shift_id` = ?\"\n        rows, err := txn.Query(queryCurrentOnCall, true, 123)\n        if err != nil {\n            return err\n        }\n        defer rows.Close()\n        fmt.Println(txnComment + queryCurrentOnCall + \" successful\")\n\n        count := 0\n        if rows.Next() {\n            err = rows.Scan(&count)\n            if err != nil {\n                return err\n            }\n        }\n        rows.Close()\n\n        if count < 2 {\n            return fmt.Errorf(\"at least one doctor is on call\")\n        }\n\n        shift := \"UPDATE `doctors` SET `on_call` = ? WHERE `id` = ? AND `shift_id` = ?\"\n        _, err = txn.Exec(shift, false, doctorID, 123)\n        if err == nil {\n            fmt.Println(txnComment + shift + \" successful\")\n        }\n        return err\n    }\n\n    err = txnFunc()\n    if err == nil {\n        txn.Commit()\n        fmt.Println(\"[runTxn] commit success\")\n    } else {\n        txn.Rollback()\n        fmt.Printf(\"[runTxn] got an error, rollback: %+v\\n\", err)\n    }\n\n    // Txn 2 is done. Let txn 1 run again.\n    if goroutineID == 2 {\n        waitingChan <- true\n    }\n\n    return nil\n}\n\nfunc prepareData(db *sql.DB) error {\n    err := createDoctorTable(db)\n    if err != nil {\n        return err\n    }\n\n    err = createDoctor(db, 1, \"Alice\", true, 123)\n    if err != nil {\n        return err\n    }\n    err = createDoctor(db, 2, \"Bob\", true, 123)\n    if err != nil {\n        return err\n    }\n    err = createDoctor(db, 3, \"Carol\", false, 123)\n    if err != nil {\n        return err\n    }\n    return nil\n}\n\nfunc createDoctorTable(db *sql.DB) error {\n    _, err := db.Exec(\"CREATE TABLE IF NOT EXISTS `doctors` (\" +\n        \"    `id` int NOT NULL,\" +\n        \"    `name` varchar(255) DEFAULT NULL,\" +\n        \"    `on_call` tinyint DEFAULT NULL,\" +\n        \"    `shift_id` int DEFAULT NULL,\" +\n        \"    PRIMARY KEY (`id`),\" +\n        \"    KEY `idx_shift_id` (`shift_id`)\" +\n        \"  ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\")\n    return err\n}\n\nfunc createDoctor(db *sql.DB, id int, name string, onCall bool, shiftID int) error {\n    _, err := db.Exec(\"INSERT INTO `doctors` (`id`, `name`, `on_call`, `shift_id`) VALUES (?, ?, ?, ?)\",\n```\n\n----------------------------------------\n\nTITLE: Configuring Prometheus monitoring_servers in TiDB Cluster\nDESCRIPTION: Configuration example for setting up Prometheus monitoring services in a TiDB cluster, including remote writing/reading configuration and external alertmanagers. This shows how to specify the host, rule directory, and remote monitoring integrations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-dm-topology-reference.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nmonitoring_servers:\n  - host: 10.0.1.11\n    rule_dir: /local/rule/dir\n    remote_config:\n      remote_write:\n      - queue_config:\n          batch_send_deadline: 5m\n          capacity: 100000\n          max_samples_per_send: 10000\n          max_shards: 300\n        url: http://127.0.0.1:8003/write\n      remote_read:\n      - url: http://127.0.0.1:8003/read\\\n      external_alertmanagers:\n      - host: 10.1.1.1\n      web_port: 9093\n      - host: 10.1.1.2\n      web_port: 9094\n```\n\n----------------------------------------\n\nTITLE: Configuring sync-diff-inspector Configuration File\nDESCRIPTION: Example TOML configuration file for sync-diff-inspector with comprehensive settings for database sources, routes, tasks, and table configurations\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/sync-diff-inspector-overview.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n# Diff Configuration.\n\n######################### Global config #########################\ncheck-thread-count = 4\n\nexport-fix-sql = true\n\ncheck-data-only = false\n\ncheck-struct-only = false\n\nnskip-non-existing-table = false\n\n######################### Datasource config #########################\n[data-sources]\n[data-sources.mysql1]\n    host = \"127.0.0.1\"\n    port = 3306\n    user = \"root\"\n    password = \"\"\n\n    route-rules = [\"rule1\", \"rule2\"]\n\n[data-sources.tidb0]\n    host = \"127.0.0.1\"\n    port = 4000\n    user = \"root\"\n    password = \"\"\n\n########################### Routes ##############################\n[routes]\n[routes.rule1]\n    schema-pattern = \"test_*\"\n    table-pattern = \"t_*\"\n    target-schema = \"test\"\n    target-table = \"t\"\n\n######################### task config #########################\n[task]\n    output-dir = \"./output\"\n    source-instances = [\"mysql1\"]\n    target-instance = \"tidb0\"\n    target-check-tables = [\"schema*.table*\", \"!c.*\", \"test2.t2\"]\n    target-configs = [\"config1\"]\n\n######################### Table config #########################\n[table-configs.config1]\n    target-tables = [\"schema*.test*\", \"test2.t2\"]\n```\n\n----------------------------------------\n\nTITLE: Start Chat2Query Session with API\nDESCRIPTION: This snippet demonstrates how to start a Chat2Query session using the `/v3/sessions` endpoint. It uses a curl command to send a POST request with authentication details, cluster ID, database name, and a session name to the TiDB Cloud API. The response includes a session ID used for subsequent interactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-sessions.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user ${PUBLIC_KEY}:${PRIVATE_KEY} --request POST 'https://<region>.data.tidbcloud.com/api/v1beta/app/chat2query-<ID>/endpoint/v3/sessions'\\\n    --header 'content-type: application/json'\\\n    --data-raw '{\n    \"cluster_id\": \"10140100115280519574\",\n    \"database\": \"sp500insight\",\n    \"name\": \"<Your session name>\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Stopping and Removing MySQL on Ubuntu\nDESCRIPTION: In this snippet, commands are provided for stopping the MySQL service and completely removing it from an Ubuntu system. This aids in the cleanup process post-testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nsudo systemctl stop mysql\n sudo apt-get remove --purge -y mysql-server\n sudo apt-get autoremove -y\n```\n\n----------------------------------------\n\nTITLE: Setting the ulimit parameter\nDESCRIPTION: This command sets the `ulimit` parameter, which controls the maximum number of open file descriptors, to 1000000. A sufficiently high `ulimit` value is crucial for TiFlash's proper functioning and stability.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n```shell\nulimit -n 1000000\n```\n```\n\n----------------------------------------\n\nTITLE: SET RESOURCE GROUP EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the SET RESOURCE GROUP statement, showing the statement structure and allowed resource group name formats.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-resource-group.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nSetResourceGroupStmt ::=\n    \"SET\" \"RESOURCE\" \"GROUP\" ResourceGroupName\n\nResourceGroupName ::=\n    Identifier\n|   \"DEFAULT\"\n```\n\n----------------------------------------\n\nTITLE: Setting CN Region for Diag\nDESCRIPTION: Command to configure Diag to use CN (China) region for data upload and encryption\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag config clinic.region CN\n```\n\n----------------------------------------\n\nTITLE: Creating Incremental Backups in TiDB\nDESCRIPTION: Examples of incremental backups by providing the LAST_BACKUP parameter to only back up changes since the previous backup.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-backup.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n-- timestamp (in current time zone)\nBACKUP DATABASE `test` TO 'local:///mnt/backup/hist02'\n    LAST_BACKUP = '2020-04-01 12:00:00';\n\n-- timestamp oracle\nBACKUP DATABASE `test` TO 'local:///mnt/backup/hist03'\n    LAST_BACKUP = 415685305958400;\n```\n\n----------------------------------------\n\nTITLE: Running Transaction Example in Java\nDESCRIPTION: Shell command to compile and run the Java transaction example with Alice buying 4 books and Bob buying 7 books from a limited inventory of 10 books.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nmvn clean package\njava -jar target/plain-java-txn-0.0.1-jar-with-dependencies.jar ALICE_NUM=4 BOB_NUM=7\n```\n\n----------------------------------------\n\nTITLE: Edge Function Implementation with Next.js\nDESCRIPTION: TypeScript code for implementing an edge function using Next.js, Drizzle ORM, and TiDB Cloud serverless driver.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-drizzle-example.md#2025-04-18_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\nimport { connect } from '@tidbcloud/serverless';\nimport { drizzle } from 'drizzle-orm/tidb-serverless';\nimport { mysqlTable, serial, text, varchar } from 'drizzle-orm/mysql-core';\nexport const runtime = 'edge';\n\n// Initialize\nconst client = connect({ url: process.env.DATABASE_URL });\nconst db = drizzle(client);\n\n// Define schema\nexport const users = mysqlTable('users', {\n  id: serial(\"id\").primaryKey(),\n  fullName: text('full_name'),\n  phone: varchar('phone', { length: 256 }),\n});\nexport type User = typeof users.$inferSelect; // return type when queried\nexport type NewUser = typeof users.$inferInsert; // insert type\n\nexport async function GET(request: NextRequest) {\n  // Insert and select data\n  const user: NewUser = { fullName: 'John Doe', phone: '123-456-7890' };\n  await db.insert(users).values(user)\n  const result: User[] = await db.select().from(users);\n  return NextResponse.json(result);\n}\n```\n\n----------------------------------------\n\nTITLE: Column Data Format (Basic)\nDESCRIPTION: Shows the basic structure of a column data format with name, type, connect parameters, and Avro type. It describes how column metadata is represented when a column is not nullable.  `{{ColumnName}}` is a placeholder for the actual column name, `{{TIDB_TYPE}}` for the TiDB type, and `{{AVRO_TYPE}}` for the Avro type.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-protocol.md#2025-04-18_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\":\"{{ColumnName}}\",\n    \"type\":{\n        \"connect.parameters\":{\n            \"tidb_type\":\"{{TIDB_TYPE}}\"\n        },\n        \"type\":\"{{AVRO_TYPE}}\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using AUTO_RANDOM_BASE in CREATE TABLE\nDESCRIPTION: Reference to AUTO_RANDOM_BASE parameter used in CREATE TABLE statements to set the initial incremental part value of auto_random. This is considered an internal interface parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-random.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE ... AUTO_RANDOM_BASE\n```\n\n----------------------------------------\n\nTITLE: Checking TiFlash Replication Status\nDESCRIPTION: SQL query to check the replication status of TiFlash replicas for all tables in the tpcc database.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-ch.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = 'tpcc';\n```\n\n----------------------------------------\n\nTITLE: Fixing View Column Selection in TiDB\nDESCRIPTION: Resolves an error when executing 'SELECT view_name.col_name FROM view_name' statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_32\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT view_name.column_name FROM view_name\n```\n\n----------------------------------------\n\nTITLE: Preparing Offline TiUP Package - Shell\nDESCRIPTION: This command describes how to send the required offline component packages necessary for deploying a TiDB cluster. It includes tar commands to create the required packages.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntar czvf tidb-community-server-${version}-linux-amd64.tar.gz tidb-community-server-${version}-linux-amd64\n```\n\nLANGUAGE: shell\nCODE:\n```\ntar czvf tidb-community-toolkit-${version}-linux-amd64.tar.gz tidb-community-toolkit-${version}-linux-amd64\n```\n\n----------------------------------------\n\nTITLE: Modifying PD Configuration via pd-ctl\nDESCRIPTION: This shell command is used to modify the `location-labels` configuration for a PD cluster that has already been initialized, allowing dynamic updates to the configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/schedule-replicas-by-topology-labels.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npd-ctl config set location-labels zone,rack,host\n```\n\n----------------------------------------\n\nTITLE: Disabling Accelerated Table Creation in TiDB\nDESCRIPTION: Sets the global system variable tidb_enable_fast_create_table to OFF to disable performance optimization for creating tables, reverting to the standard table creation behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/accelerated-table-creation.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_fast_create_table = OFF;\n```\n\n----------------------------------------\n\nTITLE: Removing a User Account in TiDB\nDESCRIPTION: Remove a user account using the DROP USER statement, which deletes the user records from mysql.user table and related privilege tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nDROP USER 'test'@'localhost';\n```\n\n----------------------------------------\n\nTITLE: Updating TiDB Tools Version Using TiUP\nDESCRIPTION: This command installs the control tools (ctl component) for a specific TiDB version using TiUP. It allows updating tools like pd-ctl after upgrading the main TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ntiup install ctl:v8.5.0\n```\n\n----------------------------------------\n\nTITLE: First Possible Result with NON-FULL GROUP BY\nDESCRIPTION: One potential result set from the NON-FULL GROUP BY query, showing an arbitrary selection of student names for each class. This demonstrates the instability when non-aggregated columns aren't included in the GROUP BY clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-unstable-result-set.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+------------+--------------+------------------------+\n| class      | stuname      | max( `b`.`courscore` ) |\n+------------+--------------+------------------------+\n| 2018_CS_01 | MonkeyDLuffy |                   95.5 |\n| 2018_CS_03 | PatrickStar  |                   99.0 |\n+------------+--------------+------------------------+\n```\n\n----------------------------------------\n\nTITLE: Configuring Monitoring Servers with Remote Write and Alertmanagers in YAML\nDESCRIPTION: Example configuration for monitoring_servers showing Prometheus setup with remote write/read capabilities, custom rules directory, and external alertmanagers configuration. Includes additional arguments for Prometheus execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\nmonitoring_servers:\n  - host: 10.0.1.11\n    rule_dir: /local/rule/dir\n    additional_args:\n    - --web.enable-lifecycle\n    remote_config:\n      remote_write:\n      - queue_config:\n          batch_send_deadline: 5m\n          capacity: 100000\n          max_samples_per_send: 10000\n          max_shards: 300\n        url: http://127.0.0.1:8003/write\n      remote_read:\n      - url: http://127.0.0.1:8003/read\n      external_alertmanagers:\n      - host: 10.1.1.1\n        web_port: 9093\n      - host: 10.1.1.2\n        web_port: 9094\n```\n\n----------------------------------------\n\nTITLE: Checking Trust Entity Configuration in IAM Role\nDESCRIPTION: This JSON snippet represents a sample trust entity used in an IAM role that allows TiDB Cloud to assume the role. It includes necessary identifiers like the TiDB Cloud Account ID and External ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/troubleshoot-import-access-denied-error.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::380838443567:root\"\n            },\n            \"Action\": \"sts:AssumeRole\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"sts:ExternalId\": \"696e6672612d617069a79c22fa5740944bf8bb32e4a0c4e3fe\"\n                }\n            }\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Expanded Form of INTERVAL Partitioned Table in SQL\nDESCRIPTION: The expanded form of the employees table with Range INTERVAL partitioning, showing how TiDB automatically creates multiple partitions based on the interval value. This demonstrates the resulting table structure.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `employees` (\n  `id` int unsigned NOT NULL,\n  `fname` varchar(30) DEFAULT NULL,\n  `lname` varchar(30) DEFAULT NULL,\n  `hired` date NOT NULL DEFAULT '1970-01-01',\n  `separated` date DEFAULT '9999-12-31',\n  `job_code` int DEFAULT NULL,\n  `store_id` int NOT NULL\n)\nPARTITION BY RANGE (`id`)\n(PARTITION `P_LT_100` VALUES LESS THAN (100),\n PARTITION `P_LT_200` VALUES LESS THAN (200),\n...\n PARTITION `P_LT_9900` VALUES LESS THAN (9900),\n PARTITION `P_LT_10000` VALUES LESS THAN (10000),\n PARTITION `P_MAXVALUE` VALUES LESS THAN (MAXVALUE))\n```\n\n----------------------------------------\n\nTITLE: Configuring DM-master Servers in YAML\nDESCRIPTION: Example configuration for DM-master servers in TiDB Data Migration. It specifies deployment details, network ports, directory paths, and custom configurations for multiple master instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-dm-topology-reference.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nmaster_servers:\n  - host: 10.0.1.11\n    name: master1\n    ssh_port: 22\n    port: 8261\n    peer_port: 8291\n    deploy_dir: \"/dm-deploy/dm-master-8261\"\n    data_dir: \"/dm-data/dm-master-8261\"\n    log_dir: \"/dm-deploy/dm-master-8261/log\"\n    numa_node: \"0,1\"\n    # The following configs are used to overwrite the `server_configs.master` values.\n    config:\n      log-level: info\n      rpc-timeout: \"30s\"\n      rpc-rate-limit: 10.0\n      rpc-rate-burst: 40\n  - host: 10.0.1.18\n    name: master2\n  - host: 10.0.1.19\n    name: master3\n```\n\n----------------------------------------\n\nTITLE: EXPLAIN Queries Demonstrating IndexJoin and Apply Operators\nDESCRIPTION: SQL queries showcasing different join and subquery scenarios to illustrate EXPLAIN output and row estimation changes in TiDB versions\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-overview.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT /*+ INL_JOIN(t2) */ * FROM t1 JOIN t2 ON t1.a = t2.a;\nEXPLAIN SELECT (SELECT a FROM t2 WHERE t2.a = t1.b LIMIT 1) FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Setting Prefill For Recycle Configuration in TiKV - YAML\nDESCRIPTION: This YAML snippet configures the 'prefill-for-recycle' parameter in TiKV to control log recycling behavior. Depending on the workload, this parameter can affect performance, especially for write-heavy operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nraft-engine.prefill-for-recycle = false\n```\n\nLANGUAGE: yaml\nCODE:\n```\nraft-engine.prefill-for-recycle = true\n```\n\n----------------------------------------\n\nTITLE: Canceling Export Task in Non-Interactive Mode\nDESCRIPTION: Example of canceling an export task in non-interactive mode. This requires specifying the cluster ID and export task ID using flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-cancel.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export cancel -c <cluster-id> -e <export-id>\n```\n\n----------------------------------------\n\nTITLE: Querying Deadlocks Information in TiDB\nDESCRIPTION: This SQL query retrieves information about recent deadlock errors from the information_schema.deadlocks table, showing the waiting relationships, SQL statements, and keys involved in deadlocks.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-lock-conflicts.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nselect * from information_schema.deadlocks;\n```\n\n----------------------------------------\n\nTITLE: Enabling Automatic Repair for TiDB Cluster\nDESCRIPTION: This command enables automatic repair of the potential risks identified during the cluster check. It attempts to automatically resolve the identified issues to facilitate a smooth scaling process.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster check <cluster-name> scale-out.yml --cluster --apply --user root [-p] [-i /home/root/.ssh/gcp_rsa]\"\n```\n\n----------------------------------------\n\nTITLE: SHOW PRIVILEGES Statement Syntax Definition\nDESCRIPTION: Defines the EBNF syntax for the SHOW PRIVILEGES statement in TiDB, representing the basic structure of executing the command with no additional parameters\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-privileges.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowPrivilegesStmt ::=\n    \"SHOW\" \"PRIVILEGES\"\n```\n\n----------------------------------------\n\nTITLE: Querying Other Unexpected Errors from TiProxy Traffic Replay Database - SQL\nDESCRIPTION: This SQL query fetches the first row from the `other_errors` table in the `tiproxy_traffic_replay` database. It can help identify unexpected errors encountered during replay.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-traffic-replay.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM tiproxy_traffic_replay.other_errors LIMIT 1\\G\n```\n\n----------------------------------------\n\nTITLE: Transferring Data Source to Different Worker with cURL in Shell\nDESCRIPTION: This example demonstrates how to change the bindings between a data source and DM-workers. The request specifies the target worker to which the source should be transferred.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'POST' \\\n  'http://127.0.0.1:8261/api/v1/sources/mysql-01/transfer' \\\n  -H 'accept: */*' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"worker_name\": \"worker-1\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Identifying Problematic Locks in TiKV Log\nDESCRIPTION: This log entry shows information about locks with the minimum start timestamp in the resolver. It includes the keys affected and the start timestamp of the transaction, which is crucial for tracing the source of stale read issues in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-stale-read.md#2025-04-18_snippet_4\n\nLANGUAGE: log\nCODE:\n```\n[2023/07/17 21:16:44.257 +08:00] [INFO] [resolver.rs:213] [\"locks with the minimum start_ts in resolver\"] [keys=\"[74800000000000006A5F7280000000000405F6, ... , 74800000000000006A5F72800000000000EFF6, 74800000000000006A5F7280000000000721D9, 74800000000000006A5F72800000000002F691]\"] [start_ts=442918429687808001] [region_id=3121]\n```\n\n----------------------------------------\n\nTITLE: Schema Capture Configuration for File Patterns in TiDB Lightning\nDESCRIPTION: Configuration for capturing schema name from regex pattern matching. The $1 refers to the first capture group in the pattern expression used for parsing files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\n'$1'\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Cloud Serverless Driver with npm\nDESCRIPTION: npm command to install the TiDB Cloud serverless driver package in the Node.js project.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-node-example.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nnpm install @tidbcloud/serverless\n```\n\n----------------------------------------\n\nTITLE: Configuring TiCDC Changefeed for Kafka with Debezium Protocol\nDESCRIPTION: Example command to create a TiCDC changefeed that uses the Debezium protocol to send changes to Kafka. It specifies the CDC server, changefeed ID, and sink URI with Kafka configuration and protocol set to Debezium.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-debezium.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://127.0.0.1:8300 --changefeed-id=\"kafka-debezium\" --sink-uri=\"kafka://127.0.0.1:9092/topic-name?kafka-version=2.4.0&protocol=debezium\"\n```\n\n----------------------------------------\n\nTITLE: Formatting Disk Partition with ext4 for TiKV\nDESCRIPTION: Command to format the newly created partition with the ext4 filesystem, which is recommended for TiKV data storage in production environments.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkfs.ext4 /dev/nvme0n1p1\n```\n\n----------------------------------------\n\nTITLE: TIFLASH_TABLES Table Structure Output\nDESCRIPTION: This snippet shows the output of the DESC command on the TIFLASH_TABLES table, listing all 54 fields with their respective types, null constraints, keys, default values, and extra information.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tiflash-tables.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------------------------+--------------+------+------+---------+-------+\n| Field                                     | Type         | Null | Key  | Default | Extra |\n+-------------------------------------------+--------------+------+------+---------+-------+\n| DATABASE                                  | varchar(64)  | YES  |      | NULL    |       |\n| TABLE                                     | varchar(64)  | YES  |      | NULL    |       |\n| TIDB_DATABASE                             | varchar(64)  | YES  |      | NULL    |       |\n| TIDB_TABLE                                | varchar(64)  | YES  |      | NULL    |       |\n| TABLE_ID                                  | bigint(64)   | YES  |      | NULL    |       |\n| IS_TOMBSTONE                              | bigint(64)   | YES  |      | NULL    |       |\n| SEGMENT_COUNT                             | bigint(64)   | YES  |      | NULL    |       |\n| TOTAL_ROWS                                | bigint(64)   | YES  |      | NULL    |       |\n| TOTAL_SIZE                                | bigint(64)   | YES  |      | NULL    |       |\n| TOTAL_DELETE_RANGES                       | bigint(64)   | YES  |      | NULL    |       |\n| DELTA_RATE_ROWS                           | double       | YES  |      | NULL    |       |\n| DELTA_RATE_SEGMENTS                       | double       | YES  |      | NULL    |       |\n| DELTA_PLACED_RATE                         | double       | YES  |      | NULL    |       |\n| DELTA_CACHE_SIZE                          | bigint(64)   | YES  |      | NULL    |       |\n| DELTA_CACHE_RATE                          | double       | YES  |      | NULL    |       |\n| DELTA_CACHE_WASTED_RATE                   | double       | YES  |      | NULL    |       |\n| DELTA_INDEX_SIZE                          | bigint(64)   | YES  |      | NULL    |       |\n| AVG_SEGMENT_ROWS                          | double       | YES  |      | NULL    |       |\n| AVG_SEGMENT_SIZE                          | double       | YES  |      | NULL    |       |\n| DELTA_COUNT                               | bigint(64)   | YES  |      | NULL    |       |\n| TOTAL_DELTA_ROWS                          | bigint(64)   | YES  |      | NULL    |       |\n| TOTAL_DELTA_SIZE                          | bigint(64)   | YES  |      | NULL    |       |\n| AVG_DELTA_ROWS                            | double       | YES  |      | NULL    |       |\n| AVG_DELTA_SIZE                            | double       | YES  |      | NULL    |       |\n| AVG_DELTA_DELETE_RANGES                   | double       | YES  |      | NULL    |       |\n| STABLE_COUNT                              | bigint(64)   | YES  |      | NULL    |       |\n| TOTAL_STABLE_ROWS                         | bigint(64)   | YES  |      | NULL    |       |\n| TOTAL_STABLE_SIZE                         | bigint(64)   | YES  |      | NULL    |       |\n| TOTAL_STABLE_SIZE_ON_DISK                 | bigint(64)   | YES  |      | NULL    |       |\n| AVG_STABLE_ROWS                           | double       | YES  |      | NULL    |       |\n| AVG_STABLE_SIZE                           | double       | YES  |      | NULL    |       |\n| TOTAL_PACK_COUNT_IN_DELTA                 | bigint(64)   | YES  |      | NULL    |       |\n| MAX_PACK_COUNT_IN_DELTA                   | bigint(64)   | YES  |      | NULL    |       |\n| AVG_PACK_COUNT_IN_DELTA                   | double       | YES  |      | NULL    |       |\n| AVG_PACK_ROWS_IN_DELTA                    | double       | YES  |      | NULL    |       |\n| AVG_PACK_SIZE_IN_DELTA                    | double       | YES  |      | NULL    |       |\n| TOTAL_PACK_COUNT_IN_STABLE                | bigint(64)   | YES  |      | NULL    |       |\n| AVG_PACK_COUNT_IN_STABLE                  | double       | YES  |      | NULL    |       |\n| AVG_PACK_ROWS_IN_STABLE                   | double       | YES  |      | NULL    |       |\n| AVG_PACK_SIZE_IN_STABLE                   | double       | YES  |      | NULL    |       |\n| STORAGE_STABLE_NUM_SNAPSHOTS              | bigint(64)   | YES  |      | NULL    |       |\n| STORAGE_STABLE_OLDEST_SNAPSHOT_LIFETIME   | double       | YES  |      | NULL    |       |\n| STORAGE_STABLE_OLDEST_SNAPSHOT_THREAD_ID  | bigint(64)   | YES  |      | NULL    |       |\n| STORAGE_STABLE_OLDEST_SNAPSHOT_TRACING_ID | varchar(128) | YES  |      | NULL    |       |\n| STORAGE_DELTA_NUM_SNAPSHOTS               | bigint(64)   | YES  |      | NULL    |       |\n| STORAGE_DELTA_OLDEST_SNAPSHOT_LIFETIME    | double       | YES  |      | NULL    |       |\n| STORAGE_DELTA_OLDEST_SNAPSHOT_THREAD_ID   | bigint(64)   | YES  |      | NULL    |       |\n| STORAGE_DELTA_OLDEST_SNAPSHOT_TRACING_ID  | varchar(128) | YES  |      | NULL    |       |\n| STORAGE_META_NUM_SNAPSHOTS                | bigint(64)   | YES  |      | NULL    |       |\n| STORAGE_META_OLDEST_SNAPSHOT_LIFETIME     | double       | YES  |      | NULL    |       |\n| STORAGE_META_OLDEST_SNAPSHOT_THREAD_ID    | bigint(64)   | YES  |      | NULL    |       |\n| STORAGE_META_OLDEST_SNAPSHOT_TRACING_ID   | varchar(128) | YES  |      | NULL    |       |\n| BACKGROUND_TASKS_LENGTH                   | bigint(64)   | YES  |      | NULL    |       |\n| TIFLASH_INSTANCE                          | varchar(64)  | YES  |      | NULL    |       |\n+-------------------------------------------+--------------+------+------+---------+-------+\n54 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Default Placement Rules Configuration JSON\nDESCRIPTION: This JSON shows the default Placement Rules configuration. It defines a single rule with 'role: voter' and 'count: 3', meaning data is stored on three nodes as voting replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/readonly-nodes.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"group_id\": \"pd\",\n    \"group_index\": 0,\n    \"group_override\": false,\n    \"rules\": [\n      {\n        \"group_id\": \"pd\",\n        \"id\": \"default\",\n        \"start_key\": \"\",\n        \"end_key\": \"\",\n        \"role\": \"voter\",\n        \"count\": 3\n      }\n    ]\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Specifying Query Blocks in Optimizer Hints - SQL\nDESCRIPTION: This snippet illustrates how to specify query block names in optimizer hints to control their effective scope within a complex SQL statement. The syntax enhances clarity when multiple tables share the same name or alias. This is meant to improve the optimizer's execution of the query.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ HASH_JOIN(@sel_1 t1@sel_1, t3) */ * FROM (SELECT t1.a, t1.b FROM t t1, t t2 WHERE t1.a = t2.a) t1, t t3 WHERE t1.b = t3.b;\n```\n\n----------------------------------------\n\nTITLE: Upgrading Prometheus with TiUP\nDESCRIPTION: Command to upgrade Prometheus in the TiDB cluster using TiUP\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-monitoring-services.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster patch <cluster-name> prometheus-v{new-version}.tar.gz -R prometheus --overwrite\n```\n\n----------------------------------------\n\nTITLE: Troubleshooting TiDB Cloud Data Import Issues\nDESCRIPTION: Common troubleshooting steps for resolving data import issues in TiDB Cloud, including handling warnings and addressing zero rows in imported tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-csv-files.md#2025-04-18_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n### Resolve warnings during data import\n\nAfter clicking **Start Import**, if you see a warning message such as `can't find the corresponding source files`, resolve this by providing the correct source file, renaming the existing one according to [Naming Conventions for Data Import](/tidb-cloud/naming-conventions-for-data-import.md), or using **Advanced Settings** to make changes.\n\nAfter resolving these issues, you need to import the data again.\n\n### Zero rows in the imported tables\n\nAfter the import progress shows **Completed**, check the imported tables. If the number of rows is zero, it means no data files matched the Bucket URI that you entered. In this case, resolve this issue by providing the correct source file, renaming the existing one according to [Naming Conventions for Data Import](/tidb-cloud/naming-conventions-for-data-import.md), or using **Advanced Settings** to make changes. After that, import those tables again.\n```\n\n----------------------------------------\n\nTITLE: Output Structure of tidb_mdl_view\nDESCRIPTION: The following output represents the structure of the tidb_mdl_view, showing types, nullability, primary keys, and default values for each field intended for use by database administrators and developers working with metadata locks.\nSOURCE: https://github.com/pingcap/docs/blob/master/mysql-schema/mysql-schema-tidb-mdl-view.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"+-------------+-----------------+------+------+---------+-------+\\n| Field       | Type            | Null | Key  | Default | Extra |\\n+-------------+-----------------+------+------+---------+-------+\\n| job_id      | bigint          | NO   | PRI  | NULL    |       |\\n| db_name     | longtext        | YES  |      | NULL    |       |\\n| table_name  | longtext        | YES  |      | NULL    |       |\\n| query       | longtext        | YES  |      | NULL    |       |\\n| session_id  | bigint unsigned | YES  |      | NULL    |       |\\n| start_time  | timestamp(6)    | YES  |      | NULL    |       |\\n| SQL_DIGESTS | varchar(5)      | YES  |      | NULL    |       |\\n+-------------+-----------------+------+------+---------+-------+\\n7 rows in set (0.00 sec)\"\n```\n\n----------------------------------------\n\nTITLE: Enabling TiDB Lightning Server Mode via Command Line\nDESCRIPTION: Command to start TiDB Lightning in server mode using the tiup command with the --server-mode flag and specifying a status address port.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-web-interface.md#2025-04-18_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ntiup tidb-lightning --server-mode --status-addr :8289\n```\n\n----------------------------------------\n\nTITLE: PD Pending Peer Region Count Alert Query\nDESCRIPTION: PromQL query to monitor the number of Regions with lagged Raft logs\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_11\n\nLANGUAGE: promql\nCODE:\n```\n(sum(pd_regions_status{type=\"pending-peer-region-count\"}) by (instance) > 100) and (sum(etcd_server_is_leader) by (instance) > 0)\n```\n\n----------------------------------------\n\nTITLE: Enabling Level Merge in Titan\nDESCRIPTION: Configuration to enable experimental Level Merge feature to improve range query performance and reduce GC impact\nSOURCE: https://github.com/pingcap/docs/blob/master/storage-engine/titan-configuration.md#2025-04-18_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n[rocksdb.defaultcf.titan]\nlevel-merge = true\n```\n\n----------------------------------------\n\nTITLE: Setting New Thread Configuration\nDESCRIPTION: Sets tidb_max_tiflash_threads to 20, which will result in 60 total threads across 3 TiFlash instances (20 threads × 3 instances).\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nmysql> set @@tidb_max_tiflash_threads = 20;\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Filtering tables to replicate using table filter rules in TiDB Cloud\nDESCRIPTION: This snippet describes the usage of table filter rules in TiDB Cloud changefeeds. It includes information on defining rules, replicating all tables (`*.*`), and excluding specific tables using a rule such as `!test.tbl1`. It's important to have valid keys (primary or unique) for data consistency or exclude tables without them.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/changefeed-sink-to-apache-kafka.md#2025-04-18_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n\"*.*\"\n```\n\nLANGUAGE: text\nCODE:\n```\n\"!test.tbl1\"\n```\n\n----------------------------------------\n\nTITLE: Configuring cert-allowed-cn for TiKV\nDESCRIPTION: This code snippet demonstrates the configuration of `cert-allowed-cn` in the TiKV configuration file to verify the caller's identity. It specifies a list of allowed Common Names (CNs) for secure connections to TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_11\n\nLANGUAGE: toml\nCODE:\n```\n    ```toml\n    [security]\n    cert-allowed-cn = [\"tidb\", \"pd\", \"tikv\", \"tiflash\", \"prometheus\"]\n    ```\n```\n\n----------------------------------------\n\nTITLE: Querying and Removing TiFlash Replicas - SQL Commands\nDESCRIPTION: SQL commands to check existing TiFlash replicas and set their count to 0 before removing TiFlash nodes. This query first checks all tables with TiFlash replicas and then removes the replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-disaggregated-and-s3.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.TIFLASH_REPLICA; # Query all tables with TiFlash replicas\nALTER TABLE table_name SET TIFLASH REPLICA 0;     # Set the TiFlash replica count of all tables to `0`\n```\n\n----------------------------------------\n\nTITLE: JWT Header Configuration in JSON\nDESCRIPTION: Defines the metadata for a JWT token, specifying the signature algorithm, token type, and key ID\nSOURCE: https://github.com/pingcap/docs/blob/master/security-compatibility-with-mysql.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"alg\": \"RS256\",\n  \"kid\": \"the-key-id-0\",\n  \"typ\": \"JWT\"\n}\n```\n\n----------------------------------------\n\nTITLE: Viewing Execution Plan Caching Warnings in SQL\nDESCRIPTION: This example demonstrates how TiDB shows warnings when an execution plan cannot be cached. In this case, the optimizer detects that a non-INT type might be converted to INT, potentially changing the execution plan depending on the parameter value.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.6.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nmysql> PREPARE st FROM 'SELECT * FROM t WHERE a<?';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SET @a='1';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> EXECUTE st USING @a;\nEmpty set, 1 warning (0.01 sec)\n\nmysql> SHOW WARNINGS;\n+---------+------+----------------------------------------------+\n| Level   | Code | Message                                      |\n+---------+------+----------------------------------------------+\n| Warning | 1105 | skip plan-cache: '1' may be converted to INT |\n+---------+------+----------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Downloading Monitoring Components\nDESCRIPTION: Commands for downloading Prometheus, node_exporter, and Grafana packages along with their extraction\nSOURCE: https://github.com/pingcap/docs/blob/master/deploy-monitoring-services.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Downloads the package.\nwget https://github.com/prometheus/prometheus/releases/download/v2.49.1/prometheus-2.49.1.linux-amd64.tar.gz\nwget https://download.pingcap.org/node_exporter-v1.3.1-linux-amd64.tar.gz\nwget https://download.pingcap.org/grafana-7.5.17.linux-amd64.tar.gz\n```\n\nLANGUAGE: bash\nCODE:\n```\n# Extracts the package.\ntar -xzf prometheus-2.49.1.linux-amd64.tar.gz\ntar -xzf node_exporter-v1.3.1-linux-amd64.tar.gz\ntar -xzf grafana-7.5.17.linux-amd64.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Key Partitioning\nDESCRIPTION: This SQL snippet demonstrates creating a table with Key partitioning, a newly supported feature in TiDB v7.0.0. It shows how to partition a table named 'employees' by the 'store_id' column using the KEY partitioning method. The `PARTITIONS 4` clause specifies that the table should be divided into four partitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.0.0.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n    CREATE TABLE employees (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT) PARTITION BY KEY(store_id) PARTITIONS 4;\n\n```\n\n----------------------------------------\n\nTITLE: TiDB Bug Fix Changelog\nDESCRIPTION: List of bug fixes in TiDB ecosystem components including database engine fixes, distributed coordination improvements, and tool enhancements.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.2.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## Bug fixes\n\n+ TiDB\n\n    - Fix the potential wrong results of index hash join when the hash column is the `ENUM` type [#27893]\n    - Fix a batch client bug that recycle idle connection might block sending requests in some rare cases [#27678]\n    - Fix the issue that the overflow check of the `FLOAT64` type is different with that of MySQL [#23897]\n    [... additional fixes truncated for brevity ...]\n\n+ TiKV\n\n    - Fix a panic issue that occurs after TiKV is upgraded from v3.x to later versions [#10902]\n    [... additional fixes truncated for brevity ...]\n\n+ PD\n\n    - Fix the issue that PD does not fix the down peers in time [#4077]\n    [... additional fixes truncated for brevity ...]\n\n+ TiFlash\n\n    - Fix the issue of unexpected results when TiFlash fails to establish MPP connections\n    [... additional fixes truncated for brevity ...]\n\n+ Tools\n\n    + Backup & Restore (BR)\n    + Dumpling\n    + TiCDC\n    [... additional fixes truncated for brevity ...]\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with npm\nDESCRIPTION: Command to install required packages for the sample application using npm.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Fetching Repository Data in Next.js\nDESCRIPTION: This JavaScript code fetches data from the `GET /repositories` endpoint using the generated API client and renders the repository names in the frontend. It demonstrates how to interact with the API within a Next.js application.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-oas-with-nextjs.md#2025-04-18_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nimport {DefaultApi, Configuration} from \"../gen/api\"\n\nexport default async function Home() {\n  const config = new Configuration({\n    username: process.env.TIDBCLOUD_DATA_SERVICE_PUBLIC_KEY,\n    password: process.env.TIDBCLOUD_DATA_SERVICE_PRIVATE_KEY,\n  });\n  const apiClient = new DefaultApi(config);\n  const resp = await apiClient.getRepositories();\n  return (\n    <main className=\\\"flex min-h-screen flex-col items-center justify-between p-24\\\">\n      <ul className=\\\"font-mono text-2xl\\\">\n        {resp.data.rows.map((repo) => (\n          <a href={repo.url}>\n            <li key={repo.id}>{repo.name}</li>\n          </a>\n        ))}\n      </ul>\n    </main>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Specifying CA Path for TLS in TiDB\nDESCRIPTION: Indicates the public certificate of the CA for TLS connections. Setting it to an empty string disables TLS for SQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_16\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- Example: `\"/path/to/ca.pem\"` -->\n```\n\n----------------------------------------\n\nTITLE: Configuring Isolation Level in PD Configuration File (TOML)\nDESCRIPTION: This snippet shows how to set the isolation-level in the PD configuration file to 'zone'. This configuration enhances topological isolation requirements on TiKV clusters when location-labels are already configured.\nSOURCE: https://github.com/pingcap/docs/blob/master/schedule-replicas-by-topology-labels.md#2025-04-18_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[replication]\nisolation-level = \"zone\"\n```\n\n----------------------------------------\n\nTITLE: Modifying User Password in TiDB\nDESCRIPTION: This snippet illustrates the proper command to change a user's password in TiDB, emphasizing the use of the standard SQL statement 'ALTER USER' to ensure passwords are updated across nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/high-reliability-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER USER 'test'@'localhost' IDENTIFIED BY 'mypass';\n```\n\n----------------------------------------\n\nTITLE: Setting I/O Rate Limits for TiFlash in TOML\nDESCRIPTION: Example of configuring I/O rate limits for TiFlash in the tiflash.toml file. This demonstrates how to set total, read, and write bandwidth limits for disk operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[storage.io_rate_limit]\nmax_bytes_per_sec = 104857600  # 100MB/s\nmax_read_bytes_per_sec = 52428800  # 50MB/s\nmax_write_bytes_per_sec = 52428800  # 50MB/s\n```\n\n----------------------------------------\n\nTITLE: Describing the INSPECTION_RULES Table Schema in TiDB\nDESCRIPTION: This SQL query displays the structure of the INSPECTION_RULES table in the information_schema database, showing field names, data types, and other column properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-rules.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC inspection_rules;\n```\n\n----------------------------------------\n\nTITLE: Monitoring Disk Quota in TiDB\nDESCRIPTION: Specifies the interval at which the local disk quota is checked during the physical import mode, aimed at preventing storage issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-configuration.md#2025-04-18_snippet_27\n\nLANGUAGE: markdown\nCODE:\n```\nDefault value: \"60s\", which means 60 seconds.\n```\n\n----------------------------------------\n\nTITLE: YAML Front Matter Configuration for Release Notes\nDESCRIPTION: YAML configuration block defining the title and summary of the TiDB 5.3.1 release notes document.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.1.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: TiDB 5.3.1 Release Notes\nsummary: TiDB 5.3.1 was released on March 3, 2022. The release includes compatibility changes, improvements, and bug fixes for TiDB, TiKV, PD, TiCDC, TiFlash, Backup & Restore (BR), and TiDB Data Migration (DM). Some notable changes include optimizing user login mode mapping, reducing TiCDC recovery time, and fixing various bugs in TiDB, TiKV, PD, TiFlash, and tools like TiCDC and TiDB Lightning. These fixes address issues related to data import, user login, garbage collection, configuration parameters, and more.\n---\n```\n\n----------------------------------------\n\nTITLE: Setting Maximum User Connections in TiDB\nDESCRIPTION: Example of setting the maximum number of connections for 'newuser' to 3 and then verifying the change in the mysql.user table. This demonstrates how to limit resource usage per user in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-user.md#2025-04-18_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'newuser' WITH MAX_USER_CONNECTIONS 3;\nmysql> SELECT User, Host, max_user_connections FROM mysql.user WHERE User='newuser';\n+---------+------+----------------------+\n| User    | Host | max_user_connections |\n+---------+------+----------------------+\n| newuser | %    |                    3 |\n+---------+------+----------------------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Using Optimizer Hint in Non-Transactional DML SQL\nDESCRIPTION: This snippet demonstrates how to use an optimizer hint within a non-transactional 'DELETE' statement in TiDB. Limitations and dependencies include TiDB's support for optimizer hints in SQL operations. Essential parameters involve specifying the column and size of batches as shown. The hint 'USE_INDEX' specifies which index to use, optimizing the execution of delete operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nBATCH ON id LIMIT 2 DELETE /*+ USE_INDEX(t)*/ FROM t WHERE v < 6;\n```\n\n----------------------------------------\n\nTITLE: ENGINES Table Structure Output in SQL\nDESCRIPTION: This shows the result of the DESC command on the ENGINES table, displaying the column names, data types, and other attributes of the table structure.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-engines.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+--------------+-------------+------+------+---------+-------+\n| Field        | Type        | Null | Key  | Default | Extra |\n+--------------+-------------+------+------+---------+-------+\n| ENGINE       | varchar(64) | YES  |      | NULL    |       |\n| SUPPORT      | varchar(8)  | YES  |      | NULL    |       |\n| COMMENT      | varchar(80) | YES  |      | NULL    |       |\n| TRANSACTIONS | varchar(3)  | YES  |      | NULL    |       |\n| XA           | varchar(3)  | YES  |      | NULL    |       |\n| SAVEPOINTS   | varchar(3)  | YES  |      | NULL    |       |\n+--------------+-------------+------+------+---------+-------+\n6 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring MySQL DataSource for TiDB Connection in Java\nDESCRIPTION: This code snippet demonstrates how to configure a MysqlDataSource object with TiDB connection parameters, including optional SSL configuration. It sets the server name, port, user, password, and database name.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-jdbc.md#2025-04-18_snippet_0\n\nLANGUAGE: java\nCODE:\n```\npublic MysqlDataSource getMysqlDataSource() throws SQLException {\n    MysqlDataSource mysqlDataSource = new MysqlDataSource();\n\n    mysqlDataSource.setServerName(${tidb_host});\n    mysqlDataSource.setPortNumber(${tidb_port});\n    mysqlDataSource.setUser(${tidb_user});\n    mysqlDataSource.setPassword(${tidb_password});\n    mysqlDataSource.setDatabaseName(${tidb_db_name});\n    if (${tidb_use_ssl}) {\n        mysqlDataSource.setSslMode(PropertyDefinitions.SslMode.VERIFY_IDENTITY.name());\n        mysqlDataSource.setEnabledTLSProtocols(\"TLSv1.2,TLSv1.3\");\n    }\n\n    return mysqlDataSource;\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Terraform Apply for Cluster Update\nDESCRIPTION: This snippet illustrates using the 'terraform apply' command to apply changes defined in the configuration file. It outlines how to confirm changes and prompts for user input to proceed with the updates. Ensure Terraform is configured with the appropriate provider files and permissions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_7\n\nLANGUAGE: Shell\nCODE:\n```\n$ terraform apply\n\ntidbcloud_cluster.example_cluster: Refreshing state... [id=1379661944630234067]\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  ~ update in-place\n\nTerraform will perform the following actions:\n\n  # tidbcloud_cluster.example_cluster will be updated in-place\n  ~ resource \"tidbcloud_cluster\" \"example_cluster\" {\n      ~ config         = {\n          ~ components     = {\n              + tiflash = {\n                  + node_quantity    = 1\n                  + node_size        = \"8C64G\"\n                  + storage_size_gib = 500\n                }\n                # (2 unchanged attributes hidden)\n            }\n            # (3 unchanged attributes hidden)\n        }\n        id             = \"1379661944630234067\"\n        name           = \"firstCluster\"\n      ~ status         = \"AVAILABLE\" -> (known after apply)\n        # (4 unchanged attributes hidden)\n    }\n\nPlan: 0 to add, 1 to change, 0 to destroy.\n\nDo you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only 'yes' will be accepted to approve.\n\n  Enter a value:\n\n```\n\n----------------------------------------\n\nTITLE: Using INSERT INTO SELECT with TiFlash for Query Result Materialization in SQL\nDESCRIPTION: An example of using the INSERT INTO SELECT statement to save TiFlash query results. This feature pushes down the SELECT clause to TiFlash and allows saving analytical query results into a TiDB table for further analysis, effectively acting as result materialization.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.5.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t2 SELECT Mod(x,y) FROM t1;\n```\n\n----------------------------------------\n\nTITLE: Executing BENCHMARK Function (SQL)\nDESCRIPTION: The `BENCHMARK()` function executes a given expression a specified number of times, allowing for performance testing of SQL expressions.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/information-functions.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT BENCHMARK(5, SLEEP(2));\n```\n+------------------------+\n| BENCHMARK(5, SLEEP(2)) |\n+------------------------+\n|                      0 |\n+------------------------+\n1 row in set (10.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Pushing Down CAST Functions in TiFlash\nDESCRIPTION: Adds support for pushing down CAST functions to TiFlash, which can improve query performance by offloading type conversion operations to the storage layer.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.8.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCAST(column_name AS data_type)\n```\n\n----------------------------------------\n\nTITLE: Querying MySQL Binlog Events\nDESCRIPTION: Example showing how to query binlog events to check previous GTIDs in MySQL. Demonstrates output format showing log position, event type and GTID information.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-faq.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nmysql> show binlog events in 'mysql-bin.000005' limit 2;\n+------------------+------+----------------+-----------+-------------+--------------------------------------------------------------------+\n| Log_name         | Pos  | Event_type     | Server_id | End_log_pos | Info                                                               |\n+------------------+------+----------------+-----------+-------------+--------------------------------------------------------------------+\n| mysql-bin.000005 |    4 | Format_desc    |    123452 |         123 | Server ver: 5.7.32-35-log, Binlog ver: 4                           |\n| mysql-bin.000005 |  123 | Previous_gtids |    123452 |         194 | d3618e68-6052-11eb-a68b-0242ac110002:6-7                           |\n+------------------+------+----------------+-----------+-------------+--------------------------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Creating a User Profile in Interactive Mode\nDESCRIPTION: This example demonstrates how to create a user profile in interactive mode. The command will prompt the user for necessary information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-create.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud config create\n```\n\n----------------------------------------\n\nTITLE: WATERMARK Event Format in Canal-JSON\nDESCRIPTION: Sample of a WATERMARK Event encoded in Canal-JSON format. This special event type is sent only when enable-tidb-extension is true and indicates that all events with commitTs less than watermarkTs have been sent.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"id\": 0,\n    \"database\": \"\",\n    \"table\": \"\",\n    \"pkNames\": null,\n    \"isDdl\": false,\n    \"type\": \"TIDB_WATERMARK\",\n    \"es\": 1640007049196,\n    \"ts\": 1640007050284,\n    \"sql\": \"\",\n    \"sqlType\": null,\n    \"mysqlType\": null,\n    \"data\": null,\n    \"old\": null,\n    \"_tidb\": {     // TiDB extension field\n        \"watermarkTs\": 429918007904436226  // A TiDB TSO timestamp\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating v2.0+ Data Migration Task Configuration\nDESCRIPTION: This YAML configuration snippet shows how to update the v1.0.x data migration task configuration for v2.0+, including changing the task name, setting the task mode to incremental, and specifying the starting point for incremental replication based on the global checkpoint information.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/manually-upgrade-dm-1.0-to-2.0.md#2025-04-18_snippet_3\n\nLANGUAGE: YAML\nCODE:\n```\nmysql-instances:\n  - source-id: \"mysql-replica-01\"\n    meta:\n      binlog-name: \"mysql-bin.000123\"\n      binlog-pos: 15847\n\n  - source-id: \"mysql-replica-02\"\n    meta:\n      binlog-name: \"mysql-bin.000456\"\n      binlog-pos: 10485\n```\n\n----------------------------------------\n\nTITLE: Describing SESSION_VARIABLES Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the SESSION_VARIABLES table in the INFORMATION_SCHEMA database. It shows the column names, data types, and other attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-session-variables.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC SESSION_VARIABLES;\n```\n\n----------------------------------------\n\nTITLE: Enabling Specific Roles in the Current Session in TiDB\nDESCRIPTION: This snippet shows how to enable specific roles for the current session using the `SET ROLE` statement. After `rw_user1` logs in, this statement enables the `app_read` and `app_write` roles, but only for the current session. The user must have been granted the role before it can be enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSET ROLE 'app_read', 'app_write';\n```\n\n----------------------------------------\n\nTITLE: Starting Log Backup in TiDB\nDESCRIPTION: Command to initiate a continuous log backup task named 'pitr' that sends data changes to an S3 storage location.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-use-cases.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log start --task-name=pitr --pd=\"${PD_IP}:2379\" \\\n--storage='s3://tidb-pitr-bucket/backup-data/log-backup'\n```\n\n----------------------------------------\n\nTITLE: Set Operations with Parentheses\nDESCRIPTION: Shows how parentheses can be used to control the order of set operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/set-operators.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n(SELECT * FROM t1 UNION ALL SELECT * FROM t1) INTERSECT SELECT * FROM t2;\n```\n\n----------------------------------------\n\nTITLE: Altering Placement Policy for a Partition in TiDB\nDESCRIPTION: Demonstrates how to change the placement policy for a specific partition after the table has been created.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t1 PARTITION p1 PLACEMENT POLICY=storageforhistorydata;\n```\n\n----------------------------------------\n\nTITLE: Viewing Result from TIDB_ENCODE_SQL_DIGEST for 'SELECT 1'\nDESCRIPTION: Shows the output of TIDB_ENCODE_SQL_DIGEST for 'SELECT 1', returning a hexadecimal digest string representing the normalized query (which would be 'SELECT ?').\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------------------------------------------+\n| TIDB_ENCODE_SQL_DIGEST('SELECT 1')                               |\n+------------------------------------------------------------------+\n| e1c71d1661ae46e09b7aaec1c390957f0d6260410df4e4bc71b9c8d681021471 |\n+------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Expanded Data Result with GID Values\nDESCRIPTION: Example showing the result after applying the Expand operator, demonstrating how GID values are assigned for different grouping combinations in a ROLLUP operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/group-by-modifier.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n+------------+------+-------+-----+\n| profit     | year | month | gid |\n+------------+------+-------+-----+\n| 10.3000000 | 2000 | Jan   |  3  |\n+------------+------+-------+-----+\n| 10.3000000 | 2000 | NULL  |  1  |\n+------------+------+-------+-----+\n| 10.3000000 | NULL | NULL  |  0  |\n+------------+------+-------+-----+\n```\n\n----------------------------------------\n\nTITLE: Titan Blob Storage Configuration\nDESCRIPTION: Configuration settings for Titan blob storage engine, including compression, cache sizes, and GC parameters. Controls how large values are stored and managed in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_19\n\nLANGUAGE: yaml\nCODE:\n```\ntitan:\n  min-blob-size: \"32KiB\"\n  blob-file-compression: \"zstd\"\n  zstd-dict-size: \"0KiB\"\n  blob-cache-size: \"0GiB\"\n  shared-blob-cache: true\n  min-gc-batch-size: \"16MiB\"\n  max-gc-batch-size: \"64MiB\"\n  discardable-ratio: 0.5\n  sample-ratio: 0.1\n  merge-small-file-threshold: \"8MiB\"\n  blob-run-mode: \"normal\"\n```\n\n----------------------------------------\n\nTITLE: Viewing Resource Control Controller Configuration in TiDB\nDESCRIPTION: This command displays the current configuration of the Resource Control controller, including settings for degraded mode, token bucket, and request unit costs.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_28\n\nLANGUAGE: bash\nCODE:\n```\nresource-manager config controller show\n```\n\nLANGUAGE: bash\nCODE:\n```\n{\n    \"degraded-mode-wait-duration\": \"0s\",\n    \"ltb-max-wait-duration\": \"30s\",\n    \"request-unit\": {                    # Configurations of RU. Do not modify.\n        \"read-base-cost\": 0.125,\n        \"read-per-batch-base-cost\": 0.5,\n        \"read-cost-per-byte\": 0.0000152587890625,\n        \"write-base-cost\": 1,\n        \"write-per-batch-base-cost\": 1,\n        \"write-cost-per-byte\": 0.0009765625,\n        \"read-cpu-ms-cost\": 0.3333333333333333\n    },\n    \"enable-controller-trace-log\": \"false\"\n}\n```\n\n----------------------------------------\n\nTITLE: Describing CLIENT_ERRORS_SUMMARY_GLOBAL Table Structure\nDESCRIPTION: SQL command to show the structure of the CLIENT_ERRORS_SUMMARY_GLOBAL table including field names, data types, and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/client-errors-summary-global.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC CLIENT_ERRORS_SUMMARY_GLOBAL;\n```\n\n----------------------------------------\n\nTITLE: Required Attributes Validation\nDESCRIPTION: SQL queries checking for required attributes in the JSON document\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-validate.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SCHEMA_VALID('{\"required\": [\"fruits\",\"vegetables\"]}',@j)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SCHEMA_VALID('{\"required\": [\"fruits\",\"vegetables\",\"grains\"]}',@j)\n```\n\n----------------------------------------\n\nTITLE: Updating TiDB Cloud Serverless Cluster labels\nDESCRIPTION: This command shows how to update the labels of a TiDB Cloud Serverless cluster in non-interactive mode, specifying the cluster ID and the new labels in JSON format.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-update.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless update -c <cluster-id> --labels \"{\\\"label1\\\":\\\"value1\\\"}\"\n```\n\n----------------------------------------\n\nTITLE: Creating basic Terraform configuration file\nDESCRIPTION: Initial Terraform configuration specifying the TiDB Cloud provider with version constraints. This configuration is required to download the TiDB Cloud provider from Terraform Registry.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-get-tidbcloud-provider.md#2025-04-18_snippet_2\n\nLANGUAGE: terraform\nCODE:\n```\nterraform {\n  required_providers {\n    tidbcloud = {\n      source = \"tidbcloud/tidbcloud\"\n      version = \"~> 0.3.0\"\n    }\n  }\n  required_version = \">= 1.0.0\"\n}\n```\n\n----------------------------------------\n\nTITLE: TUF Timestamp File Format in JSON\nDESCRIPTION: The timestamp file format contains signature information and metadata about the snapshot file. It includes the file type, expiration date, SHA-256 hash of the snapshot file, and version information for tracking updates.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror-reference.md#2025-04-18_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"signatures\": [                                             # The file's signature.\n        {\n            \"keyid\": \"{id-of-index-key-1}\",                     # The ID of the first private key that participates in the signature.\n            \"sig\": \"{signature-by-index-key-1}\",                # The signed part of this file by this private key.\n        },\n        ...\n        {\n            \"keyid\": \"{id-of-root-key-N}\",                      # The ID of the Nth private key that participates in the signature.\n            \"sig\": \"{signature-by-root-key-N}\"                  # The signed part of this file by this private key.\n        }\n    ],\n    \"signed\": {\n        \"_type\": \"timestamp\",                                   # The file type.\n        \"expires\": \"{expiration-date-of-this-file}\",            # The expiration time of the file. If the file expires, the client rejects the file.\n        \"meta\": {                                               # The information of snapshot.json.\n            \"/snapshot.json\": {\n                \"hashes\": {\n                    \"sha256\": \"{sum-of-sha256}\"                 # snapshot.json's sha256.\n                },\n                \"length\": {length-of-json-file}                 # The length of snapshot.json.\n            }\n        },\n        \"spec_version\": \"0.1.0\",                                # The specified version followed by this file. If the file structure is changed in the future, the version number needs to be upgraded. The current version number is 0.1.0.\n        \"version\": {N}                                          # The version number of this file. You need to overwrite timestamp.json every time you update the file, and set its version to N + 1.\n\n```\n\n----------------------------------------\n\nTITLE: Deleting a Replication Task via DELETE API in Shell\nDESCRIPTION: This example shows how to delete an existing replication task by its name using the DELETE API endpoint. The request is synchronous and returns a 204 status code upon success.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_29\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'DELETE' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1' \\\n  -H 'accept: application/json'\n```\n\n----------------------------------------\n\nTITLE: Sink URI Example for Azure Blob Storage\nDESCRIPTION: Basic sink URI configuration for Azure Blob Storage, specifying the bucket, prefix, and protocol for data replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"azure://bucket/prefix?protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: Using JSON_EXTRACT() to Get a JSON Property\nDESCRIPTION: This example demonstrates using JSON_EXTRACT() to extract the 'database' property from a JSON document, which returns the value with quotes.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-modify.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_EXTRACT('{\"database\": \"TiDB\"}', '$.database');\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning for Parquet Import\nDESCRIPTION: TOML configuration file for TiDB Lightning, specifying logging, backend settings, data source directory, and target TiDB cluster information for importing parquet files.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-parquet-files-to-tidb.md#2025-04-18_snippet_3\n\nLANGUAGE: TOML\nCODE:\n```\n[lightning]\nlevel = \"info\"\nfile = \"tidb-lightning.log\"\n\n[tikv-importer]\nbackend = \"local\"\nsorted-kv-dir = \"${sorted-kv-dir}\"\n\n[mydumper]\ndata-source-dir = \"${data-path}\"\n\n[tidb]\nhost = ${host}\nport = ${port}\nuser = \"${user_name}\"\npassword = \"${password}\"\nstatus-port = ${status-port}\npd-addr = \"${ip}:${port}\"\n```\n\n----------------------------------------\n\nTITLE: Example JSON Metadata Structure\nDESCRIPTION: Demonstrates a sample JSON metadata structure for a document in TiDB Vector Store.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_14\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"page\": 12,\n  \"book_title\": \"Siddhartha\"\n}\n```\n\n----------------------------------------\n\nTITLE: Generating dbt Documentation\nDESCRIPTION: Commands to generate and serve visual documentation for the dbt project. The documentation includes the overall structure and descriptions of all tables and views.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ndbt docs generate\n```\n\n----------------------------------------\n\nTITLE: Removing SQL Plan Binding Using SQL Digest in TiDB\nDESCRIPTION: This snippet shows how to create multiple global bindings and then remove them using SQL Digests. It demonstrates two methods: directly specifying the digests and using a user variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-binding.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1(a INT, b INT, c INT, INDEX ia(a));\nCREATE TABLE t2(a INT, b INT, c INT, INDEX ia(a));\nCREATE GLOBAL BINDING FOR SELECT * FROM t1 WHERE a > 1 USING SELECT * FROM t1 USE INDEX (ia) WHERE a > 1;\nCREATE GLOBAL BINDING FOR SELECT * FROM t2 WHERE a < 1 USING SELECT * FROM t2 USE INDEX (ia) WHERE a < 1;\nCREATE GLOBAL BINDING FOR SELECT * FROM t1 JOIN t2 ON t1.b = t2.a USING SELECT /*+ HASH_JOIN(t1) */ * FROM t1 JOIN t2 ON t1.b = t2.a;\nSHOW GLOBAL BINDINGS;\n\nDROP GLOBAL BINDING FOR SQL DIGEST '31026623c8f22264fe0dfc26f29c69c5c457d6b85960c578ebcf17a967ed7893', '0f38b2e769927ae37981c66f0988c6299b602e03f029e38aa071e656fc321593', '3c8dfc451b0e36afd904cefca5137e68fb051f02964e1958ed60afdadc25f57e';\nSHOW GLOBAL BINDINGS;\n\nSET @digests='31026623c8f22264fe0dfc26f29c69c5c457d6b85960c578ebcf17a967ed7893, 0f38b2e769927ae37981c66f0988c6299b602e03f029e38aa071e656fc321593, 3c8dfc451b0e36afd904cefca5137e68fb051f02964e1958ed60afdadc25f57e';\nDROP GLOBAL BINDING FOR SQL DIGEST @digests;\nSHOW GLOBAL BINDINGS;\n```\n\n----------------------------------------\n\nTITLE: Setting DATABASE_URL Environment Variable\nDESCRIPTION: Command to set the DATABASE_URL secret for the Cloudflare Worker using Wrangler CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-cloudflare.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nwrangler secret put <DATABASE_URL>\n```\n\n----------------------------------------\n\nTITLE: Setting and Showing Role Privileges\nDESCRIPTION: SQL commands demonstrating role activation and privilege verification for the analytics team role.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-revoke-role.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS;\nSHOW TABLES in test;\nSET ROLE analyticsteam;\nSHOW GRANTS;\nSHOW TABLES IN test;\n```\n\n----------------------------------------\n\nTITLE: SQL Query with Index Merge\nDESCRIPTION: This code snippet illustrates a SQL query that benefits from the Index Merge feature in TiDB.  When the filtering conditions in a `WHERE` clause are connected by `OR` and have their respective indexes on different columns, the Index Merge feature filters the respective indexes simultaneously, merges the query results, and returns the merged result. This helps to avoid unnecessary full table scans and improve query performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.4.0.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM table WHERE key1 <= 100 OR key2 = 200;\n```\n\n----------------------------------------\n\nTITLE: Enabling Log Redaction in TiDB\nDESCRIPTION: These configuration items enable desensitization of sensitive information in logs for different TiDB components. Each setting defaults to `false` and needs to be set to `true` to activate log redaction for the corresponding server.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0.md#2025-04-18_snippet_3\n\nLANGUAGE: YAML\nCODE:\n```\ntidb_redact_log = 1\n```\n\nLANGUAGE: YAML\nCODE:\n```\nsecurity.redact-info-log = true\n```\n\nLANGUAGE: YAML\nCODE:\n```\nsecurity.redact_info_log = true\n```\n\n----------------------------------------\n\nTITLE: Manually Create Data Service Endpoint\nDESCRIPTION: Step-by-step process for manually creating a custom endpoint in TiDB Cloud Data Service, allowing precise configuration of database interactions\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-manage-endpoint.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n1. Navigate to Data Service page\n2. Select Data App\n3. Click \"Create Endpoint\"\n4. Update endpoint name\n5. Configure endpoint details\n6. Define SQL statements\n7. Set parameters and properties\n```\n\n----------------------------------------\n\nTITLE: Configuring ONLY_FULL_GROUP_BY SQL Mode\nDESCRIPTION: Example showing how to set the ONLY_FULL_GROUP_BY SQL mode, which enforces proper GROUP BY behavior. This demonstrates both a successful query without the mode enabled and the error produced when using NON-FULL GROUP BY syntax with the mode enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-unstable-result-set.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nmysql> select a.class, a.stuname, max(b.courscore) from stu_info a join stu_score b on a.stuno=b.stuno group by a.class order by a.class, a.stuname;\n+------------+--------------+------------------+\n| class      | stuname      | max(b.courscore) |\n+------------+--------------+------------------+\n| 2018_CS_01 | MonkeyDLuffy |             95.5 |\n| 2018_CS_03 | PatrickStar  |             99.0 |\n+------------+--------------+------------------+\n2 rows in set (0.01 sec)\n\nmysql> set @@sql_mode='STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,ONLY_FULL_GROUP_BY';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> select a.class, a.stuname, max(b.courscore) from stu_info a join stu_score b on a.stuno=b.stuno group by a.class order by a.class, a.stuname;\nERROR 1055 (42000): Expression #2 of ORDER BY is not in GROUP BY clause and contains nonaggregated column '' which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by\n```\n\n----------------------------------------\n\nTITLE: Modifying TiProxy Configuration using TOML\nDESCRIPTION: Demonstrates the TOML format for modifying TiProxy configuration. This example changes the log level to 'warning'.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-api.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[log]\nlevel='warning'\n```\n\n----------------------------------------\n\nTITLE: Installing Terraform via Homebrew\nDESCRIPTION: Command to install Terraform on macOS using the previously added HashiCorp tap.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-get-tidbcloud-provider.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbrew install hashicorp/tap/terraform\n```\n\n----------------------------------------\n\nTITLE: Observing AUTO_INCREMENT After Server Restart with AUTO_ID_CACHE\nDESCRIPTION: This snippet shows how auto-increment ID cache is lost after TiDB restart, with new insert operations allocating IDs starting from beyond the previously cached range of 100 values.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES();\nQuery OK, 1 row affected (0.00 sec)\n\nSELECT * FROM t;\n+-----+\n| a   |\n+-----+\n|   1 |\n| 101 |\n+-----+\n2 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Disk Quota for TiDB Lightning (TOML)\nDESCRIPTION: This snippet sets up a disk quota configuration for TiDB Lightning, limiting the usage of storage space during data import operations. It includes parameters for disk-quota and check-disk-quota, balancing the need for temporary file storage with efficient writing processes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-physical-import-mode-usage.md#2025-04-18_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[tikv-importer]\n# MaxInt64 by default, which is 9223372036854775807 bytes.\ndisk-quota = \"10GB\"\nbackend = \"local\"\n\n[cron]\n# The interval of checking disk quota. 60 seconds by default.\ncheck-disk-quota = \"30s\"\n```\n\n----------------------------------------\n\nTITLE: Using TIDB_DECODE_SQL_DIGESTS to Query Normalized SQL Statements\nDESCRIPTION: Demonstrates how to use the TIDB_DECODE_SQL_DIGESTS function to query normalized SQL statements corresponding to a set of SQL digests. This function accepts a JSON string array of digests and an optional statement truncation length parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSET @digests = '[\"e6f07d43b5c21db0fbb9a31feac2dc599787763393dd5acbfad80e247eb02ad5\",\"38b03afa5debbdf0326a014dbe5012a62c51957f1982b3093e748460f8b00821\",\"e5796985ccafe2f71126ed6c0ac939ffa015a8c0744a24b7aee6d587103fd2f7\"]';\n\nSELECT TIDB_DECODE_SQL_DIGESTS(@digests);\n```\n\n----------------------------------------\n\nTITLE: MyDumper Compression Configuration for Files - TOML\nDESCRIPTION: This snippet configures MyDumper for handling compressed data files in TiDB Lightning using TOML. It shows how to specify the compression format alongside the renaming patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[mydumper]\ndata-source-dir = \"/some-subdir/some-database/\"\n[[mydumper.files]]\npattern = '^(srcdb)\\.(.*?)-schema-create\\.(sql)\\.(gz)'\nschema = 'tgtdb'\ntype = \"schema-schema\"\ncompression = '$4'\n[[mydumper.files]]\npattern = '^(srcdb)\\.(.*?)-schema\\.(sql)\\.(gz)'\nschema = 'tgtdb'\ntable = '$2'\ntype = \"table-schema\"\ncompression = '$4'\n[[mydumper.files]]\npattern = '^(srcdb)\\.(.*?)\\.(?:[0-9]+)\\.(sql)\\.(gz)'\nschema = 'tgtdb'\ntable = '$2'\ntype = '$3'\ncompression = '$4'\n```\n\n----------------------------------------\n\nTITLE: Configuring cert-allowed-cn for TiProxy\nDESCRIPTION: This code snippet demonstrates how to configure `cert-allowed-cn` within the `server-http-tls` section of the TiProxy configuration file.  It defines the list of allowed Common Names (CNs) for clients connecting to TiProxy, enhancing security by ensuring only authorized components can establish connections.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_14\n\nLANGUAGE: toml\nCODE:\n```\n    ```toml\n    [security]\n        [server-http-tls]\n        cert-allowed-cn = [\"tiproxy\", \"tidb\", \"test-client\", \"prometheus\"]\n    ```\n```\n\n----------------------------------------\n\nTITLE: Configuring max-write-buffer-number in TiKV\nDESCRIPTION: This snippet demonstrates how to adjust the `max-write-buffer-number` parameter for RocksDB Column Families (CF) in TiKV to mitigate stalls caused by too many memtables.  Increasing this value allows for more memtables, potentially improving write performance during business peaks, but also increasing memory usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_7\n\nLANGUAGE: TOML\nCODE:\n```\n\"[rocksdb.defaultcf] max-write-buffer-number = 8\"\n```\n\n----------------------------------------\n\nTITLE: Checking Placement Rules Configuration\nDESCRIPTION: This command retrieves the current placement rules configuration from PD, allowing you to inspect the `default: count` value. This value determines the number of replicas, including TiFlash replicas, that PD will maintain for the data. Ensuring this value is reasonable and aligned with the number of TiKV and TiFlash nodes is critical.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n```shell\ntiup ctl:nightly pd -u http://${pd-ip}:${pd-port} config placement-rules show | grep -C 10 default\n```\n```\n\n----------------------------------------\n\nTITLE: Relay Log Metrics Table in Markdown\nDESCRIPTION: Table defining relay log metrics including storage capacity, error tracking, and performance measurements with their alert conditions and severity levels. Note that DM v2.0 does not support enabling the relay log feature.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/monitor-a-dm-cluster.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Metric name | Description | Alert | Severity level |\n|:----|:------------|:----|:----|\n| storage capacity | The storage capacity of the disk occupied by the relay log | N/A | N/A |\n| storage remain | The remaining storage capacity of the disk occupied by the relay log | An alert is needed once the value is smaller than 10G | critical |\n| process exits with error | The relay log encounters an error within the DM-worker and exits | Immediate alerts | critical |\n| relay log data corruption | The number of corrupted relay log files | Immediate alerts | emergency |\n```\n\n----------------------------------------\n\nTITLE: Export Data Using TiDB Cloud CLI\nDESCRIPTION: Commands to create and download an export task from a TiDB Cloud Serverless cluster using the CLI\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-export.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export create -c <cluster-id>\nticloud serverless export download -c <cluster-id> -e <export-id>\n```\n\n----------------------------------------\n\nTITLE: Analyzing Complex SQL Query Execution in TiDB\nDESCRIPTION: This SQL command uses EXPLAIN ANALYZE to show the execution plan and actual performance statistics for a complex query involving multiple tables, date calculations, and subqueries. It's used to compare performance before and after enabling MPP mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nexplain analyze select o_orderpriority, count(*) as order_count from orders where o_orderdate >= '1995-01-01' and o_orderdate < date_add('1995-01-01', interval '3' month) and exists (select * from lineitem where l_orderkey = o_orderkey and l_commitdate < l_receiptdate) group by o_orderpriority;\n```\n\n----------------------------------------\n\nTITLE: Comparing SHOW PLACEMENT and PLACEMENT_POLICIES Table in TiDB\nDESCRIPTION: Example demonstrating the difference between SHOW PLACEMENT command and querying the PLACEMENT_POLICIES table. This shows how to create tables with placement policies and view the resulting configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-placement-policies.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1 (a INT); \nCREATE PLACEMENT POLICY p1 primary_region=\"us-east-1\" regions=\"us-east-1\";\nCREATE TABLE t3 (a INT) PLACEMENT POLICY=p1;\nSHOW PLACEMENT; -- Shows all information, including table t3.\nSELECT * FROM information_schema.placement_policies; -- Only shows placement policies, excluding t3.\n```\n\n----------------------------------------\n\nTITLE: Deleting TiDB Cloud Serverless Cluster using CLI\nDESCRIPTION: This command deletes a TiDB Cloud Serverless cluster from your project. It can be used in both interactive and non-interactive modes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-delete.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless delete [flags]\n```\n\n----------------------------------------\n\nTITLE: Sample CLUSTER_CONFIG Table Structure Output\nDESCRIPTION: Shows the table structure output for the CLUSTER_CONFIG table, displaying field names, data types, null constraints and other column properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-config.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+----------+--------------+------+------+---------+-------+\n| Field    | Type         | Null | Key  | Default | Extra |\n+----------+--------------+------+------+---------+-------+\n| TYPE     | varchar(64)  | YES  |      | NULL    |       |\n| INSTANCE | varchar(64)  | YES  |      | NULL    |       |\n| KEY      | varchar(256) | YES  |      | NULL    |       |\n| VALUE    | varchar(128) | YES  |      | NULL    |       |\n+----------+--------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Displaying Cluster Status after Scale-in\nDESCRIPTION: This command displays the current status of the cluster after the TiCDC node has been removed, allowing verification of the successful scale-in operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_26\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster display <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Displaying All Components Including Hidden Ones\nDESCRIPTION: Command to show all available components, including those that are typically hidden by default. Provides a comprehensive view of the entire component repository.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-list.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup list --all\n```\n\n----------------------------------------\n\nTITLE: BATCH Syntax Definition\nDESCRIPTION: EBNF syntax definition for the BATCH statement showing the grammar rules for non-transactional DML statements including delete, update, insert, and replace operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-batch.md#2025-04-18_snippet_2\n\nLANGUAGE: ebnf\nCODE:\n```\nNonTransactionalDMLStmt ::=\n    'BATCH' ( 'ON' ColumnName )? 'LIMIT' NUM DryRunOptions? ShardableStmt\n\nDryRunOptions ::=\n    'DRY' 'RUN' 'QUERY'?\n\nShardableStmt ::=\n    DeleteFromStmt\n|   UpdateStmt\n|   InsertIntoStmt\n|   ReplaceIntoStmt\n```\n\n----------------------------------------\n\nTITLE: Status Code 408 Response Example\nDESCRIPTION: This code snippet presents a Data Service response with an HTTP status code of 408, indicating that the request exceeded the endpoint's timeout duration. The `result.code` is 408, and the `message` field states \"request timeout.\". This response means the request took too long to process and was terminated.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-response-and-status-code.md#2025-04-18_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"sql_endpoint\",\n    \"data\": {\n        \"columns\": [],\n        \"rows\": [],\n        \"result\": {\n            \"code\": 408,\n            \"message\": \"request timeout.\",\n            \"start_ms\": \"\",\n            \"end_ms\": \"\",\n            \"latency\": \"\",\n            \"row_count\": 0,\n            \"row_affect\": 0,\n            \"limit\": 0\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Rolling Back a Transaction in TiDB\nDESCRIPTION: Example of rolling back a transaction using the ROLLBACK statement. This cancels all changes made in the current transaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/transaction-overview.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nROLLBACK;\n```\n\n----------------------------------------\n\nTITLE: Defining CREATE PLACEMENT POLICY Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the CREATE PLACEMENT POLICY statement in TiDB. It specifies the structure and options available when creating a placement policy.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-placement-policy.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCreatePolicyStmt ::=\n    \"CREATE\" \"PLACEMENT\" \"POLICY\" IfNotExists PolicyName PlacementOptionList\n\nPolicyName ::=\n    Identifier\n\nPlacementOptionList ::=\n    PlacementOption\n|   PlacementOptionList PlacementOption\n|   PlacementOptionList ',' PlacementOption\n\nPlacementOption ::=\n    CommonPlacementOption\n|   SugarPlacementOption\n|   AdvancedPlacementOption\n\nCommonPlacementOption ::=\n    \"FOLLOWERS\" EqOpt LengthNum\n\nSugarPlacementOption ::=\n    \"PRIMARY_REGION\" EqOpt stringLit\n|   \"REGIONS\" EqOpt stringLit\n|   \"SCHEDULE\" EqOpt stringLit\n\nAdvancedPlacementOption ::=\n    \"LEARNERS\" EqOpt LengthNum\n|   \"CONSTRAINTS\" EqOpt stringLit\n|   \"LEADER_CONSTRAINTS\" EqOpt stringLit\n|   \"FOLLOWER_CONSTRAINTS\" EqOpt stringLit\n|   \"LEARNER_CONSTRAINTS\" EqOpt stringLit\n|   \"SURVIVAL_PREFERENCES\" EqOpt stringLit\n```\n\n----------------------------------------\n\nTITLE: Modifying Linux Kernel Parameters\nDESCRIPTION: Commands to modify various sysctl parameters for optimizing system performance for TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_32\n\nLANGUAGE: bash\nCODE:\n```\necho \"fs.file-max = 1000000\">> /etc/sysctl.conf\necho \"net.core.somaxconn = 32768\">> /etc/sysctl.conf\necho \"net.ipv4.tcp_syncookies = 0\">> /etc/sysctl.conf\necho \"vm.overcommit_memory = 1\">> /etc/sysctl.conf\necho \"vm.min_free_kbytes = 1048576\">> /etc/sysctl.conf\nsysctl -p\n```\n\n----------------------------------------\n\nTITLE: Response Example - Querying Replication Tasks - TiCDC - JSON\nDESCRIPTION: This JSON response shows an example of the data returned when querying the replication task list. It includes information such as the `id`, `state`, `checkpoint_tso`, `checkpoint_time`, and `error` status of each replication task.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n[\n    {\n        \"id\": \"test1\",\n        \"state\": \"normal\",\n        \"checkpoint_tso\": 426921294362574849,\n        \"checkpoint_time\": \"2021-08-10 14:04:54.242\",\n        \"error\": null\n    },\n    {\n        \"id\": \"test2\",\n        \"state\": \"normal\",\n        \"checkpoint_tso\": 426921294362574849,\n        \"checkpoint_time\": \"2021-08-10 14:04:54.242\",\n        \"error\": null\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Defining Delete Event Value Format in JSON\nDESCRIPTION: Describes the value format for Delete events in Row Changed Events. It contains the deleted row data.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"d\":{\n        <Column Name>:{\n            \"t\":<Column Type>,\n            \"h\":<Where Handle>,\n            \"f\":<Flag>,\n            \"v\":<Column Value>\n        },\n        <Column Name>:{\n            \"t\":<Column Type>,\n            \"h\":<Where Handle>,\n            \"f\":<Flag>,\n            \"v\":<Column Value>\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP Cluster Replay Command in Shell\nDESCRIPTION: The command syntax for using 'tiup cluster replay'. It requires an audit ID as an argument, which can be obtained using the 'tiup cluster audit' command. The -h or --help flag can be used to print help information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-replay.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster replay <audit-id> [flags]\n```\n\n----------------------------------------\n\nTITLE: Disabling TiKV Auto-Tune via tikv-ctl\nDESCRIPTION: This snippet demonstrates how to disable the auto-tune feature in TiKV using the `tikv-ctl` command-line tool. This feature, introduced in TiDB v5.4.0, dynamically adjusts backup task resource usage based on cluster workload. Disabling it can be useful when you want to maximize backup speed, especially in offline clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n\"backup.enable-auto-tune\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TiSpark Master Nodes in YAML\nDESCRIPTION: Example configuration for TiSpark master nodes showing various Spark configurations and environment variables. Includes memory settings, GRPC parameters, and worker specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\ntispark_masters:\n  - host: 10.0.1.21\n    spark_config:\n      spark.driver.memory: \"2g\"\n      spark.eventLog.enabled: \"False\"\n      spark.tispark.grpc.framesize: 2147483647\n      spark.tispark.grpc.timeout_in_sec: 100\n      spark.tispark.meta.reload_period_in_sec: 60\n      spark.tispark.request.command.priority: \"Low\"\n      spark.tispark.table.scan_concurrency: 256\n    spark_env:\n      SPARK_EXECUTOR_CORES: 5\n      SPARK_EXECUTOR_MEMORY: \"10g\"\n      SPARK_WORKER_CORES: 5\n      SPARK_WORKER_MEMORY: \"10g\"\n  - host: 10.0.1.22\n```\n\n----------------------------------------\n\nTITLE: Creating a Knowledge Base with Chat2Query API - Bash\nDESCRIPTION: This snippet demonstrates how to create a knowledge base using the Chat2Query API by invoking a POST request to the specific endpoint. It requires the PUBLIC_KEY and PRIVATE_KEY for authentication and includes necessary data to define the knowledge base characteristics.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-knowledge.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user ${PUBLIC_KEY}:${PRIVATE_KEY} --request POST 'https://<region>.data.tidbcloud.com/api/v1beta/app/chat2query-<ID>/endpoint/v3/knowledgeBases'\\\n --header 'content-type: application/json'\\\n --data-raw '{\n    \"cluster_id\": \"<The ID of the cluster to which the database belongs>\",\n    \"database\": \"<The name of the target database>\",\n    \"description\": \"<Your knowledge base description>\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Sample Output of get-region-read-progress Command\nDESCRIPTION: Example output from the get-region-read-progress command showing Region read progress status and resolver information. This helps diagnose issues with stale reads by showing timestamps, indices, and lock information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_31\n\nLANGUAGE: shell\nCODE:\n```\nRegion read progress:\n    exist: true,\n    safe_ts: 0,\n    applied_index: 92,\n    pending front item (oldest) ts: 0,\n    pending front item (oldest) applied index: 0,\n    pending back item (latest) ts: 0,\n    pending back item (latest) applied index: 0,\n    paused: false,\nResolver:\n    exist: true,\n    resolved_ts: 0,\n    tracked index: 92,\n    number of locks: 0,\n    number of transactions: 0,\n    stopped: false,\n```\n\n----------------------------------------\n\nTITLE: Index Creation and Join Query Analysis in TiDB\nDESCRIPTION: SQL statements for adding an index on t2.t1_id column and executing different join strategies including index nested loop join, hash join, and default join with EXPLAIN ANALYZE\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n-- Re-add index\nALTER TABLE t2 ADD INDEX (t1_id);\n\nEXPLAIN ANALYZE SELECT /*+ INL_JOIN(t1, t2) */  * FROM t1 INNER JOIN t2 ON t1.id = t2.t1_id WHERE t1.int_col = 1;\nEXPLAIN ANALYZE SELECT /*+ HASH_JOIN(t1, t2) */  * FROM t1 INNER JOIN t2 ON t1.id = t2.t1_id WHERE t1.int_col = 1;\nEXPLAIN ANALYZE SELECT * FROM t1 INNER JOIN t2 ON t1.id = t2.t1_id WHERE t1.int_col = 1;\n```\n\n----------------------------------------\n\nTITLE: Schema-Level Route Configuration in TOML\nDESCRIPTION: Configuration example demonstrating how to set up routing rules for comparing multiple tables between databases with different schema names.\nSOURCE: https://github.com/pingcap/docs/blob/master/sync-diff-inspector/route-diff.md#2025-04-18_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n######################### Datasource config #########################\n[data-sources.mysql1]\n    host = \"127.0.0.1\"\n    port = 3306\n    user = \"root\"\n    password = \"\"\n    route-rules = [\"rule1\"]\n\n[data-sources.tidb0]\n    host = \"127.0.0.1\"\n    port = 4000\n    user = \"root\"\n    password = \"\"\n########################### Routes ###########################\n[routes.rule1]\nschema-pattern = \"test_1\"      # Matches the schema name of the data source. Supports the wildcards \"*\" and \"?\"\ntable-pattern = \"*\"            # Matches the table name of the data source. Supports the wildcards \"*\" and \"?\"\ntarget-schema = \"test_2\"       # The name of the schema in the target database\ntarget-table = \"t_2\"           # The name of the target table\n```\n\n----------------------------------------\n\nTITLE: MySQL Compatibility Variable\nDESCRIPTION: Example showing TiDB's compatibility with MySQL 5.7's noop variable innodb_default_row_format, which has no effect when set.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.3.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET innodb_default_row_format = 'value';\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiKV cluster with tikv-ctl\nDESCRIPTION: This command-line example shows how to connect to a TiKV cluster using `tikv-ctl` after enabling TLS.  It uses the `--ca-path`, `--cert-path`, and `--key-path` parameters to provide the CA certificate, client certificate, and client key for secure authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n    ```bash\n    ./tikv-ctl --host=\"127.0.0.1:20160\" --ca-path=\"/path/to/ca.pem\" --cert-path=\"/path/to/client.pem\" --key-path=\"/path/to/clinet-key.pem\"\n    ```\n```\n\n----------------------------------------\n\nTITLE: CLIENT_ERRORS_SUMMARY_GLOBAL Table Output Structure\nDESCRIPTION: Shows the table structure output with six columns including ERROR_NUMBER, ERROR_MESSAGE, ERROR_COUNT, WARNING_COUNT, FIRST_SEEN, and LAST_SEEN with their respective data types and properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/client-errors-summary-global.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+---------------+---------------+------+------+---------+-------+\n| Field         | Type          | Null | Key  | Default | Extra |\n+---------------+---------------+------+------+---------+-------+\n| ERROR_NUMBER  | bigint(64)    | NO   |      | NULL    |       |\n| ERROR_MESSAGE | varchar(1024) | NO   |      | NULL    |       |\n| ERROR_COUNT   | bigint(64)    | NO   |      | NULL    |       |\n| WARNING_COUNT | bigint(64)    | NO   |      | NULL    |       |\n| FIRST_SEEN    | timestamp     | YES  |      | NULL    |       |\n| LAST_SEEN     | timestamp     | YES  |      | NULL    |       |\n+---------------+---------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Clustered Primary Key in SQL\nDESCRIPTION: The SQL statement illustrates the creation of a table where the primary key is defined as a clustered index. This approach facilitates quicker access to rows through the primary key and is supported by TiDB's clustering logic. Required configuration includes ensuring the clustered index feature is active or using the CLUSTERED keyword explicitly.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `t` (`a` VARCHAR(255) PRIMARY KEY CLUSTERED, `b` INT);\n```\n\n----------------------------------------\n\nTITLE: Writing Data to TiDB using JDBC DataSource in Scala\nDESCRIPTION: Demonstrates writing data to TiDB using Spark JDBC with custom configuration options for performance and connection settings\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_4\n\nLANGUAGE: scala\nCODE:\n```\nimport org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions\n\nval customer = spark.sql(\"select * from customer limit 100000\")\n// you might need to repartition the source to make it balanced across nodes\n// and increase concurrency\nval df = customer.repartition(32)\ndf.write\n.mode(saveMode = \"append\")\n.format(\"jdbc\")\n.option(\"driver\", \"com.mysql.jdbc.Driver\")\n // replace the host and port with yours and be sure to use rewrite batch\n.option(\"url\", \"jdbc:mysql://127.0.0.1:4000/test?rewriteBatchedStatements=true\")\n.option(\"useSSL\", \"false\")\n// as tested, setting to `150` is a good practice\n.option(JDBCOptions.JDBC_BATCH_INSERT_SIZE, 150)\n.option(\"dbtable\", s\"cust_test_select\") // database name and table name here\n.option(\"isolationLevel\", \"NONE\") // set isolationLevel to NONE\n.option(\"user\", \"root\") // TiDB user here\n.save()\n```\n\n----------------------------------------\n\nTITLE: Member Management Commands\nDESCRIPTION: Commands for managing PD cluster members, including viewing member information, deleting members, and managing leader priorities.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\n>> member\n>> member delete name pd2\n>> member delete id 1319539429105371180\n>> member leader show\n>> member leader resign\n>> member leader transfer pd3\n\nmember leader_priority  pd-1 4\nmember leader_priority  pd-2 3\nmember leader_priority  pd-3 2\nmember leader_priority  pd-4 1\nmember leader_priority  pd-5 0\n```\n\n----------------------------------------\n\nTITLE: Viewing Result from TIDB_ENCODE_SQL_DIGEST for 'SELECT 2'\nDESCRIPTION: Shows the output of TIDB_ENCODE_SQL_DIGEST for 'SELECT 2', which produces the same digest as 'SELECT 1' because both normalize to 'SELECT ?'.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------------------------------------------+\n| TIDB_ENCODE_SQL_DIGEST('SELECT 2')                               |\n+------------------------------------------------------------------+\n| e1c71d1661ae46e09b7aaec1c390957f0d6260410df4e4bc71b9c8d681021471 |\n+------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Filtering Regions by Store ID in TiKV\nDESCRIPTION: This command filters Regions to find those with a specified store ID by adjusting the selection criteria in Jq.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_67\n\nLANGUAGE: bash\nCODE:\n```\nregion --jq=\".regions[] | {id: .id, peer_stores: [.peers[].store_id] | select(any(.==30))}\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nregion --jq=\".regions[] | {id: .id, peer_stores: [.peers[].store_id] | select(any(.==(30,31)))}\"\n```\n\n----------------------------------------\n\nTITLE: Sysbench Configuration Example\nDESCRIPTION: Sample configuration for Sysbench benchmarking tool showing connection parameters, test duration, thread counts, and reporting interval for TiDB testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_3\n\nLANGUAGE: txt\nCODE:\n```\nmysql-host={TIDB_HOST}\nmysql-port=4000\nmysql-user=root\nmysql-password=password\nmysql-db=sbtest\ntime=600\nthreads={8, 16, 32, 64, 128, 256}\nreport-interval=10\ndb-driver=mysql\n```\n\n----------------------------------------\n\nTITLE: Checking for potential risks before scaling out\nDESCRIPTION: This command checks the cluster for potential risks before scaling out using the provided topology file. It validates the configuration and identifies any issues that might prevent a successful scale-out operation. The `--cluster` flag specifies that the check should be performed against the existing cluster state.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster check <cluster-name> scale-out.yml --cluster --user root [-p] [-i /home/root/.ssh/gcp_rsa]\"\n```\n\n----------------------------------------\n\nTITLE: Running Terraform Apply for TiDB Cloud Restore\nDESCRIPTION: Terminal output showing the Terraform apply command execution for creating a restore task in TiDB Cloud. The output displays the execution plan and confirmation prompt.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-restore-resource.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform apply\ntidbcloud_cluster.example_cluster: Refreshing state... [id=1379661944630234067]\ntidbcloud_backup.example_backup: Refreshing state... [id=1350048]\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # tidbcloud_restore.example_restore will be created\n  + resource \"tidbcloud_restore\" \"example_restore\" {\n      + backup_id        = \"1350048\"\n      + cluster          = {\n          + id     = (known after apply)\n          + name   = (known after apply)\n          + status = (known after apply)\n        }\n      + cluster_id       = (known after apply)\n      + config           = {\n          + components    = {\n              + tidb    = {\n                  + node_quantity = 2\n                  + node_size     = \"8C16G\"\n                }\n              + tiflash = {\n                  + node_quantity    = 2\n                  + node_size        = \"8C64G\"\n                  + storage_size_gib = 500\n                }\n              + tikv    = {\n                  + node_quantity    = 6\n                  + node_size        = \"8C32G\"\n                  + storage_size_gib = 500\n                }\n            }\n          + port          = 4000\n          + root_password = \"Your_root_password1.\"\n        }\n      + create_timestamp = (known after apply)\n      + error_message    = (known after apply)\n      + id               = (known after apply)\n      + name             = \"restoreCluster\"\n      + project_id       = \"1372813089189561287\"\n      + status           = (known after apply)\n    }\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\nDo you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only 'yes' will be accepted to approve.\n\n  Enter a value: yes\n\ntidbcloud_restore.example_restore: Creating...\ntidbcloud_restore.example_restore: Creation complete after 1s [id=780114]\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n```\n\n----------------------------------------\n\nTITLE: Query Execution Plan Before Distinct Optimization\nDESCRIPTION: Shows the execution plan for a count distinct query before enabling the optimization, demonstrating slower performance due to processing distinct operations in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nmysql> explain analyze select count(distinct a) from test.t;\n```\n\n----------------------------------------\n\nTITLE: Setting Active User Profile in TiDB Cloud CLI (Shell)\nDESCRIPTION: This command sets a specified profile as the active user profile in the TiDB Cloud CLI. It requires the profile name as an argument and can be used with optional flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-use.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud config use <profile-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Simulating Write Workload in TiDB Clusters\nDESCRIPTION: This command simulates service workload by continuously writing data to specified tables in the upstream TiDB cluster using Sysbench. It allows up to 100 transactions per second (TPS) with 10 worker threads. Dependencies include the same Sysbench configuration as above.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-between-primary-and-secondary-clusters.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nsysbench oltp_write_only --config-file=./tidb-config --tables=3 run\n```\n\n----------------------------------------\n\nTITLE: Viewing Log Start Command Options in Shell\nDESCRIPTION: Displays help information for the log backup start command, showing available parameters for initiating a log backup task.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log start --help\nstart a log backup task\n\nUsage:\n  br log start [flags]\n\nFlags:\n  -h, --help               help for start\n  --start-ts string        usually equals last full backupTS, used for backup log. Default value is current ts. support TSO or datetime, e.g. '400036290571534337' or '2018-05-11 01:42:23+0800'.\n  --task-name string       The task name for the backup log task.\n\nGlobal Flags:\n --ca string                  CA certificate path for TLS connection\n --cert string                Certificate path for TLS connection\n --key string                 Private key path for TLS connection\n -u, --pd strings             PD address (default [127.0.0.1:2379])\n -s, --storage string         specify the url where backup storage, eg, \"s3://bucket/path/prefix\"\n\n```\n\n----------------------------------------\n\nTITLE: TiKV Configuration Setting\nDESCRIPTION: Default configuration value change for leader transfer maximum log lag parameter to improve transfer success rate.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.12.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nleader-transfer-max-log-lag\n```\n\n----------------------------------------\n\nTITLE: Ignoring Checking Items in DM Configuration - YAML\nDESCRIPTION: This YAML configuration snippet specifies items that should be ignored during privilege checking in DM. It is necessary when using accounts without SUPER privileges in MariaDB to enable smooth data migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-mariadb.md#2025-04-18_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nignore-checking-items: [\"replication_privilege\"]\n```\n\n----------------------------------------\n\nTITLE: Executing PD Control command in single-command mode\nDESCRIPTION: This snippet demonstrates how to execute a PD Control command in single-command mode. It uses `tiup ctl` to execute the `pd store` command, retrieving store information from the PD server at the specified address.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd store -u http://127.0.0.1:2379\n```\n\n----------------------------------------\n\nTITLE: MySQL User Creation and Privileges\nDESCRIPTION: SQL commands to create a dedicated user for DM with necessary replication privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'tidb-dm'@'%'\n    IDENTIFIED WITH mysql_native_password\n    BY 'MyPassw0rd!';\n\nGRANT PROCESS, BACKUP_ADMIN, RELOAD, REPLICATION SLAVE, REPLICATION CLIENT, SELECT ON *.* TO 'tidb-dm'@'%';\n```\n\n----------------------------------------\n\nTITLE: Drizzle ORM Implementation with TiDB\nDESCRIPTION: TypeScript code demonstrating Drizzle ORM setup, schema definition, and data operations with TiDB Cloud serverless driver.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-drizzle-example.md#2025-04-18_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { connect } from '@tidbcloud/serverless';\nimport { drizzle } from 'drizzle-orm/tidb-serverless';\nimport { mysqlTable, serial, text, varchar } from 'drizzle-orm/mysql-core';\n\n// Initialize\nconst client = connect({ url: process.env.DATABASE_URL });\nconst db = drizzle(client);\n\n// Define schema\nexport const users = mysqlTable('users', {\n  id: serial(\"id\").primaryKey(),\n  fullName: text('full_name'),\n  phone: varchar('phone', { length: 256 }),\n});\nexport type User = typeof users.$inferSelect; // return type when queried\nexport type NewUser = typeof users.$inferInsert; // insert type\n\n// Insert and select data\nconst user: NewUser = { fullName: 'John Doe', phone: '123-456-7890' };\nawait db.insert(users).values(user)\nconst result: User[] = await db.select().from(users);\nconsole.log(result);\n```\n\n----------------------------------------\n\nTITLE: Enforcing MPP Query Execution Mode in TiDB SQL\nDESCRIPTION: Controls whether to ignore the optimizer's cost estimation and forcibly use the MPP mode for query execution. This is a newly added system variable in TiDB 5.1 with a default value of false.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.0.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_enforce_mpp = TRUE|FALSE;\n```\n\n----------------------------------------\n\nTITLE: Updating CREATE Statement for a Table (Shell)\nDESCRIPTION: This snippet demonstrates how to use cURL to update the CREATE statement for a specific table in a schema associated with a replication task. It sends a PUT request to the API endpoint with the new SQL content and optional flush and sync parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_42\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'PUT' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1/sources/task-1/schemas/db1/table1' \\\n  -H 'accept: */*' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"sql_content\": \"CREATE TABLE `t1` ( `c1` int DEFAULT NULL, `c2` int DEFAULT NULL, `c3` int DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\",\n  \"flush\": true,\n  \"sync\": true\n}'\n```\n\n----------------------------------------\n\nTITLE: Standard Method for Using STRAIGHT_JOIN in TiDB\nDESCRIPTION: Shows the standard way to use STRAIGHT_JOIN in TiDB without comment syntax. This is equivalent to using the MySQL-compatible comment syntax shown above.\nSOURCE: https://github.com/pingcap/docs/blob/master/comment-syntax.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT STRAIGHT_JOIN col1 FROM table1,table2 WHERE ...\n```\n\n----------------------------------------\n\nTITLE: Canceling Export Task via TiDB Cloud CLI\nDESCRIPTION: This command cancels an ongoing export task in TiDB Cloud using the CLI. It requires the cluster ID and export ID as parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-export.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export cancel -c <cluster-id> -e <export-id>\n```\n\n----------------------------------------\n\nTITLE: Monitoring Encryption in TiKV - Monitoring Instructions\nDESCRIPTION: This section provides insights into how to monitor encryption status within TiKV using metrics to track the initialization of encryption and data key statistics for performance monitoring.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_8\n\nLANGUAGE: ini\nCODE:\n```\n# No specific code snippet for this section, descriptive content only.\n# You can monitor the following metrics in Grafana:\n# - Encryption initialized\n# - Encryption data keys\n# - Encrypted files\n# - Encryption meta file size\n# - Read/Write encryption meta duration\n```\n\n----------------------------------------\n\nTITLE: Describing TIDB_TRX Table Structure in SQL\nDESCRIPTION: SQL commands to access and describe the structure of the TIDB_TRX table in the INFORMATION_SCHEMA database, showing all available columns and their data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-trx.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC TIDB_TRX;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+-------------------------+-----------------------------------------------------------------+------+------+---------+-------+\n| Field                   | Type                                                            | Null | Key  | Default | Extra |\n+-------------------------+-----------------------------------------------------------------+------+------+---------+-------+\n| ID                      | bigint(21) unsigned                                             | NO   | PRI  | NULL    |       |\n| START_TIME              | timestamp(6)                                                    | YES  |      | NULL    |       |\n| CURRENT_SQL_DIGEST      | varchar(64)                                                     | YES  |      | NULL    |       |\n| CURRENT_SQL_DIGEST_TEXT | text                                                            | YES  |      | NULL    |       |\n| STATE                   | enum('Idle','Running','LockWaiting','Committing','RollingBack') | YES  |      | NULL    |       |\n| WAITING_START_TIME      | timestamp(6)                                                    | YES  |      | NULL    |       |\n| MEM_BUFFER_KEYS         | bigint(64)                                                      | YES  |      | NULL    |       |\n| MEM_BUFFER_BYTES        | bigint(64)                                                      | YES  |      | NULL    |       |\n| SESSION_ID              | bigint(21) unsigned                                             | YES  |      | NULL    |       |\n| USER                    | varchar(16)                                                     | YES  |      | NULL    |       |\n| DB                      | varchar(64)                                                     | YES  |      | NULL    |       |\n| ALL_SQL_DIGESTS         | text                                                            | YES  |      | NULL    |       |\n| RELATED_TABLE_IDS       | text                                                            | YES  |      | NULL    |       |\n+-------------------------+-----------------------------------------------------------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Key-Value Mapping: Secondary Index\nDESCRIPTION: This code snippet illustrates the encoding for ordinary secondary indexes in TiDB, where a single key might correspond to multiple rows, requiring range queries. The key includes the table ID, index ID, indexed column values, and the `RowID`, while the value is typically `null`.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-computing.md#2025-04-18_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n\"Key:   tablePrefix{TableID}_indexPrefixSep{IndexID}_indexedColumnsValue_{RowID}\\nValue: null\"\n```\n\n----------------------------------------\n\nTITLE: SQL Query to Identify Potential MVCC Amplification Issues\nDESCRIPTION: SQL query to detect slow queries in TiDB where Total_keys is significantly greater than Process_keys, indicating potential MVCC amplification issues that could benefit from the in-memory engine.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-in-memory-engine.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    Time,\n    DB,\n    Index_names,\n    Process_keys,\n    Total_keys,\n    CONCAT(\n        LEFT(REGEXP_REPLACE(Query, '\\\\s+', ' '), 20),\n        '...',\n        RIGHT(REGEXP_REPLACE(Query, '\\\\s+', ' '), 10)\n    ) as Query,\n    Query_time,\n    Cop_time,\n    Process_time\nFROM\n    INFORMATION_SCHEMA.SLOW_QUERY\nWHERE\n    Is_internal = 0\n    AND Cop_time > 1\n    AND Process_keys > 0\n    AND Total_keys / Process_keys >= 10\n    AND Time >= NOW() - INTERVAL 10 MINUTE\nORDER BY Total_keys DESC\nLIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Configuring tidb_enable_paging in TiDB\nDESCRIPTION: This variable controls the use of paging in coprocessor requests. The behavior differs by TiDB version, significantly aiding OLTP scenarios and limiting resource consumption in specific contexts.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_34\n\nLANGUAGE: markdown\nCODE:\n```\n- Scope: SESSION | GLOBAL\n- Persists to cluster: Yes\n- Applies to hint [SET_VAR](/optimizer-hints.md#set_varvar_namevar_value): Yes\n- Type: Boolean\n- Default value: `ON`\n- This variable controls whether to use the method of paging to send coprocessor requests.\n```\n\n----------------------------------------\n\nTITLE: Listing TiUP Clusters using `tiup cluster list` command\nDESCRIPTION: This snippet shows how to use the `tiup cluster list` command to list the TiDB clusters managed by TiUP. The output includes the cluster name, user, version, path, and private key, providing essential information for identifying the user and configuration details of the TiDB cluster involved in backup and restore operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\n\n    tiup cluster list\n    \n```\n\n----------------------------------------\n\nTITLE: DDL Progress Output Example\nDESCRIPTION: Example output of ADMIN SHOW DDL command showing schema version, owner ID, running job details including index addition progress and other metadata.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/sql-faq.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n*************************** 1. row ***************************\n  SCHEMA_VER: 140\n       OWNER: 1a1c4174-0fcd-4ba0-add9-12d08c4077dc\nRUNNING_JOBS: ID:121, Type:add index, State:running, SchemaState:write reorganization, SchemaID:1, TableID:118, RowCount:77312, ArgLen:0, start time: 2018-12-05 16:26:10.652 +0800 CST, Err:<nil>, ErrCount:0, SnapshotVersion:404749908941733890\n     SELF_ID: 1a1c4174-0fcd-4ba0-add9-12d08c4077dc\n```\n\n----------------------------------------\n\nTITLE: Configuring MySQL Data Source for DM in YAML\nDESCRIPTION: This YAML configuration defines a MySQL data source for TiDB Data Migration (DM). It specifies the source ID, GTID settings, and connection details for the upstream MySQL database.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n# MySQL Configuration.\nsource-id: \"mysql-replica-01\"\n# Specifies whether DM-worker pulls binlogs with GTID (Global Transaction Identifier).\n# The prerequisite is that you have already enabled GTID in the upstream MySQL.\n# If you have configured the upstream database service to switch master between different nodes automatically, you must enable GTID.\nenable-gtid: true\nfrom:\n host: \"${host}\"           # For example: 192.168.10.101\n user: \"user01\"\n password: \"${password}\"   # Plaintext passwords are supported but not recommended. It is recommended that you use dmctl encrypt to encrypt plaintext passwords.\n port: ${port}             # For example: 3307\n```\n\n----------------------------------------\n\nTITLE: Unlocking Table Statistics and Running ANALYZE in TiDB\nDESCRIPTION: This SQL snippet demonstrates unlocking table statistics with UNLOCK STATS, which allows the ANALYZE statement to be successfully executed again without the 'skip analyze' warning.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_24\n\nLANGUAGE: sql\nCODE:\n```\nmysql> UNLOCK STATS t;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> ANALYZE TABLE t;\nQuery OK, 0 rows affected, 1 warning (0.03 sec)\n\nmysql> SHOW WARNINGS;\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------+\n| Level | Code | Message                                                                                                                                 |\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------+\n| Note  | 1105 | Analyze use auto adjusted sample rate 1.000000 for table test.t, reason to use this rate is \"use min(1, 110000/8) as the sample-rate=1\" |\n+-------+------+-----------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Obtaining ts-map in TiDB (SQL)\nDESCRIPTION: This SQL query fetches the current ts-map from the downstream TiDB cluster, which contains mappings between upstream and downstream timestamps necessary for consistent snapshot reads and data validation.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-upstream-downstream-check.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nselect * from tidb_cdc.syncpoint_v1;\n+------------------+----------------+--------------------+--------------------+---------------------+\n| ticdc_cluster_id | changefeed     | primary_ts         | secondary_ts       | created_at          |\n+------------------+----------------+--------------------+--------------------+---------------------+\n| default          | test-2         | 435953225454059520 | 435953235516456963 | 2022-09-13 08:40:15 |\n+------------------+----------------+--------------------+--------------------+---------------------+\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB Current TSO\nDESCRIPTION: This SQL snippet queries the current timestamp oracle (TSO) in TiDB, which is used to coordinate the replication state between primary and secondary clusters for switchover operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dr-secondary-cluster.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nBEGIN; SELECT TIDB_CURRENT_TSO(); ROLLBACK;\n```\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.00 sec)\n\n+--------------------+\n| TIDB_CURRENT_TSO() |\n+--------------------+\n| 452654700157468673 |\n+--------------------+\n1 row in set (0.00 sec)\n\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Enabling Strict Format for CSV Files in TiDB Lightning\nDESCRIPTION: TOML configuration to enable strict format for CSV files, allowing TiDB Lightning to automatically split large files when no fields contain newline characters, which helps improve import speed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/troubleshoot-tidb-lightning.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[mydumper]\nstrict-format = true\n```\n\n----------------------------------------\n\nTITLE: DR Auto-Sync Configuration: wait-recover-timeout\nDESCRIPTION: DR Auto-Sync supports configuring `wait-recover-timeout`, which enables you to control the waiting time for switching back to the `sync-recover` status after the network recovers. This configuration enhances control over the DR Auto-Sync process.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.5.9.md#2025-04-18_snippet_1\n\nLANGUAGE: N/A\nCODE:\n```\nDR Auto-Sync supports configuring [`wait-recover-timeout`](https://docs.pingcap.com/tidb/v6.5/two-data-centers-in-one-city-deployment#enable-the-dr-auto-sync-mode), which enables you to control the waiting time for switching back to the `sync-recover` status after the network recovers [#6295](https://github.com/tikv/pd/issues/6295) @[disksing](https://github.com/disksing)\n```\n\n----------------------------------------\n\nTITLE: Calculating Negative Inner Product in TiDB SQL\nDESCRIPTION: VEC_NEGATIVE_INNER_PRODUCT function calculates the negative dot product between two vectors. The vectors must have the same dimension.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-functions-and-operators.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VEC_NEGATIVE_INNER_PRODUCT('[1,2]', '[3,4]');\n```\n\n----------------------------------------\n\nTITLE: Updating the TiDB Cloud CLI\nDESCRIPTION: This command updates the TiDB Cloud CLI to the latest version if the currently installed version is outdated.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nticloud update\n```\n\n----------------------------------------\n\nTITLE: Generate CSV Data for Specific TPC-C Tables (Bash)\nDESCRIPTION: This command generates CSV data for the `history` and `orders` tables of the TPC-C benchmark, placing the output in the `data` directory. It extends the previous example by adding the `--tables` flag to specify the tables for which data should be generated.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench tpcc --warehouses 4 prepare --output-dir data --output-type=csv --tables history,orders\n```\n\n----------------------------------------\n\nTITLE: Documentation Page Structure with Learning Path Components\nDESCRIPTION: Hierarchical HTML structure using custom LearningPathContainer and LearningPath components to organize TiDB documentation into logical sections with icons and links.\nSOURCE: https://github.com/pingcap/docs/blob/master/_index.md#2025-04-18_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<LearningPathContainer platform=\"tidb\" title=\"TiDB Self-Managed\" subTitle=\"TiDB is an open-source distributed SQL database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads. Find the guide, samples, and references you need to use TiDB.\">\n\n<!-- Localization note for TiDB:\n\n- English: use distributed SQL, and start to emphasize HTAP\n- Chinese: can keep \"NewSQL\" and emphasize one-stop real-time HTAP (\"一栈式实时 HTAP\")\n- Japanese: use NewSQL because it is well-recognized\n\n-->\n\n<LearningPath label=\"Learn\" icon=\"cloud1\">\n[...]\n</LearningPath>\n\n<LearningPath label=\"Try\" icon=\"cloud5\">\n[...]\n</LearningPath>\n\n[Additional LearningPath components...]</LearningPathContainer>\n```\n\n----------------------------------------\n\nTITLE: Table Renaming in MySQL with gh-ost\nDESCRIPTION: SQL statement for final table renaming to complete the online DDL operation. DM splits this into separate operations and applies the recorded DDL changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nRename /* gh-ost */ table `test`.`test4` to `test`.`_test4_del`, `test`.`_test4_gho` to `test`.`test4`;\n```\n\n----------------------------------------\n\nTITLE: Creating Bikeshare Database Schema in TiDB\nDESCRIPTION: SQL statements to create the bikeshare database schema and trips table in TiDB. The table structure includes fields for trip details such as duration, dates, station information, bike number, and member type.\nSOURCE: https://github.com/pingcap/docs/blob/master/import-example-data.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SCHEMA bikeshare;\nUSE bikeshare;\nCREATE TABLE trips (\n  `trip_id` BIGINT NOT NULL PRIMARY KEY AUTO_RANDOM,\n  `duration` INT NOT NULL,\n  `start date` DATETIME,\n  `end date` DATETIME,\n  `start station number` INT,\n  `start station` VARCHAR(255),\n  `end station number` INT,\n  `end station` VARCHAR(255),\n  `bike number` VARCHAR(255),\n  `member type` VARCHAR(255)\n);\n```\n\n----------------------------------------\n\nTITLE: REVOKE Role Statement Syntax in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the REVOKE role statement, showing the structure for revoking roles from users.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-revoke-role.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nRevokeRoleStmt ::=\n    'REVOKE' RolenameList 'FROM' UsernameList\n\nRolenameList ::=\n    Rolename ( ',' Rolename )*\n\nUsernameList ::=\n    Username ( ',' Username )*\n```\n\n----------------------------------------\n\nTITLE: CLUSTER_LOAD Table Structure Output\nDESCRIPTION: Displays the result of describing the CLUSTER_LOAD table, showing six columns that store instance and device load information.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-load.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+-------------+--------------+------+------+---------+-------+\n| Field       | Type         | Null | Key  | Default | Extra |\n+-------------+--------------+------+------+---------+-------+\n| TYPE        | varchar(64)  | YES  |      | NULL    |       |\n| INSTANCE    | varchar(64)  | YES  |      | NULL    |       |\n| DEVICE_TYPE | varchar(64)  | YES  |      | NULL    |       |\n| DEVICE_NAME | varchar(64)  | YES  |      | NULL    |       |\n| NAME        | varchar(256) | YES  |      | NULL    |       |\n| VALUE       | varchar(128) | YES  |      | NULL    |       |\n+-------------+--------------+------+------+---------+-------+\n6 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: SQL Configuration to Disable Mutation Checker\nDESCRIPTION: SQL command to disable the mutation checker which validates data consistency during write operations. This configuration bypasses checks for errors 8138, 8139, and 8140.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-data-inconsistency-errors.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_enable_mutation_checker=0\n```\n\n----------------------------------------\n\nTITLE: Updating Replication Task Configuration via API - TiCDC - Shell\nDESCRIPTION: This example demonstrates how to update the `mounter_worker_num` configuration of a TiCDC replication task using a PUT request to the API. The request sends a JSON payload specifying the new value for `mounter_worker_num` to the specified changefeed ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X PUT -H \"'Content-type':'application/json'\" http://127.0.0.1:8300/api/v1/changefeeds/test1 -d '{\"mounter_worker_num\":32}'\n```\n\n----------------------------------------\n\nTITLE: Dropping a View in TiDB SQL\nDESCRIPTION: This snippet shows how to drop a view in TiDB using the DROP VIEW statement. It removes the book_with_ratings view from the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-views.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nDROP VIEW book_with_ratings;\n```\n\n----------------------------------------\n\nTITLE: Displaying Table Structure in Markdown\nDESCRIPTION: This code snippet shows a markdown table structure listing the table name and description for the sys schema in TiDB. It includes information about the schema_unused_indexes table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sys-schema/sys-schema.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Table name                                                                                       | Description                                               |\n|--------------------------------------------------------------------------------------------------|-----------------------------------------------------------|\n| [`schema_unused_indexes`](/sys-schema/sys-schema-unused-indexes.md)                                  | Records indexes that have not been used since the last start of TiDB. |\n```\n\n----------------------------------------\n\nTITLE: Command Line Execution Bash\nDESCRIPTION: This code snippet demonstrates how to enter a command in a Bash terminal as part of a task step. No additional dependencies are required. The command execution will have an expected output that users can verify to ensure successful operation. The inputs are command line instructions, and the output is a confirmation of successful execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/resources/doc-templates/template-task.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# command\n```\n\n----------------------------------------\n\nTITLE: Searching for Write Conflicts in TiDB Logs\nDESCRIPTION: Example log entry showing a write conflict in TiDB with detailed information about the transaction timestamps, conflicting keys, and table information.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-write-conflicts.md#2025-04-18_snippet_0\n\nLANGUAGE: log\nCODE:\n```\n[2020/05/12 15:17:01.568 +08:00] [WARN] [session.go:446] [\"commit failed\"] [conn=3] [\"finished txn\"=\"Txn{state=invalid}\"] [error=\"[kv:9007]Write conflict, txnStartTS=416617006551793665, conflictStartTS=416617018650001409, conflictCommitTS=416617023093080065, key={tableID=47, indexID=1, indexValues={string, }} primary={tableID=47, indexID=1, indexValues={string, }} [try again later]\"]\n```\n\n----------------------------------------\n\nTITLE: Querying Top 50 Eldest Authors Using Non-recursive CTE in SQL\nDESCRIPTION: This SQL snippet demonstrates how to use a non-recursive CTE to query information about the 50 oldest authors and the number of books they've written.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-common-table-expression.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nWITH top_50_eldest_authors_cte AS (\n    SELECT a.id, a.name, (IFNULL(a.death_year, YEAR(NOW())) - a.birth_year) AS age\n    FROM authors a\n    ORDER BY age DESC\n    LIMIT 50\n)\nSELECT\n    ANY_VALUE(ta.id) AS author_id,\n    ANY_VALUE(ta.age) AS author_age,\n    ANY_VALUE(ta.name) AS author_name,\n    COUNT(*) AS books\nFROM top_50_eldest_authors_cte ta\nLEFT JOIN book_authors ba ON ta.id = ba.author_id\nGROUP BY ta.id;\n```\n\n----------------------------------------\n\nTITLE: Performing Similarity Search with Relevance Scores in Python using TiDB Vector Store\nDESCRIPTION: This code shows how to use similarity_search_with_relevance_scores() method to find the top k documents with the highest relevance scores from a TiDB vector store. Higher scores indicate greater similarity between document and query.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndocs_with_relevance_score = vector_store.similarity_search_with_relevance_scores(query, k=2)\nfor doc, score in docs_with_relevance_score:\n    print(\"-\" * 80)\n    print(\"Score: \", score)\n    print(doc.page_content)\n    print(\"-\" * 80)\n```\n\n----------------------------------------\n\nTITLE: Directory Structure for BR Checkpoint Data\nDESCRIPTION: Example directory tree showing the organization of checkpoint data in external storage, including paths for log, SST, and snapshot data.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-checkpoint-restore.md#2025-04-18_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n.\n`-- restore-{downstream-cluster-ID}\n    |-- log\n    |   |-- checkpoint.meta\n    |   |-- data\n    |   |   |-- {uuid}.cpt\n    |   |   |-- {uuid}.cpt\n    |   |   `-- {uuid}.cpt\n    |   |-- ingest_index.meta\n    |   `-- progress.meta\n    |-- snapshot\n    |   |-- checkpoint.meta\n    |   |-- checksum\n    |   |   |-- {uuid}.cpt\n    |   |   |-- {uuid}.cpt\n    |   |   `-- {uuid}.cpt\n    |   `-- data\n    |       |-- {uuid}.cpt\n    |       |-- {uuid}.cpt\n    |       `-- {uuid}.cpt\n    `-- sst\n        `-- checkpoint.meta\n```\n\n----------------------------------------\n\nTITLE: Comparing NULL Sorting Behavior in Oracle and TiDB SQL Queries\nDESCRIPTION: Examples showing equivalent ORDER BY statements between Oracle and TiDB with different NULL handling. In TiDB, NULL values appear first in ascending sorts and last in descending sorts by default, which differs from Oracle's behavior where NULLS FIRST/LAST can be explicitly specified.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_32\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 ORDER BY name NULLS FIRST;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 ORDER BY name;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 ORDER BY name DESC NULLS LAST;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 ORDER BY name DESC;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 ORDER BY name DESC NULLS FIRST;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 ORDER BY ISNULL(name) DESC, name DESC;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 ORDER BY name ASC NULLS LAST;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 ORDER BY ISNULL(name), name;\n```\n\n----------------------------------------\n\nTITLE: Observing AUTO_INCREMENT Query Results with Jumps in Sequence\nDESCRIPTION: This snippet shows the results of AUTO_INCREMENT operations where values jump from 3 to 2000001 due to the cache allocation across different TiDB servers.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 1 row affected (0.03 sec)\n\n+---------+---------------------+\n| a       | b                   |\n+---------+---------------------+\n|       1 | 2020-09-09 20:38:22 |\n|       2 | 2020-09-09 20:38:22 |\n|       3 | 2020-09-09 20:38:22 |\n| 2000001 | 2020-09-09 20:43:43 |\n+---------+---------------------+\n4 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Replacing Binary Files with Hotfix Package\nDESCRIPTION: Sequence of commands to extract the hotfix package, replace the original binary files with the hotfix versions, and repackage the modified files to prepare for deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-patch.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n# Decompress the hotfix package and use it to replace the binary file.\ncd /root; tar -zxvf dm-linux-amd64.tar.gz\ncp /root/dm-linux-amd64/bin/dm-master /tmp/package/dm-master/dm-master\ncp /root/dm-linux-amd64/bin/dm-worker /tmp/package/dm-worker/dm-worker\n# Re-package the modified files.\n# Note that the packaging method might be different for other deployment methods.\ncd /tmp/package/ && tar -czvf dm-master-hotfix-linux-amd64.tar.gz dm-master/\ncd /tmp/package/ && tar -czvf dm-worker-hotfix-linux-amd64.tar.gz dm-worker/\n```\n\n----------------------------------------\n\nTITLE: AUTO_RANDOM Column Usage Example in TiDB\nDESCRIPTION: Example showing how to create a table with AUTO_RANDOM column and pre-split regions, insert data with explicit and implicit values, and view the table structure and region distribution.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-random.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\ntidb> CREATE TABLE t (a BIGINT PRIMARY KEY AUTO_RANDOM, b VARCHAR(255)) /*T! PRE_SPLIT_REGIONS=2 */ ;\nQuery OK, 0 rows affected, 1 warning (0.01 sec)\n\ntidb> INSERT INTO t(a, b) VALUES (1, 'string');\nQuery OK, 1 row affected (0.00 sec)\n\ntidb> SELECT * FROM t;\n+---+--------+\n| a | b      |\n+---+--------+\n| 1 | string |\n+---+--------+\n1 row in set (0.01 sec)\n\ntidb> INSERT INTO t(b) VALUES ('string2');\nQuery OK, 1 row affected (0.00 sec)\n\ntidb> INSERT INTO t(b) VALUES ('string3');\nQuery OK, 1 row affected (0.00 sec)\n\ntidb> SELECT * FROM t;\n+---------------------+---------+\n| a                   | b       |\n+---------------------+---------+\n|                   1 | string  |\n| 1152921504606846978 | string2 |\n| 4899916394579099651 | string3 |\n+---------------------+---------+\n3 rows in set (0.00 sec)\n\ntidb> SHOW CREATE TABLE t;\n+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Table | Create Table                                                                                                                                                                                                                                                    |\n+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| t     | CREATE TABLE `t` (\n  `a` bigint NOT NULL /*T![auto_rand] AUTO_RANDOM(5) */,\n  `b` varchar(255) DEFAULT NULL,\n  PRIMARY KEY (`a`) /*T![clustered_index] CLUSTERED */\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin /*T! PRE_SPLIT_REGIONS=2 */ |\n+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n\ntidb> SHOW TABLE t REGIONS;\n+-----------+-----------------------------+-----------------------------+-----------+-----------------+---------------------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n| REGION_ID | START_KEY                   | END_KEY                     | LEADER_ID | LEADER_STORE_ID | PEERS               | SCATTERING | WRITTEN_BYTES | READ_BYTES | APPROXIMATE_SIZE(MB) | APPROXIMATE_KEYS | SCHEDULING_CONSTRAINTS | SCHEDULING_STATE |\n+-----------+-----------------------------+-----------------------------+-----------+-----------------+---------------------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n|     62798 | t_158_                      | t_158_r_2305843009213693952 |     62810 |              28 | 62811, 62812, 62810 |          0 |           151 |          0 |                    1 |                0 |                        |                  |\n|     62802 | t_158_r_2305843009213693952 | t_158_r_4611686018427387904 |     62803 |               1 | 62803, 62804, 62805 |          0 |            39 |          0 |                    1 |                0 |                        |                  |\n|     62806 | t_158_r_4611686018427387904 | t_158_r_6917529027641081856 |     62813 |               4 | 62813, 62814, 62815 |          0 |           160 |          0 |                    1 |                0 |                        |                  |\n|      9289 | t_158_r_6917529027641081856 | 78000000                    |     48268 |               1 | 48268, 58951, 62791 |          0 |         10628 |      43639 |                    2 |             7999 |                        |                  |\n+-----------+-----------------------------+-----------------------------+-----------+-----------------+---------------------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n4 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Self-Managed Connection String\nDESCRIPTION: Environment variable configuration for connecting to a self-managed TiDB installation.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_6\n\nLANGUAGE: dotenv\nCODE:\n```\nDATABASE_URL='mysql2://{user}:{password}@{host}:{port}/{database}'\n```\n\n----------------------------------------\n\nTITLE: Demonstrating AUTO_INCREMENT Gaps with ON DUPLICATE KEY UPDATE\nDESCRIPTION: Example showing how gaps can appear in AUTO_INCREMENT sequences when using ON DUPLICATE KEY UPDATE, which differs from the consecutive property.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (id INT NOT NULL PRIMARY KEY auto_increment, a VARCHAR(10), cnt INT NOT NULL DEFAULT 1, UNIQUE KEY (a));\nINSERT INTO t (a) VALUES ('A'), ('B');\nSELECT * FROM t;\nINSERT INTO t (a) VALUES ('A'), ('C') ON DUPLICATE KEY UPDATE cnt = cnt + 1;\nSELECT * FROM t;\n```\n\n----------------------------------------\n\nTITLE: Configuring mTLS Authentication in TiCDC Server\nDESCRIPTION: Enable mTLS authentication by setting the security.mtls parameter to true in the TiCDC server configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-client-authentication.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[security]\n# This parameter controls whether to enable the TLS client authentication. The default value is false.\nmtls = true\n```\n\n----------------------------------------\n\nTITLE: Replaying Traffic from Local Directory in SQL\nDESCRIPTION: SQL example demonstrating how to replay traffic from a local directory using the TRAFFIC REPLAY syntax with a specific user and password.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-traffic-replay.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nTRAFFIC REPLAY FROM \"/tmp/traffic\" USER=\"u1\" PASSWORD=\"123456\";\n```\n\n----------------------------------------\n\nTITLE: Applying Updated Configuration to TiDB Cluster\nDESCRIPTION: Command to reload a TiDB production cluster with updated configuration after editing the config file. This redistributes configurations and restarts components as needed.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster reload prod-cluster\n```\n\n----------------------------------------\n\nTITLE: Concatenate Column Values in TiDB\nDESCRIPTION: This snippet shows how to concatenate values of a column using LISTAGG in Oracle and GROUP_CONCAT in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_23\n\nLANGUAGE: sql\nCODE:\n```\nLISTAGG(CONCAT(E.dimensionid,'---',E.DIMENSIONNAME),'***') within GROUP(ORDER BY DIMENSIONNAME)\n```\n\nLANGUAGE: sql\nCODE:\n```\nGROUP_CONCAT(CONCAT(E.dimensionid,'---',E.DIMENSIONNAME) ORDER BY DIMENSIONNAME SEPARATOR '***')\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud Serverless\nDESCRIPTION: Command to establish a secure connection to TiDB Cloud Serverless cluster using MySQL client with SSL verification.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-build-cluster-in-cloud.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nmysql --connect-timeout 15 -u '<prefix>.root' -h <host> -P 4000 -D test --ssl-mode=VERIFY_IDENTITY --ssl-ca=/etc/ssl/cert.pem -p\n```\n\n----------------------------------------\n\nTITLE: Setting a Table as Cached in SQL\nDESCRIPTION: SQL statement to alter the 'users' table and set it as a cached table.\nSOURCE: https://github.com/pingcap/docs/blob/master/cached-tables.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE users CACHE;\n```\n\n----------------------------------------\n\nTITLE: Running DM-worker with Configuration File\nDESCRIPTION: Command to start DM-worker using the specified configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-binary.md#2025-04-18_snippet_5\n\nLANGUAGE: Bash\nCODE:\n```\n./dm-worker -config conf/dm-worker1.toml\n```\n\n----------------------------------------\n\nTITLE: Starting TiDB Lightning via Shell Script\nDESCRIPTION: Shell script to start TiDB Lightning process in background using nohup to prevent SIGHUP signal termination.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-distributed-import.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n# !/bin/bash\nnohup tiup tidb-lightning -config tidb-lightning.toml > nohup.out &\n```\n\n----------------------------------------\n\nTITLE: Converting Subqueries with USE_TOJA Hint\nDESCRIPTION: Example demonstrating how to enable conversion of IN subqueries to join and aggregation operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_44\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ USE_TOJA(TRUE) */ t1.a, t1.b from t1 where t1.a in (select t2.a from t2) subq;\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB through ProxySQL using Python Script\nDESCRIPTION: Command to run a Python script that connects to the TiDB cluster through ProxySQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npython3 proxysql-connect.py\n```\n\n----------------------------------------\n\nTITLE: Downloading and Installing go-tpc\nDESCRIPTION: This shell command downloads and installs the `go-tpc` tool, which is used for conducting TPC-C benchmark tests. This command uses `curl` to fetch the installation script from GitHub and then executes it using `sh`. `go-tpc` facilitates generating and loading TPC-C data into TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v6.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n\"curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/pingcap/go-tpc/master/install.sh | sh\"\n```\n\n----------------------------------------\n\nTITLE: Running Sysbench Traffic Capture Test (Bash)\nDESCRIPTION: This snippet runs a Sysbench test to evaluate the performance impact that traffic capture features may have on TiProxy. It compares QPS, average latency, and CPU usage between enabled and disabled capture options under various concurrent loads. Requires Sysbench and MySQL database access.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-performance-test.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nsysbench oltp_read_write \\\n    --threads=$threads \\\n    --time=1200 \\\n    --report-interval=5 \\\n    --rand-type=uniform \\\n    --db-driver=mysql \\\n    --mysql-db=sbtest \\\n    --mysql-host=$host \\\n    --mysql-port=$port \\\n    run --tables=32 --table-size=1000000\n```\n\n----------------------------------------\n\nTITLE: Upgrading TiUP and TiUP Cluster Components\nDESCRIPTION: Commands to upgrade TiUP and the TiUP Cluster component to the latest versions. This is a prerequisite step before upgrading the TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\ntiup update --self\ntiup --version\ntiup update cluster\ntiup cluster --version\n```\n\n----------------------------------------\n\nTITLE: Using BEGIN Statement in TiDB SQL\nDESCRIPTION: SQL example demonstrating how to start a transaction with BEGIN, perform an INSERT operation, and commit the changes to a table. This shows the basic transaction workflow in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-begin.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (a int NOT NULL PRIMARY KEY);\nQuery OK, 0 rows affected (0.12 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> INSERT INTO t1 VALUES (1);\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> COMMIT;\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Generating CA Key with OpenSSL for TiDB Certificate Authentication\nDESCRIPTION: Command to generate a 2048-bit RSA private key for the Certificate Authority (CA) that will be used to sign server and client certificates in TiDB's certificate-based authentication system.\nSOURCE: https://github.com/pingcap/docs/blob/master/certificate-authentication.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo openssl genrsa 2048 > ca-key.pem\n```\n\n----------------------------------------\n\nTITLE: Configuring DR Auto-Sync Mode with pd-ctl Commands (Shell)\nDESCRIPTION: Shell commands using pd-ctl to modify PD configurations for enabling DR Auto-Sync mode in an already deployed cluster. Sets the replication mode, label key, primary and DR zones, and replica counts.\nSOURCE: https://github.com/pingcap/docs/blob/master/two-data-centers-in-one-city-deployment.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nconfig set replication-mode dr-auto-sync\nconfig set replication-mode dr-auto-sync label-key az\nconfig set replication-mode dr-auto-sync primary east\nconfig set replication-mode dr-auto-sync dr west\nconfig set replication-mode dr-auto-sync primary-replicas 3\nconfig set replication-mode dr-auto-sync dr-replicas 2\n```\n\n----------------------------------------\n\nTITLE: Disabling Relay-Log for Data Source with cURL in Shell\nDESCRIPTION: This example shows how to disable the relay-log feature for a data source by making a POST request to the DM API. The request specifies the list of workers from which relay log should be disabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'POST' \\\n  'http://127.0.0.1:8261/api/v1/sources/mysql-01/relay/disable' \\\n  -H 'accept: */*' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"worker_name_list\": [\n    \"worker-1\"\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Filtering data using indexed columns\nDESCRIPTION: This snippet demonstrates how to improve the efficiency of deleting data by using a strong filter index column or primary key. This is useful for selecting a specific range of data to be deleted. This can speed up the deletion process by targeting the specific data that needs to be removed.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/migration-tidb-faq.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n\"id >= 5000*n+m and id < 5000*(n+1)+m\"\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Configuration File\nDESCRIPTION: Command to copy the example environment file to create a new .env configuration file for database connection settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Configuring Column Selectors in TiCDC Kafka Sink\nDESCRIPTION: Example configuration for column selectors that filter which columns are included in the change events sent to Kafka. Supports exact matches, wildcards, and exclusion patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-kafka.md#2025-04-18_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\n[sink]\ncolumn-selectors = [\n    {matcher = ['test.t1'], columns = ['a', 'b']},\n    {matcher = ['test.*'], columns = [\"*\", \"!b\"]},\n    {matcher = ['test1.t1'], columns = ['column*', '!column1']},\n    {matcher = ['test3.t'], columns = [\"column?\", \"!column1\"]},\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Parameters in TiDB Cloud\nDESCRIPTION: This YAML snippet configures the TiKV parameter 'prefill-for-recycle' to determine the behavior of log recycling in a TiKV cluster when running different OLTP workloads. The value is set to 'false' for 'oltp_point_select' workloads and 'true' for other specified workloads.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.1-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nraft-engine.prefill-for-recycle = false\n```\n\n----------------------------------------\n\nTITLE: Creating Global Binding for Execution Plans - SQL\nDESCRIPTION: This SQL statement simplifies the creation of execution plan bindings in TiDB v7.6.0 by eliminating the need to specify the original SQL statement. Instead, it allows the identification of the original statement from hints, making it easier to manage execution strategies.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.6.0.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE GLOBAL BINDING\nUSING\nSELECT /*+ merge_join(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Creating Tables with Unqualified and Qualified Names\nDESCRIPTION: Illustrate creating tables with and without database qualifiers, showing how to specify database names explicitly\nSOURCE: https://github.com/pingcap/docs/blob/master/schema-object-names.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (i int);\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test.t (i int);\n```\n\n----------------------------------------\n\nTITLE: Viewing Original SQL of DDL Jobs in TiDB\nDESCRIPTION: The ADMIN SHOW DDL JOB QUERIES command is used to view the original SQL statement of the DDL task corresponding to the specified job_id.\nSOURCE: https://github.com/pingcap/docs/blob/master/ddl-introduction.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW DDL JOB QUERIES job_id [, job_id]\n```\n\n----------------------------------------\n\nTITLE: TiFlash Compact Table Command\nDESCRIPTION: SQL command syntax for compacting data in TiFlash using ALTER TABLE statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE ... COMPACT\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for SHOW CREATE PLACEMENT POLICY\nDESCRIPTION: Provides the formal grammar definition for the SHOW CREATE PLACEMENT POLICY statement using Extended Backus-Naur Form (EBNF)\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-placement-policy.md#2025-04-18_snippet_1\n\nLANGUAGE: ebnf\nCODE:\n```\nShowCreatePlacementPolicyStmt ::=\n    \"SHOW\" \"CREATE\" \"PLACEMENT\" \"POLICY\" PolicyName\n\nPolicyName ::=\n    Identifier\n```\n\n----------------------------------------\n\nTITLE: Issuing DM-master Certificate\nDESCRIPTION: Command to issue and generate the final certificate for DM-master, signed by the CA and including extensions from the configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nopenssl x509 -req -days 365 -CA ca.pem -CAkey ca-key.pem -CAcreateserial -in master-cert.pem -out master-cert.pem -extensions v3_req -extfile openssl.cnf\n```\n\n----------------------------------------\n\nTITLE: TiFlash DeltaTree Logical Split Configuration Parameter (Modified)\nDESCRIPTION: TiFlash parameter that determines whether the segment of DeltaTree Storage Engine uses logical split. The default value has been changed from true to false.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\nprofiles.default.dt_enable_logical_split\n```\n\n----------------------------------------\n\nTITLE: API Error Message Template in JSON\nDESCRIPTION: Standard error response format returned by the API when an error occurs, containing error message and code.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"error_msg\": \"\",\n    \"error_code\": \"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using Reserved Keywords as Identifiers in TiDB SQL\nDESCRIPTION: This snippet demonstrates the need to enclose reserved keywords in backticks when using them as identifiers in SQL statements. Without backticks, an error is thrown.\nSOURCE: https://github.com/pingcap/docs/blob/master/keywords.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE select (a INT);\n```\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `select` (a INT);\n```\n\n----------------------------------------\n\nTITLE: Configuring statement summary max count in TiDB 5.2\nDESCRIPTION: Sets the maximum number of statements that the statement summary tables store in memory. The default value is changed from 200 to 3000.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.2.0.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_stmt_summary_max_stmt_count = 3000;\n```\n\n----------------------------------------\n\nTITLE: Importing S3 Data with AWS IAM Role ARN - Bash\nDESCRIPTION: This snippet shows how to use a specific AWS IAM role ARN for S3 data access in TiDB Lightning. It's essential for applications that require controlled access through IAM roles.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-data-source.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ntiup tidb-lightning --tidb-port=4000 --pd-urls=127.0.0.1:2379 --backend=local --sorted-kv-dir=/tmp/sorted-kvs \\\n    -d 's3://my-bucket/test-data?role-arn=arn:aws:iam::888888888888:role/my-role'\n```\n\n----------------------------------------\n\nTITLE: Data Migration to New Table in pt-osc\nDESCRIPTION: SQL statement used by pt-osc to copy data from the original table to the '_new' table. DM doesn't execute this as it only processes DML operations for the real table.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nINSERT LOW_PRIORITY IGNORE INTO `test`.`_test4_new` (`id`, `date`, `account_id`, `conversion_price`, `ocpc_matched_conversions`, `ad_cost`, `cl2`, `cl1`) SELECT `id`, `date`, `account_id`, `conversion_price`, `ocpc_matched_conversions`, `ad_cost`, `cl2`, `cl1` FROM `test`.`test4` LOCK IN SHARE MODE /*pt-online-schema-change 3227 copy table*/\n```\n\n----------------------------------------\n\nTITLE: Performing Left Shift Operation in SQL\nDESCRIPTION: The '<<' operator shifts the binary representation of a number to the left by a specified number of positions, filling in with zeros. The expected input is a number for left shifting, and the output will be the shifted binary representation.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/bit-functions-and-operators.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nWITH RECURSIVE cte(n) AS (\n    SELECT 0 AS n\n    UNION ALL\n    SELECT 1+n FROM cte WHERE n<10\n)\nSELECT n,1<<n,LPAD(CONV(1<<n,10,2),11,0) FROM cte;\n```\n\n----------------------------------------\n\nTITLE: Executing ROLLUP Query in TiDB with TiFlash MPP Mode\nDESCRIPTION: This SQL snippet shows the execution plan for the same ROLLUP query in TiFlash MPP mode. The Expand operator is executed in TiFlash, allowing for better data distribution and parallel processing across multiple nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/group-by-modifier.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT year, month, grouping(year), grouping(month), SUM(profit) AS profit FROM bank GROUP BY year, month WITH ROLLUP;\n```\n\n----------------------------------------\n\nTITLE: Displaying Table Structure in SQL\nDESCRIPTION: This SQL output shows the structure of the 'child' table after creation. It demonstrates that the 'REFERENCES' clause used in the CREATE TABLE statement was ignored, as no foreign key constraint is present in the table definition.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_13\n\nLANGUAGE: SQL\nCODE:\n```\n+-------+-------------------------------------------------------------+\n| Table | Create Table                                                |\n+-------+-------------------------------------------------------------+\n| child | CREATE TABLE `child` (                                      |\n|       |   `id` int DEFAULT NULL,                                |\n|       |   `pid` int DEFAULT NULL                                |\n|       | ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin |\n+-------+-------------------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Generating Test Data with TPC-C Workload\nDESCRIPTION: Commands to use go-tpc benchmark tool to prepare and run a TPC-C workload against the TiDB cluster, generating data changes that will be captured by TiCDC and replicated to Confluent Cloud.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup bench tpcc -H 127.0.0.1 -P 4000 -D tpcc --warehouses 4 prepare\ntiup bench tpcc -H 127.0.0.1 -P 4000 -D tpcc --warehouses 4 run --time 300s\n```\n\n----------------------------------------\n\nTITLE: Window Function with Non-Primary Key PARTITION BY in SQL (TiDB)\nDESCRIPTION: This example shows a window function where the PARTITION BY column is not a prefix of the primary key. In this case, the SQL is not rewritten for TopN optimization.\nSOURCE: https://github.com/pingcap/docs/blob/master/derive-topn-from-window.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id1 int, id2 int, value1 int, value2 int, primary key(id1,id2) clustered);\nSET tidb_opt_derive_topn=on;\nEXPLAIN SELECT * FROM (SELECT ROW_NUMBER() OVER (PARTITION BY value1) AS rownumber FROM t) dt WHERE rownumber <= 3;\n```\n\n----------------------------------------\n\nTITLE: Using MERGE_JOIN Optimizer Hint - SQL\nDESCRIPTION: This snippet provides an example of applying the MERGE_JOIN optimizer hint to facilitate the use of the sort-merge join algorithm. This approach is appropriate in scenarios with large data volumes, as it may consume less memory at the cost of longer processing times.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ MERGE_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Execute Batch Update of Table Statistics in TiDB\nDESCRIPTION: This SQL code snippet first sets the session `tidb_partition_prune_mode` to `dynamic`. Then, it executes the SQL statements stored in the `gatherGlobalStats.sql` file using the `source` command. This effectively updates the statistics for all partitioned tables listed in the file.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_84\n\nLANGUAGE: sql\nCODE:\n```\nSET session tidb_partition_prune_mode = dynamic;\nsource gatherGlobalStats.sql\n```\n\n----------------------------------------\n\nTITLE: Second Possible Result with NON-FULL GROUP BY\nDESCRIPTION: An alternative result set from the same NON-FULL GROUP BY query, showing a different selection of student names. This further illustrates the unstable nature of results when proper grouping is not specified.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-unstable-result-set.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n+------------+--------------+------------------+\n| class      | stuname      | max(b.courscore) |\n+------------+--------------+------------------+\n| 2018_CS_01 | MonkeyDLuffy |             95.5 |\n| 2018_CS_03 | SpongeBob    |             99.0 |\n+------------+--------------+------------------+\n```\n\n----------------------------------------\n\nTITLE: Configuring DM-master Using TOML File\nDESCRIPTION: Example TOML configuration file for DM-master, including settings for logging, network addresses, and cluster initialization.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-binary.md#2025-04-18_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n# Master Configuration.\nname = \"master1\"\n\n# Log configurations.\nlog-level = \"info\"\nlog-file = \"dm-master.log\"\n\n# The listening address of DM-master.\nmaster-addr = \"192.168.0.4:8261\"\n\n# The peer URLs of DM-master.\npeer-urls = \"192.168.0.4:8291\"\n\n# The value of `initial-cluster` is the combination of the `advertise-peer-urls` value of all DM-master nodes in the initial cluster.\ninitial-cluster = \"master1=http://192.168.0.4:8291,master2=http://192.168.0.5:8291,master3=http://192.168.0.6:8291\"\n```\n\n----------------------------------------\n\nTITLE: Modifying Resource Group for Background Tasks in SQL\nDESCRIPTION: These SQL snippets show how to modify the `default` resource group to identify certain tasks as background tasks and set limits on resource utilization for these tasks. Requires a TiDB environment with resource groups configured. Task types and their limits are specified as parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-background-tasks.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nALTER RESOURCE GROUP `default` BACKGROUND=(TASK_TYPES='br,ddl', UTILIZATION_LIMIT=30);\n```\n\n----------------------------------------\n\nTITLE: Filtering Partition Operations in YAML Configuration\nDESCRIPTION: Global filtering rule to handle SQL statements that TiDB parser cannot process, specifically targeting partition-related ALTER TABLE statements. Uses schema-pattern: \"*\" to apply globally.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-binlog-event-filter.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nfilters:\n  filter-partition-rule:\n    schema-pattern: \"*\"\n    sql-pattern: [\"ALTER\\\\s+TABLE[\\\\s\\\\S]*ADD\\\\s+PARTITION\", \"ALTER\\\\s+TABLE[\\\\s\\\\S]*DROP\\\\s+PARTITION\"]\n    action: Ignore\n```\n\n----------------------------------------\n\nTITLE: Using PD Control Tool to Check Transaction Timestamp Interval\nDESCRIPTION: These shell commands help check the time interval between transaction start_ts and commit_ts using the PD control tool. This can help determine if the commit time exceeds the TTL time, which could cause a LockNotFound error.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-lock-conflicts.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd tso [start_ts]\ntiup ctl:v<CLUSTER_VERSION> pd tso [commit_ts]\n```\n\n----------------------------------------\n\nTITLE: Examining Region Read Progress with tikv-ctl in Bash\nDESCRIPTION: This command uses tikv-ctl to retrieve detailed information about the read progress of a specific region (3121) in TiKV. It helps diagnose issues related to stale reads by showing the region's safe timestamp, applied index, and resolver status.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-stale-read.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./tikv-ctl --host 127.0.0.1:20160 get-region-read-progress -r 3121 --log\n```\n\n----------------------------------------\n\nTITLE: Sample Output of bad-ssts Command\nDESCRIPTION: Example output from the bad-ssts command showing corruption information, SST metadata, affected regions, and recommended cleanup operations. The output helps administrators understand the extent of damage and how to repair it.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_29\n\nLANGUAGE: shell\nCODE:\n```\n--------------------------------------------------------\ncorruption info:\ndata/tikv-21107/db/000014.sst: Corruption: Bad table magic number: expected 9863518390377041911, found 759105309091689679 in data/tikv-21107/db/000014.sst\n\nsst meta:\n14:552997[1 .. 5520]['0101' seq:1, type:1 .. '7A7480000000000000FF0F5F728000000000FF0002160000000000FAFA13AB33020BFFFA' seq:2032, type:1] at level 0 for Column family \"default\"  (ID 0)\nit isn't easy to handle local data, start key:0101\n\noverlap region:\nRegionInfo { region: id: 4 end_key: 7480000000000000FF0500000000000000F8 region_epoch { conf_ver: 1 version: 2 } peers { id: 5 store_id: 1 }, leader: Some(id: 5 store_id: 1) }\n\nrefer operations:\ntikv-ctl ldb --db=/path/to/tikv/db unsafe_remove_sst_file 000014\ntikv-ctl --data-dir=/path/to/tikv tombstone -r 4 --pd <endpoint>\n--------------------------------------------------------\ncorruption analysis has completed\n```\n\n----------------------------------------\n\nTITLE: Setting Optimizer Fix Controls in TiDB\nDESCRIPTION: This SQL statement demonstrates how to set the `tidb_opt_fix_control` system variable to enable or disable specific optimizer fixes. Multiple fixes can be set at once, separated by commas, using the format `<#issue>:<value>`.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-fix-controls.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET SESSION tidb_opt_fix_control = '44262:ON,44389:ON';\n```\n\n----------------------------------------\n\nTITLE: Disabling TiDB Transaction Auto-Retry\nDESCRIPTION: SQL command to disable automatic transaction retry in TiDB, which prevents Sysbench from quitting due to transaction conflict errors during data import.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nset global tidb_disable_txn_auto_retry = off;\n```\n\n----------------------------------------\n\nTITLE: Custom PD Configuration Deployment\nDESCRIPTION: Command to override default PD configuration using a custom configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground --pd.config ~/config/pd.toml\n```\n\n----------------------------------------\n\nTITLE: Get Position Based on Offset in TiDB\nDESCRIPTION: Demonstrates the different approaches to find occurrences of a substring based on an offset in both systems.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_22\n\nLANGUAGE: sql\nCODE:\n```\nINSTR('abcabc','b',2,1)\n```\n\nLANGUAGE: sql\nCODE:\n```\nLOCATE('b','abcabc',2)\n```\n\n----------------------------------------\n\nTITLE: Configuring Raft Entry Cache Parameters\nDESCRIPTION: This snippet sets parameters for managing Raft entry cache lifetime, including limits on leftover logs and management of log memory usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\n+ The maximum remaining time allowed for the log cache in memory\n+ Default value: `\"30s\"`\n+ Minimum value: `0`\n```\n\n----------------------------------------\n\nTITLE: Starting MySQL Containers with Docker\nDESCRIPTION: Commands to start two MySQL instances using Docker, configured with binary logging and GTID mode enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-create-task.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm --name mysql-3306 -p 3306:3306 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql:5.7.22 --log-bin=mysql-bin --port=3306 --bind-address=0.0.0.0 --binlog-format=ROW --server-id=1 --gtid_mode=ON --enforce-gtid-consistency=true > mysql.3306.log 2>&1 &\ndocker run --rm --name mysql-3307 -p 3307:3307 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql:5.7.22 --log-bin=mysql-bin --port=3307 --bind-address=0.0.0.0 --binlog-format=ROW --server-id=1 --gtid_mode=ON --enforce-gtid-consistency=true > mysql.3307.log 2>&1 &\n```\n\n----------------------------------------\n\nTITLE: DDL_JOBS Table Schema Output\nDESCRIPTION: Displays the complete table structure showing all columns including JOB_ID, DB_NAME, TABLE_NAME, and other metadata fields with their respective data types and properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-ddl-jobs.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+--------------+-------------+------+------+---------+-------+\n| Field        | Type        | Null | Key  | Default | Extra |\n+--------------+-------------+------+------+---------+-------+\n| JOB_ID       | bigint(21)  | YES  |      | NULL    |       |\n| DB_NAME      | varchar(64) | YES  |      | NULL    |       |\n| TABLE_NAME   | varchar(64) | YES  |      | NULL    |       |\n| JOB_TYPE     | varchar(64) | YES  |      | NULL    |       |\n| SCHEMA_STATE | varchar(64) | YES  |      | NULL    |       |\n| SCHEMA_ID    | bigint(21)  | YES  |      | NULL    |       |\n| TABLE_ID     | bigint(21)  | YES  |      | NULL    |       |\n| ROW_COUNT    | bigint(21)  | YES  |      | NULL    |       |\n| START_TIME   | datetime    | YES  |      | NULL    |       |\n| END_TIME     | datetime    | YES  |      | NULL    |       |\n| STATE        | varchar(64) | YES  |      | NULL    |       |\n| QUERY        | varchar(64) | YES  |      | NULL    |       |\n+--------------+-------------+------+------+---------+-------+\n```\n\n----------------------------------------\n\nTITLE: Splitting Joint Index by Specified Values in SQL\nDESCRIPTION: This SQL statement splits the index 'idx3' into 10 Regions based on a time range for column 'a' and value conditions for column 'b'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT TABLE t INDEX idx3 BETWEEN (\"2010-01-01 00:00:00\", \"a\") AND (\"2010-01-01 00:00:00\", \"z\") REGIONS 10;\n```\n\n----------------------------------------\n\nTITLE: Creating Placement Policy and Table with SQL\nDESCRIPTION: Demonstrates creating a placement policy named 'p1' with region and follower configurations, and associating it with a table\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-placement-policy.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY p1 PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\" FOLLOWERS=4;\nCREATE TABLE t1 (a INT) PLACEMENT POLICY=p1;\nSHOW CREATE PLACEMENT POLICY p1\\G\n```\n\n----------------------------------------\n\nTITLE: TiUP Cluster Scale-Out Command Syntax\nDESCRIPTION: Basic syntax for the tiup cluster scale-out command. Requires cluster name and topology file as arguments. The topology file should only contain configuration for new nodes being added to the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-scale-out.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster scale-out <cluster-name> <topology.yaml> [flags]\n```\n\n----------------------------------------\n\nTITLE: Beginning a Transaction with Isolation Option in TypeScript\nDESCRIPTION: This code snippet shows how to initiate a transaction with a specified isolation level using the TiDB Cloud serverless driver. The isolation option is crucial for managing transactional behavior and consistency in the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nconst conn = connect({url: 'mysql://[username]:[password]@[host]/[database]'});\nconst tx = await conn.begin({isolation:\"READ COMMITTED\"});\n```\n\n----------------------------------------\n\nTITLE: Viewing Foreign Key Definitions with SHOW CREATE TABLE in SQL\nDESCRIPTION: This SQL snippet demonstrates how to view the definition of a foreign key constraint for a table using the SHOW CREATE TABLE statement. It provides the entire table schema including the foreign key constraints. This requires no special dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/foreign-key.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nmysql> SHOW CREATE TABLE child\\G\n*************************** 1. row ***************************\n       Table: child\nCreate Table: CREATE TABLE `child` (\n  `id` int DEFAULT NULL,\n  `pid` int DEFAULT NULL,\n  KEY `idx_pid` (`pid`),\n  CONSTRAINT `fk_1` FOREIGN KEY (`pid`) REFERENCES `test`.`parent` (`id`) ON DELETE CASCADE\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\n\n```\n\n----------------------------------------\n\nTITLE: Technical Terms and Common Misspellings List\nDESCRIPTION: A reference list of misspelled terms and their correct forms, including database terminology, monitoring tools, and cloud platform references. The list uses regex pattern (?i) to indicate case-insensitive matching for many terms.\nSOURCE: https://github.com/pingcap/docs/blob/master/styles/config/vocabularies/PingCAP/reject.txt#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nTiBD\n(?i)libary\n(?i)clsuter\nLighting\n(?i)CRATE\nPromethous\nPromethus\nGrafna\nAlertManager\n(?i)infomation\n(?i)durid\n(?i)desrciption\n(?i)montoring\n(?i)theses\n(?i)tomestone\n(?i)relaod\nZookeeper\n(?i)recommanded\n(?i)uft8\n(?i)mirrir\n(?i)architecure\n(?i)charater\n(?i)contian\n(?i)automatially\n(?i)forcely\n(?i)fixe\nBinglog\n(?i)earlist\nDraienr\n(?i)ut8mb4\n(?i)PESSMISTIC\n(?i)substaintially\n(?i)capactiy\n(?i)enviroment\n(?i)seperate\n(?i)runing\n(?i)seach\n(?i)absense\n(?i)excecute\n(?i)compatiblity\n(?i)sucessfully\n(?i)avaliable\n(?i)timpestamp\n(?i)resoureces\n(?i)statisctics\n(?i)snapshort\n(?i)qiery\n(?i)adoptor\n(?i)asess\n(?i)shema\n(?i)synchronise\n(?i)pushgateway\nPush Gateway\n(?i)relavant\n(?i)statment\n(?i)spliting\n(?i)settting\nFeburary\n(?i)foramt\n(?i)reslove\n(?i)schedulor\n(?i)ROCSDB\nGCP\n(?i)Google Cloud Platform\n```\n\n----------------------------------------\n\nTITLE: Creating Range Partitioned Table and Demonstrating Pruning Limitation in TiDB\nDESCRIPTION: This SQL snippet creates a range partitioned table t1, a regular table t2, and executes an EXPLAIN statement to show how partition pruning fails to optimize a subquery involving both tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/partition-pruning.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t1 (x int) partition by range (x) (\n    partition p0 values less than (5),\n    partition p1 values less than (10));\ncreate table t2 (x int);\nexplain select * from t2 where x < (select * from t1 where t2.x < t1.x and t2.x < 2);\n```\n\n----------------------------------------\n\nTITLE: Displaying DDL Job Details in TiDB\nDESCRIPTION: The ADMIN SHOW DDL JOBS command is used to view the detailed status of DDL tasks running in the cluster environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/ddl-introduction.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW DDL JOBS\n```\n\n----------------------------------------\n\nTITLE: Example Output of Blocked Transaction Query in TiDB\nDESCRIPTION: Example output showing details of a transaction that is blocking another transaction, including transaction ID, SQL statements, state, and timing information. The output demonstrates how to interpret the results from the data_lock_waits join query.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-lock-conflicts.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n*************************** 1. row ***************************\n                    key: 74800000000000004D5F728000000000000001\n               INSTANCE: 127.0.0.1:10080\n                     ID: 426832040186609668\n             START_TIME: 2021-08-06 07:30:16.581000\n     CURRENT_SQL_DIGEST: 06da614b93e62713bd282d4685fc5b88d688337f36e88fe55871726ce0eb80d7\nCURRENT_SQL_DIGEST_TEXT: update `t` set `v` = `v` + ? where `id` = ? ;\n                  STATE: LockWaiting\n     WAITING_START_TIME: 2021-08-06 07:30:16.592763\n        MEM_BUFFER_KEYS: 1\n       MEM_BUFFER_BYTES: 19\n             SESSION_ID: 113\n                   USER: root\n                     DB: test\n        ALL_SQL_DIGESTS: [\"0fdc781f19da1c6078c9de7eadef8a307889c001e05f107847bee4cfc8f3cdf3\",\"a4e28cc182bdd18288e2a34180499b9404cd0ba07e3cc34b6b3be7b7c2de7fe9\",\"06da614b93e62713bd282d4685fc5b88d688337f36e88fe55871726ce0eb80d7\"]\n                   sqls: [\"begin ;\",\"select * from `t` where `id` = ? for update ;\",\"update `t` set `v` = `v` + ? where `id` = ? ;\"]\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying Hot Regions for a Specific Table and Time Period in SQL\nDESCRIPTION: This SQL query selects hot region data for a specific table within a given time range. It filters results based on both update_time and table_name fields.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-hot-regions-history.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM INFORMATION_SCHEMA.TIDB_HOT_REGIONS_HISTORY WHERE update_time >'2021-08-18 21:40:00' and update_time <'2021-09-19 00:00:00' and TABLE_NAME = 'table_name';\n```\n\n----------------------------------------\n\nTITLE: Output of error generation and summary query in TiDB\nDESCRIPTION: The result set showing the division-by-zero warning, the corresponding entry in the CLIENT_ERRORS_SUMMARY_BY_HOST table, and the empty result after flushing the error summary.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/client-errors-summary-by-host.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+-----+\n| 0/0 |\n+-----+\n| NULL |\n+-----+\n1 row in set, 1 warning (0.00 sec)\n\n+-----------+--------------+---------------+-------------+---------------+---------------------+---------------------+\n| HOST      | ERROR_NUMBER | ERROR_MESSAGE | ERROR_COUNT | WARNING_COUNT | FIRST_SEEN          | LAST_SEEN           |\n+-----------+--------------+---------------+-------------+---------------+---------------------+---------------------+\n| 127.0.0.1 |         1365 | Division by 0 |           0 |             1 | 2021-03-18 12:51:54 | 2021-03-18 12:51:54 |\n+-----------+--------------+---------------+-------------+---------------+---------------------+---------------------+\n1 row in set (0.00 sec)\n\nQuery OK, 0 rows affected (0.00 sec)\n\nEmpty set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Examining TiKV Server Logs for LockNotFound Error\nDESCRIPTION: This log snippet shows how a TxnLockNotFound error appears in TiKV logs. The error indicates that the transaction needs to be restarted due to a lock issue, and there's a remote connection problem.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-lock-conflicts.md#2025-04-18_snippet_6\n\nLANGUAGE: log\nCODE:\n```\nError: KV error safe to retry restarts txn: Txn(Mvcc(TxnLockNotFound)) [ERROR [Kv.rs:708] [\"KvService::batch_raft send response fail\"] [err=RemoteStoped]\n```\n\n----------------------------------------\n\nTITLE: TiKV RaftStore Max Message Size Configuration Parameter (Modified)\nDESCRIPTION: TiKV parameter that controls the maximum size of Raft messages. The value range and unit have been modified with minimum value now greater than 0, maximum value set to 3GB, and unit options expanded to KB|MB|GB.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\nraftstore.raft-max-size-per-msg\n```\n\n----------------------------------------\n\nTITLE: Querying Uptime Metrics in TiDB\nDESCRIPTION: This SQL snippet demonstrates how to query the uptime metrics from the METRICS_SCHEMA and retrieve the corresponding PromQL query from INFORMATION_SCHEMA.METRICS_TABLES.\nSOURCE: https://github.com/pingcap/docs/blob/master/metrics-schema.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE metrics_schema;\nSELECT * FROM uptime;\nSELECT * FROM information_schema.metrics_tables WHERE table_name='uptime'\\G\n```\n\n----------------------------------------\n\nTITLE: Dropping Multiple Global SQL Bindings in TiDB\nDESCRIPTION: Removes multiple global SQL bindings using their SQL digest values. The statement affects bindings for three different queries identified by their unique digest hashes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-binding.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nDROP GLOBAL BINDING FOR SQL DIGEST '31026623c8f22264fe0dfc26f29c69c5c457d6b85960c578ebcf17a967ed7893', '0f38b2e769927ae37981c66f0988c6299b602e03f029e38aa071e656fc321593', '3c8dfc451b0e36afd904cefca5137e68fb051f02964e1958ed60afdadc25f57e';\n```\n\n----------------------------------------\n\nTITLE: Configuring HAProxy with PROXY Protocol for TiDB in YAML\nDESCRIPTION: HAProxy configuration snippet showing how to implement the PROXY protocol for TiDB connections. This allows tracking the source IP address of client connections via SHOW PROCESSLIST.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/haproxy-best-practices.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n   server tidb-1 10.9.18.229:4000 send-proxy check inter 2000 rise 2 fall 3       \n   server tidb-2 10.9.39.208:4000 send-proxy check inter 2000 rise 2 fall 3\n   server tidb-3 10.9.64.166:4000 send-proxy check inter 2000 rise 2 fall 3\n```\n\n----------------------------------------\n\nTITLE: Migrate Only DML Operations of Sharded Schemas and Tables - YAML\nDESCRIPTION: This snippet demonstrates how to set up filters to replicate only DML operations from specified schemas and tables while ignoring other events, using 'Do' action settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/filter-binlog-event.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nfilters:\n  do-table-rule:\n    schema-pattern: \"test_*\"\n    table-pattern: \"t_*\"\n    events: [\"create table\", \"all dml\"]\n    action: Do\n  do-schema-rule:\n    schema-pattern: \"test_*\"\n    events: [\"create database\"]\n    action: Do\n```\n\n----------------------------------------\n\nTITLE: Configuring Grafana Dashboards in TiUP\nDESCRIPTION: This YAML configuration shows how to set 'dashboard_dir' in the topology.yaml file for Grafana servers within a TiUP-managed TiDB cluster. It specifies the directory for customized Grafana Dashboard configurations, facilitating the deployment of tailored dashboards.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/customized-montior-in-tiup-environment.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ngrafana_servers:\n  - host: 127.0.0.1\n    dashboard_dir: /home/tidb/dashboards\n```\n\n----------------------------------------\n\nTITLE: Configuring Automatic Retry for TiDB Optimistic Transactions - Toml\nDESCRIPTION: This snippet configures the automatic retry settings for optimistic transactions in TiDB. Setting 'tidb_disable_txn_auto_retry' to 'OFF' enables automatic retries, and 'tidb_retry_limit' sets the maximum number of retries allowed.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimistic-transaction.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n# Whether to disable automatic retry. (\"on\" by default)\ntidb_disable_txn_auto_retry = OFF\n# Set the maximum number of the retires. (\"10\" by default)\n# When \"tidb_retry_limit = 0\", automatic retry is completely disabled.\ntidb_retry_limit = 10\n```\n\n----------------------------------------\n\nTITLE: Enabling DNS Settings for AWS VPC\nDESCRIPTION: AWS CLI commands to modify the VPC attributes, enabling DNS hostname resolution and DNS support, which are required for proper domain name resolution across the VPC peering connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-vpc-peering-connections.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# Modifies the VPC attribute to enable DNS-hostname and DNS-support.\naws ec2 modify-vpc-attribute --vpc-id \"$app_vpc_id\" --enable-dns-hostnames\naws ec2 modify-vpc-attribute --vpc-id \"$app_vpc_id\" --enable-dns-support\n```\n\n----------------------------------------\n\nTITLE: Creating New SQL User for Index Insight Troubleshooting\nDESCRIPTION: SQL statements to create a new user with required privileges when troubleshooting authentication or privilege issues with Index Insight. This includes necessary grants for the feature to function properly.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/index-insight.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE user 'index_insight_user'@'%' IDENTIFIED by 'random_password';\nGRANT SELECT ON information_schema.* TO 'index_insight_user'@'%';\nGRANT SELECT ON mysql.* TO 'index_insight_user'@'%';\nGRANT PROCESS, REFERENCES ON *.* TO 'index_insight_user'@'%';\nFLUSH PRIVILEGES;\n```\n\n----------------------------------------\n\nTITLE: Executing Commands on DM Cluster Nodes\nDESCRIPTION: Command to run shell commands on specified nodes in a DM cluster using TiUP. It allows executing commands on all or specific nodes based on roles.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm exec prod-cluster --command='ls /tmp'\n```\n\n----------------------------------------\n\nTITLE: Checking TiDB Cloud Backup Status\nDESCRIPTION: Terminal output showing how to use the terraform state show command to check the initial status of the created backup.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-backup-resource.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform state show tidbcloud_backup.example_backup\n\n# tidbcloud_backup.example_backup:\nresource \"tidbcloud_backup\" \"example_backup\" {\n    cluster_id       = \"1379661944630234067\"\n    create_timestamp = \"2022-08-26T07:56:10Z\"\n    description      = \"create by terraform\"\n    id               = \"1350048\"\n    name             = \"firstBackup\"\n    project_id       = \"1372813089189561287\"\n    size             = \"0\"\n    status           = \"PENDING\"\n    type             = \"MANUAL\"\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading go-tpc Test Program using Shell\nDESCRIPTION: This shell command downloads the `go-tpc` test program from GitHub. This program is used to implement the TPC-C test. The command uses `curl` to download the installation script and executes it using `sh`.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n\"curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/pingcap/go-tpc/master/install.sh | sh\"\n```\n\n----------------------------------------\n\nTITLE: Create Changefeed with CLI\nDESCRIPTION: This command attempts to create a TiCDC changefeed using the CLI. It connects to the TiCDC server and specifies a sink URI. The command fails with an error if the upstream and downstream TiDB clusters have the same cluster ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed create --server=http://127.0.0.1:8300 --sink-uri=\"mysql://root:@127.0.0.1:8300/\" --changefeed-id=\"create-cmd\"\n```\n\n----------------------------------------\n\nTITLE: Update Validation Cutover Point Command in DM\nDESCRIPTION: Command syntax for updating the cutover point in continuous data validation. Supports both GTID and binary log position specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-continuous-data-validation.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nUsage:\n  dmctl validation update <task-name> [flags]\n\nFlags:\n      --cutover-binlog-gtid string   specify the cutover binlog gtid for validation, only valid when source config's gtid is enabled, e.g. '1642618e-cf65-11ec-9e3d-0242ac110002:1-30'\n      --cutover-binlog-pos string    specify the cutover binlog name for validation, should include binlog name and pos in brackets, e.g. '(mysql-bin.000001, 5989)'\n  -h, --help                         help for update\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Migration Task in YAML\nDESCRIPTION: Task configuration file specifying migration settings including source/target databases, table filters, and processing options\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/migrate-data-using-dm.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nname: \"test\"\ntask-mode: \"all\"\ntarget-database:\n  host: \"172.16.10.83\"\n  port: 4000\n  user: \"root\"\n  password: \"\"\n\nmysql-instances:\n-\n  source-id: \"mysql-replica-01\"\n  block-allow-list: \"global\"\n  mydumper-config-name: \"global\"\n\n-\n  source-id: \"mysql-replica-02\"\n  block-allow-list: \"global\"\n  mydumper-config-name: \"global\"\n\nblock-allow-list:\n  global:\n    do-tables:\n    - db-name: \"test_db\"\n      tbl-name: \"test_table\"\n\nmydumpers:\n  global:\n    extra-args: \"\"\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration\nDESCRIPTION: YAML frontmatter configuration block defining the document title, aliases for URL routing, and a summary of the TiDB 4.0.0 GA release.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0-ga.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: TiDB 4.0 GA Release Notes\naliases: ['/docs/dev/releases/release-4.0-ga/']\nsummary: TiDB 4.0.0 GA was released on May 28, 2020. This version optimized error messages for large-sized transactions, improved usability of `Changefeed` configuration file, added new configuration items and support for various syntax and functions, fixed multiple bugs and issues in TiKV, TiFlash, PD, and Tools, added new monitoring items and support for various features in PD, and fixed various issues in Backup & Restore (BR) and TiCDC.\n---\n```\n\n----------------------------------------\n\nTITLE: Setting a TIUP Mirror Address in Shell\nDESCRIPTION: The snippet demonstrates the `tiup mirror set` command, which is used to set the mirror source for TIUP. Users can specify the mirror address either as a network URL or a local file path. The command can also accept a root certificate to ensure the security of network mirrors.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-set.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror set <mirror-addr> [flags]\n```\n\n----------------------------------------\n\nTITLE: LOAD DATA Transaction Behavior in TiDB Versions\nDESCRIPTION: Documents the transaction commit behavior of LOAD DATA across different TiDB versions, including changes in row commit frequency and transaction mode processing\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-load-data.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nLOAD DATA\n```\n\n----------------------------------------\n\nTITLE: Stopping TiFlash Instance Using TiUP\nDESCRIPTION: Command to stop TiFlash instance before upgrade using TiUP cluster management tool.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash-upgrade-guide.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster stop <cluster-name> -R tiflash\n```\n\n----------------------------------------\n\nTITLE: Configuring Engine Isolation in TiDB SQL\nDESCRIPTION: This SQL command sets the isolation read engines at the session level, allowing you to specify which storage engines to use for queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tidb-to-read-tiflash.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nset @@session.tidb_isolation_read_engines = \"engine list separated by commas\";\n```\n\n----------------------------------------\n\nTITLE: SHOW COLUMN_STATS_USAGE example\nDESCRIPTION: This snippet demonstrates a basic usage example of the `SHOW COLUMN_STATS_USAGE` statement. It displays the last usage and collection time of column statistics for all tables in the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-column-stats-usage.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n\"SHOW COLUMN_STATS_USAGE;\"\n```\n\n----------------------------------------\n\nTITLE: Identifying Damaged SST Files with TiKV Control\nDESCRIPTION: This command shows information about damaged SST files in TiKV to help with cleanup. It requires stopping the running TiKV instance first, and provides file details, overlap regions, and suggested operations to fix the problem.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_28\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir </path/to/tikv> bad-ssts --pd <endpoint>\n```\n\n----------------------------------------\n\nTITLE: Deleting Existing ProxySQL SQLite Database\nDESCRIPTION: This command removes the existing ProxySQL SQLite database file, which is necessary when configuring ProxySQL using a configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nrm /var/lib/proxysql/proxysql.db\n```\n\n----------------------------------------\n\nTITLE: Updating TiUP and Components\nDESCRIPTION: This shell command updates TiUP itself as well as installed components within the TiUP ecosystem. It is essential to regularly perform updates to ensure compatibility and include the latest features provided in new releases. Reading release logs and compatibility notes is also recommended.\nSOURCE: https://github.com/pingcap/docs/blob/master/migration-tools.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup update --self && tiup update dm\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Parameters for Non-Point Select Workloads\nDESCRIPTION: This YAML snippet enables the 'prefill-for-recycle' parameter in TiKV for workloads such as 'oltp_insert', 'oltp_read_write', 'oltp_update_index', and 'oltp_update_non_index', allowing immediate log recycling after initialization for these scenarios.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.1-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nraft-engine.prefill-for-recycle = true\n```\n\n----------------------------------------\n\nTITLE: Describing the tidb_mdl_view Structure in MySQL\nDESCRIPTION: This SQL snippet demonstrates how to describe the structure of the tidb_mdl_view within the MySQL schema. The output includes definitions of various fields such as job_id, db_name, table_name, and others, detailing their types and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/mysql-schema/mysql-schema-tidb-mdl-view.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nDESC mysql.tidb_mdl_view;\n```\n\n----------------------------------------\n\nTITLE: SAVEPOINT EBNF Syntax in TiDB SQL\nDESCRIPTION: Provides the Extended Backus-Naur Form (EBNF) syntax for SAVEPOINT, ROLLBACK TO SAVEPOINT, and RELEASE SAVEPOINT statements in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-savepoint.md#2025-04-18_snippet_1\n\nLANGUAGE: EBNF\nCODE:\n```\nSavepointStmt ::=\n    \"SAVEPOINT\" Identifier\n\nRollbackToStmt ::=\n    \"ROLLBACK\" \"TO\" \"SAVEPOINT\"? Identifier\n\nReleaseSavepointStmt ::=\n    \"RELEASE\" \"SAVEPOINT\" Identifier\n```\n\n----------------------------------------\n\nTITLE: Example Amazon S3 URI for TiDB Lightning and BR\nDESCRIPTION: Shows how to format an Amazon S3 URI for use with TiDB Lightning and BR tools, specifying a specific folder path with access credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/external-storage-uri.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ns3://external/testfolder?access-key=${access-key}&secret-access-key=${secret-access-key}\n```\n\n----------------------------------------\n\nTITLE: Counting Authors by Birth Year Using SQL GROUP BY in TiDB\nDESCRIPTION: This SQL query groups authors by birth year and counts the distinct IDs to find out which years had more authors born. The results are ordered by the count in descending order.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-get-data-from-single-table.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT birth_year, COUNT (DISTINCT id) AS author_count\nFROM authors\nGROUP BY birth_year\nORDER BY author_count DESC;\n```\n\n----------------------------------------\n\nTITLE: Parsing TSO Timestamp with TIDB_PARSE_TSO() Function\nDESCRIPTION: This snippet shows how to parse a TiDB TSO timestamp into a human-readable datetime format using the TIDB_PARSE_TSO() SQL function, which converts the physical part of the timestamp.\nSOURCE: https://github.com/pingcap/docs/blob/master/tso.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_PARSE_TSO(443852055297916932);\n+------------------------------------+\n| TIDB_PARSE_TSO(443852055297916932) |\n+------------------------------------+\n| 2023-08-27 20:33:41.687000         |\n+------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining DEALLOCATE Statement Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) diagram defining the syntax of the DEALLOCATE statement in TiDB. It shows that DEALLOCATE can be used with the PREPARE keyword followed by an identifier, and that DEALLOCATE can also be expressed as DROP.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-deallocate.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDeallocateStmt ::=\n    DeallocateSym 'PREPARE' Identifier\n\nDeallocateSym ::=\n    'DEALLOCATE'\n|   'DROP'\n\nIdentifier ::=\n    identifier\n|   UnReservedKeyword\n|   NotKeywordToken\n|   TiDBKeyword\n```\n\n----------------------------------------\n\nTITLE: Demonstrating tidb_constraint_check_in_place=OFF with Optimistic Transactions in SQL\nDESCRIPTION: This example shows how setting tidb_constraint_check_in_place to OFF with optimistic transactions defers uniqueness checking until transaction commit time, allowing conflicting inserts to succeed temporarily.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_16\n\nLANGUAGE: sql\nCODE:\n```\ntidb> create table t (i int key);\ntidb> insert into t values (1);\ntidb> begin optimistic;\ntidb> insert into t values (1);\nQuery OK, 1 row affected\ntidb> commit; -- Check only when a transaction is committed.\nERROR 1062 : Duplicate entry '1' for key 't.PRIMARY'\n```\n\n----------------------------------------\n\nTITLE: Scaling out the TiDB cluster using TiUP\nDESCRIPTION: This command scales out the TiDB cluster using the provided scale-out topology file. It adds the nodes defined in the YAML file to the specified cluster. The command uses the specified user credentials to access and configure the new nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster scale-out <cluster-name> scale-out.yml [-p] [-i /home/root/.ssh/gcp_rsa]\"\n```\n\n----------------------------------------\n\nTITLE: Using SHOW [FULL] FIELDS FROM in TiDB SQL\nDESCRIPTION: This SQL statement is used to display the fields of a table within the TiDB database, serving as an alias for SHOW [FULL] COLUMNS FROM to ensure compatibility with MySQL. It provides information about the structure of the table, including fields and their types.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-fields-from.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW [FULL] FIELDS FROM table_name;\n```\n\n----------------------------------------\n\nTITLE: Dumpling Export Commands for MySQL Instances\nDESCRIPTION: Shell commands using Dumpling to export MySQL data to Amazon S3 in CSV format\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n[root@localhost ~]# tiup dumpling -u {username} -p {password} -P {port} -h {mysql01-ip} -B store_01,store_02 -r 20000 --filetype csv --no-schemas -o \"s3://dumpling-s3/store/sales/instance01/\" --s3.region \"ap-northeast-1\"\n\n[root@localhost ~]# tiup dumpling -u {username} -p {password} -P {port} -h {mysql02-ip} -B store_01,store_02 -r 20000 --filetype csv --no-schemas -o \"s3://dumpling-s3/store/sales/instance02/\" --s3.region \"ap-northeast-1\"\n```\n\n----------------------------------------\n\nTITLE: RocksDB WAL and Compaction Settings\nDESCRIPTION: Core RocksDB configurations for Write-Ahead Log (WAL) size, compaction behavior, and I/O settings. Includes parameters for buffer sizes, direct I/O, and pipelined operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_21\n\nLANGUAGE: yaml\nCODE:\n```\nmax-total-wal-size: \"4GiB\"\ncompaction-readahead-size: \"2MiB\"\nwritable-file-max-buffer-size: \"1MiB\"\nuse-direct-io-for-flush-and-compaction: false\nenable-pipelined-write: true\nallow-concurrent-memtable-write: true\n```\n\n----------------------------------------\n\nTITLE: Granting ALL Privileges to a Role in TiDB\nDESCRIPTION: This snippet shows how to grant all privileges on the `app_db` database to the `app_developer` role. This provides the role with complete access and control over the specified database. The user executing this statement needs appropriate grant privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nGRANT ALL ON app_db.* TO 'app_developer';\n```\n\n----------------------------------------\n\nTITLE: Listing Data Export Tasks in TiDB Cloud Serverless - Shell\nDESCRIPTION: This snippet demonstrates how to list all data export tasks for TiDB Cloud Serverless clusters using the `ticloud serverless export list` command. It provides various options for listing tasks, including interactive and non-interactive modes, as well as output formats.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-list.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export list [flags]\n```\n\n----------------------------------------\n\nTITLE: Enabling utf8mb4_general_ci Collation in TiDB 4.0 RC\nDESCRIPTION: TiDB 4.0 RC adds support for case-insensitive collations, allowing users to enable 'utf8mb4_general_ci' and 'utf8_general_ci' in new clusters. This feature enhances string comparison and sorting capabilities.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-rc.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\n-- Example of enabling utf8mb4_general_ci collation\nCREATE TABLE example (\n  id INT,\n  name VARCHAR(255) COLLATE utf8mb4_general_ci\n) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\n```\n\n----------------------------------------\n\nTITLE: Analyzing Tables for Optimal Execution Plans\nDESCRIPTION: SQL statements that collect statistics for various tables within the 'tpcc' database to ensure the TiDB optimizer can generate an optimal execution plan.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE customer;\nANALYZE TABLE district;\nANALYZE TABLE history;\nANALYZE TABLE item;\nANALYZE TABLE new_order;\nANALYZE TABLE order_line;\nANALYZE TABLE orders;\nANALYZE TABLE stock;\nANALYZE TABLE warehouse;\n```\n\n----------------------------------------\n\nTITLE: Optimized Query Using JOIN Instead of Correlated Subquery in SQL\nDESCRIPTION: This SQL query is an optimized version of the previous correlated subquery example. It uses a JOIN operation instead, which is generally more efficient for TiDB to execute.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-subqueries.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT *\nFROM\n    authors a1,\n    (\n        SELECT\n            gender, AVG(\n                IFNULL(a2.death_year, YEAR(NOW())) - IFNULL(a2.birth_year, YEAR(NOW()))\n            ) AS average_age\n        FROM\n            authors a2\n        GROUP BY gender\n    ) a2\nWHERE\n    a1.gender = a2.gender\n    AND (IFNULL(a1.death_year, YEAR(NOW())) - a1.birth_year) > a2.average_age;\n```\n\n----------------------------------------\n\nTITLE: Running Query Status Command in TiUP DMCTL Shell\nDESCRIPTION: This shell command is used to query the status of a specific replication task in a DM cluster. The command connects to a DM control instance using the specified master address and retrieves the task status for 'test-task1'.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\n[root@localhost ~]# tiup dmctl --master-addr 192.168.11.110:9261 query-status test-task1\n```\n\n----------------------------------------\n\nTITLE: Disabling Binding Evolution Before Upgrade in TiDB SQL\nDESCRIPTION: This SQL command checks the status of the 'tidb_evolve_plan_baselines' variable and disables it for a successful upgrade if it is found to be enabled. It is crucial to perform this step when upgrading from older versions of TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_37\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@global.tidb_evolve_plan_baselines;\nSET GLOBAL tidb_evolve_plan_baselines = OFF;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiSpark Authentication and Authorization in Spark\nDESCRIPTION: Configuration settings for enabling authentication and authorization in TiSpark v2.5.0+ through TiDB. These settings are added to spark-defaults.conf to specify connection details and enable security features.\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_11\n\nLANGUAGE: conf\nCODE:\n```\n// Enable authentication and authorization\nspark.sql.auth.enable true\n\n// Configure TiDB information\nspark.sql.tidb.addr $your_tidb_server_address\nspark.sql.tidb.port $your_tidb_server_port\nspark.sql.tidb.user $your_tidb_server_user\nspark.sql.tidb.password $your_tidb_server_password\n```\n\n----------------------------------------\n\nTITLE: Capturing gh-ost test output to a file\nDESCRIPTION: Command to run gh-ost in test mode with verbose output redirected to a log file for review before actual execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/styles/config/vocabularies/PingCAP/accept.txt#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ngh-ost \\\n  --user=root \\\n  --password=123456 \\\n  --host=192.168.16.221 \\\n  --port=4000 \\\n  --database=test \\\n  --table=person \\\n  --alter=\"add column age int\" \\\n  --max-load=Threads_running=90 \\\n  --allow-on-master \\\n  --assume-rbr \\\n  --approve-renamed-columns \\\n  --verbose \\\n  --test-on-replica \\\n  --execute > test.log 2>&1\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB DM Task Status using dmctl\nDESCRIPTION: This snippet shows how to use the `dmctl` tool to query the status of the TiDB DM task by connecting to the master address of the DM components. This command is essential to ensure that the migration process is running as expected.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr 127.0.0.1:8261 query-status\n```\n\n----------------------------------------\n\nTITLE: EXPLAIN Query with Optimized Partition Pruning\nDESCRIPTION: An EXPLAIN statement analyzing a query that benefits from partition pruning. The execution plan shows that TiDB only needs to access the p2017 partition because the query specifies an exact date that falls within that partition.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-partitions.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT COUNT(*) FROM t1 WHERE d = '2017-06-01';\n```\n\n----------------------------------------\n\nTITLE: Backing Up Specific Database to S3\nDESCRIPTION: Command to back up a single database from a TiDB cluster to Amazon S3 storage using the BR tool. It specifies the database name, storage location, rate limit, and log file.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup db \\\n    --pd \"${PD_IP}:2379\" \\\n    --db test \\\n    --storage \"s3://${backup_collection_addr}/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --ratelimit 128 \\\n    --log-file backuptable.log\n```\n\n----------------------------------------\n\nTITLE: Fixing Date_Format Function Handling in TiFlash\nDESCRIPTION: This fix addresses a panic issue in TiFlash that occurred when the Date_Format function was called with STRING type arguments and NULL values. The fix improves the stability of TiFlash when processing date formatting operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.3.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nDate_Format()\n```\n\n----------------------------------------\n\nTITLE: Creating AWS VPC Endpoint via CLI\nDESCRIPTION: AWS CLI command to create a VPC interface endpoint that connects to a TiDB Cloud endpoint service. The command requires VPC ID, region, service name, and subnet IDs as parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-private-endpoint-connections.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\naws ec2 create-vpc-endpoint --vpc-id ${your_vpc_id} --region ${your_region} --service-name ${your_endpoint_service_name} --vpc-endpoint-type Interface --subnet-ids ${your_application_subnet_ids}\n```\n\n----------------------------------------\n\nTITLE: Configuration Example for Titan Engine Mode in TiKV\nDESCRIPTION: Shows the configuration parameter 'blob-run-mode' that controls the Titan engine's running mode in TiKV, with possible values being 'normal', 'read-only', or 'fallback'.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.1.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- Add the `blob-run-mode` configuration parameter to control the running mode of the Titan engine, and its value can be `normal`, `read-only` or `fallback` [#4865](https://github.com/tikv/tikv/pull/4865)\n```\n\n----------------------------------------\n\nTITLE: Executing EXPLAIN ANALYZE on SELECT Queries\nDESCRIPTION: This SQL snippet shows the usage of EXPLAIN ANALYZE with a SELECT statement on table t1 to analyze execution plans and performance metrics.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-bindings.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nmysql> EXPLAIN ANALYZE SELECT * FROM t1 WHERE b = 123;\n+-------------------------------+---------+---------+-----------+----------------------+---------------------------------------------------------------------------+-----------------------------------+----------------+------+\n| id                            | estRows | actRows | task      | access object        | execution info                                                            | operator info                     | memory         | disk |\n+-------------------------------+---------+---------+-----------+----------------------+---------------------------------------------------------------------------+-----------------------------------+----------------+------+\n| IndexLookUp_10                | 583.00  | 297     | root      |                      | time:10.545072ms, loops:2, rpc num: 1, rpc time:398.359µs, proc keys:297  |                                   | 109.1484375 KB | N/A  |\n| ├─IndexRangeScan_8(Build)     | 583.00  | 297     | cop[tikv] | table:t1, index:b(b) | time:0s, loops:4                                                          | range:[123,123], keep order:false | N/A            | N/A  |\n| └─TableRowIDScan_9(Probe)     | 583.00  | 297     | cop[tikv] | table:t1             | time:12ms, loops:4                                                        | keep order:false                  | N/A            | N/A  |\n+-------------------------------+---------+---------+-----------+----------------------+---------------------------------------------------------------------------+-----------------------------------+----------------+------+\n3 rows in set (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Upstream Database TLS in YAML\nDESCRIPTION: YAML configuration for enabling TLS encryption for connections to the upstream MySQL database.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-enable-tls.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nfrom:\n    security:\n        ssl-ca: \"/path/to/mysql-ca.pem\"\n        ssl-cert: \"/path/to/mysql-cert.pem\"\n        ssl-key: \"/path/to/mysql-key.pem\"\n```\n\n----------------------------------------\n\nTITLE: Displaying S3 Folder URI Example for Parquet Import\nDESCRIPTION: Shows an example S3 folder URI format used when importing multiple Parquet files from a specific directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-parquet-files.md#2025-04-18_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\ns3://sampledata/ingest/\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW COLUMNS Statement in EBNF\nDESCRIPTION: This EBNF diagram outlines the syntax for the SHOW COLUMNS FROM statement in TiDB. It includes optional keywords for a more comprehensive output and specifies how table and schema names can be included in the statement. Additional clauses allow filtering with LIKE or WHERE conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-columns-from.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\n\"ShowColumnsFromStmt ::=\\n    \\\"SHOW\\\" \\\"FULL\\\"? (\\\"COLUMNS\\\" | \\\"FIELDS\\\") (\\\"FROM\\\" | \\\"IN\\\") TableName ( (\\\"FROM\\\" | \\\"IN\\\") SchemaName)? ShowLikeOrWhere?\\n\\nTableName ::=\\n    (Identifier \\\".\\\")? Identifier\\n\\nShowLikeOrWhere ::=\\n    \\\"LIKE\\\" SimpleExpr\\n|   \\\"WHERE\\\" Expression\"\n```\n\n----------------------------------------\n\nTITLE: Inserting Back to Original TiDB Server with Available Cache\nDESCRIPTION: This snippet shows an INSERT operation against the initial TiDB server which still has space in its AUTO_INCREMENT cache, resulting in non-monotonic value generation (value 4 after 2000001).\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nmysql> INSERT INTO t (a) VALUES (NULL);\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> SELECT * FROM t ORDER BY b;\n+---------+---------------------+\n| a       | b                   |\n+---------+---------------------+\n|       1 | 2020-09-09 20:38:22 |\n|       2 | 2020-09-09 20:38:22 |\n|       3 | 2020-09-09 20:38:22 |\n| 2000001 | 2020-09-09 20:43:43 |\n|       4 | 2020-09-09 20:44:43 |\n+---------+---------------------+\n5 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Checking TIFLASH Replica Status - SQL\nDESCRIPTION: Queries the availability and replication progress of TiFlash replicas for tables in the 'test' schema, assessing the readiness of the replication process for column-based query execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-htap.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = 'test' and TABLE_NAME = 'customer';\nSELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = 'test' and TABLE_NAME = 'orders';\nSELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = 'test' and TABLE_NAME = 'lineitem';\n```\n\n----------------------------------------\n\nTITLE: Converting Timestamp to Readable Time with pd-ctl\nDESCRIPTION: Command to convert a transaction timestamp to a human-readable time format using the pd-ctl tool, useful for troubleshooting write conflicts.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-write-conflicts.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd -u https://127.0.0.1:2379 tso {TIMESTAMP}\n```\n\n----------------------------------------\n\nTITLE: Generating bash completion file for TiUP\nDESCRIPTION: This snippet shows how to generate the bash completion file for TiUP using the `tiup completion bash` command and how to source it in `.bash_profile`. The generated file provides auto-completion for TiUP commands in the bash shell.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-completion.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup completion bash > ~/.tiup.completion.bash\n\nprintf \"\n# tiup shell completion\nsource '$HOME/.tiup.completion.bash'\n\" >> $HOME/.bash_profile\n\nsource $HOME/.bash_profile\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP on Darwin and Linux\nDESCRIPTION: Command to install TiUP on Darwin and Linux operating systems. This installs TiUP in the $HOME/.tiup folder and adds it to the PATH environment variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Enabling TiDB Distributed Task\nDESCRIPTION: This SQL statement enables the TiDB Distributed Task framework, which is a prerequisite for using the Global Sort feature. Starting from v8.1.0, this variable is enabled by default. It sets the `tidb_enable_dist_task` global variable to `ON`.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-global-sort.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_dist_task = ON;\n```\n\n----------------------------------------\n\nTITLE: Disabling Audit Logging in PD\nDESCRIPTION: Disables the audit logging function for HTTP requests processed by PD.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nconfig set service-middleware audit enable-audit false\n```\n\n----------------------------------------\n\nTITLE: Retrieving Last Backup Timestamp for TiDB Incremental Backup\nDESCRIPTION: This command retrieves the end-version timestamp from a previous backup using the BR validate command. The timestamp is stored in the LAST_BACKUP_TS variable for use in incremental backup.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-incremental-guide.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nLAST_BACKUP_TS=`tiup br validate decode --field=\"end-version\" --storage \"s3://backup-101/snapshot-202209081330?access-key=${access-key}&secret-access-key=${secret-access-key}\"| tail -n1`\n```\n\n----------------------------------------\n\nTITLE: Describing TIDB_INDEX_USAGE Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the TIDB_INDEX_USAGE table in the INFORMATION_SCHEMA database, showing all columns and their properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-index-usage.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC TIDB_INDEX_USAGE;\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for AWS VPC Peering\nDESCRIPTION: Template for setting up environment variables with your AWS account information, including TiDB peering ID, app region, VPC ID, and TiDB Cloud CIDR range.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-vpc-peering-connections.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Sets up the related variables.\npcx_tidb_to_app_id=\"<TiDB peering id>\"\napp_region=\"<APP Region>\"\napp_vpc_id=\"<Your VPC ID>\"\ntidbcloud_project_cidr=\"<TiDB Cloud Project VPC CIDR>\"\n```\n\n----------------------------------------\n\nTITLE: Example: Checking Compaction State of a Non-Partitioned Table\nDESCRIPTION: Complete example showing how to create a table with TiFlash replica, check its compaction state, insert data, and observe changes in delta rows before and after compaction.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-table-compact.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nUSE test;\n\nCREATE TABLE foo(id INT);\n\nALTER TABLE foo SET TIFLASH REPLICA 1;\n\nSELECT TOTAL_DELTA_ROWS, TOTAL_STABLE_ROWS FROM INFORMATION_SCHEMA.TIFLASH_TABLES\n    WHERE IS_TOMBSTONE = 0 AND\n    `TIDB_DATABASE` = \"test\" AND `TIDB_TABLE` = \"foo\";\n+------------------+-------------------+\n| TOTAL_DELTA_ROWS | TOTAL_STABLE_ROWS |\n+------------------+-------------------+\n|                0 |                 0 |\n+------------------+-------------------+\n\nINSERT INTO foo VALUES (1), (3), (7);\n\nSELECT TOTAL_DELTA_ROWS, TOTAL_STABLE_ROWS FROM INFORMATION_SCHEMA.TIFLASH_TABLES\n    WHERE IS_TOMBSTONE = 0 AND\n    `TIDB_DATABASE` = \"test\" AND `TIDB_TABLE` = \"foo\";\n+------------------+-------------------+\n| TOTAL_DELTA_ROWS | TOTAL_STABLE_ROWS |\n+------------------+-------------------+\n|                3 |                 0 |\n+------------------+-------------------+\n-- Newly written data can be compacted\n\nALTER TABLE foo COMPACT TIFLASH REPLICA;\n\nSELECT TOTAL_DELTA_ROWS, TOTAL_STABLE_ROWS FROM INFORMATION_SCHEMA.TIFLASH_TABLES\n    WHERE IS_TOMBSTONE = 0 AND\n    `TIDB_DATABASE` = \"test\" AND `TIDB_TABLE` = \"foo\";\n+------------------+-------------------+\n| TOTAL_DELTA_ROWS | TOTAL_STABLE_ROWS |\n+------------------+-------------------+\n|                0 |                 3 |\n+------------------+-------------------+\n-- All data is in the best state and no compaction is needed\n```\n\n----------------------------------------\n\nTITLE: Executing markdownlint locally\nDESCRIPTION: This snippet shows how to run the markdownlint tool locally to check Markdown files for compliance with the defined rules.  It takes file paths as arguments and reports any violations.\nSOURCE: https://github.com/pingcap/docs/blob/master/resources/markdownlint-rules.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\". /scripts/markdownlint [FILE...]\"\n```\n\n----------------------------------------\n\nTITLE: Resuming a Log Backup Task\nDESCRIPTION: This command resumes a log backup task that has stopped due to an error. You need to identify and address the cause of the error before running this command. Specifying the task name and PD address is crucial for resuming the correct task.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/backup-and-restore-faq.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n\"br log resume --task-name=task1 --pd x.x.x.x:2379\"\n```\n\n----------------------------------------\n\nTITLE: Listing Serverless Clusters in Non-Interactive Mode\nDESCRIPTION: Example of listing all TiDB Cloud Serverless clusters in a specified project using non-interactive mode. The project ID must be provided using the -p flag.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-list.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless list -p <project-id>\n```\n\n----------------------------------------\n\nTITLE: Getting Data Source List with cURL in Shell\nDESCRIPTION: This example demonstrates how to retrieve a list of all data sources by making a GET request to the DM API. The 'with_status=true' parameter includes the current status of each data source.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/sources?with_status=true' \\\n  -H 'accept: application/json'\n```\n\n----------------------------------------\n\nTITLE: Adding store to evict-leader-scheduler in TiDB PD\nDESCRIPTION: This command adds leader eviction scheduling for a specified store to an existing evict-leader-scheduler.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_44\n\nLANGUAGE: bash\nCODE:\n```\nscheduler config evict-leader-scheduler add-store 2       // Add leader eviction scheduling for store 2\n```\n\n----------------------------------------\n\nTITLE: Using STRAIGHT_JOIN to Control Join Order in TiDB SQL\nDESCRIPTION: This example shows how to use the STRAIGHT_JOIN keyword to enforce a specific join order in TiDB. The tables will be joined in the exact order specified in the FROM clause, overriding the optimizer's choice.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-join-tables.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT *\nFROM authors a STRAIGHT_JOIN book_authors ba STRAIGHT_JOIN books b\nWHERE b.id = ba.book_id AND ba.author_id = a.id;\n```\n\n----------------------------------------\n\nTITLE: Using tiup clean Command Syntax\nDESCRIPTION: This snippet demonstrates the syntax of the tiup clean command, allowing users to specify a component name or clear all records if no name is provided. The command requires flags for appropriate operation and provides clear delineation of options available.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-clean.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup clean [name] [flags]\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Non-Pushdown of User Variable Predicates in TiDB SQL\nDESCRIPTION: This SQL snippet creates a table, sets a user variable, and explains a query with a predicate containing the user variable. The execution plan shows that the predicate is not pushed down to TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/predicate-push-down.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id int primary key, a char);\nset @a = 1;\nexplain select * from t where a < @a;\n```\n\n----------------------------------------\n\nTITLE: Consolidate Markdown Files with Python\nDESCRIPTION: This command executes a Python script named `merge_by_toc.py` which merges all markdown files into a single file `doc.md` based on the `TOC.md` file. The merged `doc.md` file is created in the same directory as `TOC.md`.\nSOURCE: https://github.com/pingcap/docs/blob/master/resources/tidb-pdf-generation-tutorial.md#2025-04-18_snippet_4\n\nLANGUAGE: python\nCODE:\n```\npython3 scripts/merge_by_toc.py\n```\n\n----------------------------------------\n\nTITLE: Run TPC-H Test Without Result Checking (Bash)\nDESCRIPTION: This command runs the TPC-H benchmark with a scale factor of 1 without checking the results. It sets the count to 22, running all the queries, and omits the `--check=true` flag.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench tpch --count=22 --sf=1 run\n```\n\n----------------------------------------\n\nTITLE: Installing Test Data Generation Tool - Shell\nDESCRIPTION: This command utilizes TiUP to install the 'bench' tool, which assists in generating test datasets suitable for HTAP experimentation within TiDB. This tool needs to be installed before generating TPC-H test datasets.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-htap.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup install bench\n```\n\n----------------------------------------\n\nTITLE: Markdown Release Notes Header\nDESCRIPTION: Title and metadata section of the release notes document, including version information and release date.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.9.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: TiDB 4.0.9 Release Notes\nsummary: TiDB 4.0.9 was released on December 21, 2020. The release includes compatibility changes, new features, improvements, bug fixes, and updates to TiKV, TiDB Dashboard, PD, TiFlash, and various tools. Notable changes include the deprecation of the `enable-streaming` configuration item in TiDB, support for storing the latest data of the storage engine on multiple disks in TiFlash, and various bug fixes in TiDB and TiKV.\n---\n\n# TiDB 4.0.9 Release Notes\n\nRelease date: December 21, 2020\n\nTiDB version: 4.0.9\n```\n\n----------------------------------------\n\nTITLE: Capturing Execution Plans using PLAN REPLAYER CAPTURE\nDESCRIPTION: This section describes the functionality of PLAN REPLAYER CAPTURE, which registers a target SQL statement and its associated execution plan for capturing optimizer information when matched. The resulting data is exported as a ZIP file.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-replayer.md#2025-04-18_snippet_3\n\n\n\n----------------------------------------\n\nTITLE: Running DM-master with Configuration File\nDESCRIPTION: Command to start DM-master using the specified configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-binary.md#2025-04-18_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\n./dm-master -config conf/dm-master1.toml\n```\n\n----------------------------------------\n\nTITLE: Setting Store Limit for individual stores\nDESCRIPTION: Commands to configure store limits for a specific store by ID, allowing for targeted throttling of add-peer and remove-peer operations on particular nodes.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-store-limit.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd store limit 1 5                     // store 1 can at most add and delete 5 peers per minute.\ntiup ctl:v<CLUSTER_VERSION> pd store limit 1 5 add-peer            // store 1 can at most add 5 peers per minute.\ntiup ctl:v<CLUSTER_VERSION> pd store limit 1 5 remove-peer         // store 1 can at most delete 5 peers per minute.\n```\n\n----------------------------------------\n\nTITLE: Managing Operators with pd-ctl in TiDB\nDESCRIPTION: This snippet demonstrates pd-ctl commands for managing operators in TiDB, including adding peers, transferring leaders, splitting regions, and removing operators.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/pd-scheduling-best-practices.md#2025-04-18_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n- `operator add add-peer 2 5`: Adds peers to Region 2 in Store 5\n- `operator add transfer-leader 2 5`: Migrates the leader of Region 2 to Store 5\n- `operator add split-region 2`: Splits Region 2 into two regions evenly in size\n- `operator remove 2`: Removes currently pending operator in Region 2\n```\n\n----------------------------------------\n\nTITLE: Example of Vector Index Not Being Used Due to Missing LIMIT\nDESCRIPTION: This EXPLAIN query shows an example where the vector index is not used because a Top K (LIMIT) clause is not specified in the query. Without a LIMIT, the query cannot leverage the vector index for optimization.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-index.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM vector_table_with_index\nORDER BY VEC_COSINE_DISTANCE(embedding, '[1, 2, 3]');\n```\n\n----------------------------------------\n\nTITLE: Creating and Using a Placement Policy in TiDB SQL\nDESCRIPTION: SQL example demonstrating how to create a placement policy, apply it to a table, and show the created policy. The policy specifies primary region, regions, and number of followers for data placement.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-placement-policy.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY p1 PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1,us-west-1\" FOLLOWERS=4;\nCREATE TABLE t1 (a INT) PLACEMENT POLICY=p1;\nSHOW CREATE PLACEMENT POLICY p1;\n```\n\n----------------------------------------\n\nTITLE: Displaying TiDB Cluster Status\nDESCRIPTION: This command displays the current status of the TiDB cluster, including all nodes and their respective roles. It is used to verify that the scale-out operation was successful and that the new nodes are functioning correctly.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster display <cluster-name>\"\n```\n\n----------------------------------------\n\nTITLE: Querying MySQL Binlog Status for Migration\nDESCRIPTION: SQL command to check the binlog file name and position of the source database, which is necessary for configuring a migration job to TiDB Cloud. This information is used to specify the starting point for incremental data migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-incremental-data-from-mysql-using-data-migration.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW MASTER STATUS;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV-CDC Servers in YAML\nDESCRIPTION: Example YAML configuration for kvcdc_servers specifying two TiKV-CDC instances. This minimal configuration only defines the host machines where TiKV-CDC services will be deployed, using default values for other parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nkvcdc_servers:\n  - host: 10.0.1.21\n  - host: 10.0.1.22\n```\n\n----------------------------------------\n\nTITLE: Skipping a Specific Field During Import\nDESCRIPTION: This SQL statement imports a CSV file into a TiDB table while skipping a specific field.  `@1` acts as a placeholder to skip the `age` field during import. This allows selective import of columns without modifying the source file.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO t(id, name, @1) FROM '/path/to/file.csv' WITH skip_rows=1;\n```\n\n----------------------------------------\n\nTITLE: SQL Table Definition with Floating-Point Default for Integer\nDESCRIPTION: An example SQL definition showing an integer column with a floating-point default value ('0.0') that previously caused TiFlash bootstrap failures. This issue has been fixed in the referenced update.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.5.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\n`i` int(11) NOT NULL DEFAULT '0.0'\n```\n\n----------------------------------------\n\nTITLE: Configuring `location-labels` for PD\nDESCRIPTION: This TOML snippet configures the PD server's `location-labels`, which is crucial for ensuring the PD understands the hierarchy of labels used in TiKV. It also mentions methods for configuring it for both initialized and uninitialized PD clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/schedule-replicas-by-topology-labels.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[replication]\nlocation-labels = [\"zone\", \"rack\", \"host\"]\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB with Go-MySQL-Driver\nDESCRIPTION: Function to open a database connection using Go-MySQL-Driver. It constructs the DSN string with connection parameters and executes a provided function with the database connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-golang-sql-driver.md#2025-04-18_snippet_0\n\nLANGUAGE: Go\nCODE:\n```\nfunc openDB(driverName string, runnable func(db *sql.DB)) {\n    dsn := fmt.Sprintf(\"%s:%s@tcp(%s:%s)/%s?charset=utf8mb4&tls=%s\",\n        ${tidb_user}, ${tidb_password}, ${tidb_host}, ${tidb_port}, ${tidb_db_name}, ${use_ssl})\n    db, err := sql.Open(driverName, dsn)\n    if err != nil {\n        panic(err)\n    }\n    defer db.Close()\n\n    runnable(db)\n}\n```\n\n----------------------------------------\n\nTITLE: ENGINES Table Query Results in SQL\nDESCRIPTION: This shows the result of the SELECT query on the ENGINES table, displaying that TiDB only shows InnoDB as its supported storage engine for compatibility purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-engines.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+--------+---------+------------------------------------------------------------+--------------+------+------------+\n| ENGINE | SUPPORT | COMMENT                                                    | TRANSACTIONS | XA   | SAVEPOINTS |\n+--------+---------+------------------------------------------------------------+--------------+------+------------+\n| InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES          | YES  | YES        |\n+--------+---------+------------------------------------------------------------+--------------+------+------------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining TINYBLOB Column in TiDB\nDESCRIPTION: Syntax for creating a TINYBLOB column with maximum length of 255 bytes.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nTINYBLOB\n```\n\n----------------------------------------\n\nTITLE: Running TPC-C Stress Tests\nDESCRIPTION: This shell command conducts stress tests on the TiDB Cloud Dedicated cluster using `go-tpc tpcc`. It specifies the host, port, number of warehouses, database name, number of threads, test duration, and password. The `${HOST}` and `${PASSWORD}` placeholders should be replaced with actual values.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v6.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n\"go-tpc tpcc --host ${HOST} -P 4000 --warehouses 1000 run -D tpcc -T ${THREAD} --time 2h0m0s -p ${PASSWORD} --ignore-error\"\n```\n\n----------------------------------------\n\nTITLE: Checking Lock Availability with IS_FREE_LOCK in TiDB SQL\nDESCRIPTION: Checks if a specified lock is free and available for acquisition.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/locking-functions.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nIS_FREE_LOCK(lockName)\n```\n\n----------------------------------------\n\nTITLE: Installing OpenSSL on RedHat/CentOS\nDESCRIPTION: Command to install OpenSSL on RedHat or CentOS operating systems using the yum package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nyum install openssl\n```\n\n----------------------------------------\n\nTITLE: Restoring Multiple Tables Using Filter\nDESCRIPTION: Command to restore multiple tables using table filter patterns with BR. Uses the tiup br restore full command with PD endpoint, table filter pattern, and S3 storage location parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-guide.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup br restore full \\\n--pd \"${PD_IP}:2379\" \\\n--filter 'db*.tbl*' \\\n--storage \"s3://backup-101/snapshot-202209081330?access-key=${access-key}&secret-access-key=${secret-access-key}\"\n```\n\n----------------------------------------\n\nTITLE: Correcting STR_TO_DATE Function in TiDB\nDESCRIPTION: This fix addresses inconsistencies in the STR_TO_DATE function's handling of format tokens '%r' and '%h' compared to MySQL. It aligns TiDB's behavior with MySQL for these specific format tokens.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.5.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSTR_TO_DATE(..., '%r'), STR_TO_DATE(..., '%h')\n```\n\n----------------------------------------\n\nTITLE: Example Output from tidb-server command\nDESCRIPTION: This shows example output from the `tidb-server -h` command, which lists available options. It highlights the `-store` flag and the possible registered store names (tikv, mocktikv, unistore).\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/tidb-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nUsage of ./bin/tidb-server:\n  -L string\n        log level: info, debug, warn, error, fatal (default \"info\")\n  -P string\n        tidb server port (default \"4000\")\n  -V    print version information and exit (default false)\n.........\n  -store string\n        registered store name, [tikv, mocktikv, unistore] (default \"unistore\")\n  ......\n\n```\n\n----------------------------------------\n\nTITLE: Explaining Query Execution Plan with Minimal tidb_opt_range_max_size in TiDB\nDESCRIPTION: This SQL query explains the execution plan for a SELECT statement after setting tidb_opt_range_max_size to 100 bytes. It demonstrates how the optimizer chooses IndexFullScan due to severe memory limitations.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_74\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t USE INDEX (idx) WHERE a IN (10,20,30) AND b IN (40,50,60);\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP DM Prune Command in Shell\nDESCRIPTION: This command is used to manually clean up metadata in etcd after scaling in a DM cluster. It takes the cluster name as an argument and supports optional flags. The '-h' or '--help' flag can be used to print help information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-prune.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm prune <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Basic DATETIME Type Declaration\nDESCRIPTION: Syntax for declaring DATETIME type with optional fractional seconds precision parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nDATETIME[(fsp)]\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Employees Table in SQL\nDESCRIPTION: SQL statement to create a basic employees table with id, hired date, and store_id fields, which will be used to demonstrate List partitioning in subsequent examples.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    store_id INT\n);\n```\n\n----------------------------------------\n\nTITLE: Array Items Count Validation\nDESCRIPTION: SQL queries checking the minimum number of items in arrays\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-validate.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SCHEMA_VALID('{\"properties\": {\"fruits\": {\"type\": \"array\", \"minItems\": 3}}}',@j)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SCHEMA_VALID('{\"properties\": {\"fruits\": {\"type\": \"array\", \"minItems\": 4}}}',@j)\n```\n\n----------------------------------------\n\nTITLE: Configuring PD Client Request Forwarding\nDESCRIPTION: This snippet discusses the parameter that controls whether the PD client in TiKV forwards requests through followers in case of network isolation, highlighting potential performance implications.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n+ Controls whether the PD client in TiKV forwards requests to the leader via the followers in the case of possible network isolation.\n+ Default value: `false`\n+ If the environment might have isolated network, enabling this parameter can reduce the window of service unavailability.\n```\n\n----------------------------------------\n\nTITLE: RocksDB SST Format Version Configuration\nDESCRIPTION: Configuration options for SST file format versioning in TiKV. Supports different versions with varying compatibility and features like checksum types and compression encoding.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_18\n\nLANGUAGE: yaml\nCODE:\n```\nformat-version:\n  - 0: # Default CRC32 checksum\n  - 1: # Supports non-default checksums\n  - 2: # Changed compressed block encoding\n  - 3: # Changed index block key encoding\n  - 4: # Changed index block value encoding\n  - 5: # Improved Bloom filter implementation\n```\n\n----------------------------------------\n\nTITLE: Optimizing Max/Min Query Performance in TiDB Planner\nDESCRIPTION: Optimizes the performance of statements like 'select max(a), min(a) from t' by transforming them to use ORDER BY and LIMIT when an index exists on the column, avoiding full table scans.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.9.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nselect max(a), min(a) from t\n```\n\nLANGUAGE: SQL\nCODE:\n```\nselect * from (select a from t order by a desc limit 1) as t1, (select a from t order by a limit 1) as t2\n```\n\n----------------------------------------\n\nTITLE: Creating VPC Endpoint via AWS CLI\nDESCRIPTION: AWS CLI command to create a VPC interface endpoint for connecting to TiDB Cloud Serverless. Requires VPC ID, region ID, service name, and subnet ID as parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-private-endpoint-connections-serverless.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\naws ec2 create-vpc-endpoint --vpc-id ${your_vpc_id} --region ${region_id} --service-name ${service_name} --vpc-endpoint-type Interface --subnet-ids ${your_subnet_id}\n```\n\n----------------------------------------\n\nTITLE: Merging Mirrors with TiUP\nDESCRIPTION: This command merges one or more specified mirrors into the current mirror. It requires that all component owner IDs are present in the current mirror and that the corresponding private keys are available in the user's keys directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-merge.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror merge <mirror-dir-1> [mirror-dir-N] [flags]\n```\n\n----------------------------------------\n\nTITLE: Using SET_VAR Hint for Pipelined DML in SQL Statements\nDESCRIPTION: Illustrates how to enable Pipelined DML for specific SQL statements using the SET_VAR hint. This method applies to data archiving, updates, and deletions when dealing with large datasets.\nSOURCE: https://github.com/pingcap/docs/blob/master/pipelined-dml.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT /*+ SET_VAR(tidb_dml_type='bulk') */ INTO target_table SELECT * FROM source_table;\n```\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE /*+ SET_VAR(tidb_dml_type='bulk') */ products\nSET price = price * 1.1\nWHERE category = 'electronics';\n```\n\nLANGUAGE: sql\nCODE:\n```\nDELETE /*+ SET_VAR(tidb_dml_type='bulk') */ FROM logs WHERE log_time < '2023-01-01';\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Connection Environment Variables\nDESCRIPTION: Sample environment variable configuration for connecting to a TiDB Cloud Serverless cluster, including host, port, credentials, and SSL settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_4\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_HOST=gateway01.****.prod.aws.tidbcloud.com\nTIDB_PORT=4000\nTIDB_USERNAME=********.root\nTIDB_PASSWORD=********\nTIDB_DATABASE=test\nTIDB_CA_PATH=/etc/ssl/cert.pem\n```\n\n----------------------------------------\n\nTITLE: Sysbench Data Preparation for Performance Testing\nDESCRIPTION: Bash command for preparing test data with sysbench, loading 1000 tables with 10,000 rows each for performance benchmarking of the optimized configuration against baseline settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsysbench oltp_read_only prepare --mysql-host={host} --mysql-port={port} --mysql-user=root --db-driver=mysql --mysql-db=test --threads=100 --time=900 --report-interval=10 --tables=1000 --table-size=10000\n```\n\n----------------------------------------\n\nTITLE: Retrieving Last Value with LAST_VALUE() in SQL\nDESCRIPTION: This snippet shows the usage of LAST_VALUE() window function with partitioning. It demonstrates how the function returns the last value in each partition defined by the condition n<=5.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/window-functions.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nWITH RECURSIVE cte(n) AS (\n    SELECT\n        1\n    UNION\n    SELECT\n        n+1\n    FROM\n        cte\n    WHERE\n        n<10\n)\nSELECT\n    n,\n    LAST_VALUE(n) OVER (PARTITION BY n<=5)\nFROM\n    cte\nORDER BY\n    n;\n```\n\n----------------------------------------\n\nTITLE: Inserting Sample Data for Deadlock Example\nDESCRIPTION: SQL statement to insert two rows into the 'books' table for demonstration purposes in the deadlock example. This creates the initial data state before the deadlock scenario is demonstrated.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-troubleshoot.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO books (id, title, stock, published_at) VALUES (1, 'book-1', 10, now()), (2, 'book-2', 10, now());\n```\n\n----------------------------------------\n\nTITLE: Redeclaring Global Environment Variable\nDESCRIPTION: This snippet displays a shell command to refresh the session environment by re-declaring environment variables stored in the '.bash_profile' file. It is commonly required after modifying environment variables to ensure that current shell sessions are aware of the changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/migration-tools.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsource ~/.bash_profile\n```\n\n----------------------------------------\n\nTITLE: Inserting Player Data with Prisma in JavaScript\nDESCRIPTION: This snippet demonstrates how to create a single Player record using Prisma's create method. It returns the created Player object, including the auto-generated id field from TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\nconst player: Player = await prisma.player.create({\n   data: {\n      name: 'Alice',\n      coins: 100,\n      goods: 200,\n      createdAt: new Date(),\n   }\n});\n```\n\n----------------------------------------\n\nTITLE: Restoring Default PD Configuration after Replication\nDESCRIPTION: Commands for reverting the replication speed limits back to default settings after completing TiFlash replication. It's essential to reset these values to avoid adversely affecting online services.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd -u http://<PD_ADDRESS>:2379 store limit all engine tiflash 30 add-peer\n```\n\n----------------------------------------\n\nTITLE: Using tiup cluster rename Command in Shell\nDESCRIPTION: Command syntax for renaming a TiDB cluster from old-cluster-name to new-cluster-name with optional flags. This command changes the cluster name after deployment, but requires additional steps if Grafana dashboards are configured.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-rename.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster rename <old-cluster-name> <new-cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Prepare TPC-H Data with TiUP Bench (Bash)\nDESCRIPTION: This command prepares data for a TPC-H benchmark with a scale factor of 1. It utilizes the `prepare` subcommand of the TiUP bench tpch component and requires the `tiup` command-line tool and a TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench tpch --sf=1 prepare\n```\n\n----------------------------------------\n\nTITLE: Creating Global and Cross-database SQL Bindings in TiDB\nDESCRIPTION: Demonstrates how to create both standard global bindings and cross-database bindings using wildcards in TiDB. This feature requires enabling the tidb_opt_enable_fuzzy_binding system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_22\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE GLOBAL BINDING USING SELECT /*+ use_index(t, idx_a) */ * FROM t; -- Create a GLOBAL scope standard binding.\nCREATE GLOBAL BINDING USING SELECT /*+ use_index(t, idx_a) */ * FROM *.t; -- Create a GLOBAL scope cross-database binding.\nSHOW GLOBAL BINDINGS;\n```\n\n----------------------------------------\n\nTITLE: Example Amazon S3 URI for TiCDC sink-uri\nDESCRIPTION: Demonstrates how to create a TiCDC changefeed with an S3 sink URI, including endpoint and credentials parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/external-storage-uri.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc:v7.5.0 cli changefeed create \\\n    --server=http://172.16.201.18:8300 \\\n    --sink-uri=\"s3://cdc?endpoint=http://10.240.0.38:9000&access-key=${access-key}&secret-access-key=${secret-access-key}\" \\\n    --changefeed-id=\"cdcTest\" \\\n    --config=cdc_csv.toml\n```\n\n----------------------------------------\n\nTITLE: Raft Election Timeout and Heartbeat Calculation in TiKV\nDESCRIPTION: Configuration relationships showing how raft-base-tick-interval affects election timeout and heartbeat intervals through multiplication with their respective tick settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/massive-regions-best-practices.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nraft-election-timeout = raft-base-tick-interval * raft-election-timeout-ticks\nraft-heartbeat-interval = raft-base-tick-interval * raft-heartbeat-ticks\n```\n\n----------------------------------------\n\nTITLE: Dropping Column from Table\nDESCRIPTION: This SQL statement drops the `Name` column from the merged `tbl` table in the downstream TiDB. This action occurs after the column has been dropped from all upstream sharded tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-shard-merge-optimistic.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER TABLE `tbl` DROP COLUMN `Name`;\n```\n```\n\n----------------------------------------\n\nTITLE: Displaying GCS File URI Format for Parquet Import\nDESCRIPTION: Shows the expected format for Google Cloud Storage URIs when importing Parquet files, with examples for both single files and folders.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-parquet-files.md#2025-04-18_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\ngs://[bucket_name]/[data_source_folder]/[file_name].parquet\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud Serverless Cluster with User, Password, and Cluster ID\nDESCRIPTION: This snippet demonstrates connecting to a TiDB Cloud Serverless cluster using a specific user, password, and cluster ID in non-interactive mode. The `-c` flag specifies the cluster ID, `-u` specifies the username, and `--password` specifies the password.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-shell.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nticloud connect -c <cluster-id> -u <user-name> --password <password>\n```\n\n----------------------------------------\n\nTITLE: TiUP Telemetry Command Syntax\nDESCRIPTION: This code snippet shows the general syntax for using the `tiup telemetry` command. The `<command>` placeholder represents sub-commands like `status`, `reset`, `enable`, and `disable`. This syntax is used to manage TiUP telemetry settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-telemetry.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n```shell\ntiup telemetry <command>\n```\n```\n\n----------------------------------------\n\nTITLE: Measuring JSON Storage Size\nDESCRIPTION: Demonstrates the use of JSON_STORAGE_SIZE function to calculate approximate storage size in bytes for a JSON value. Note that the size doesn't account for TiKV compression.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-utility.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_STORAGE_SIZE('{}');\n```\n\n----------------------------------------\n\nTITLE: Filtering Regions by Replica Count in TiKV\nDESCRIPTION: This command filters Regions based on the number of replicas, allowing users to identify Regions that do not meet specified criteria.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_66\n\nLANGUAGE: bash\nCODE:\n```\nregion --jq=\".regions[] | {id: .id, peer_stores: [.peers[].store_id] | select(length != 3)}\"\n```\n\n----------------------------------------\n\nTITLE: Output of SHOW PLACEMENT and PLACEMENT_POLICIES Comparison\nDESCRIPTION: Shows the output of the comparison between SHOW PLACEMENT and PLACEMENT_POLICIES queries, highlighting that SHOW PLACEMENT shows all placement information including tables, while PLACEMENT_POLICIES only lists the policy definitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-placement-policies.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.09 sec)\n\nQuery OK, 0 rows affected (0.11 sec)\n\nQuery OK, 0 rows affected (0.08 sec)\n\n+---------------+------------------------------------------------+------------------+\n| Target        | Placement                                      | Scheduling_State |\n+---------------+------------------------------------------------+------------------+\n| POLICY p1     | PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1\" | NULL             |\n| TABLE test.t3 | PRIMARY_REGION=\"us-east-1\" REGIONS=\"us-east-1\" | PENDING          |\n+---------------+------------------------------------------------+------------------+\n2 rows in set (0.00 sec)\n\n+-----------+--------------+-------------+----------------+-----------+-------------+--------------------+----------------------+---------------------+----------+-----------+----------+\n| POLICY_ID | CATALOG_NAME | POLICY_NAME | PRIMARY_REGION | REGIONS   | CONSTRAINTS | LEADER_CONSTRAINTS | FOLLOWER_CONSTRAINTS | LEARNER_CONSTRAINTS | SCHEDULE | FOLLOWERS | LEARNERS |\n+-----------+--------------+-------------+----------------+-----------+-------------+--------------------+----------------------+---------------------+----------+-----------+----------+\n| 1         | def          | p1          | us-east-1      | us-east-1 |             |                    |                      |                     |          | 2         | 0        |\n+-----------+--------------+-------------+----------------+-----------+-------------+--------------------+----------------------+---------------------+----------+-----------+----------+\n1 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Table Schema Definitions for Error Reporting in TiDB Lightning\nDESCRIPTION: SQL definitions for the tables and view that TiDB Lightning creates to store error information, including type_error_v1, conflict_error_v3, conflict_records tables, and the conflict_view view.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE type_error_v1 (\n    task_id     bigint NOT NULL,\n    create_time datetime(6) NOT NULL DEFAULT now(6),\n    table_name  varchar(261) NOT NULL,\n    path        varchar(2048) NOT NULL,\n    offset      bigint NOT NULL,\n    error       text NOT NULL,\n    row_data    text NOT NULL\n);\nCREATE TABLE conflict_error_v3 (\n    task_id     bigint NOT NULL,\n    create_time datetime(6) NOT NULL DEFAULT now(6),\n    table_name  varchar(261) NOT NULL,\n    index_name  varchar(128) NOT NULL,\n    key_data    text NOT NULL,\n    row_data    text NOT NULL,\n    raw_key     mediumblob NOT NULL,\n    raw_value   mediumblob NOT NULL,\n    raw_handle  mediumblob NOT NULL,\n    raw_row     mediumblob NOT NULL,\n    kv_type     tinyint NOT NULL,\n    INDEX (task_id, table_name),\n    INDEX (index_name),\n    INDEX (table_name, index_name),\n    INDEX (kv_type)\n);\nCREATE TABLE conflict_records (\n    task_id     bigint NOT NULL,\n    create_time datetime(6) NOT NULL DEFAULT now(6),\n    table_name  varchar(261) NOT NULL,\n    path        varchar(2048) NOT NULL,\n    offset      bigint NOT NULL,\n    error       text NOT NULL,\n    row_id      bigint NOT NULL COMMENT 'the row id of the conflicted row',\n    row_data    text NOT NULL COMMENT 'the row data of the conflicted row',\n    KEY (task_id, table_name)\n);\nCREATE VIEW conflict_view AS\n    SELECT 0 AS is_precheck_conflict, task_id, create_time, table_name, index_name, key_data, row_data, raw_key, raw_value, raw_handle, raw_row, kv_type, NULL AS path, NULL AS offset, NULL AS error, NULL AS row_id\n    FROM conflict_error_v3\n    UNION ALL\n    SELECT 1 AS is_precheck_conflict, task_id, create_time, table_name, NULL AS index_name, NULL AS key_data, row_data, NULL AS raw_key, NULL AS raw_value, NULL AS raw_handle, NULL AS raw_row, NULL AS kv_type, path, offset, error, row_id\n    FROM conflict_records;\n```\n\n----------------------------------------\n\nTITLE: Checking NIC TX Errors\nDESCRIPTION: Command to check for transmission errors on a network interface, which might indicate an insufficient TX queue length.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nip -s link\n```\n\n----------------------------------------\n\nTITLE: Resetting Table Attributes in SQL\nDESCRIPTION: Demonstrates how to reset attributes for a table or partition to default values using SQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/table-attributes.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t [PARTITION p] ATTRIBUTES [=] DEFAULT;\n```\n\n----------------------------------------\n\nTITLE: Inserting NULL into a Column Without NOT NULL Constraint\nDESCRIPTION: This example shows that NULL values are allowed by default in columns that are not explicitly defined with a NOT NULL constraint.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO users (id,age,last_login) VALUES (NULL,123,NULL);\n```\n\n----------------------------------------\n\nTITLE: Backing Up User and Privilege Information in TiDB\nDESCRIPTION: This shell script exports user and privilege information from a TiDB cluster. It connects to the database, retrieves user details, and generates SQL statements to recreate users and their privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\n#!/bin/bash\n\nexport MYSQL_HOST={tidb_op_host}\nexport MYSQL_TCP_PORT={tidb_op_port}\nexport MYSQL_USER=root\nexport MYSQL_PWD={root_password}\nexport MYSQL=\"mysql -u${MYSQL_USER} --default-character-set=utf8mb4\"\n\nfunction backup_user_priv(){\n    ret=0\n    sql=\"SELECT CONCAT(user,':',host,':',authentication_string) FROM mysql.user WHERE user NOT IN ('root')\"\n    for usr in `$MYSQL -se \"$sql\"`;do\n        u=`echo $usr | awk -F \":\" '{print $1}'`\n        h=`echo $usr | awk -F \":\" '{print $2}'`\n        p=`echo $usr | awk -F \":\" '{print $3}'`\n        echo \"-- Grants for '${u}'@'${h}';\"\n        [[ ! -z \"${p}\" ]] && echo \"CREATE USER IF NOT EXISTS '${u}'@'${h}' IDENTIFIED WITH 'mysql_native_password' AS '${p}' ;\"\n        $MYSQL -se \"SHOW GRANTS FOR '${u}'@'${h}';\" | sed 's/$/;/g'\n        [ $? -ne 0 ] && ret=1 && break\n    done\n    return $ret\n}\n\nbackup_user_priv\n```\n\n----------------------------------------\n\nTITLE: Deleting Store Label in TiKV\nDESCRIPTION: This command deletes a specific label of a store by specifying the store ID and the label key to be removed, using the --delete option.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_55\n\nLANGUAGE: bash\nCODE:\n```\nstore label 1 disk --delete\n```\n\n----------------------------------------\n\nTITLE: Query Example Without Extended Statistics\nDESCRIPTION: Sample query where the optimizer must choose between indexes without knowledge of column correlation, which can lead to suboptimal execution plans.\nSOURCE: https://github.com/pingcap/docs/blob/master/extended-statistics.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t WHERE col1 > 1 ORDER BY col2 LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Querying Hot Region Status with pd-ctl in TiDB\nDESCRIPTION: This snippet shows various pd-ctl commands for querying hot region status in TiDB, including hot read/write regions and top read/write traffic regions.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/pd-scheduling-best-practices.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- `hot read`: Queries hot read regions\n- `hot write`: Queries hot write regions\n- `hot store`: Queries the distribution of hot regions by store\n- `region topread [limit]`: Queries the region with top read traffic\n- `region topwrite [limit]`: Queries the region with top write traffic\n```\n\n----------------------------------------\n\nTITLE: Creating JSON Objects with JSON_OBJECT()\nDESCRIPTION: Constructs JSON objects from key-value pairs, allowing dynamic object creation with various data types. Supports multiple key-value entries and different value types including strings and booleans.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-create.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_OBJECT(\"database\", \"TiDB\", \"distributed\", TRUE);\n```\n\n----------------------------------------\n\nTITLE: Removing a TiDB Vector Store\nDESCRIPTION: This code shows how to remove an existing TiDB vector store using the drop_vectorstore() method, which deletes the vector store from the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nvector_store.drop_vectorstore()\n```\n\n----------------------------------------\n\nTITLE: Configuring Firewall Rules for TiKV Server\nDESCRIPTION: Commands to set up firewall rules for the TiKV component, opening ports 20160/tcp and 20180/tcp.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nfirewall-cmd --permanent --new-service tikv\nfirewall-cmd --permanent --service tikv --set-description=\"TiKV Server\"\nfirewall-cmd --permanent --service tikv --set-short=\"TiKV\"\nfirewall-cmd --permanent --service tikv --add-port=20160/tcp\nfirewall-cmd --permanent --service tikv --add-port=20180/tcp\nfirewall-cmd --permanent --zone=public --add-service=tikv\n```\n\n----------------------------------------\n\nTITLE: Instance Relay Log Metrics Table in Markdown\nDESCRIPTION: Detailed table of instance-specific relay log metrics including storage, error conditions, and performance measurements with associated alert thresholds and severity levels.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/monitor-a-dm-cluster.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Metric name | Description | Alert | Severity level |\n|:----|:------------|:----|:----|\n| storage capacity | The total storage capacity of the disk occupied by the relay log | N/A | N/A |\n| storage remain | The remaining storage capacity within the disk occupied by the relay log | An alert occurs once the value is smaller than 10G | critical |\n```\n\n----------------------------------------\n\nTITLE: Encrypting Log Backup with Local Master Key in Shell\nDESCRIPTION: Example of starting a log backup task with encryption using a master key stored on a local disk for enhanced security.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log start \\\n    --task-name=pitr-with-encryption \\\n    --pd ${PD_IP}:2379 \\\n    --storage \"s3://${BACKUP_COLLECTION_ADDR}/snapshot-${DATE}?access-key=${AWS_ACCESS_KEY}&secret-access-key=${AWS_SECRET_ACCESS_KEY}\" \\\n    --master-key-crypter-method aes128-ctr \\\n    --master-key \"local:///path/to/master.key\"\n```\n\n----------------------------------------\n\nTITLE: Comparing EXPLAIN Results with View vs Direct Table Query in TiDB\nDESCRIPTION: This snippet shows the output of the EXPLAIN statements, demonstrating that TiDB uses the same execution plan (IndexLookUp with IndexRangeScan) whether querying through the view or directly from the table with the same condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-views.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (2 min 10.11 sec)\n\nQuery OK, 0 rows affected (0.13 sec)\n\n+--------------------------------+------------+-----------+---------------------------------------+-------------------------------------+\n| id                             | estRows    | task      | access object                         | operator info                       |\n+--------------------------------+------------+-----------+---------------------------------------+-------------------------------------+\n| IndexLookUp_12                 | 6372547.67 | root      |                                       |                                     |\n| ├─IndexRangeScan_10(Build)     | 6372547.67 | cop[tikv] | table:trips, index:duration(duration) | range:(3600,+inf], keep order:false |\n| └─TableRowIDScan_11(Probe)     | 6372547.67 | cop[tikv] | table:trips                           | keep order:false                    |\n+--------------------------------+------------+-----------+---------------------------------------+-------------------------------------+\n3 rows in set (0.00 sec)\n\n+-------------------------------+-----------+-----------+---------------------------------------+-------------------------------------+\n| id                            | estRows   | task      | access object                         | operator info                       |\n+-------------------------------+-----------+-----------+---------------------------------------+-------------------------------------+\n| IndexLookUp_10                | 833219.37 | root      |                                       |                                     |\n| ├─IndexRangeScan_8(Build)     | 833219.37 | cop[tikv] | table:trips, index:duration(duration) | range:(3600,+inf], keep order:false |\n| └─TableRowIDScan_9(Probe)     | 833219.37 | cop[tikv] | table:trips                           | keep order:false                    |\n+-------------------------------+-----------+-----------+---------------------------------------+-------------------------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Updating Player Data with MySQL.js in JavaScript\nDESCRIPTION: This snippet demonstrates how to update a player's coins and goods in the database using MySQL.js. It adds 50 coins and 50 goods to the player with ID 1.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysqljs.md#2025-04-18_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\nconn.query(\n   'UPDATE players SET coins = coins + ?, goods = goods + ? WHERE id = ?;',\n   [50, 50, 1],\n   (err, ok) => {\n      if (err) {\n         console.error(err);\n      } else {\n          console.log(ok.affectedRows);\n      }\n   }\n);\n```\n\n----------------------------------------\n\nTITLE: Monthly Analysis Query\nDESCRIPTION: Query to analyze monthly data using the materialized daily analysis results.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-results-materialization.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT MONTH(rec_date), customer_id, sum(daily_fee) FROM daily_data GROUP BY MONTH(rec_date), customer_id;\n```\n\n----------------------------------------\n\nTITLE: Markdown Bug Fixes Documentation\nDESCRIPTION: Comprehensive listing of bug fixes implemented across different components of the TiDB ecosystem including core database, storage, placement driver, computation engine and tools.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.3.0.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## Bug fixes\n\n+ TiDB\n\n    - Fix the issue that when the MySQL Cursor Fetch protocol is used...\n    [Additional content trimmed for brevity]\n\n## Contributors\n\nWe would like to thank the following contributors from the TiDB community:\n\n[List of contributors...]\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Connection in .env File\nDESCRIPTION: Example of the .env file content for configuring TiDB connection parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nTIDB_HOST='{host}'  # e.g. gateway01.ap-northeast-1.prod.aws.tidbcloud.com\nTIDB_PORT='4000'\nTIDB_USER='{user}'  # e.g. xxxxxx.root\nTIDB_PASSWORD='{password}'\nTIDB_DB_NAME='test'\nCA_PATH='{ssl_ca}'  # e.g. /etc/ssl/certs/ca-certificates.crt (Debian / Ubuntu / Arch)\n```\n\n----------------------------------------\n\nTITLE: Creating a Key Partitioned Table with Empty Column List in SQL\nDESCRIPTION: This SQL snippet shows how to create a Key partitioned table with an empty partition column list, using the primary key as the partitioning key.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_31\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL PRIMARY KEY,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT\n)\n\nPARTITION BY KEY()\nPARTITIONS 4;\n```\n\n----------------------------------------\n\nTITLE: Demonstrating LEAD() Window Function in SQL\nDESCRIPTION: This snippet shows how to use the LEAD() function to retrieve values from subsequent rows. It uses a recursive CTE to generate a sequence of numbers and applies LEAD() to fetch the next value in the sequence.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/window-functions.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nWITH RECURSIVE cte(n) AS (\n    SELECT\n        1\n    UNION\n    SELECT\n        n+1\n    FROM\n        cte\n    WHERE\n        n<10\n)\nSELECT\n    n,\n    LEAD(n) OVER ()\nFROM\n    cte;\n```\n\n----------------------------------------\n\nTITLE: Enable TiFlash Replication in TiDB\nDESCRIPTION: This SQL statement enables data replication for a specific table to TiFlash. The replica count should not exceed the number of TiFlash nodes in the cluster. Setting the replica count to 0 removes the replica from TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-htap-cluster.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name SET TIFLASH REPLICA 1;\n```\n\n----------------------------------------\n\nTITLE: Granting Required TiDB Cloud Downstream Privileges\nDESCRIPTION: SQL command to grant necessary privileges to the downstream TiDB Cloud cluster user, including CREATE, SELECT, INSERT, UPDATE, DELETE, ALTER, DROP, and INDEX privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-mysql-using-data-migration.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nGRANT CREATE,SELECT,INSERT,UPDATE,DELETE,ALTER,DROP,INDEX ON *.* TO 'your_user'@'your_IP_address_of_host'\n```\n\n----------------------------------------\n\nTITLE: Deploying TiDB Cluster with TiCDC Using TiUP Playground\nDESCRIPTION: Commands to quickly deploy a TiDB cluster with TiCDC component included for testing purposes using TiUP Playground, and to check the cluster status.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground --host 0.0.0.0 --db 1 --pd 1 --kv 1 --tiflash 0 --ticdc 1\n# View cluster status\ntiup status\n```\n\n----------------------------------------\n\nTITLE: tiup mirror publish Syntax\nDESCRIPTION: This snippet shows the syntax for the `tiup mirror publish` command. It includes placeholders for the component name, version, tarball path, and entry point, as well as optional flags for customization.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-publish.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup mirror publish <comp-name> <version> <tarball> <entry> [flags]\"\n```\n\n----------------------------------------\n\nTITLE: Altering First Partition in INTERVAL Partitioned Table in SQL\nDESCRIPTION: SQL syntax for changing the first partition in an INTERVAL partitioned table. This statement drops all partitions with values less than the given expression and makes the matched partition the new first partition.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE table_name FIRST PARTITION LESS THAN (<expression>)\n```\n\n----------------------------------------\n\nTITLE: Setting Broadcast Join Threshold Count in TiDB\nDESCRIPTION: Sets the threshold row count for using Broadcast Hash Join algorithm for subqueries. If the estimated number of rows is fewer than this value, Broadcast Hash Join is used instead of Shuffled Hash Join.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_broadcast_join_threshold_count = 100000;\n```\n\n----------------------------------------\n\nTITLE: Inserting Complete Records in TiDB with SQL\nDESCRIPTION: This SQL statement inserts a complete record into the 'person' table with values for all columns. It demonstrates how to add a new record with an ID of 1, name 'tom', and a birthday date of '20170912'.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-tidb-crud-sql.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO person VALUES(1,'tom','20170912');\n```\n\n----------------------------------------\n\nTITLE: Granting Required Upstream Database Privileges in MySQL\nDESCRIPTION: SQL command to grant necessary privileges to the upstream database user for data migration, including SELECT, LOCK TABLES, REPLICATION SLAVE, and REPLICATION CLIENT privileges.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-mysql-using-data-migration.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nGRANT SELECT,LOCK TABLES,REPLICATION SLAVE,REPLICATION CLIENT ON *.* TO 'your_user'@'your_IP_address_of_host'\n```\n\n----------------------------------------\n\nTITLE: Querying Com_ Status Variables in TiDB SQL\nDESCRIPTION: TiDB does not maintain Com_* counters like MySQL does. This statement shows the difference in behavior between TiDB and MySQL for these status variables.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-third-party-tools-compatibility.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW GLOBAL STATUS LIKE 'Com_%'\n```\n\n----------------------------------------\n\nTITLE: Sample TiDB Lightning Error Log\nDESCRIPTION: Example of an error log message from TiDB Lightning indicating data type errors. The log shows the time, severity level, source file, and a message pointing to the error table.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-error-resolution.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n[2022/03/13 05:33:57.736 +08:00] [WARN] [errormanager.go:459] [\"Detect 1000 data type errors in total, please refer to table `lightning_task_info`.`type_error_v1` for more details\"]\n```\n\n----------------------------------------\n\nTITLE: Encrypting MySQL Password with dmctl in TiDB Data Migration\nDESCRIPTION: This snippet demonstrates how to use the dmctl encrypt command to encrypt a MySQL password for use in DM configuration files. The encrypted password is different for each encryption of the same original password.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-manage-source.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./dmctl encrypt 'abc!@#123'\n```\n\n----------------------------------------\n\nTITLE: Example of Insert with AUTO_INCREMENT Column in TiDB\nDESCRIPTION: Example of an INSERT statement that caused incorrect LAST INSERT ID values when explicitly setting a value for the AUTO_INCREMENT column in the first row and using NULL for subsequent rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.4.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\ninsert into t (pk, c) values (1, 2), (NULL, 3)\n```\n\n----------------------------------------\n\nTITLE: Configuring Causal Timestamp Settings in TiKV\nDESCRIPTION: These YAML configuration options control the behavior of causal timestamps in TiKV, including pre-allocation buffer size, renewal intervals, and batch sizes for timestamp requests.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_33\n\nLANGUAGE: yaml\nCODE:\n```\ncausal-ts:\n  alloc-ahead-buffer: \"3s\"\n  renew-interval: \"100ms\"\n  renew-batch-min-size: 100\n  renew-batch-max-size: 8192\n```\n\n----------------------------------------\n\nTITLE: TiKV ReadPool Thread Count Configuration Parameter (Modified)\nDESCRIPTION: TiKV parameter that controls the maximum thread count for unified read pool. The adjustable range has been changed to be between the minimum thread count and the maximum of 4 or CPU count.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\nreadpool.unified.max-thread-count\n```\n\n----------------------------------------\n\nTITLE: DM Duplicate Handling Configuration Parameter (New)\nDESCRIPTION: New DM parameter that specifies how to resolve conflicts during the full import phase. Default value is 'replace', which means using new data to replace existing data.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_19\n\nLANGUAGE: toml\nCODE:\n```\nloaders.<name>.on-duplicate\n```\n\n----------------------------------------\n\nTITLE: File Location Pattern Examples for Amazon S3\nDESCRIPTION: Examples of valid file location patterns for importing data from Amazon S3, demonstrating single file imports and wildcard usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-import-into.md#2025-04-18_snippet_1\n\nLANGUAGE: text\nCODE:\n```\ns3://<bucket-name>/path/to/data/foo.csv\ns3://<bucket-name>/path/to/data/*\ns3://<bucket-name>/path/to/data/*.csv\ns3://<bucket-name>/path/to/data/foo*\ns3://<bucket-name>/path/to/data/foo*.csv\ns3://<bucket-name>/path/to/data/[12].csv\n```\n\n----------------------------------------\n\nTITLE: Merging Offline Packages - Shell\nDESCRIPTION: This command merges the offline toolkit package with the server package in order to prepare the TiUP environment for deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntar xf tidb-community-toolkit-${version}-linux-amd64.tar.gz\nls -ld tidb-community-server-${version}-linux-amd64 tidb-community-toolkit-${version}-linux-amd64\ncd tidb-community-server-${version}-linux-amd64/\ncp -rp keys ~/.tiup/\ntiup mirror merge ../tidb-community-toolkit-${version}-linux-amd64\n```\n\n----------------------------------------\n\nTITLE: Adding Index with Batch Size 4096\nDESCRIPTION: Performance test configuration using tidb_ddl_reorg_batch_size=4096 with varying worker counts. Shows fastest index creation but higher impact on concurrent workload performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/online-workloads-and-add-index-operations.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\ntidb_ddl_reorg_batch_size = 4096\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Cache Behavior with Manual Value Insertion\nDESCRIPTION: This example shows what happens when a value near the end of a cache range is manually inserted, causing TiDB to retrieve a new cache range for subsequent AUTO_INCREMENT values.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nmysql> INSERT INTO t (a) VALUES (2029998);\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> INSERT INTO t (a) VALUES (NULL);\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> INSERT INTO t (a) VALUES (NULL);\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> INSERT INTO t (a) VALUES (NULL);\nQuery OK, 1 row affected (0.02 sec)\n\nmysql> INSERT INTO t (a) VALUES (NULL);\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> SELECT * FROM t ORDER BY b;\n+---------+---------------------+\n| a       | b                   |\n+---------+---------------------+\n|       1 | 2020-09-09 20:38:22 |\n|       2 | 2020-09-09 20:38:22 |\n|       3 | 2020-09-09 20:38:22 |\n| 2000001 | 2020-09-09 20:43:43 |\n|       4 | 2020-09-09 20:44:43 |\n| 2030001 | 2020-09-09 20:54:11 |\n| 2029998 | 2020-09-09 21:08:11 |\n| 2029999 | 2020-09-09 21:08:11 |\n| 2030000 | 2020-09-09 21:08:11 |\n| 2060001 | 2020-09-09 21:08:11 |\n| 2060002 | 2020-09-09 21:08:11 |\n+---------+---------------------+\n11 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining Time Type in JSON Schema\nDESCRIPTION: This JSON snippet outlines how time types are defined in TiDB schemas, specifying the column name and type along with the precision for seconds.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_15\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"ColumnName\":\"COL1\",\n    \"ColumnType\":\"{TT}\",\n    \"ColumnScale\":\"{M}\"\n}\n```\n\n----------------------------------------\n\nTITLE: Quoting Strings as JSON Values with JSON_QUOTE()\nDESCRIPTION: Converts a string into a properly quoted JSON string value, handling escape characters and preserving string integrity. Useful for ensuring proper JSON string formatting and escaping special characters.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-create.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_QUOTE('The name is \"O\\'Neil\"');\n```\n\n----------------------------------------\n\nTITLE: Querying TiKV Garbage Collection Safe Point in TiDB\nDESCRIPTION: SQL query to check the current GC safe point in TiDB, which determines how far back you can flashback a database. Any database dropped after this safe point time can be restored.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-database.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM mysql.tidb WHERE variable_name = 'tikv_gc_safe_point';\n```\n\n----------------------------------------\n\nTITLE: Setting Isolation Level Using pd-ctl (Bash)\nDESCRIPTION: This command demonstrates how to change the isolation-level to 'zone' using the pd-ctl tool for an already initialized PD cluster. It allows for online configuration changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/schedule-replicas-by-topology-labels.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config set isolation-level zone\n```\n\n----------------------------------------\n\nTITLE: Fixing Schema Change Reporting in TiDB Transactions\nDESCRIPTION: Addresses a problem where 'schema change' was reported during transaction commit when concurrent DDL operations were performed on a table without proper locking.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_12\n\nLANGUAGE: SQL\nCODE:\n```\nBEGIN;\nALTER TABLE table_name ADD COLUMN new_column INT;\nCOMMIT;\n```\n\n----------------------------------------\n\nTITLE: Alternative TableFullScan for Large Result Sets in TiDB\nDESCRIPTION: Example showing how TiDB's optimizer might choose TableFullScan instead of IndexLookup when a large number of rows match a condition, based on statistics analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-indexes.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t1 WHERE intkey > 100;\n```\n\n----------------------------------------\n\nTITLE: Adding Column to Table\nDESCRIPTION: This SQL statement adds a column named `Level` of type `INT` to the `tbl01` table. It demonstrates incremental addition of columns to sharded tables during data migration.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-shard-merge-optimistic.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER TABLE `tbl01` ADD COLUMN `Level` INT;\n```\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax for ADMIN ALTER DDL JOBS in TiDB\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the ADMIN ALTER DDL JOBS statement in TiDB. It shows the structure of the statement including options for altering job parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-alter-ddl.md#2025-04-18_snippet_2\n\nLANGUAGE: ebnf\nCODE:\n```\nAdminAlterDDLStmt ::=\n    'ADMIN' 'ALTER' 'DDL' 'JOBS' Int64Num AlterJobOptionList\n\nAlterJobOptionList ::=\n    AlterJobOption ( ',' AlterJobOption )*\n\nAlterJobOption ::=\n    identifier \"=\" SignedLiteral\n```\n\n----------------------------------------\n\nTITLE: Markdown Front Matter\nDESCRIPTION: YAML front matter containing title and summary metadata for the release notes document\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.4.1.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: TiDB 5.4.1 Release Notes\nsummary: \"TiDB 5.4.1 Release Notes: This release includes compatibility changes, improvements, and bug fixes for TiDB, TiKV, PD, TiFlash, and various tools. Improvements include support for using the PointGet plan, adding more logs and metrics, and displaying multiple Kubernetes clusters in the Grafana dashboard. Bug fixes address issues such as incorrect handling of date_format, wrong data writing, wrong query results, and various panics and errors. Fixes for TiKV, PD, TiFlash, and tools are also included.\"\n---\n```\n\n----------------------------------------\n\nTITLE: Renaming CSV Files for Import\nDESCRIPTION: This bash script renames all CSV files in the current directory to a standardized format with sequential numbering. The format used is 'bikeshare.trips.XXX.csv' where XXX is a zero-padded sequential number.\nSOURCE: https://github.com/pingcap/docs/blob/master/import-example-data.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ni=1; for csv in *csv; do mv $csv bikeshare.trips.$(printf \"%03d\" $i).csv; i=$((i+1)); done\n```\n\n----------------------------------------\n\nTITLE: Using INL_MERGE_JOIN Optimizer Hint - SQL\nDESCRIPTION: This snippet illustrates the INL_MERGE_JOIN hint, instructing the optimizer to utilize the index nested loop merge join algorithm for the given tables, ensuring optimal resource utilization during query execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ INL_MERGE_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Downloading JWKS Configuration in Bash\nDESCRIPTION: Retrieves an example JWKS (JSON Web Key Set) using wget for TiDB JWT authentication configuration\nSOURCE: https://github.com/pingcap/docs/blob/master/security-compatibility-with-mysql.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nwget https://raw.githubusercontent.com/CbcWestwolf/generate_jwt/master/JWKS.json\n```\n\n----------------------------------------\n\nTITLE: Querying Salesforce Account Data in TiDB\nDESCRIPTION: SQL query to select all records from the sf_account table that contains Salesforce Account object data. The query demonstrates the successful data transfer from Salesforce to TiDB through AWS AppFlow.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-aws-appflow-integration.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM sf_account;\n```\n\n----------------------------------------\n\nTITLE: Generating CA Certificate from CA Key for TiDB Authentication\nDESCRIPTION: Command to create a self-signed X.509 certificate for the Certificate Authority using the previously generated CA key. This certificate will be used to sign server and client certificates.\nSOURCE: https://github.com/pingcap/docs/blob/master/certificate-authentication.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo openssl req -new -x509 -nodes -days 365000 -key ca-key.pem -out ca-cert.pem\n```\n\n----------------------------------------\n\nTITLE: Cloning TiUP Mirror for Offline Use\nDESCRIPTION: This command clones the necessary components for a DM cluster into a local directory for offline use.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup-offline.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror clone tidb-dm-${version}-linux-amd64 --os=linux --arch=amd64 \\\n    --dm-master=${version} --dm-worker=${version} --dmctl=${version} \\\n    --alertmanager=v0.17.0 --grafana=v4.0.3 --prometheus=v4.0.3 \\\n    --dm=v$(tiup --version|grep 'tiup'|awk -F ' ' '{print $1}')\n```\n\n----------------------------------------\n\nTITLE: Dropping Column from Table\nDESCRIPTION: This SQL statement drops a column named `Name` from the `tbl01` table. It shows the process of removing a column as part of optimistic DDL changes with DM.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-shard-merge-optimistic.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nALTER TABLE `tbl01` DROP COLUMN `Name`;\n```\n```\n\n----------------------------------------\n\nTITLE: Creating TiDB Cloud Serverless Cluster in Non-Interactive Mode (Shell)\nDESCRIPTION: This example shows how to create a TiDB Cloud Serverless cluster in non-interactive mode. The command requires specifying the project ID, display name, and region as flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-create.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless create --project-id <project-id> --display-name <display-name> --region <region>\n```\n\n----------------------------------------\n\nTITLE: Configuring BR Snapshot Restore with Coarse-Grained Region Scatter\nDESCRIPTION: Experimental command for improving snapshot restore speed by utilizing a new parallel recovery algorithm with batch Region scattering\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.6.0.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbr restore full \\\n--pd \"${PDIP}:2379\" \\\n--storage \"s3://${Bucket}/${Folder}\" \\\n--s3.region \"${region}\" \\\n--granularity \"coarse-grained\" \\\n--send-credentials-to-tikv=true \\ \n--log-file restorefull.log\n```\n\n----------------------------------------\n\nTITLE: Upgrading TiDB Cluster with TiCDC Using TiUP\nDESCRIPTION: Command sequence for upgrading a TiDB cluster (including TiCDC) using TiUP. Updates TiUP itself, all components, and then upgrades the cluster with an extended transfer timeout.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/deploy-ticdc.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup update --self && \\\ntiup update --all && \\\ntiup cluster upgrade <cluster-name> <version> --transfer-timeout 600\n```\n\n----------------------------------------\n\nTITLE: Time Type Definition with Fractional Seconds\nDESCRIPTION: Shows how fractional seconds precision (fsp) is specified for temporal data types like TIME, DATETIME, and TIMESTAMP. The fsp value must be between 0 and 6.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nTIME(fsp)\nDATETIME(fsp)\nTIMESTAMP(fsp)\n```\n\n----------------------------------------\n\nTITLE: Pruning Tombstone Nodes in TiDB Cluster with TiUP\nDESCRIPTION: This bash command cleans up tombstone nodes (nodes that have been removed but still have metadata) from the TiDB cluster using TiUP. It requires the cluster name as input.\nSOURCE: https://github.com/pingcap/docs/blob/master/online-unsafe-recovery.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster prune <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Empty Response from Filtered Vector Search\nDESCRIPTION: Shows the expected output when filtering out documents with book='paul_graham', resulting in an empty response because all matching documents were excluded by the filter.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_11\n\nLANGUAGE: plain\nCODE:\n```\nEmpty Response\n```\n\n----------------------------------------\n\nTITLE: Downloading Exported ZIP File from TiDB\nDESCRIPTION: This shell command demonstrates how to download the exported ZIP file from the TiDB server using its HTTP interface by specifying the file token in the URL.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-replayer.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncurl http://127.0.0.1:10080/plan_replayer/dump/replayer_JOGvpu4t7dssySqJfTtS4A==_1635750890568691080.zip > plan_replayer.zip\n```\n\n----------------------------------------\n\nTITLE: Querying Replication Subtask List - TiCDC - Shell\nDESCRIPTION: This example demonstrates how to query the list of replication subtasks (processors) using a GET request to the `/api/v1/processors` endpoint.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v1/processors\n```\n\n----------------------------------------\n\nTITLE: SET NAMES/CHARACTER SET Syntax Definition in EBNF\nDESCRIPTION: EBNF syntax diagram showing the structure of SET NAMES and SET CHARACTER SET statements, including options for DEFAULT, CharsetName, and COLLATE clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-names.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nSetNamesStmt ::=\n    \"SET\" (\"NAMES\" (\"DEFAULT\" | CharsetName (\"COLLATE\" (\"DEFAULT\" | CollationName))?) | (\"CHARSET\" | (\"CHAR\" | \"CHARACTER\") \"SET\") (\"DEFAULT\" | CharsetName))\n```\n\n----------------------------------------\n\nTITLE: Setting SQL Isolation Level Check Bypass in TiDB\nDESCRIPTION: SQL command to bypass isolation level checks in TiDB by setting the tidb_skip_isolation_level_check system variable to 1. This is useful when using third-party tools or frameworks that set unsupported isolation levels.\nSOURCE: https://github.com/pingcap/docs/blob/master/error-codes.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_skip_isolation_level_check = 1;\n```\n\n----------------------------------------\n\nTITLE: Filtering aggregated results using HAVING with GROUP BY in SQL\nDESCRIPTION: This SQL snippet shows how to filter the results of an aggregation using the HAVING clause to exclude NULL values in the context of a GROUP BY query that includes WITH ROLLUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/group-by-modifier.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT year, month, SUM(profit) AS profit FROM bank GROUP BY year, month WITH ROLLUP HAVING year IS NOT null AND month IS NOT null;\n```\n\n----------------------------------------\n\nTITLE: PD Control Tool Output for TSO Parsing\nDESCRIPTION: This snippet shows the output from the PD control tool when parsing a TSO timestamp, displaying the system time (physical timestamp) and the logical component separately.\nSOURCE: https://github.com/pingcap/docs/blob/master/tso.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nsystem:  2023-08-27 20:33:41.687 +0200 CEST\nlogic:   4\n```\n\n----------------------------------------\n\nTITLE: TiSpark Server Configuration Overview\nDESCRIPTION: JSON-like representation of server configurations for TiSpark deployment, showing instance types, hardware specifications, and network configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-deployment-topology.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Instance | Count | Physical machine configuration | IP | Configuration |\n| :-- | :-- | :-- | :-- | :-- |\n| TiSpark | 3 | 8 VCore 16GB * 1 | 10.0.1.21 (master) <br/> 10.0.1.22 (worker) <br/> 10.0.1.23 (worker) | Default port <br/> Global directory configuration |\n```\n\n----------------------------------------\n\nTITLE: Show Create Table MySQL\nDESCRIPTION: This SQL command retrieves the create table statement for the given shard_table in the shard_db schema, providing insights into its structure and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE shard_db.shard_table;\n```\n\n----------------------------------------\n\nTITLE: Querying Evicted Statements Summary Data in TiDB\nDESCRIPTION: SQL query to check the statements_summary_evicted table which contains information about SQL statements that were evicted from the statement summary tables due to capacity limits, showing time periods and counts.\nSOURCE: https://github.com/pingcap/docs/blob/master/statement-summary-tables.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nselect * from information_schema.statements_summary_evicted;\n```\n\n----------------------------------------\n\nTITLE: Binlog Replace Command for First Shard Table 2\nDESCRIPTION: Command to replace the problematic DDL with two equivalent statements for the first MySQL instance's shard_table_2.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nbinlog replace test -s mysql-replica-01 \"ALTER TABLE `shard_db_1`.`shard_table_2` ADD COLUMN `new_col` INT;ALTER TABLE `shard_db_1`.`shard_table_2` ADD UNIQUE(`new_col`)\"\n```\n\n----------------------------------------\n\nTITLE: DROP TABLE EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the DROP TABLE statement, including optional temporary table modifiers and table name specifications.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-table.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nDropTableStmt ::=\n    'DROP' OptTemporary TableOrTables IfExists TableNameList RestrictOrCascadeOpt\n\nOptTemporary ::=\n    ( 'TEMPORARY' | ('GLOBAL' 'TEMPORARY') )?\n\nTableOrTables ::=\n    'TABLE'\n|   'TABLES'\n\nTableNameList ::=\n    TableName ( ',' TableName )*\n```\n\n----------------------------------------\n\nTITLE: Creating Tables with Comment Syntax for Clustered Indexes\nDESCRIPTION: Examples showing how to specify clustered indexes using TiDB's comment syntax for backward compatibility.\nSOURCE: https://github.com/pingcap/docs/blob/master/clustered-indexes.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a BIGINT PRIMARY KEY /*T![clustered_index] CLUSTERED */, b VARCHAR(255));\nCREATE TABLE t (a BIGINT PRIMARY KEY /*T![clustered_index] NONCLUSTERED */, b VARCHAR(255));\nCREATE TABLE t (a BIGINT, b VARCHAR(255), PRIMARY KEY(a, b) /*T![clustered_index] CLUSTERED */);\nCREATE TABLE t (a BIGINT, b VARCHAR(255), PRIMARY KEY(a, b) /*T![clustered_index] NONCLUSTERED */);\n```\n\n----------------------------------------\n\nTITLE: Semantic Search for Airport Reviews in Python\nDESCRIPTION: Performs a semantic search for airports with specific amenities using TiDBVectorStore's retriever in Python.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nretriever = vector_store.as_retriever(\n    search_type=\"similarity_score_threshold\",\n    search_kwargs={\"k\": 3, \"score_threshold\": 0.85},\n)\nsemantic_query = \"Could you recommend a US airport with clean lounges and good vegetarian dining options?\"\nreviews = retriever.invoke(semantic_query)\nfor r in reviews:\n    print(\"-\" * 80)\n    print(r.page_content)\n    print(r.metadata)\n    print(\"-\" * 80)\n```\n\n----------------------------------------\n\nTITLE: Getting Schema List for Data Source with cURL in Shell\nDESCRIPTION: This example shows how to retrieve a list of schema names available in a specific data source by making a GET request to the DM API.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/sources/source-1/schemas' \\\n  -H 'accept: application/json'\n```\n\n----------------------------------------\n\nTITLE: Fetching Allocated ID from PD Log in Bash\nDESCRIPTION: Uses a grep command pipeline to extract the largest allocated ID from PD log files. Ensures it reads from the last PD leader logs.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-recover.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngrep \"idAllocator allocates a new id\" {{/path/to}}/pd*.log |  awk -F'=' '{print $2}' | awk -F']' '{print $1}' | sort -r -n | head -n 1\n```\n\n----------------------------------------\n\nTITLE: Using ANY_VALUE Function in TiDB SQL\nDESCRIPTION: Demonstrates using ANY_VALUE() function to handle non-aggregated columns in GROUP BY queries. Shows table creation, data insertion and grouping examples.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE fruits (id INT PRIMARY KEY, name VARCHAR(255));\n\nINSERT INTO fruits VALUES (1,'apple'),(2,'apple'),(3,'pear'),(4,'banana'),(5, 'pineapple');\n\nSELECT ANY_VALUE(id),GROUP_CONCAT(id),name FROM fruits GROUP BY name;\n```\n\n----------------------------------------\n\nTITLE: Using HASH_JOIN_BUILD Hint in SQL Queries\nDESCRIPTION: The HASH_JOIN_BUILD hint tells the optimizer to use specified tables as the build side when using the hash join algorithm. This controls which tables are used to build hash tables during join operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ HASH_JOIN_BUILD(t1) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Defining Date Type in JSON Schema\nDESCRIPTION: This JSON snippet defines the structure for date types in TiDB schemas where the column name and type are specified without additional parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_14\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"ColumnName\":\"COL1\",\n    \"ColumnType\":\"{DT}\"\n}\n```\n\n----------------------------------------\n\nTITLE: Table Split Operations with Clustered Indexes\nDESCRIPTION: Shows various table split operations and their behavior with clustered indexes, including both incorrect and correct usage patterns.\nSOURCE: https://github.com/pingcap/docs/blob/master/clustered-indexes.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (a int, b varchar(255), primary key(a, b) clustered);\nsplit table t between (0) and (1000000) regions 5;\nsplit table t by (0), (50000), (100000);\nsplit table t between (0, 'aaa') and (1000000, 'zzz') regions 5;\nsplit table t by (0, ''), (50000, ''), (100000, '');\n```\n\n----------------------------------------\n\nTITLE: Sample Output of Version Consistency Check in TiDB\nDESCRIPTION: This snippet shows a sample output of the version consistency check, indicating an inconsistency in TiDB versions within the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-result.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n***************************[ 1. row ]***************************\nRULE      | version\nITEM      | git_hash\nTYPE      | tidb\nINSTANCE  |\nVALUE     | inconsistent\nREFERENCE | consistent\nSEVERITY  | critical\nDETAILS   | the cluster has 2 different tidb versions, execute the sql to see more detail: SELECT * FROM information_schema.cluster_info WHERE type='tidb'\n```\n\n----------------------------------------\n\nTITLE: Inserting Initial Data in TiDB SQL\nDESCRIPTION: Inserts three rows with values 1, 2, and 3 into the previously created table 't'. This establishes the initial dataset for the demonstration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-read-staleness.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\ninsert into t values (1), (2), (3);\n```\n\n----------------------------------------\n\nTITLE: tiup cluster audit cleanup Output\nDESCRIPTION: This code snippet shows the standard output message when the `tiup cluster audit cleanup` command completes successfully. This output indicates that the audit logs have been cleaned up as per the configured settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-audit-cleanup.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n\"clean audit log successfully\"\n```\n\n----------------------------------------\n\nTITLE: Example Replication Mode Status Response (JSON)\nDESCRIPTION: Example JSON response from the replication mode status API showing the current mode (dr-auto-sync) and state (sync). Displays label-key configuration currently in use.\nSOURCE: https://github.com/pingcap/docs/blob/master/two-data-centers-in-one-city-deployment.md#2025-04-18_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mode\": \"dr-auto-sync\",\n  \"dr-auto-sync\": {\n    \"label-key\": \"az\",\n    \"state\": \"sync\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: TiUP Installation Success Output\nDESCRIPTION: Example output showing successful TiUP installation with mirror configuration and shell profile updates\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: log\nCODE:\n```\nSuccessfully set mirror to https://tiup-mirrors.pingcap.com\nDetected shell: zsh\nShell profile:  /Users/user/.zshrc\n/Users/user/.zshrc has been modified to add tiup to PATH\nopen a new terminal or source /Users/user/.zshrc to use it\nInstalled path: /Users/user/.tiup/bin/tiup\n===============================================\nHave a try:     tiup playground\n===============================================\n```\n\n----------------------------------------\n\nTITLE: Creating Optimized Index for SQL Query\nDESCRIPTION: This SQL snippet demonstrates the creation of a new index on the 'snapshot_id' column to optimize the query execution. It also includes an ANALYZE TABLE statement to update statistics for the new index.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-tuning-best-practice.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX test_new ON test(snapshot_id);\nANALYZE TABLE test INDEX test_new;\n```\n\n----------------------------------------\n\nTITLE: Starting a Data Import Task in TiDB Cloud CLI\nDESCRIPTION: Command to start a data import task using the TiDB Cloud CLI. This can be used in interactive or non-interactive mode to import data, primarily CSV files, into a TiDB Cloud cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-start.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import start [flags]\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning to Bypass Compatibility Checks\nDESCRIPTION: Modification of Lightning configuration to disable precheck requirements when using physical import mode or importing tables that may not be compatible with log backup or TiCDC\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-compatibility-and-scenarios.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nLightning:\n  check-requirements: false\n```\n\n----------------------------------------\n\nTITLE: Editing TiDB cluster configuration\nDESCRIPTION: This command allows you to edit the TiDB cluster configuration. It opens the cluster configuration file in a text editor, allowing you to modify parameters such as the PD working mode (`pd_mode`).\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-microservices-using-tiup.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster edit-config <cluster-name>\"\n```\n\n----------------------------------------\n\nTITLE: Checking Region Health with pd-ctl in TiDB\nDESCRIPTION: This snippet demonstrates pd-ctl commands for checking region health in TiDB, including queries for regions with missing, extra, down, or pending peers.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/pd-scheduling-best-practices.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- `region check miss-peer`: Queries regions without enough peers\n- `region check extra-peer`: Queries regions with extra peers\n- `region check down-peer`: Queries regions with down peers\n- `region check pending-peer`: Queries regions with pending peers\n```\n\n----------------------------------------\n\nTITLE: Importing LangChain Libraries for Document Processing and Vector Storage\nDESCRIPTION: Imports required classes from LangChain libraries for document loading, vector storage, embeddings generation, and text splitting functionalities.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_community.vectorstores import TiDBVectorStore\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import CharacterTextSplitter\n```\n\n----------------------------------------\n\nTITLE: Matching Schemas and Tables with Prefixes in YAML Configuration\nDESCRIPTION: This YAML configuration shows how to match all tables that have a 'schema_' prefix in the schema name and a 'table_' prefix in the table name using Table Selector.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/table-selector.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nschema-pattern = \"schema_*\"\ntable-pattern = \"table_*\"\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP Cluster Prune Command\nDESCRIPTION: Command syntax for pruning scaled-in components in a TiDB cluster. Takes a cluster name parameter and optional flags. The -h or --help flag can be used to display help information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-prune.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster prune <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Using tiup dm import Command Syntax for DM Cluster Upgrade\nDESCRIPTION: The basic syntax for the `tiup dm import` command. This command is used to import DM v1.0 clusters deployed with TiDB Ansible and redeploy them as DM v2.0 clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-dm-import.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm import [flags]\n```\n\n----------------------------------------\n\nTITLE: Reverting Cached Table to Normal Table\nDESCRIPTION: Demonstrates how to remove the cache attribute from a table using the NOCACHE option, allowing subsequent DDL operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/cached-tables.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE users NOCACHE;\n```\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Registering SQL Statement Digest\nDESCRIPTION: Shows how to register a specific SQL digest and plan digest for capture in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-replayer.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nPLAN REPLAYER CAPTURE 'sql_digest' 'plan_digest';\n```\n\n----------------------------------------\n\nTITLE: Extracting Logical Component from TSO with TIDB_PARSE_TSO_LOGICAL()\nDESCRIPTION: This snippet demonstrates how to extract the logical component (last 18 bits) from a TiDB TSO timestamp using the TIDB_PARSE_TSO_LOGICAL() SQL function.\nSOURCE: https://github.com/pingcap/docs/blob/master/tso.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT TIDB_PARSE_TSO_LOGICAL(443852055297916932);\n+--------------------------------------------+\n| TIDB_PARSE_TSO_LOGICAL(443852055297916932) |\n+--------------------------------------------+\n|                                          4 |\n+--------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining Warning Alert Rule for CDC Multiple Owners in YAML\nDESCRIPTION: YAML configuration for a warning alert rule that triggers when there are multiple owners in the TiCDC cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-alert-rules.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nsum(rate(ticdc_owner_ownership_counter[30s])) >= 2\n```\n\n----------------------------------------\n\nTITLE: Example Query without SEMI_JOIN_REWRITE Hint\nDESCRIPTION: This example shows a query plan for a semi-join without using the SEMI_JOIN_REWRITE hint. The optimizer is restricted in its join selection and can only use specific execution strategies.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t WHERE EXISTS (SELECT 1 FROM t1 WHERE t1.a = t.a);\n```\n\n----------------------------------------\n\nTITLE: Running TiDB Full Backup\nDESCRIPTION: Performs a full snapshot backup of the TiDB cluster to S3 storage, typically scheduled on a regular basis.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-guide.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd \"${PD_IP}:2379\" \\\n--storage 's3://backup-101/snapshot-${date}?access-key=${access-key}&secret-access-key=${secret-access-key}'\n```\n\n----------------------------------------\n\nTITLE: TABLE_STORAGE_STATS Field Values Example\nDESCRIPTION: Sample output showing the storage statistics for a newly created table including peer count, region count, and table size metrics.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-table-storage-stats.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n*************************** 1. row ***************************\n      TABLE_SCHEMA: test\n        TABLE_NAME: t1\n          TABLE_ID: 56\n        PEER_COUNT: 1\n      REGION_COUNT: 1\nEMPTY_REGION_COUNT: 1\n        TABLE_SIZE: 1\n        TABLE_KEYS: 0\n```\n\n----------------------------------------\n\nTITLE: Deleting Data Using Parameterized Queries in JavaScript\nDESCRIPTION: This snippet demonstrates how to delete a record from the 'players' table using a parameterized query with the node-mysql2 driver. The query deletes the player with ID 1 and logs the number of affected rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysql2.md#2025-04-18_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nconst [rsh] = await conn.query('DELETE FROM players WHERE id = ?;', [1]);\nconsole.log(rsh.affectedRows);\n```\n\n----------------------------------------\n\nTITLE: Casting a Value as a Certain Type in TiDB\nDESCRIPTION: This snippet shows how to cast a value as a specific data type in TiDB using the CONVERT function, and compares it with Oracle's TO_NUMBER and TO_CHAR functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nTO_NUMBER(key)\nTO_CHAR(key)\n```\n\nLANGUAGE: sql\nCODE:\n```\nCONVERT(key,dataType)\n```\n\n----------------------------------------\n\nTITLE: Current Directory Relay Log Purge Command - Bash\nDESCRIPTION: This command purges relay logs before the current relay log's binlog file. It results in the deletion of all relay logs before the specified binlog in the current subdirectory while retaining logs in the current subdirectory.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/relay-log.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npurge-relay -s mysql-replica-01 --filename mysql-bin.000001\n```\n\n----------------------------------------\n\nTITLE: Enabling synchronous operations in TiDB Cloud Terraform Provider\nDESCRIPTION: Terraform provider configuration with the sync parameter enabled. This allows synchronous creation, updating, and deletion of supported resources, currently limited to cluster resources.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-get-tidbcloud-provider.md#2025-04-18_snippet_5\n\nLANGUAGE: terraform\nCODE:\n```\nprovider \"tidbcloud\" {\n  public_key = \"your_public_key\"\n  private_key = \"your_private_key\"\n  sync = true\n}\n```\n\n----------------------------------------\n\nTITLE: DM Import Mode Configuration Parameter (New)\nDESCRIPTION: New DM parameter that specifies the import mode during the full import phase. Default value is 'sql', which uses TiDB Lightning's TiDB-backend mode instead of the previous Loader component.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_18\n\nLANGUAGE: toml\nCODE:\n```\nloaders.<name>.import-mode\n```\n\n----------------------------------------\n\nTITLE: Creating a Jupyter Notebook File for TiDB Vector Search Integration\nDESCRIPTION: Creates a new Jupyter Notebook file to implement TiDB Vector Search with LangChain integration.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntouch integrate_with_langchain.ipynb\n```\n\n----------------------------------------\n\nTITLE: Run RawSQL Test (Bash)\nDESCRIPTION: This command runs a RawSQL test using the query defined in `demo.sql`.  It sets the execution count to 60 and uses the `--query-files` flag to specify the SQL file containing the query.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench rawsql run --count 60 --query-files demo.sql\n```\n\n----------------------------------------\n\nTITLE: Exporting Schema from Aurora using Dumpling\nDESCRIPTION: This command uses Dumpling to export the schema from Amazon Aurora to an S3 bucket. It filters specific tables and excludes data.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-aurora-to-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\nexport AWS_ACCESS_KEY_ID=${access_key}\nexport AWS_SECRET_ACCESS_KEY=${secret_key}\ntiup dumpling --host ${host} --port 3306 --user root --password ${password} --filter 'my_db1.table[12],mydb.*' --consistency none --no-data --output 's3://my-bucket/schema-backup'\n```\n\n----------------------------------------\n\nTITLE: TiDB Cluster Deployment Commands\nDESCRIPTION: Commands for deploying, starting, scaling, and upgrading a TiDB cluster in no-sudo mode\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-no-sudo-mode.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n# Deploy cluster\ntiup cluster deploy mycluster v8.5.0 topology.yaml --user tidb\n\n# Start cluster\ntiup cluster start mycluster\n\n# Scale out cluster\ntiup cluster scale-out mycluster scale.yaml --user tidb\n\n# Scale in cluster\ntiup cluster scale-in mycluster -N 192.168.124.27:20160\n\n# Upgrade cluster\ntiup cluster upgrade mycluster v8.2.0\n```\n\n----------------------------------------\n\nTITLE: Date Arithmetic with Fractional Intervals in SQL\nDESCRIPTION: Illustrates date arithmetic using the DATE_ADD function with a fractional interval. This query shows how TiDB handles date calculations involving microseconds.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.2.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nselect 0.000 % 0.11234500000000000000\n```\n\n----------------------------------------\n\nTITLE: Viewing TiCDC Status with CLI Command\nDESCRIPTION: Command to check the status of TiCDC capture nodes using the TiUP CLI tool, showing how to list all capture nodes with their details by connecting to a specific TiCDC server.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/deploy-ticdc.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc:v<CLUSTER_VERSION> cli capture list --server=http://10.0.10.25:8300\n```\n\n----------------------------------------\n\nTITLE: Hash Join EXPLAIN Output in TiDB\nDESCRIPTION: The execution plan output showing the hash join operation details, including build and probe phases, table access methods, and estimated row counts.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-joins.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n+-----------------------------+-----------+-----------+---------------+------------------------------------------------+\n| id                          | estRows   | task      | access object | operator info                                  |\n+-----------------------------+-----------+-----------+---------------+------------------------------------------------+\n| HashJoin_27                 | 142020.00 | root      |               | inner join, equal:[eq(test.t1.id, test.t2.id)] |\n| ├─TableReader_29(Build)     | 142020.00 | root      |               | data:TableFullScan_28                          |\n| │ └─TableFullScan_28        | 142020.00 | cop[tikv] | table:t1      | keep order:false                               |\n| └─TableReader_31(Probe)     | 180000.00 | root      |               | data:TableFullScan_30                          |\n|   └─TableFullScan_30        | 180000.00 | cop[tikv] | table:t2      | keep order:false                               |\n+-----------------------------+-----------+-----------+---------------+------------------------------------------------+\n```\n\n----------------------------------------\n\nTITLE: Using LIKE operator with underscore in TiKV\nDESCRIPTION: The underscore (_) in the LIKE operator was not matching non-ASCII characters when the new collation was not enabled. This issue has been fixed in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.4.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM table WHERE column LIKE '%_%';\n```\n\n----------------------------------------\n\nTITLE: Setting Initial Connection Commands in TiDB SQL\nDESCRIPTION: Controls the initial connection to a TiDB server by specifying SQL commands to be executed when a client connects. This is a newly added system variable in TiDB 5.1.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.0.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET init_connect = '<sql_commands>';\n```\n\n----------------------------------------\n\nTITLE: CANCEL IMPORT SQL Example Usage\nDESCRIPTION: Example SQL statement showing how to cancel an import job with ID 1, including the expected query output showing success with 0 rows affected.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-cancel-import-job.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCANCEL IMPORT JOB 1;\n```\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Splitting Large Files for TiDB Cloud Import using Bash\nDESCRIPTION: This Bash script splits a large file into smaller chunks for importing into TiDB Cloud, as the service has a file size limit. It takes the number of parts and the filename as input, splits the file, and renames the split files to keep the original extension.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/tidb-cloud-import-local-files.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n\"#!/bin/bash\nn=$1\nfile_path=$2\nfile_extension=\\\"${file_path##*.}\\\"\nfile_name=\\\"${file_path%.*}\\\"\ntotal_lines=$(wc -l < $file_path)\nlines_per_file=$(( (total_lines + n - 1) / n ))\nsplit -d -a 1 -l $lines_per_file $file_path $file_name.\nfor (( i=0; i<$n; i++ ))\ndo\n    mv $file_name.$i $file_name.$i.$file_extension\ndone\"\n```\n\n----------------------------------------\n\nTITLE: Using EXPLAIN to View MPP Query Plan in TiDB\nDESCRIPTION: This demonstrates how to use the EXPLAIN statement to view the execution plan for a query that will be processed in MPP mode, showing how it's divided into multiple fragments.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-mpp.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT COUNT(*) FROM t1 GROUP BY id;\n```\n\n----------------------------------------\n\nTITLE: Role and User Creation SQL Commands\nDESCRIPTION: SQL commands to create an analytics role, grant permissions, create a user, and assign the role to the user.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-default-role.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE ROLE analyticsteam;\nQuery OK, 0 rows affected (0.02 sec)\n\nGRANT SELECT ON test.* TO analyticsteam;\nQuery OK, 0 rows affected (0.02 sec)\n\nCREATE USER jennifer;\nQuery OK, 0 rows affected (0.01 sec)\n\nGRANT analyticsteam TO jennifer;\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Binlog Replace Command for First Shard\nDESCRIPTION: Command to replace the problematic DDL with two equivalent statements for the first MySQL instance's shard_table_1.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nbinlog replace test -s mysql-replica-01 \"ALTER TABLE `shard_db_1`.`shard_table_1` ADD COLUMN `new_col` INT;ALTER TABLE `shard_db_1`.`shard_table_1` ADD UNIQUE(`new_col`)\"\n```\n\n----------------------------------------\n\nTITLE: Sample Sysbench Config File with Specific Values\nDESCRIPTION: An example of a concrete Sysbench configuration file with actual values filled in, including a specific TiDB host IP address and thread count.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_4\n\nLANGUAGE: txt\nCODE:\n```\nmysql-host=172.16.30.33\nmysql-port=4000\nmysql-user=root\nmysql-password=password\nmysql-db=sbtest\ntime=600\nthreads=16\nreport-interval=10\ndb-driver=mysql\n```\n\n----------------------------------------\n\nTITLE: TiKV In-Memory Pessimistic Lock Configuration Parameter (New)\nDESCRIPTION: New TiKV parameter that controls whether to enable in-memory pessimistic locks to improve performance by storing locks in memory instead of writing to disk or replicating to other replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_14\n\nLANGUAGE: toml\nCODE:\n```\npessimistic-txn.in-memory\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW TABLES Statement Syntax\nDESCRIPTION: This EBNF diagram defines the syntax for the SHOW [FULL] TABLES statement in TiDB, outlining its structure and optional components.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-tables.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\n\"ShowTableStmt ::=\\n    \\\"SHOW\\\" \\\"FULL\\\"? \\\"TABLES\\\" (\\\"FROM\\\" Identifier | \\\"IN\\\" Identifier )? ShowLikeOrWhere?\\n\\nShowLikeOrWhere ::=\\n    \\\"LIKE\\\" SimpleExpr\\n|   \\\"WHERE\\\" Expression\"\n```\n\n----------------------------------------\n\nTITLE: TiUP Install Syntax\nDESCRIPTION: This snippet shows the general syntax for the `tiup install` command. It includes the component name with optional version and flags. Multiple components can be installed at once.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-install.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup install <component1>[:version] [component2...N] [flags]\n```\n\n----------------------------------------\n\nTITLE: Reverting Background Task Type in SQL\nDESCRIPTION: This SQL example reverts the background task type of the `default` resource group to its original configuration by setting `BACKGROUND` to NULL. It assumes the existence of a configured `default` resource group.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-background-tasks.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nALTER RESOURCE GROUP `default` BACKGROUND=NULL;\n```\n\n----------------------------------------\n\nTITLE: Allowing Optimizer to Decide on MPP Mode\nDESCRIPTION: This SQL snippet sets the session variables to allow the TiDB optimizer to decide on the use of MPP mode based on cost estimation. It sets 'tidb_allow_mpp' to 1 and 'tidb_enforce_mpp' to 0.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tiflash-mpp-mode.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nset @@session.tidb_allow_mpp=1;\nset @@session.tidb_enforce_mpp=0;\n```\n\n----------------------------------------\n\nTITLE: Generating Autocompletion Script for Zsh\nDESCRIPTION: This snippet shows the command to generate the autocompletion script tailored for the zsh shell. Running this command helps zsh users benefit from autocompletion features while using the TiDB Cloud CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-completion.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud completion zsh\n```\n\n----------------------------------------\n\nTITLE: Generating Autocompletion Script for Bash\nDESCRIPTION: This snippet demonstrates how to specifically generate the autocompletion script for the bash shell option of the TiDB Cloud CLI. Users may run this command in their terminal to set up bash autocompletion.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-completion.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud completion bash\n```\n\n----------------------------------------\n\nTITLE: TiKV Titan Engine Configuration for Column Families\nDESCRIPTION: Shows the configuration parameter 'blob_run_mode' that determines whether to enable the Titan engine on a specific Column Family (CF) in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.1.md#2025-04-18_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n- Set `blob_run_mode` to decide whether to enable the Titan engine on a specific CF [#4991](https://github.com/tikv/tikv/pull/4991)\n```\n\n----------------------------------------\n\nTITLE: Checking Missing Peers in TiDB Regions using PD Control\nDESCRIPTION: This command checks for regions with missing peers and returns a count along with region details. It's part of the region check functionality in PD Control.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_27\n\nLANGUAGE: bash\nCODE:\n```\n>> region check miss-peer\n{\n  \"count\": 2,\n  \"regions\": [......],\n}\n```\n\n----------------------------------------\n\nTITLE: Deleting Player Data with MySQL.js in JavaScript\nDESCRIPTION: This snippet shows how to delete a player record from the database using MySQL.js. It removes the player with ID 1 from the 'players' table.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysqljs.md#2025-04-18_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\nconn.query('DELETE FROM players WHERE id = ?;', [1], (err, ok) => {\n    if (err) {\n        reject(err);\n    } else {\n        resolve(ok.affectedRows);\n    }\n});\n```\n\n----------------------------------------\n\nTITLE: Scaling In a TiDB Cluster by Removing a TiKV Node\nDESCRIPTION: This command scales in the 'prod-cluster' by removing the TiKV node at 172.16.5.140:20160. It demonstrates how to take a specific node offline from the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster scale-in prod-cluster -N 172.16.5.140:20160\n```\n\n----------------------------------------\n\nTITLE: Querying Specific Processor - Shell and JSON\nDESCRIPTION: Example of how to retrieve details for a specific processor using GET /api/v2/processors/{changefeed_id}/{capture_id}. Returns the table IDs being replicated.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v2/processors/test/561c3784-77f0-4863-ad52-65a3436db6af\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"table_ids\": [\n    80\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Connection in env.json\nDESCRIPTION: JSON configuration for TiDB connection parameters in the env.json file, including host, port, user, and password.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"Parameters\": {\n    \"TIDB_HOST\": \"{gateway-region}.aws.tidbcloud.com\",\n    \"TIDB_PORT\": \"4000\",\n    \"TIDB_USER\": \"{prefix}.root\",\n    \"TIDB_PASSWORD\": \"{password}\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Viewing RU Consumption of Last Executed SQL - TiDB\nDESCRIPTION: The snippet demonstrates how to query a system variable to retrieve RU consumption data for the last executed SQL statement. This is useful for monitoring and performance analysis.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-resource-control-ru-groups.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@tidb_last_query_info;\n```\n\n----------------------------------------\n\nTITLE: Cleaning TiDB Cluster Data\nDESCRIPTION: Commands to clean up cluster data and logs with various options for selective cleanup.\nSOURCE: https://github.com/pingcap/docs/blob/master/maintain-tidb-using-tiup.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster clean ${cluster-name} --data\ntiup cluster clean ${cluster-name} --log\ntiup cluster clean ${cluster-name} --all\ntiup cluster clean ${cluster-name} --all --ignore-role prometheus\ntiup cluster clean ${cluster-name} --all --ignore-node 172.16.13.11:9000\ntiup cluster clean ${cluster-name} --all --ignore-node 172.16.13.12\n```\n\n----------------------------------------\n\nTITLE: Example of generating and querying SQL errors in TiDB\nDESCRIPTION: This example demonstrates generating a division-by-zero warning, querying the CLIENT_ERRORS_SUMMARY_BY_HOST table to view the warning, and then resetting the error summary with FLUSH CLIENT_ERRORS_SUMMARY.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/client-errors-summary-by-host.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 0/0;\nSELECT * FROM CLIENT_ERRORS_SUMMARY_BY_HOST;\nFLUSH CLIENT_ERRORS_SUMMARY;\nSELECT * FROM CLIENT_ERRORS_SUMMARY_BY_HOST;\n```\n\n----------------------------------------\n\nTITLE: Example of Deleting a User Profile\nDESCRIPTION: This snippet provides an example of how to use the `ticloud config delete` command to delete a user profile without any flags. This demonstrates a straightforward application of the command for users.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-delete.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud config delete <profile-name>\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP Commands in Shell\nDESCRIPTION: Demonstrates the basic syntax for executing TiUP commands or running components. The first line shows how to execute a command, while the second line shows how to run a component directly.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-reference.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup [flags] <command> [args...]        # Executes a command\n# or\ntiup [flags] <component> [args...]      # Runs a component\n```\n\n----------------------------------------\n\nTITLE: Collecting Statistics on Indexes in TiDB\nDESCRIPTION: SQL syntax for collecting statistics on specific indexes in a table. When IndexNameList is empty, it collects statistics on all indexes in the table. With tidb_analyze_version=2, it also collects statistics on the indexed columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE TableName INDEX [IndexNameList] [WITH NUM BUCKETS|TOPN|CMSKETCH DEPTH|CMSKETCH WIDTH]|[WITH NUM SAMPLES|WITH FLOATNUM SAMPLERATE];\n```\n\n----------------------------------------\n\nTITLE: Creating View Based on Union in SQL\nDESCRIPTION: Demonstrates how to create a view in TiDB based on a UNION of two SELECT statements. This feature allows combining data from multiple tables into a single view.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.6.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\ncreate view v as select * from t1 union select * from t2\n```\n\n----------------------------------------\n\nTITLE: Creating TiDB Cloud Serverless Cluster in Interactive Mode (Shell)\nDESCRIPTION: This example demonstrates how to create a TiDB Cloud Serverless cluster in interactive mode. The user will be prompted for necessary information during the creation process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-create.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless create\n```\n\n----------------------------------------\n\nTITLE: Fixing SET CHARSET Statement Behavior in TiDB\nDESCRIPTION: This fix corrects the wrong behavior of the SET CHARSET statement in TiDB. It ensures that character set changes are properly applied and consistent with expected behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.5.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSET CHARSET\n```\n\n----------------------------------------\n\nTITLE: Listing Export Tasks with Alias Command - Shell\nDESCRIPTION: This snippet shows the alias command for listing data export tasks in TiDB Cloud Serverless clusters. It serves as a shorthand for the default command, helping users to quickly access the listing functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-list.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export ls [flags]\n```\n\n----------------------------------------\n\nTITLE: Custom Content Block for TiDB Cloud Platform\nDESCRIPTION: Markdown block containing support channel information specifically for TiDB Cloud platform users\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-gui-mysql-workbench.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n<CustomContent platform=\"tidb-cloud\">\n\nAsk the community on [Discord](https://discord.gg/DQZ2dy3cuc?utm_source=doc) or [Slack](https://slack.tidb.io/invite?team=tidb-community&channel=everyone&ref=pingcap-docs), or [submit a support ticket](https://tidb.support.pingcap.com/).\n\n</CustomContent>\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Index in SQL\nDESCRIPTION: Creates a table named 't' with an INT column and an index on columns 'c' and 'd'. This table will be used in subsequent operations for analyzing statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a INT, b INT, c INT, d INT, INDEX idx_c_d(c, d));\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB GC Safe Point\nDESCRIPTION: SQL query to retrieve the current Garbage Collection safe point in TiDB, which defines the earliest point in time to which the cluster can be flashed back.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flashback-cluster.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM mysql.tidb WHERE variable_name = 'tikv_gc_safe_point';\n```\n\n----------------------------------------\n\nTITLE: Example JSON Response for Chat2Data Call\nDESCRIPTION: This JSON snippet is an example of the response received after calling the `/v3/sessions/{session_id}/chat2data` endpoint. It includes a `job_id` which can be used to check the status of the analysis and the session_id. This job ID is used to check the analysis status.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-sessions.md#2025-04-18_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"code\": 200,\n  \"msg\": \"\",\n  \"result\": {\n    \"job_id\": \"d96b6fd23c5f445787eb5fd067c14c0b\",\n    \"session_id\": 305685\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Listing DM-Worker Bindings in TiDB Data Migration\nDESCRIPTION: This example shows how to list the current bindings of all DM-workers. It uses the list-member command with the --worker flag to display information about worker bindings and their states.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-manage-source.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nlist-member --worker\n```\n\n----------------------------------------\n\nTITLE: Setting I/O Scheduler for SSD Devices\nDESCRIPTION: Shell command to set the I/O scheduling policy to 'noop' for SSD devices to optimize I/O operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\necho noop > /sys/block/${SSD_DEV_NAME}/queue/scheduler\n```\n\n----------------------------------------\n\nTITLE: Formatting Table in Markdown - TiDB Diagnostic Data\nDESCRIPTION: Markdown table showing TiDB diagnostic data types, exported files and collection parameters\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-data-instruction-for-tiup.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Data type | Exported file | Parameter for data collection by PingCAP Clinic |\n| :------ | :------ |:-------- |\n| Log | `tidb.log` | `--include=log` |\n| Error log | `tidb_stderr.log` | `--include=log` |\n| Slow log | `tidb_slow_query.log` | `--include=log` |\n| Configuration file | `tidb.toml` | `--include=config` |\n| Real-time configuration | `config.json` | `--include=config` |\n```\n\n----------------------------------------\n\nTITLE: Defining CANCEL TRAFFIC JOBS Syntax in EBNF\nDESCRIPTION: This EBNF snippet defines the syntax for the CANCEL TRAFFIC JOBS statement in TiDB. It specifies that the statement consists of the keywords 'CANCEL', 'TRAFFIC', and 'JOBS' in that order.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-cancel-traffic-jobs.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nTrafficStmt ::=\n    \"CANCEL\" \"TRAFFIC\" \"JOBS\"\n```\n\n----------------------------------------\n\nTITLE: TiKV Backup Threads Configuration Parameter (Modified)\nDESCRIPTION: TiKV parameter that controls the number of threads for backup operations. The allowed value range has been modified to be between 1 and the number of CPU cores.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\nbackup.num-threads\n```\n\n----------------------------------------\n\nTITLE: TiKV Configuration Dynamic Modification Support\nDESCRIPTION: List of TiKV configuration items that now support dynamic value modifications without requiring process restart\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.0.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n- raftstore.raft-entry-max-size\n- quota.foreground-cpu-time\n- quota.foreground-write-bandwidth\n- quota.foreground-read-bandwidth\n- quota.max-delay-duration\n- server.grpc-memory-pool-quota\n- server.max-grpc-send-msg-len\n- server.raft-msg-max-batch-size\n```\n\n----------------------------------------\n\nTITLE: Demonstrating tidb_constraint_check_in_place_pessimistic=ON with Pessimistic Transactions in SQL\nDESCRIPTION: This example shows how setting tidb_constraint_check_in_place_pessimistic to ON with pessimistic transactions causes uniqueness validation to happen immediately during statement execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nset @@tidb_constraint_check_in_place_pessimistic=ON;\nbegin pessimistic;\ninsert into t values (1);\n\nERROR 1062 : Duplicate entry '1' for key 't.PRIMARY'\n```\n\n----------------------------------------\n\nTITLE: Configuring TiFlash for Performance Optimization\nDESCRIPTION: TOML configuration for TiFlash that controls the maximum allowable disk bandwidth for data replication from TiKV to TiFlash, balancing replication speed and system stability.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[raftstore-proxy.server]\nsnap-io-max-bytes-per-sec = \"300MiB\"\n```\n\n----------------------------------------\n\nTITLE: Sample Output of Changefeed List - JSON\nDESCRIPTION: This JSON output example shows the state and checkpoint of a TiCDC changefeed, indicating the replication progress. It accompanies the shell command to list changefeeds, serving as expected output.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-faq.md#2025-04-18_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"id\": \"4e24dde6-53c1-40b6-badf-63620e4940dc\",\n    \"summary\": {\n      \"state\": \"normal\",\n      \"tso\": 417886179132964865,\n      \"checkpoint\": \"2020-07-07 16:07:44.881\",\n      \"error\": null\n    }\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: SAVEPOINT Syntax in TiDB SQL\nDESCRIPTION: Defines the syntax for SAVEPOINT, ROLLBACK TO SAVEPOINT, and RELEASE SAVEPOINT statements in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-savepoint.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSAVEPOINT identifier\nROLLBACK TO [SAVEPOINT] identifier\nRELEASE SAVEPOINT identifier\n```\n\n----------------------------------------\n\nTITLE: TableSchema Definition in TiCDC Simple Protocol\nDESCRIPTION: JSON representation of the TableSchema object in TiCDC Simple Protocol. It contains schema information including table name, ID, version, columns, and indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-simple-protocol.md#2025-04-18_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"schema\":\"simple\",\n    \"table\":\"user\",\n    \"tableID\":148,\n    \"version\":447984074911121426,\n    \"columns\":[\n        {\n        \"name\":\"id\",\n        \"dataType\":{\n            \"mysqlType\":\"int\",\n            \"charset\":\"binary\",\n            \"collate\":\"binary\",\n            \"length\":11\n        },\n        \"nullable\":false,\n        \"default\":null\n        },\n        {\n        \"name\":\"name\",\n        \"dataType\":{\n            \"mysqlType\":\"varchar\",\n            \"charset\":\"utf8mb4\",\n            \"collate\":\"utf8mb4_bin\",\n            \"length\":255\n        },\n        \"nullable\":true,\n        \"default\":null\n        },\n        {\n        \"name\":\"age\",\n        \"dataType\":{\n            \"mysqlType\":\"int\",\n            \"charset\":\"binary\",\n            \"collate\":\"binary\",\n            \"length\":11\n        },\n        \"nullable\":true,\n        \"default\":null\n        },\n        {\n        \"name\":\"score\",\n        \"dataType\":{\n            \"mysqlType\":\"float\",\n            \"charset\":\"binary\",\n            \"collate\":\"binary\",\n            \"length\":12\n        },\n        \"nullable\":true,\n        \"default\":null\n        }\n    ],\n    \"indexes\":[\n        {\n        \"name\":\"primary\",\n        \"unique\":true,\n        \"primary\":true,\n        \"nullable\":false,\n        \"columns\":[\n            \"id\"\n        ]\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Left Join and Right Join in TiDB\nDESCRIPTION: This snippet explains the syntax differences for performing left and right joins between Oracle and TiDB, highlighting the use of JOIN clauses in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM a, b WHERE a.id = b.id(+);\nSELECT * FROM a, b WHERE a.id(+) = b.id;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM a LEFT JOIN b ON a.id = b.id;\nSELECT * FROM a RIGHT JOIN b ON a.id = b.id;\n```\n\n----------------------------------------\n\nTITLE: Sharding Deletion Filter Configuration\nDESCRIPTION: Configuration example for filtering out all deletion operations in sharded tables and schemas.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-binlog-event-filter.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nfilters:\n  filter-table-rule:\n    schema-pattern: \"test_*\"\n    table-pattern: \"t_*\"\n    events: [\"truncate table\", \"drop table\", \"delete\"]\n    action: Ignore\n  filter-schema-rule:\n    schema-pattern: \"test_*\"\n    events: [\"drop database\"]\n    action: Ignore\n```\n\n----------------------------------------\n\nTITLE: Using tiup cluster meta backup Command in Shell\nDESCRIPTION: The basic syntax for backing up TiUP meta files for a specific cluster. The command requires a cluster name parameter and can accept optional flags to customize the backup process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-meta-backup.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster meta backup <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: Creating a User Profile in Non-Interactive Mode\nDESCRIPTION: This example shows how to create a user profile in non-interactive mode by specifying all required flags: profile name, public key, and private key.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-config-create.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud config create --profile-name <profile-name> --public-key <public-key> --private-key <private-key>\n```\n\n----------------------------------------\n\nTITLE: Selecting Database for Bikeshare Queries in SQL\nDESCRIPTION: This SQL command selects the 'bikeshare' database for subsequent queries. It ensures that all following queries are executed within the correct database context.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-sample-data.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nuse bikeshare;\n```\n\n----------------------------------------\n\nTITLE: Converting DATETIME to DATE using CAST in SQL\nDESCRIPTION: This snippet shows how to explicitly convert a DATETIME value to a DATE type using the CAST function in SQL. This conversion discards the time portion of the DATETIME value.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\ndate_col = CAST(datetime_col AS DATE)\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into TiDB with Go-MySQL-Driver\nDESCRIPTION: Example of inserting data into a 'player' table using Go-MySQL-Driver. It demonstrates executing an INSERT SQL statement with parameterized values.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-golang-sql-driver.md#2025-04-18_snippet_1\n\nLANGUAGE: Go\nCODE:\n```\nopenDB(\"mysql\", func(db *sql.DB) {\n    insertSQL = \"INSERT INTO player (id, coins, goods) VALUES (?, ?, ?)\"\n    _, err := db.Exec(insertSQL, \"id\", 1, 1)\n\n    if err != nil {\n        panic(err)\n    }\n})\n```\n\n----------------------------------------\n\nTITLE: Creating TiDB Target Schema\nDESCRIPTION: SQL commands to create the target database and table schema in TiDB Cloud\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-sql-shards.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE DATABASE store;\nQuery OK, 0 rows affected (0.16 sec)\nmysql> use store;\nDatabase changed\n\nmysql> CREATE TABLE `sales` (\n  `id` bigint(20) NOT NULL ,\n  `uid` varchar(40) NOT NULL,\n  `sale_num` bigint DEFAULT NULL,\n  INDEX (`id`),\n  UNIQUE KEY `ind_uid` (`uid`)\n);\nQuery OK, 0 rows affected (0.17 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining SHOW CHARACTER SET Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the SHOW CHARACTER SET statement in TiDB, including optional LIKE or WHERE clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-character-set.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowCharsetStmt ::=\n    \"SHOW\" ( (\"CHARACTER\" | \"CHAR\") \"SET\" | \"CHARSET\" ) ShowLikeOrWhere?\n\nShowLikeOrWhere ::=\n    \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Setting Keyspace Name for TiDB Lightning in Multi-tenant Environment\nDESCRIPTION: Parameter configuration for specifying the keyspace name when importing data to a multi-tenant TiDB cluster. This provides flexibility in configuring TiDB Lightning for multi-tenant deployments.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.0.0.md#2025-04-18_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\ntikv-importer.keyspace-name: \"<keyspace_name>\"\n```\n\n----------------------------------------\n\nTITLE: Setting Resource Group for Current Session in TiDB SQL\nDESCRIPTION: This snippet demonstrates how to set the resource group for the current session using the SET RESOURCE GROUP statement and then verify the change using CURRENT_RESOURCE_GROUP() function in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET RESOURCE GROUP `rg2`;\nSELECT CURRENT_RESOURCE_GROUP();\n```\n\n----------------------------------------\n\nTITLE: TiFlash AWS KMS Master Key Configuration\nDESCRIPTION: Configuration for using AWS KMS as the master key provider, specifying key ID, region and endpoint details.\nSOURCE: https://github.com/pingcap/docs/blob/master/encryption-at-rest.md#2025-04-18_snippet_11\n\nLANGUAGE: toml\nCODE:\n```\n[security.encryption.master-key]\ntype = \"kms\"\nkey-id = \"0987dcba-09fe-87dc-65ba-ab0987654321\"\nregion = \"us-west-2\"\nendpoint = \"https://kms.us-west-2.amazonaws.com\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB to Read from Read-Only Nodes\nDESCRIPTION: This SQL command sets the 'tidb_replica_read' system variable to 'learner', directing read requests to learner replicas on read-only nodes instead of voting replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/readonly-nodes.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nset tidb_replica_read=learner;\n```\n\n----------------------------------------\n\nTITLE: Resetting Checkpoint After Invalid Status Error in TiDB Lightning\nDESCRIPTION: Command to delete imported data when encountering a checkpoint error with invalid status, which typically happens after an abnormal exit of TiDB Lightning or TiKV Importer.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/troubleshoot-tidb-lightning.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntidb-lightning-ctl --config conf/tidb-lightning.toml --checkpoint-error-destroy=all\n```\n\n----------------------------------------\n\nTITLE: Querying Latest Published Books in SQL\nDESCRIPTION: This SQL query selects the latest published books and their prices from the 'books' table, ordered by publication date in descending order and limited to 5 results.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-stale-read.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT id, title, type, price FROM books ORDER BY published_at DESC LIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Warming Data with Sysbench\nDESCRIPTION: Bash command to warm data in TiDB by loading it from disk into memory block cache, which significantly improves system performance before testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nsysbench --config-file=config oltp_point_select --tables=32 --table-size=10000000 prewarm\n```\n\n----------------------------------------\n\nTITLE: Listing Branches in Interactive Mode\nDESCRIPTION: This example demonstrates how to list all branches for a TiDB Cloud Serverless cluster in interactive mode. The user will be prompted for necessary information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-list.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch list\n```\n\n----------------------------------------\n\nTITLE: Dropping a Global Binding - SQL\nDESCRIPTION: This SQL snippet shows how to drop a global binding in TiDB that limits the execution time of a specific query. Removing this binding will eliminate the imposed execution time constraint.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/sql-faq.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP GLOBAL BINDING for\n    SELECT * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Creating a Database Schema SQL Statement for TiDB Cloud Import\nDESCRIPTION: SQL statement to create a database named 'mydb' to be included in a database schema file (mydb-schema-create.sql) when importing CSV files from Amazon S3 or GCS into TiDB Cloud.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-csv-files.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE mydb;\n```\n\n----------------------------------------\n\nTITLE: Displaying SHOW BINDINGS Syntax EBNF\nDESCRIPTION: This EBNF snippet defines the syntax structure for the SHOW BINDINGS SQL statement in TiDB. It allows for optional GLOBAL or SESSION context in the command.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-bindings.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowBindingsStmt ::=\n    \"SHOW\" (\"GLOBAL\" | \"SESSION\")? \"BINDINGS\" ShowLikeOrWhere?\n\nShowLikeOrWhere ::=\n    \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: Restore Progress Display\nDESCRIPTION: Example output showing the progress bars during a restore operation, indicating completion percentages for different restore phases.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-snapshot-manual.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nSplit&Scatter Region <--------------------------------------------------------------------> 100.00%\nDownload&Ingest SST <---------------------------------------------------------------------> 100.00%\nRestore Pipeline <-------------------------/...............................................> 17.12%\n```\n\n----------------------------------------\n\nTITLE: Deploying a TiDB Cluster with TiUP\nDESCRIPTION: Deploys a TiDB cluster using the specified topology configuration. This command initializes all components of the TiDB cluster according to the topology file, using the specified version and authentication.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster deploy tidb-test v8.5.0 ./topology.yaml --user root [-p] [-i /home/root/.ssh/gcp_rsa]\n```\n\n----------------------------------------\n\nTITLE: Setting Global Password Lifetime in SQL\nDESCRIPTION: SQL command to establish a global automatic password expiration policy with a password lifetime of 180 days. This applies to all accounts that don't have an account-level override.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_13\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL default_password_lifetime = 180;\n```\n\n----------------------------------------\n\nTITLE: Using JSON_SET() to Update and Add Multiple Values\nDESCRIPTION: This example demonstrates using JSON_SET() to update an existing property ('version') and add a new property ('branch') to a JSON document in a single operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-modify.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SET('{\"version\": 1.1, \"name\": \"example\"}','$.version',1.2,'$.branch', \"main\");\n```\n\n----------------------------------------\n\nTITLE: Adding Index with Batch Size 32\nDESCRIPTION: Performance test configuration using tidb_ddl_reorg_batch_size=32 with varying worker counts. Shows impact on TPS/QPS and index creation duration.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/online-workloads-and-add-index-operations.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ntidb_ddl_reorg_batch_size = 32\n```\n\n----------------------------------------\n\nTITLE: Running dbt Transformation for TiDB Cloud\nDESCRIPTION: This command executes the dbt run command to transform data according to the models defined in the dbt project. It creates tables and views in the target TiDB Cloud instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ndbt run\n```\n\n----------------------------------------\n\nTITLE: Using JSON_UNQUOTE() to Remove Quotes from JSON Strings\nDESCRIPTION: The JSON_UNQUOTE() function removes the surrounding quotes from a JSON string value and returns the unquoted string. This example demonstrates unquoting a simple string.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-modify.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_UNQUOTE('\"foo\"');\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB Cloud Serverless Cluster\nDESCRIPTION: This snippet demonstrates the basic syntax for connecting to a TiDB Cloud Serverless cluster using the `ticloud serverless shell` command. The command provides access to a shell for interacting with the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-shell.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless shell [flags]\n```\n\n----------------------------------------\n\nTITLE: Listing Branches for TiDB Cloud Serverless Cluster\nDESCRIPTION: This command lists all branches for a TiDB Cloud Serverless cluster. It requires a cluster ID and can be used in both interactive and non-interactive modes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-list.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch list <cluster-id> [flags]\n```\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch ls <cluster-id> [flags]\n```\n\n----------------------------------------\n\nTITLE: Basic TABLE Statement Usage\nDESCRIPTION: Example of using the TABLE statement to view all data in table t1 without filtering, showing the equivalent of SELECT * FROM t1.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-table.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nTABLE t1;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+----+\n| id |\n+----+\n|  1 |\n|  2 |\n|  3 |\n+----+\n3 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: TiDB Cloud Serverless Connection Configuration\nDESCRIPTION: Dotenv configuration for establishing database connection parameters including host, port, username, password, and database name.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/dev-guide-wordpress.md#2025-04-18_snippet_4\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_HOST='{HOST}'\\nTIDB_PORT='4000'\\nTIDB_USER='{USERNAME}'\\nTIDB_PASSWORD='{PASSWORD}'\\nTIDB_DB_NAME='test'\n```\n\n----------------------------------------\n\nTITLE: Compiling TiProxy from Source Code\nDESCRIPTION: Compilation procedure for TiProxy from GitHub source repository, requiring Go 1.21 or later\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-command-line-flags.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/pingcap/tiproxy.git\ncd tiproxy\nmake\nls bin/tiproxyctl\n```\n\n----------------------------------------\n\nTITLE: Configuring Batch Commit in TiDB SQL Transactions\nDESCRIPTION: Introduces a variable to split a transaction into multiple transactions based on the number of statements, improving performance for large transactions.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0-beta.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_batch_commit = 100;\n```\n\n----------------------------------------\n\nTITLE: Running a Custom TiUP Component\nDESCRIPTION: Demonstrates running a custom component that was published to a private mirror.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ tiup hello\n```\n\n----------------------------------------\n\nTITLE: Generating TiKV Private Key\nDESCRIPTION: Command to generate a 2048-bit RSA private key for TiKV instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nopenssl genrsa -out tikv.key 2048\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Configuration File\nDESCRIPTION: Command to copy the example environment file to create a new .env file for configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Updating Data in TiDB with node-mysql2 in JavaScript\nDESCRIPTION: Illustrates how to update a Player record by adding coins and goods, and retrieve the number of affected rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysql2.md#2025-04-18_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nconst [rsh] = await conn.query(\n    'UPDATE players SET coins = coins + ?, goods = goods + ? WHERE id = ?;',\n    [50, 50, 1]\n);\nconsole.log(rsh.affectedRows);\n```\n\n----------------------------------------\n\nTITLE: Installing Diag Using TiUP\nDESCRIPTION: Command to install the Diag diagnostic tool using TiUP package manager\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup install diag\n```\n\n----------------------------------------\n\nTITLE: Creating New Resource Group\nDESCRIPTION: Shows how to create a new resource group named 'rg1' with specific RU_PER_SEC limit.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-resource-groups.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE RESOURCE GROUP rg1 RU_PER_SEC=1000;\n```\n\n----------------------------------------\n\nTITLE: Configuring pt-osc in TiDB DM pre-v2.0.5\nDESCRIPTION: Configuration setting for enabling pt-osc tool support in TiDB Data Migration versions before 2.0.5. Uses the deprecated online-ddl-scheme parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-online-ddl-tool-support.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nonline-ddl-scheme: \"pt\"\n```\n\n----------------------------------------\n\nTITLE: JSON_SET() Multiple Updates Result Example\nDESCRIPTION: The output shows the JSON document after applying JSON_SET() to both update 'version' to 1.2 and add the new 'branch' property with value 'main'.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-modify.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------------------------------------------------------------+\n| JSON_SET('{\"version\": 1.1, \"name\": \"example\"}','$.version',1.2,'$.branch', \"main\") |\n+------------------------------------------------------------------------------------+\n| {\"branch\": \"main\", \"name\": \"example\", \"version\": 1.2}                              |\n+------------------------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Describing import task in non-interactive mode using Shell\nDESCRIPTION: This example shows how to describe an import task in non-interactive mode by specifying the required flags (cluster-id and import-id) directly in the command.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-describe.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import describe --cluster-id <cluster-id> --import-id <import-id>\n```\n\n----------------------------------------\n\nTITLE: Uneven Split Syntax for Partitioned Tables\nDESCRIPTION: This SQL syntax explains how to perform an uneven split for partitioned tables by specifying the value lists for the split.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nSPLIT [PARTITION] TABLE table_name [PARTITION (partition_name_list...)] [INDEX index_name] BY (value_list) [, (value_list)] ...;\n```\n\n----------------------------------------\n\nTITLE: Github Issue References in Release Notes\nDESCRIPTION: References to GitHub pull requests showing specific improvements and bug fixes in the TiDB 2.1 RC2 release.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1-rc.2.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[#7543](https://github.com/pingcap/tidb/pull/7543)\n[#7276](https://github.com/pingcap/tidb/pull/7276)\n[#7577](https://github.com/pingcap/tidb/pull/7577)\n```\n\n----------------------------------------\n\nTITLE: Creating a View and Querying VIEWS Table in TiDB\nDESCRIPTION: This SQL snippet demonstrates how to create a simple view and then query the VIEWS table to see the information about the created view.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-views.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE VIEW test.v1 AS SELECT 1;\nSELECT * FROM VIEWS\\G\n```\n\n----------------------------------------\n\nTITLE: Example Azure Blob Storage URI for BR\nDESCRIPTION: Shows how to format an Azure Blob Storage URI for the BR backup and restore tool, specifying a folder path with account name and key.\nSOURCE: https://github.com/pingcap/docs/blob/master/external-storage-uri.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nazure://external/testfolder?account-name=${account-name}&account-key=${account-key}\n```\n\n----------------------------------------\n\nTITLE: Calculate Days Between Two Dates in TiDB\nDESCRIPTION: This snippet demonstrates how to calculate the number of days between two dates using DATEDIFF in TiDB, compared with Oracle's subtraction method.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\ndate1 - date2\n```\n\nLANGUAGE: sql\nCODE:\n```\nDATEDIFF(date1, date2)\n```\n\n----------------------------------------\n\nTITLE: SQL Feature ID Comment Syntax\nDESCRIPTION: New special comment functionality that only allows registered statement fragments to be parsed, while ignoring unregistered ones. Improves SQL statement parsing control.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.1.1.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n/*+ Feature ID */\n```\n\n----------------------------------------\n\nTITLE: TiFlash Elastic ThreadPool Configuration Parameter (Modified)\nDESCRIPTION: TiFlash parameter that controls whether to enable the elastic thread pool. The default value has been changed from false to true.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_11\n\nLANGUAGE: toml\nCODE:\n```\nprofiles.default.enable_elastic_threadpool\n```\n\n----------------------------------------\n\nTITLE: Configuring mTLS Authentication for Pulsar in TiCDC\nDESCRIPTION: This snippet illustrates the sink URI configuration when using mTLS for Pulsar in TiCDC. It specifies the `pulsar+ssl` protocol.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\n--sink-uri=\"pulsar+ssl://127.0.0.1:6651/persistent://public/default/yktest?protocol=canal-json\"\n```\n\n----------------------------------------\n\nTITLE: MySQL Transaction Setting Command\nDESCRIPTION: Added support for SET TRANSACTION syntax to configure transaction characteristics\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.0-rc.4.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET TRANSACTION\n```\n\n----------------------------------------\n\nTITLE: Showing the CREATE DATABASE statement in TiDB\nDESCRIPTION: This SQL statement shows the `CREATE DATABASE` statement used to create the 'test' database. It retrieves the exact SQL statement that can be used to recreate the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-database.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE DATABASE test;\n```\n\n----------------------------------------\n\nTITLE: SQL Example of ADMIN PAUSE DDL JOBS Statement in TiDB\nDESCRIPTION: An SQL example showing how to use the ADMIN PAUSE DDL JOBS statement in TiDB. It demonstrates pausing one or more DDL jobs by specifying their job IDs.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-pause-ddl.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN PAUSE DDL JOBS job_id [, job_id] ...;\n```\n\n----------------------------------------\n\nTITLE: Accessing TiDB Dashboard URL Example\nDESCRIPTION: Example URL pattern for accessing the TiDB Dashboard cluster information page through a web browser. The URL needs to be modified with the actual PD instance address and port.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-cluster-info.md#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nhttp://127.0.0.1:2379/dashboard/#/cluster_info/instance\n```\n\n----------------------------------------\n\nTITLE: Markdown Table - TiKV Node Status Definitions\nDESCRIPTION: A markdown table defining TiKV node status states and their descriptions for TiDB Cloud Dedicated clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/monitor-tidb-cluster.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n| TiKV node status | Description |\n|:--|:--|\n| **Available** | The TiKV node is healthy and available. |\n| **Creating** | The TiKV node is being created. |\n| **Unavailable** | The TiKV node is not available. |\n| **Deleting** | The TiKV node is being deleted. |\n```\n\n----------------------------------------\n\nTITLE: Custom Content Block for TiDB Platform\nDESCRIPTION: Markdown block containing support channel information specifically for TiDB platform users\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-gui-mysql-workbench.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<CustomContent platform=\"tidb\">\n\nAsk the community on [Discord](https://discord.gg/DQZ2dy3cuc?utm_source=doc) or [Slack](https://slack.tidb.io/invite?team=tidb-community&channel=everyone&ref=pingcap-docs), or [submit a support ticket](/support.md).\n\n</CustomContent>\n```\n\n----------------------------------------\n\nTITLE: Running Snapshot Backup in TiDB with Specific Timestamp\nDESCRIPTION: Command to execute a snapshot (full) backup with a specified backup timestamp of May 14, 2022.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-use-cases.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full --pd=\"${PD_IP}:2379\" \\\n--storage='s3://tidb-pitr-bucket/backup-data/snapshot-20220514000000' \\\n--backupts='2022/05/14 00:00:00 +08:00'\n```\n\n----------------------------------------\n\nTITLE: Setting DDL Reorganization Worker Count\nDESCRIPTION: Sets the tidb_ddl_reorg_worker_cnt variable to control the concurrency of DDL operations in the re-organize phase. This affects the speed of operations like ADD INDEX.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_27\n\nLANGUAGE: SQL\nCODE:\n```\nSET SESSION tidb_ddl_reorg_worker_cnt = 4;\n```\n\n----------------------------------------\n\nTITLE: Metadata Filter Examples in JSON\nDESCRIPTION: Shows various metadata filter examples using JSON syntax, demonstrating different filter operators like $eq, $in, $nin, $lt, $or, and $and.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_15\n\nLANGUAGE: json\nCODE:\n```\n{ \"page\": 12 }\n```\n\nLANGUAGE: json\nCODE:\n```\n{ \"page\": { \"$eq\": 12 } }\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"page\": {\n    \"$in\": [11, 12, 13]\n  }\n}\n```\n\nLANGUAGE: json\nCODE:\n```\n{ \"page\": { \"$nin\": [13] } }\n```\n\nLANGUAGE: json\nCODE:\n```\n{ \"page\": { \"$lt\": 11 } }\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"$or\": [{ \"page\": 11 }, { \"page\": 12 }],\n  \"$and\": [{ \"page\": 12 }, { \"page\": 13 }]\n}\n```\n\n----------------------------------------\n\nTITLE: RocksDB Compression Configuration Parameters\nDESCRIPTION: Compression-related settings for different RocksDB levels and column families.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\ncompression-per-level:\n  defaultcf: [\"no\", \"no\", \"lz4\", \"lz4\", \"lz4\", \"zstd\", \"zstd\"]\n  writecf: [\"no\", \"no\", \"lz4\", \"lz4\", \"lz4\", \"zstd\", \"zstd\"]\n  lockcf: [\"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\"]\n\nbottommost-level-compression: \"zstd\"\n```\n\n----------------------------------------\n\nTITLE: Decorrelated JOIN Query in SQL\nDESCRIPTION: The optimized version of the correlated subquery, rewritten as a JOIN operation with grouping to improve performance by executing the subquery only once.\nSOURCE: https://github.com/pingcap/docs/blob/master/correlated-subquery-optimization.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nselect t1.* from t1, (select b, sum(a) sum_a from t2 group by b) t2 where t1.b = t2.b and t1.a < t2.sum_a\n```\n\n----------------------------------------\n\nTITLE: Basic SHOW TABLE REGIONS Syntax\nDESCRIPTION: SQL statement to display region information for a table, with optional filtering using WHERE clause. Supports showing regions for entire tables or specific indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-regions.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLE [table_name] REGIONS [WhereClauseOptional];\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLE [table_name] INDEX [index_name] REGIONS [WhereClauseOptional];\n```\n\n----------------------------------------\n\nTITLE: TiKV Quota Limiter Configuration Parameters (New)\nDESCRIPTION: New TiKV configuration parameters related to Quota Limiter, which limit resources occupied by frontend requests. The feature is experimental and disabled by default.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_15\n\nLANGUAGE: toml\nCODE:\n```\nquota\n```\n\n----------------------------------------\n\nTITLE: Cloning a TiUP Mirror\nDESCRIPTION: This command clones an official TiUP mirror to a local directory with options to specify version and components. It can be used to create an offline mirror for isolated environments.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup mirror clone <target-dir> [global-version] [flags]\n```\n\n----------------------------------------\n\nTITLE: Configuring Auto-Increment Removal Permission\nDESCRIPTION: Controls whether dropping the AUTO INCREMENT attribute of a column is allowed. This can be modified using the tidb_allow_remove_auto_inc system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.18.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_allow_remove_auto_inc = TRUE;\n```\n\n----------------------------------------\n\nTITLE: Describing the PARTITIONS Table Schema in TiDB\nDESCRIPTION: This SQL statement uses the DESC command to display the structure of the PARTITIONS table in the INFORMATION_SCHEMA database, showing all available columns and their data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-partitions.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC partitions;\n```\n\n----------------------------------------\n\nTITLE: Using SQL Hint for Aggregation Pushdown\nDESCRIPTION: Demonstrates how to use the AGG_TO_COP hint to manually push down aggregation operators when querying slow queries grouped by user.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-slow-query.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ AGG_TO_COP() */ COUNT(*) FROM CLUSTER_SLOW_QUERY GROUP BY user;\n```\n\n----------------------------------------\n\nTITLE: Changing Binding Status for a SQL Statement in TiDB\nDESCRIPTION: SQL command to change the status of a binding from ENABLED to DISABLED or vice versa. The effective scope is GLOBAL by default and cannot be modified.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nSET BINDING [ENABLED | DISABLED] FOR BindableStmt;\n```\n\n----------------------------------------\n\nTITLE: Committing a Transaction in TiDB - SQL\nDESCRIPTION: This snippet shows the SQL command used to commit a transaction in TiDB. After the commit, any data in the global temporary table is cleared, illustrating the temporary nature of the data.\nSOURCE: https://github.com/pingcap/docs/blob/master/temporary-tables.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nCOMMIT;\n```\n\n----------------------------------------\n\nTITLE: TiDB Admin Plugins SQL Statements\nDESCRIPTION: Shows the SQL statements 'ADMIN PLUGINS ENABLE' and 'ADMIN PLUGINS DISABLE' used to dynamically enable or disable plugins in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.1.md#2025-04-18_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n+ Add the `ADMIN PLUGINS ENABLE`/`ADMIN PLUGINS DISABLE` SQL statement to dynamically enable or disable plugins [#11157](https://github.com/pingcap/tidb/pull/11157)\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Inconsistent Index\nDESCRIPTION: Example of using ADMIN CLEANUP INDEX to remove dangling index entries and verifying the fix with ADMIN CHECK INDEX.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-cleanup.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nADMIN CLEANUP INDEX tbl idx;\n+---------------+\n| REMOVED_COUNT |\n+---------------+\n|             1 |\n+---------------+\n\nADMIN CHECK INDEX tbl idx;\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a Sample CSV File for Import to TiDB Cloud\nDESCRIPTION: A sample CSV file with semicolon separators containing ID, name, and age data for importing into TiDB Cloud.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-import-resource.md#2025-04-18_snippet_0\n\nLANGUAGE: csv\nCODE:\n```\nid;name;age\n1;Alice;20\n2;Bob;30\n```\n\n----------------------------------------\n\nTITLE: Deleting Player Data with Prisma in JavaScript\nDESCRIPTION: This snippet shows how to delete a Player record using Prisma's delete method. It removes the Player with ID 101 from the database.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-prisma.md#2025-04-18_snippet_12\n\nLANGUAGE: javascript\nCODE:\n```\nawait prisma.player.delete({\n   where: {\n      id: 101,\n   }\n});\n```\n\n----------------------------------------\n\nTITLE: Scaling In a TiCDC Node with TiUP\nDESCRIPTION: Command to scale in (remove) a TiCDC node from a TiDB cluster using TiUP, specifying the node to be removed by its address and port.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/deploy-ticdc.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster scale-in <cluster-name> --node 10.0.1.4:8300\n```\n\n----------------------------------------\n\nTITLE: Locking Table Statistics in TiDB\nDESCRIPTION: SQL commands to lock statistics for a table, show locked statistics, and attempt to analyze the table. This demonstrates how ANALYZE is skipped for locked tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-lock-stats.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nLOCK STATS t;\nSHOW STATS_LOCKED;\nANALYZE TABLE t;\nSHOW WARNINGS;\n```\n\n----------------------------------------\n\nTITLE: Showing View Metadata with SHOW CREATE VIEW in SQL\nDESCRIPTION: This SQL snippet demonstrates how to retrieve the metadata of a view named 'v' using the SHOW CREATE VIEW statement. It displays the CREATE VIEW statement and character set information.\nSOURCE: https://github.com/pingcap/docs/blob/master/views.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nshow create view v;\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Django TiDB Integration\nDESCRIPTION: Commands to install the required Python packages for the Django TiDB integration project, including django-tidb which provides TiDB-specific features.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Downloading gh-ost pre-built binary\nDESCRIPTION: Command to download a pre-built gh-ost binary directly from the GitHub releases page using curl.\nSOURCE: https://github.com/pingcap/docs/blob/master/styles/config/vocabularies/PingCAP/accept.txt#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -L https://github.com/github/gh-ost/releases/download/v1.1.0/gh-ost-binary-linux-20200828140552.tar.gz -o gh-ost.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Displaying TiDB Cloud Cluster State with Terraform\nDESCRIPTION: This shell command displays the current state of the TiDB Cloud cluster resource using Terraform. It shows details such as cluster ID, name, and status.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_4\n\nLANGUAGE: Shell\nCODE:\n```\n$ terraform state show tidbcloud_cluster.example_cluster\n```\n\n----------------------------------------\n\nTITLE: Patching a Specific TiDB Node\nDESCRIPTION: Example command to patch a single TiDB node in a cluster with a hotfix package by specifying the node's address and port.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster patch test-cluster /tmp/tidb-hotfix.tar.gz -N 172.16.4.5:4000\n```\n\n----------------------------------------\n\nTITLE: Setting TiSpark to Read from TiFlash via Spark Initialization Command\nDESCRIPTION: This command-line option can be added when initializing Spark shell or Thrift server to configure TiSpark to read from TiFlash replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tispark-to-read-tiflash.md#2025-04-18_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n--conf spark.tispark.isolation_read_engines=tiflash\n```\n\n----------------------------------------\n\nTITLE: Convert Date to String in TiDB\nDESCRIPTION: This snippet illustrates how to convert a date to a formatted string in TiDB using DATE_FORMAT, contrasting with Oracle's TO_CHAR syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nTO_CHAR(SYSDATE,'yyyy-MM-dd hh24:mi:ss')\nTO_CHAR(SYSDATE,'yyyy-MM-dd')\n```\n\nLANGUAGE: sql\nCODE:\n```\nDATE_FORMAT(NOW(),'%Y-%m-%d %H:%i:%s')\nDATE_FORMAT(NOW(),'%Y-%m-%d')\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Self-Managed Connection in .env File\nDESCRIPTION: Example of a .env file configuration for connecting to a self-managed TiDB cluster with connection parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_5\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_DATABASE_URL=\"mysql+pymysql://<USER>:<PASSWORD>@<HOST>:<PORT>/<DATABASE>\"\n# For example: TIDB_DATABASE_URL=\"mysql+pymysql://root@127.0.0.1:4000/test\"\n```\n\n----------------------------------------\n\nTITLE: Scaling out TiDB cluster with TiCDC using TiUP\nDESCRIPTION: Commands to add TiCDC component to an existing TiDB cluster using TiUP and verify the deployment status.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster scale-out <cluster-name> scale-out.yml\ntiup cluster display <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Executing TiUP Status Command\nDESCRIPTION: Basic command to view the operational status of TiDB components. Displays a comprehensive table with component details like name, PID, status, and runtime arguments.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-status.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup status [flags]\n```\n\n----------------------------------------\n\nTITLE: EBNF Grammar Definition for SHOW BUILTINS\nDESCRIPTION: Formal grammar definition for the SHOW BUILTINS statement using Extended Backus-Naur Form (EBNF) notation. Defines the syntactical structure of the command in a precise, machine-readable format.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-builtins.md#2025-04-18_snippet_1\n\nLANGUAGE: ebnf\nCODE:\n```\nShowBuiltinsStmt ::=\n    \"SHOW\" \"BUILTINS\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Scheduling Servers in YAML\nDESCRIPTION: Example configuration for scheduling microservices showing host machine specifications for the scheduling service deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\nscheduling_servers:\n  - host: 10.0.1.21\n  - host: 10.0.1.22\n```\n\n----------------------------------------\n\nTITLE: Getting Current User (SQL)\nDESCRIPTION: The `CURRENT_USER()` function identifies the authenticated user for the current session, which aids in session management and security.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/information-functions.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT CURRENT_USER();\n```\n+----------------+\n| CURRENT_USER() |\n+----------------+\n| root@%         |\n+----------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Server Version in TiDB\nDESCRIPTION: This snippet explains how to configure the server version string in TiDB for compliance with security tools. Users must modify the server version in the configuration file or using TiUP commands.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/high-reliability-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  tidb:\n    server-version: 'YOUR_VERSION_STRING'\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster edit-config <cluster-name>\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster reload <cluster-name> -R tidb\n```\n\n----------------------------------------\n\nTITLE: Showing Create Table for Cached Table Metadata in SQL\nDESCRIPTION: SQL statement to show the create table syntax for the 'mysql.table_cache_meta' table, which stores metadata for cached tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/cached-tables.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW CREATE TABLE mysql.table_cache_meta\\G\n```\n\n----------------------------------------\n\nTITLE: Setting Partition Pruning Mode in TiDB SQL\nDESCRIPTION: Specifies whether to enable dynamic pruning mode for partitioned tables. This is an experimental feature in TiDB 5.1 with a default value of 'static'.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.0.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_partition_prune_mode = 'static'|'dynamic';\n```\n\n----------------------------------------\n\nTITLE: Collecting TiDB Cluster Diagnostic Data with Diag\nDESCRIPTION: Command to collect diagnostic data from a TiDB cluster for a specified time range using the TiUP diag tool.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag collect ${cluster-name} -f=\"-4h\" -t=\"-2h\"\n```\n\n----------------------------------------\n\nTITLE: Cloning WordPress TiDB Docker Repository\nDESCRIPTION: Git command to clone the sample WordPress repository with TiDB Docker configuration. Provides the initial setup for the WordPress deployment process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/dev-guide-wordpress.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https:\\/\\/github.com\\/Icemap\\/wordpress-tidb-docker.git\\ncd wordpress-tidb-docker\n```\n\n----------------------------------------\n\nTITLE: Calculating SM3 Hash in TiDB SQL\nDESCRIPTION: The SM3() function calculates a 256-bit ShangMi 3 (SM3) hash for the given argument. This is a TiDB extension not implemented in MySQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT SM3('abc');\n```\n\n----------------------------------------\n\nTITLE: Insert Statement Syntax Differences\nDESCRIPTION: Compares the syntax for insert statements where reading and writing to the same table is allowed in Oracle but not in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_25\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO table1 VALUES (field1,(SELECT field2 FROM table1 WHERE...))\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO table1 VALUES (field1,(SELECT T.fields2 FROM table1 T WHERE...))\n```\n\n----------------------------------------\n\nTITLE: Setting System Variable in TiDB\nDESCRIPTION: Example showing system variable tidb_multi_statement_mode default value change from WARN to OFF after upgrading from v4.0 to v5.0 or later.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.3.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_multi_statement_mode = 'OFF';\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP Package Manager\nDESCRIPTION: Downloads and installs the TiUP package manager using a curl command with HTTPS protocol and TLS 1.2\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in SQL\nDESCRIPTION: This SQL statement creates a table named `t1` in the `test` schema with an integer primary key column `id` and a varchar column `val`.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-protocol.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n\"CREATE TABLE test.t1(id int primary key, val varchar(16));\"\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Vector SQLAlchemy Integration\nDESCRIPTION: Command to install TiDB Vector base package for SQLAlchemy integration\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integration-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install tidb-vector\n```\n\n----------------------------------------\n\nTITLE: Output of Partitioned Table Query in TiDB\nDESCRIPTION: Shows the result of querying the PARTITIONS table for a specific partitioned table, displaying all metadata for both partitions including partition names, methods, expressions, and TiDB-specific information.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-partitions.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n*************************** 1. row ***************************\n                TABLE_CATALOG: def\n                 TABLE_SCHEMA: test\n                   TABLE_NAME: t1\n               PARTITION_NAME: p0\n            SUBPARTITION_NAME: NULL\n   PARTITION_ORDINAL_POSITION: 1\nSUBPARTITION_ORDINAL_POSITION: NULL\n             PARTITION_METHOD: HASH\n          SUBPARTITION_METHOD: NULL\n         PARTITION_EXPRESSION: `id`\n      SUBPARTITION_EXPRESSION: NULL\n        PARTITION_DESCRIPTION: \n                   TABLE_ROWS: 0\n               AVG_ROW_LENGTH: 0\n                  DATA_LENGTH: 0\n              MAX_DATA_LENGTH: 0\n                 INDEX_LENGTH: 0\n                    DATA_FREE: 0\n                  CREATE_TIME: 2022-12-14 06:09:33\n                  UPDATE_TIME: NULL\n                   CHECK_TIME: NULL\n                     CHECKSUM: NULL\n            PARTITION_COMMENT: \n                    NODEGROUP: NULL\n              TABLESPACE_NAME: NULL\n            TIDB_PARTITION_ID: 89\n   TIDB_PLACEMENT_POLICY_NAME: NULL\n*************************** 2. row ***************************\n                TABLE_CATALOG: def\n                 TABLE_SCHEMA: test\n                   TABLE_NAME: t1\n               PARTITION_NAME: p1\n            SUBPARTITION_NAME: NULL\n   PARTITION_ORDINAL_POSITION: 2\nSUBPARTITION_ORDINAL_POSITION: NULL\n             PARTITION_METHOD: HASH\n          SUBPARTITION_METHOD: NULL\n         PARTITION_EXPRESSION: `id`\n      SUBPARTITION_EXPRESSION: NULL\n        PARTITION_DESCRIPTION: \n                   TABLE_ROWS: 0\n               AVG_ROW_LENGTH: 0\n                  DATA_LENGTH: 0\n              MAX_DATA_LENGTH: 0\n                 INDEX_LENGTH: 0\n                    DATA_FREE: 0\n                  CREATE_TIME: 2022-12-14 06:09:33\n                  UPDATE_TIME: NULL\n                   CHECK_TIME: NULL\n                     CHECKSUM: NULL\n            PARTITION_COMMENT: \n                    NODEGROUP: NULL\n              TABLESPACE_NAME: NULL\n            TIDB_PARTITION_ID: 90\n   TIDB_PLACEMENT_POLICY_NAME: NULL\n2 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring In-memory Engine to Mitigate MVCC Versions\nDESCRIPTION: This TOML configuration enables the in-memory engine feature in TiKV to help manage MVCC version accumulation, at the cost of increased memory usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-performance-tuning-config.md#2025-04-18_snippet_14\n\nLANGUAGE: toml\nCODE:\n```\n[in-memory-engine]\nenable = true\n```\n\n----------------------------------------\n\nTITLE: Patching DM Cluster Components with TiUP\nDESCRIPTION: Commands to replace running components with temporary packages for debugging or hotfixes. It demonstrates how to patch all DM-master packages or a specific one in the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm patch --help\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm patch prod-cluster /tmp/dm-master-hotfix.tar.gz -R dm-master\n```\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm patch prod-cluster /tmp/dm--hotfix.tar.gz -N 172.16.4.5:8261\n```\n\n----------------------------------------\n\nTITLE: TiKV RaftStore Store Batch Size Configuration Parameter (Modified)\nDESCRIPTION: TiKV parameter that controls the maximum batch size for store operations. The maximum value has been set to 10240.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\nraftstore.store-max-batch-size\n```\n\n----------------------------------------\n\nTITLE: Querying Slow Log Within a Specific Time Range\nDESCRIPTION: SQL query to count slow queries and display the minimum and maximum timestamps within a specified time range, which searches through relevant slow log files.\nSOURCE: https://github.com/pingcap/docs/blob/master/identify-slow-queries.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nselect count(*),\n      min(time),\n      max(time)\nfrom slow_query\nwhere time > '2020-03-10 00:00:00'\n  and time < '2020-03-11 00:00:00';\n```\n\n----------------------------------------\n\nTITLE: INTEGER Type Declaration in SQL\nDESCRIPTION: Two equivalent syntaxes for declaring INTEGER/INT type with optional display width, unsigned flag and zero-fill option\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-numeric.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nINT[(M)] [UNSIGNED] [ZEROFILL]\n```\n\nLANGUAGE: sql\nCODE:\n```\nINTEGER[(M)] [UNSIGNED] [ZEROFILL]\n```\n\n----------------------------------------\n\nTITLE: Configuration for Raftstore Settings\nDESCRIPTION: This snippet covers various configuration options related to Raftstore in TiKV, including parameters for enabling prevotes, setting storage capacity, and more.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\nConfiguration items related to Raftstore.\n```\n\n----------------------------------------\n\nTITLE: Configuring AWS CLI\nDESCRIPTION: Command to set up AWS CLI with your account credentials. This configuration is required before executing any AWS command line operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-vpc-peering-connections.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naws configure\n```\n\n----------------------------------------\n\nTITLE: Executing TiCloud AI Command in Shell\nDESCRIPTION: Basic usage of the 'ticloud ai' command with optional flags. This command allows users to interact with the TiDB Bot for querying information about TiDB Cloud.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-ai.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud ai [flags]\n```\n\n----------------------------------------\n\nTITLE: Altering Table Schema in MySQL\nDESCRIPTION: DDL statement to modify the decimal precision of column c2 from DECIMAL(11,3) to DECIMAL(10,3)\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE db1.tbl1 CHANGE c2 c2 DECIMAL (10, 3);\n```\n\n----------------------------------------\n\nTITLE: Running TiCloud AI in Interactive Mode\nDESCRIPTION: Example of using the 'ticloud ai' command in interactive mode. This mode allows users to engage in a conversation with the TiDB Bot through CLI prompts.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-ai.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud ai\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Self-Managed Connection Environment Variables\nDESCRIPTION: Sample environment variable configuration for connecting to a self-managed TiDB cluster running locally.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_5\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_HOST=127.0.0.1\nTIDB_PORT=4000\nTIDB_USERNAME=root\nTIDB_PASSWORD=\nTIDB_DATABASE=test\n```\n\n----------------------------------------\n\nTITLE: TTL with JSON Type\nDESCRIPTION: Creates a table with TTL using JSON data type and extracted creation date for expiration.\nSOURCE: https://github.com/pingcap/docs/blob/master/time-to-live.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE orders (\n    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    order_info JSON,\n    created_at DATE AS (JSON_EXTRACT(order_info, '$.created_at')) VIRTUAL\n) TTL = `created_at` + INTERVAL 3 month;\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Configuration File\nDESCRIPTION: Command to create a .env file from the example template for storing database connection information.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Referencing GitHub Issue in Markdown\nDESCRIPTION: Examples of how GitHub issue references are formatted in the release notes, using Markdown syntax to create hyperlinks to the corresponding GitHub issues.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1-rc.4.md#2025-04-18_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n[#7941](https://github.com/pingcap/tidb/pull/7941)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Database and Running Migrations\nDESCRIPTION: Commands to create the database, run migrations, and seed sample data for the Rails application.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nbundle exec rails db:create\nbundle exec rails db:migrate\n```\n\n----------------------------------------\n\nTITLE: Viewing DDL Status in TiDB\nDESCRIPTION: The ADMIN SHOW DDL command is used to view the status of TiDB DDL operations, including schema version, DDL Owner details, and current DDL tasks.\nSOURCE: https://github.com/pingcap/docs/blob/master/ddl-introduction.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW DDL\n```\n\n----------------------------------------\n\nTITLE: Creating a Database User in TiDB Cloud Serverless\nDESCRIPTION: This SQL command shows how to create a new database user in a TiDB Cloud Serverless cluster, incorporating the required user name prefix.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/select-cluster-tier.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER '3pTAoNNegb47Uc8.jeffrey';\n```\n\n----------------------------------------\n\nTITLE: Displaying Warnings - SQL\nDESCRIPTION: This SQL query retrieves any warnings generated during prior SQL commands. It is particularly useful for diagnosing issues related to configuration modifications in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/dynamic-config.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nshow warnings;\n```\n\n----------------------------------------\n\nTITLE: Addressing StaleCommand Error Handling in TiDB\nDESCRIPTION: Fixes an issue where no error message was returned when SQL execution was blocked due to TiKV continuously returning StaleCommand errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_18\n\nLANGUAGE: SQL\nCODE:\n```\n-- Any SQL statement that might trigger StaleCommand errors\n```\n\n----------------------------------------\n\nTITLE: Ignore Error Rows Command in DM\nDESCRIPTION: Command syntax for ignoring error rows in validation. Allows marking specific error IDs or all errors as ignored.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-continuous-data-validation.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nUsage:\n  dmctl validation ignore-error <task-name> <error-id|--all> [flags]\n\nFlags:\n      --all    all errors\n      -h, --help   help for ignore-error\n```\n\n----------------------------------------\n\nTITLE: TiKV Leader Drop Alert Rule\nDESCRIPTION: Monitors sudden drops in TiKV leadership count. Alerts when leader count decreases by more than 10 in 30 seconds.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_17\n\nLANGUAGE: promql\nCODE:\n```\ndelta(tikv_pd_heartbeat_tick_total{type=\"leader\"}[30s]) < -10\n```\n\n----------------------------------------\n\nTITLE: Querying Data from TiDB Table\nDESCRIPTION: This SQL command retrieves all entries from the 'tab_tidb' table, showcasing the results of previously performed insert operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/post-installation-check.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nselect * from tab_tidb;\n```\n\n----------------------------------------\n\nTITLE: Selecting Data from Orders Stream - SQL\nDESCRIPTION: Executes a `SELECT` statement in ksqlDB to continuously retrieve and display records from the `ORDERS` stream.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/integrate-confluent-using-ticdc.md#2025-04-18_snippet_14\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM ORDERS EMIT CHANGES;\n```\n\n----------------------------------------\n\nTITLE: Checking Environment Variables in Shell\nDESCRIPTION: Commands to verify that the DATABASE_URL environment variable is correctly set in both local and Netlify environments.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n# check the environment variable for your own space\nenv | grep DATABASE_URL\n\n# check the environment variable for the Netlify space\nnetlify env:list\n```\n\n----------------------------------------\n\nTITLE: Manually Enabling GC After Interrupted Log Restore in TiDB\nDESCRIPTION: SQL command to manually enable garbage collection (GC) after an interrupted log restore by resetting the gc.ratio-threshold configuration parameter to its default value.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-checkpoint-restore.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET config tikv gc.ratio-threshold = 1.1;\n```\n\n----------------------------------------\n\nTITLE: Configuring TTL Job Settings\nDESCRIPTION: SQL commands to configure TTL job execution intervals and schedule windows.\nSOURCE: https://github.com/pingcap/docs/blob/master/time-to-live.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE orders TTL_JOB_INTERVAL = '48h';\nSET @@global.tidb_ttl_job_enable = OFF;\nSET @@global.tidb_ttl_job_schedule_window_start_time = '01:00 +0000';\nSET @@global.tidb_ttl_job_schedule_window_end_time = '05:00 +0000';\n```\n\n----------------------------------------\n\nTITLE: Retrieving Table Metadata via HTTP API\nDESCRIPTION: Shell command to fetch table metadata using cURL, helpful for investigating charset configurations during upgrades\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/upgrade-faq.md#2025-04-18_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ncurl \"http://$IP:10080/schema/test/t\" | python -m json.tool\n```\n\n----------------------------------------\n\nTITLE: Configuring TiSpark to Read from TiFlash in spark-defaults.conf\nDESCRIPTION: This snippet shows how to add a configuration item to the spark-defaults.conf file to set TiSpark to read data exclusively from TiFlash replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tispark-to-read-tiflash.md#2025-04-18_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nspark.tispark.isolation_read_engines tiflash\n```\n\n----------------------------------------\n\nTITLE: Enabling Unified Sorter in TiCDC\nDESCRIPTION: Enables the unified sorter feature by default in TiCDC, improving sorting performance for change data capture operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.10.md#2025-04-18_snippet_1\n\nLANGUAGE: Go\nCODE:\n```\n// GitHub PR: https://github.com/pingcap/tiflow/pull/1230\n// Implementation details not provided in the release notes\n```\n\n----------------------------------------\n\nTITLE: Deleting Records in TiDB with SQL\nDESCRIPTION: This SQL statement deletes a record from the 'person' table where the ID equals 2. It shows how to remove data based on a specific condition.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-tidb-crud-sql.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM person WHERE id=2;\n```\n\n----------------------------------------\n\nTITLE: Creating Table with CHECK Constraint Example\nDESCRIPTION: Demonstrates how to create a table with a CHECK constraint and enable the check constraint feature globally.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-check-constraints.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_check_constraint = ON;\nCREATE TABLE test.t1 (id INT PRIMARY KEY, CHECK (id%2 = 0));\nSELECT * FROM TIDB_CHECK_CONSTRAINTS\\G\n```\n\n----------------------------------------\n\nTITLE: Deleting TiDB Cloud Serverless Cluster in Non-Interactive Mode\nDESCRIPTION: This example shows how to delete a TiDB Cloud Serverless cluster using the CLI in non-interactive mode, where the cluster ID is specified directly in the command.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-delete.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless delete --cluster-id <cluster-id>\n```\n\n----------------------------------------\n\nTITLE: Backing Up a Database in TiDB\nDESCRIPTION: Example of backing up a single database to a local filesystem destination. The result includes details about the backup size, timestamp, and execution time.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-backup.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP DATABASE `test` TO 'local:///mnt/backup/2020/04/';\n```\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------+-----------+-----------------+---------------------+---------------------+\n| Destination                  | Size      | BackupTS        | Queue Time          | Execution Time      |\n+------------------------------+-----------+-----------------+---------------------+---------------------+\n| local:///mnt/backup/2020/04/ | 248665063 | 416099531454472 | 2020-04-12 23:09:48 | 2020-04-12 23:09:48 |\n+------------------------------+-----------+-----------------+---------------------+---------------------+\n1 row in set (58.453 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring MySQL Instances for Data Migration in YAML\nDESCRIPTION: This snippet shows the configuration for MySQL instances in a DM task. It includes settings for source identification, binlog position, routing rules, filtering, and processing unit configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/task-configuration-file-full.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nmysql-instances:\n  -\n    source-id: \"mysql-replica-01\"                   # The `source-id` in source.toml.\n    meta:\n      binlog-name: binlog.000001\n      binlog-pos: 4\n      binlog-gtid: \"03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170\"\n    route-rules: [\"route-rule-1\", \"route-rule-2\"]\n    filter-rules: [\"filter-rule-1\", \"filter-rule-2\"]\n    block-allow-list:  \"bw-rule-1\"\n    expression-filters: [\"even_c\"]\n    mydumper-config-name: \"global\"\n    loader-config-name: \"global\"\n    syncer-config-name: \"global\"\n    validator-config-name: \"global\"\n\n  -\n    source-id: \"mysql-replica-02\"\n    mydumper-thread: 4\n    loader-thread: 16\n    syncer-thread: 16\n```\n\n----------------------------------------\n\nTITLE: Configuring HAProxy Root Path Reverse Proxy for TiDB Dashboard\nDESCRIPTION: HAProxy configuration for proxying TiDB Dashboard at the root path. Includes simplified frontend and backend configuration with path rewriting.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-reverse-proxy.md#2025-04-18_snippet_8\n\nLANGUAGE: haproxy\nCODE:\n```\nfrontend tidb_dashboard_front\n  bind *:8033\n  use_backend tidb_dashboard_back\nbackend tidb_dashboard_back\n  mode http\n  http-request set-path /dashboard%[path]\n  server tidb_dashboard 192.168.0.123:2379\n```\n\n----------------------------------------\n\nTITLE: Example Output of DDL Job Query Lookup\nDESCRIPTION: This example shows the result of looking up the original SQL statement for job ID 51, which created a table. The output includes the exact SQL query that was used to initiate the DDL operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-show-ddl.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ADMIN SHOW DDL JOB QUERIES 51;\n+--------------------------------------------------------------+\n| QUERY                                                        |\n+--------------------------------------------------------------+\n| CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment) |\n+--------------------------------------------------------------+\n1 row in set (0.02 sec)\n```\n\n----------------------------------------\n\nTITLE: Basic SHOW TRAFFIC JOBS Example\nDESCRIPTION: Demonstrates how to execute the SHOW TRAFFIC JOBS command to display current traffic capture or replay jobs across TiProxy instances. Shows job details including start time, instance, type, progress, and status.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-traffic-jobs.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TRAFFIC JOBS;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB DDL Reorg Parameters in SQL\nDESCRIPTION: Changes tidb_ddl_reorg_worker_cnt and tidb_ddl_reorg_batch_size to global variables for more flexible DDL reorganization control.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.4.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_ddl_reorg_worker_cnt = <value>;\nSET GLOBAL tidb_ddl_reorg_batch_size = <value>;\n```\n\n----------------------------------------\n\nTITLE: Running the Sample Application\nDESCRIPTION: Command to execute the Ruby sample application that connects to TiDB and performs CRUD operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nruby app.rb\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW STATS_HISTOGRAMS in TiDB\nDESCRIPTION: The SHOW STATS_HISTOGRAMS statement runs within the TiDB environment to show histogram information of database tables. This example performs a direct execution of the statement, illustrating how to fetch statistical data without conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-histograms.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW STATS_HISTOGRAMS;\n```\n\n----------------------------------------\n\nTITLE: Dump RocksDB Manifest\nDESCRIPTION: This command dumps the manifest file of a given RocksDB, which is vital for understanding the database’s state.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_24\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl ldb --hex manifest_dump --path=/tmp/db/MANIFEST-000001\n```\n\n----------------------------------------\n\nTITLE: Error Message from Multiple Table Joins\nDESCRIPTION: The error message returned when trying to execute a non-transactional DML statement with tables not related to the shard column in the WHERE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/non-transactional-dml.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\n(1054, \"Unknown column 't3.id' in 'where clause'\")\n```\n\n----------------------------------------\n\nTITLE: Displaying System Variable Compatibility Changes Table in Markdown\nDESCRIPTION: A markdown table listing system variables that have been modified or newly added in TiDB v6.1.0, including their change types and descriptions. The table shows variable names, change types (Modified/Newly added), and detailed descriptions of each change.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.0.md#2025-04-18_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n| Variable name | Change type | Description |\n|---|---|---|\n| [`tidb_enable_list_partition`](/system-variables.md#tidb_enable_list_partition-new-in-v50) | Modified | The default value is changed from `OFF` to `ON`. |\n| [`tidb_mem_quota_query`](/system-variables.md#tidb_mem_quota_query) | Modified | This variable adds the GLOBAL scope, and the variable value persists to the cluster. |\n| [`tidb_query_log_max_len`](/system-variables.md#tidb_query_log_max_len) | Modified | The variable scope is changed from INSTANCE to GLOBAL. The variable value persists to the cluster, and the value range is changed to `[0, 1073741824]`. |\n| [`require_secure_transport`](/system-variables.md#require_secure_transport-new-in-v610) | Newly added | This setting was previously a `tidb.toml` option (`security.require-secure-transport`), but changed to a system variable starting from TiDB v6.1.0. |\n| [`tidb_committer_concurrency`](/system-variables.md#tidb_committer_concurrency-new-in-v610) | Newly added | This setting was previously a `tidb.toml` option (`performance.committer-concurrency`), but changed to a system variable starting from TiDB v6.1.0. |\n| [`tidb_enable_auto_analyze`](/system-variables.md#tidb_enable_auto_analyze-new-in-v610) | Newly added | This setting was previously a `tidb.toml` option (`run-auto-analyze`), but changed to a system variable starting from TiDB v6.1.0. |\n| [`tidb_enable_new_only_full_group_by_check`](/system-variables.md#tidb_enable_new_only_full_group_by_check-new-in-v610) | Newly added | This variable controls the behavior when TiDB performs the `ONLY_FULL_GROUP_BY` check. |\n| [`tidb_enable_outer_join_reorder`](/system-variables.md#tidb_enable_outer_join_reorder-new-in-v610) | Newly added | Since v6.1.0, the Join Reorder algorithm of TiDB supports Outer Join. This variable controls the support behavior, and the default value is `ON`. |\n| [`tidb_enable_prepared_plan_cache`](/system-variables.md#tidb_enable_prepared_plan_cache-new-in-v610) | Newly added | This setting was previously a `tidb.toml` option (`prepared-plan-cache.enabled`), but changed to a system variable starting from TiDB v6.1.0. |\n| [`tidb_gc_max_wait_time`](/system-variables.md#tidb_gc_max_wait_time-new-in-v610) | Newly added | This variable is used to set the maximum time of GC safe point blocked by uncommitted transactions. |\n| [tidb_max_auto_analyze_time](/system-variables.md#tidb_max_auto_analyze_time-new-in-v610) | Newly added | This variable is used to specify the maximum execution time of auto analyze. |\n| [`tidb_max_tiflash_threads`](/system-variables.md#tidb_max_tiflash_threads-new-in-v610) | Newly added | This variable is used to set the maximum concurrency for TiFlash to execute a request. |\n| [`tidb_mem_oom_action`](/system-variables.md#tidb_mem_oom_action-new-in-v610) | Newly added | This setting was previously a `tidb.toml` option (`oom-action`), but changed to a system variable starting from TiDB v6.1.0. |\n| [`tidb_mem_quota_analyze`](/system-variables.md#tidb_mem_quota_analyze-new-in-v610) | Newly added | This variable controls the maximum memory usage when TiDB updates statistics, including manually executed [`ANALYZE TABLE`](/sql-statements/sql-statement-analyze-table.md) by users and automatic analyze tasks in the TiDB background. |\n| [`tidb_nontransactional_ignore_error`](/system-variables.md#tidb_nontransactional_ignore_error-new-in-v610) | Newly added | This variable specifies whether to return error immediately when an error occurs in a non-transactional DML statement. |\n| [`tidb_prepared_plan_cache_memory_guard_ratio`](/system-variables.md#tidb_prepared_plan_cache_memory_guard_ratio-new-in-v610) | Newly added | This setting was previously a `tidb.toml` option (`prepared-plan-cache.memory-guard-ratio`), but changed to a system variable starting from TiDB v6.1.0. |\n| [`tidb_prepared_plan_cache_size`](/system-variables.md#tidb_prepared_plan_cache_size-new-in-v610) | Newly added | This setting was previously a `tidb.toml` option (`prepared-plan-cache.capacity`), but changed to a system variable starting from TiDB v6.1.0. |\n| [`tidb_stats_cache_mem_quota`](/system-variables.md#tidb_stats_cache_mem_quota-new-in-v610) | Newly added | This variable sets the memory quota for the TiDB statistics cache. |\n```\n\n----------------------------------------\n\nTITLE: Configuring cert-allowed-cn for PD\nDESCRIPTION: This code snippet illustrates how to configure `cert-allowed-cn` in the PD configuration file. The specified list contains the allowed Common Names (CNs) for clients connecting to PD, ensuring only authorized components can communicate with it.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-tls-between-components.md#2025-04-18_snippet_12\n\nLANGUAGE: toml\nCODE:\n```\n    ```toml\n    [security]\n    cert-allowed-cn = [\"tidb\", \"pd\", \"tikv\", \"tiflash\", \"tiproxy\", \"test-client\", \"prometheus\"]\n    ```\n```\n\n----------------------------------------\n\nTITLE: String Character Set Specification\nDESCRIPTION: Syntax for specifying character set and collation for string literals.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n[_charset_name]'string' [COLLATE collation_name]\n```\n\n----------------------------------------\n\nTITLE: Accessing TiDB Dashboard Resource Manager URL\nDESCRIPTION: The URL pattern to access the Resource Manager page directly through a web browser. Replace the IP and port with actual PD instance details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-resource-manager.md#2025-04-18_snippet_0\n\nLANGUAGE: url\nCODE:\n```\nhttp://127.0.0.1:2379/dashboard/#/resource_manager\n```\n\n----------------------------------------\n\nTITLE: Default SSL Certificate Paths for mysql2 gem\nDESCRIPTION: Lists the default filesystem paths where the mysql2 gem searches for CA certificates across different operating systems and distributions.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_15\n\nLANGUAGE: markdown\nCODE:\n```\n1. /etc/ssl/certs/ca-certificates.crt # Debian / Ubuntu / Gentoo / Arch / Slackware\n2. /etc/pki/tls/certs/ca-bundle.crt # RedHat / Fedora / CentOS / Mageia / Vercel / Netlify\n3. /etc/ssl/ca-bundle.pem # OpenSUSE\n4. /etc/ssl/cert.pem # MacOS / Alpine (docker container)\n```\n\n----------------------------------------\n\nTITLE: SQL Partition Selection Syntax\nDESCRIPTION: Fixed partition selection syntax for hash partitioned tables, now supporting formats like 'partition (P0)' without throwing errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.1.1.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\npartition (P0)\n```\n\n----------------------------------------\n\nTITLE: Initializing a TiUP Mirror\nDESCRIPTION: This code snippet demonstrates the syntax for initializing a TiUP mirror using the `tiup mirror init` command. It specifies the path where the mirror files will be stored.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-init.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup mirror init <path> [flags]\"\n```\n\n----------------------------------------\n\nTITLE: Querying with Disabled tidb_opt_prefix_index_single_scan in TiDB\nDESCRIPTION: This SQL query demonstrates the execution plan when tidb_opt_prefix_index_single_scan is disabled, showing that a table lookup is required.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_65\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN FORMAT='brief' SELECT COUNT(1) FROM t WHERE a = 1 AND b IS NOT NULL;\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in TiDB\nDESCRIPTION: This SQL command creates a new table named 'tab_tidb' within the 'pingcap' database, defining its structure with columns and data types, facilitating data storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/post-installation-check.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE `tab_tidb` (\n    `id` int NOT NULL AUTO_INCREMENT,\n    `name` varchar(20) NOT NULL DEFAULT '',\n    `age` int NOT NULL DEFAULT 0,\n    `version` varchar(20) NOT NULL DEFAULT '',\n    PRIMARY KEY (`id`),\n    KEY `idx_age` (`age`));\n```\n\n----------------------------------------\n\nTITLE: Configuring Low Space Ratio in PD\nDESCRIPTION: Sets the threshold value for insufficient store space to 0.9. When a node's occupied space ratio exceeds this, PD tries to avoid migrating data to it.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nconfig set low-space-ratio 0.9\n```\n\n----------------------------------------\n\nTITLE: Consistency Check with tikv-ctl Shell\nDESCRIPTION: The consistency-check command is used to perform a Raft-region consistency verification among TiKV replicas. Dependencies include knowledge of the region leader and configurations in line with TiDB garbage collection mechanisms.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --host 127.0.0.1:20160 consistency-check -r 2\n```\n\nLANGUAGE: shell\nCODE:\n```\nsuccess!\n```\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --host 127.0.0.1:20161 consistency-check -r 2\n```\n\nLANGUAGE: shell\nCODE:\n```\nDebugClient::check_region_consistency: RpcFailure(RpcStatus { status: Unknown, details: Some(\"StringError(\\\"Leader is on store 1\\\")\") })\n```\n\n----------------------------------------\n\nTITLE: Displaying Global SQL Bindings in TiDB\nDESCRIPTION: Shows the current SQL bindings table with columns including original SQL, bound SQL, database, status, and other metadata.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-binding.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GLOBAL BINDINGS;\n```\n\n----------------------------------------\n\nTITLE: WithList EBNF Syntax Definition\nDESCRIPTION: The EBNF syntax definition for the WithList component of the WITH clause, showing how multiple Common Table Expressions can be combined.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-with.md#2025-04-18_snippet_1\n\nLANGUAGE: ebnf\nCODE:\n```\nWithList ::=\n        WithList ',' CommonTableExpr\n|       CommonTableExpr\n```\n\n----------------------------------------\n\nTITLE: Using HASH_JOIN Hint for View Query Block\nDESCRIPTION: Examples demonstrating HASH_JOIN hint usage with query blocks in views using QB_NAME notation.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_42\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ QB_NAME(v1_1, v2.v1@SEL_2) hash_join(t@v1_1) */ * FROM v2;\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ QB_NAME(v1_2, v2.v1@SEL_2 .@SEL_2) hash_join(t1@v1_2) hash_agg(@v1_2) */ * FROM v2;\n```\n\n----------------------------------------\n\nTITLE: Installing Offline TiUP Components\nDESCRIPTION: These commands extract the TiUP package and run the local installation script in the offline environment.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup-offline.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntar xzvf tidb-dm-${version}-linux-amd64.tar.gz\nsh tidb-dm-${version}-linux-amd64/local_install.sh\nsource /home/tidb/.bash_profile\n```\n\n----------------------------------------\n\nTITLE: Creating a Hash Partitioned Table in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a table partitioned by Hash with two partitions based on the 'id' column.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_40\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE example (\n  id INT PRIMARY KEY,\n  data VARCHAR(1024)\n)\nPARTITION BY HASH(id)\nPARTITIONS 2;\n```\n\n----------------------------------------\n\nTITLE: Unsupported Sequelize Feature: Adding Foreign Key\nDESCRIPTION: This code snippet illustrates an unsupported Sequelize operation in TiDB for adding a foreign key reference using queryInterface.addColumn.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-third-party-tools-compatibility.md#2025-04-18_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nqueryInterface.addColumn\n```\n\n----------------------------------------\n\nTITLE: Verifying Garbage Collection Status in TiDB\nDESCRIPTION: This SQL query checks the status of the garbage collection mechanism in TiDB by retrieving the value of the global variable tidb_gc_enable.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@global.tidb_gc_enable;\n```\n\n----------------------------------------\n\nTITLE: Setting TiSpark to Read from TiFlash in Thrift Server via Beeline\nDESCRIPTION: This SQL-like command can be used in a Beeline session connected to a Thrift server to configure TiSpark to read from TiFlash replicas.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tispark-to-read-tiflash.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nset spark.tispark.isolation_read_engines=tiflash\n```\n\n----------------------------------------\n\nTITLE: TiFlash Pipeline Execution Model Configuration\nDESCRIPTION: System variable to enable or disable the new experimental pipeline execution model in TiFlash for improved thread resource management\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.2.0.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_enable_tiflash_pipeline_model = ON;\n```\n\n----------------------------------------\n\nTITLE: Clustered vs Non-Clustered Primary Key Operations\nDESCRIPTION: Demonstrates the difference between dropping clustered and non-clustered primary keys in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/constraints.md#2025-04-18_snippet_14\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t5 (a INT NOT NULL, b INT NOT NULL, PRIMARY KEY (a,b) CLUSTERED);\nALTER TABLE t5 DROP PRIMARY KEY;\n\nCREATE TABLE t5 (a INT NOT NULL, b INT NOT NULL, PRIMARY KEY (a,b) NONCLUSTERED);\nALTER TABLE t5 DROP PRIMARY KEY;\n```\n\n----------------------------------------\n\nTITLE: Dynamic Mode Query Example\nDESCRIPTION: Demonstrates the simplified execution plan in dynamic mode without Union operator for the same query.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_76\n\nLANGUAGE: sql\nCODE:\n```\nmysql> set @@session.tidb_partition_prune_mode = 'dynamic';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> explain select * from t1 where id < 150;\n```\n\n----------------------------------------\n\nTITLE: Examining CLUSTER_INFO Table Schema in TiDB\nDESCRIPTION: This SQL command shows the structure of the CLUSTER_INFO table in the information_schema database, displaying all available fields and their data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-info.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\ndesc cluster_info;\n```\n\n----------------------------------------\n\nTITLE: TiDB Cluster Startup Output\nDESCRIPTION: Example output showing successful TiDB cluster startup with connection endpoints\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_4\n\nLANGUAGE: log\nCODE:\n```\n🎉 TiDB Playground Cluster is started, enjoy!\n\nConnect TiDB:    mysql --comments --host 127.0.0.1 --port 4000 -u root\nTiDB Dashboard:  http://127.0.0.1:2379/dashboard\nGrafana:         http://127.0.0.1:3000\n```\n\n----------------------------------------\n\nTITLE: Using TiDB Cloud Serverless Driver in Netlify Edge Function\nDESCRIPTION: Code example demonstrating how to integrate the TiDB Cloud Serverless Driver with a Netlify Edge Function.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver.md#2025-04-18_snippet_5\n\nLANGUAGE: ts\nCODE:\n```\nimport { connect } from 'https://esm.sh/@tidbcloud/serverless'\n\nexport default async () => {\n  const conn = connect({url: Netlify.env.get('DATABASE_URL')})\n  const result = await conn.execute('show tables')\n  return new Response(JSON.stringify(result));\n}\n```\n\n----------------------------------------\n\nTITLE: Querying DM-master Information (Shell/JSON)\nDESCRIPTION: Example of using curl to query DM-master information via the API and the expected JSON response.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/cluster/masters' \\\n  -H 'accept: application/json'\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"total\": 1,\n  \"data\": [\n    {\n      \"name\": \"master1\",\n      \"alive\": true,\n      \"leader\": true,\n      \"addr\": \"127.0.0.1:8261\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Pausing Query Execution with SLEEP() in SQL\nDESCRIPTION: This function pauses the execution of queries for a specified number of seconds. It returns 0 after the sleep completes.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT SLEEP(1.5);\n```\n\n----------------------------------------\n\nTITLE: Editing TiUP Topology Configuration in Shell\nDESCRIPTION: This command opens the topology configuration file for editing using the TiUP cluster edit-config command. It allows modification of cluster parameters before upgrading.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster edit-config <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Running commands with TiUP Cloud\nDESCRIPTION: This snippet shows the command format to run commands using the TiDB Cloud CLI installed via TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ntiup cloud serverless create\n```\n\n----------------------------------------\n\nTITLE: Replaying Failed TiUP Cluster Operations in Shell\nDESCRIPTION: This command retries a failed TiDB cluster operation, such as an interrupted upgrade. It uses the audit ID obtained from the tiup cluster audit command.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster replay <audit-id>\n```\n\n----------------------------------------\n\nTITLE: Applying Placement Rules via PD Control\nDESCRIPTION: Bash commands for loading and saving placement rules configuration using pd-ctl tool.\nSOURCE: https://github.com/pingcap/docs/blob/master/two-data-centers-in-one-city-deployment.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules rule-bundle load --out=\"default.json\"\npd-ctl config placement-rules rule-bundle save --in=\"rule.json\"\n```\n\n----------------------------------------\n\nTITLE: Analyzing SQL Execution with EXPLAIN ANALYZE\nDESCRIPTION: Uses the EXPLAIN ANALYZE statement to show actual performance plans and execution information for DML statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0-rc.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT * FROM table_name;\n```\n\n----------------------------------------\n\nTITLE: Truncate Log Backup Example\nDESCRIPTION: Example command to truncate log backup data until a specific timestamp with S3 storage configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log truncate --until='2022-07-26 21:20:00+0800' \\\n--storage='s3://backup-101/logbackup?access-key=${access-key}&secret-access-key=${secret-access-key}'\n```\n\n----------------------------------------\n\nTITLE: Stopping HAProxy Process in Bash\nDESCRIPTION: Command to terminate the HAProxy process using its process ID. This uses the kill -9 signal to force immediate termination.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/haproxy-best-practices.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nkill -9 ${haproxy.pid}\n```\n\n----------------------------------------\n\nTITLE: Configuring TSO Servers in YAML\nDESCRIPTION: Example configuration for TSO (Timestamp Oracle) servers showing host machine specifications for timestamp service deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-topology-reference.md#2025-04-18_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\ntso_servers:\n  - host: 10.0.1.21\n  - host: 10.0.1.22\n```\n\n----------------------------------------\n\nTITLE: Checking CPU Interrupt Distribution\nDESCRIPTION: Command to observe the distribution of NIC interrupts across CPUs, which is useful for diagnosing uneven interrupt handling.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-operating-system.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n/proc/interrupts\n```\n\n----------------------------------------\n\nTITLE: Querying Tables with Specific Attributes in SQL\nDESCRIPTION: Shows how to find all tables and partitions that have a specific attribute using a SELECT statement with a LIKE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/table-attributes.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.attributes WHERE attributes LIKE '%key%';\n```\n\n----------------------------------------\n\nTITLE: Creating Local Temporary Table in SQL\nDESCRIPTION: SQL statement to create a local temporary table for storing the top 50 eldest authors, visible only to the current session.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TEMPORARY TABLE top_50_eldest_authors (\n    id BIGINT,\n    name VARCHAR(255),\n    age INT,\n    PRIMARY KEY(id)\n);\n```\n\n----------------------------------------\n\nTITLE: Verifying Document Deletion with a Vector Search in Python\nDESCRIPTION: Performs a vector search after document deletion to verify that the deleted document is no longer available in the search results.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nquery_engine = index.as_query_engine()\nresponse = query_engine.query(\"What did the author learn?\")\nprint(textwrap.fill(str(response), 100))\n```\n\n----------------------------------------\n\nTITLE: Get Position of Second Occurrence in TiDB\nDESCRIPTION: This snippet shows how to find the position of the second occurrence of a character in a string in both Oracle and TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_21\n\nLANGUAGE: sql\nCODE:\n```\nINSTR('stst','s',1,2)\n```\n\nLANGUAGE: sql\nCODE:\n```\nLENGTH(SUBSTRING_INDEX('stst','s',2)) + 1\n```\n\n----------------------------------------\n\nTITLE: Time Value Conversion Example in MySQL\nDESCRIPTION: Demonstrates how TiDB automatically converts date/time values into numeric types when needed in calculations.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-date-and-time.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT NOW(), NOW()+0, NOW(3)+0;\n```\n\n----------------------------------------\n\nTITLE: Fixing DATE_ADD Function with Negative Interval (SQL)\nDESCRIPTION: Addresses an issue where the DATE_ADD function produced incorrect results when given a negative INTERVAL value.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.16.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nDATE_ADD(date, INTERVAL -1 DAY)\n```\n\n----------------------------------------\n\nTITLE: Verifying Role Removal in TiDB\nDESCRIPTION: SQL commands to check user privileges and attempt to set a dropped role, demonstrating the effects of role removal.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-role.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS;\nSET ROLE analyticsteam;\n```\n\n----------------------------------------\n\nTITLE: Cloning the sample app repository\nDESCRIPTION: Git commands to clone the sample code repository and navigate to the project directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysqljs.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/tidb-samples/tidb-nodejs-mysqljs-quickstart.git\ncd tidb-nodejs-mysqljs-quickstart\n```\n\n----------------------------------------\n\nTITLE: Adding APPROX_PERCENTILE Aggregate Function in TiDB\nDESCRIPTION: Adds support for the new aggregate function APPROX_PERCENTILE in TiDB. This function allows for approximate percentile calculations in SQL queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.8.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nAPPROX_PERCENTILE(column_name, percentile)\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable for Prisma TiDB Cloud Connection in Vercel\nDESCRIPTION: This environment variable is automatically added to your Vercel project when using the TiDB Cloud Vercel integration with Prisma framework.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-vercel.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nDATABASE_URL\n```\n\n----------------------------------------\n\nTITLE: Using Non-Reserved Keywords as Identifiers in TiDB SQL\nDESCRIPTION: This example shows that non-reserved keywords like BEGIN and END can be used as identifiers without backticks in TiDB SQL statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/keywords.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE `select` (BEGIN int, END int);\n```\n\n----------------------------------------\n\nTITLE: PD Lock Granularity Optimization\nDESCRIPTION: The granularity of locks in PD is optimized to reduce lock contention and improve the capability of processing heartbeat in high concurrency scenarios. This optimization enhances the overall performance and stability of the PD component.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.3.md#2025-04-18_snippet_1\n\n\n\n----------------------------------------\n\nTITLE: Listing Only Installed Components\nDESCRIPTION: Command to display only the components and versions that are currently installed on the system, providing a quick overview of local TiUP components.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-list.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup list --installed\n```\n\n----------------------------------------\n\nTITLE: Describing the COLLATIONS Table Schema in TiDB\nDESCRIPTION: This SQL command displays the structure of the COLLATIONS table in the information_schema database, showing the column definitions and data types.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-collations.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC collations;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------+-------------+------+------+---------+-------+\n| Field              | Type        | Null | Key  | Default | Extra |\n+--------------------+-------------+------+------+---------+-------+\n| COLLATION_NAME     | varchar(32) | YES  |      | NULL    |       |\n| CHARACTER_SET_NAME | varchar(32) | YES  |      | NULL    |       |\n| ID                 | bigint(11)  | YES  |      | NULL    |       |\n| IS_DEFAULT         | varchar(3)  | YES  |      | NULL    |       |\n| IS_COMPILED        | varchar(3)  | YES  |      | NULL    |       |\n| SORTLEN            | bigint(3)   | YES  |      | NULL    |       |\n+--------------------+-------------+------+------+---------+-------+\n6 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Hexadecimal and binary ASCII character expressions example\nDESCRIPTION: This example shows how to load data using hexadecimal and binary ASCII character expressions to define field delimiters and enclosing characters.  This allows using non-standard characters for data formatting during the load process.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-load-data.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nLOAD DATA LOCAL INFILE '/mnt/evo970/data-sets/bikeshare-data/2017Q4-capitalbikeshare-tripdata.csv' INTO TABLE trips FIELDS TERMINATED BY x'2c' ENCLOSED BY b'100010' LINES TERMINATED BY '\\r\\n' IGNORE 1 LINES (duration, start_date, end_date, start_station_number, start_station, end_station_number, end_station, bike_number, member_type);\n```\n\n----------------------------------------\n\nTITLE: IMPORT INTO Statement with Disabled Precheck\nDESCRIPTION: SQL statement for importing data while bypassing compatibility checks using the DISABLE_PRECHECK option\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-compatibility-and-scenarios.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nIMPORT INTO table_name FROM 'file_path' WITH OPTIONS (DISABLE_PRECHECK)\n```\n\n----------------------------------------\n\nTITLE: Disabling tidb_opt_prefix_index_single_scan in TiDB\nDESCRIPTION: This SQL command disables the tidb_opt_prefix_index_single_scan optimization feature in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/system-variables.md#2025-04-18_snippet_64\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_opt_prefix_index_single_scan = 'OFF';\n```\n\n----------------------------------------\n\nTITLE: Show Table Schema SQL Query\nDESCRIPTION: SQL command to display the create table statement for the target merged table schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE shard_db.shard_table;\n```\n\n----------------------------------------\n\nTITLE: Deleting Data from TiDB with Spring Data JPA\nDESCRIPTION: This Java code demonstrates how to delete a player entity by ID from TiDB using the deleteById method from JpaRepository.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-spring-boot.md#2025-04-18_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nplayerRepository.deleteById(id);\n```\n\n----------------------------------------\n\nTITLE: Backing Up to External Storage in TiDB\nDESCRIPTION: Examples of backing up data to external storage services like S3, including credentials management for cloud environments.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-backup.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP DATABASE `test` TO 's3://example-bucket-2020/backup-05/?access-key={YOUR_ACCESS_KEY}&secret-access-key={YOUR_SECRET_KEY}';\n```\n\nLANGUAGE: sql\nCODE:\n```\nBACKUP DATABASE `test` TO 's3://example-bucket-2020/backup-05/'\n    SEND_CREDENTIALS_TO_TIKV = FALSE;\n```\n\n----------------------------------------\n\nTITLE: Full Cluster Compaction with tikv-ctl\nDESCRIPTION: Command to perform full cluster compaction using tikv-ctl, which consumes significant I/O and CPU resources\nSOURCE: https://github.com/pingcap/docs/blob/master/storage-engine/titan-configuration.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntikv-ctl --pd <PD_ADDR> compact-cluster --bottommost force\n```\n\n----------------------------------------\n\nTITLE: Dump Existing RocksDB in HEX\nDESCRIPTION: This command dumps the content of an existing RocksDB in hexadecimal format. It helps in analyzing the database structure.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_23\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl ldb --hex --db=/tmp/db dump\n```\n\n----------------------------------------\n\nTITLE: Using EXPLAIN FORMAT in TiDB\nDESCRIPTION: Returns an empty set when executing EXPLAIN with 'dot' format for a connection, fixing previous incorrect behavior.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.17.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nEXPLAIN FORMAT=\"dot\" FOR CONNECTION connection_id;\n```\n\n----------------------------------------\n\nTITLE: Cloning the TiDB Rails Sample Repository\nDESCRIPTION: Commands to clone the sample application repository and navigate to the project directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-rails.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/tidb-samples/tidb-ruby-rails-quickstart.git\ncd tidb-ruby-rails-quickstart\n```\n\n----------------------------------------\n\nTITLE: Using NEXT VALUE FOR Function in TiDB\nDESCRIPTION: This snippet demonstrates the use of NEXT VALUE FOR function, which is an alias for NEXTVAL(), to get the next value from sequence 's1'.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/sequence-functions.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT NEXT VALUE FOR s1;\n```\n\n----------------------------------------\n\nTITLE: Creating User with Password History Limit in SQL\nDESCRIPTION: SQL command to create a new user with a password reuse policy that prohibits reusing the last 5 passwords.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_22\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE USER 'test'@'localhost' PASSWORD HISTORY 5;\n```\n\n----------------------------------------\n\nTITLE: Monitoring TiDB Lightning Migration Progress\nDESCRIPTION: This section provides information on monitoring the migration progress of TiDB Lightning, detailing how to use log files, monitoring dashboards, and web interfaces to check the ongoing migration status.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-shards-to-tidb.md#2025-04-18_snippet_5\n\nLANGUAGE: plaintext\nCODE:\n```\nAfter starting the migration task, you can check the progress by using either of the following methods:\n- Use `grep` tool to search the keyword `progress` in the log. By default, a message reporting the progress is flushed into the log file every 5 minutes.\n- View progress via the monitoring dashboard. For more information, see [TiDB Lightning Monitoring]( /tidb-lightning/monitor-tidb-lightning.md).\n- View the progress via the Web page. See [Web Interface](/tidb-lightning/tidb-lightning-web-interface.md).\n```\n\n----------------------------------------\n\nTITLE: Creating Placement Rule via HTTP API\nDESCRIPTION: HTTP POST request to configure placement rules for TiFlash replication, specifying replication group and constraints\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/troubleshoot-tiflash.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST -d '{\n    \"group_id\": \"pd\",\n    \"id\": \"default\",\n    \"start_key\": \"\",\n    \"end_key\": \"\",\n    \"role\": \"voter\",\n    \"count\": 3,\n    \"location_labels\": [\n    \"host\"\n    ]\n}' <http://172.16.x.xxx:2379/pd/api/v1/config/rule>\n```\n\n----------------------------------------\n\nTITLE: Building and Invoking TiDB AWS Lambda Function\nDESCRIPTION: Commands to build the bundle and invoke the sample Lambda function using SAM CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\nsam local invoke --env-vars env.json -e events/event.json \"tidbHelloWorldFunction\"\n```\n\n----------------------------------------\n\nTITLE: Executing ALTER INSTANCE RELOAD TLS in SQL\nDESCRIPTION: Example SQL statement to reload TLS certificates, keys, and CA files for a TiDB instance.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-instance.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nALTER INSTANCE RELOAD TLS;\n```\n\n----------------------------------------\n\nTITLE: Setting Local TiUP Mirror Path\nDESCRIPTION: Command to configure TiUP to use a local file directory as the mirror source for component downloads and management.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-terminology-and-concepts.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nTIUP_MIRRORS=/path/to/local tiup list\n```\n\n----------------------------------------\n\nTITLE: Enabling All Roles with SET ROLE ALL in TiDB SQL\nDESCRIPTION: SQL commands to enable all roles for the current session using SET ROLE ALL, followed by a query to check the current roles.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-role.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET ROLE ALL;\nSELECT CURRENT_ROLE();\n```\n\n----------------------------------------\n\nTITLE: Explaining Query Execution Before ANALYZE\nDESCRIPTION: SQL command to explain the execution plan for a query on table 't1' before running ANALYZE, showing inaccurate statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-analyze-table.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nEXPLAIN SELECT * FROM t1 WHERE c1 = 3;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Thread Pool in YAML\nDESCRIPTION: YAML frontmatter for the TiKV thread pool tuning documentation, specifying the title, summary, and aliases for the page.\nSOURCE: https://github.com/pingcap/docs/blob/master/tune-tikv-thread-performance.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: Tune TiKV Thread Pool Performance\nsummary: Learn how to tune TiKV thread pools for optimal performance.\naliases: ['/docs/dev/tune-tikv-thread-performance/']\n---\n```\n\n----------------------------------------\n\nTITLE: Cloning the TiDB Vector Python Repository\nDESCRIPTION: Command to clone the tidb-vector-python repository which contains example code for integrating TiDB Vector Search with SQLAlchemy.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-sqlalchemy.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/pingcap/tidb-vector-python.git\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Store IO Pool Size\nDESCRIPTION: Configuration item for TiKV that can be dynamically modified to facilitate more flexible performance tuning.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.6.0.md#2025-04-18_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\nstore-io-pool-size\n```\n\n----------------------------------------\n\nTITLE: Generating DROP STATS Statements for SQL\nDESCRIPTION: Generates DROP STATS SQL statements for all tables with statistics version 2 to facilitate a switch in statistics versions.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DISTINCT(CONCAT('DROP STATS ', table_schema, '.', table_name, ';'))\nFROM information_schema.tables JOIN mysql.stats_histograms\nON table_id = tidb_table_id\nWHERE stats_ver = 2;\n```\n\n----------------------------------------\n\nTITLE: Using the Alias Command for Branch Description in Shell\nDESCRIPTION: An alternative alias command that can be used instead of 'ticloud serverless branch describe' to get branch information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-describe.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch get [flags]\n```\n\n----------------------------------------\n\nTITLE: Python Script Update for Table Region Analysis\nDESCRIPTION: Script 'table-regions.py' was optimized to display leader distribution information by table within TiKV clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.0-rc.1.md#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntable-regions.py\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Connection in .env File\nDESCRIPTION: Example of environment variables to be set in the .env file for connecting to TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_3\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_HOST={host}\nTIDB_PORT=4000\nTIDB_USER={user}\nTIDB_PASSWORD={password}\nTIDB_DATABASE=test\nTIDB_ENABLE_SSL=true\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP on Control Machine\nDESCRIPTION: Commands to install TiUP and the DM component on the control machine. Requires curl and uses the TiUP mirror.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\n```\n\nLANGUAGE: shell\nCODE:\n```\ntiup install dm dmctl\n```\n\n----------------------------------------\n\nTITLE: Describing CLUSTER_TIDB_INDEX_USAGE Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the CLUSTER_TIDB_INDEX_USAGE table in the INFORMATION_SCHEMA database, showing all columns including the additional INSTANCE field.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-index-usage.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC CLUSTER_TIDB_INDEX_USAGE;\n```\n\n----------------------------------------\n\nTITLE: PD gRPC Gateway Configuration Option\nDESCRIPTION: Shows the configuration option 'enable-grpc-gateway' that enables the gRPC gateway feature of etcd in PD.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.1.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- Add the `enable-grpc-gateway` configuration option to enable the gRPC gateway feature of etcd [#1596](https://github.com/pingcap/pd/pull/1596)\n```\n\n----------------------------------------\n\nTITLE: Generating CA Certificate for TiDB Data Migration\nDESCRIPTION: Command to generate a self-signed CA certificate valid for 1000 days using the previously created CA key.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nopenssl req -new -x509 -days 1000 -key ca-key.pem -out ca.pem\n```\n\n----------------------------------------\n\nTITLE: Initializing Netlify Site Configuration in Shell\nDESCRIPTION: Command to start the Netlify site setup process, which configures continuous deployment from your GitHub repository.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nnetlify init\n```\n\n----------------------------------------\n\nTITLE: Describing TiDB Cloud Serverless Cluster in Non-Interactive Mode\nDESCRIPTION: Example of using the describe command in non-interactive mode, where the cluster ID is specified directly in the command.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-describe.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless describe --cluster-id <cluster-id>\n```\n\n----------------------------------------\n\nTITLE: Set Operations Syntax Differences\nDESCRIPTION: Illustrates the differences between using MINUS in Oracle and EXCEPT in TiDB to get results between two queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_29\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 MINUS SELECT * FROM t2\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t1 EXCEPT SELECT * FROM t2\n```\n\n----------------------------------------\n\nTITLE: BIGINT Type Declaration in SQL\nDESCRIPTION: Syntax for declaring BIGINT type with optional display width, unsigned flag and zero-fill option\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-numeric.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nBIGINT[(M)] [UNSIGNED] [ZEROFILL]\n```\n\n----------------------------------------\n\nTITLE: Calibrate Resource with Start and End Time\nDESCRIPTION: SQL example demonstrating resource calibration using specific start and end timestamps.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-calibrate-resource.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCALIBRATE RESOURCE START_TIME '2023-04-18 08:00:00' END_TIME '2023-04-18 08:20:00';\n```\n\n----------------------------------------\n\nTITLE: Showing Initial Table Schema in MySQL\nDESCRIPTION: SQL command to display the create table statement for the initial schema of db1.tbl1\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSHOW CREATE TABLE db1.tbl1;\n```\n\n----------------------------------------\n\nTITLE: Querying Table Regions with WHERE Clause in TiDB SQL\nDESCRIPTION: Adds support for using a WHERE clause in the SHOW TABLE REGIONS syntax to filter region results.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.17.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW TABLE ... REGIONS WHERE ...\n```\n\n----------------------------------------\n\nTITLE: Listing Serverless Import Tasks - Non-Interactive Mode with Cluster ID\nDESCRIPTION: Command to list import tasks for a specific cluster in non-interactive mode, requiring explicit cluster ID specification\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-import-list.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless import list --cluster-id <cluster-id>\n```\n\n----------------------------------------\n\nTITLE: Installing OpenSSL on Debian/Ubuntu\nDESCRIPTION: Command to install OpenSSL on Debian or Ubuntu operating systems using the apt package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\napt install openssl\n```\n\n----------------------------------------\n\nTITLE: New SQL Syntax Support in TiDB 2.0.4\nDESCRIPTION: Example of newly supported SQL syntax for dropping columns with CASCADE option in ALTER TABLE statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.0.4.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE t DROP COLUMN a CASCADE\n```\n\n----------------------------------------\n\nTITLE: Check TiDB Version Using SQL\nDESCRIPTION: This SQL command retrieves the version information of the TiDB server, helping to confirm the correct installation and version compatibility.\nSOURCE: https://github.com/pingcap/docs/blob/master/post-installation-check.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nselect tidb_version()\\G\n```\n\n----------------------------------------\n\nTITLE: Executing Basic TiUP Update Command\nDESCRIPTION: Basic syntax for updating TiUP components, allowing specification of single or multiple components with optional version targeting\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-update.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup update [component1][:version] [component2..N] [flags]\n```\n\n----------------------------------------\n\nTITLE: Enabling Relay Log in DM v2.0.2-v5.3.0\nDESCRIPTION: Command to enable relay log for a data source and specify workers in DM versions between v2.0.2 and v5.3.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/relay-log.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nstart-relay -s mysql-replica-01 worker1 worker2\n```\n\n----------------------------------------\n\nTITLE: Checking Scheduling Progress of Placement Policies SQL\nDESCRIPTION: The SQL command checks the progress of applying placement policies asynchronously across a cluster, important for ensuring policy enforcement.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSHOW PLACEMENT;\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies\nDESCRIPTION: Pip command to install required packages including Django, django-tidb, and mysqlclient for the sample application.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Allowing Region Merging for a Partition in SQL\nDESCRIPTION: Shows how to allow merging of Regions belonging to a specific partition by setting the merge_option attribute to 'allow'.\nSOURCE: https://github.com/pingcap/docs/blob/master/table-attributes.md#2025-04-18_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE t PARTITION p ATTRIBUTES 'merge_option=allow';\n```\n\n----------------------------------------\n\nTITLE: Uploading Diagnostic Data to Clinic Server\nDESCRIPTION: Command to upload collected diagnostic data directly to the Clinic Server when internet access is available.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag upload\n```\n\n----------------------------------------\n\nTITLE: Truncating Log Backup Data in TiDB\nDESCRIPTION: Command to delete log backup data before a specified time point, used for managing backup retention periods.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-use-overview.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntiup br log truncate\n```\n\n----------------------------------------\n\nTITLE: Variable Configuration Change - tidb_multi_statement_mode\nDESCRIPTION: Default value change for tidb_multi_statement_mode variable to OFF for clusters upgrading from v4.0 to v5.1.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.1.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_multi_statement_mode = 'OFF';\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for TiDB Cloud Serverless\nDESCRIPTION: Environment variables configuration for connecting to a TiDB Cloud Serverless cluster with TLS encryption enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_4\n\nLANGUAGE: dotenv\nCODE:\n```\nDATABASE_HOST={host}\nDATABASE_PORT=4000\nDATABASE_USER={user}\nDATABASE_PASSWORD={password}\nDATABASE_NAME=test\nDATABASE_ENABLE_SSL=true\n```\n\n----------------------------------------\n\nTITLE: Altering User Password History Limit in SQL\nDESCRIPTION: SQL command to modify an existing user's password reuse policy to prohibit reusing the last 5 passwords.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_23\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER 'test'@'localhost' PASSWORD HISTORY 5;\n```\n\n----------------------------------------\n\nTITLE: Terminating ANALYZE Task in SQL\nDESCRIPTION: SQL statement to terminate a running ANALYZE task using its task ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_29\n\nLANGUAGE: SQL\nCODE:\n```\nKILL TIDB ${id};\n```\n\n----------------------------------------\n\nTITLE: Decoding Binary Plans with TIDB_DECODE_BINARY_PLAN in SQL\nDESCRIPTION: This snippet demonstrates how to use the TIDB_DECODE_BINARY_PLAN function to decode binary plans from the STATEMENTS_SUMMARY table. It requires the tidb_generate_binary_plan variable to be set to ON.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT BINARY_PLAN,TIDB_DECODE_BINARY_PLAN(BINARY_PLAN) FROM information_schema.STATEMENTS_SUMMARY LIMIT 1\\G\n```\n\n----------------------------------------\n\nTITLE: TiDB Configuration for JWT Authentication in TOML\nDESCRIPTION: Configures the JWKS path in the TiDB configuration file to enable token-based authentication\nSOURCE: https://github.com/pingcap/docs/blob/master/security-compatibility-with-mysql.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[security]\nauth-token-jwks = \"JWKS.json\"\n```\n\n----------------------------------------\n\nTITLE: Deploy with TiProxy\nDESCRIPTION: Command to deploy TiDB cluster with TiProxy component and custom configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground v8.5.0 --tiproxy 1 --db.config tidb.toml\n```\n\n----------------------------------------\n\nTITLE: JSON Search Functions\nDESCRIPTION: Functions for searching and extracting data from JSON documents, including path-based extraction and containment checking.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nJSON_CONTAINS()\nJSON_CONTAINS_PATH()\nJSON_EXTRACT()\n->\n->>\nJSON_KEYS()\nJSON_SEARCH()\nMEMBER OF()\nJSON_OVERLAPS()\n```\n\n----------------------------------------\n\nTITLE: Retrieving Uncompressed Length in TiDB SQL\nDESCRIPTION: The UNCOMPRESSED_LENGTH() function returns the first 4 bytes of compressed data, which store the length of the original uncompressed string before compression with COMPRESS().\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_11\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT UNCOMPRESSED_LENGTH(0x03000000789C72747206040000FFFF018D00C7);\n```\n\n----------------------------------------\n\nTITLE: Creating a test table for gh-ost examples\nDESCRIPTION: SQL commands to create a test database and a 'person' table with 'id' and 'name' columns, then populating it with sample data.\nSOURCE: https://github.com/pingcap/docs/blob/master/styles/config/vocabularies/PingCAP/accept.txt#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE IF NOT EXISTS test;\n\nUSE test;\n\nCREATE TABLE IF NOT EXISTS person (\n  id INT NOT NULL PRIMARY KEY,\n  name VARCHAR(32) NOT NULL\n);\n\nINSERT INTO person (id, name) VALUES (1, 'Tom'), (2, 'Jerry');\n```\n\n----------------------------------------\n\nTITLE: Setting Spending Limit in Non-Interactive Mode - TiDB Cloud CLI - Shell\nDESCRIPTION: This command allows setting the spending limit for a TiDB Cloud Serverless cluster in non-interactive mode by specifying the necessary flags. It requires the 'cluster-id' and 'monthly' parameters for operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-spending-limit.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless spending-limit -c <cluster-id> --monthly <spending-limit-monthly>\n```\n\n----------------------------------------\n\nTITLE: Testing Disk Performance with Fio (Random Read)\nDESCRIPTION: This command uses `fio` to perform a random read test on a disk. It specifies parameters like the I/O engine (`psync`), block size (`32k`), file synchronization (`fdatasync=1`), read/write pattern (`randread`), and the filename for the test.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/deploy-and-maintain-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\n./fio -ioengine=psync -bs=32k -fdatasync=1 -thread -rw=randread -size=10G -filename=fio_randread_test.txt -name='fio randread test' -iodepth=4 -runtime=60 -numjobs=4 -group_reporting --output-format=json --output=fio_randread_result.json\n\n```\n\n----------------------------------------\n\nTITLE: Describing CLUSTER_TIDB_TRX Table Structure in SQL\nDESCRIPTION: This SQL snippet describes the structure of the CLUSTER_TIDB_TRX table, which provides transaction information across all TiDB nodes. It includes column details such as field names, data types, primary key, and other metadata.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-trx.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC CLUSTER_TIDB_TRX;\n```\n\n----------------------------------------\n\nTITLE: Describing TiDB Cloud Serverless Cluster in Interactive Mode\nDESCRIPTION: Example of using the describe command in interactive mode, where the CLI will prompt for necessary information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-describe.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless describe\n```\n\n----------------------------------------\n\nTITLE: Adding Primary Key Constraint in TiDB\nDESCRIPTION: Prevents adding a primary key to a table that already has no primary key or an existing integer primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.17.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE table_name ADD PRIMARY KEY (column_name);\n```\n\n----------------------------------------\n\nTITLE: SHOW CREATE TABLE Syntax Definition in EBNF\nDESCRIPTION: The formal syntax definition for the SHOW CREATE TABLE statement using Extended Backus-Naur Form (EBNF) notation.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-table.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShowCreateTableStmt ::=\n    \"SHOW\" \"CREATE\" \"TABLE\" (SchemaName \".\")? TableName\n```\n\n----------------------------------------\n\nTITLE: ORDER BY Example with Partial Sorting\nDESCRIPTION: A SQL query demonstrating the use of ORDER BY with a single field (class). This example shows how TiDB only sorts by the specified column, which can lead to unstable ordering within each class grouping if additional ORDER BY fields aren't specified.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-unstable-result-set.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nmysql> select a.class, a.stuname, b.course, b.courscore from stu_info a join stu_score b on a.stuno=b.stuno order by a.class;\n+------------+--------------+-------------------------+-----------+\n| class      | stuname      | course                  | courscore |\n+------------+--------------+-------------------------+-----------+\n| 2018_CS_01 | MonkeyDLuffy | PrinciplesofDatabase    |      60.5 |\n| 2018_CS_01 | MonkeyDLuffy | English                 |      43.0 |\n| 2018_CS_01 | MonkeyDLuffy | OpSwimming              |      67.0 |\n| 2018_CS_01 | MonkeyDLuffy | OpFencing               |      76.0 |\n| 2018_CS_01 | MonkeyDLuffy | FundamentalsofCompiling |      88.0 |\n| 2018_CS_01 | MonkeyDLuffy | OperatingSystem         |      90.5 |\n| 2018_CS_01 | MonkeyDLuffy | PrincipleofStatistics   |      69.0 |\n| 2018_CS_01 | MonkeyDLuffy | ProbabilityTheory       |      76.0 |\n| 2018_CS_01 | MonkeyDLuffy | Physics                 |      63.5 |\n| 2018_CS_01 | MonkeyDLuffy | AdvancedMathematics     |      95.5 |\n| 2018_CS_01 | MonkeyDLuffy | LinearAlgebra           |      92.5 |\n| 2018_CS_01 | MonkeyDLuffy | DiscreteMathematics     |      89.0 |\n| 2018_CS_03 | SpongeBob    | PrinciplesofDatabase    |      88.0 |\n| 2018_CS_03 | SpongeBob    | English                 |      79.0 |\n| 2018_CS_03 | SpongeBob    | OpBasketball            |      92.0 |\n| 2018_CS_03 | SpongeBob    | OpTennis                |      94.0 |\n| 2018_CS_03 | PatrickStar  | LinearAlgebra           |       6.5 |\n| 2018_CS_03 | PatrickStar  | AdvancedMathematics     |       5.0 |\n| 2018_CS_03 | SpongeBob    | DiscreteMathematics     |      72.0 |\n| 2018_CS_03 | PatrickStar  | ProbabilityTheory       |      12.0 |\n| 2018_CS_03 | PatrickStar  | PrincipleofStatistics   |      20.0 |\n| 2018_CS_03 | PatrickStar  | OperatingSystem         |      36.0 |\n| 2018_CS_03 | PatrickStar  | FundamentalsofCompiling |       2.0 |\n| 2018_CS_03 | PatrickStar  | DiscreteMathematics     |      14.0 |\n| 2018_CS_03 | PatrickStar  | PrinciplesofDatabase    |       9.0 |\n| 2018_CS_03 | PatrickStar  | English                 |      60.0 |\n| 2018_CS_03 | PatrickStar  | OpTableTennis           |      12.0 |\n| 2018_CS_03 | PatrickStar  | OpPiano                 |      99.0 |\n| 2018_CS_03 | SpongeBob    | FundamentalsofCompiling |      43.0 |\n| 2018_CS_03 | SpongeBob    | OperatingSystem         |      95.0 |\n| 2018_CS_03 | SpongeBob    | PrincipleofStatistics   |      90.0 |\n| 2018_CS_03 | SpongeBob    | ProbabilityTheory       |      87.0 |\n| 2018_CS_03 | SpongeBob    | Physics                 |      65.0 |\n| 2018_CS_03 | SpongeBob    | AdvancedMathematics     |      55.0 |\n| 2018_CS_03 | SpongeBob    | LinearAlgebra           |      60.5 |\n| 2018_CS_03 | PatrickStar  | Physics                 |       6.0 |\n+------------+--------------+-------------------------+-----------+\n36 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Defining Enum and Set Types in JSON Schema\nDESCRIPTION: This JSON snippet shows the structure for Enum and Set types in schemas, defining the column name and type in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-cloud-storage.md#2025-04-18_snippet_17\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"ColumnName\":\"COL1\",\n    \"ColumnType\":\"{ENUM/SET}\"\n}\n```\n\n----------------------------------------\n\nTITLE: Deleting a Data Source with cURL in Shell\nDESCRIPTION: This example demonstrates how to delete a data source by making a DELETE request to the DM API. The 'force=true' parameter ensures the operation proceeds even if there are dependencies.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'DELETE' \\\n  'http://127.0.0.1:8261/api/v1/sources/mysql-01?force=true' \\\n  -H 'accept: application/json'\n```\n\n----------------------------------------\n\nTITLE: Creating New Grafana Package\nDESCRIPTION: Commands to create a new Grafana package for TiUP by compressing the modified files\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-monitoring-services.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd grafana-v{version}-linux-amd64\ntar -zcvf ../grafana-v{new-version}.tar.gz ./\n```\n\n----------------------------------------\n\nTITLE: Adding Column with Default Value in SQL\nDESCRIPTION: SQL statements to add a new column 'Age' with different default values to sharded tables, demonstrating a scenario that can lead to data inconsistency in optimistic mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-shard-merge-optimistic.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE `tbl01` ADD COLUMN `Age` INT DEFAULT 0;\n```\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE `tbl00` ADD COLUMN `Age` INT DEFAULT -1;\n```\n\n----------------------------------------\n\nTITLE: Using NO_INDEX_MERGE_JOIN Optimizer Hint - SQL\nDESCRIPTION: This snippet shows how to prevent the optimizer from using the index nested loop merge join algorithm with the NO_INDEX_MERGE_JOIN hint on the specified tables, granting developers more control over how joins are processed in their queries.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nSELECT /*+ NO_INDEX_MERGE_JOIN(t1, t2) */ * FROM t1, t2 WHERE t1.id = t2.id;\n```\n\n----------------------------------------\n\nTITLE: Specifying Query Engine with Optimizer Hints in SQL\nDESCRIPTION: This SQL query demonstrates how to use the read_from_storage optimizer hint to specify the TiKV engine for the 'orders' table. It's part of a complex query involving window functions and common table expressions.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-hybrid-oltp-and-olap-queries.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nWITH orders_group_by_month AS (\n    SELECT\n        /*+ read_from_storage(tikv[o]) */\n        b.type AS book_type,\n        DATE_FORMAT(ordered_at, '%Y-%c') AS month,\n        COUNT(*) AS orders\n    FROM orders o\n    LEFT JOIN books b ON o.book_id = b.id\n    WHERE b.type IS NOT NULL\n    GROUP BY book_type, month\n), acc AS (\n    SELECT\n        book_type,\n        month,\n        SUM(orders) OVER(PARTITION BY book_type ORDER BY book_type, month ASC) as acc\n    FROM orders_group_by_month mo\n    ORDER BY book_type, month ASC\n)\nSELECT * FROM acc;\n```\n\n----------------------------------------\n\nTITLE: Querying TIDB_INDEXES Table Structure in SQL\nDESCRIPTION: This SQL query displays the structure of the TIDB_INDEXES table in the information_schema database, showing all fields and their properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-indexes.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC tidb_indexes;\n```\n\n----------------------------------------\n\nTITLE: Incorrect Hint Placement Example\nDESCRIPTION: Demonstrates syntax error when hint is placed in wrong location within SQL query.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_54\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * /*+ use_index(t, a) */ FROM t;\nSHOW WARNINGS;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+---------+------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Level   | Code | Message                                                                                                                                                                                                                                 |\n+---------+------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Warning | 1064 | You have an error in your SQL syntax; check the manual that corresponds to your TiDB version for the right syntax to use [parser:8066]Optimizer hint can only be followed by certain keywords like SELECT, INSERT, etc. |\n+---------+------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n1 row in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Setting Global Variable for Cached Table Lease in SQL\nDESCRIPTION: SQL statement to set the global variable 'tidb_table_cache_lease' which controls the write latency for cached tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/cached-tables.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nset @@global.tidb_table_cache_lease = 10;\n```\n\n----------------------------------------\n\nTITLE: SQL Schema Modification Fix - ALTER Column Default\nDESCRIPTION: Fix for ALTER COLUMN SET DEFAULT statement that was incorrectly updating table schema\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.1.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE table_name ALTER COLUMN column_name SET DEFAULT default_value\n```\n\n----------------------------------------\n\nTITLE: Updating TiUP Cluster Tools\nDESCRIPTION: Commands to upgrade TiUP and its cluster component to ensure compatibility with dashboard location display feature.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-security.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup update --self\ntiup update cluster --force\n```\n\n----------------------------------------\n\nTITLE: Querying TiDB-Specific Variables\nDESCRIPTION: SQL example showing how to list all TiDB-specific variables using the SHOW GLOBAL VARIABLES statement with a LIKE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-variables.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW GLOBAL VARIABLES LIKE 'tidb%';\n```\n\n----------------------------------------\n\nTITLE: Altering User Password in TiDB\nDESCRIPTION: Change the password for an existing user using ALTER USER statement, which is the preferred method to update user credentials.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-account-management.md#2025-04-18_snippet_19\n\nLANGUAGE: sql\nCODE:\n```\nALTER USER 'test'@'localhost' IDENTIFIED BY 'mypass';\n```\n\n----------------------------------------\n\nTITLE: Describing KEYWORDS Table Structure in TiDB INFORMATION_SCHEMA\nDESCRIPTION: This SQL snippet describes the structure of the KEYWORDS table in the INFORMATION_SCHEMA database, showing the fields, their types, and other attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-keywords.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC keywords;\n```\n\n----------------------------------------\n\nTITLE: TiUP Mirror Rotate Command Syntax\nDESCRIPTION: Basic command for rotating the TiUP mirror configuration, which opens an editor to modify root.json and initiates a signing process\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-rotate.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror rotate [flags]\n```\n\n----------------------------------------\n\nTITLE: SHUTDOWN Statement Syntax in EBNF\nDESCRIPTION: The EBNF (Extended Backus-Naur Form) syntax definition for the SHUTDOWN statement in TiDB, which is a simple statement with no additional parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-shutdown.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nShutdownStmt ::=\n    \"SHUTDOWN\"\n```\n\n----------------------------------------\n\nTITLE: Running Branch Describe in Non-Interactive Mode\nDESCRIPTION: Example of running the branch describe command in non-interactive mode, specifying all required parameters as flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-describe.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch describe --branch-id <branch-id> --cluster-id <cluster-id>\n```\n\n----------------------------------------\n\nTITLE: Command to verify gh-ost installation\nDESCRIPTION: Command to check that gh-ost is properly installed by displaying its version information.\nSOURCE: https://github.com/pingcap/docs/blob/master/styles/config/vocabularies/PingCAP/accept.txt#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngh-ost --version\n```\n\n----------------------------------------\n\nTITLE: Creating SqlSessionFactory for TiDB Connection\nDESCRIPTION: Java method to create a SqlSessionFactory using the MyBatis configuration file for connecting to TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-java-mybatis.md#2025-04-18_snippet_2\n\nLANGUAGE: java\nCODE:\n```\npublic SqlSessionFactory getSessionFactory() {\n    InputStream inputStream = Resources.getResourceAsStream(\"mybatis-config.xml\");\n    SqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder().build(inputStream);\n}\n```\n\n----------------------------------------\n\nTITLE: Topology Configuration Template for TiSpark Deployment\nDESCRIPTION: YAML configuration template for defining TiSpark and related TiDB cluster components, including server specifications, IP addresses, and deployment configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-deployment-topology.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# Example configuration snippet referenced in documentation\n# Demonstrates basic topology for TiSpark deployment\n```\n\n----------------------------------------\n\nTITLE: NVL2 Function Comparison\nDESCRIPTION: Compares the NVL2 function from Oracle with IF statements in TiDB for checking NULL conditions.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nNVL2(key, val1, val2)\n```\n\nLANGUAGE: sql\nCODE:\n```\nIF(key is NOT NULL, val1, val2)\n```\n\n----------------------------------------\n\nTITLE: Creating Table with AUTO_RANDOM Column\nDESCRIPTION: Example of creating a table with an AUTO_RANDOM column and viewing the maximum implicit allocation times using SHOW WARNINGS.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-random.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t (a BIGINT AUTO_RANDOM, b VARCHAR(255), PRIMARY KEY (a));\nSHOW WARNINGS;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+-------+------+---------------------------------------------------------+\n| Level | Code | Message                                                 |\n+-------+------+---------------------------------------------------------+\n| Note  | 1105 | Available implicit allocation times: 288230376151711743 |\n+-------+------+---------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Enabling Placement Rules in PD Configuration\nDESCRIPTION: Configuration in the PD toml file to enable the Placement Rules feature before initializing the cluster. This setting is enabled by default in TiDB v5.0+.\nSOURCE: https://github.com/pingcap/docs/blob/master/configure-placement-rules.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[replication]\nenable-placement-rules = true\n```\n\n----------------------------------------\n\nTITLE: Updating TiDB Cloud CLI via TiUP\nDESCRIPTION: This snippet shows the command to update the TiDB Cloud CLI component through TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ntiup update cloud\n```\n\n----------------------------------------\n\nTITLE: Running sync-diff-inspector in Shell\nDESCRIPTION: This command runs sync-diff-inspector to check data consistency between upstream and downstream clusters.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-mysql.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nsync_diff_inspector -C ./config.yaml\n```\n\n----------------------------------------\n\nTITLE: Adding Days to a Date in TiDB\nDESCRIPTION: Demonstrates adding days to a date in both Oracle and TiDB, emphasizing the use of INTERVAL for TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nDATEVAL + n\n```\n\nLANGUAGE: sql\nCODE:\n```\nDATE_ADD(dateVal,INTERVAL n DAY)\n```\n\n----------------------------------------\n\nTITLE: TiFlash Feature Reference\nDESCRIPTION: Configuration reference for new TiFlash replica status checking tools added for online rolling updates.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.12.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ntiflash replica\n```\n\n----------------------------------------\n\nTITLE: Converting Table Charset to UTF8MB4\nDESCRIPTION: SQL command to modify table charset to UTF8MB4, recommended solution for charset compatibility after v2.1.3\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/upgrade-faq.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nalter table t convert to character set utf8mb4;\n```\n\n----------------------------------------\n\nTITLE: Generating SSH Key\nDESCRIPTION: Create SSH key for establishing trust between cluster machines\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-no-sudo-mode.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nssh-keygen\n```\n\n----------------------------------------\n\nTITLE: Installing Wrangler CLI for Cloudflare Workers\nDESCRIPTION: Command to install Wrangler, the official Cloudflare Worker CLI, using npm.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-cloudflare.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install wrangler\n```\n\n----------------------------------------\n\nTITLE: Show Create Table - Auto_Increment Max Value SQL\nDESCRIPTION: Reference to implementation showing maximum value for current Auto_Increment ID in Show Create Table output.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-1.0.5.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW CREATE TABLE table_name;\n```\n\n----------------------------------------\n\nTITLE: Inserting Values with Explicit AUTO_INCREMENT Values in TiDB\nDESCRIPTION: Example showing how to insert a row with an explicitly specified value for the AUTO_INCREMENT column.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t(id, c) VALUES (6, 6);\n```\n\n----------------------------------------\n\nTITLE: Downloading exported data from TiDB Cloud Serverless (interactive)\nDESCRIPTION: Downloads exported data from TiDB Cloud Serverless in interactive mode.  The command prompts the user for necessary information, such as cluster ID and export ID.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-download.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export download\n```\n\n----------------------------------------\n\nTITLE: Defining the TRUNCATE Statement Syntax\nDESCRIPTION: This code defines the syntax for the TRUNCATE statement using an EBNF diagram. It outlines how the table name should be structured in the statement. No specific dependencies are required for understanding this syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-truncate.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\nTruncateTableStmt ::= \\n    \"TRUNCATE\" ( \"TABLE\" )? TableName\\n\\nTableName ::=\\n    (Identifier \".\")? Identifier\n```\n\n----------------------------------------\n\nTITLE: Defining Warning Alert Rule for TiCDC Changefeed Error in YAML\nDESCRIPTION: YAML configuration for a warning alert rule that triggers when a TiCDC replication task encounters an error.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-alert-rules.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n(max_over_time(ticdc_owner_status[1m]) == 1 or max_over_time(ticdc_owner_status[1m]) == 6) > 0\n```\n\n----------------------------------------\n\nTITLE: Equivalent Query Used for Row Count Estimation\nDESCRIPTION: The optimizer internally translates the original query into this form when estimating row counts, leveraging the correlation information from extended statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/extended-statistics.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM t WHERE col1 <= 1 OR col1 IS NULL;\n```\n\n----------------------------------------\n\nTITLE: Viewing Resource Group Definition in TiDB SQL\nDESCRIPTION: SQL example showing how to use the SHOW CREATE RESOURCE GROUP statement to view the definition of the previously created resource group 'rg1'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-resource-group.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW CREATE RESOURCE GROUP rg1;\n```\n\n----------------------------------------\n\nTITLE: Compacting TiFlash Table Replica\nDESCRIPTION: SQL command to compact TiFlash replica data after upgrading to v6.2.0 for converting to new format.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash-upgrade-guide.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE <table_name> COMPACT tiflash replica;\n```\n\n----------------------------------------\n\nTITLE: Stopping a DM-master Node (Shell)\nDESCRIPTION: Example of using curl to stop a DM-master node via the API.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'DELETE' \\\n  'http://127.0.0.1:8261/api/v1/cluster/masters/master1' \\\n  -H 'accept: */*'\n```\n\n----------------------------------------\n\nTITLE: Setting US Region for Diag\nDESCRIPTION: Command to configure Diag to use US region for data upload and encryption\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag config clinic.region US\n```\n\n----------------------------------------\n\nTITLE: Index Key Example in TiDB\nDESCRIPTION: Concrete example of an encoded index key in TiDB storage, with table_id 22, index_id 5, and index_value 'abc'.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_10\n\nLANGUAGE: Go\nCODE:\n```\nt22_i5abc\n```\n\n----------------------------------------\n\nTITLE: Listing Managed DM Clusters\nDESCRIPTION: Command to list all DM clusters managed by TiUP, showing cluster name, user, version, and key information.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-tiup.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup dm list\n```\n\n----------------------------------------\n\nTITLE: Error Message Template JSON Structure\nDESCRIPTION: Standard JSON error response format used by the TiCDC API, containing error message and error code fields.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api-v2.md#2025-04-18_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"error_msg\": \"\",\n    \"error_code\": \"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Dropping Table with Conditional Check in SQL\nDESCRIPTION: Shows how to drop a table with a conditional check to prevent errors if the table does not exist.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sql-development-specification.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\ndrop table if exists table_name\n```\n\n----------------------------------------\n\nTITLE: Scaling in a TiKV Node in TiDB Cluster\nDESCRIPTION: This command removes a TiKV node from the specified host in a TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster scale-in <cluster-name> --node 10.0.1.5:20160\n```\n\n----------------------------------------\n\nTITLE: Capturing Traffic with tiproxyctl\nDESCRIPTION: This shell command is used to connect to a TiProxy instance and capture traffic for a specified duration, saving it to a directory in TiProxy's local storage.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-traffic-replay.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiproxyctl traffic capture --host 10.0.1.10 --port 3080 --output=\"/tmp/traffic\" --duration=1h\n```\n\n----------------------------------------\n\nTITLE: Testing IPv4-mapped Addresses with IS_IPV4_MAPPED() in SQL\nDESCRIPTION: This function tests whether the given argument is an IPv4-mapped address. It returns 1 if the argument is an IPv4-mapped address, otherwise 0.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/miscellaneous-functions.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT IS_IPV4_MAPPED(INET6_ATON('::ffff:127.0.0.1'));\n```\n\n----------------------------------------\n\nTITLE: TiKV RocksDB Background Jobs Configuration Parameter (Modified)\nDESCRIPTION: TiKV parameter that controls the maximum number of concurrent background jobs in RocksDB. Default values are now CPU-dependent, with 9 for 10-core machines and 7 for 8-core machines.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_9\n\nLANGUAGE: toml\nCODE:\n```\nrocksdb.max-background-jobs\n```\n\n----------------------------------------\n\nTITLE: TiDB Self-Managed Connection Command\nDESCRIPTION: Example command to connect to a local TiDB Self-Managed cluster using MySQL CLI.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-get-started-using-sql.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmysql --comments --host 127.0.0.1 --port 4000 -u root\n```\n\n----------------------------------------\n\nTITLE: Installing dependencies for an existing project\nDESCRIPTION: npm command to install mysql and dotenv packages for an existing Node.js project.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-mysqljs.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nnpm install mysql dotenv --save\n```\n\n----------------------------------------\n\nTITLE: Configuration Setting for TiDB Snapshot\nDESCRIPTION: Example of setting the tidb_snapshot configuration value to TSO (Timestamp Oracle) format.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.0.4.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET tidb_snapshot = 'TSO_VALUE'\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB as jennifer user\nDESCRIPTION: Shell command to connect to TiDB as the jennifer user using the MySQL client.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-role.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 127.0.0.1 -P 4000 -u jennifer\n```\n\n----------------------------------------\n\nTITLE: TiProxy Configuration Setting Example\nDESCRIPTION: Example of setting TiProxy configuration using a TOML file with tiproxyctl\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-command-line-flags.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ cat test.toml\n[log]\nlevel='warning'\n$ cat test.toml | tiproxyctl config set\n\"\"\n$ tiproxyctl config get | grep level\nlevel = 'warning'\n```\n\n----------------------------------------\n\nTITLE: Concatenate Strings in TiDB\nDESCRIPTION: Demonstrates concatenating strings using the concatenation operator in Oracle and CONCAT function in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_17\n\nLANGUAGE: sql\nCODE:\n```\n'a' || 'b'\n```\n\nLANGUAGE: sql\nCODE:\n```\nCONCAT('a','b')\n```\n\n----------------------------------------\n\nTITLE: Querying Binlog Skip Help Command\nDESCRIPTION: Command to display help information for the binlog skip subcommand\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/handle-failed-ddl-statements.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nbinlog skip -h\n```\n\n----------------------------------------\n\nTITLE: Deploy PD Microservices\nDESCRIPTION: Command to deploy TiDB cluster with PD microservices mode including TSO and scheduling services.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ntiup playground v8.5.0 --pd.mode ms --pd 3 --tso 2 --scheduling 2\n```\n\n----------------------------------------\n\nTITLE: Adding PRE_SPLIT_REGIONS Table Option in TiDB SQL\nDESCRIPTION: Adds the PRE_SPLIT_REGIONS table option to support Region presplit, addressing hotspot issues in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.13.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nPRE_SPLIT_REGIONS\n```\n\n----------------------------------------\n\nTITLE: Markdown System Variable Configuration\nDESCRIPTION: Code reference showing the system variable tidb_analyze_version configuration change in the documentation.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.4.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[`tidb_analyze_version`](/system-variables.md#tidb_analyze_version-new-in-v510)\n```\n\n----------------------------------------\n\nTITLE: ANALYZE TABLE for PREDICATE COLUMNS in SQL\nDESCRIPTION: Performs the ANALYZE command on table 't' specifically for PREDICATE COLUMNS to collect relevant statistics.\nSOURCE: https://github.com/pingcap/docs/blob/master/statistics.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nANALYZE TABLE t PREDICATE COLUMNS;\n```\n\n----------------------------------------\n\nTITLE: Creating Sysbench Test Database\nDESCRIPTION: SQL command to create the 'sbtest' database in TiDB that will be used for Sysbench benchmark testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/benchmark-tidb-using-sysbench.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\ncreate database sbtest;\n```\n\n----------------------------------------\n\nTITLE: Updating Diag to Latest Version\nDESCRIPTION: Command to update the Diag tool to its latest version using TiUP\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup update diag\n```\n\n----------------------------------------\n\nTITLE: Setting a User-Defined Variable in TiDB\nDESCRIPTION: Sets a user-defined variable '@favorite_db' with the value 'TiDB'. User-defined variables are session-specific and prefixed with '@'.\nSOURCE: https://github.com/pingcap/docs/blob/master/user-defined-variables.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSET @favorite_db = 'TiDB';\n```\n\n----------------------------------------\n\nTITLE: DDL Lock Unlock Help Command\nDESCRIPTION: Shows help information for the unlock subcommand which is used to forcefully unlock unresolved DDL locks\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/manually-handling-sharding-ddl-locks.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nshard-ddl-lock unlock -h\n```\n\n----------------------------------------\n\nTITLE: Checking TiUP Version\nDESCRIPTION: Command to check the installed version of TiUP, which displays the version number, Go version, Git reference, and Git hash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-overview.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntiup --version\n```\n\nLANGUAGE: bash\nCODE:\n```\n1.14.0 tiup\nGo Version: go1.21.4\nGit Ref: v1.14.0\nGitHash: c3e9fc518aea0da66a37f82ee5a516171de9c372\n```\n\n----------------------------------------\n\nTITLE: Request Unit (RU) Consumption Metric\nDESCRIPTION: Measurement of system resource consumption using a unified Request Unit abstraction in TiDB resource control\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-explain-analyze.md#2025-04-18_snippet_13\n\nLANGUAGE: json\nCODE:\n```\n\"RU\":273.842670\n```\n\n----------------------------------------\n\nTITLE: Setting TiKV Labels via Command Line and Configuration\nDESCRIPTION: This section provides command-line instructions and a configuration example in shell and TOML formats for setting the 'labels' for TiKV and TiFlash. This is essential for identifying instances based on their locations.\nSOURCE: https://github.com/pingcap/docs/blob/master/schedule-replicas-by-topology-labels.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntikv-server --labels zone=<zone>,dc=<dc>,rack=<rack>,host=<host>\n```\n\nLANGUAGE: toml\nCODE:\n```\n[server]\n[server.labels]\nzone = \"<zone>\"\ndc = \"<dc>\"\nrack = \"<rack>\"\nhost = \"<host>\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Data Key Rotation Period\nDESCRIPTION: Sets the interval for rotating the data encryption key, important for maintaining data security.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_11\n\nLANGUAGE: TOML\nCODE:\n```\n\"security.encryption.data-key-rotation-period = \\\"7d\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Changing Column Charset Explicitly\nDESCRIPTION: SQL command to change column charset while maintaining compatibility during TiDB upgrades\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/upgrade-faq.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nalter table t change column a a varchar(20) character set utf8mb4;\n```\n\n----------------------------------------\n\nTITLE: Basic TiDB Cloud Logout Command\nDESCRIPTION: The base command for logging out of TiDB Cloud CLI with optional flags support.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-auth-logout.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud auth logout [flags]\n```\n\n----------------------------------------\n\nTITLE: Configuring Maximum Log Retention Days\nDESCRIPTION: Defines the maximum number of days to retain log files, allowing automatic cleanup of outdated logs.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_5\n\nLANGUAGE: TOML\nCODE:\n```\n\"log.file.max-days = 30\"\n```\n\n----------------------------------------\n\nTITLE: Resuming DM Task Using dmctl\nDESCRIPTION: Command to restart a data migration task after resolving an error using the dmctl tool.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-error-handling.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nresume-task ${task name}\n```\n\n----------------------------------------\n\nTITLE: Traffic Capture Command Example\nDESCRIPTION: Example of capturing traffic for one hour on a TiProxy instance\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-command-line-flags.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiproxyctl traffic capture --host 10.0.1.10 --port 3080 --output=\"/tmp/traffic\" --duration=1h\n```\n\n----------------------------------------\n\nTITLE: TiDB Cloud Logout Example\nDESCRIPTION: A simple example showing how to log out of TiDB Cloud CLI without any additional flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-auth-logout.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud auth logout\n```\n\n----------------------------------------\n\nTITLE: Setting TiFlash Replica for Partitioned Table\nDESCRIPTION: Adds a TiFlash replica to the partitioned employees table to enable analytical processing\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tiflash-mpp-mode.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nALTER table test.employees SET tiflash replica 1;\n```\n\n----------------------------------------\n\nTITLE: Configuring PD Replica Count\nDESCRIPTION: Configuration to set the number of Raft Group replicas for high availability.\nSOURCE: https://github.com/pingcap/docs/blob/master/geo-distributed-deployment-topology.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nreplication.max-replicas: 5\n```\n\n----------------------------------------\n\nTITLE: Setting Default Role in TiDB\nDESCRIPTION: SQL command to set a default role for a user, allowing automatic role activation upon login.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-role.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSET DEFAULT ROLE analyticsteam TO jennifer;\n```\n\n----------------------------------------\n\nTITLE: Adding Months to a Date in TiDB\nDESCRIPTION: This snippet shows how to add months to a date in both database systems, highlighting the use of INTERVAL in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nADD_MONTHS(dateVal,n)\n```\n\nLANGUAGE: sql\nCODE:\n```\nDATE_ADD(dateVal,INTERVAL n MONTH)\n```\n\n----------------------------------------\n\nTITLE: Adjusting ADD/CREATE INDEX Concurrency\nDESCRIPTION: Starting from v8.0.0, the concurrency of `ADD INDEX` and `CREATE INDEX` can be adjusted using the `tidb_ddl_reorg_worker_cnt` system variable.  The default value is `4`. You can adjust this system variable based on the workload of your cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n\"`tidb_ddl_reorg_worker_cnt`\"\n```\n\n----------------------------------------\n\nTITLE: Converting Vector to String in TiDB SQL\nDESCRIPTION: VEC_AS_TEXT function converts a vector type into its string representation.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-functions-and-operators.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT VEC_AS_TEXT('[1.000,   2.5]');\n```\n\n----------------------------------------\n\nTITLE: TiKV Parameter Configuration in YAML\nDESCRIPTION: This YAML snippet configures the `prefill-for-recycle` parameter in TiKV.  Enabling this parameter makes log recycling effective immediately after initialization. It is a TiKV configuration file setting.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v8.1-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n\"raft-engine.prefill-for-recycle = true\"\n```\n\n----------------------------------------\n\nTITLE: Deleting TiDB Cloud Serverless Cluster in Interactive Mode\nDESCRIPTION: This example demonstrates how to delete a TiDB Cloud Serverless cluster using the CLI in interactive mode, where the user is prompted for necessary information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-cluster-delete.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless delete\n```\n\n----------------------------------------\n\nTITLE: Querying TiKV Coprocessor Configuration\nDESCRIPTION: SQL query that filters the CLUSTER_CONFIG table to show only TiKV coprocessor-related configuration settings. This demonstrates how to retrieve specific configuration items for a particular component type.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-config.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM cluster_config WHERE type='tikv' AND `key` LIKE 'coprocessor%';\n```\n\n----------------------------------------\n\nTITLE: Unlocking DDL Lock Example\nDESCRIPTION: Example command to unlock a specific DDL lock by its ID\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/manually-handling-sharding-ddl-locks.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nshard-ddl-lock unlock test-`shard_db`.`shard_table`\n```\n\n----------------------------------------\n\nTITLE: Connecting to TiDB as jennifer\nDESCRIPTION: Shell command to connect to TiDB as the user jennifer.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-role.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nmysql -h 127.0.0.1 -P 4000 -u jennifer\n```\n\n----------------------------------------\n\nTITLE: Example of Using Table Alias in Point Queries\nDESCRIPTION: Example of a point query using a table alias which is now supported in TiDB 3.0.4.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.4.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nselect * from t tmp where a = \"aa\"\n```\n\n----------------------------------------\n\nTITLE: Converting Partitioned Table to Non-Partitioned in SQL\nDESCRIPTION: This SQL snippet shows how to remove partitioning from a table, effectively converting it to a non-partitioned table.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_45\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE members REMOVE PARTITIONING\n```\n\n----------------------------------------\n\nTITLE: Using BR Backup with Table Filters\nDESCRIPTION: Example of using table filters with BR backup tool to backup schemas matching 'foo*' and 'bar*' patterns\nSOURCE: https://github.com/pingcap/docs/blob/master/table-filter.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup br backup full -f 'foo*.*' -f 'bar*.*' -s 'local:///tmp/backup'\n```\n\n----------------------------------------\n\nTITLE: UTF8MB4 Character Set Test Cases\nDESCRIPTION: SQL examples demonstrating the handling of 4-byte emoji characters in utf8 vs utf8mb4 character sets.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE utf8_test (\n     c char(1) NOT NULL\n    ) CHARACTER SET utf8;\n\nCREATE TABLE utf8m4_test (\n     c char(1) NOT NULL\n    ) CHARACTER SET utf8mb4;\n\nINSERT INTO utf8_test VALUES ('😉');\nINSERT INTO utf8m4_test VALUES ('😉');\n\nSELECT char_length(c), length(c), c FROM utf8_test;\nSELECT char_length(c), length(c), c FROM utf8m4_test;\n```\n\n----------------------------------------\n\nTITLE: Subquery in SHOW Statement in SQL\nDESCRIPTION: Demonstrates the use of a subquery within a SHOW statement. This query filters columns based on a condition specified in the subquery.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.2.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW COLUMNS FROM tbl WHERE FIELDS IN (SELECT 'a')\n```\n\n----------------------------------------\n\nTITLE: Example pause-task Command with Response\nDESCRIPTION: Shows a complete example of pausing a task named 'test' and the expected JSON response including operation status and source details.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-pause-task.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npause-task test\n```\n\n----------------------------------------\n\nTITLE: Generating Private Key for DM-master Certificate\nDESCRIPTION: Command to generate a 2048-bit RSA private key for the DM-master component certificate.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nopenssl genrsa -out master-key.pem 2048\n```\n\n----------------------------------------\n\nTITLE: Defining TiDB Memory Usage Alert Rule in Prometheus\nDESCRIPTION: Alert rule to monitor TiDB memory usage. Triggers when usage exceeds 10 GB.\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_4\n\nLANGUAGE: prometheus\nCODE:\n```\ngo_memstats_heap_inuse_bytes{job=\"tidb\"} > 1e+10\n```\n\n----------------------------------------\n\nTITLE: Log4j Configuration Path\nDESCRIPTION: Reference to log4j configuration file addition in Spark environment\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.2.md#2025-04-18_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nlog4j\n```\n\n----------------------------------------\n\nTITLE: Defining ALTER INSTANCE Statement Syntax in EBNF\nDESCRIPTION: EBNF syntax diagram for the ALTER INSTANCE statement in TiDB, showing the structure of the statement including the RELOAD TLS option.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-instance.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nAlterInstanceStmt ::=\n    'ALTER' 'INSTANCE' InstanceOption\n\nInstanceOption ::=\n    'RELOAD' 'TLS' ('NO' 'ROLLBACK' 'ON' 'ERROR')?\n```\n\n----------------------------------------\n\nTITLE: Supporting Partitioned Tables in TiDB MVCC HTTP API\nDESCRIPTION: Extends support for partitioned tables in the HTTP API of the MVCC series.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_25\n\nLANGUAGE: SQL\nCODE:\n```\n-- HTTP API call for MVCC information on a partitioned table\n```\n\n----------------------------------------\n\nTITLE: Correcting NOT, ISTRUE, and ISFALSE Functions in TiDB SQL\nDESCRIPTION: Addresses incorrect results of the NOT, ISTRUE, and ISFALSE functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT NOT column, ISTRUE(column), ISFALSE(column) FROM table\n```\n\n----------------------------------------\n\nTITLE: Defining EXECUTE Statement Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) representation of the EXECUTE statement syntax in TiDB SQL.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-execute.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nExecuteStmt ::=\n    'EXECUTE' Identifier ( 'USING' UserVariable ( ',' UserVariable )* )?\n```\n\n----------------------------------------\n\nTITLE: Setting BDR Role to Primary\nDESCRIPTION: SQL commands showing how to set a cluster's BDR role to PRIMARY and verify the change.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-bdr-role.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SET BDR ROLE PRIMARY;\n```\n\nLANGUAGE: sql\nCODE:\n```\nQuery OK, 0 rows affected (0.01 sec)\n```\n\nLANGUAGE: sql\nCODE:\n```\nADMIN SHOW BDR ROLE;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+----------+\n| BDR_ROLE |\n+----------+\n| primary  |\n+----------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Querying Specific Resource Group\nDESCRIPTION: Shows how to query information about a specific resource group using WHERE clause.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-resource-groups.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.resource_groups WHERE NAME = 'rg1';\n```\n\n----------------------------------------\n\nTITLE: System Limits Configuration\nDESCRIPTION: Required system limits configuration in /etc/security/limits.conf for TiDB deployment user\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-check.md#2025-04-18_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n<deploy-user> soft nofile 1000000\n<deploy-user> hard nofile 1000000\n<deploy-user> soft stack 10240\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with AUTO_INCREMENT Unique Key in TiDB\nDESCRIPTION: Example of creating a table with an AUTO_INCREMENT column defined as a unique key rather than a primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/auto-increment.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id int UNIQUE KEY AUTO_INCREMENT, c int);\n```\n\n----------------------------------------\n\nTITLE: National Character Set Examples\nDESCRIPTION: Shows equivalent ways to create strings in the national character set.\nSOURCE: https://github.com/pingcap/docs/blob/master/literal-values.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT N'some text';\nSELECT n'some text';\nSELECT _utf8'some text';\n```\n\n----------------------------------------\n\nTITLE: Describing the TABLES Information Schema in TiDB\nDESCRIPTION: Shows how to use the DESC command to view the structure of the TABLES information schema table in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tables.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC tables;\n```\n\n----------------------------------------\n\nTITLE: Reloading TiDB Cluster\nDESCRIPTION: Command to reload the TiDB cluster after upgrade, which automatically starts TiFlash.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash-upgrade-guide.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster reload <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Unix Socket\nDESCRIPTION: Example of setting up TiDB to use a Unix socket file for external connections instead of TCP/IP.\nSOURCE: https://github.com/pingcap/docs/blob/master/command-line-flags-for-tidb-configuration.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntidb-server --socket=\"/tmp/tidb.sock\"\n```\n\n----------------------------------------\n\nTITLE: Resolving CURRENT_ROLE Function Error in TiDB SQL\nDESCRIPTION: Fixes an error reported by the CURRENT_ROLE function caused by the SET ROLE statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nSET ROLE role_name;\nSELECT CURRENT_ROLE();\n```\n\n----------------------------------------\n\nTITLE: Creating Expression Index in TiDB\nDESCRIPTION: Shows how to create an expression index using CREATE INDEX or ALTER TABLE statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-beta.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE INDEX idx_expr ON table_name ((LOWER(column_name)));\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Netlify CLI in Shell\nDESCRIPTION: Command to log in to Netlify CLI and authenticate your account before deploying applications.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-netlify.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nnetlify login\n```\n\n----------------------------------------\n\nTITLE: Stop Log Backup Example\nDESCRIPTION: Example command to stop a log backup task with specified task name and PD address.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log stop --task-name=pitr --pd=\"${PD_IP}:2379\"\n```\n\n----------------------------------------\n\nTITLE: Validating CA Certificate for TiDB Data Migration\nDESCRIPTION: Command to display the contents of the CA certificate for verification purposes.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nopenssl x509 -text -in ca.pem -noout\n```\n\n----------------------------------------\n\nTITLE: Display TiDB Dashboard Instance\nDESCRIPTION: Command to check which PD instance is serving the TiDB Dashboard using TiUP cluster tool.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-deploy.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster display CLUSTER_NAME --dashboard\n```\n\n----------------------------------------\n\nTITLE: TiDB Lightning S3 Permission\nDESCRIPTION: Reference to S3 bucket list permission requirement for TiDB Lightning data import functionality.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.12.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\ns3:ListBucket\n```\n\n----------------------------------------\n\nTITLE: Resolving data race in statistics updates\nDESCRIPTION: Addresses inaccurate statistics caused by data races during statistics updates.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.7.md#2025-04-18_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\n[#13687](https://github.com/pingcap/tidb/pull/13687)\n```\n\n----------------------------------------\n\nTITLE: Extracting Binary Package\nDESCRIPTION: Command to extract the downloaded component package into the temporary directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-patch.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntar xf /tmp/${component}-${version}-${os}-${arch}.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Dynamic Level Bytes Configuration\nDESCRIPTION: TiKV parameter implementation for improving space collection efficiency.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-1.0.5.md#2025-04-18_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\ndynamic-level-bytes\n```\n\n----------------------------------------\n\nTITLE: Converting UPDATEs into DELETE and INSERTs\nDESCRIPTION: This snippet represents how TiCDC splits `UPDATE` events into `DELETE` and `INSERT` operations, which helps achieve consistent data states in downstream databases.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-split-update-behavior.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nBEGIN;\nDELETE FROM t WHERE a = 1;\nREPLACE INTO t VALUES (2, 1);\nDELETE FROM t WHERE a = 2;\nREPLACE INTO t VALUES (3, 2);\nCOMMIT;\n```\n\nLANGUAGE: SQL\nCODE:\n```\nBEGIN;\nDELETE FROM t WHERE a = 1;\nDELETE FROM t WHERE a = 2;\nREPLACE INTO t VALUES (2, 1);\nREPLACE INTO t VALUES (3, 2);\nCOMMIT;\n```\n\n----------------------------------------\n\nTITLE: Adding Boolean Column in SQL for Migration Tracking\nDESCRIPTION: SQL statement to add a boolean column 'ten_point' to track which ratings have been migrated to the 10-point scale.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-update-data.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE `bookshop`.`ratings` ADD COLUMN `ten_point` BOOL NOT NULL DEFAULT FALSE;\n```\n\n----------------------------------------\n\nTITLE: Describing DEADLOCKS Table Structure in TiDB\nDESCRIPTION: This SQL snippet shows how to describe the structure of the DEADLOCKS table in TiDB's INFORMATION_SCHEMA. It displays the columns, their types, and other metadata.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-deadlocks.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC deadlocks;\n```\n\n----------------------------------------\n\nTITLE: EBNF Syntax Definition for ALTER PLACEMENT POLICY\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition showing the complete grammar for the ALTER PLACEMENT POLICY statement, including all supported options and configurations.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-placement-policy.md#2025-04-18_snippet_1\n\nLANGUAGE: ebnf\nCODE:\n```\nAlterPolicyStmt ::=\n    \"ALTER\" \"PLACEMENT\" \"POLICY\" IfExists PolicyName PlacementOptionList\n\nPolicyName ::=\n    Identifier\n\nPlacementOptionList ::=\n    PlacementOption\n|   PlacementOptionList PlacementOption\n|   PlacementOptionList ',' PlacementOption\n\nPlacementOption ::=\n    CommonPlacementOption\n|   SugarPlacementOption\n|   AdvancedPlacementOption\n\nCommonPlacementOption ::=\n    \"FOLLOWERS\" EqOpt LengthNum\n\nSugarPlacementOption ::=\n    \"PRIMARY_REGION\" EqOpt stringLit\n|   \"REGIONS\" EqOpt stringLit\n|   \"SCHEDULE\" EqOpt stringLit\n\nAdvancedPlacementOption ::=\n    \"LEARNERS\" EqOpt LengthNum\n|   \"CONSTRAINTS\" EqOpt stringLit\n|   \"LEADER_CONSTRAINTS\" EqOpt stringLit\n|   \"FOLLOWER_CONSTRAINTS\" EqOpt stringLit\n|   \"LEARNER_CONSTRAINTS\" EqOpt stringLit\n|   \"SURVIVAL_PREFERENCES\" EqOpt stringLit\n```\n\n----------------------------------------\n\nTITLE: Setting Traditional SQL Mode in TiDB\nDESCRIPTION: Demonstrates how to enable strict mode and ERROR_FOR_DIVISION_BY_ZERO by setting the SQL mode to TRADITIONAL.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/precision-math.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET sql_mode = 'TRADITIONAL`;\n```\n\n----------------------------------------\n\nTITLE: TiProxy Control Command Example\nDESCRIPTION: Example of using tiproxyctl to connect to a TiProxy server and retrieve configuration\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-command-line-flags.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntiproxyctl --host 127.0.0.1 --port 3080 config get\n```\n\n----------------------------------------\n\nTITLE: Pausing Relay Log\nDESCRIPTION: Command to pause the relay log pulling process for specified data sources.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/relay-log.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npause-relay -s mysql-replica-01 -s mysql-replica-02\n```\n\n----------------------------------------\n\nTITLE: Starting PD Node with New Cluster Forcefully in Shell\nDESCRIPTION: Starts a surviving PD node with a new cluster forcefully using specific startup parameters, including client and peer URLs.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-recover.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n./bin/pd-server --force-new-cluster --name=pd-127.0.0.10-2379 --client-urls=http://0.0.0.0:2379 --advertise-client-urls=http://127.0.0.1:2379 --peer-urls=http://0.0.0.0:2380 --advertise-peer-urls=http://127.0.0.1:2380 --config=conf/pd.toml\n```\n\n----------------------------------------\n\nTITLE: Viewing SSH Configuration\nDESCRIPTION: Shell command to open the SSH daemon configuration file for editing maximum session and startup limits.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-faq.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nvi /etc/ssh/sshd_config\n```\n\n----------------------------------------\n\nTITLE: Displaying GCS Folder URI Example for Parquet Import\nDESCRIPTION: Shows an example GCS folder URI format used when importing multiple Parquet files from a specific directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/import-parquet-files.md#2025-04-18_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\ngs://sampledata/ingest/\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into a Cached Table in SQL\nDESCRIPTION: SQL statement to insert a new record into the cached 'users' table.\nSOURCE: https://github.com/pingcap/docs/blob/master/cached-tables.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nINSERT INTO users(id, name) VALUES(1001, 'Davis');\n```\n\n----------------------------------------\n\nTITLE: Running Database Migrations with TypeORM CLI\nDESCRIPTION: Command to execute TypeORM migrations and initialize the database schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nnpm run migration:run\n```\n\n----------------------------------------\n\nTITLE: Deploying AWS Lambda Function with SAM CLI\nDESCRIPTION: SAM CLI command to deploy the AWS Lambda Function with guided prompts.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nsam deploy --guided\n```\n\n----------------------------------------\n\nTITLE: Extracting Grafana Package\nDESCRIPTION: Command to extract the Grafana package from the downloaded TiDB distribution\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-monitoring-services.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntar -xzf grafana-v{version}-linux-amd64.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Creating Table Example in TiDB\nDESCRIPTION: SQL statement to create a sample table t1 with an integer primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-admin-checksum-table.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t1(id INT PRIMARY KEY);\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Case-Insensitive Collation\nDESCRIPTION: Series of SQL commands demonstrating case-insensitive behavior and padding rules in TiDB collations.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_13\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES ('A');\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES ('a');\n```\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO t VALUES ('a ');\n```\n\n----------------------------------------\n\nTITLE: Installing MySQL Client on Ubuntu Linux\nDESCRIPTION: Commands to install MySQL client on Ubuntu Linux systems.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-build-cluster-in-cloud.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\napt-get install mysql-client\n```\n\n----------------------------------------\n\nTITLE: Enabling Async Commit in SQL\nDESCRIPTION: SQL command to enable the async commit feature by setting a global variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0-rc.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_enable_async_commit = ON;\n```\n\n----------------------------------------\n\nTITLE: Resuming Relay Log\nDESCRIPTION: Command to resume the relay log pulling process for a specified data source.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/relay-log.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nresume-relay -s mysql-replica-01\n```\n\n----------------------------------------\n\nTITLE: Deploying New TiDB Cluster\nDESCRIPTION: Deploy a new TiDB cluster with a specified configuration file and version\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-upgrade-migration-guide.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster deploy ${new_cluster_name} ${cluster_version} tidb-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: TABLE Statement with ORDER BY Clause\nDESCRIPTION: Example of using the TABLE statement with an ORDER BY clause to sort the results in descending order by the id column.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-table.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nTABLE t1 ORDER BY id DESC;\n```\n\nLANGUAGE: sql\nCODE:\n```\n+----+\n| id |\n+----+\n|  3 |\n|  2 |\n|  1 |\n+----+\n3 rows in set (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Disabling In-Memory Pessimistic Lock\nDESCRIPTION: TOML configuration to disable the in-memory pessimistic lock feature in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/pessimistic-transaction.md#2025-04-18_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n[pessimistic-txn]\nin-memory = false\n```\n\n----------------------------------------\n\nTITLE: Retrieving TiProxy Monitoring Data using Bash\nDESCRIPTION: Demonstrates how to fetch TiProxy monitoring data using the /metrics/ endpoint.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-api.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://127.0.0.1:3080/metrics/\n```\n\n----------------------------------------\n\nTITLE: Scale Out Configuration\nDESCRIPTION: YAML configuration for adding a new worker node to the DM cluster\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n---\n\nworker_servers:\n  - host: 172.16.5.140\n```\n\n----------------------------------------\n\nTITLE: Creating Table and Displaying NEXT_ROW_ID in SQL\nDESCRIPTION: The snippet demonstrates how to create a simple table in SQL and then use the SHOW TABLE NEXT_ROW_ID command to display the next row ID for the newly created table in TiDB. Initially, the next row ID is 1 as no data has been inserted.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-next-rowid.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(a int);\nQuery OK, 0 rows affected (0.06 sec)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLE t NEXT_ROW_ID;\n+---------+------------+-------------+--------------------+\n| DB_NAME | TABLE_NAME | COLUMN_NAME | NEXT_GLOBAL_ROW_ID |\n+---------+------------+-------------+--------------------+\n| test    | t          | _tidb_rowid |                  1 |\n+---------+------------+-------------+--------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Resolving encoding issues in input files for TiDB Lightning\nDESCRIPTION: This snippet discusses errors related to unsupported file encodings in TiDB Lightning and provides guidance on how to handle them.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_17\n\nLANGUAGE: markdown\nCODE:\n```\n- Cause: TiDB Lightning only supports the UTF-8 and GB-18030 encodings. This error means the file is not in any of these encodings. It is also possible that the file has mixed encoding, such as containing a string in UTF-8 and another string in GB-18030, due to historical ALTER TABLE executions.\n\n    - Solution: See [Troubleshooting Solution](/tidb-lightning/troubleshoot-tidb-lightning.md#cannot-guess-encoding-for-input-file-please-convert-to-utf-8-manually).\n```\n\n----------------------------------------\n\nTITLE: INSERT INTO SELECT Basic Syntax\nDESCRIPTION: Shows the basic syntax structure for INSERT INTO SELECT statements in TiDB, including optional clauses and parameters for inserting query results into tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-results-materialization.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nINSERT [LOW_PRIORITY | HIGH_PRIORITY] [IGNORE]\n    [INTO] tbl_name\n    [PARTITION (partition_name [, partition_name] ...)]\n    [(col_name [, col_name] ...)]\n    SELECT ...\n    [ON DUPLICATE KEY UPDATE assignment_list]value:\n    {expr | DEFAULT}\n\nassignment:\n    col_name = valueassignment_list:\n    assignment [, assignment] ...\n```\n\n----------------------------------------\n\nTITLE: Removing TiCDC Replication Task\nDESCRIPTION: Command to remove an existing replication task.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed remove --server=http://10.0.10.25:8300 --changefeed-id simple-replication-task\n```\n\n----------------------------------------\n\nTITLE: DROP STATS for Partitioned Tables\nDESCRIPTION: Example showing how to drop statistics for specific partitions of a table.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-stats.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP STATS TableName PARTITION PartitionNameList;\n```\n\n----------------------------------------\n\nTITLE: Downloading the Go-TPC Test Program\nDESCRIPTION: A shell command for downloading the go-tpc test program used for generating TPC-C workloads in the TiDB database.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.5-performance-benchmarking-with-tpcc.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/pingcap/go-tpc/master/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Defining BACKUP Statement Syntax in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the BACKUP statement in TiDB, showing the complete grammar including all available options and parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-backup.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nBackupStmt ::=\n    \"BACKUP\" BRIETables \"TO\" stringLit BackupOption*\n\nBRIETables ::=\n    \"DATABASE\" ( '*' | DBName (',' DBName)* )\n|   \"TABLE\" TableNameList\n\nBackupOption ::=\n    \"CHECKSUM\" '='? Boolean\n|   \"CHECKSUM_CONCURRENCY\" '='? LengthNum\n|   \"COMPRESSION_LEVEL\" '='? LengthNum\n|   \"COMPRESSION_TYPE\" '='? stringLit\n|   \"CONCURRENCY\" '='? LengthNum\n|   \"IGNORE_STATS\" '='? Boolean\n|   \"LAST_BACKUP\" '='? BackupTSO\n|   \"RATE_LIMIT\" '='? LengthNum \"MB\" '/' \"SECOND\"\n|   \"SEND_CREDENTIALS_TO_TIKV\" '='? Boolean\n|   \"SNAPSHOT\" '='? ( BackupTSO | LengthNum TimestampUnit \"AGO\" )\n\nBoolean ::=\n    NUM | \"TRUE\" | \"FALSE\"\n\nBackupTSO ::=\n    LengthNum | stringLit\n```\n\n----------------------------------------\n\nTITLE: SQL Partition Definition with FLOOR Function\nDESCRIPTION: Fixed error in SELECT statements for partitioned tables where partition definition uses FLOOR() function for rounding partitioned columns.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.7.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nFLOOR()\n```\n\n----------------------------------------\n\nTITLE: Enabling GTID Mode in Self-Hosted MySQL\nDESCRIPTION: SQL commands to enable GTID mode in a self-hosted MySQL instance. Sets global GTID mode and enforce_gtid_consistency parameters, then resets master.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-incremental-data-from-mysql-using-data-migration.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL gtid_mode = ON;\n\nSET GLOBAL enforce_gtid_consistency = ON;\n\nRESET MASTER;\n```\n\n----------------------------------------\n\nTITLE: Removing TiDB Lightning Checkpoints\nDESCRIPTION: The shell command to remove all intermediate data created by TiDB Lightning. It's necessary for complete cleanup, specially the checkpoint files, which might hinder subsequent imports if not removed. This command relies on the 'tidb-lightning-ctl' utility.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/tidb-lightning-faq.md#2025-04-18_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ntidb-lightning-ctl --config conf/tidb-lightning.toml --checkpoint-remove=all\n```\n\n----------------------------------------\n\nTITLE: Dropping Temporary Hive Table\nDESCRIPTION: SQL command to drop the temporary table in Hive after exporting the parquet files, which also deletes the exported files in HDFS.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-parquet-files-to-tidb.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nDROP TABLE temp;\n```\n\n----------------------------------------\n\nTITLE: Configuring Read-Only TiKV Nodes with YAML\nDESCRIPTION: This YAML configuration snippet shows how to mark a TiKV node as read-only by adding a special label with '$mode: readonly'. This label prevents PD from scheduling data to these nodes unless explicitly specified using Placement Rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/readonly-nodes.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntikv_servers:\n  - host: ...\n    ...\n    labels:\n      $mode: readonly\n```\n\n----------------------------------------\n\nTITLE: Displaying store information in TiDB PD\nDESCRIPTION: This command displays information about all stores in the TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_47\n\nLANGUAGE: bash\nCODE:\n```\nstore\n```\n\n----------------------------------------\n\nTITLE: TiDB Cloud Row Trigger Deduplication Strategy\nDESCRIPTION: Explains the hierarchical strategy used by the New Row trigger to generate the id field for deduplication, including column selection priority and limitations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-zapier.md#2025-04-18_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n1. If the result contains an `id` column, use the `id` column.\n2. If you specify a `Dedupe Key` in the trigger configuration, use the `Dedupe Key`.\n3. If the table has a primary key, use the primary key. If there are multiple primary keys, use the first column.\n4. If the table has a unique key, use the unique key.\n5. Use the first column of the table.\n```\n\n----------------------------------------\n\nTITLE: Stop Validation Command in DM\nDESCRIPTION: Command syntax for stopping continuous data validation. Can be applied to specific tasks or all tasks using the --all-task flag.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-continuous-data-validation.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nUsage:\n  dmctl validation stop [--all-task] [task-name] [flags]\n\nFlags:\n      --all-task   whether applied to all tasks\n  -h, --help       help for stop\n```\n\n----------------------------------------\n\nTITLE: Example Output of PLACEMENT_POLICIES Table Structure\nDESCRIPTION: Shows the output of describing the PLACEMENT_POLICIES table, including all columns such as POLICY_ID, CATALOG_NAME, POLICY_NAME, and various constraints fields that define how data is distributed across regions.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-placement-policies.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+----------------------+---------------+------+-----+---------+-------+\n| Field                | Type          | Null | Key | Default | Extra |\n+----------------------+---------------+------+-----+---------+-------+\n| POLICY_ID            | bigint(64)    | NO   |     | <null>  |       |\n| CATALOG_NAME         | varchar(512)  | NO   |     | <null>  |       |\n| POLICY_NAME          | varchar(64)   | NO   |     | <null>  |       |\n| PRIMARY_REGION       | varchar(1024) | YES  |     | <null>  |       |\n| REGIONS              | varchar(1024) | YES  |     | <null>  |       |\n| CONSTRAINTS          | varchar(1024) | YES  |     | <null>  |       |\n| LEADER_CONSTRAINTS   | varchar(1024) | YES  |     | <null>  |       |\n| FOLLOWER_CONSTRAINTS | varchar(1024) | YES  |     | <null>  |       |\n| LEARNER_CONSTRAINTS  | varchar(1024) | YES  |     | <null>  |       |\n| SCHEDULE             | varchar(20)   | YES  |     | <null>  |       |\n| FOLLOWERS            | bigint(64)    | YES  |     | <null>  |       |\n| LEARNERS             | bigint(64)    | YES  |     | <null>  |       |\n+----------------------+---------------+------+-----+---------+-------+\n12 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Describing TIFLASH_SEGMENTS Table Structure in SQL\nDESCRIPTION: SQL command to show the structure of the TIFLASH_SEGMENTS table in the information_schema database.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tiflash-segments.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC tiflash_segments;\n```\n\n----------------------------------------\n\nTITLE: Configuring Disk Spill Encryption in TiDB\nDESCRIPTION: This code snippet demonstrates how to enable encryption for disk spill files in the TiDB configuration file. Setting `spilled-file-encryption-method` to `aes128-ctr` enables AES128-CTR encryption, while `plaintext` disables it.\nSOURCE: https://github.com/pingcap/docs/blob/master/enable-disk-spill-encrypt.md#2025-04-18_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n\"[security]\nspilled-file-encryption-method = \\\"aes128-ctr\\\"\"\n```\n\n----------------------------------------\n\nTITLE: Connecting to ProxySQL\nDESCRIPTION: Command to connect to ProxySQL's MySQL interface for testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_28\n\nLANGUAGE: bash\nCODE:\n```\nmysql -u root -h 127.0.0.1 -P 6034\n```\n\n----------------------------------------\n\nTITLE: Updating TiUP Itself\nDESCRIPTION: Update the TiUP utility to its latest version using the --self flag\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-update.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntiup update --self\n```\n\n----------------------------------------\n\nTITLE: New PD Client Function Addition\nDESCRIPTION: Addition of GetAllMembers function in PD client to retrieve PD member information.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.7.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nGetAllMembers\n```\n\n----------------------------------------\n\nTITLE: TiDB Configuration for TiProxy\nDESCRIPTION: TOML configuration for graceful shutdown in TiDB when using TiProxy.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\ngraceful-wait-before-shutdown=15\n```\n\n----------------------------------------\n\nTITLE: TiKV Region Snapshot Compression\nDESCRIPTION: Implementation of zstd compression for Region snapshots in TiKV\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.1.md#2025-04-18_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nzstd compression for Region snapshot\n```\n\n----------------------------------------\n\nTITLE: Replication Mode Configuration\nDESCRIPTION: Configuration mode parameter used for monitoring replication status changes\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-rc.2.md#2025-04-18_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nwatch\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Configuration\nDESCRIPTION: Shell command to create a copy of the example environment configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-django.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Creating a Sequence in SQL\nDESCRIPTION: An SQL example demonstrating how to create a simple sequence named 'seq' in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-create-sequence.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE SEQUENCE seq;\n```\n\n----------------------------------------\n\nTITLE: Setting ANSI_QUOTES SQL Mode\nDESCRIPTION: Configure SQL mode to recognize double-quoted identifiers, demonstrating how to enable and use ANSI_QUOTES mode\nSOURCE: https://github.com/pingcap/docs/blob/master/schema-object-names.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET SESSION sql_mode='ANSI_QUOTES';\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE \"test\" (a varchar(10));\n```\n\n----------------------------------------\n\nTITLE: Using Hypothetical Index Hint in TiDB Query\nDESCRIPTION: Demonstrates how to use the HYPO_INDEX optimizer hint to evaluate a query's performance with a hypothetical index without actually creating the index. This is part of TiDB's index recommendation evaluation process.\nSOURCE: https://github.com/pingcap/docs/blob/master/index-advisor.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN FORMAT='VERBOSE' SELECT /*+ HYPO_INDEX(t, idx_ab, a, b) */ a, b FROM t WHERE a=1 AND b=1;\n```\n\n----------------------------------------\n\nTITLE: Creating Flink Table to Consume Kafka Data - SQL\nDESCRIPTION: Defines a table within Flink that will consume data from a Kafka topic, enabling integration with the Flink ecosystem.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-data-to-kafka.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE tpcc_orders (\n    o_id INTEGER,\n    o_d_id INTEGER,\n    o_w_id INTEGER,\n    o_c_id INTEGER,\n    o_entry_d STRING,\n    o_carrier_id INTEGER,\n    o_ol_cnt INTEGER,\n    o_all_local INTEGER\n) WITH (\n'connector' = 'kafka',\n'topic' = 'tidb_tpcc_orders',\n'properties.bootstrap.servers' = '127.0.0.1:9092',\n'properties.group.id' = 'testGroup',\n'format' = 'canal-json',\n'scan.startup.mode' = 'earliest-offset',\n'properties.auto.offset.reset' = 'earliest'\n)\n```\n\n----------------------------------------\n\nTITLE: Region State Protocol Definition Reference\nDESCRIPTION: Reference to the RegionState protocol buffer definition used for Region leader heartbeat reporting.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-scheduling.md#2025-04-18_snippet_1\n\nLANGUAGE: protobuf\nCODE:\n```\nRegionState\n```\n\n----------------------------------------\n\nTITLE: Configuring Safe Mode in DM Task (YAML)\nDESCRIPTION: YAML configuration snippet to enable safe mode in the DM task configuration file to ensure re-entrant migration after manual recovery.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-error-handling.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nsyncers:\n  safe-mode: true\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Vector Django Integration\nDESCRIPTION: Command to install Django TiDB integration package with vector search support\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integration-overview.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install django-tidb[vector]\n```\n\n----------------------------------------\n\nTITLE: Canceling a Data Export Task in TiDB Cloud CLI\nDESCRIPTION: This command cancels a data export task in TiDB Cloud. It can be used in both interactive and non-interactive modes, with different flag requirements for each mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-cancel.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export cancel [flags]\n```\n\n----------------------------------------\n\nTITLE: Generating Random Bytes in SQL\nDESCRIPTION: The `RANDOM_BYTES(n)` function returns a number of random bytes specified by the parameter n.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/encryption-and-compression-functions.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT RANDOM_BYTES(3);\n```\n\n----------------------------------------\n\nTITLE: YAML Front Matter Configuration for Overview Page\nDESCRIPTION: YAML configuration block defining the page title, summary and aliases for the TiDB Dashboard overview documentation.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: Overview Page\nsummary: The TiDB overview page displays cluster QPS, latency, top SQL statements, recent slow queries, instance status, and monitor/alert links. Access it via TiDB Dashboard or left navigation menu. QPS and latency require Prometheus monitoring. Top SQL and slow queries need SQL Statements and slow query logs enabled. Instance status shows total and abnormal instances. Monitor and alert links lead to Grafana dashboard, AlertManager, and cluster diagnostics.\naliases: ['/docs/dev/dashboard/dashboard-overview/']\n---\n```\n\n----------------------------------------\n\nTITLE: DROP SEQUENCE Single Sequence Example\nDESCRIPTION: Example showing how to drop a single sequence named 'seq' in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-drop-sequence.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDROP SEQUENCE seq;\n```\n\n----------------------------------------\n\nTITLE: Renaming TiDB Cluster\nDESCRIPTION: Command to rename an existing TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/maintain-tidb-using-tiup.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster rename ${cluster-name} ${new-name}\n```\n\n----------------------------------------\n\nTITLE: Describing TABLE_STORAGE_STATS Schema\nDESCRIPTION: Shows the structure and field definitions of the TABLE_STORAGE_STATS table using the DESC command.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-table-storage-stats.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC TABLE_STORAGE_STATS;\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB, TiKV, and TiFlash Labels using TiUP\nDESCRIPTION: This YAML snippet configures the 'replication.location-labels' for scheduling purposes within a TiDB cluster. It specifies the configuration for TiDB servers, TiKV servers, and TiFlash servers distributed across different zones and hosts.\nSOURCE: https://github.com/pingcap/docs/blob/master/schedule-replicas-by-topology-labels.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nserver_configs:\n  pd:\n    replication.location-labels: [\"zone\", \"host\"]\ntidb_servers:\n# z1\n  - host: tidb-host-machine-1\n    config:\n      labels:\n        zone: z1\n        host: tidb-host-machine-1\n  - host: tidb-host-machine-2\n    config:\n      labels:\n        zone: z1\n        host: tidb-host-machine-2\n# z2\n  - host: tidb-host-machine-3\n    config:\n      labels:\n        zone: z2\n        host: tidb-host-machine-3\n  - host: tikv-host-machine-4\n    config:\n      labels:\n        zone: z2\n        host: tidb-host-machine-4\n# z3\n  - host: tidb-host-machine-5\n    config:\n      labels:\n        zone: z3\n        host: tidb-host-machine-5\n  - host: tidb-host-machine-6\n    config:\n      labels:\n        zone: z3\n        host: tidb-host-machine-6\ntikv_servers:\n# z1\n  # machine-1 on z1\n  - host: tikv-host-machine-1\n    port: 20160\n    config:\n      server.labels:\n        zone: z1\n        host: tikv-host-machine-1\n  - host: tikv-host-machine-1\n    port: 20161\n    config:\n      server.labels:\n        zone: z1\n        host: tikv-host-machine-1\n  # machine-2 on z1\n  - host: tikv-host-machine-2\n    port: 20160\n    config:\n      server.labels:\n        zone: z1\n        host: tikv-host-machine-2\n  - host: tikv-host-machine-2\n    port: 20161\n    config:\n      server.labels:\n        zone: z1\n        host: tikv-host-machine-2\n# z2\n  - host: tikv-host-machine-3\n    config:\n      server.labels:\n        zone: z2\n        host: tikv-host-machine-3\n  - host: tikv-host-machine-4\n    config:\n      server.labels:\n        zone: z2\n        host: tikv-host-machine-4\n# z3\n  - host: tikv-host-machine-5\n    config:\n      server.labels:\n        zone: z3\n        host: tikv-host-machine-5\n  - host: tikv-host-machine-6\n    config:\n      server.labels:\n        zone: z3\n        host: tikv-host-machine-6\ntiflash_servers:\n# z1\n  - host: tiflash-host-machine-1\n    learner_config:\n      server.labels:\n        zone: z1\n        host: tiflash-host-machine-1\n  - host: tiflash-host-machine-2\n    learner_config:\n      server.labels:\n        zone: z1\n        host: tiflash-host-machine-2\n# z2\n  - host: tiflash-host-machine-3\n    learner_config:\n      server.labels:\n        zone: z2\n        host: tiflash-host-machine-3\n  - host: tiflash-host-machine-4\n    learner_config:\n      server.labels:\n        zone: z2\n        host: tiflash-host-machine-4\n# z3\n  - host: tiflash-host-machine-5\n    learner_config:\n      server.labels:\n        zone: z3\n        host: tiflash-host-machine-5\n  - host: tiflash-host-machine-6\n    learner_config:\n      server.labels:\n        zone: z3\n        host: tiflash-host-machine-6\n```\n\n----------------------------------------\n\nTITLE: Creating Users with Comments and Attributes in TiDB\nDESCRIPTION: These SQL statements demonstrate how to create users with comments and attributes, and then query the USER_ATTRIBUTES table to view the results. It shows the usage of CREATE USER statements with COMMENT and ATTRIBUTE clauses.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-user-attributes.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER testuser1 COMMENT 'This user is created only for test';\nCREATE USER testuser2 ATTRIBUTE '{\"email\": \"user@pingcap.com\"}';\nSELECT * FROM information_schema.user_attributes;\n```\n\n----------------------------------------\n\nTITLE: DDL Error Reporting Configuration in YAML\nDESCRIPTION: Configuration to block and report errors on specific DDL operations like table truncation before replication to TiDB. Applies to tables matching the test_*.t_* pattern.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-binlog-event-filter.md#2025-04-18_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nfilters:\n  filter-procedure-rule:\n    schema-pattern: \"test_*\"\n    table-pattern: \"t_*\"\n    events: [\"truncate table\", \"truncate table partition\"]\n    action: Error\n```\n\n----------------------------------------\n\nTITLE: TiKV Parameter Configuration in YAML\nDESCRIPTION: This snippet shows the YAML configuration for enabling the `prefill-for-recycle` parameter in TiKV. This parameter is intended to make log recycling effective immediately after initialization. It's used for specific Sysbench workloads during the performance testing.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/v7.5-performance-benchmarking-with-sysbench.md#2025-04-18_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\n\"raft-engine.prefill-for-recycle = false\"\n```\n\n----------------------------------------\n\nTITLE: TiCDC Canal-JSON Update Event Message Structure\nDESCRIPTION: JSON representation of an update event message in TiCDC, showing full column data in the 'old' field\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\\n    \"id\": 0,\\n    \"type\": \"UPDATE\",\\n    \"data\": [\\n        {\\n            \"c_bigint\": \"9223372036854775807\",\\n            \"c_int\": \"0\",\\n            \"c_mediumint\": \"8388607\",\\n            \"c_smallint\": \"32767\",\\n            \"c_tinyint\": \"0\",\\n            \"id\": \"2\"\\n        }\\n    ],\\n    \"old\": [\\n        {\\n            \"c_bigint\": \"9223372036854775807\",\\n            \"c_int\": \"2147483647\",\\n            \"c_mediumint\": \"8388607\",\\n            \"c_smallint\": \"32767\",\\n            \"c_tinyint\": \"127\",\\n            \"id\": \"2\"\\n        }\\n    ]\\n}\n```\n\n----------------------------------------\n\nTITLE: Previewing Next.js Application\nDESCRIPTION: This shell command starts a local development server for the Next.js application, allowing the user to see the application in action. Users can visit the specified URL to view their application.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-oas-with-nextjs.md#2025-04-18_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nyarn dev\n```\n\n----------------------------------------\n\nTITLE: Enabling Table Locks in TiDB\nDESCRIPTION: Shows how to use table locks in TiDB to control concurrent access to tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.0-beta.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nLOCK TABLES table_name READ;\n```\n\n----------------------------------------\n\nTITLE: Installing TiDB Cloud CLI via Script on macOS/Linux\nDESCRIPTION: This snippet shows how to install the TiDB Cloud CLI using a script. It downloads and executes the installation script directly from the official repository.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/get-started-with-cli.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl https://raw.githubusercontent.com/tidbcloud/tidbcloud-cli/main/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: TiCDC API Example\nDESCRIPTION: Example of TiCDC owner eviction API endpoint mentioned in fixes\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-7.5.2.md#2025-04-18_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n/api/v2/owner/resign\n```\n\n----------------------------------------\n\nTITLE: Window Function with PARTITION BY Example\nDESCRIPTION: Example demonstrating optimization of window function with PARTITION BY clause using clustered primary key.\nSOURCE: https://github.com/pingcap/docs/blob/master/derive-topn-from-window.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id1 int, id2 int, value1 int, value2 int, primary key(id1,id2) clustered);\nSET tidb_opt_derive_topn=on;\nEXPLAIN SELECT * FROM (SELECT ROW_NUMBER() OVER (PARTITION BY id1) AS rownumber FROM t) dt WHERE rownumber <= 3;\n```\n\n----------------------------------------\n\nTITLE: Querying Replication Tasks - TiCDC - Shell\nDESCRIPTION: This example showcases how to query the basic information of all replication tasks with a specific state (normal in this case) using a GET request. It demonstrates the use of the `state` query parameter to filter the results.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v1/changefeeds?state=normal\n```\n\n----------------------------------------\n\nTITLE: Installing BR Command-line Tool using TiUP\nDESCRIPTION: Command to install the BR (Backup & Restore) command-line tool online using TiUP package manager.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-use-overview.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntiup install br\n```\n\n----------------------------------------\n\nTITLE: Manual Compacting of TiKV Data\nDESCRIPTION: Using tikv-ctl, this snippet demonstrates how to manually compact data in TiKV instances. It provides options for specifying compaction range, regions, column families, threads, and bottommost files inclusion. Dependencies include a valid data directory or host and Tikv instances properly set up.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --data-dir /path/to/tikv compact -d kv\n```\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --host ip:port compact -d kv\n```\n\n----------------------------------------\n\nTITLE: Using COMMIT in a Transaction Example\nDESCRIPTION: A SQL example demonstrating how to use the COMMIT statement after creating a table and inserting data within a transaction. This shows the typical workflow of starting a transaction, performing operations, and committing changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-commit.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (a int NOT NULL PRIMARY KEY);\nQuery OK, 0 rows affected (0.12 sec)\n\nmysql> START TRANSACTION;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> INSERT INTO t1 VALUES (1);\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> COMMIT;\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Window Function with Non-Clustered Primary Key in SQL (TiDB)\nDESCRIPTION: This example demonstrates a window function where the PARTITION BY column is a prefix of the primary key, but the primary key is not a clustered index. The SQL is not rewritten for TopN optimization in this case.\nSOURCE: https://github.com/pingcap/docs/blob/master/derive-topn-from-window.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id1 int, id2 int, value1 int, value2 int, primary key(id1,id2) nonclustered);\nSET tidb_opt_derive_topn=on;\nEXPLAIN SELECT * FROM (SELECT ROW_NUMBER() OVER (PARTITION BY id1) AS rownumber FROM t use index()) dt WHERE rownumber <= 3;\n```\n\n----------------------------------------\n\nTITLE: Showing When TopN Cannot be Pushed Down Before Join\nDESCRIPTION: SQL example illustrating a case where TopN cannot be pushed down before an Inner Join because it would affect the query result correctness.\nSOURCE: https://github.com/pingcap/docs/blob/master/topn-limit-push-down.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t(id int primary key, a int not null);\ncreate table s(id int primary key, a int not null);\nexplain select * from t join s on t.a = s.a order by t.id limit 10;\n```\n\n----------------------------------------\n\nTITLE: Defining MEDIUMBLOB Column in TiDB\nDESCRIPTION: Syntax for creating a MEDIUMBLOB column supporting up to 16,777,215 bytes.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\nMEDIUMBLOB\n```\n\n----------------------------------------\n\nTITLE: Assigning Dashboard Role to User\nDESCRIPTION: SQL commands to create a user and assign the dashboard access role as their default role.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-user.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'dashboardAdmin'@'%' IDENTIFIED BY '<YOUR_PASSWORD>';\nGRANT 'dashboard_access' TO 'dashboardAdmin'@'%';\n-- You need to set dashboard_access as the default role to the user\nSET DEFAULT ROLE dashboard_access to 'dashboardAdmin'@'%';\n```\n\n----------------------------------------\n\nTITLE: Type Validation Examples\nDESCRIPTION: SQL queries demonstrating JSON type validation using JSON_SCHEMA_VALID\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-validate.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SCHEMA_VALID('{\"type\": \"object\"}',@j)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_SCHEMA_VALID('{\"type\": \"array\"}',@j)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT JSON_TYPE(@j)\n```\n\n----------------------------------------\n\nTITLE: Starting Docker on CentOS\nDESCRIPTION: Command to start Docker service on CentOS systems.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nsystemctl start docker\n```\n\n----------------------------------------\n\nTITLE: Verifying a Cached Table in SQL\nDESCRIPTION: SQL statement to show the create table syntax for the 'users' table, which includes the 'CACHED ON' attribute for cached tables.\nSOURCE: https://github.com/pingcap/docs/blob/master/cached-tables.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW CREATE TABLE users;\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP\nDESCRIPTION: Installs TiUP, a package manager for TiDB ecosystem tools, using a shell script. The script downloads and installs TiUP, then sets it in the PATH. Prerequisite: curl installed. Outputs a setup TiUP for managing TiDB Lightning.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-lightning/deploy-tidb-lightning.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: TiUP Cluster Patch Command Usage\nDESCRIPTION: Shows the syntax and available flags for the 'patch' command, which allows replacing currently running components with temporary packages for debugging or hotfixing.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster patch --help\n```\n\n----------------------------------------\n\nTITLE: Modifying GC Lifetime for Historical Data Restoration\nDESCRIPTION: Demonstrates how to adjust the Garbage Collection (GC) lifetime to prevent historical data from being cleared during restoration process\nSOURCE: https://github.com/pingcap/docs/blob/master/read-historical-data.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_life_time=\"60m\";\n```\n\n----------------------------------------\n\nTITLE: Setting Global Level Configuration for TiDB Transactions - SQL\nDESCRIPTION: This SQL snippet sets the configuration for automatic retry and retry limit in TiDB at the global level. These settings apply to all sessions and are crucial for ensuring robust transaction management in applications.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimistic-transaction.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_disable_txn_auto_retry = OFF;\nSET GLOBAL tidb_retry_limit = 10;\n```\n\n----------------------------------------\n\nTITLE: Completely Disabling Titan\nDESCRIPTION: Configuration to completely disable Titan storage engine in TiKV\nSOURCE: https://github.com/pingcap/docs/blob/master/storage-engine/titan-configuration.md#2025-04-18_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\n[rocksdb.titan]\nenabled = false\n```\n\n----------------------------------------\n\nTITLE: Configuring Snap Handle Pool Size\nDESCRIPTION: Specifies the number of threads dedicated to handling snapshots, optimizing snapshot processing performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_8\n\nLANGUAGE: TOML\nCODE:\n```\n\"raftstore.snap-handle-pool-size = 2\"\n```\n\n----------------------------------------\n\nTITLE: Explaining SQL Query with TiFlash Push-down\nDESCRIPTION: This snippet illustrates the usage of an `EXPLAIN` query to show how a SQL `SELECT` statement utilizes the TiFlash push-down feature, which helps in efficiently processing and limiting result sets. Dependencies include a TiDB cluster with an active TiFlash instance. The `EXPLAIN` command is used without producing a final output but to understand query execution. The results demonstrate that the `Limit` operator can push its operations to TiFlash, as shown in the `mpp[tiflash]` task.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-supported-pushdown-calculations.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM t LIMIT 3;\n\n+------------------------------+---------+--------------+---------------+--------------------------------+\n| id                           | estRows | task         | access object | operator info                  |\n+------------------------------+---------+--------------+---------------+--------------------------------+\n| Limit_9                      | 3.00    | root         |               | offset:0, count:3              |\n| └─TableReader_17             | 3.00    | root         |               | data:ExchangeSender_16         |\n|   └─ExchangeSender_16        | 3.00    | mpp[tiflash] |               | ExchangeType: PassThrough      |\n|     └─Limit_15               | 3.00    | mpp[tiflash] |               | offset:0, count:3              |\n|       └─TableFullScan_14     | 3.00    | mpp[tiflash] | table:t       | keep order:false, stats:pseudo |\n+------------------------------+---------+--------------+---------------+--------------------------------+\n5 rows in set (0.18 sec)\n```\n\n----------------------------------------\n\nTITLE: Verifying ext4 Mount Options for TiKV Disk\nDESCRIPTION: Command to check that the ext4 filesystem has been properly mounted with the required nodelalloc option, which is necessary for TiKV deployment.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmount -t ext4\n```\n\n----------------------------------------\n\nTITLE: Creating a Key Partitioned Table by Store ID in SQL\nDESCRIPTION: This SQL snippet demonstrates how to create a Key partitioned table divided into 4 partitions based on the store_id column.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_28\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE employees (\n    id INT NOT NULL,\n    fname VARCHAR(30),\n    lname VARCHAR(30),\n    hired DATE NOT NULL DEFAULT '1970-01-01',\n    separated DATE DEFAULT '9999-12-31',\n    job_code INT,\n    store_id INT\n)\n\nPARTITION BY KEY(store_id)\nPARTITIONS 4;\n```\n\n----------------------------------------\n\nTITLE: Querying TiFlash Replica Information\nDESCRIPTION: Accelerates the /tiflash/replica HTTP API when there are many history DDL jobs in the TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.17.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\n-- Example of querying TiFlash replica information\nSELECT * FROM information_schema.tiflash_replica;\n```\n\n----------------------------------------\n\nTITLE: EXPLAIN Output Showing Predicate Pushdown in TiDB\nDESCRIPTION: This snippet shows how TiDB pushes down predicates from the view definition. The first query uses the duration index to satisfy the view condition and then applies the bike_number filter, while the second query uses a full table scan since there's no applicable index.\nSOURCE: https://github.com/pingcap/docs/blob/master/explain-views.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------------+---------+-----------+---------------------------------------+---------------------------------------------------+\n| id                             | estRows | task      | access object                         | operator info                                     |\n+--------------------------------+---------+-----------+---------------------------------------+---------------------------------------------------+\n| IndexLookUp_14                 | 3.33    | root      |                                       |                                                   |\n| ├─IndexRangeScan_11(Build)     | 3333.33 | cop[tikv] | table:trips, index:duration(duration) | range:(3600,+inf], keep order:false, stats:pseudo |\n| └─Selection_13(Probe)          | 3.33    | cop[tikv] |                                       | eq(bikeshare.trips.bike_number, \"W00950\")         |\n|   └─TableRowIDScan_12          | 3333.33 | cop[tikv] | table:trips                           | keep order:false, stats:pseudo                    |\n+--------------------------------+---------+-----------+---------------------------------------+---------------------------------------------------+\n4 rows in set (0.00 sec)\n\n+-------------------------+-------------+-----------+---------------+-------------------------------------------+\n| id                      | estRows     | task      | access object | operator info                             |\n+-------------------------+-------------+-----------+---------------+-------------------------------------------+\n| TableReader_7           | 43.00       | root      |               | data:Selection_6                          |\n| └─Selection_6           | 43.00       | cop[tikv] |               | eq(bikeshare.trips.bike_number, \"W00950\") |\n|   └─TableFullScan_5     | 19117643.00 | cop[tikv] | table:trips   | keep order:false                          |\n+-------------------------+-------------+-----------+---------------+-------------------------------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Response Example - Querying a Specific Replication Task - TiCDC - JSON\nDESCRIPTION: This JSON response shows the detailed information returned when querying a specific replication task. It includes details such as `id`, `sink_uri`, `create_time`, `state`, `error`, and `task_status`.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"id\": \"test1\",\n    \"sink_uri\": \"blackhole://\",\n    \"create_time\": \"2021-08-10 11:41:30.642\",\n    \"start_ts\": 426919038970232833,\n    \"target_ts\": 0,\n    \"checkpoint_tso\": 426921014615867393,\n    \"checkpoint_time\": \"2021-08-10 13:47:07.093\",\n    \"sort_engine\": \"unified\",\n    \"state\": \"normal\",\n    \"error\": null,\n    \"error_history\": null,\n    \"creator_version\": \"\",\n    \"task_status\": [\n        {\n            \"capture_id\": \"d8924259-f52f-4dfb-97a9-c48d26395945\",\n            \"table_ids\": [\n                63,\n                65\n            ],\n            \"table_operations\": {}\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Checking CPU Instruction Set Support Command for TiFlash\nDESCRIPTION: Shell commands to verify CPU support for required instruction sets when deploying TiFlash. For AMD64 architecture, checks AVX2 support, and for ARM64 architecture, checks ARMv8 instruction set support.\nSOURCE: https://github.com/pingcap/docs/blob/master/hardware-and-software-requirements.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngrep avx2 /proc/cpuinfo\n```\n\nLANGUAGE: shell\nCODE:\n```\ngrep 'crc32' /proc/cpuinfo | grep 'asimd'\n```\n\n----------------------------------------\n\nTITLE: Disabling Firewall Service Autostart for TiDB Hosts\nDESCRIPTION: Command to disable automatic startup of the firewalld service, ensuring that the firewall remains disabled after system reboots.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl disable firewalld.service\n```\n\n----------------------------------------\n\nTITLE: Altering User with Hashed Password in TiDB\nDESCRIPTION: This SQL command shows that TiDB does not apply the password complexity policy to hashed passwords, allowing modifications without checking the complexity rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nmysql> ALTER USER 'test'@'localhost' IDENTIFIED WITH mysql_native_password AS '*0D3CED9BEC10A777AEC23CCC353A8C08A633045E';\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n----------------------------------------\n\nTITLE: Describing TIDB_SERVERS_INFO Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the TIDB_SERVERS_INFO table in the INFORMATION_SCHEMA database, showing field names, data types, and other attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tidb-servers-info.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE INFORMATION_SCHEMA;\nDESC tidb_servers_info;\n```\n\n----------------------------------------\n\nTITLE: Truncate Log Backup Help Command\nDESCRIPTION: Shows help information for the log backup truncate command including available flags and global options.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log truncate --help\ntruncate the incremental log until sometime.\n\nUsage:\n  br log truncate [flags]\n\nFlags:\n  --dry-run        Run the command but don't really delete the files.\n  -h, --help       help for truncate\n  --until string   Remove all backup data until this TS.(support TSO or datetime, e.g. '400036290571534337' or '2018-05-11 01:42:23+0800'.)\n  -y, --yes        Skip all prompts and always execute the command.\n\n\nGlobal Flags:\n  -s, --storage string         specify the url where backup storage, eg, \"s3://bucket/path/prefix\"\n```\n\n----------------------------------------\n\nTITLE: TiDB SQL Function and Query Fixes\nDESCRIPTION: Bug fixes for various SQL functions including UNIX_TIMESTAMP(), COERCIBILITY(), HEX(), FIELD(), and STR_TO_DATE(). Also includes fixes for query execution plans, isolation settings, and runtime errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0.2.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nUNIX_TIMESTAMP()\nCOERCIBILITY()\nHEX()\nFIELD()\nSTR_TO_DATE()\nEXPLAIN FOR CONNECTION\nDROP DATABASE\nALTER TABLE ... RENAME\nALTER USER\n```\n\n----------------------------------------\n\nTITLE: Vector Search Results Sample Output\nDESCRIPTION: Shows the expected output from the basic vector search query about the author's activities, displaying text that has been semantically retrieved from the vector store.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_9\n\nLANGUAGE: plain\nCODE:\n```\nThe author worked on writing, programming, building microcomputers, giving talks at conferences,\npublishing essays online, developing spam filters, painting, hosting dinner parties, and purchasing\na building for office use.\n```\n\n----------------------------------------\n\nTITLE: Modifying TiKV Configuration - Set Write CF Block Cache Size\nDESCRIPTION: This command sets the block cache size for the write column family in TiKV to 256MB. It requires the same options as the previous command for configuration scheduling.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --host ip:port modify-tikv-config -n rocksdb.writecf.block-cache-size -v 256MB\n```\n\n----------------------------------------\n\nTITLE: Checking THP Status\nDESCRIPTION: Command to check if Transparent Huge Pages (THP) is enabled on the system\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-check.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncat /sys/kernel/mm/transparent_hugepage/enabled\n```\n\n----------------------------------------\n\nTITLE: Configuring DM-worker Servers in YAML\nDESCRIPTION: Example configuration for DM-worker servers in TiDB Data Migration. It demonstrates how to specify host details, deployment directories, and custom configurations for worker instances.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-dm-topology-reference.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nworker_servers:\n  - host: 10.0.1.12\n    ssh_port: 22\n    port: 8262\n    deploy_dir: \"/dm-deploy/dm-worker-8262\"\n    log_dir: \"/dm-deploy/dm-worker-8262/log\"\n    numa_node: \"0,1\"\n    # config is used to overwrite the `server_configs.worker` values\n    config:\n      log-level: info\n  - host: 10.0.1.19\n```\n\n----------------------------------------\n\nTITLE: Using RECOVER Syntax in TiDB SQL\nDESCRIPTION: Support for using the `RECOVER` syntax to recover truncated tables in TiDB. This allows restoring tables that were accidentally truncated.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.1.0-rc.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nRECOVER TABLE table_name;\n```\n\n----------------------------------------\n\nTITLE: Creating Invalid Partitioned Tables with Unique Keys - SQL\nDESCRIPTION: This SQL snippet illustrates invalid table creation statements where unique keys do not comply with partitioning key requirements. It emphasizes the need for all unique keys, including primary keys, to encompass every column in the partitioning expression.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_53\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCREATE TABLE t1 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    UNIQUE KEY (col1, col2)\n)\n\nPARTITION BY HASH(col3)\nPARTITIONS 4;\n\nCREATE TABLE t2 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    UNIQUE KEY (col1),\n    UNIQUE KEY (col3)\n)\n\nPARTITION BY HASH(col1 + col3)\nPARTITIONS 4;\n```\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for TiDB Cloud Data App Connection in Vercel\nDESCRIPTION: These environment variables are automatically added to your Vercel project when using the TiDB Cloud Vercel integration for a Data App connection.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-vercel.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nDATA_APP_BASE_URL\nDATA_APP_PUBLIC_KEY\nDATA_APP_PRIVATE_KEY\n```\n\n----------------------------------------\n\nTITLE: Normalized SQL Statement Example\nDESCRIPTION: The normalized form of SQL statements after TiDB's digest calculation process, which ignores constants, whitespace, and is case insensitive.\nSOURCE: https://github.com/pingcap/docs/blob/master/statement-summary-tables.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nselect * from employee where id in (...) and salary between ? and ?;\n```\n\n----------------------------------------\n\nTITLE: TiKV Coprocessor Configuration Query Results\nDESCRIPTION: Example output showing TiKV coprocessor configuration values, including batch-split-limit, region size and key limits, and table split settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-config.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+------+-----------------+-----------------------------------+---------+\n| TYPE | INSTANCE        | KEY                               | VALUE   |\n+------+-----------------+-----------------------------------+---------+\n| tikv | 127.0.0.1:20165 | coprocessor.batch-split-limit     | 10      |\n| tikv | 127.0.0.1:20165 | coprocessor.region-max-keys       | 3840000 |\n| tikv | 127.0.0.1:20165 | coprocessor.region-max-size       | 384MiB  |\n| tikv | 127.0.0.1:20165 | coprocessor.region-split-keys     | 2560000  |\n| tikv | 127.0.0.1:20165 | coprocessor.region-split-size     | 256MiB   |\n| tikv | 127.0.0.1:20165 | coprocessor.split-region-on-table | false   |\n+------+-----------------+-----------------------------------+---------+\n6 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple C Program for Custom Component\nDESCRIPTION: Creates a simple C program that will be packaged as a custom TiUP component.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ cat > hello.c << END\n> #include <stdio.h>\nint main() {\n  printf(\"hello\\n\");\n  return (0);\n}\nEND\n$ gcc hello.c -o hello\n$ tiup package hello --entry hello --name hello --release v0.0.1\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into Local Temporary Table in SQL\nDESCRIPTION: SQL statement to insert the results of the eldest authors query into the previously created temporary table.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-temporary-tables.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO top_50_eldest_authors\nSELECT a.id, a.name, (IFNULL(a.death_year, YEAR(NOW())) - a.birth_year) AS age\nFROM authors a\nORDER BY age DESC\nLIMIT 50;\n```\n\n----------------------------------------\n\nTITLE: TPC-DS Query Execution Plan With Runtime Filter\nDESCRIPTION: SQL query execution plan demonstrating improved performance metrics when Runtime Filter is enabled, showing the same query structure but with optimized execution.\nSOURCE: https://github.com/pingcap/docs/blob/master/runtime-filter.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN ANALYZE SELECT cs_ship_date_sk FROM catalog_sales, date_dim\n    -> WHERE d_date = '2002-2-01' AND\n    ->      cs_ship_date_sk = d_date_sk;\n```\n\n----------------------------------------\n\nTITLE: Enabling Amend Pessimistic Transactions in TiDB\nDESCRIPTION: This snippet shows how to enable the automatic update of the transaction's SCHEMA VERSION in pessimistic transaction mode, avoiding the `Information schema is changed` error when transactions are interrupted by DDL operations or SCHEMA VERSION changes. This feature requires setting the `tidb_enable_amend_pessimistic_txn` system variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.0.0.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nSET GLOBAL tidb_enable_amend_pessimistic_txn = ON;\n```\n\n----------------------------------------\n\nTITLE: Verifying TiDB Cloud Backup Deletion\nDESCRIPTION: Terminal command showing how to verify the backup has been deleted by running terraform show, which returns nothing when the resource has been cleared.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-backup-resource.md#2025-04-18_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ terraform show\n```\n\n----------------------------------------\n\nTITLE: Uninstalling MySQL on macOS using Homebrew\nDESCRIPTION: This snippet details the commands to stop the MySQL service and uninstall it from a macOS system using Homebrew. It also provides instructions for data removal.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nbrew services stop mysql@8.0\n brew uninstall mysql@8.0\n```\n\n----------------------------------------\n\nTITLE: Stopping and Removing MySQL Docker Container\nDESCRIPTION: The snippet provides commands to stop and remove a MySQL instance running as a Docker container. This is useful for cleaning up after testing and ensuring there are no leftover resources.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/quick-start-with-dm.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ndocker stop mysql80\n docker rm mysql80\n```\n\n----------------------------------------\n\nTITLE: Querying Slow Logs in TiDB SQL\nDESCRIPTION: Adds support for checking slow logs using an administrative command, useful for performance tuning and troubleshooting.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0-beta.md#2025-04-18_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN SHOW SLOW;\n```\n\n----------------------------------------\n\nTITLE: Customizing Other Grafana Configurations in TiUP\nDESCRIPTION: This YAML snippet details setting additional configuration items in 'grafana_servers' of the topology.yaml file. It demonstrates how to configure log levels and SMTP settings for Grafana, allowing enhanced monitoring and alerting capabilities.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/customized-montior-in-tiup-environment.md#2025-04-18_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ngrafana_servers:\n  - host: 127.0.0.1\n    config:\n      log.file.level: warning\n      smtp.enabled: true\n      smtp.host: {IP}:{port}\n      smtp.user: example@pingcap.com\n      smtp.password: {password}\n      smtp.skip_verify: true\n```\n\n----------------------------------------\n\nTITLE: Creating Partitioned Employees Table in TiDB\nDESCRIPTION: Creates a partitioned table with range partitioning based on store_id, defining four partitions with different value ranges\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/use-tiflash-mpp-mode.md#2025-04-18_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE test.employees\n(id int NOT NULL,\n fname varchar(30) DEFAULT NULL,\n lname varchar(30) DEFAULT NULL,\n hired date NOT NULL DEFAULT '1970-01-01',\n separated date DEFAULT '9999-12-31',\n job_code int DEFAULT NULL,\n store_id int NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\nPARTITION BY RANGE (store_id)\n(PARTITION p0 VALUES LESS THAN (6),\n PARTITION p1 VALUES LESS THAN (11),\n PARTITION p2 VALUES LESS THAN (16),\n PARTITION p3 VALUES LESS THAN (MAXVALUE));\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Old TiDB Snapshot Backups\nDESCRIPTION: Removes old snapshot backup data from S3 storage to free up space.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-guide.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\naws s3 rm --recursive s3://backup-101/snapshot-${date}\n```\n\n----------------------------------------\n\nTITLE: Examining `Access denied` error in Data Migration\nDESCRIPTION: This snippet outlines the common `Access denied for user 'root'@'172.31.43.27'` error during DM operation, highlighting database privilege requirements and password encryption recommendations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n- The database related passwords in all the DM configuration files should be encrypted by `dmctl`. If a database password is empty, it is unnecessary to encrypt the password. Cleartext passwords can be used since v1.0.6.\n- During DM operation, the user of the upstream and downstream databases must have the corresponding read and write privileges. Data Migration also [prechecks the corresponding privileges](/dm/dm-precheck.md) automatically while starting the data replication task.\n```\n\n----------------------------------------\n\nTITLE: Manually Parsing TSO Components with SQL Bitwise Operations\nDESCRIPTION: This snippet demonstrates how to manually parse both physical and logical components of a TSO timestamp using SQL bitwise operations, including right shift for physical timestamp extraction and bitwise AND for logical timestamp extraction.\nSOURCE: https://github.com/pingcap/docs/blob/master/tso.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @ts, UNIX_TIMESTAMP(NOW(6)), (@ts >> 18)/1000, FROM_UNIXTIME((@ts >> 18)/1000), NOW(6), @ts & 0x3FFFF\\G\n*************************** 1. row ***************************\n                            @ts: 443852055297916932\n         UNIX_TIMESTAMP(NOW(6)): 1693161835.502954\n               (@ts >> 18)/1000: 1693161221.6870\nFROM_UNIXTIME((@ts >> 18)/1000): 2023-08-27 20:33:41.6870\n                         NOW(6): 2023-08-27 20:43:55.502954\n                  @ts & 0x3FFFF: 4\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Configuring Log4j to Suppress Warnings\nDESCRIPTION: Configuration snippet to add to log4j.properties to suppress benign warnings about database lookup failures. This sets the logger level for ObjectStore to ERROR to prevent excessive warnings.\nSOURCE: https://github.com/pingcap/docs/blob/master/tispark-overview.md#2025-04-18_snippet_10\n\nLANGUAGE: properties\nCODE:\n```\n# tispark disable \"WARN ObjectStore:568 - Failed to get database\"\nlog4j.logger.org.apache.hadoop.hive.metastore.ObjectStore=ERROR\n```\n\n----------------------------------------\n\nTITLE: Configuring TiKV Election Timeout\nDESCRIPTION: Configuration to adjust the election timeout ticks for remote TiKV nodes to prevent unnecessary Raft elections.\nSOURCE: https://github.com/pingcap/docs/blob/master/geo-distributed-deployment-topology.md#2025-04-18_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nraftstore.raft-min-election-timeout-ticks: 50\nraftstore.raft-max-election-timeout-ticks: 60\n```\n\n----------------------------------------\n\nTITLE: Altering Ghost Table in MySQL with gh-ost\nDESCRIPTION: SQL statement to apply DDL changes to the ghost table. DM records this DDL operation in its metadata but doesn't execute it directly.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nAlter /* gh-ost */ table `test`.`_test4_gho` add column cl1 varchar(20) not null ;\n```\n\n----------------------------------------\n\nTITLE: Executing Correlated Subquery Without NO_DECORRELATE Hint in SQL\nDESCRIPTION: Demonstrates the default behavior where TiDB automatically performs decorrelation for a correlated subquery. The query selects rows from t1 where t1.a is less than the sum of t2.a values where t2.b equals t1.b.\nSOURCE: https://github.com/pingcap/docs/blob/master/optimizer-hints.md#2025-04-18_snippet_20\n\nLANGUAGE: sql\nCODE:\n```\nexplain select * from t1 where t1.a < (select sum(t2.a) from t2 where t2.b = t1.b);\n```\n\n----------------------------------------\n\nTITLE: Creating Directory and Downloading Sample Document with Shell\nDESCRIPTION: Creates a directory for sample data and downloads a test document (Paul Graham essay) from the LlamaIndex GitHub repository.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n!mkdir -p 'data/paul_graham/'\n!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'\n```\n\n----------------------------------------\n\nTITLE: Setting PD Connection Retry Interval\nDESCRIPTION: This snippet sets the interval for retrying PD connections in TiKV, detailing default values and their implications for connection management.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n+ The interval for retrying the PD connection.\n+ Default value: `\"300ms\"`\n```\n\n----------------------------------------\n\nTITLE: Refreshing and Showing TiDB Cloud Cluster State\nDESCRIPTION: These shell commands refresh the Terraform state and then display the updated state of the TiDB Cloud cluster, useful for checking the latest cluster status.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/terraform-use-cluster-resource.md#2025-04-18_snippet_5\n\nLANGUAGE: Shell\nCODE:\n```\n$ terraform refresh\n\n$ terraform state show tidbcloud_cluster.example_cluster\n```\n\n----------------------------------------\n\nTITLE: TiDB System Variables Table in Markdown\nDESCRIPTION: A markdown table listing TiDB system variables, their change types, and detailed descriptions. Includes variables for transaction handling, DDL operations, logging, query optimization, and schema management.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\n| Variable name | Change type | Description |\n|--------|------------------------------|------|\n| [`tidb_disable_txn_auto_retry`](/system-variables.md#tidb_disable_txn_auto_retry) | Deprecated | Starting from v8.0.0, this system variable is deprecated, and TiDB no longer supports automatic retries of optimistic transactions. It is recommended to use the [Pessimistic transaction mode](/pessimistic-transaction.md). If you encounter optimistic transaction conflicts, you can capture the error and retry transactions in your application. |\n| `tidb_ddl_version` | Renamed | Controls whether to enable TiDB DDL V2. Starting from v8.0.0, this variable is renamed to [`tidb_enable_fast_create_table`](/system-variables.md#tidb_enable_fast_create_table-new-in-v800) to better reflect its purpose. |\n| [`tidb_enable_collect_execution_info`](/system-variables.md#tidb_enable_collect_execution_info) | Modified | Adds a control to whether to record the [usage statistics of indexes](/information-schema/information-schema-tidb-index-usage.md). The default value is `ON`. |\n```\n\n----------------------------------------\n\nTITLE: SQL Examples of Fixed Issues\nDESCRIPTION: Examples of SQL statements and scenarios that were previously problematic but have been fixed in TiDB\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.2.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT DISTINCT CAST(col AS DECIMAL), CAST(col AS SIGNED) FROM ...\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT INTO OUTFILE\n```\n\nLANGUAGE: sql\nCODE:\n```\nPREPARE/EXECUTE statements with CONV(?, ...)\n```\n\nLANGUAGE: sql\nCODE:\n```\nCREATE OR REPLACE VIEW\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE ... REMOVE PARTITIONING\n```\n\nLANGUAGE: sql\nCODE:\n```\nALTER DATABASE ... SET TIFLASH REPLICA\n```\n\n----------------------------------------\n\nTITLE: Re-enabling Optimization Rules\nDESCRIPTION: SQL commands to remove rules from the blocklist and reload the configuration to re-enable them.\nSOURCE: https://github.com/pingcap/docs/blob/master/blocklist-control-plan.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM mysql.opt_rule_blacklist WHERE name IN (\"join_reorder\", \"topn_push_down\");\n```\n\n----------------------------------------\n\nTITLE: Resolving `event from * in * diff from passed-in event *` and binlog errors\nDESCRIPTION: This snippet details errors related to relay units and binlog parsing during replication tasks, including descriptions of the causes and suggested solutions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-troubleshooting-map.md#2025-04-18_snippet_11\n\nLANGUAGE: markdown\nCODE:\n```\n- During the process that DM pulls relay log or the incremental replication, these two errors might occur if the size of the upstream binlog file exceeds 4 GB.\n\n    - Cause: When writing relay logs, DM needs to perform event verification based on binlog positions and the binlog file size, and store the replicated binlog positions as checkpoints. However, the official MySQL uses uint32 to store binlog positions, which means the binlog position for a binlog file over 4 GB overflows, and then the errors above occur.\n\n    - Solution:\n\n        - For relay processing units, [manually recover replication](https://pingcap.com/docs/tidb-data-migration/dev/error-handling/#the-relay-unit-throws-error-event-from--in--diff-from-passed-in-event--or-a-replication-task-is-interrupted-with-failing-to-get-or-parse-binlog-errors-like-get-binlog-error-error-1236-hy000-and-binlog-checksum-mismatch-data-may-be-corrupted-returned).\n        - For binlog replication processing units, [manually recover replication](https://pingcap.com/docs/tidb-data-migration/dev/error-handling/#the-relay-unit-throws-error-event-from--in--diff-from-passed-in-event--or-a-replication-task-is-interrupted-with-failing-to-get-or-parse-binlog-errors-like-get-binlog-error-error-1236-hy000-and-binlog-checksum-mismatch-data-may-be-corrupted-returned).\n```\n\n----------------------------------------\n\nTITLE: Writing Data to TiDB Using go-tpc - Shell\nDESCRIPTION: Uses go-tpc to prepare and run a workload on the TiDB cluster to generate change logs for replication.\nSOURCE: https://github.com/pingcap/docs/blob/master/replicate-data-to-kafka.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup bench tpcc -H 127.0.0.1 -P 4000 -D tpcc --warehouses 4 prepare\ntiup bench tpcc -H 127.0.0.1 -P 4000 -D tpcc --warehouses 4 run --time 300s\n```\n\n----------------------------------------\n\nTITLE: Configuring Maximum Number of Log Backups\nDESCRIPTION: Specifies the maximum number of old log files to keep, helping manage disk space usage for log files.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-configuration.md#2025-04-18_snippet_4\n\nLANGUAGE: TOML\nCODE:\n```\n\"log.file.max-backups = 7\"\n```\n\n----------------------------------------\n\nTITLE: Viewing DM-worker Command-line Parameters\nDESCRIPTION: Shows how to display the available command-line parameters for DM-worker using the --help flag.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/deploy-a-dm-cluster-using-binary.md#2025-04-18_snippet_3\n\nLANGUAGE: Bash\nCODE:\n```\n./dm-worker --help\n```\n\n----------------------------------------\n\nTITLE: Adding Index on Irrelevant Column\nDESCRIPTION: Test command for adding an index on a column not involved in the main workload.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/online-workloads-and-add-index-operations.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nalter table test add index pad_idx(pad)\n```\n\n----------------------------------------\n\nTITLE: Connecting to a TiDB Cloud Serverless branch with required parameters\nDESCRIPTION: Example showing how to connect to a TiDB Cloud Serverless branch with cluster ID and branch ID in non-interactive mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-shell.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch shell -c <cluster-id> -b <branch-id>\n```\n\n----------------------------------------\n\nTITLE: Analyzing Region Information Updates in TiDB Slow Query Log\nDESCRIPTION: This slow query log excerpt shows Cop_backoff information, which can indicate if outdated Region information is causing query slowdown in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/analyze-slow-queries.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\n# Cop_backoff_regionMiss_total_times: 200 Cop_backoff_regionMiss_total_time: 0.2 Cop_backoff_regionMiss_max_time: 0.2 Cop_backoff_regionMiss_max_addr: 127.0.0.1 Cop_backoff_regionMiss_avg_time: 0.2 Cop_backoff_regionMiss_p90_time: 0.2\n# Cop_backoff_rpcPD_total_times: 200 Cop_backoff_rpcPD_total_time: 0.2 Cop_backoff_rpcPD_max_time: 0.2 Cop_backoff_rpcPD_max_addr: 127.0.0.1 Cop_backoff_rpcPD_avg_time: 0.2 Cop_backoff_rpcPD_p90_time: 0.2\n```\n\n----------------------------------------\n\nTITLE: Creating a Table and Inserting Data\nDESCRIPTION: This SQL snippet demonstrates the process of creating a table named t1, then inserting random data into it using various SELECT commands and functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-bindings.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nmysql> CREATE TABLE t1 (\n          id INT NOT NULL PRIMARY KEY auto_increment,\n          b INT NOT NULL,\n          pad VARBINARY(255),\n          INDEX(b)\n         );\nQuery OK, 0 rows affected (0.07 sec)\n\nmysql> INSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM dual;\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\nQuery OK, 8 rows affected (0.00 sec)\nRecords: 8  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\nQuery OK, 1000 rows affected (0.04 sec)\nRecords: 1000  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\nQuery OK, 100000 rows affected (1.74 sec)\nRecords: 100000  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\nQuery OK, 100000 rows affected (2.15 sec)\nRecords: 100000  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t1 SELECT NULL, FLOOR(RAND()*1000), RANDOM_BYTES(255) FROM t1 a JOIN t1 b JOIN t1 c LIMIT 100000;\nQuery OK, 100000 rows affected (2.64 sec)\nRecords: 100000  Duplicates: 0  Warnings: 0\n\nmysql> SELECT SLEEP(1);\n+----------+\n| SLEEP(1) |\n+----------+\n|        0 |\n+----------+\n1 row in set (1.00 sec)\n\nmysql> ANALYZE TABLE t1;\nQuery OK, 0 rows affected (1.33 sec)\n```\n\n----------------------------------------\n\nTITLE: Disabling All Roles in the Current Session in TiDB\nDESCRIPTION: This snippet demonstrates how to disable all roles for the current session using the `SET ROLE NONE` statement. This deactivates all roles that were previously enabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/role-based-access-control.md#2025-04-18_snippet_18\n\nLANGUAGE: sql\nCODE:\n```\nSET ROLE NONE\n```\n\n----------------------------------------\n\nTITLE: Creating Test Table with Sample Data\nDESCRIPTION: Demonstrates table creation and initial data insertion for historical data testing in TiDB\nSOURCE: https://github.com/pingcap/docs/blob/master/read-historical-data.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\ncreate table t (c int);\ninsert into t values (1), (2), (3);\n```\n\n----------------------------------------\n\nTITLE: Setting Global Variable for Binding Evolution in TiDB SQL\nDESCRIPTION: This SQL command enables the automatic binding evolution feature by setting the global variable 'tidb_evolve_plan_baselines' to ON. This feature must be used with caution as it is experimental and not recommended for production environments.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_34\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_evolve_plan_baselines = ON;\n```\n\n----------------------------------------\n\nTITLE: Response from Inclusion-Filtered Vector Search\nDESCRIPTION: Shows the expected output when filtering for documents with book='paul_graham', returning detailed information about the author's learning experiences from those specific documents.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_13\n\nLANGUAGE: plain\nCODE:\n```\nThe author learned programming on an IBM 1401 using an early version of Fortran in 9th grade, then\nlater transitioned to working with microcomputers like the TRS-80 and Apple II. Additionally, the\nauthor studied philosophy in college but found it unfulfilling, leading to a switch to studying AI.\nLater on, the author attended art school in both the US and Italy, where they observed a lack of\nsubstantial teaching in the painting department.\n```\n\n----------------------------------------\n\nTITLE: DM's Metadata Cleanup for pt-osc\nDESCRIPTION: SQL query executed by DM to clean up metadata records related to ghost tables in the dm_meta table. This is done before processing new online DDL operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/feature-online-ddl.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM dm_meta.{task_name}_onlineddl WHERE id = {server_id} and ghost_schema = {ghost_schema} and ghost_table = {ghost_table};\n```\n\n----------------------------------------\n\nTITLE: Specifying Temporary Server Address for Mirror Rotation\nDESCRIPTION: Option to customize the listening address for the temporary HTTP server used during mirror rotation, allowing other administrators to sign the file\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror-rotate.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror rotate --addr 0.0.0.0:8080\n```\n\n----------------------------------------\n\nTITLE: Dump Specific Data Encryption Key\nDESCRIPTION: This command prints the specified data encryption key details, ensuring security practices are observed during the operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-control.md#2025-04-18_snippet_27\n\nLANGUAGE: shell\nCODE:\n```\ntikv-ctl --config=./conf.toml encryption-meta dump-key --ids=9291156302549018620\n```\n\n----------------------------------------\n\nTITLE: Safe Start Success Output\nDESCRIPTION: Example output showing successful cluster start with safe start method, including the automatically generated root password that needs to be recorded.\nSOURCE: https://github.com/pingcap/docs/blob/master/production-deployment-using-tiup.md#2025-04-18_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\nStarted cluster `tidb-test` successfully.\nThe root password of TiDB database has been changed.\nThe new password is: 'y_+3Hwp=*AWz8971s6'.\nCopy and record it to somewhere safe, it is only displayed once, and will not be stored.\nThe generated password can NOT be got again in future.\n```\n\n----------------------------------------\n\nTITLE: Setting up Python Virtual Environment for Django TiDB Project\nDESCRIPTION: Commands to set up a Python virtual environment for the Django project that will integrate with TiDB Vector Search.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-django-orm.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd tidb-vector-python/examples/orm-django-quickstart\npython3 -m venv .venv\nsource .venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Dynamically Adjusting TiKV GC Parameters with tikv-ctl\nDESCRIPTION: A shell command to dynamically modify the garbage collection write bandwidth limit in TiKV without restarting the cluster. This allows for runtime tuning of the garbage collection process to balance resource usage and performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/three-nodes-hybrid-deployment.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> tikv --host=${ip:port} modify-tikv-config -n gc.max_write_bytes_per_sec -v ${limit}\n```\n\n----------------------------------------\n\nTITLE: Enabling/Disabling Plugins with ADMIN PLUGINS SQL Statements in TiDB\nDESCRIPTION: Added ADMIN PLUGINS ENABLE and ADMIN PLUGINS DISABLE SQL statements to dynamically enable or disable plugins in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1.15.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nADMIN PLUGINS ENABLE\nADMIN PLUGINS DISABLE\n```\n\n----------------------------------------\n\nTITLE: PD Down Peer Region Count Alert Query\nDESCRIPTION: PromQL query to monitor the number of Regions with unresponsive peers reported by Raft leader\nSOURCE: https://github.com/pingcap/docs/blob/master/alert-rules.md#2025-04-18_snippet_10\n\nLANGUAGE: promql\nCODE:\n```\n(sum(pd_regions_status{type=\"down-peer-region-count\"}) by (instance)  > 0) and (sum(etcd_server_is_leader) by (instance) > 0)\n```\n\n----------------------------------------\n\nTITLE: Sink Configuration Example\nDESCRIPTION: Example configuration for sink parameters including dispatchers and protocol settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"dispatchers\":[\n    {\"matcher\":[\"test1.*\", \"test2.*\"], \"dispatcher\":\"ts\"},\n    {\"matcher\":[\"test3.*\", \"test4.*\"], \"dispatcher\":\"index-value\"}\n  ],\n  \"protocol\":\"canal-json\"\n}\n```\n\n----------------------------------------\n\nTITLE: Showing Configuration with LIKE Clause\nDESCRIPTION: This SQL statement demonstrates how to use the `LIKE` clause to show the configuration where the `type` is `tidb`. It filters the configuration based on a pattern matching the `type` column.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-config.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n\"SHOW CONFIG LIKE 'tidb';\"\n```\n\n----------------------------------------\n\nTITLE: Creating Final Package\nDESCRIPTION: Command to create the final tarball package for patching.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-patch.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntar czf /tmp/${component}-hotfix-${os}-${arch}.tar.gz *\n```\n\n----------------------------------------\n\nTITLE: Official Canal Output for Data Representation in JSON\nDESCRIPTION: This JSON snippet demonstrates the output from the official Canal for the same data structure, which includes complete MySQL types with parameters for each column in 'mysqlType'.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"id\": 0,\n    ...\n    \"isDdl\": false,\n    \"sqlType\": {\n        ...\n    },\n    \"mysqlType\": {\n        \"c_binary\": \"binary(16)\",\n        \"c_bit\": \"bit(64)\",\n        \"c_char\": \"char(16)\",\n        \"c_decimal\": \"decimal(10, 4)\",\n        \"c_enum\": \"enum('a','b','c')\",\n        \"c_set\": \"set('a','b','c')\",\n        \"c_varbinary\": \"varbinary(16)\",\n        \"c_varchar\": \"varchar(16)\",\n        \"id\": \"int\"\n    },\n    \"data\": [\n        {\n            ...\n        }\n    ],\n    \"old\": null,\n}\n```\n\n----------------------------------------\n\nTITLE: FLOAT Type Declaration in SQL\nDESCRIPTION: Two syntaxes for declaring FLOAT type with optional precision, display width, decimal places, unsigned flag and zero-fill option\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-numeric.md#2025-04-18_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nFLOAT[(M,D)] [UNSIGNED] [ZEROFILL]\n```\n\nLANGUAGE: sql\nCODE:\n```\nFLOAT(p) [UNSIGNED] [ZEROFILL]\n```\n\n----------------------------------------\n\nTITLE: Querying Specific TiCDC Replication Task Status\nDESCRIPTION: Commands to query detailed information about a specific replication task, with simplified and detailed output options.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-manage-changefeed.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed query -s --server=http://10.0.10.25:8300 --changefeed-id=simple-replication-task\n```\n\nLANGUAGE: shell\nCODE:\n```\ncdc cli changefeed query --server=http://10.0.10.25:8300 --changefeed-id=simple-replication-task\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Bundler\nDESCRIPTION: Command to install required Ruby gems (mysql2 and dotenv) using bundler for the sample application.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-ruby-mysql2.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbundle install\n```\n\n----------------------------------------\n\nTITLE: Configuring Available Zones for TiFlash Replicas\nDESCRIPTION: Configuration details for assigning zone labels to TiFlash nodes, facilitating disaster recovery setups across multiple data centers. Labels are set via the cluster configuration file, and this example demonstrates applying two different zone labels.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/create-tiflash-replicas.md#2025-04-18_snippet_9\n\nLANGUAGE: other\nCODE:\n```\ntiflash_servers:\n  - host: 172.16.5.81\n      logger.level: \"info\"\n    learner_config:\n      server.labels:\n        zone: \"z1\"\n  - host: 172.16.5.82\n    config:\n      logger.level: \"info\"\n    learner_config:\n      server.labels:\n        zone: \"z1\"\n  - host: 172.16.5.85\n    config:\n      logger.level: \"info\"\n    learner_config:\n      server.labels:\n        zone: \"z2\"\n```\n\n----------------------------------------\n\nTITLE: Enabling User Lingering for Systemd\nDESCRIPTION: Enable persistent systemd user instances for the tidb user\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster-no-sudo-mode.md#2025-04-18_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nloginctl enable-linger tidb\nloginctl show-user -p Linger tidb\n```\n\n----------------------------------------\n\nTITLE: Improving deadlock detector in TiKV\nDESCRIPTION: Enhances deadlock detector to only observe valid Regions, ensuring the deadlock manager operates in a valid Region.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.7.md#2025-04-18_snippet_6\n\nLANGUAGE: Rust\nCODE:\n```\n[#6110](https://github.com/tikv/tikv/pull/6110)\n```\n\n----------------------------------------\n\nTITLE: Equivalent Table Listing Statements in TiDB\nDESCRIPTION: Shows equivalent SQL statements for listing tables in a database, comparing the INFORMATION_SCHEMA.TABLES query approach with the simpler SHOW TABLES command.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-tables.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT table_name FROM INFORMATION_SCHEMA.TABLES\n  WHERE table_schema = 'db_name'\n  [AND table_name LIKE 'wild']\n\nSHOW TABLES\n  FROM db_name\n  [LIKE 'wild']\n```\n\n----------------------------------------\n\nTITLE: Column Data Format for DECIMAL(10, 4)\nDESCRIPTION: Illustrates the structure for a DECIMAL column with a precision of 10 and a scale of 4. It includes `logicalType`, `precision`, and `scale` properties.  The Avro type is `bytes`.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-avro-protocol.md#2025-04-18_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\":\"{{ColumnName}}\",\n    \"type\":{\n        \"connect.parameters\":{\n            \"tidb_type\":\"DECIMAL\",\n        },\n        \"logicalType\":\"decimal\",\n        \"precision\":10,\n        \"scale\":4,\n        \"type\":\"bytes\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring TiProxy Connection Buffer Size\nDESCRIPTION: Configuration for TiProxy connection buffer size, used in performance testing to optimize network communication\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-performance-test.md#2025-04-18_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nproxy.conn-buffer-size: 131072\n```\n\n----------------------------------------\n\nTITLE: Loading DM Data Source Configuration\nDESCRIPTION: Illustrates the selection of a source configuration in DM with `tiup dmctl`. The command uploads a source YAML file to a DM cluster via the master address.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-large-mysql-to-tidb.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntiup dmctl --master-addr ${advertise-addr} operate-source create source1.yaml\n```\n\n----------------------------------------\n\nTITLE: Using TiUP Cluster Destroy Command in Shell\nDESCRIPTION: Basic syntax for destroying a TiDB cluster using tiup cluster destroy. The command requires a cluster name parameter and supports optional flags for forced execution and data retention.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-destroy.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup cluster destroy <cluster-name> [flags]\n```\n\n----------------------------------------\n\nTITLE: TRAFFIC CAPTURE EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the TRAFFIC CAPTURE statement, showing the grammar rules and supported options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-traffic-capture.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nTrafficStmt ::=\n    \"TRAFFIC\" \"CAPTURE\" \"TO\" stringLit TrafficCaptureOptList\n\nTrafficCaptureOptList ::=\n    TrafficCaptureOpt\n|   TrafficCaptureOptList TrafficCaptureOpt\n\nTrafficCaptureOpt ::=\n    \"DURATION\" EqOpt stringLit\n|   \"ENCRYPTION_METHOD\" EqOpt stringLit\n|   \"COMPRESS\" EqOpt Boolean\n```\n\n----------------------------------------\n\nTITLE: Defining VARCHAR Column in TiDB\nDESCRIPTION: Syntax for creating a VARCHAR column with variable length and optional character set and collation. Maximum length depends on character set used.\nSOURCE: https://github.com/pingcap/docs/blob/master/data-type-string.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n[NATIONAL] VARCHAR(M) [CHARACTER SET charset_name] [COLLATE collation_name]\n```\n\n----------------------------------------\n\nTITLE: TiKV RaftStore Apply Batch Size Configuration Parameter (Modified)\nDESCRIPTION: TiKV parameter that controls the maximum batch size for raftstore apply operations. The maximum value has been changed to 10240.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.0.0-dmr.md#2025-04-18_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\nraftstore.apply-max-batch-size\n```\n\n----------------------------------------\n\nTITLE: SLOW_QUERY Table Structure Output in TiDB\nDESCRIPTION: This snippet shows the output of the DESC SLOW_QUERY command, displaying all columns in the SLOW_QUERY table along with their types, null constraints, key information, and default values.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-slow-query.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------------------------------+-----------------+------+------+---------+-------+\n| Field                                      | Type            | Null | Key  | Default | Extra |\n+--------------------------------------------+-----------------+------+------+---------+-------+\n| Time                                       | timestamp(6)    | NO   | PRI  | NULL    |       |\n| Txn_start_ts                               | bigint unsigned | YES  |      | NULL    |       |\n| User                                       | varchar(64)     | YES  |      | NULL    |       |\n| Host                                       | varchar(64)     | YES  |      | NULL    |       |\n| Conn_ID                                    | bigint unsigned | YES  |      | NULL    |       |\n| Session_alias                              | varchar(64)     | YES  |      | NULL    |       |\n| Exec_retry_count                           | bigint unsigned | YES  |      | NULL    |       |\n| Exec_retry_time                            | double          | YES  |      | NULL    |       |\n| Query_time                                 | double          | YES  |      | NULL    |       |\n| Parse_time                                 | double          | YES  |      | NULL    |       |\n| Compile_time                               | double          | YES  |      | NULL    |       |\n| Rewrite_time                               | double          | YES  |      | NULL    |       |\n| Preproc_subqueries                         | bigint unsigned | YES  |      | NULL    |       |\n| Preproc_subqueries_time                    | double          | YES  |      | NULL    |       |\n| Optimize_time                              | double          | YES  |      | NULL    |       |\n| Wait_TS                                    | double          | YES  |      | NULL    |       |\n| Prewrite_time                              | double          | YES  |      | NULL    |       |\n| Wait_prewrite_binlog_time                  | double          | YES  |      | NULL    |       |\n| Commit_time                                | double          | YES  |      | NULL    |       |\n| Get_commit_ts_time                         | double          | YES  |      | NULL    |       |\n| Commit_backoff_time                        | double          | YES  |      | NULL    |       |\n| Backoff_types                              | varchar(64)     | YES  |      | NULL    |       |\n| Resolve_lock_time                          | double          | YES  |      | NULL    |       |\n| Local_latch_wait_time                      | double          | YES  |      | NULL    |       |\n| Write_keys                                 | bigint          | YES  |      | NULL    |       |\n| Write_size                                 | bigint          | YES  |      | NULL    |       |\n| Prewrite_region                            | bigint          | YES  |      | NULL    |       |\n| Txn_retry                                  | bigint          | YES  |      | NULL    |       |\n| Cop_time                                   | double          | YES  |      | NULL    |       |\n| Process_time                               | double          | YES  |      | NULL    |       |\n| Wait_time                                  | double          | YES  |      | NULL    |       |\n| Backoff_time                               | double          | YES  |      | NULL    |       |\n| LockKeys_time                              | double          | YES  |      | NULL    |       |\n| Request_count                              | bigint unsigned | YES  |      | NULL    |       |\n| Total_keys                                 | bigint unsigned | YES  |      | NULL    |       |\n| Process_keys                               | bigint unsigned | YES  |      | NULL    |       |\n| Rocksdb_delete_skipped_count               | bigint unsigned | YES  |      | NULL    |       |\n| Rocksdb_key_skipped_count                  | bigint unsigned | YES  |      | NULL    |       |\n| Rocksdb_block_cache_hit_count              | bigint unsigned | YES  |      | NULL    |       |\n| Rocksdb_block_read_count                   | bigint unsigned | YES  |      | NULL    |       |\n| Rocksdb_block_read_byte                    | bigint unsigned | YES  |      | NULL    |       |\n| DB                                         | varchar(64)     | YES  |      | NULL    |       |\n| Index_names                                | varchar(100)    | YES  |      | NULL    |       |\n| Is_internal                                | tinyint(1)      | YES  |      | NULL    |       |\n| Digest                                     | varchar(64)     | YES  |      | NULL    |       |\n| Stats                                      | varchar(512)    | YES  |      | NULL    |       |\n| Cop_proc_avg                               | double          | YES  |      | NULL    |       |\n| Cop_proc_p90                               | double          | YES  |      | NULL    |       |\n| Cop_proc_max                               | double          | YES  |      | NULL    |       |\n| Cop_proc_addr                              | varchar(64)     | YES  |      | NULL    |       |\n| Cop_wait_avg                               | double          | YES  |      | NULL    |       |\n| Cop_wait_p90                               | double          | YES  |      | NULL    |       |\n| Cop_wait_max                               | double          | YES  |      | NULL    |       |\n| Cop_wait_addr                              | varchar(64)     | YES  |      | NULL    |       |\n| Mem_max                                    | bigint          | YES  |      | NULL    |       |\n| Disk_max                                   | bigint          | YES  |      | NULL    |       |\n| KV_total                                   | double          | YES  |      | NULL    |       |\n| PD_total                                   | double          | YES  |      | NULL    |       |\n| Backoff_total                              | double          | YES  |      | NULL    |       |\n| Unpacked_bytes_sent_tikv_total             | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_received_tikv_total         | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_sent_tikv_cross_zone        | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_received_tikv_cross_zone    | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_sent_tiflash_total          | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_received_tiflash_total      | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_sent_tiflash_cross_zone     | bigint          | YES  |      | NULL    |       |\n| Unpacked_bytes_received_tiflash_cross_zone | bigint          | YES  |      | NULL    |       |\n| Write_sql_response_total                   | double          | YES  |      | NULL    |       |\n| Result_rows                                | bigint          | YES  |      | NULL    |       |\n| Warnings                                   | longtext        | YES  |      | NULL    |       |\n| Backoff_Detail                             | varchar(4096)   | YES  |      | NULL    |       |\n| Prepared                                   | tinyint(1)      | YES  |      | NULL    |       |\n| Succ                                       | tinyint(1)      | YES  |      | NULL    |       |\n| IsExplicitTxn                              | tinyint(1)      | YES  |      | NULL    |       |\n| IsWriteCacheTable                          | tinyint(1)      | YES  |      | NULL    |       |\n| Plan_from_cache                            | tinyint(1)      | YES  |      | NULL    |       |\n| Plan_from_binding                          | tinyint(1)      | YES  |      | NULL    |       |\n| Has_more_results                           | tinyint(1)      | YES  |      | NULL    |       |\n| Resource_group                             | varchar(64)     | YES  |      | NULL    |       |\n| Request_unit_read                          | double          | YES  |      | NULL    |       |\n| Request_unit_write                         | double          | YES  |      | NULL    |       |\n| Time_queued_by_rc                          | double          | YES  |      | NULL    |       |\n| Tidb_cpu_time                              | double          | YES  |      | NULL    |       |\n| Tikv_cpu_time                              | double          | YES  |      | NULL    |       |\n| Plan                                       | longtext        | YES  |      | NULL    |       |\n| Plan_digest                                | varchar(128)    | YES  |      | NULL    |       |\n| Binary_plan                                | longtext        | YES  |      | NULL    |       |\n| Prev_stmt                                  | longtext        | YES  |      | NULL    |       |\n```\n\n----------------------------------------\n\nTITLE: Checking Directory Structure\nDESCRIPTION: Command to inspect the file structure in the temporary directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-patch.md#2025-04-18_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nfind .\n```\n\n----------------------------------------\n\nTITLE: Pausing Changefeed in TiCDC\nDESCRIPTION: This shell command pauses the active changefeed to prevent further data replication during the migration of writing services from the upstream to the downstream TiDB cluster, ensuring data consistency.\nSOURCE: https://github.com/pingcap/docs/blob/master/migrate-from-tidb-to-tidb.md#2025-04-18_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ntiup cdc cli changefeed pause -c \"upstream-to-downstream\" --server=http://172.16.6.122:8300\n\n```\n\n----------------------------------------\n\nTITLE: Listing Available Collations in TiDB\nDESCRIPTION: SQL query to show all supported collations in TiDB with their properties and attributes.\nSOURCE: https://github.com/pingcap/docs/blob/master/character-set-and-collation.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLLATION;\n```\n\n----------------------------------------\n\nTITLE: Filtered SHOW COLLATION Query\nDESCRIPTION: Example of using SHOW COLLATION with a WHERE clause to filter results for a specific character set (utf8mb4).\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-collation.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSHOW COLLATION WHERE Charset=\"utf8mb4\";\n```\n\n----------------------------------------\n\nTITLE: Configuring pessimistic auto-commit in TiDB\nDESCRIPTION: The 'pessimistic-auto-commit' configuration item in TiDB controls automatic committing for pessimistic transactions. It was found to not take effect for point-get queries, which has been fixed in this release.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.1.4.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\npessimistic-auto-commit = true\n```\n\n----------------------------------------\n\nTITLE: Configuring In-Memory Engine in TiKV\nDESCRIPTION: These YAML configuration options control the in-memory engine for accelerating multi-version queries in TiKV, including enabling the engine, setting memory capacity, and configuring GC intervals.\nSOURCE: https://github.com/pingcap/docs/blob/master/tikv-configuration-file.md#2025-04-18_snippet_37\n\nLANGUAGE: yaml\nCODE:\n```\nin-memory-engine:\n  enable: false\n  capacity: \"10%\"\n  gc-run-interval: \"3m\"\n  mvcc-amplification-threshold: 10\n```\n\n----------------------------------------\n\nTITLE: Listing exported files from Dumpling\nDESCRIPTION: Command to list the exported files generated by Dumpling, showing file sizes and names.\nSOURCE: https://github.com/pingcap/docs/blob/master/dumpling-overview.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nls -lh /tmp/test | awk '{print $5 \"\\t\" $9}'\n```\n\nLANGUAGE: shell\nCODE:\n```\n140B  metadata\n66B   test-schema-create.sql\n300B  test.sbtest1-schema.sql\n190K  test.sbtest1.0.sql\n300B  test.sbtest2-schema.sql\n190K  test.sbtest2.0.sql\n300B  test.sbtest3-schema.sql\n190K  test.sbtest3.0.sql\n```\n\n----------------------------------------\n\nTITLE: SHOW MASTER STATUS Output Example\nDESCRIPTION: This snippet provides a sample output format of the SHOW MASTER STATUS command, showing the structure of the returned result set. Each row contains fields that describe the current state of the binlog and TSO, important for replication and data consistency in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-master-status.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n+-------------+--------------------+--------------+------------------+-------------------+\n| File        | Position           | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |\n+-------------+--------------------+--------------+------------------+-------------------+\n| tidb-binlog | 416916363252072450 |              |                  |                   |\n+-------------+--------------------+--------------+------------------+-------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Updating TiUP Components\nDESCRIPTION: Updates TiUP and its cluster component to the latest version.\nSOURCE: https://github.com/pingcap/docs/blob/master/quick-start-with-tidb.md#2025-04-18_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ntiup update --self && tiup update cluster\n```\n\n----------------------------------------\n\nTITLE: Installing TiProxy using TiUP\nDESCRIPTION: Command to download and install TiProxy and TiProxy Control binaries using TiUP package manager\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-command-line-flags.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup install tiproxy\n# download https://tiup-mirrors.pingcap.com/tiproxy-v1.3.0-linux-amd64.tar.gz 22.51 MiB / 22.51 MiB 100.00% 13.99 MiB/s\nls `tiup --binary tiproxy`ctl\n# /root/.tiup/components/tiproxy/v1.3.0/tiproxyctl\n```\n\n----------------------------------------\n\nTITLE: Retrieving a Replication Task via GET API in Shell\nDESCRIPTION: An example of how to retrieve the configuration and status of an existing replication task by its name. The request includes the 'with_status=true' parameter to include task status information in the response.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_28\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'GET' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1?with_status=true' \\\n  -H 'accept: application/json'\n```\n\n----------------------------------------\n\nTITLE: Executing SQL Transactions to Prevent Write Skew\nDESCRIPTION: This SQL snippet shows the transaction flow using SELECT FOR UPDATE to prevent write skew. It checks the count of on-call doctors and updates the status if conditions are met.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-restraints.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\n/* txn 1 */ BEGIN\n    /* txn 2 */ BEGIN\n    /* txn 2 */ SELECT COUNT(*) as `count` FROM `doctors` WHERE `on_call` = 1 AND `shift_id` = 123\n    /* txn 2 */ UPDATE `doctors` SET `on_call` = 0 WHERE `id` = 2 AND `shift_id` = 123\n    /* txn 2 */ COMMIT\n/* txn 1 */ SELECT COUNT(*) AS `count` FROM `doctors` WHERE `on_call` = 1 and `shift_id` = 123\n/* txn 1 */ UPDATE `doctors` SET `on_call` = 0 WHERE `id` = 1 AND `shift_id` = 123\n/* txn 1 */ COMMIT\n```\n\n----------------------------------------\n\nTITLE: TiCDC Output for Data Representation in JSON\nDESCRIPTION: This JSON snippet illustrates the output generated by TiCDC for a data record in the Canal-JSON format, detailing MySQL types without parameters. It showcases the fields and their types for 'mysqlType'.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-canal-json.md#2025-04-18_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"id\": 0,\n    ...\n    \"isDdl\": false,\n    \"sqlType\": {\n        ...\n    },\n    \"mysqlType\": {\n        \"c_binary\": \"binary\",\n        \"c_bit\": \"bit\",\n        \"c_char\": \"char\",\n        \"c_decimal\": \"decimal\",\n        \"c_enum\": \"enum\",\n        \"c_set\": \"set\",\n        \"c_varbinary\": \"varbinary\",\n        \"c_varchar\": \"varchar\",\n        \"id\": \"int\"\n    },\n    \"data\": [\n        {\n            ...\n        }\n    ],\n    \"old\": null,\n}\n```\n\n----------------------------------------\n\nTITLE: Running Sysbench Test on TiDB\nDESCRIPTION: This shell command executes a Sysbench test on a TiDB cluster to simulate online workloads. The test runs with specified threads for 300,000 seconds, using uniform random distribution, and reports results every 15 seconds. It operates on the table created in the preparation step.\nSOURCE: https://github.com/pingcap/docs/blob/master/benchmark/online-workloads-and-add-index-operations.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsysbench $testname \\\n    --threads=$threads \\\n    --time=300000 \\\n    --report-interval=15 \\\n    --rand-type=uniform \\\n    --rand-seed=$RANDOM \\\n    --db-driver=mysql \\\n    --mysql-db=sbtest \\\n    --mysql-host=$tidb_host \\\n    --mysql-port=$tidb_port \\\n    --mysql-user=root \\\n    run --tables=1 --table-size=2000000\n```\n\n----------------------------------------\n\nTITLE: Fixing potential memory leak in TiKV\nDESCRIPTION: Addresses a potential memory leak issue in TiKV.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.7.md#2025-04-18_snippet_7\n\nLANGUAGE: Rust\nCODE:\n```\n[#6128](https://github.com/tikv/tikv/pull/6128)\n```\n\n----------------------------------------\n\nTITLE: Analyzing Query Plan Before Aggregate Push Down\nDESCRIPTION: Shows the execution plan and performance characteristics of a query before enabling the aggregate push down optimization, with aggregate operations occurring after the Join operation\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tune-tiflash-performance.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nexplain analyze select count(*) from t1 join t2 where t1.a = t2.b group by t1.a;\n```\n\n----------------------------------------\n\nTITLE: XML Configuration for Java Main Class\nDESCRIPTION: Maven project configuration to specify the startup class for the optimistic transaction example, enabling easy class path resolution and application entry point configuration\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_15\n\nLANGUAGE: xml\nCODE:\n```\n<mainClass>com.pingcap.txn.optimistic.TxnExample</mainClass>\n```\n\n----------------------------------------\n\nTITLE: Generating TiKV Certificate Signing Request\nDESCRIPTION: Command to generate a certificate signing request (CSR) for TiKV using the custom OpenSSL configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/generate-self-signed-certificates.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nopenssl req -new -key tikv.key -out tikv.csr -config openssl.cnf\n```\n\n----------------------------------------\n\nTITLE: Managing TiUP Mirrors - Command Syntax\nDESCRIPTION: This snippet defines the syntax for the 'tiup mirror' command, which is the primary interface for managing both local and remote mirrors. The command accepts various sub-commands and flags to perform different mirror-related operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-mirror.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup mirror <command> [flags]\n```\n\n----------------------------------------\n\nTITLE: Updating to Nightly Version\nDESCRIPTION: Update a specific component to its nightly development version using the --nightly flag\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-update.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiup update [component] --nightly\n```\n\n----------------------------------------\n\nTITLE: Component Metadata File Structure in JSON\nDESCRIPTION: The component metadata file contains information about component-specific platforms and versions. It includes signatures, component descriptions, platform support details, and versioning information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror-reference.md#2025-04-18_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"signatures\": [                                             # The file's signature.\n        {\n            \"keyid\": \"{id-of-index-key-1}\",                     # The ID of the first private key that participates in the signature.\n            \"sig\": \"{signature-by-index-key-1}\",                # The signed part of this file by this private key.\n        },\n        ...\n        {\n            \"keyid\": \"{id-of-root-key-N}\",                      # The ID of the Nth private key that participates in the signature.\n            \"sig\": \"{signature-by-root-key-N}\"                  # The signed part of this file by this private key.\n        }\n    ],\n    \"signed\": {\n        \"_type\": \"component\",                                   # The file type.\n        \"description\": \"{description-of-the-component}\",        # The description of the component.\n        \"expires\": \"{expiration-date-of-this-file}\",            # The expiration time of the file. If the file expires, the client rejects the file.\n        \"id\": \"{component-id}\",                                 # The globally unique ID of the component.\n        \"nightly\": \"{nightly-cursor}\",                          # The nightly cursor, and the value is the latest nightly version number (for example, v5.0.0-nightly-20201209).\n        \"platforms\": {                                          # The component's supported platforms (such as darwin/amd64, linux/arm64).\n            \"{platform-pair-1}\": {\n                \"{version-1}\": {                                # The semantic version number (for example, v1.0.0).\n                    \"dependencies\": null,                       # Specifies the dependency relationship between components. The field is not used yet and is fixed as null.\n                    \"entry\": \"{entry}\",                         # The relative path of the entry binary file in the tar package.\n                    \"hashs\": {                                  # The checksum of the tar package. sha256 and sha512 are used.\n                        \"sha256\": \"{sum-of-sha256}\",\n                        \"sha512\": \"{sum-of-sha512}\",\n                    },\n                    \"length\": {length-of-tar},                  # The length of the tar package.\n                    \"released\": \"{release-time}\",               # The release date of the version.\n                    \"url\": \"{url-of-tar}\",                      # The download address of the tar package.\n                    \"yanked\": {bool}                            # Indicates whether this version is disabled.\n                }\n            },\n            ...\n            \"{platform-pair-N}\": {\n                ...\n            }\n        },\n        \"spec_version\": \"0.1.0\",                                # The specified version followed by this file. If the file structure is changed in the future, the version number needs to be upgraded. The current version number is 0.1.0.\n        \"version\": {N}                                          # The version number of this file. You need to create a new {N+1}.{component}.json every time you update the file, and set its version to N + 1.\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Placement Policies for a Partitioned Table in TiDB\nDESCRIPTION: Shows how to specify placement policies for a partitioned table and individual partitions, demonstrating policy inheritance for partitions without explicit policies.\nSOURCE: https://github.com/pingcap/docs/blob/master/placement-rules-in-sql.md#2025-04-18_snippet_15\n\nLANGUAGE: sql\nCODE:\n```\nCREATE PLACEMENT POLICY storageforhistorydata CONSTRAINTS=\"[+node=history]\";\nCREATE PLACEMENT POLICY storagefornewdata CONSTRAINTS=\"[+node=new]\";\nCREATE PLACEMENT POLICY companystandardpolicy CONSTRAINTS=\"\";\n\nCREATE TABLE t1 (id INT, name VARCHAR(50), purchased DATE, UNIQUE INDEX idx(id) GLOBAL)\nPLACEMENT POLICY=companystandardpolicy\nPARTITION BY RANGE( YEAR(purchased) ) (\n  PARTITION p0 VALUES LESS THAN (2000) PLACEMENT POLICY=storageforhistorydata,\n  PARTITION p1 VALUES LESS THAN (2005),\n  PARTITION p2 VALUES LESS THAN (2010),\n  PARTITION p3 VALUES LESS THAN (2015),\n  PARTITION p4 VALUES LESS THAN MAXVALUE PLACEMENT POLICY=storagefornewdata\n);\n```\n\n----------------------------------------\n\nTITLE: Decreasing Partition Count in SQL\nDESCRIPTION: This SQL snippet shows how to decrease the number of partitions for a Hash partitioned table by one using COALESCE PARTITION.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_43\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE example COALESCE PARTITION 1;\n```\n\n----------------------------------------\n\nTITLE: Re-enable TiDB Dashboard\nDESCRIPTION: Command to re-enable TiDB Dashboard and trigger PD instance negotiation for dashboard service.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-ops-deploy.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd -u http://127.0.0.1:2379 config set dashboard-address auto\n```\n\n----------------------------------------\n\nTITLE: Even Split Example with Smaller Range in TiDB\nDESCRIPTION: SQL example for splitting a table into 16 evenly distributed regions across a smaller numeric range (0 to 1 billion) in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-split-region.md#2025-04-18_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nSPLIT TABLE t BETWEEN (0) AND (1000000000) REGIONS 16;\n```\n\n----------------------------------------\n\nTITLE: Copying OpenSSL Configuration Template\nDESCRIPTION: Command to copy the OpenSSL configuration template file to the current directory for customization.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-generate-self-signed-certificates.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncp /usr/lib/ssl/openssl.cnf .\n```\n\n----------------------------------------\n\nTITLE: Using Indexes to Override Optimizer Behavior in TiDB\nDESCRIPTION: This snippet shows how to use the USE INDEX hint to override the default optimizer behavior by specifying a particular index for query execution. This flexibility allows better control over the execution plan chosen by the optimizer, especially for complex queries that might benefit from specific index usage. The snippet assumes the existence of a database table with indices and is dependent on TiDB's compatibility with MySQL syntax.\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/sql-faq.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT column_name FROM table_name USE INDEX（index_name）WHERE where_condition;\n```\n\n----------------------------------------\n\nTITLE: Resume Log Backup Example\nDESCRIPTION: Example command to resume a paused log backup task with specified task name and PD address.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/br-pitr-manual.md#2025-04-18_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ntiup br log resume --task-name=pitr --pd=\"${PD_IP}:2379\"\n```\n\n----------------------------------------\n\nTITLE: Setting TiDB Connection String for Self-Managed Deployments\nDESCRIPTION: Example of a TiDB connection string format for self-managed deployments, showing the structure and required parameters for database connectivity.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-langchain.md#2025-04-18_snippet_4\n\nLANGUAGE: dotenv\nCODE:\n```\nTIDB_DATABASE_URL=\"mysql+pymysql://<USERNAME>:<PASSWORD>@<HOST>:<PORT>/<DATABASE_NAME>\"\n# For example: TIDB_DATABASE_URL=\"mysql+pymysql://root@127.0.0.1:4000/test\"\n```\n\n----------------------------------------\n\nTITLE: Checking I/O Scheduler in Linux\nDESCRIPTION: Command to view the current I/O scheduler settings for block devices sdb and sdc.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_30\n\nLANGUAGE: bash\nCODE:\n```\ncat /sys/block/sd[bc]/queue/scheduler\n```\n\n----------------------------------------\n\nTITLE: Load YCSB Data into TiKV (Bash)\nDESCRIPTION: This command loads data into TiKV for a YCSB benchmark. It uses the `load` subcommand of the TiUP bench ycsb component, specifying the PD address and the record count. The `-p` flag is used to set properties for the YCSB benchmark.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench ycsb load tikv -p tikv.pd=\"127.0.0.1:2379\" -p recordcount=10000\n```\n\n----------------------------------------\n\nTITLE: Querying Version Consistency in TiDB\nDESCRIPTION: This SQL query checks the version consistency of TiDB components by querying the inspection_result table in the information_schema.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-result.md#2025-04-18_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM information_schema.inspection_result WHERE rule='version'\\G\n```\n\n----------------------------------------\n\nTITLE: Checking CPU Support for TiFlash on Linux AMD64\nDESCRIPTION: Command to verify AVX2 instruction set support required for TiFlash deployment on Linux AMD64 architecture.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-overview.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngrep avx2 /proc/cpuinfo\n```\n\n----------------------------------------\n\nTITLE: tiup clean Output Message\nDESCRIPTION: This snippet showcases the output message format when the tiup clean command is executed successfully. It indicates which instance was cleaned along with its directory, enhancing user feedback.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-clean.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nClean instance of \"%s\", directory: %s\n```\n\n----------------------------------------\n\nTITLE: Querying Relay Log Status\nDESCRIPTION: Command to query the status of relay log for a specific data source.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/relay-log.md#2025-04-18_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nquery-status -s mysql-replica-01\n```\n\n----------------------------------------\n\nTITLE: Creating a Branch for TiDB Cloud Serverless Cluster (Command Syntax)\nDESCRIPTION: The base command syntax for creating a branch in a TiDB Cloud Serverless cluster. This command can be used in both interactive and non-interactive modes.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-branch-create.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless branch create [flags]\n```\n\n----------------------------------------\n\nTITLE: Checking Azure AD Environment Variables for TiDB Backup\nDESCRIPTION: These commands verify that the required Azure AD environment variables are properly configured in the operating environment before performing a backup operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/br/backup-and-restore-storages.md#2025-04-18_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\necho $AZURE_CLIENT_ID\necho $AZURE_TENANT_ID\necho $AZURE_CLIENT_SECRET\n```\n\n----------------------------------------\n\nTITLE: Querying DATA_LOCK_WAITS Table in SQL\nDESCRIPTION: This SQL snippet demonstrates how to query all columns from the DATA_LOCK_WAITS table, displaying the results in a vertical format.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-data-lock-waits.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nselect * from information_schema.data_lock_waits\\G\n```\n\n----------------------------------------\n\nTITLE: Integrating ProxySQL with TiDB Cloud Serverless\nDESCRIPTION: Command to execute the proxysql-prepare.sql script inside the ProxySQL Admin Interface, configuring ProxySQL to work with TiDB Cloud Serverless.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-proxysql-integration.md#2025-04-18_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose exec proxysql sh -c \"mysql -uadmin -padmin -h127.0.0.1 -P6032 < ./proxysql-prepare.sql\"\n```\n\n----------------------------------------\n\nTITLE: SHOW STATS_TOPN Syntax\nDESCRIPTION: This EBNF diagram defines the syntax for the `SHOW STATS_TOPN` statement in TiDB. It shows the optional `LIKE` or `WHERE` clauses that can be used to filter the results.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-topn.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf+diagram\nCODE:\n```\n\"SHOW\" \"STATS_TOPN\" ShowLikeOrWhere?\n\nShowLikeOrWhere ::=\n    \"LIKE\" SimpleExpr\n|   \"WHERE\" Expression\n```\n\n----------------------------------------\n\nTITLE: GRANT <role> EBNF Syntax Definition\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the GRANT <role> statement in TiDB, showing how to assign roles to users.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-grant-role.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nGrantRoleStmt ::=\n    'GRANT' RolenameList 'TO' UsernameList\n\nRolenameList ::=\n    Rolename ( ',' Rolename )*\n\nUsernameList ::=\n    Username ( ',' Username )*\n```\n\n----------------------------------------\n\nTITLE: Exporting Default Placement Rules with pd-ctl\nDESCRIPTION: This shell command exports the default Placement Rules configuration from PD. It's the first step in configuring read-only nodes to store data as learners.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/readonly-nodes.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npd-ctl config placement-rules rule-bundle load --out=\"rules.json\"\n```\n\n----------------------------------------\n\nTITLE: Installing TiUP on Linux\nDESCRIPTION: Command to install TiUP, a package manager for TiDB ecosystem tools, on a Linux system using curl.\nSOURCE: https://github.com/pingcap/docs/blob/master/get-started-with-tidb-lightning.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Changing Directory to Next.js Project\nDESCRIPTION: This shell command changes the current directory to the newly created Next.js project directory, `hello-repos`, to facilitate further commands.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-oas-with-nextjs.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncd hello-repos\n```\n\n----------------------------------------\n\nTITLE: Configuring Titan Engine Shared Cache in TiKV\nDESCRIPTION: This configuration snippet shows Titan engine parameters for enabling shared cache between blob files and RocksDB block files, which improves memory utilization and performance.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.0.0.md#2025-04-18_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\nshared-blob-cache\n```\n\nLANGUAGE: markdown\nCODE:\n```\nblob-cache-size\n```\n\n----------------------------------------\n\nTITLE: Fixing WEEKEND Function Compatibility in TiDB SQL\nDESCRIPTION: Addresses an issue where the WEEKEND function was not compatible with MySQL when the SQL mode is set to ALLOW_INVALID_DATES.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nWEEKEND()\n```\n\n----------------------------------------\n\nTITLE: Exporting data to Amazon S3 using Dumpling\nDESCRIPTION: Command to run Dumpling for exporting data from TiDB to an Amazon S3 bucket. Includes parameters for connection details, concurrency, file size limits, and S3 configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/migrate-from-op-tidb.md#2025-04-18_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ndumpling \\\n-u root \\\n-P 4000 \\\n-h 127.0.0.1 \\\n-r 20000 \\\n--filetype {sql|csv}  \\\n-F 256MiB  \\\n-t 8 \\\n-o \"${S3 URI}\" \\\n--s3.region \"${s3.region}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Token from File Parameter for Pulsar in TiCDC\nDESCRIPTION: This TOML snippet shows how to configure TiCDC to read the authentication token from a file.  The specified path must be accessible by the TiCDC server.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-sink-to-pulsar.md#2025-04-18_snippet_11\n\nLANGUAGE: toml\nCODE:\n```\n[sink.pulsar-config]\n# Pulsar uses tokens for authentication on the Pulsar server. Specify the path to the token file, which will be read from the TiCDC server.\ntoken-from-file=\"/data/pulsar/token-file.txt\"\n```\n\n----------------------------------------\n\nTITLE: Replaying Traffic with tiproxyctl\nDESCRIPTION: This shell command connects to a TiProxy instance to replay previously captured traffic using the specified user credentials and input directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiproxy/tiproxy-traffic-replay.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntiproxyctl traffic replay --host 10.0.1.10 --port 3080 --username=\"u1\" --password=\"123456\" --input=\"/tmp/traffic\"\n```\n\n----------------------------------------\n\nTITLE: Health Check API Call\nDESCRIPTION: cURL command to check the health status of a TiCDC cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-open-api.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X GET http://127.0.0.1:8300/api/v1/health\n```\n\n----------------------------------------\n\nTITLE: Manually Expiring a User Password in TiDB\nDESCRIPTION: This SQL statement shows how a database administrator can manually set a password to expire for a user, requiring the password to be changed before further login attempts.\nSOURCE: https://github.com/pingcap/docs/blob/master/password-management.md#2025-04-18_snippet_11\n\nLANGUAGE: SQL\nCODE:\n```\nALTER USER 'test'@'localhost' PASSWORD EXPIRE;\n```\n\n----------------------------------------\n\nTITLE: Fixing Privilege Check for SET DEFAULT ROLE ALL in TiDB\nDESCRIPTION: Corrects incorrect privilege checking for the SET DEFAULT ROLE ALL statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\nSET DEFAULT ROLE ALL TO user_name\n```\n\n----------------------------------------\n\nTITLE: Setting Firewall to Trusted Zone for TiDB Deployment\nDESCRIPTION: Command to set the default firewall zone to 'trusted', which allows all traffic by default. This is an alternative to completely disabling the firewall.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nfirewall-cmd --set-default-zone trusted\n```\n\n----------------------------------------\n\nTITLE: LOCK STATS Syntax in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax for the LOCK STATS command in TiDB. It shows how to lock statistics for tables or partitions.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-lock-stats.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nLockStatsStmt ::=\n    'LOCK' 'STATS' (TableNameList) | (TableName 'PARTITION' PartitionNameList)\n\nTableNameList ::=\n    TableName (',' TableName)*\n\nTableName ::=\n    Identifier ( '.' Identifier )?\n\nPartitionNameList ::=\n    Identifier ( ',' Identifier )*\n```\n\n----------------------------------------\n\nTITLE: Listing GitHub Pull Requests in Markdown\nDESCRIPTION: This snippet demonstrates how to list GitHub pull requests with links in Markdown format. It's used throughout the document to reference specific changes.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.8.md#2025-04-18_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n[#13891](https://github.com/pingcap/tidb/pull/13891)\n```\n\n----------------------------------------\n\nTITLE: Stopping TiDB Cluster Components\nDESCRIPTION: Commands to stop a TiDB cluster or specific components using TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/maintain-tidb-using-tiup.md#2025-04-18_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster stop ${cluster-name}\ntiup cluster stop ${cluster-name} -R tidb\ntiup cluster stop ${cluster-name} -N 1.2.3.4:4000,1.2.3.5:4000\n```\n\n----------------------------------------\n\nTITLE: Querying Environment Variables Using TiUP\nDESCRIPTION: The `tiup env` command retrieves user-defined environment variables in TiUP. It can display specific variables if given, or all variables by default. No additional options are available, and the output format differs based on whether specific variables are requested or not.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-command-env.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntiup env [name1...N]\n```\n\n----------------------------------------\n\nTITLE: Removing tombstone stores in TiDB PD\nDESCRIPTION: This command removes all stores in the 'Tombstone' state from the TiDB cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/pd-control.md#2025-04-18_snippet_51\n\nLANGUAGE: bash\nCODE:\n```\nstore remove-tombstone\n```\n\n----------------------------------------\n\nTITLE: Enabling Private DNS for VPC Endpoint\nDESCRIPTION: AWS CLI command to modify a VPC endpoint and enable private DNS functionality. This command requires the VPC endpoint ID as a parameter.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-private-endpoint-connections.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naws ec2 modify-vpc-endpoint --vpc-endpoint-id ${your_vpc_endpoint_id} --private-dns-enabled\n```\n\n----------------------------------------\n\nTITLE: Reloading Prometheus Configuration\nDESCRIPTION: This command reloads the Prometheus configuration and restarts Prometheus. It ensures that Prometheus is configured to monitor the newly added nodes. This is needed for versions earlier than TiUP v1.15.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/scale-tidb-using-tiup.md#2025-04-18_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\n\"tiup cluster reload <cluster-name> -R prometheus\"\n```\n\n----------------------------------------\n\nTITLE: Using a Mirror via Environment Variable\nDESCRIPTION: Example of using the TIUP_MIRRORS environment variable to temporarily use a specific mirror location without changing the global configuration.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nexport TIUP_MIRRORS=/shared_data/tiup\ntiup list\n```\n\n----------------------------------------\n\nTITLE: Installing NTP Service on CentOS 7\nDESCRIPTION: Commands to install NTP packages, start the service, and enable it for automatic startup.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\nsudo yum install ntp ntpdate && \\\nsudo systemctl start ntpd.service && \\\nsudo systemctl enable ntpd.service\n```\n\n----------------------------------------\n\nTITLE: Describing ANALYZE_STATUS Table Structure in SQL\nDESCRIPTION: This SQL query describes the structure of the ANALYZE_STATUS table in the information_schema database, showing all fields, their data types, and properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-analyze-status.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC analyze_status;\n```\n\n----------------------------------------\n\nTITLE: Example Response for Data Source Update in JSON\nDESCRIPTION: This JSON represents the response format returned after updating a data source. It contains the source configuration details including connection parameters and security settings.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"source_name\": \"mysql-01\",\n  \"host\": \"127.0.0.1\",\n  \"port\": 3306,\n  \"user\": \"root\",\n  \"password\": \"123456\",\n  \"enable\": true,\n  \"enable_gtid\": false,\n  \"security\": {\n    \"ssl_ca_content\": \"\",\n    \"ssl_cert_content\": \"\",\n    \"ssl_key_content\": \"\",\n    \"cert_allowed_cn\": [\n      \"string\"\n    ]\n  },\n  \"purge\": {\n    \"interval\": 3600,\n    \"expires\": 0,\n    \"remain_space\": 15\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting GC Life Time in TiDB\nDESCRIPTION: This snippet demonstrates how to adjust the `tidb_gc_life_time` system variable in TiDB to prevent data deletion issues caused by long transactions. Adjusting this parameter might consume extra storage space.\nSOURCE: https://github.com/pingcap/docs/blob/master/error-codes.md#2025-04-18_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSET GLOBAL tidb_gc_life_time = '30m';\n```\n\n----------------------------------------\n\nTITLE: Using Cluster Controllers with TiUP\nDESCRIPTION: Integrated control tools (tidb-ctl, pd-ctl, tikv-ctl, etcd-ctl) usage through TiUP's ctl component. Shows command mapping and example usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-cluster.md#2025-04-18_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\ntiup ctl:v<CLUSTER_VERSION> pd -u http://127.0.0.1:2379 store\n```\n\n----------------------------------------\n\nTITLE: Creating a New Jupyter Notebook File with Shell\nDESCRIPTION: Uses the touch command to create a new Jupyter Notebook file named integrate_with_llamaindex.ipynb in the root directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntouch integrate_with_llamaindex.ipynb\n```\n\n----------------------------------------\n\nTITLE: Call Chat2Data endpoint with Session ID\nDESCRIPTION: This snippet shows how to call the `/v3/sessions/{session_id}/chat2data` endpoint to continue a conversation using a session ID. It uses a curl command to send a POST request with the session ID, a user question, and optional feedback parameters. The `sql_generate_mode` parameter allows specifying how the SQL statements should be generated.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-sessions.md#2025-04-18_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --digest --user ${PUBLIC_KEY}:${PRIVATE_KEY} --request POST 'https://eu-central-1.data.tidbcloud.com/api/v1beta/app/chat2query-YqAvnlRj/endpoint/v3/sessions/{session_id}/chat2data'\\\n --header 'content-type: application/json'\\\n --data-raw '{\n    \"question\": \"<Your question to generate data>\",\n    \"feedback_answer_id\": \"\",\n    \"feedback_task_id\": \"\",\n    \"sql_generate_mode\": \"direct\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Creating a Replication Task with cURL (DM API)\nDESCRIPTION: This example demonstrates how to create a new replication task using the DM API. The PUT request configures a task with specific migration rules, source and target configurations, and binlog filtering rules.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-open-api.md#2025-04-18_snippet_30\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X 'PUT' \\\n  'http://127.0.0.1:8261/api/v1/tasks/task-1' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"task\": {\n    \"name\": \"task-1\",\n    \"task_mode\": \"all\",\n    \"shard_mode\": \"pessimistic\",\n    \"meta_schema\": \"dm-meta\",\n    \"enhance_online_schema_change\": true,\n    \"on_duplicate\": \"overwrite\",\n    \"target_config\": {\n      \"host\": \"127.0.0.1\",\n      \"port\": 3306,\n      \"user\": \"root\",\n      \"password\": \"123456\",\n      \"security\": {\n        \"ssl_ca_content\": \"\",\n        \"ssl_cert_content\": \"\",\n        \"ssl_key_content\": \"\",\n        \"cert_allowed_cn\": [\n          \"string\"\n        ]\n      }\n    },\n    \"binlog_filter_rule\": {\n      \"rule-1\": {\n        \"ignore_event\": [\n          \"all dml\"\n        ],\n        \"ignore_sql\": [\n          \"^Drop\"\n        ]\n      },\n      \"rule-2\": {\n        \"ignore_event\": [\n          \"all dml\"\n        ],\n        \"ignore_sql\": [\n          \"^Drop\"\n        ]\n      },\n      \"rule-3\": {\n        \"ignore_event\": [\n          \"all dml\"\n        ],\n        \"ignore_sql\": [\n          \"^Drop\"\n        ]\n      }\n    },\n    \"table_migrate_rule\": [\n      {\n        \"source\": {\n          \"source_name\": \"source-name\",\n          \"schema\": \"db-*\",\n          \"table\": \"tb-*\"\n        },\n        \"target\": {\n          \"schema\": \"db1\",\n          \"table\": \"tb1\"\n        },\n        \"binlog_filter_rule\": [\n          \"rule-1\",\n          \"rule-2\",\n          \"rule-3\",\n        ]\n      }\n    ],\n    \"source_config\": {\n      \"full_migrate_conf\": {\n        \"export_threads\": 4,\n        \"import_threads\": 16,\n        \"data_dir\": \"./exported_data\",\n        \"consistency\": \"auto\",\n        \"import_mode\": \"physical\",\n        \"sorting_dir\": \"./sort_dir\",\n        \"disk_quota\": \"80G\",\n        \"checksum\": \"required\",\n        \"analyze\": \"optional\",\n        \"range_concurrency\": 0,\n        \"compress-kv-pairs\": \"\",\n        \"pd_addr\": \"\",\n        \"on_duplicate_logical\": \"error\",\n        \"on_duplicate_physical\": \"none\"\n      },\n      \"incr_migrate_conf\": {\n        \"repl_threads\": 16,\n        \"repl_batch\": 100\n      },\n      \"source_conf\": [\n        {\n          \"source_name\": \"mysql-replica-01\",\n          \"binlog_name\": \"binlog.000001\",\n          \"binlog_pos\": 4,\n          \"binlog_gtid\": \"03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170\"\n        }\n      ]\n    }\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Displaying CLUSTER_CONFIG Table Structure in TiDB\nDESCRIPTION: SQL command to show the structure of the CLUSTER_CONFIG table in TiDB's information_schema database. The table contains four fields: TYPE, INSTANCE, KEY, and VALUE.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-cluster-config.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC cluster_config;\n```\n\n----------------------------------------\n\nTITLE: Testing Role Permissions SQL Commands\nDESCRIPTION: SQL commands demonstrating role permission behavior before setting the role active.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-set-default-role.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW GRANTS;\n+---------------------------------------------+\n| Grants for User                             |\n+---------------------------------------------+\n| GRANT USAGE ON *.* TO 'jennifer'@'%'        |\n| GRANT 'analyticsteam'@'%' TO 'jennifer'@'%' |\n+---------------------------------------------+\n2 rows in set (0.00 sec)\n\nSHOW TABLES in test;\nERROR 1044 (42000): Access denied for user 'jennifer'@'%' to database 'test'\nSET ROLE analyticsteam;\nQuery OK, 0 rows affected (0.00 sec)\n\nSHOW GRANTS;\n+---------------------------------------------+\n| Grants for User                             |\n+---------------------------------------------+\n| GRANT USAGE ON *.* TO 'jennifer'@'%'        |\n| GRANT Select ON test.* TO 'jennifer'@'%'    |\n| GRANT 'analyticsteam'@'%' TO 'jennifer'@'%' |\n+---------------------------------------------+\n3 rows in set (0.00 sec)\n\nSHOW TABLES IN test;\n+----------------+\n| Tables_in_test |\n+----------------+\n| t1             |\n+----------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Fixing lock TTL issue in TiDB\nDESCRIPTION: Addresses the problem where lock TTL value is too large due to TiDB server's local time being behind PD's timestamp.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.7.md#2025-04-18_snippet_0\n\nLANGUAGE: Go\nCODE:\n```\n[#13868](https://github.com/pingcap/tidb/pull/13868)\n```\n\n----------------------------------------\n\nTITLE: Removing Changefeed using TiUP CLI\nDESCRIPTION: This code snippet demonstrates how to remove a changefeed using the TiUP CLI. It is crucial when encountering issues due to incompatible CLI versions. The command forcefully removes the specified changefeed using its ID and the PD address.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-compatibility.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n\"tiup cdc:v4.0.9 cli changefeed remove -c xxxx --pd=xxxxx --force\"\n```\n\n----------------------------------------\n\nTITLE: Creating Node.js Project Directory for TiDB Cloud Serverless Driver\nDESCRIPTION: Shell commands to create a new directory for the Node.js project and navigate into it.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/serverless-driver-node-example.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nmkdir node-example\ncd node-example\n```\n\n----------------------------------------\n\nTITLE: FLUSH STATUS EBNF Syntax Definition\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the FLUSH STATUS statement and related flush operations in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-flush-status.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nFlushStmt ::=\n    'FLUSH' NoWriteToBinLogAliasOpt FlushOption\n\nNoWriteToBinLogAliasOpt ::=\n    ( 'NO_WRITE_TO_BINLOG' | 'LOCAL' )?\n\nFlushOption ::=\n    'PRIVILEGES'\n|   'STATUS'\n|    'TIDB' 'PLUGINS' PluginNameList\n|    'HOSTS'\n|   LogTypeOpt 'LOGS'\n|   TableOrTables TableNameListOpt WithReadLockOpt\n```\n\n----------------------------------------\n\nTITLE: Configuring TiDB Lightning\nDESCRIPTION: TOML configuration file for TiDB Lightning. It includes settings for logging, import mode, data source directory, and target TiDB cluster information.\nSOURCE: https://github.com/pingcap/docs/blob/master/get-started-with-tidb-lightning.md#2025-04-18_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[lightning]\nlevel = \"info\"\nfile = \"tidb-lightning.log\"\n\n[tikv-importer]\nbackend = \"local\"\nsorted-kv-dir = \"/mnt/ssd/sorted-kv-dir\"\n\n[mydumper]\ndata-source-dir = \"/data/my_datasource/\"\nfilter = ['*.*', '!mysql.*', '!sys.*', '!INFORMATION_SCHEMA.*', '!PERFORMANCE_SCHEMA.*', '!METRICS_SCHEMA.*', '!INSPECTION_SCHEMA.*']\n\n[tidb]\nhost = \"172.16.31.2\"\nport = 4000\nuser = \"root\"\npassword = \"rootroot\"\nstatus-port = 10080\npd-addr = \"172.16.31.3:2379,56.78.90.12:3456\"\n```\n\n----------------------------------------\n\nTITLE: Basic TiUP Playground Usage\nDESCRIPTION: Basic command structure for deploying a TiDB cluster using TiUP playground with version specification and flags.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-playground.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup playground ${version} [flags]\n```\n\n----------------------------------------\n\nTITLE: Querying a View in TiDB SQL\nDESCRIPTION: This snippet shows how to query a view in TiDB using the SELECT statement. It retrieves all columns from the book_with_ratings view, limiting the result to 10 rows.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-use-views.md#2025-04-18_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM book_with_ratings LIMIT 10;\n```\n\n----------------------------------------\n\nTITLE: Describing VARIABLES_INFO Table Structure in SQL\nDESCRIPTION: Shows the table structure of VARIABLES_INFO including field names, data types, and constraints.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-variables-info.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nUSE information_schema;\nDESC variables_info;\n```\n\n----------------------------------------\n\nTITLE: CREATE ROLE Syntax in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax definition for the CREATE ROLE statement in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-create-role.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCreateRoleStmt ::=\n    'CREATE' 'ROLE' IfNotExists RoleSpec (',' RoleSpec)*\n\nIfNotExists ::=\n    ('IF' 'NOT' 'EXISTS')?\n\nRoleSpec ::=\n    Rolename\n```\n\n----------------------------------------\n\nTITLE: Defining the BEGIN Statement Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) diagram showing the syntax of BEGIN and START TRANSACTION statements in TiDB SQL, including optional PESSIMISTIC/OPTIMISTIC transaction modes and READ WRITE/ONLY options.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-begin.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nBeginTransactionStmt ::=\n    'BEGIN' ( 'PESSIMISTIC' | 'OPTIMISTIC' )?\n|   'START' 'TRANSACTION' ( 'READ' ( 'WRITE' | 'ONLY' ( 'WITH' 'TIMESTAMP' 'BOUND' TimestampBound )? ) | 'WITH' 'CONSISTENT' 'SNAPSHOT' )?\n```\n\n----------------------------------------\n\nTITLE: Viewing TiDB Cluster List with TiUP\nDESCRIPTION: Command to display all TiDB clusters managed by TiUP.\nSOURCE: https://github.com/pingcap/docs/blob/master/maintain-tidb-using-tiup.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster list\n```\n\n----------------------------------------\n\nTITLE: MyBatis Batch Insert XML Mapper Configuration\nDESCRIPTION: XML configuration for MyBatis mapper demonstrating batch insert functionality with dynamic SQL foreach loop and duplicate key handling.\nSOURCE: https://github.com/pingcap/docs/blob/master/best-practices/java-app-best-practices.md#2025-04-18_snippet_9\n\nLANGUAGE: xml\nCODE:\n```\n<insert id=\"insertTestBatch\" parameterType=\"java.util.List\" fetchSize=\"1\">\n  insert into test\n   (id, v1, v2)\n  values\n  <foreach item=\"item\" index=\"index\" collection=\"list\" separator=\",\">\n  (\n   #{item.id}, #{item.v1}, #{item.v2}\n  )\n  </foreach>\n  on duplicate key update v2 = v1 + values(v1)\n</insert>\n```\n\n----------------------------------------\n\nTITLE: Displaying Help Information for tiup cluster audit\nDESCRIPTION: The `-h` or `--help` flag provides users with help information about the tiup cluster audit command. This flag is disabled by default, and users can enable it, allowing them to see usage instructions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-component-cluster-audit.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n-h, --help\n```\n\n----------------------------------------\n\nTITLE: Creating Table for SAVEPOINT Example in TiDB SQL\nDESCRIPTION: Creates a table 't1' with a single integer column 'a' as the primary key for demonstrating SAVEPOINT usage.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-savepoint.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t1 (a INT NOT NULL PRIMARY KEY);\n```\n\n----------------------------------------\n\nTITLE: Diagnosing TiDB Configuration Data\nDESCRIPTION: Command to analyze collected configuration data using the tiup diag check command. Requires the path containing meta.yaml file from the previous collection step.\nSOURCE: https://github.com/pingcap/docs/blob/master/clinic/clinic-user-guide-for-tiup.md#2025-04-18_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ntiup diag check ${subdir-in-output-data}\n```\n\n----------------------------------------\n\nTITLE: Time-Range Constrained Query on INSPECTION_RESULT in SQL\nDESCRIPTION: SQL query using a time_range hint to select diagnostic results from the inspection_result table within a specified time range.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-inspection-result.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nselect /*+ time_range(\"2020-03-26 00:03:00\", \"2020-03-26 00:08:00\") */ * from information_schema.inspection_result\\G\n```\n\n----------------------------------------\n\nTITLE: Aligning View Column Name Handling with MySQL in TiDB\nDESCRIPTION: Addresses inconsistency with MySQL in handling long view column names by automatically generating short column names.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_28\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE VIEW view_name AS SELECT very_long_column_name FROM table\n```\n\n----------------------------------------\n\nTITLE: GitHub Pull Request References in Release Notes\nDESCRIPTION: A collection of GitHub pull request references showing changes made across different components of TiDB ecosystem. These references link to specific changes including optimizations, bug fixes, and new feature implementations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-4.0-ga.md#2025-04-18_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[#17219](https://github.com/pingcap/tidb/pull/17219)\n[#588](https://github.com/pingcap/tiflow/pull/588)\n[#589](https://github.com/pingcap/tiflow/pull/589)\n[#7937](https://github.com/tikv/tikv/pull/7937)\n[#7930](https://github.com/tikv/tikv/pull/7930)\n[#7927](https://github.com/tikv/tikv/pull/7927)\n```\n\n----------------------------------------\n\nTITLE: JSON_TYPE Value Type Detection\nDESCRIPTION: Complex example showing how JSON_TYPE() identifies different value types in JSON data using a WITH clause and UNION.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/json-functions/json-functions-return.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nWITH demo AS (\n    SELECT 'null' AS 'v' \n    UNION SELECT '\"foobar\"' \n    UNION SELECT 'true' \n    UNION SELECT '5' \n    UNION SELECT '1.14' \n    UNION SELECT '[]' \n    UNION SELECT '{}' \n    UNION SELECT POW(2,63)\n)\nSELECT v, JSON_TYPE(v) FROM demo ORDER BY 2;\n```\n\n----------------------------------------\n\nTITLE: Failed ALTER TABLE Operation on Cached Table\nDESCRIPTION: Shows that adding an index to a cached table is not supported and results in an error.\nSOURCE: https://github.com/pingcap/docs/blob/master/cached-tables.md#2025-04-18_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nmysql> ALTER TABLE users ADD INDEX k_id(id);\n```\n\nLANGUAGE: sql\nCODE:\n```\nERROR 8242 (HY000): 'Alter Table' is unsupported on cache tables.\n```\n\n----------------------------------------\n\nTITLE: Error Response Structure from Chat2Data Endpoint in JSON\nDESCRIPTION: This json snippet illustrates an error response from the Chat2Data v1 endpoint. When execution fails, an error code like '500' is returned along with an error message, reflecting issues such as exceeded deadlines or permissions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/use-chat2query-api.md#2025-04-18_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"chat2data_endpoint\",\n  \"data\": {\n    \"columns\": [],\n    \"rows\": [],\n    \"result\": {\n      \"code\": 500,\n      \"message\": \"internal error! defaultPermissionHelper: rpc error: code = DeadlineExceeded desc = context deadline exceeded\",\n      \"start_ms\": \"\",\n      \"end_ms\": \"\",\n      \"latency\": \"\",\n      \"row_count\": 0,\n      \"row_affect\": 0,\n      \"limit\": 0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Rate Limit Exceeded Error Response in Bash\nDESCRIPTION: Example of a 429 HTTP response when API key rate limit is exceeded, showing rate limit headers and error details\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/data-service-api-key.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nHTTP/2 429\ndate: Mon, 05 Sep 2023 02:50:52 GMT\ncontent-type: application/json\ncontent-length: 420\nx-debug-trace-id: 202309040250529dcdf2055e7b2ae5e9\nx-ratelimit-reset: 8\nx-ratelimit-remaining-minute: 0\nx-ratelimit-limit-minute: 10\nx-kong-response-latency: 1\nserver: kong/2.8.1\n\n{\"type\":\"\",\"data\":{\"columns\":[],\"rows\":[],\"result\":{\"latency\":\"\",\"row_affect\":0,\"code\":49900007,\"row_count\":0,\"end_ms\":0,\"limit\":0,\"message\":\"API key rate limit exceeded. The limit can be increased up to 1000 requests per minute per API key in TiDB Cloud console. For an increase in quota beyond 1000 rpm, please contact us: https://tidb.support.pingcap.com/\",\"start_ms\":0}}}\n```\n\n----------------------------------------\n\nTITLE: Updating dbt project configuration file\nDESCRIPTION: YAML configuration for the dbt_project.yml file that defines project settings including the profile to use, path configurations, and materialization settings for different model types.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-dbt.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nname: 'jaffle_shop'\n\nconfig-version: 2\nversion: '0.1'\n\nprofile: 'jaffle_shop_tidb'                   # note the modification here\n\nmodel-paths: [\"models\"]                       # model path\nseed-paths: [\"seeds\"]                         # seed path\ntest-paths: [\"tests\"]\nanalysis-paths: [\"analysis\"]\nmacro-paths: [\"macros\"]\n\ntarget-path: \"target\"\nclean-targets:\n    - \"target\"\n    - \"dbt_modules\"\n    - \"logs\"\n\nrequire-dbt-version: [\">='1.0.0'\", \"<2.0.0\"]\n\nmodels:\n  jaffle_shop:\n      materialized: table            # *.sql which in models/ would be materialized to table\n      staging:\n        materialized: view           # *.sql which in models/staging/ would bt materialized to view\n```\n\n----------------------------------------\n\nTITLE: ALTER RANGE Syntax in EBNF\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax diagram for the ALTER RANGE statement in TiDB. It shows that the statement consists of the keywords 'ALTER RANGE', followed by an Identifier and a PlacementPolicyOption.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-alter-range.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nAlterRangeStmt ::=\n    'ALTER' 'RANGE' Identifier PlacementPolicyOption\n```\n\n----------------------------------------\n\nTITLE: SQL Range INTERVAL Partition Definition Example\nDESCRIPTION: New syntactic sugar for defining Range partitions in TiDB that simplifies DDL statements by eliminating the need to enumerate all partitions manually. This feature is marked as experimental.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-6.3.0.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nPARTITION BY RANGE COLUMNS (column_list)\n```\n\n----------------------------------------\n\nTITLE: Expected Output Verification Bash\nDESCRIPTION: This snippet displays how the expected output of a Bash command should look. By comparing this output, users can verify the success of their operations. There are no dependencies or parameters; this is purely an example of expected output.\nSOURCE: https://github.com/pingcap/docs/blob/master/resources/doc-templates/template-task.md#2025-04-18_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# expected output\n```\n\n----------------------------------------\n\nTITLE: SQL Pushdown Restriction for TiFlash\nDESCRIPTION: This SQL snippet illustrates constraints on pushing down expressions to TiFlash using a table and instances where certain operations must be computed on the root layer. It highlights unsupported functions in TiFlash, such as 'Time' and 'Cast'. Dependencies are similar, requiring TiDB and TiFlash. Output is an EXPLAIN table showing limited pushdown and warnings from unsupported functions.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiflash/tiflash-supported-pushdown-calculations.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE t(id INT PRIMARY KEY, a INT);\nALTER TABLE t SET TIFLASH REPLICA 1;\nINSERT INTO t(id,a) VALUES (1,2),(2,4),(11,2),(12,4),(13,4),(14,7);\n\nEXPLAIN SELECT id FROM t WHERE TIME(now()+ a) < '12:00:00';\n\n+-----------------------------+---------+--------------+---------------+--------------------------------------------------------------------------------------------------+\n| id                          | estRows | task         | access object | operator info                                                                                    |\n+-----------------------------+---------+--------------+---------------+--------------------------------------------------------------------------------------------------+\n| Projection_4                | 4.80    | root         |               | test.t.id                                                                                        |\n| └─Selection_6               | 4.80    | root         |               | lt(cast(time(cast(plus(20230110083056, test.t.a), var_string(20))), var_string(10)), \"12:00:00\") |\n|   └─TableReader_11          | 6.00    | root         |               | data:ExchangeSender_10                                                                           |\n|     └─ExchangeSender_10     | 6.00    | mpp[tiflash] |               | ExchangeType: PassThrough                                                                        |\n|       └─TableFullScan_9     | 6.00    | mpp[tiflash] | table:t       | keep order:false, stats:pseudo                                                                   |\n+-----------------------------+---------+--------------+---------------+--------------------------------------------------------------------------------------------------+\n5 rows in set, 3 warnings (0.20 sec)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSHOW WARNINGS;\n\n+---------+------+------------------------------------------------------------------------------------------------------------------------------------+\n| Level   | Code | Message                                                                                                                            |\n+---------+------+------------------------------------------------------------------------------------------------------------------------------------+\n| Warning | 1105 | Scalar function 'time'(signature: Time, return type: time) is not supported to push down to storage layer now.                     |\n| Warning | 1105 | Scalar function 'cast'(signature: CastDurationAsString, return type: var_string(10)) is not supported to push down to tiflash now. |\n| Warning | 1105 | Scalar function 'cast'(signature: CastDurationAsString, return type: var_string(10)) is not supported to push down to tiflash now. |\n+---------+------+------------------------------------------------------------------------------------------------------------------------------------+\n3 rows in set (0.18 sec)\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration\nDESCRIPTION: YAML configuration block defining document metadata including title, aliases, and summary information.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.1-rc.2.md#2025-04-18_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: TiDB 2.1 RC2 Release Notes\naliases: ['/docs/dev/releases/release-2.1-rc.2/','/docs/dev/releases/21rc2/']\nsummary: TiDB 2.1 RC2 was released on September 14, 2018, with improvements in stability, SQL optimizer, statistics, and execution engine.\n---\n```\n\n----------------------------------------\n\nTITLE: Modifying TiKV GC I/O Limit Using tikv-ctl\nDESCRIPTION: Shows how to use tikv-ctl to dynamically modify the GC I/O limit in TiKV. This command sets the maximum write bytes per second for garbage collection to 10MB.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.6.md#2025-04-18_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\ntikv-ctl --host=ip:port modify-tikv-config -m server -n gc.max_write_bytes_per_sec -v 10MB\n```\n\n----------------------------------------\n\nTITLE: Displaying Table Creation SQL with Global Indexes in TiDB\nDESCRIPTION: This SQL command shows how to display the creation SQL for a table with global indexes using the SHOW CREATE TABLE statement in TiDB.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_64\n\nLANGUAGE: SQL\nCODE:\n```\nSHOW CREATE TABLE t1\\G\n```\n\n----------------------------------------\n\nTITLE: Displaying Stats Healthy After Update\nDESCRIPTION: This SQL snippet displays the output of the `SHOW STATS_HEALTHY` command after deleting records, showing the database name, table name, partition name, and updated health percentage.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-stats-healthy.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n\"...\\nmysql> SHOW STATS_HEALTHY;\\n+---------+------------+----------------+---------+\\n| Db_name | Table_name | Partition_name | Healthy |\\n+---------+------------+----------------+---------+\\n| test    | t1         |                |      50 |\\n+---------+------------+----------------+---------+\\n1 row in set (0.00 sec)\\n\"\n```\n\n----------------------------------------\n\nTITLE: Modeling Primary Key UPDATE with Splits\nDESCRIPTION: This SQL segment demonstrates splitting a primary key `UPDATE` event into separate `DELETE` and `INSERT` events when primary keys are swapped within a transaction with multiple updates.\nSOURCE: https://github.com/pingcap/docs/blob/master/ticdc/ticdc-split-update-behavior.md#2025-04-18_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE t (a INT PRIMARY KEY, b INT);\nINSERT INTO t VALUES (1, 1);\nINSERT INTO t VALUES (2, 2);\n\nBEGIN;\nUPDATE t SET a = 3 WHERE a = 1;\nUPDATE t SET a = 1 WHERE a = 2;\nUPDATE t SET a = 2 WHERE a = 3;\nCOMMIT;\n```\n\n----------------------------------------\n\nTITLE: Java Program for Preventing Overselling Example\nDESCRIPTION: This snippet demonstrates how to run a Java program to prevent overselling when multiple transactions are executed simultaneously. It modifies the previous command by updating Bob's purchase quantity.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-optimistic-and-pessimistic-transaction.md#2025-04-18_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\nmvn clean package\njava -jar target/plain-java-txn-0.0.1-jar-with-dependencies.jar ALICE_NUM=4 BOB_NUM=7\n```\n\n----------------------------------------\n\nTITLE: Viewing Result from TIDB_DECODE_SQL_DIGESTS Function\nDESCRIPTION: Shows the output of TIDB_DECODE_SQL_DIGESTS function which returns a JSON array of SQL statements corresponding to the provided digest values. The second element is null because the digest couldn't be found in the cluster.\nSOURCE: https://github.com/pingcap/docs/blob/master/functions-and-operators/tidb-functions.md#2025-04-18_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n+------------------------------------+\n| TIDB_DECODE_SQL_DIGESTS(@digests)  |\n+------------------------------------+\n| [\"begin\",null,\"select * from `t`\"] |\n+------------------------------------+\n1 row in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into TiDB with mysqlclient in Python\nDESCRIPTION: This code snippet demonstrates how to insert data into a TiDB table using mysqlclient. It uses a parameterized query to safely insert values.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-python-mysqlclient.md#2025-04-18_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nwith get_mysqlclient_connection(autocommit=True) as conn:\n    with conn.cursor() as cur:\n        player = (\"1\", 1, 1)\n        cursor.execute(\"INSERT INTO players (id, coins, goods) VALUES (%s, %s, %s)\", player)\n```\n\n----------------------------------------\n\nTITLE: Executing Sample Application\nDESCRIPTION: Command to run the sample Node.js application that connects to TiDB using TypeORM.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-nodejs-typeorm.md#2025-04-18_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nnpm start\n```\n\n----------------------------------------\n\nTITLE: Upgrading Grafana with TiUP\nDESCRIPTION: Command to upgrade Grafana in the TiDB cluster using TiUP\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-monitoring-services.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster patch <cluster-name> grafana-v{new-version}.tar.gz -R grafana --overwrite\n```\n\n----------------------------------------\n\nTITLE: Querying All Table Attributes in SQL\nDESCRIPTION: Shows how to view attributes of all tables and partitions using a SELECT statement on the information_schema.attributes table.\nSOURCE: https://github.com/pingcap/docs/blob/master/table-attributes.md#2025-04-18_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.attributes;\n```\n\n----------------------------------------\n\nTITLE: Deprecation of Global Index and Partitioning Variables (Markdown)\nDESCRIPTION: Describes the deprecation of several variables related to indexing and partitioning, specifically their fixed default values from version 8.4.0.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-8.4.0.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| [`tidb_enable_global_index`](/system-variables.md#tidb_enable_global_index-new-in-v760) | Deprecated | In v8.4.0, this variable is deprecated. Its value will be fixed to the default value `ON`, that is, [global index](/partitioned-table.md#global-indexes) is enabled by default. You only need to add the keyword `GLOBAL` to the corresponding column when executing `CREATE TABLE` or `ALTER TABLE` to create a global index. |\n| [`tidb_enable_list_partition`](/system-variables.md#tidb_enable_list_partition-new-in-v50) | Deprecated | In v8.4.0, this variable is deprecated. Its value will be fixed to the default value `ON`, that is, [list partitioning](/partitioned-table.md#list-partitioning) is enabled by default. |\n| [`tidb_enable_table_partition`](/system-variables.md#tidb_enable_table_partition) | Deprecated | In v8.4.0, this variable is deprecated. Its value will be fixed to the default value `ON`, that is, [table partitioning](/system-variables.md) is enabled by default. |\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for TiDB and OpenAI\nDESCRIPTION: Securely prompts for and sets environment variables for TiDB connection string and OpenAI API key using getpass module.\nSOURCE: https://github.com/pingcap/docs/blob/master/vector-search/vector-search-integrate-with-llamaindex.md#2025-04-18_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Use getpass to securely prompt for environment variables in your terminal.\nimport getpass\nimport os\n\n# Copy your connection string from the TiDB Cloud console.\n# Connection string format: \"mysql+pymysql://<USER>:<PASSWORD>@<HOST>:4000/<DB>?ssl_ca=/etc/ssl/cert.pem&ssl_verify_cert=true&ssl_verify_identity=true\"\ntidb_connection_string = getpass.getpass(\"TiDB Connection String:\")\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n```\n\n----------------------------------------\n\nTITLE: Creating CPU Power Management Service\nDESCRIPTION: Script to create a systemd service for setting CPU frequency governor to performance mode.\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_29\n\nLANGUAGE: bash\nCODE:\n```\ncat  >> /etc/systemd/system/cpupower.service << EOF\n[Unit]\nDescription=CPU performance\n[Service]\nType=oneshot\nExecStart=/usr/bin/cpupower frequency-set --governor performance\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\n----------------------------------------\n\nTITLE: Viewing TiUP DM Help Information\nDESCRIPTION: Displays help information and available commands for the TiUP DM component\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/maintain-dm-using-tiup.md#2025-04-18_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntiup dm --help\n```\n\n----------------------------------------\n\nTITLE: Creating global binding - DELETE with USING clause\nDESCRIPTION: This code demonstrates a case where creating a global binding fails due to syntax conflicts with `DELETE` statements that contain the `USING` keyword.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-plan-management.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n-- Type two: `DELETE` statements that contain the `USING` keyword.\nCREATE GLOBAL BINDING for\n    DELETE FROM users USING users JOIN orders ON users.id = orders.user_id\nUSING\n    DELETE FROM users USING users JOIN orders ON users.id = orders.user_id;\n```\n\n----------------------------------------\n\nTITLE: Unsupported Sequelize Feature: Showing Index\nDESCRIPTION: This code snippet demonstrates an unsupported Sequelize operation in TiDB for showing indexes of a table.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-third-party-tools-compatibility.md#2025-04-18_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nsequelize.queryInterface.showIndex(Model.tableName);\n```\n\n----------------------------------------\n\nTITLE: Configuring Automatic Relay Log Purge\nDESCRIPTION: YAML configuration for enabling automatic purging of relay logs in the source configuration file.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/relay-log.md#2025-04-18_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\npurge:\n    interval: 3600\n    expires: 24\n    remain-space: 15\n```\n\n----------------------------------------\n\nTITLE: COMMIT Statement Syntax in EBNF Format\nDESCRIPTION: The Extended Backus-Naur Form (EBNF) syntax diagram for the COMMIT statement in TiDB, showing the command structure including optional parameters for transaction completion type.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-commit.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nCommitStmt ::=\n    'COMMIT' CompletionTypeWithinTransaction?\n\nCompletionTypeWithinTransaction ::=\n    'AND' ( 'CHAIN' ( 'NO' 'RELEASE' )? | 'NO' 'CHAIN' ( 'NO'? 'RELEASE' )? )\n|   'NO'? 'RELEASE'\n```\n\n----------------------------------------\n\nTITLE: Rewritten INSERT with ON DUPLICATE KEY UPDATE\nDESCRIPTION: The result of rewriting multiple INSERT statements with ON DUPLICATE KEY UPDATE clauses when using VALUES function. The statements are combined into a single SQL statement.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-connection-parameters.md#2025-04-18_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO `t` (`a`) VALUES (10), (11), (12) ON DUPLICATE KEY UPDATE a = VALUES(`a`);\n```\n\n----------------------------------------\n\nTITLE: CHARACTER_SETS Table Content Output\nDESCRIPTION: Displays the actual content of the CHARACTER_SETS table, showing supported character sets in TiDB with their properties.\nSOURCE: https://github.com/pingcap/docs/blob/master/information-schema/information-schema-character-sets.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n+--------------------+----------------------+-------------------------------------+--------+\n| CHARACTER_SET_NAME | DEFAULT_COLLATE_NAME | DESCRIPTION                         | MAXLEN |\n+--------------------+----------------------+-------------------------------------+--------+\n| ascii              | ascii_bin            | US ASCII                            |      1 |\n| binary             | binary               | binary                              |      1 |\n| gbk                | gbk_chinese_ci       | Chinese Internal Code Specification |      2 |\n| latin1             | latin1_bin           | Latin1                              |      1 |\n| utf8               | utf8_bin             | UTF-8 Unicode                       |      3 |\n| utf8mb4            | utf8mb4_bin          | UTF-8 Unicode                       |      4 |\n+--------------------+----------------------+-------------------------------------+--------+\n6 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: Simulating Write Skew in Doctor Shift Management (Java)\nDESCRIPTION: This Java code demonstrates a write skew scenario in a doctor shift management system using TiDB. It simulates two doctors attempting to take sick leave simultaneously, potentially violating the constraint of having at least one doctor on call.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-transaction-restraints.md#2025-04-18_snippet_0\n\nLANGUAGE: java\nCODE:\n```\npackage com.pingcap.txn.write.skew;\n\nimport com.zaxxer.hikari.HikariDataSource;\n\nimport java.sql.Connection;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.util.concurrent.CountDownLatch;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.Semaphore;\n\npublic class EffectWriteSkew {\n    public static void main(String[] args) throws SQLException, InterruptedException {\n        HikariDataSource ds = new HikariDataSource();\n        ds.setJdbcUrl(\"jdbc:mysql://localhost:4000/test?useServerPrepStmts=true&cachePrepStmts=true\");\n        ds.setUsername(\"root\");\n\n        // prepare data\n        Connection connection = ds.getConnection();\n        createDoctorTable(connection);\n        createDoctor(connection, 1, \"Alice\", true, 123);\n        createDoctor(connection, 2, \"Bob\", true, 123);\n        createDoctor(connection, 3, \"Carol\", false, 123);\n\n        Semaphore txn1Pass = new Semaphore(0);\n        CountDownLatch countDownLatch = new CountDownLatch(2);\n        ExecutorService threadPool = Executors.newFixedThreadPool(2);\n\n        threadPool.execute(() -> {\n            askForLeave(ds, txn1Pass, 1, 1);\n            countDownLatch.countDown();\n        });\n\n        threadPool.execute(() -> {\n            askForLeave(ds, txn1Pass, 2, 2);\n            countDownLatch.countDown();\n        });\n\n        countDownLatch.await();\n    }\n\n    public static void createDoctorTable(Connection connection) throws SQLException {\n        connection.createStatement().executeUpdate(\"CREATE TABLE `doctors` (\" +\n                \"    `id` int NOT NULL,\" +\n                \"    `name` varchar(255) DEFAULT NULL,\" +\n                \"    `on_call` tinyint DEFAULT NULL,\" +\n                \"    `shift_id` int DEFAULT NULL,\" +\n                \"    PRIMARY KEY (`id`),\" +\n                \"    KEY `idx_shift_id` (`shift_id`)\" +\n                \"  ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\");\n    }\n\n    public static void createDoctor(Connection connection, Integer id, String name, Boolean onCall, Integer shiftID) throws SQLException {\n        PreparedStatement insert = connection.prepareStatement(\n                \"INSERT INTO `doctors` (`id`, `name`, `on_call`, `shift_id`) VALUES (?, ?, ?, ?)\");\n        insert.setInt(1, id);\n        insert.setString(2, name);\n        insert.setBoolean(3, onCall);\n        insert.setInt(4, shiftID);\n        insert.executeUpdate();\n    }\n\n    public static void askForLeave(HikariDataSource ds, Semaphore txn1Pass, Integer txnID, Integer doctorID) {\n        try(Connection connection = ds.getConnection()) {\n            try {\n                connection.setAutoCommit(false);\n\n                String comment = txnID == 2 ? \"    \" : \"\" + \"/* txn #{txn_id} */ \";\n                connection.createStatement().executeUpdate(comment + \"BEGIN\");\n\n                // Txn 1 should be waiting for txn 2 done\n                if (txnID == 1) {\n                    txn1Pass.acquire();\n                }\n\n                PreparedStatement currentOnCallQuery = connection.prepareStatement(comment +\n                        \"SELECT COUNT(*) AS `count` FROM `doctors` WHERE `on_call` = ? AND `shift_id` = ?\");\n                currentOnCallQuery.setBoolean(1, true);\n                currentOnCallQuery.setInt(2, 123);\n                ResultSet res = currentOnCallQuery.executeQuery();\n\n                if (!res.next()) {\n                    throw new RuntimeException(\"error query\");\n                } else {\n                    int count = res.getInt(\"count\");\n                    if (count >= 2) {\n                        // If current on-call doctor has 2 or more, this doctor can leave\n                        PreparedStatement insert = connection.prepareStatement( comment +\n                                \"UPDATE `doctors` SET `on_call` = ? WHERE `id` = ? AND `shift_id` = ?\");\n                        insert.setBoolean(1, false);\n                        insert.setInt(2, doctorID);\n                        insert.setInt(3, 123);\n                        insert.executeUpdate();\n\n                        connection.commit();\n                    } else {\n                        throw new RuntimeException(\"At least one doctor is on call\");\n                    }\n                }\n\n                // Txn 2 done, let txn 1 run again\n                if (txnID == 2) {\n                    txn1Pass.release();\n                }\n            } catch (Exception e) {\n                // If got any error, you should roll back, data is priceless\n                connection.rollback();\n                e.printStackTrace();\n            }\n        } catch (SQLException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Markdown RawKV Mode Link Reference\nDESCRIPTION: Documentation link reference to TiKV's RawKV mode TTL feature documentation.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.1.4.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n[RawKV mode](https://tikv.org/docs/5.1/concepts/explore-tikv-features/ttl/)\n```\n\n----------------------------------------\n\nTITLE: Run TPC-H Test with Result Checking (Bash)\nDESCRIPTION: This command runs the TPC-H benchmark with a scale factor of 1 and checks the results. It sets the count to 22 and enables result checking with the `--check=true` flag.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-bench.md#2025-04-18_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ntiup bench tpch --count=22 --sf=1 --check=true run\n```\n\n----------------------------------------\n\nTITLE: Testing TiDB Cloud Connection\nDESCRIPTION: Simple SQL query to verify successful connection to TiDB Cloud.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-build-cluster-in-cloud.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSELECT 'Hello TiDB Cloud!';\n```\n\n----------------------------------------\n\nTITLE: Upgrading TiUP Offline Mirror\nDESCRIPTION: Steps to upgrade the TiUP offline mirror, including extracting the new version package, running the local install script, and merging offline mirrors.\nSOURCE: https://github.com/pingcap/docs/blob/master/upgrade-tidb-using-tiup.md#2025-04-18_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\ntar xzvf tidb-community-server-${version}-linux-amd64.tar.gz\nsh tidb-community-server-${version}-linux-amd64/local_install.sh\nsource /home/tidb/.bash_profile\n```\n\nLANGUAGE: Bash\nCODE:\n```\ntar xf tidb-community-toolkit-${version}-linux-amd64.tar.gz\nls -ld tidb-community-server-${version}-linux-amd64 tidb-community-toolkit-${version}-linux-amd64\ncd tidb-community-server-${version}-linux-amd64/\ncp -rp keys ~/.tiup/\ntiup mirror merge ../tidb-community-toolkit-${version}-linux-amd64\n```\n\nLANGUAGE: Bash\nCODE:\n```\ntiup update cluster\n```\n\n----------------------------------------\n\nTITLE: Restarting Component Type\nDESCRIPTION: Command to restart all instances of a specific component type in the cluster\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-troubleshooting-guide.md#2025-04-18_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntiup cluster restart -R <component>\n```\n\n----------------------------------------\n\nTITLE: Aligning UNION Statement Error Handling with SELECT in TiDB\nDESCRIPTION: Ensures that error handling for UNION statements is consistent with that of SELECT statements.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_26\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT column1 FROM table1\nUNION\nSELECT column2 FROM table2\n```\n\n----------------------------------------\n\nTITLE: Checking if the query hits plan cache in TiDB\nDESCRIPTION: This SQL snippet checks the value of the `@@last_plan_from_cache` session variable. If the value is 1, it indicates that the last executed query used an execution plan from the cache.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-non-prepared-plan-cache.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nSELECT @@last_plan_from_cache;\n```\n\n----------------------------------------\n\nTITLE: Displaying an Error When Creating Invalid Partitioned Tables - SQL\nDESCRIPTION: This snippet shows an SQL table creation statement that generates an error due to unique key constraints not being met in relation to the partitioning key. It provides insight into the conditions that lead to such errors.\nSOURCE: https://github.com/pingcap/docs/blob/master/partitioned-table.md#2025-04-18_snippet_55\n\nLANGUAGE: sql\nCODE:\n```\n```sql\nCREATE TABLE t3 (\n    col1 INT NOT NULL,\n    col2 DATE NOT NULL,\n    col3 INT NOT NULL,\n    col4 INT NOT NULL,\n    UNIQUE KEY (col1, col2),\n    UNIQUE KEY (col3)\n)\n\nPARTITION BY HASH(col1 + col3)\nPARTITIONS 4;\n```\n```\nERROR 8264 (HY000): Global Index is needed for index 'col1', since the unique index is not including all partitioning columns, and GLOBAL is not given as IndexOption\n```\n```\n\n----------------------------------------\n\nTITLE: Union with OrderBy SQL Example\nDESCRIPTION: Demonstrates the fixed behavior of Union statements with OrderBy clauses to maintain consistency with MySQL results.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-2.0.4.md#2025-04-18_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nSELECT ... UNION ... ORDER BY ...\n```\n\n----------------------------------------\n\nTITLE: Querying with TIDB_INLJ Hint in SQL\nDESCRIPTION: Demonstrates a query using the TIDB_INLJ hint for index nested loop join. This snippet shows how the hint is applied to a specific table in a join operation.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.2.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nexplain select /*+ TIDB_INLJ(t1) */ t1.b, t2.a from t t1, t t2 where t1.b = t2.a\n```\n\n----------------------------------------\n\nTITLE: Setting Table Attributes in TiDB\nDESCRIPTION: Demonstrates the syntax for altering table or partition attributes in TiDB. Currently supports setting the merge_option attribute to control Region merge behavior, useful after SPLIT TABLE operations.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-5.3.0.md#2025-04-18_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE [PARTITION] ATTRIBUTES\n```\n\n----------------------------------------\n\nTITLE: Viewing Region Distribution Output in TiDB\nDESCRIPTION: Example output from SHOW TABLE REGIONS command, displaying how a table is split into multiple Regions. Shows the Region IDs, key ranges, leader information, and storage statistics for each Region.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-show-table-regions.md#2025-04-18_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\n...\nmysql> SHOW TABLE t1 REGIONS;\n+-----------+--------------+--------------+-----------+-----------------+-------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n| REGION_ID | START_KEY    | END_KEY      | LEADER_ID | LEADER_STORE_ID | PEERS | SCATTERING | WRITTEN_BYTES | READ_BYTES | APPROXIMATE_SIZE(MB) | APPROXIMATE_KEYS | SCHEDULING_CONSTRAINTS | SCHEDULING_STATE |\n+-----------+--------------+--------------+-----------+-----------------+-------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n|        94 | t_75_        | t_75_r_31717 |        95 |               1 | 95    |          0 |             0 |          0 |                  112 |           207465 |                        |                  |\n|        96 | t_75_r_31717 | t_75_r_63434 |        97 |               1 | 97    |          0 |             0 |          0 |                   97 |                0 |                        |                  |\n|         2 | t_75_r_63434 |              |         3 |               1 | 3     |          0 |     269323514 |   66346110 |                  245 |           162020 |                        |                  |\n+-----------+--------------+--------------+-----------+-----------------+-------+------------+---------------+------------+----------------------+------------------+------------------------+------------------+\n3 rows in set (0.00 sec)\n```\n\n----------------------------------------\n\nTITLE: TiDB Dashboard Multi-PD Instance URL\nDESCRIPTION: URL format when accessing TiDB Dashboard with multiple PD instances deployed.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-access.md#2025-04-18_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nhttp://127.0.0.1:2379/dashboard/\n```\n\n----------------------------------------\n\nTITLE: Accepting AWS VPC Peering Connection\nDESCRIPTION: AWS CLI command to accept a pending VPC peering connection request from TiDB Cloud, using the peering connection ID stored in the environment variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/set-up-vpc-peering-connections.md#2025-04-18_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Accepts the VPC peering connection request.\naws ec2 accept-vpc-peering-connection --vpc-peering-connection-id \"$pcx_tidb_to_app_id\"\n```\n\n----------------------------------------\n\nTITLE: REPLACE Statement Syntax in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) representation of the REPLACE statement syntax in TiDB. It defines the structure and options for the REPLACE statement, including priority, table name, partition options, and insert values.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-replace.md#2025-04-18_snippet_0\n\nLANGUAGE: EBNF\nCODE:\n```\nReplaceIntoStmt ::=\n    'REPLACE' PriorityOpt IntoOpt TableName PartitionNameListOpt InsertValues\n\nPriorityOpt ::=\n    ( 'LOW_PRIORITY' | 'HIGH_PRIORITY' | 'DELAYED' )?\n\nIntoOpt ::= 'INTO'?\n\nTableName ::=\n    Identifier ( '.' Identifier )?\n\nPartitionNameListOpt ::=\n    ( 'PARTITION' '(' Identifier ( ',' Identifier )* ')' )?\n\nInsertValues ::=\n    '(' ( ColumnNameListOpt ')' ( ValueSym ValuesList | SelectStmt | '(' SelectStmt ')' | UnionStmt ) | SelectStmt ')' )\n|   ValueSym ValuesList\n|   SelectStmt\n|   UnionStmt\n|   'SET' ColumnSetValue? ( ',' ColumnSetValue )*\n```\n\n----------------------------------------\n\nTITLE: Listing Firewall Zone Policies for TiDB Environment\nDESCRIPTION: Command to list all policies for the trusted firewall zone, showing that all traffic is allowed by default (target: ACCEPT).\nSOURCE: https://github.com/pingcap/docs/blob/master/check-before-deployment.md#2025-04-18_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nfirewall-cmd --zone=trusted --list-all\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Configuration\nDESCRIPTION: Shell command to copy the example environment file and create a configuration for TiDB Cloud Serverless connection parameters.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/dev-guide-wordpress.md#2025-04-18_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Cloning Airbyte Repository and Changing Directory\nDESCRIPTION: Clone the Airbyte source code repository and navigate to the project directory.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-airbyte.md#2025-04-18_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/airbytehq/airbyte.git && \\\ncd airbyte\n```\n\n----------------------------------------\n\nTITLE: Decoding TiDB Execution Plan in SQL\nDESCRIPTION: SQL command to parse and view the detailed execution plan of a query in TiDB. This helps in analyzing query performance and identifying potential issues with execution plans.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-cpu-issues.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nselect tidb_decode_plan('xxx...')\n```\n\n----------------------------------------\n\nTITLE: Derived Table Alias Requirement in TiDB\nDESCRIPTION: Compares the requirement for derived table aliases in TiDB against Oracle's lack of such a requirement.\nSOURCE: https://github.com/pingcap/docs/blob/master/oracle-functions-to-tidb.md#2025-04-18_snippet_28\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM (SELECT * FROM test)\n```\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM (SELECT * FROM test) t\n```\n\n----------------------------------------\n\nTITLE: Output from Running Custom Component\nDESCRIPTION: Shows the expected output when running a custom component for the first time, including the automatic installation process.\nSOURCE: https://github.com/pingcap/docs/blob/master/tiup/tiup-mirror.md#2025-04-18_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nThe component `hello` version  is not installed; downloading from repository.\nStarting component `hello`: /home/dvaneeden/.tiup/components/hello/v0.0.1/hello\nhello\n```\n\n----------------------------------------\n\nTITLE: Database Object Naming Examples\nDESCRIPTION: Examples showing recommended naming patterns for temporary and test databases\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-object-naming-guidelines.md#2025-04-18_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ntmp_crm\ntest_crm\n```\n\n----------------------------------------\n\nTITLE: Key-Value pairs in TiKV without MVCC\nDESCRIPTION: This code snippet illustrates the Key-Value pair structure in TiKV before the introduction of Multi-Version Concurrency Control (MVCC). Each key is directly associated with a single value, representing the latest state of the data.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-storage.md#2025-04-18_snippet_0\n\nLANGUAGE: none\nCODE:\n```\n\"Key1 -> Value\nKey2 -> Value\n……\nKeyN -> Value\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Cascades Optimizer in TiDB SQL\nDESCRIPTION: Adds a new variable to enable the Cascades optimizer, which is not fully implemented and turned off by default.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0-beta.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_enable_cascades_planner = 1;\n```\n\n----------------------------------------\n\nTITLE: Creating Dashboard Admin User without SEM\nDESCRIPTION: SQL commands to create a dashboard admin user with minimum required privileges when Security Enhanced Mode is disabled.\nSOURCE: https://github.com/pingcap/docs/blob/master/dashboard/dashboard-user.md#2025-04-18_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE USER 'dashboardAdmin'@'%' IDENTIFIED BY '<YOUR_PASSWORD>';\nGRANT PROCESS, CONFIG ON *.* TO 'dashboardAdmin'@'%';\nGRANT SHOW DATABASES ON *.* TO 'dashboardAdmin'@'%';\nGRANT DASHBOARD_CLIENT ON *.* TO 'dashboardAdmin'@'%';\n\n-- To modify the configuration items on the interface after signing in to TiDB Dashboard, the user-defined SQL user must be granted with the following privilege.\nGRANT SYSTEM_VARIABLES_ADMIN ON *.* TO 'dashboardAdmin'@'%';\n\n-- To use the Fast Bind Executions Plan feature on the interface after signing in to TiDB Dashboard, the user-defined SQL user must be granted with the following privileges.\nGRANT SYSTEM_VARIABLES_ADMIN ON *.* TO 'dashboardAdmin'@'%';\nGRANT SUPER ON *.* TO 'dashboardAdmin'@'%';\n```\n\n----------------------------------------\n\nTITLE: Correcting Link Simplification in TiDB Query Optimization\nDESCRIPTION: Fixes an issue caused by incorrectly simplifying the link when the predicate only refers to the outer table.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM outer_table LEFT JOIN inner_table ON outer_table.id = inner_table.id WHERE outer_table.column = 'value'\n```\n\n----------------------------------------\n\nTITLE: Correcting Partitioned Table Information in TiDB Hot Table\nDESCRIPTION: Fixes incorrect information about partitioned tables in the information_schema.tidb_hot_table view.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_23\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM information_schema.tidb_hot_table\n```\n\n----------------------------------------\n\nTITLE: TiKV Region Read Progress Log Output\nDESCRIPTION: Example log output showing the Region read progress details including safe_ts, applied_index, resolver status, and other diagnostic information.\nSOURCE: https://github.com/pingcap/docs/blob/master/troubleshoot-stale-read.md#2025-04-18_snippet_1\n\nLANGUAGE: log\nCODE:\n```\nRegion read progress:\n    exist: true,\n    safe_ts: 0,\n    applied_index: 92,\n    pending front item (oldest) ts: 0,\n    pending front item (oldest) applied index: 0,\n    pending back item (latest) ts: 0,\n    pending back item (latest) applied index: 0,\n    paused: false,\nResolver:\n    exist: true,\n    resolved_ts: 0,\n    tracked index: 92,\n    number of locks: 0,\n    number of transactions: 0,\n    stopped: false,\n```\n\n----------------------------------------\n\nTITLE: Updating Environment Variables in template.yml\nDESCRIPTION: YAML configuration for setting TiDB connection environment variables in the AWS SAM template.\nSOURCE: https://github.com/pingcap/docs/blob/master/develop/dev-guide-sample-application-aws-lambda.md#2025-04-18_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nEnvironment:\n  Variables:\n    TIDB_HOST: {tidb_server_host}\n    TIDB_PORT: 4000\n    TIDB_USER: {prefix}.root\n    TIDB_PASSWORD: {password}\n```\n\n----------------------------------------\n\nTITLE: Enabling Fast Analyze in TiDB SQL\nDESCRIPTION: Enables the Fast Analyze feature to speed up statistics collection by sampling regions instead of full scans. Controlled by the tidb_enable_fast_analyze variable.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.0-rc.1.md#2025-04-18_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSET tidb_enable_fast_analyze = 1;\n```\n\n----------------------------------------\n\nTITLE: TiDB Cloud Custom Query Trigger Configuration\nDESCRIPTION: Shows the requirements and limitations for the New Row (Custom Query) trigger in TiDB Cloud Zapier integration. The query must return an id field for deduplication and execute within 30 seconds.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/integrate-tidbcloud-with-zapier.md#2025-04-18_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nThe `New Row (Custom Query)` trigger limits 1,000,000 results in every fetch. 1,000,000 is a large number, and it is only set so as to protect the whole system. It is recommended that your query includes `ORDER BY` and `LIMIT`.\n```\n\n----------------------------------------\n\nTITLE: Fixing MergeJoin Panic on Tables with Redundant Indexes in TiDB\nDESCRIPTION: Resolves a panic caused by the MergeJoin operation on tables with redundant indexes.\nSOURCE: https://github.com/pingcap/docs/blob/master/releases/release-3.0.14.md#2025-04-18_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM table1 INNER JOIN table2 ON table1.column = table2.column\n```\n\n----------------------------------------\n\nTITLE: RENAME USER Syntax Definition in EBNF\nDESCRIPTION: Extended Backus-Naur Form (EBNF) syntax definition for the RENAME USER command, showing the grammar rules for renaming users including support for host specifications and CURRENT_USER option.\nSOURCE: https://github.com/pingcap/docs/blob/master/sql-statements/sql-statement-rename-user.md#2025-04-18_snippet_0\n\nLANGUAGE: ebnf\nCODE:\n```\nRenameUserStmt ::=\n    'RENAME' 'USER' UserToUser ( ',' UserToUser )*\nUserToUser ::=\n    Username 'TO' Username\nUsername ::=\n    StringName ('@' StringName | singleAtIdentifier)? | 'CURRENT_USER' OptionalBraces\n```\n\n----------------------------------------\n\nTITLE: Enabling MB4 Value Check via HTTP API\nDESCRIPTION: Using HTTP API to enable or disable MB4 value checking on a single TiDB server\nSOURCE: https://github.com/pingcap/docs/blob/master/faq/upgrade-faq.md#2025-04-18_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST -d \"check_mb4_value_in_utf8=1\" http://{TiDBIP}:10080/settings\n```\n\n----------------------------------------\n\nTITLE: Exporting Data in Interactive Mode\nDESCRIPTION: This example shows how to run the export command in interactive mode, where the user will be prompted for necessary information.\nSOURCE: https://github.com/pingcap/docs/blob/master/tidb-cloud/ticloud-serverless-export-create.md#2025-04-18_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nticloud serverless export create\n```\n\n----------------------------------------\n\nTITLE: Managing Task Status Transitions Using Diagrams\nDESCRIPTION: This ASCII diagram represents the status transitions of tasks in a system. It visually demonstrates how tasks move between states such as 'New', 'Running', 'Paused', 'Stopped', and 'Finished'. Transitions are triggered by actions like 'resume-task', 'pause-task', and 'stop-task', or when errors occur. It helps in understanding the system's workflow and managing tasks effectively.\nSOURCE: https://github.com/pingcap/docs/blob/master/dm/dm-query-status.md#2025-04-18_snippet_3\n\nLANGUAGE: Diagram\nCODE:\n```\n                                         error occurs\n                            New --------------------------------|\n                             |                                  |\n                             |           resume-task            |\n                             |  |----------------------------|  |\n                             |  |                            |  |\n                             |  |                            |  |\n                             v  v        error occurs        |  v\n  Finished <-------------- Running -----------------------> Paused\n                             ^  |        or pause-task       |\n                             |  |                            |\n                  start task |  | stop task                  |\n                             |  |                            |\n                             |  v        stop task           |\n                           Stopped <-------------------------|\n```"
  }
]