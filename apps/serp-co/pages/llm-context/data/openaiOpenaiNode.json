[
  {
    "owner": "openai",
    "repo": "openai-node",
    "content": "TITLE: Creating Chat Completions using OpenAI Node.js Client\nDESCRIPTION: Calls the `create` method on the `chat.completions` resource to generate a chat completion. It accepts an object with parameters (like messages and model) and returns a `ChatCompletion` object. This corresponds to the `POST /chat/completions` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nclient.chat.completions.create({ ...params }) -> ChatCompletion\n```\n\n----------------------------------------\n\nTITLE: Creating Embeddings using OpenAI Node.js Client\nDESCRIPTION: Calls the `create` method on the `embeddings` resource to generate vector embeddings for input text. It accepts an object with parameters (like input text and model) and returns a `CreateEmbeddingResponse` object containing the generated embeddings. This corresponds to the `POST /embeddings` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nclient.embeddings.create({ ...params }) -> CreateEmbeddingResponse\n```\n\n----------------------------------------\n\nTITLE: Creating Moderations with OpenAI Node.js Client\nDESCRIPTION: Invokes the OpenAI Moderations API endpoint to check input content against OpenAI's usage policies. It utilizes the `create` method on the `client.moderations` object, taking parameters like the input text or image URL, and returns a `ModerationCreateResponse` object detailing the moderation results.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_21\n\nLANGUAGE: typescript\nCODE:\n```\nclient.moderations.create({ ...params }) -> ModerationCreateResponse\n```\n\n----------------------------------------\n\nTITLE: Parsing Function Tool Calls with Zod Schemas in OpenAI Chat Completions - TypeScript\nDESCRIPTION: Shows how to define complex input and function tool schemas using Zod, and apply the zodFunction helper to enable type-safe auto-parsing of function tool call arguments in OpenAI's chat completions. Requires OpenAI Node.js SDK and Zod. Key parameters include elaborate Zod schemas for tables, columns, operators, and the overall query structure mapping to a database-like request. Outputs are type-checked, parsed arguments for function tool calls, along with example access to parsed fields. All tool schemas must be marked as strict as required by the parse() API constraint.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { zodFunction } from 'openai/helpers/zod';\nimport OpenAI from 'openai/index';\nimport { z } from 'zod';\n\nconst Table = z.enum(['orders', 'customers', 'products']);\n\nconst Column = z.enum([\n  'id',\n  'status',\n  'expected_delivery_date',\n  'delivered_at',\n  'shipped_at',\n  'ordered_at',\n  'canceled_at',\n]);\n\nconst Operator = z.enum(['=', '>', '<', '<=', '>=', '!=']);\n\nconst OrderBy = z.enum(['asc', 'desc']);\n\nconst DynamicValue = z.object({\n  column_name: z.string(),\n});\n\nconst Condition = z.object({\n  column: z.string(),\n  operator: Operator,\n  value: z.union([z.string(), z.number(), DynamicValue]),\n});\n\nconst Query = z.object({\n  table_name: Table,\n  columns: z.array(Column),\n  conditions: z.array(Condition),\n  order_by: OrderBy,\n});\n\nconst client = new OpenAI();\nconst completion = await client.beta.chat.completions.parse({\n  model: 'gpt-4o-2024-08-06',\n  messages: [\n    {\n      role: 'system',\n      content:\n        'You are a helpful assistant. The current date is August 6, 2024. You help users query for the data they are looking for by calling the query function.',\n    },\n    {\n      role: 'user',\n      content: 'look up all my orders in november of last year that were fulfilled but not delivered on time',\n    },\n  ],\n  tools: [zodFunction({ name: 'query', parameters: Query })],\n});\nconsole.dir(completion, { depth: 10 });\n\nconst toolCall = completion.choices[0]?.message.tool_calls?.[0];\nif (toolCall) {\n  const args = toolCall.function.parsed_arguments as z.infer<typeof Query>;\n  console.log(args);\n  console.log(args.table_name);\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Listing Chat Completions using OpenAI Node.js Client\nDESCRIPTION: Calls the `list` method on the `chat.completions` resource to retrieve a list of chat completions. It accepts an optional object with parameters for filtering or pagination and returns a `ChatCompletionsPage` object. This corresponds to the `GET /chat/completions` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nclient.chat.completions.list({ ...params }) -> ChatCompletionsPage\n```\n\n----------------------------------------\n\nTITLE: Integrating Zod for Schema Validation in OpenAI Function Calls (TypeScript)\nDESCRIPTION: Illustrates integrating the 'zod' library with the OpenAI Node.js SDK to validate function call arguments and generate the JSON schema for the tool parameters. The example uses `runTools`, defines a tool with `parse` (using `ZodObject.parse`) and `parameters` (using `zodToJsonSchema`), creates a Zod schema, implements the corresponding function, and awaits the final content.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\n```ts\nimport OpenAI from 'openai';\nimport { z } from 'zod';\nimport { zodToJsonSchema } from 'zod-to-json-schema';\n\nconst client = new OpenAI();\n\nasync function main() {\n  const runner = client.chat.completions\n    .runTools({\n      model: 'gpt-3.5-turbo',\n      messages: [{ role: 'user', content: \"How's the weather this week in Los Angeles?\" }],\n      tools: [\n        {\n          type: 'function',\n          function: {\n            function: getWeather,\n            parse: GetWeatherParameters.parse,\n            parameters: zodToJsonSchema(GetWeatherParameters),\n          },\n        },\n      ],\n    })\n    .on('message', (message) => console.log(message));\n\n  const finalContent = await runner.finalContent();\n  console.log('Final content:', finalContent);\n}\n\nconst GetWeatherParameters = z.object({\n  location: z.enum(['Boston', 'New York City', 'Los Angeles', 'San Francisco']),\n});\n\nasync function getWeather(args: z.infer<typeof GetWeatherParameters>) {\n  const { location } = args;\n  // … do lookup …\n  return { temperature, precipitation };\n}\n\nmain();\n```\n```\n\n----------------------------------------\n\nTITLE: Installing the OpenAI SDK from JSR and Deno - Shell Script\nDESCRIPTION: These commands demonstrate how to add the OpenAI SDK using JSR for both Deno and Node.js projects. Requires Deno for the 'deno add' command and JSR tooling for 'npx jsr add'. This allows the OpenAI SDK to be imported directly or via JSR for flexible runtime support.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ndeno add jsr:@openai/openai\nnpx jsr add @openai/openai\n```\n\n----------------------------------------\n\nTITLE: Installing the OpenAI SDK with npm - Shell Script\nDESCRIPTION: Installs the official OpenAI SDK in your project using npm. No prerequisites beyond having Node.js and npm installed. This command adds the openai package as a dependency for use in TypeScript or JavaScript projects.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnpm install openai\n```\n\n----------------------------------------\n\nTITLE: Parsing Structured Chat Completion Responses with Zod Schema in OpenAI SDK - TypeScript\nDESCRIPTION: Demonstrates how to define data validation schemas using Zod and utilize the zodResponseFormat helper to auto-parse structured JSON responses from OpenAI's chat completions API. Requires the 'openai' Node.js SDK and 'zod' for schema definitions. Inputs include a Zod object describing the expected result (here, a math problem solution) and standard chat completion parameters. Outputs a ParsedChatCompletion object with type-safe parsed content, which is accessed through the returned data structure. Limitations include dependency on proper schema definitions and error-throwing if the finish_reason is 'length' or 'content_filter'.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { zodResponseFormat } from 'openai/helpers/zod';\nimport OpenAI from 'openai/index';\nimport { z } from 'zod';\n\nconst Step = z.object({\n  explanation: z.string(),\n  output: z.string(),\n});\n\nconst MathResponse = z.object({\n  steps: z.array(Step),\n  final_answer: z.string(),\n});\n\nconst client = new OpenAI();\n\nconst completion = await client.beta.chat.completions.parse({\n  model: 'gpt-4o-2024-08-06',\n  messages: [\n    { role: 'system', content: 'You are a helpful math tutor.' },\n    { role: 'user', content: 'solve 8x + 31 = 2' },\n  ],\n  response_format: zodResponseFormat(MathResponse, 'math_response'),\n});\n\nconsole.dir(completion, { depth: 5 });\n\nconst message = completion.choices[0]?.message;\nif (message?.parsed) {\n  console.log(message.parsed.steps);\n  console.log(`answer: ${message.parsed.final_answer}`);\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Chat Completions using OpenAI Node.js Client\nDESCRIPTION: Calls the `retrieve` method on the `chat.completions` resource to fetch a specific chat completion by its ID. It requires the `completionId` as an argument and returns a `ChatCompletion` object. This corresponds to the `GET /chat/completions/{completion_id}` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nclient.chat.completions.retrieve(completionId) -> ChatCompletion\n```\n\n----------------------------------------\n\nTITLE: Listing Chat Completion Messages using OpenAI Node.js Client\nDESCRIPTION: Calls the `list` method on the `chat.completions.messages` resource to retrieve the messages associated with a specific chat completion. It requires the `completionId` and accepts optional parameters for pagination, returning a `ChatCompletionStoreMessagesPage` object. This corresponds to the `GET /chat/completions/{completion_id}/messages` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nclient.chat.completions.messages.list(completionId, { ...params }) -> ChatCompletionStoreMessagesPage\n```\n\n----------------------------------------\n\nTITLE: Generating Text with the Chat Completions API - OpenAI SDK - TypeScript\nDESCRIPTION: Shows how to use the Chat Completions API with the OpenAI SDK to generate a conversation-like text output. After client initialization, it sends a series of messages to the GPT-4o model and logs the returned reply. It requires the openai package and an API key.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_4\n\nLANGUAGE: ts\nCODE:\n```\nimport OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: process.env['OPENAI_API_KEY'], // This is the default and can be omitted\n});\n\nconst completion = await client.chat.completions.create({\n  model: 'gpt-4o',\n  messages: [\n    { role: 'developer', content: 'Talk like a pirate.' },\n    { role: 'user', content: 'Are semicolons optional in JavaScript?' },\n  ],\n});\n\nconsole.log(completion.choices[0].message.content);\n```\n\n----------------------------------------\n\nTITLE: Updating Chat Completions using OpenAI Node.js Client\nDESCRIPTION: Calls the `update` method on the `chat.completions` resource to modify a specific chat completion. It requires the `completionId` and an object containing parameters to update, returning the updated `ChatCompletion` object. This corresponds to the `POST /chat/completions/{completion_id}` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nclient.chat.completions.update(completionId, { ...params }) -> ChatCompletion\n```\n\n----------------------------------------\n\nTITLE: Managing and Polling Runs within Assistant Threads - OpenAI Beta Client - TypeScript\nDESCRIPTION: This snippet covers methods for creating, retrieving, updating, listing, cancelling, and submitting tool outputs for runs inside threads via the OpenAI Node.js beta client. It implements both synchronous and streaming interfaces using TypeScript, and uses thread and run IDs as key parameters. Outputs are Run or RunsPage results. The API allows for polling and streaming for async workflows, and includes methods for step-by-step action submissions. Requires the OpenAI Node.js client and correct typing context.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_51\n\nLANGUAGE: typescript\nCODE:\n```\nclient.beta.threads.runs.create(threadId, { ...params }) -> Run\nclient.beta.threads.runs.retrieve(threadId, runId) -> Run\nclient.beta.threads.runs.update(threadId, runId, { ...params }) -> Run\nclient.beta.threads.runs.list(threadId, { ...params }) -> RunsPage\nclient.beta.threads.runs.cancel(threadId, runId) -> Run\nclient.beta.threads.runs.submitToolOutputs(threadId, runId, { ...params }) -> Run\nclient.beta.threads.runs.createAndPoll(threadId, body, options?) -> Promise<Run>\nclient.beta.threads.runs.createAndStream(threadId, body, options?) -> AssistantStream\nclient.beta.threads.runs.poll(threadId, runId, options?) -> Promise<Run>\nclient.beta.threads.runs.stream(threadId, body, options?) -> AssistantStream\nclient.beta.threads.runs.submitToolOutputsAndPoll(threadId, runId, body, options?) -> Promise<Run>\nclient.beta.threads.runs.submitToolOutputsStream(threadId, runId, body, options?) -> AssistantStream\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Request Retries with OpenAI SDK - JavaScript\nDESCRIPTION: Demonstrates how to set the maxRetries configuration for the OpenAI SDK client globally and per-request. Useful for handling transient network or rate limiting errors. Requires the openai package; language is explicitly JavaScript for one example to show compatibility.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_8\n\nLANGUAGE: js\nCODE:\n```\n// Configure the default for all requests:\nconst client = new OpenAI({\n  maxRetries: 0, // default is 2\n});\n\n// Or, configure per-request:\nawait client.chat.completions.create({ messages: [{ role: 'user', content: 'How can I get the name of the current day in JavaScript?' }], model: 'gpt-4o' }, {\n  maxRetries: 5,\n});\n```\n\n----------------------------------------\n\nTITLE: Generating Text with the Responses API - OpenAI SDK - TypeScript\nDESCRIPTION: Demonstrates how to generate text completions using the OpenAI SDK's Responses API. Requires the openai package and an API key (usually passed via OPENAI_API_KEY environment variable). The code creates a client, sends instructions and input to a GPT-4o model, and logs the output text.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_3\n\nLANGUAGE: ts\nCODE:\n```\nimport OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: process.env['OPENAI_API_KEY'], // This is the default and can be omitted\n});\n\nconst response = await client.responses.create({\n  model: 'gpt-4o',\n  instructions: 'You are a coding assistant that talks like a pirate',\n  input: 'Are semicolons optional in JavaScript?',\n});\n\nconsole.log(response.output_text);\n```\n\n----------------------------------------\n\nTITLE: Accessing Raw HTTP Response Data with OpenAI Node.js SDK in TypeScript\nDESCRIPTION: Demonstrates how to retrieve the raw `fetch` `Response` object using the `.asResponse()` and `.withResponse()` methods available on the `APIPromise` returned by OpenAI client calls. This allows access to low-level HTTP details like headers and status codes, either exclusively (`.asResponse()`) or alongside the parsed data (`.withResponse()`). Requires an initialized `OpenAI` client instance.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_16\n\nLANGUAGE: typescript\nCODE:\n```\n// prettier-ignore\n```ts\nconst client = new OpenAI();\n\nconst httpResponse = await client.responses\n  .create({ model: 'gpt-4o', input: 'say this is a test.' })\n  .asResponse();\n\n// access the underlying web standard Response object\nconsole.log(httpResponse.headers.get('X-My-Header'));\nconsole.log(httpResponse.statusText);\n\nconst { data: modelResponse, response: raw } = await client.responses\n  .create({ model: 'gpt-4o', input: 'say this is a test.' })\n  .withResponse();\nconsole.log(raw.headers.get('X-My-Header'));\nconsole.log(modelResponse);\n```\n```\n\n----------------------------------------\n\nTITLE: Creating and Managing Assistant Threads - OpenAI Beta Client - TypeScript\nDESCRIPTION: This snippet lists various data types and client methods for creating, retrieving, updating, deleting, and running assistant threads via the OpenAI Node.js beta client. It demonstrates TypeScript type usage and RESTful API conventions. Key parameters include thread IDs and parameter bodies; outputs are typed Thread, ThreadDeleted, or Run resources. Dependencies include the OpenAI Node.js client and appropriate type definitions; usage presumes integration within a TypeScript project.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_50\n\nLANGUAGE: typescript\nCODE:\n```\nclient.beta.threads.create({ ...params }) -> Thread\nclient.beta.threads.retrieve(threadId) -> Thread\nclient.beta.threads.update(threadId, { ...params }) -> Thread\nclient.beta.threads.del(threadId) -> ThreadDeleted\nclient.beta.threads.createAndRun({ ...params }) -> Run\nclient.beta.threads.createAndRunPoll(body, options?) -> Promise<Threads.Run>\nclient.beta.threads.createAndRunStream(body, options?) -> AssistantStream\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom HTTP/HTTPS Agent for OpenAI Node.js Client in TypeScript\nDESCRIPTION: Shows how to configure a custom HTTP/HTTPS agent for the OpenAI client, useful for scenarios like routing requests through a proxy. An agent can be provided globally during client initialization using the `httpAgent` option, or specified per-request. The example demonstrates using `HttpsProxyAgent` for proxy support and overriding it with a standard `http.Agent` for a specific request. Requires installing the necessary agent package (e.g., `https-proxy-agent`).\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_21\n\nLANGUAGE: typescript\nCODE:\n```\n// prettier-ignore\n```ts\nimport http from 'http';\nimport { HttpsProxyAgent } from 'https-proxy-agent';\n\n// Configure the default for all requests:\nconst client = new OpenAI({\n  httpAgent: new HttpsProxyAgent(process.env.PROXY_URL),\n});\n\n// Override per-request:\nawait client.models.list({\n  httpAgent: new http.Agent({ keepAlive: false }),\n});\n```\n```\n\n----------------------------------------\n\nTITLE: Customizing Fetch Implementation for OpenAI Node.js Client in TypeScript\nDESCRIPTION: Illustrates how to provide a custom `fetch` function during `OpenAI` client instantiation. This allows intercepting requests and responses, useful for logging, adding custom headers, modifying requests/responses, or implementing other middleware logic. The example uses `undici`'s fetch, but any web-standard `fetch`-compatible function can be supplied. Requires an initialized `OpenAI` client and a fetch implementation (like `undici`).\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_20\n\nLANGUAGE: typescript\nCODE:\n```\n```ts\nimport { fetch } from 'undici'; // as one example\nimport OpenAI from 'openai';\n\nconst client = new OpenAI({\n  fetch: async (url: RequestInfo, init?: RequestInit): Promise<Response> => {\n    console.log('About to make a request', url, init);\n    const response = await fetch(url, init);\n    console.log('Got response', response);\n    return response;\n  },\n});\n```\n```\n\n----------------------------------------\n\nTITLE: Using the Realtime API with WebSocket - TypeScript\nDESCRIPTION: Demonstrates how to use the Realtime API with the OpenAI SDK by connecting via WebSocket and handling incremental text deltas. Requires openai SDK with beta features and event handling support. The listener writes streamed deltas to stdout for real-time UX.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_14\n\nLANGUAGE: ts\nCODE:\n```\nimport { OpenAIRealtimeWebSocket } from 'openai/beta/realtime/websocket';\n\nconst rt = new OpenAIRealtimeWebSocket({ model: 'gpt-4o-realtime-preview-2024-12-17' });\n\nrt.on('response.text.delta', (event) => process.stdout.write(event.delta));\n```\n\n----------------------------------------\n\nTITLE: Starting Assistant Run and Tool Output Streams with OpenAI Node SDK - TypeScript\nDESCRIPTION: Provides example invocations of the streaming helper methods available in the OpenAI SDK for managing run, message, or tool output streaming in assistants. Shows three usage styles: streaming an existing run, creating a thread and starting a run with streaming, and submitting tool outputs with streaming enabled. Requires thread/run/message contexts to exist and OpenAI Node.js SDK installed.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nopenai.beta.threads.runs.stream();\n```\n\nLANGUAGE: typescript\nCODE:\n```\nopenai.beta.threads.createAndRunStream();\n```\n\nLANGUAGE: typescript\nCODE:\n```\nopenai.beta.threads.runs.submitToolOutputsStream();\n```\n\n----------------------------------------\n\nTITLE: Listing Models with OpenAI Node.js Client\nDESCRIPTION: Retrieves a list of available models from the OpenAI API. The `list` method on the `client.models` object is called without arguments (or potentially pagination parameters) and returns a `ModelsPage` object containing the list of models.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_23\n\nLANGUAGE: typescript\nCODE:\n```\nclient.models.list() -> ModelsPage\n```\n\n----------------------------------------\n\nTITLE: Deleting Files using OpenAI Node.js Client\nDESCRIPTION: Calls the `del` method on the `files` resource to delete a specific file by its ID. It requires the `fileId` and returns a `FileDeleted` object confirming the successful deletion. This corresponds to the `DELETE /files/{file_id}` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_11\n\nLANGUAGE: javascript\nCODE:\n```\nclient.files.del(fileId) -> FileDeleted\n```\n\n----------------------------------------\n\nTITLE: Listing Files in a Vector Store with OpenAI Node.js Client\nDESCRIPTION: Retrieves a list of files contained within a specific vector store using the OpenAI API. The `list` method on `client.vectorStores.files` requires the `vectorStoreId`, accepts optional parameters (e.g., for filtering or pagination), and returns a `VectorStoreFilesPage` object.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_43\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.files.list(vectorStoreId, { ...params }) -> VectorStoreFilesPage\n```\n\n----------------------------------------\n\nTITLE: Retrieving File Content from a Vector Store with OpenAI Node.js Client\nDESCRIPTION: Fetches the content of a specific file stored within a vector store using the OpenAI API. The `content` method on `client.vectorStores.files` requires the `vectorStoreId` and `fileId`, returning a `FileContentResponsesPage` containing the file's content.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_45\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.files.content(vectorStoreId, fileId) -> FileContentResponsesPage\n```\n\n----------------------------------------\n\nTITLE: Creating a Vector Store with OpenAI Node.js Client\nDESCRIPTION: Creates a new vector store via the OpenAI API. The `create` method on `client.vectorStores` accepts parameters for configuring the vector store (e.g., name, chunking strategy) and returns a `VectorStore` object representing the created store.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_34\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.create({ ...params }) -> VectorStore\n```\n\n----------------------------------------\n\nTITLE: Retrieving a Vector Store with OpenAI Node.js Client\nDESCRIPTION: Fetches details about a specific vector store from the OpenAI API. The `retrieve` method under `client.vectorStores` takes the `vectorStoreId` as input and returns the corresponding `VectorStore` object.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_35\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.retrieve(vectorStoreId) -> VectorStore\n```\n\n----------------------------------------\n\nTITLE: Streaming Responses from OpenAI API - TypeScript\nDESCRIPTION: Demonstrates how to receive streaming responses using Server Sent Events (SSE) with the Responses API of the OpenAI SDK. After creating a client, it requests a streamed response and uses an async iterator to process events in real time. Requires openai package and relevant runtime support for SSE.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_5\n\nLANGUAGE: ts\nCODE:\n```\nimport OpenAI from 'openai';\n\nconst client = new OpenAI();\n\nconst stream = await client.responses.create({\n  model: 'gpt-4o',\n  input: 'Say \"Sheep sleep deep\" ten times fast!',\n  stream: true,\n});\n\nfor await (const event of stream) {\n  console.log(event);\n}\n```\n\n----------------------------------------\n\nTITLE: Uploading a File to a Vector Store (Beta) with OpenAI Node.js Client\nDESCRIPTION: Uploads a file (e.g., from a stream or buffer) to OpenAI and associates it with a vector store, initiating processing. This beta helper method (`upload` under `client.beta.vectorStores.files`) takes the `vectorStoreId`, the file data, and optional settings, returning a Promise resolving with the initial `VectorStoreFile` representation.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_48\n\nLANGUAGE: typescript\nCODE:\n```\nclient.beta.vectorStores.files.upload(vectorStoreId, file, options?) -> Promise<VectorStoreFile>\n```\n\n----------------------------------------\n\nTITLE: Updating a Vector Store with OpenAI Node.js Client\nDESCRIPTION: Modifies an existing vector store using the OpenAI API. The `update` method on `client.vectorStores` takes the `vectorStoreId` and parameters with the desired changes, returning the updated `VectorStore` object.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_36\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.update(vectorStoreId, { ...params }) -> VectorStore\n```\n\n----------------------------------------\n\nTITLE: Uploading and Polling a Vector Store File (Beta) with OpenAI Node.js Client\nDESCRIPTION: Combines uploading a file and polling its status until processing within the vector store is complete. This beta helper method (`uploadAndPoll` under `client.beta.vectorStores.files`) takes the `vectorStoreId`, file data, and optional settings, returning a Promise that resolves with the final `VectorStoreFile` status after successful processing.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_49\n\nLANGUAGE: typescript\nCODE:\n```\nclient.beta.vectorStores.files.uploadAndPoll(vectorStoreId, file, options?) -> Promise<VectorStoreFile>\n```\n\n----------------------------------------\n\nTITLE: Polling a Vector Store File Status (Beta) with OpenAI Node.js Client\nDESCRIPTION: Checks the processing status of a file within a vector store until it reaches a terminal state (e.g., 'completed' or 'failed'). This beta utility method (`poll` under `client.beta.vectorStores.files`) takes `vectorStoreId`, `fileId`, and optional settings, returning a Promise resolving with the final `VectorStoreFile` status.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_47\n\nLANGUAGE: typescript\nCODE:\n```\nclient.beta.vectorStores.files.poll(vectorStoreId, fileId, options?) -> Promise<VectorStoreFile>\n```\n\n----------------------------------------\n\nTITLE: Creating, Updating, and Managing Messages in Assistant Threads - OpenAI Beta Client - TypeScript\nDESCRIPTION: This snippet presents methods to create, retrieve, update, list, and delete messages within a thread using the OpenAI Node.js beta client and TypeScript. Key inputs are thread and message IDs, plus message parameters. All operations return strongly-typed Message or MessageDeleted objects. The implementation streamlines message management in context-aware assistant conversations.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_53\n\nLANGUAGE: typescript\nCODE:\n```\nclient.beta.threads.messages.create(threadId, { ...params }) -> Message\nclient.beta.threads.messages.retrieve(threadId, messageId) -> Message\nclient.beta.threads.messages.update(threadId, messageId, { ...params }) -> Message\nclient.beta.threads.messages.list(threadId, { ...params }) -> MessagesPage\nclient.beta.threads.messages.del(threadId, messageId) -> MessageDeleted\n\n```\n\n----------------------------------------\n\nTITLE: Accessing OpenAI Request IDs from Responses - TypeScript\nDESCRIPTION: Demonstrates how to log the OpenAI request ID attached to an API response. Essential for debugging or reporting issues. Requires openai package and sending at least one request via the responses.create method.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_10\n\nLANGUAGE: ts\nCODE:\n```\nconst response = await client.responses.create({ model: 'gpt-4o', input: 'testing 123' });\nconsole.log(response._request_id) // req_123\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Text Content Streaming Events in Assistant API - TypeScript\nDESCRIPTION: Exemplifies how to subscribe to specific streaming events related to text content (creation, delta, completion) in the assistant API. This event structure allows applications to assemble or process textual responses in a granular, incremental manner, supporting use cases such as live update UIs or logs.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n.on('textCreated', (content: Text) => ...)\n.on('textDelta', (delta: TextDelta, snapshot: Text) => ...)\n.on('textDone', (content: Text, snapshot: Message) => ...)\n```\n\n----------------------------------------\n\nTITLE: Accessing Request IDs with .withResponse() Method - TypeScript\nDESCRIPTION: Shows how to use the .withResponse() helper to get both response data and the request_id from a streamed response. This provides a convenient way to correlate responses with request traces for advanced debugging or logging in applications using the OpenAI SDK.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_11\n\nLANGUAGE: ts\nCODE:\n```\nconst { data: stream, request_id } = await openai.responses\n  .create({\n    model: 'gpt-4o',\n    input: 'Say this is a test',\n    stream: true,\n  })\n  .withResponse();\n```\n\n----------------------------------------\n\nTITLE: Creating Permissions for a Fine-Tuning Checkpoint with OpenAI Node.js Client\nDESCRIPTION: Creates permissions for a specific fine-tuned model checkpoint using the OpenAI API. The `create` method under `client.fineTuning.checkpoints.permissions` takes the checkpoint identifier (`fineTunedModelCheckpoint`) and parameters defining the permissions, returning a `PermissionCreateResponsesPage` object.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_31\n\nLANGUAGE: typescript\nCODE:\n```\nclient.fineTuning.checkpoints.permissions.create(fineTunedModelCheckpoint, { ...params }) -> PermissionCreateResponsesPage\n```\n\n----------------------------------------\n\nTITLE: Retrieving Permissions for a Fine-Tuning Checkpoint with OpenAI Node.js Client\nDESCRIPTION: Fetches the permissions associated with a specific fine-tuned model checkpoint via the OpenAI API. The `retrieve` method on `client.fineTuning.checkpoints.permissions` takes the checkpoint identifier (`fineTunedModelCheckpoint`) and optional parameters, returning a `PermissionRetrieveResponse` object.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_32\n\nLANGUAGE: typescript\nCODE:\n```\nclient.fineTuning.checkpoints.permissions.retrieve(fineTunedModelCheckpoint, { ...params }) -> PermissionRetrieveResponse\n```\n\n----------------------------------------\n\nTITLE: Deleting Permissions for a Fine-Tuning Checkpoint with OpenAI Node.js Client\nDESCRIPTION: Removes a specific permission from a fine-tuned model checkpoint using the OpenAI API. The `del` method on `client.fineTuning.checkpoints.permissions` requires both the checkpoint identifier (`fineTunedModelCheckpoint`) and the specific `permissionId` to delete, returning a `PermissionDeleteResponse` object.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_33\n\nLANGUAGE: typescript\nCODE:\n```\nclient.fineTuning.checkpoints.permissions.del(fineTunedModelCheckpoint, permissionId) -> PermissionDeleteResponse\n```\n\n----------------------------------------\n\nTITLE: Listing Fine-Tuning Job Events with OpenAI Node.js Client\nDESCRIPTION: Fetches a list of events associated with a specific fine-tuning job from the OpenAI API. This method, `listEvents` on `client.fineTuning.jobs`, requires the `fineTuningJobId` and accepts optional parameters (e.g., for pagination), returning a `FineTuningJobEventsPage`.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_29\n\nLANGUAGE: typescript\nCODE:\n```\nclient.fineTuning.jobs.listEvents(fineTuningJobId, { ...params }) -> FineTuningJobEventsPage\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Streaming Assistant Run Events in OpenAI Node SDK - TypeScript\nDESCRIPTION: Illustrates usage of the OpenAI SDK's assistant streaming API to handle real-time events during a run, such as text output, tool call events, and code interpreter outputs. Utilizes event-driven programming patterns, enabling subscription to both high-level and delta events for granular feedback. Relies on the beta.threads.runs.stream method with a thread and assistant id. Outputs are handled directly via process.stdout.write, demonstrating custom real-time handling for each event type.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst run = openai.beta.threads.runs\n  .stream(thread.id, { assistant_id: assistant.id })\n  .on('textCreated', (text) => process.stdout.write('\\nassistant > '))\n  .on('textDelta', (textDelta, snapshot) => process.stdout.write(textDelta.value))\n  .on('toolCallCreated', (toolCall) => process.stdout.write(`\\nassistant > ${toolCall.type}\\n\\n`))\n  .on('toolCallDelta', (toolCallDelta, snapshot) => {\n    if (toolCallDelta.type === 'code_interpreter') {\n      if (toolCallDelta.code_interpreter.input) {\n        process.stdout.write(toolCallDelta.code_interpreter.input);\n      }\n      if (toolCallDelta.code_interpreter.outputs) {\n        process.stdout.write('\\noutput >\\n');\n        toolCallDelta.code_interpreter.outputs.forEach((output) => {\n          if (output.type === 'logs') {\n            process.stdout.write(`\\n${output.logs}\\n`);\n          }\n        });\n      }\n    }\n  });\n```\n\n----------------------------------------\n\nTITLE: Handling API Errors in the OpenAI SDK - TypeScript\nDESCRIPTION: Shows how to handle API errors thrown by the OpenAI SDK. Uses async/await with try/catch on the .create method, checks for instances of OpenAI.APIError, and logs request details if an error occurs. Requires the openai package and client instantiation.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_7\n\nLANGUAGE: ts\nCODE:\n```\nasync function main() {\n  const job = await client.fineTuning.jobs\n    .create({ model: 'gpt-4o', training_file: 'file-abc123' })\n    .catch(async (err) => {\n      if (err instanceof OpenAI.APIError) {\n        console.log(err.request_id);\n        console.log(err.status); // 400\n        console.log(err.name); // BadRequestError\n        console.log(err.headers); // {server: 'nginx', ...}\n      } else {\n        throw err;\n      }\n    });\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Listing Fine-Tuning Jobs with OpenAI Node.js Client\nDESCRIPTION: Retrieves a list of fine-tuning jobs associated with the account via the OpenAI API. The `list` method on `client.fineTuning.jobs` accepts optional parameters (e.g., for pagination) and returns a `FineTuningJobsPage` object containing the list.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_27\n\nLANGUAGE: typescript\nCODE:\n```\nclient.fineTuning.jobs.list({ ...params }) -> FineTuningJobsPage\n```\n\n----------------------------------------\n\nTITLE: Implementing Automated Function Calls with runTools in TypeScript\nDESCRIPTION: This example demonstrates using the `openai.beta.chat.completions.runTools` helper in TypeScript to automate function calls with the OpenAI API. It initializes an OpenAI client, defines asynchronous functions (`getCurrentLocation`, `getWeather`), and configures `runTools` with the model, messages, and tools (including function definitions and an optional parser). The helper handles the loop of calling the API, executing the specified JavaScript functions based on the model's requests, and sending back results until a final response is generated. It uses an event listener (`.on('message', ...)` to log intermediate messages and retrieves the final content using `await runner.finalContent()`.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nimport OpenAI from 'openai';\n\nconst client = new OpenAI();\n\nasync function main() {\n  const runner = client.beta.chat.completions\n    .runTools({\n      model: 'gpt-4o',\n      messages: [{ role: 'user', content: 'How is the weather this week?' }],\n      tools: [\n        {\n          type: 'function',\n          function: {\n            function: getCurrentLocation,\n            parameters: { type: 'object', properties: {} },\n          },\n        },\n        {\n          type: 'function',\n          function: {\n            function: getWeather,\n            parse: JSON.parse, // or use a validation library like zod for typesafe parsing.\n            parameters: {\n              type: 'object',\n              properties: {\n                location: { type: 'string' },\n              },\n            },\n          },\n        },\n      ],\n    })\n    .on('message', (message) => console.log(message));\n\n  const finalContent = await runner.finalContent();\n  console.log();\n  console.log('Final content:', finalContent);\n}\n\nasync function getCurrentLocation() {\n  return 'Boston'; // Simulate lookup\n}\n\nasync function getWeather(args: { location: string }) {\n  const { location } = args;\n  // … do lookup …\n  return { temperature, precipitation };\n}\n\nmain();\n\n// {role: \"user\",      content: \"How's the weather this week?\"}\n// {role: \"assistant\", tool_calls: [{type: \"function\", function: {name: \"getCurrentLocation\", arguments: \"{}\"}, id: \"123\"}\n// {role: \"tool\",      name: \"getCurrentLocation\", content: \"Boston\", tool_call_id: \"123\"}\n// {role: \"assistant\", tool_calls: [{type: \"function\", function: {name: \"getWeather\", arguments: '{\"location\": \"Boston\"}'}, id: \"1234\"}]}\n// {role: \"tool\",      name: \"getWeather\", content: '{\"temperature\": \"50degF\", \"preciptation\": \"high\"}', tool_call_id: \"1234\"}\n// {role: \"assistant\", content: \"It's looking cold and rainy - you might want to wear a jacket!\"}\n//\n// Final content: \"It's looking cold and rainy - you might want to wear a jacket!\"\n```\n\n----------------------------------------\n\nTITLE: Aborting OpenAI Chat Stream on Function Call in TypeScript\nDESCRIPTION: Demonstrates how to use the `runner.abort()` method within a tool's function implementation to stop the chat completion stream when a specific function call is triggered. The example initializes the OpenAI client, runs chat completions with tools using `runTools`, defines a tool function that calls `runner.abort()`, logs messages, and awaits the final function call.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\n```ts\nimport OpenAI from 'openai';\n\nconst client = new OpenAI();\n\nasync function main() {\n  const runner = client.chat.completions\n    .runTools({\n      model: 'gpt-3.5-turbo',\n      messages: [{ role: 'user', content: \"How's the weather this week in Los Angeles?\" }],\n      tools: [\n        {\n          type: 'function',\n          function: {\n            function: function updateDatabase(props, runner) {\n              runner.abort()\n            },\n            // …\n          }\n        },\n      ],\n    })\n    .on('message', (message) => console.log(message));\n\n  const finalFunctionCall = await runner.finalFunctionCall();\n  console.log('Final function call:', finalFunctionCall);\n}\n\nmain();\n```\n```\n\n----------------------------------------\n\nTITLE: Initiating Streaming Chat Completions in TypeScript\nDESCRIPTION: This snippet shows the function signature for `openai.chat.completions.stream()`. This method returns a `ChatCompletionStreamingRunner` object, which facilitates handling streaming responses by emitting events and providing an async iterator. An alternative method, `openai.chat.completions.create({ stream: true, ... })`, returns a simpler async iterable of chunks and uses less memory.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nopenai.chat.completions.stream({ stream?: false, … }, options?): ChatCompletionStreamingRunner\n```\n\n----------------------------------------\n\nTITLE: Listing OpenAI Asynchronous Operation Polling Helpers in TypeScript\nDESCRIPTION: Lists the polling helper methods available in the OpenAI Node.js SDK. These methods, ending in `_AndPoll`, handle asynchronous operations by polling the API until a terminal state is reached. They apply to creating threads and runs, submitting tool outputs, and managing vector store files and batches. The polling frequency can be adjusted via `pollIntervalMs`.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_16\n\nLANGUAGE: typescript\nCODE:\n```\n```ts\nclient.beta.threads.createAndRunPoll(...)\nclient.beta.threads.runs.createAndPoll((...)\nclient.beta.threads.runs.submitToolOutputsAndPoll((...)\nclient.beta.vectorStores.files.uploadAndPoll((...)\nclient.beta.vectorStores.files.createAndPoll((...)\nclient.beta.vectorStores.fileBatches.createAndPoll((...)\nclient.beta.vectorStores.fileBatches.uploadAndPoll((...)\n```\n```\n\n----------------------------------------\n\nTITLE: Subscribing to End of Stream Event in Assistant Streaming API - TypeScript\nDESCRIPTION: Demonstrates subscription to the 'end' event in the Assistant streaming API, signifying completion of the entire event stream. This serves as a signal to finalize any post-processing or cleanup after all content and events are delivered.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\n.on('end', () => ...)\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Methods on Assistant Streaming Objects - TypeScript\nDESCRIPTION: Lists available context and query methods that can be called on assistant streaming objects to retrieve the current state of a run, event, message, or run step. Also demonstrates how to collect final accumulated messages or run steps via promises after streaming concludes. These helpers assist with contextual event handling and post-stream collation.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\n.currentEvent(): AssistantStreamEvent | undefined\n\n.currentRun(): Run | undefined\n\n.currentMessageSnapshot(): Message\n\n.currentRunStepSnapshot(): Runs.RunStep\n```\n\nLANGUAGE: typescript\nCODE:\n```\nawait .finalMessages() : Promise<Message[]>\n\nawait .finalRunSteps(): Promise<RunStep[]>\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Message Creation, Delta, and Completion Events - TypeScript\nDESCRIPTION: Details the use of the messageCreated, messageDelta, and messageDone streaming event hooks in the Assistant streaming API. Listeners on these events allow applications to respond to different stages in the lifecycle of a Message object, such as its creation, incremental updates, and completion, delivering real-time content to consumers.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\n.on('messageCreated', (message: Message) => ...)\n.on('messageDelta', (delta: MessageDelta, snapshot: Message) => ...)\n.on('messageDone', (message: Message) => ...)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Run Steps in Assistant Threads - OpenAI Beta Client - TypeScript\nDESCRIPTION: This snippet shows how to retrieve a specific run step or list all run steps from a thread's run, using the OpenAI Node.js beta client in TypeScript. Methods accept thread, run, and step IDs, as well as optional parameters. Results are strongly typed and typically returned as RunStep or RunStepsPage objects. Designed for precise monitoring and debugging of stepwise conversation workflows.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_52\n\nLANGUAGE: typescript\nCODE:\n```\nclient.beta.threads.runs.steps.retrieve(threadId, runId, stepId, { ...params }) -> RunStep\nclient.beta.threads.runs.steps.list(threadId, runId, { ...params }) -> RunStepsPage\n\n```\n\n----------------------------------------\n\nTITLE: Generating Images using OpenAI Node.js Client\nDESCRIPTION: Calls the `generate` method on the `images` resource to create new images from a text prompt using models like DALL·E. It accepts an object with parameters (prompt, number of images, size, model, etc.) and returns an `ImagesResponse` object containing the generated image(s). This corresponds to the `POST /images/generations` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_17\n\nLANGUAGE: javascript\nCODE:\n```\nclient.images.generate({ ...params }) -> ImagesResponse\n```\n\n----------------------------------------\n\nTITLE: Handling Streaming Tool Call Events in OpenAI Assistant API - TypeScript\nDESCRIPTION: Covers the event pattern for subscribing to tool call lifecycle events (creation, delta, completion) when streaming runs via the Assistant API. Code listeners facilitate programmatic reactions to external tool invocations initiated by assistant logic. Expects distinctly typed ToolCall, RunStepDelta, and snapshot payloads for each event.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\n.on('toolCallCreated', (toolCall: ToolCall) => ...)\n.on('toolCallDelta', (delta: RunStepDelta, snapshot: ToolCall) => ...)\n.on('toolCallDone', (toolCall: ToolCall) => ...)\n```\n\n----------------------------------------\n\nTITLE: Retrieving a Batch using OpenAI Node Client (JavaScript)\nDESCRIPTION: Retrieves the details of a specific batch job using its unique identifier (`batchId`) via the Node.js client. Returns a `Batch` object containing the batch information. This method corresponds to the `GET /batches/{batch_id}` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_55\n\nLANGUAGE: javascript\nCODE:\n```\nclient.batches.retrieve(batchId) -> Batch\n```\n\n----------------------------------------\n\nTITLE: Creating an Upload Part using OpenAI Node Client (JavaScript)\nDESCRIPTION: Creates (uploads) a single part for a multipart upload session identified by `uploadId` via the Node.js client. Requires parameters (`params`) containing the actual data chunk for the part. Returns an `UploadPart` object representing the successfully uploaded part. This method corresponds to the `POST /uploads/{upload_id}/parts` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_61\n\nLANGUAGE: javascript\nCODE:\n```\nclient.uploads.parts.create(uploadId, { ...params }) -> UploadPart\n```\n\n----------------------------------------\n\nTITLE: Retrieving a Response using OpenAI Node Client (JavaScript)\nDESCRIPTION: Retrieves the details of a specific response or interaction using its unique identifier (`responseId`) via the Node.js client. Optional parameters (`params`) might control the level of detail included (e.g., including input items). Returns a `Response` object. This method corresponds to the `GET /responses/{response_id}` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_63\n\nLANGUAGE: javascript\nCODE:\n```\nclient.responses.retrieve(responseId, { ...params }) -> Response\n```\n\n----------------------------------------\n\nTITLE: Listing Response Input Items using OpenAI Node Client (JavaScript)\nDESCRIPTION: Lists the input items associated with a specific response, identified by `responseId`, using the Node.js client. Supports optional parameters (`params`) for pagination (e.g., limit, before, after). Returns a `ResponseItemsPage` object containing a list of input items (type defined in `input-items.ts`) and pagination details. This method corresponds to the `GET /responses/{response_id}/input_items` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_65\n\nLANGUAGE: javascript\nCODE:\n```\nclient.responses.inputItems.list(responseId, { ...params }) -> ResponseItemsPage\n```\n\n----------------------------------------\n\nTITLE: Deleting a Response using OpenAI Node Client (JavaScript)\nDESCRIPTION: Deletes a specific response or interaction identified by its unique identifier (`responseId`) via the Node.js client. This action is irreversible. The method returns `void` upon successful deletion. This method corresponds to the `DELETE /responses/{response_id}` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_64\n\nLANGUAGE: javascript\nCODE:\n```\nclient.responses.del(responseId) -> void\n```\n\n----------------------------------------\n\nTITLE: Bulk Uploading Files to OpenAI Vector Store with Polling in TypeScript\nDESCRIPTION: Demonstrates using the `vectorStores.fileBatches.uploadAndPoll` helper function in the OpenAI Node.js SDK to upload multiple files to a specified vector store simultaneously. The example prepares a list of file streams (using `createReadStream`) and calls the helper function, which handles the upload and polls until the batch operation completes.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\n```ts\nconst fileList = [\n  createReadStream('/home/data/example.pdf'),\n  ...\n];\n\nconst batch = await openai.vectorStores.fileBatches.uploadAndPoll(vectorStore.id, {files: fileList});\n```\n```\n\n----------------------------------------\n\nTITLE: Creating, Retrieving, Updating, Listing, and Deleting Evals - OpenAI Node.js SDK - TypeScript\nDESCRIPTION: Exposes TypeScript types for Eval configuration and responses, and defines client method signatures to create, retrieve, update, list, and delete Evals via the OpenAI Node.js SDK. Each client.evals.<method> corresponds to a REST API endpoint and uses the listed input parameter structures, returning strongly-typed responses. Expected inputs include Eval parameter objects and identifiers, while outputs are structured response types. This requires the OpenAI Node.js SDK and the corresponding type definitions, and is intended for TypeScript projects integrating with OpenAI's evaluation API endpoints.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_66\n\nLANGUAGE: typescript\nCODE:\n```\n// Types\n// - EvalCustomDataSourceConfig\n// - EvalLabelModelGrader\n// - EvalStoredCompletionsDataSourceConfig\n// - EvalStringCheckGrader\n// - EvalTextSimilarityGrader\n// - EvalCreateResponse\n// - EvalRetrieveResponse\n// - EvalUpdateResponse\n// - EvalListResponse\n// - EvalDeleteResponse\n\n// Methods\n// client.evals.create({ ...params }) -> EvalCreateResponse\n// client.evals.retrieve(evalId) -> EvalRetrieveResponse\n// client.evals.update(evalId, { ...params }) -> EvalUpdateResponse\n// client.evals.list({ ...params }) -> EvalListResponsesPage\n// client.evals.del(evalId) -> EvalDeleteResponse\n```\n\n----------------------------------------\n\nTITLE: Setting up Real-time Azure OpenAI Connection in TypeScript\nDESCRIPTION: This snippet illustrates how to set up a real-time connection to Azure OpenAI using the `openai-node` SDK. It first configures an `AzureOpenAI` client with Azure AD credentials (`DefaultAzureCredential`, `getBearerTokenProvider`), the API version, and a specific deployment name. This configured client is then passed to `OpenAIRealtimeWS.azure()` to establish a real-time WebSocket instance (`rt`) for streaming interactions.\nSOURCE: https://github.com/openai/openai-node/blob/master/azure.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst cred = new DefaultAzureCredential();\nconst scope = 'https://cognitiveservices.azure.com/.default';\nconst deploymentName = 'gpt-4o-realtime-preview-1001';\nconst azureADTokenProvider = getBearerTokenProvider(cred, scope);\nconst client = new AzureOpenAI({\n  azureADTokenProvider,\n  apiVersion: '2024-10-01-preview',\n  deployment: deploymentName,\n});\nconst rt = await OpenAIRealtimeWS.azure(client);\n```\n\n----------------------------------------\n\nTITLE: Using Global Web Fetch Shim with OpenAI Node.js SDK in TypeScript\nDESCRIPTION: Demonstrates how to configure the OpenAI Node.js library to use the global web-standard `fetch` function instead of its default `node-fetch` dependency, even within a Node.js environment. This is achieved by importing `openai/shims/web` *before* importing the `OpenAI` class itself. This shim expects a compliant `fetch` to be globally available (e.g., via Node's `--experimental-fetch` or polyfills like `undici`).\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_19\n\nLANGUAGE: typescript\nCODE:\n```\n```ts\n// Tell TypeScript and the package to use the global web fetch instead of node-fetch.\n// Note, despite the name, this does not add any polyfills, but expects them to be provided if needed.\nimport 'openai/shims/web';\nimport OpenAI from 'openai';\n```\n```\n\n----------------------------------------\n\nTITLE: Creating Audio Transcriptions using OpenAI Node.js Client\nDESCRIPTION: Calls the `create` method on the `audio.transcriptions` resource to transcribe audio into text using the Whisper model. It accepts an object with parameters (including the audio file, model, language, response format) and returns a `TranscriptionCreateResponse` object containing the transcribed text and potentially other details like segments or words. This corresponds to the `POST /audio/transcriptions` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_18\n\nLANGUAGE: javascript\nCODE:\n```\nclient.audio.transcriptions.create({ ...params }) -> TranscriptionCreateResponse\n```\n\n----------------------------------------\n\nTITLE: Importing the OpenAI SDK in Deno - TypeScript\nDESCRIPTION: Shows how to import the OpenAI SDK from JSR using a JSR import specifier in a Deno runtime context. Requires a Deno environment and JSR import compatibility; no other dependencies required.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_2\n\nLANGUAGE: ts\nCODE:\n```\nimport OpenAI from 'jsr:@openai/openai';\n```\n\n----------------------------------------\n\nTITLE: Creating Speech with OpenAI Node.js Client\nDESCRIPTION: Calls the OpenAI API to synthesize speech from text. It uses the `create` method under `client.audio.speech`, accepting parameters for the speech generation process and returning a response object, likely containing the audio data.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_20\n\nLANGUAGE: typescript\nCODE:\n```\nclient.audio.speech.create({ ...params }) -> Response\n```\n\n----------------------------------------\n\nTITLE: Installing openai-node from Git via NPM in Shell\nDESCRIPTION: This shell command installs the openai-node package directly from its GitHub repository using npm. Useful for using the latest changes from source. Requires npm and Git access permissions. The output is installation of the package into your project's node_modules.\nSOURCE: https://github.com/openai/openai-node/blob/master/CONTRIBUTING.md#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\n$ npm install git+ssh://git@github.com:openai/openai-node.git\n```\n\n----------------------------------------\n\nTITLE: Uploading Files using OpenAI Node.js Client\nDESCRIPTION: Calls the `create` method on the `files` resource to upload a file to OpenAI. It accepts an object containing the file data (as a `RequestInfo` like `fs.createReadStream('my_file.jsonl')`) and the purpose of the file, returning a `FileObject` representing the uploaded file's metadata. This corresponds to the `POST /files` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nclient.files.create({ ...params }) -> FileObject\n```\n\n----------------------------------------\n\nTITLE: Running Prism Mock Server and Testing with Yarn in Shell\nDESCRIPTION: This shell snippet shows how to run a Prism mock server against your OpenAPI specification and execute the test suite with Yarn. The prism server provides mock endpoints, making local testing possible. Requires 'npx', 'prism', 'yarn', and a valid openapi.yml. Replace 'path/to/your/openapi.yml' as appropriate. Test results depend on your test suite configuration.\nSOURCE: https://github.com/openai/openai-node/blob/master/CONTRIBUTING.md#_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\n$ npx prism mock path/to/your/openapi.yml\n```\n\nLANGUAGE: sh\nCODE:\n```\n$ yarn run test\n```\n\n----------------------------------------\n\nTITLE: Creating Audio Translations using OpenAI Node.js Client\nDESCRIPTION: Calls the `create` method on the `audio.translations` resource to translate audio from various languages into English text using the Whisper model. It accepts an object with parameters (including the audio file, model) and returns a `TranslationCreateResponse` object containing the translated English text. This corresponds to the `POST /audio/translations` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_19\n\nLANGUAGE: javascript\nCODE:\n```\nclient.audio.translations.create({ ...params }) -> TranslationCreateResponse\n```\n\n----------------------------------------\n\nTITLE: Editing Images using OpenAI Node.js Client\nDESCRIPTION: Calls the `edit` method on the `images` resource to edit an image based on a text prompt and an optional mask. It accepts an object with parameters (image file, prompt, mask file, etc.) and returns an `ImagesResponse` object with the edited image(s). This corresponds to the `POST /images/edits` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_16\n\nLANGUAGE: javascript\nCODE:\n```\nclient.images.edit({ ...params }) -> ImagesResponse\n```\n\n----------------------------------------\n\nTITLE: Making a TypeScript Example Executable and Running with Yarn in Shell\nDESCRIPTION: This shell snippet shows how to make a TypeScript example file executable and run it with Yarn's tsn runner. The 'chmod' command enables execution rights, and the 'yarn tsn -T' command executes the script against your API. Replace '<your-example>.ts' with your actual script. The output depends on your script's implementation.\nSOURCE: https://github.com/openai/openai-node/blob/master/CONTRIBUTING.md#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\n$ chmod +x examples/<your-example>.ts\\n# run the example against your api\\n$ yarn tsn -T examples/<your-example>.ts\n```\n\n----------------------------------------\n\nTITLE: Auto-pagination for Listing FineTuning Jobs - TypeScript\nDESCRIPTION: Shows how to automatically iterate over paged list responses in the SDK using for-await-of syntax, fetching all fine tuning jobs across multiple pages without manual pagination logic. Requires openai package and a properly initialized client.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_12\n\nLANGUAGE: ts\nCODE:\n```\nasync function fetchAllFineTuningJobs(params) {\n  const allFineTuningJobs = [];\n  // Automatically fetches more pages as needed.\n  for await (const fineTuningJob of client.fineTuning.jobs.list({ limit: 20 })) {\n    allFineTuningJobs.push(fineTuningJob);\n  }\n  return allFineTuningJobs;\n}\n```\n\n----------------------------------------\n\nTITLE: Searching within a Vector Store with OpenAI Node.js Client\nDESCRIPTION: Performs a search operation within a specified vector store using the OpenAI API. The `search` method on `client.vectorStores` requires the `vectorStoreId` and search parameters, returning a `VectorStoreSearchResponsesPage` containing the search results.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_39\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.search(vectorStoreId, { ...params }) -> VectorStoreSearchResponsesPage\n```\n\n----------------------------------------\n\nTITLE: Creating a File in a Vector Store with OpenAI Node.js Client\nDESCRIPTION: Adds a file to a specific vector store via the OpenAI API. The `create` method under `client.vectorStores.files` takes the `vectorStoreId` and parameters (like the file ID) and returns a `VectorStoreFile` object representing the file within the store.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_40\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.files.create(vectorStoreId, { ...params }) -> VectorStoreFile\n```\n\n----------------------------------------\n\nTITLE: Creating a TypeScript Example Script\nDESCRIPTION: This TypeScript snippet is an example placeholder for adding a new script in the examples directory. The shebang uses npm's tsn runner for execution. To use, place this code in 'examples/<your-example>.ts', customize as needed, and ensure execution permissions are set. Inputs may depend on your example; outputs are determined by your script logic.\nSOURCE: https://github.com/openai/openai-node/blob/master/CONTRIBUTING.md#_snippet_1\n\nLANGUAGE: ts\nCODE:\n```\n// add an example to examples/<your-example>.ts\\n\\n#!/usr/bin/env -S npm run tsn -T\\n…\n```\n\n----------------------------------------\n\nTITLE: Uploading Files via Multiple Methods - OpenAI SDK - TypeScript\nDESCRIPTION: Illustrates various ways to upload files for fine-tuning using the OpenAI SDK: with fs.ReadStream (Node.js), the web File API, fetch's Response, and the SDK's toFile helper. Dependencies include openai, node-fetch, and optionally the Node.js fs module. Each example calls client.files.create with different data forms for file and a 'purpose' parameter.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_6\n\nLANGUAGE: ts\nCODE:\n```\nimport fs from 'fs';\nimport fetch from 'node-fetch';\nimport OpenAI, { toFile } from 'openai';\n\nconst client = new OpenAI();\n\n// If you have access to Node `fs` we recommend using `fs.createReadStream()`:\nawait client.files.create({ file: fs.createReadStream('input.jsonl'), purpose: 'fine-tune' });\n\n// Or if you have the web `File` API you can pass a `File` instance:\nawait client.files.create({ file: new File(['my bytes'], 'input.jsonl'), purpose: 'fine-tune' });\n\n// You can also pass a `fetch` `Response`:\nawait client.files.create({ file: await fetch('https://somesite/input.jsonl'), purpose: 'fine-tune' });\n\n// Finally, if none of the above are convenient, you can use our `toFile` helper:\nawait client.files.create({\n  file: await toFile(Buffer.from('my bytes'), 'input.jsonl'),\n  purpose: 'fine-tune',\n});\nawait client.files.create({\n  file: await toFile(new Uint8Array([0, 1, 2]), 'input.jsonl'),\n  purpose: 'fine-tune',\n});\n```\n\n----------------------------------------\n\nTITLE: Creating and Polling a Vector Store File (Beta) with OpenAI Node.js Client\nDESCRIPTION: Creates a file association within a vector store and polls its status until processing is complete (e.g., chunking and embedding). This beta method (`createAndPoll` under `client.beta.vectorStores.files`) takes the `vectorStoreId`, file details (`body`), and optional settings, returning a Promise that resolves with the final `VectorStoreFile`.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_46\n\nLANGUAGE: typescript\nCODE:\n```\nclient.beta.vectorStores.files.createAndPoll(vectorStoreId, body, options?) -> Promise<VectorStoreFile>\n```\n\n----------------------------------------\n\nTITLE: Canceling a Fine-Tuning Job with OpenAI Node.js Client\nDESCRIPTION: Sends a request to cancel an ongoing fine-tuning job through the OpenAI API. The `cancel` method under `client.fineTuning.jobs` takes the `fineTuningJobId` and returns the updated `FineTuningJob` object, reflecting its canceled status.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_28\n\nLANGUAGE: typescript\nCODE:\n```\nclient.fineTuning.jobs.cancel(fineTuningJobId) -> FineTuningJob\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using AzureOpenAI Client in TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize the `AzureOpenAI` client for interacting with Azure OpenAI services. It uses `@azure/identity` to obtain an Azure AD token provider (`DefaultAzureCredential`, `getBearerTokenProvider`) which is then passed to the `AzureOpenAI` constructor along with the required API version. Finally, it shows how to make a basic chat completion request using the initialized client.\nSOURCE: https://github.com/openai/openai-node/blob/master/azure.md#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { AzureOpenAI } from 'openai';\nimport { getBearerTokenProvider, DefaultAzureCredential } from '@azure/identity';\n\nconst credential = new DefaultAzureCredential();\nconst scope = 'https://cognitiveservices.azure.com/.default';\nconst azureADTokenProvider = getBearerTokenProvider(credential, scope);\n\nconst openai = new AzureOpenAI({ azureADTokenProvider, apiVersion: \"<The API version, e.g. 2024-10-01-preview>\" });\n\nconst result = await openai.chat.completions.create({\n  model: 'gpt-4o',\n  messages: [{ role: 'user', content: 'Say hello!' }],\n});\n\nconsole.log(result.choices[0]!.message?.content);\n```\n\n----------------------------------------\n\nTITLE: Retrieving File Content (String) using OpenAI Node.js Client\nDESCRIPTION: Calls the `retrieveContent` method on the `files` resource to get the content of a specific file by its ID, automatically handling the response and returning the content as a string. It requires the `fileId`. This corresponds to the `GET /files/{file_id}/content` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_13\n\nLANGUAGE: javascript\nCODE:\n```\nclient.files.retrieveContent(fileId) -> string\n```\n\n----------------------------------------\n\nTITLE: Subscribing to RunStep Creation, Delta, and Completion Events in Assistant Streaming - TypeScript\nDESCRIPTION: Shows how to attach listeners for creation, delta, and completion of RunStep events in the assistant's streaming API. Enables application logic to react to all phases of a run step, which may correspond to tool executions or message productions in the workflow. Utilizes runStepCreated, runStepDelta, and runStepDone event types.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n.on('runStepCreated', (runStep: RunStep) => ...)\n.on('runStepDelta', (delta: RunStepDelta, snapshot: RunStep) => ...)\n.on('runStepDone', (runStep: RunStep) => ...)\n```\n\n----------------------------------------\n\nTITLE: Using the OpenAI SDK with Microsoft Azure OpenAI - TypeScript\nDESCRIPTION: Shows how to configure the OpenAI SDK for use with Azure OpenAI services. Involves importing AzureOpenAI, getting Azure AD bearer credentials, instantiating the Azure-specific client, and running a chat completion. Requires @azure/identity, openai, and Azure resource/API access.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_15\n\nLANGUAGE: ts\nCODE:\n```\nimport { AzureOpenAI } from 'openai';\nimport { getBearerTokenProvider, DefaultAzureCredential } from '@azure/identity';\n\nconst credential = new DefaultAzureCredential();\nconst scope = 'https://cognitiveservices.azure.com/.default';\nconst azureADTokenProvider = getBearerTokenProvider(credential, scope);\n\nconst openai = new AzureOpenAI({ azureADTokenProvider, apiVersion: \"<The API version, e.g. 2024-10-01-preview>\" });\n\nconst result = await openai.chat.completions.create({\n  model: 'gpt-4o',\n  messages: [{ role: 'user', content: 'Say hello!' }],\n});\n\nconsole.log(result.choices[0]!.message?.content);\n```\n\n----------------------------------------\n\nTITLE: Making Custom POST Requests with OpenAI Node.js Client in TypeScript\nDESCRIPTION: Illustrates using the generic `client.post` method to send requests to potentially undocumented API endpoints. This approach allows specifying the path, request body, and query parameters while still benefiting from client-level configurations like automatic retries. Requires an initialized `OpenAI` client.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\n```ts\nawait client.post('/some/path', {\n  body: { some_prop: 'foo' },\n  query: { some_query_arg: 'bar' },\n});\n```\n```\n\n----------------------------------------\n\nTITLE: Listing Vector Stores with OpenAI Node.js Client\nDESCRIPTION: Retrieves a list of vector stores associated with the account via the OpenAI API. The `list` method on `client.vectorStores` accepts optional parameters (e.g., for pagination) and returns a `VectorStoresPage` object.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_37\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.list({ ...params }) -> VectorStoresPage\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Raw Assistant Streaming Events in OpenAI SDK - TypeScript\nDESCRIPTION: Demonstrates subscribing to all raw assistant streaming events using the event handler interface in the OpenAI Node.js SDK. The on('event') pattern enables inspection and handling of low-level AssistantStreamEvent objects. Suits cases where fine-grained or custom processing is needed across all available event types.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n.on('event', (event: AssistantStreamEvent) => ...)\n```\n\n----------------------------------------\n\nTITLE: Registering Error Event Listener for OpenAI Realtime API (ws, TypeScript)\nDESCRIPTION: Shows how to explicitly add an error event handler when using the 'OpenAIRealtimeWS' client for the Realtime API. This pattern ensures that errors, whether from client or server, are caught and handled to avoid unhandled promise rejections. Appropriate for robust production usage to maintain connection stability; requires the same dependencies as for general usage of the OpenAIRealtimeWS API.\nSOURCE: https://github.com/openai/openai-node/blob/master/realtime.md#_snippet_2\n\nLANGUAGE: TypeScript\nCODE:\n```\nconst rt = new OpenAIRealtimeWS({ model: 'gpt-4o-realtime-preview-2024-12-17' });\nrt.on('error', (err) => {\n  // in a real world scenario this should be logged somewhere as you\n  // likely want to continue procesing events regardless of any errors\n  throw err;\n});\n\n```\n\n----------------------------------------\n\nTITLE: Cancelling an Upload using OpenAI Node Client (JavaScript)\nDESCRIPTION: Cancels an ongoing upload process identified by its unique identifier (`uploadId`) via the Node.js client. This is useful if the upload is no longer needed or needs to be aborted. Returns the updated `Upload` object reflecting the cancellation status. This method corresponds to the `POST /uploads/{upload_id}/cancel` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_59\n\nLANGUAGE: javascript\nCODE:\n```\nclient.uploads.cancel(uploadId) -> Upload\n```\n\n----------------------------------------\n\nTITLE: Retrieving a File from a Vector Store with OpenAI Node.js Client\nDESCRIPTION: Fetches details about a specific file within a vector store using the OpenAI API. The `retrieve` method on `client.vectorStores.files` takes the `vectorStoreId` and `fileId` as input and returns the corresponding `VectorStoreFile` object.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_41\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.files.retrieve(vectorStoreId, fileId) -> VectorStoreFile\n```\n\n----------------------------------------\n\nTITLE: Configuring Request Timeouts with OpenAI SDK - TypeScript\nDESCRIPTION: Shows how to set custom timeout values for requests using the OpenAI SDK, both when initializing the client and per individual API call. Requires openai package. A timeout error (APIConnectionTimeoutError) will be thrown on request timeout.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_9\n\nLANGUAGE: ts\nCODE:\n```\n// Configure the default for all requests:\nconst client = new OpenAI({\n  timeout: 20 * 1000, // 20 seconds (default is 10 minutes)\n});\n\n// Override per-request:\nawait client.chat.completions.create({ messages: [{ role: 'user', content: 'How can I list all files in a directory using Python?' }], model: 'gpt-4o' }, {\n  timeout: 5 * 1000,\n});\n```\n\n----------------------------------------\n\nTITLE: Retrieving a Model with OpenAI Node.js Client\nDESCRIPTION: Fetches information about a specific model from the OpenAI API. This method, `retrieve` under `client.models`, takes the model identifier as an argument and returns a `Model` object containing details about the requested model.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_22\n\nLANGUAGE: typescript\nCODE:\n```\nclient.models.retrieve(model) -> Model\n```\n\n----------------------------------------\n\nTITLE: Manual Pagination of FineTuning Jobs - TypeScript\nDESCRIPTION: Illustrates manual pagination for listing fine tuning jobs using the SDK's list method. The code fetches one page, iterates its data, and calls getNextPage in a loop as long as hasNextPage returns true. Requires openai package and initialized client.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_13\n\nLANGUAGE: ts\nCODE:\n```\nlet page = await client.fineTuning.jobs.list({ limit: 20 });\nfor (const fineTuningJob of page.data) {\n  console.log(fineTuningJob);\n}\n\n// Convenience methods are provided for manually paginating:\nwhile (page.hasNextPage()) {\n  page = await page.getNextPage();\n  // ...\n}\n```\n\n----------------------------------------\n\nTITLE: Updating a File in a Vector Store with OpenAI Node.js Client\nDESCRIPTION: Updates metadata or properties of a specific file within a vector store via the OpenAI API. The `update` method on `client.vectorStores.files` takes the `vectorStoreId`, `fileId`, and parameters with the desired changes, returning the updated `VectorStoreFile` object.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_42\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.files.update(vectorStoreId, fileId, { ...params }) -> VectorStoreFile\n```\n\n----------------------------------------\n\nTITLE: Creating a Fine-Tuning Job with OpenAI Node.js Client\nDESCRIPTION: Initiates a new fine-tuning job using the OpenAI API. The `create` method under `client.fineTuning.jobs` accepts parameters defining the job (e.g., model, training data) and returns a `FineTuningJob` object representing the newly created job.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_25\n\nLANGUAGE: typescript\nCODE:\n```\nclient.fineTuning.jobs.create({ ...params }) -> FineTuningJob\n```\n\n----------------------------------------\n\nTITLE: Handling Image File Completion Events in Assistant Streaming API - TypeScript\nDESCRIPTION: Provides a handler for the imageFileDone event emitted by the Assistant streaming API, allowing developers to respond to image files once they are available. Since image files are not streamed incrementally, this event triggers only upon complete payload delivery. Relies on the provided content and message snapshot arguments.\nSOURCE: https://github.com/openai/openai-node/blob/master/helpers.md#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\n.on('imageFileDone', (content: ImageFile, snapshot: Message) => ...)\n```\n\n----------------------------------------\n\nTITLE: Retrieving a Fine-Tuning Job with OpenAI Node.js Client\nDESCRIPTION: Fetches details about a specific fine-tuning job from the OpenAI API. The `retrieve` method on `client.fineTuning.jobs` takes the `fineTuningJobId` as input and returns the corresponding `FineTuningJob` object.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_26\n\nLANGUAGE: typescript\nCODE:\n```\nclient.fineTuning.jobs.retrieve(fineTuningJobId) -> FineTuningJob\n```\n\n----------------------------------------\n\nTITLE: Deleting a Vector Store with OpenAI Node.js Client\nDESCRIPTION: Sends a request to delete a specific vector store using the OpenAI API. The `del` method on `client.vectorStores` requires the `vectorStoreId` and returns a `VectorStoreDeleted` object confirming the deletion.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_38\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.del(vectorStoreId) -> VectorStoreDeleted\n```\n\n----------------------------------------\n\nTITLE: Deleting a File from a Vector Store with OpenAI Node.js Client\nDESCRIPTION: Removes a specific file from a vector store via the OpenAI API. The `del` method on `client.vectorStores.files` requires both the `vectorStoreId` and the `fileId` to be deleted, returning a `VectorStoreFileDeleted` object confirming the deletion.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_44\n\nLANGUAGE: typescript\nCODE:\n```\nclient.vectorStores.files.del(vectorStoreId, fileId) -> VectorStoreFileDeleted\n```\n\n----------------------------------------\n\nTITLE: Installing and Building the Project with Yarn in Shell\nDESCRIPTION: This shell snippet installs project dependencies and builds the output files using Yarn. Requires yarn@v1 to be installed. Running these commands sets up the repository by loading all dependency modules and compiling source code to the 'dist/' directory. No parameters required, must be run in the project root.\nSOURCE: https://github.com/openai/openai-node/blob/master/CONTRIBUTING.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n$ yarn\\n$ yarn build\n```\n\n----------------------------------------\n\nTITLE: Creating Completions using OpenAI Node.js Client\nDESCRIPTION: Calls the `create` method on the `completions` resource of the OpenAI client to generate a completion based on provided parameters. It accepts an object containing parameters like prompt and model, and returns a `Completion` object. This corresponds to the `POST /completions` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nclient.completions.create({ ...params }) -> Completion\n```\n\n----------------------------------------\n\nTITLE: Connecting and Exchanging Events with OpenAI Realtime API (ws, TypeScript)\nDESCRIPTION: Illustrates establishing a WebSocket connection to the OpenAI Realtime API using the 'ws' library in Node.js, sending session and message creation events, subscribing to server events for streaming response text, and handling error and closure events. Requires the 'ws' and '@types/ws' packages, as well as the beta OpenAI client SDK. Key parameters include session settings (modalities, model) and message content. Outputs conversational replies from the model and properly closes the connection when done.\nSOURCE: https://github.com/openai/openai-node/blob/master/realtime.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n// requires `yarn add ws @types/ws`\nimport { OpenAIRealtimeWS } from 'openai/beta/realtime/ws';\n\nconst rt = new OpenAIRealtimeWS({ model: 'gpt-4o-realtime-preview-2024-12-17' });\n\n// access the underlying `ws.WebSocket` instance\nrt.socket.on('open', () => {\n  console.log('Connection opened!');\n  rt.send({\n    type: 'session.update',\n    session: {\n      modalities: ['text'],\n      model: 'gpt-4o-realtime-preview',\n    },\n  });\n\n  rt.send({\n    type: 'conversation.item.create',\n    item: {\n      type: 'message',\n      role: 'user',\n      content: [{ type: 'input_text', text: 'Say a couple paragraphs!' }],\n    },\n  });\n\n  rt.send({ type: 'response.create' });\n});\n\nrt.on('error', (err) => {\n  // in a real world scenario this should be logged somewhere as you\n  // likely want to continue procesing events regardless of any errors\n  throw err;\n});\n\nrt.on('session.created', (event) => {\n  console.log('session created!', event.session);\n  console.log();\n});\n\nrt.on('response.text.delta', (event) => process.stdout.write(event.delta));\nrt.on('response.text.done', () => console.log());\n\nrt.on('response.done', () => rt.close());\n\nrt.socket.on('close', () => console.log('\\nConnection closed!'));\n\n```\n\n----------------------------------------\n\nTITLE: Deleting Chat Completions using OpenAI Node.js Client\nDESCRIPTION: Calls the `del` method on the `chat.completions` resource to delete a specific chat completion by its ID. It requires the `completionId` and returns a `ChatCompletionDeleted` object confirming the deletion. This corresponds to the `DELETE /chat/completions/{completion_id}` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nclient.chat.completions.del(completionId) -> ChatCompletionDeleted\n```\n\n----------------------------------------\n\nTITLE: Managing Runs for Evals - OpenAI Node.js SDK - TypeScript\nDESCRIPTION: Defines types for Run data sources and responses, and provides client methods for creating, retrieving, listing, deleting, and canceling Eval Runs using the OpenAI Node.js SDK in TypeScript. Each client.evals.runs.<method> aligns with a specific REST endpoint and expects Eval and Run identifiers as parameters where relevant. Outputs are typed Run response objects. The implementation expects the OpenAI Node.js SDK and type definitions. It is suited for projects managing evaluation executions programmatically.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_67\n\nLANGUAGE: typescript\nCODE:\n```\n// Types\n// - CreateEvalCompletionsRunDataSource\n// - CreateEvalJSONLRunDataSource\n// - EvalAPIError\n// - RunCreateResponse\n// - RunRetrieveResponse\n// - RunListResponse\n// - RunDeleteResponse\n// - RunCancelResponse\n\n// Methods\n// client.evals.runs.create(evalId, { ...params }) -> RunCreateResponse\n// client.evals.runs.retrieve(evalId, runId) -> RunRetrieveResponse\n// client.evals.runs.list(evalId, { ...params }) -> RunListResponsesPage\n// client.evals.runs.del(evalId, runId) -> RunDeleteResponse\n// client.evals.runs.cancel(evalId, runId) -> RunCancelResponse\n```\n\n----------------------------------------\n\nTITLE: Connecting to OpenAI Realtime API with Native WebSocket (TypeScript)\nDESCRIPTION: Demonstrates initializing a connection to the OpenAI Realtime API using the browser's native WebSocket interface via the 'OpenAIRealtimeWebSocket' class. Intended for browser or similar environments, this snippet replaces the ws-based client with the platform-native implementation, adjusting event listener registration accordingly. Key parameters include credentials and model configuration, and standard WebSocket event patterns are followed for real-time communication.\nSOURCE: https://github.com/openai/openai-node/blob/master/realtime.md#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { OpenAIRealtimeWebSocket } from 'openai/beta/realtime/websocket';\n\nconst rt = new OpenAIRealtimeWebSocket({ model: 'gpt-4o-realtime-preview-2024-12-17' });\n// ...\nrt.socket.addEventListener('open', () => {\n // ...\n});\n\n```\n\n----------------------------------------\n\nTITLE: Waiting for File Processing using OpenAI Node.js Client\nDESCRIPTION: Calls the `waitForProcessing` helper method on the `files` resource. This utility function polls the status of a file (specified by `id`) until it reaches a 'processed' state or a timeout occurs. It accepts optional polling parameters (`pollInterval`, `maxWait`) and returns a Promise that resolves with the final `FileObject`.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_14\n\nLANGUAGE: javascript\nCODE:\n```\nclient.files.waitForProcessing(id, { pollInterval = 5000, maxWait = 30 _ 60 _ 1000 }) -> Promise<FileObject>\n```\n\n----------------------------------------\n\nTITLE: Retrieving File Content (Raw Response) using OpenAI Node.js Client\nDESCRIPTION: Calls the `content` method on the `files` resource to retrieve the content of a specific file by its ID. It requires the `fileId` and returns the raw `Response` object from the underlying HTTP client (like `fetch`), allowing access to headers and streaming capabilities. This corresponds to the `GET /files/{file_id}/content` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_12\n\nLANGUAGE: javascript\nCODE:\n```\nclient.files.content(fileId) -> Response\n```\n\n----------------------------------------\n\nTITLE: Listing Files using OpenAI Node.js Client\nDESCRIPTION: Calls the `list` method on the `files` resource to retrieve a list of uploaded files associated with the user's organization. It accepts an optional object with parameters for filtering (e.g., by purpose) and returns a paginated `FileObjectsPage` object. This corresponds to the `GET /files` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\nclient.files.list({ ...params }) -> FileObjectsPage\n```\n\n----------------------------------------\n\nTITLE: Retrieving File Metadata using OpenAI Node.js Client\nDESCRIPTION: Calls the `retrieve` method on the `files` resource to get metadata for a specific file by its ID. It requires the `fileId` as an argument and returns a `FileObject` containing details about the file. This corresponds to the `GET /files/{file_id}` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\nclient.files.retrieve(fileId) -> FileObject\n```\n\n----------------------------------------\n\nTITLE: Listing Fine-Tuning Job Checkpoints with OpenAI Node.js Client\nDESCRIPTION: Retrieves a list of checkpoints created during a specific fine-tuning job via the OpenAI API. The `list` method under `client.fineTuning.jobs.checkpoints` takes the `fineTuningJobId` and optional parameters, returning a `FineTuningJobCheckpointsPage` object.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_30\n\nLANGUAGE: typescript\nCODE:\n```\nclient.fineTuning.jobs.checkpoints.list(fineTuningJobId, { ...params }) -> FineTuningJobCheckpointsPage\n```\n\n----------------------------------------\n\nTITLE: Creating an Upload using OpenAI Node Client (JavaScript)\nDESCRIPTION: Initiates an upload process using the OpenAI API via the Node.js client. Requires parameters (`params`) specifying the details of the file to be uploaded (e.g., purpose, filename, size). Returns an `Upload` object representing the initiated upload session. This method corresponds to the `POST /uploads` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_58\n\nLANGUAGE: javascript\nCODE:\n```\nclient.uploads.create({ ...params }) -> Upload\n```\n\n----------------------------------------\n\nTITLE: Completing an Upload using OpenAI Node Client (JavaScript)\nDESCRIPTION: Marks an upload, identified by `uploadId`, as complete via the Node.js client. This is typically used after all parts of a multipart upload have been successfully uploaded. Requires additional parameters (`params`), such as the list of part IDs. Returns the completed `Upload` object. This method corresponds to the `POST /uploads/{upload_id}/complete` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_60\n\nLANGUAGE: javascript\nCODE:\n```\nclient.uploads.complete(uploadId, { ...params }) -> Upload\n```\n\n----------------------------------------\n\nTITLE: Creating a Batch using OpenAI Node Client (JavaScript)\nDESCRIPTION: Creates a new batch job using the OpenAI API via the Node.js client. Requires parameters (`params`) specific to the batch creation request, as detailed in the linked `batches.ts` file. Returns a `Batch` object representing the created batch upon successful completion. This method corresponds to the `POST /batches` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_54\n\nLANGUAGE: javascript\nCODE:\n```\nclient.batches.create({ ...params }) -> Batch\n```\n\n----------------------------------------\n\nTITLE: Listing Batches using OpenAI Node Client (JavaScript)\nDESCRIPTION: Lists existing batch jobs via the Node.js client. Optional parameters (`params`) can be provided for filtering or pagination (e.g., limit, after). Returns a `BatchesPage` object containing a list of `Batch` objects and potentially pagination cursors. This method corresponds to the `GET /batches` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_56\n\nLANGUAGE: javascript\nCODE:\n```\nclient.batches.list({ ...params }) -> BatchesPage\n```\n\n----------------------------------------\n\nTITLE: Cancelling a Batch using OpenAI Node Client (JavaScript)\nDESCRIPTION: Cancels an in-progress batch job identified by its unique identifier (`batchId`) via the Node.js client. Returns the updated `Batch` object, reflecting the cancellation status. This method corresponds to the `POST /batches/{batch_id}/cancel` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_57\n\nLANGUAGE: javascript\nCODE:\n```\nclient.batches.cancel(batchId) -> Batch\n```\n\n----------------------------------------\n\nTITLE: Deleting a Model with OpenAI Node.js Client\nDESCRIPTION: Sends a request to delete a specific fine-tuned model via the OpenAI API. It uses the `del` method (an alias for delete) on `client.models`, requires the model identifier, and returns a `ModelDeleted` object confirming the deletion.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_24\n\nLANGUAGE: typescript\nCODE:\n```\nclient.models.del(model) -> ModelDeleted\n```\n\n----------------------------------------\n\nTITLE: Retrieving and Listing OutputItems for Eval Runs - OpenAI Node.js SDK - TypeScript\nDESCRIPTION: Specifies OutputItem-related TypeScript types and lists methods for retrieving and listing OutputItems associated with specific Eval Runs using the OpenAI Node.js SDK. Methods require Eval, Run, and OutputItem identifiers as parameters, returning strongly typed OutputItem response objects. Dependencies include the OpenAI Node.js SDK and related TypeScript type definitions. Input constraints are governed by identifier validity and required parameter types.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_68\n\nLANGUAGE: typescript\nCODE:\n```\n// Types\n// - OutputItemRetrieveResponse\n// - OutputItemListResponse\n\n// Methods\n// client.evals.runs.outputItems.retrieve(evalId, runId, outputItemId) -> OutputItemRetrieveResponse\n// client.evals.runs.outputItems.list(evalId, runId, { ...params }) -> OutputItemListResponsesPage\n```\n\n----------------------------------------\n\nTITLE: Creating Image Variations using OpenAI Node.js Client\nDESCRIPTION: Calls the `createVariation` method on the `images` resource to generate variations of a given input image. It accepts an object with parameters (including the image file, number of variations, size) and returns an `ImagesResponse` object containing URLs or base64 data for the generated variations. This corresponds to the `POST /images/variations` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_15\n\nLANGUAGE: javascript\nCODE:\n```\nclient.images.createVariation({ ...params }) -> ImagesResponse\n```\n\n----------------------------------------\n\nTITLE: Creating a Response using OpenAI Node Client (JavaScript)\nDESCRIPTION: Creates a response using the OpenAI API via the Node.js client, likely interacting with an assistant or model. Requires parameters (`params`) defining the input (e.g., messages, files) and desired response characteristics (e.g., model, tools). Returns a `Response` object containing the generated output or interaction state. This method corresponds to the `POST /responses` API endpoint.\nSOURCE: https://github.com/openai/openai-node/blob/master/api.md#_snippet_62\n\nLANGUAGE: javascript\nCODE:\n```\nclient.responses.create({ ...params }) -> Response\n```\n\n----------------------------------------\n\nTITLE: Sending Undocumented Parameters with OpenAI Node.js Client in TypeScript\nDESCRIPTION: Shows how to include undocumented parameters in standard API method calls by suppressing TypeScript errors using `// @ts-expect-error`. The library does not perform runtime validation against the types, so any extra parameters provided are sent directly to the API (typically in the body for non-GET requests, or query string for GET). Requires an initialized `OpenAI` client.\nSOURCE: https://github.com/openai/openai-node/blob/master/README.md#_snippet_18\n\nLANGUAGE: typescript\nCODE:\n```\n```ts\nclient.foo.create({\n  foo: 'my_param',\n  bar: 12,\n  // @ts-expect-error baz is not yet public\n  baz: 'undocumented option',\n});\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Bun (Bash)\nDESCRIPTION: This Bash snippet installs all required dependencies for the project using Bun's package manager. It must be run from the project root directory where the dependency manifest (such as package.json or bun.lockb) is located. No additional arguments are necessary; the command will fetch and install packages as specified by the project's configuration files.\nSOURCE: https://github.com/openai/openai-node/blob/master/ecosystem-tests/bun/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbun install\n```\n\n----------------------------------------\n\nTITLE: Running the Index Script with Bun (Bash)\nDESCRIPTION: This Bash command executes the main TypeScript file (index.ts) using Bun's script runner. It assumes that index.ts is present in the root directory and that all required dependencies are already installed. The command will start the primary process or test as defined in index.ts, and is usually invoked after setting up the environment with the previous installation command.\nSOURCE: https://github.com/openai/openai-node/blob/master/ecosystem-tests/bun/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbun run index.ts\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Linking with Yarn or pnpm in Shell\nDESCRIPTION: This shell snippet demonstrates cloning the openai-node repository and linking it locally with Yarn or pnpm. These steps allow development against a local clone. Both tooling options require their respective CLIs installed. Replace '../my-package' with your actual package's directory. After linking, your package will resolve the local version of openai-node.\nSOURCE: https://github.com/openai/openai-node/blob/master/CONTRIBUTING.md#_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\n# Clone\\n$ git clone https://www.github.com/openai/openai-node\\n$ cd openai-node\\n\\n# With yarn\\n$ yarn link\\n$ cd ../my-package\\n$ yarn link openai\\n\\n# With pnpm\\n$ pnpm link --global\\n$ cd ../my-package\\n$ pnpm link -—global openai\n```\n\n----------------------------------------\n\nTITLE: Linting and Auto-Fixing Code with Yarn in Shell\nDESCRIPTION: This shell snippet provides commands for linting and auto-formatting/fixing code issues using Yarn. Project must have 'eslint' and 'prettier' configured. 'yarn lint' reports lint issues; 'yarn fix' attempts to automatically correct them. Applicable to the project's source code files.\nSOURCE: https://github.com/openai/openai-node/blob/master/CONTRIBUTING.md#_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\n$ yarn lint\n```\n\nLANGUAGE: sh\nCODE:\n```\n$ yarn fix\n```\n\n----------------------------------------\n\nTITLE: Importing Node and Web Shim Overrides (ECMAScript Imports, Markdown/JavaScript)\nDESCRIPTION: This snippet shows how users can manually import shims for specific environments (Node or web) in the openai-node SDK. By importing either the 'openai/shims/node' or 'openai/shims/web' modules, the developer can override the environment auto-detection to ensure the correct fetch shim (or other runtime behaviors) is used. This approach is especially useful in environments where automatic detection via conditional exports fails (such as when using incompatible TypeScript module resolution strategies). No other dependencies are required, but the openai-node package must be installed. The imports do not take parameters and only affect global runtime shims. Output is the installation of the correct environment shim for subsequent SDK usage.\nSOURCE: https://github.com/openai/openai-node/blob/master/src/_shims/README.md#_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport 'openai/shims/node'\n```\n\nLANGUAGE: javascript\nCODE:\n```\nimport 'openai/shims/web'\n```"
  }
]