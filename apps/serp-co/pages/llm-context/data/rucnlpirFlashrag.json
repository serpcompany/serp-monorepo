[
  {
    "owner": "ruc-nlpir",
    "repo": "flashrag",
    "content": "TITLE: Example FlashRAG Configuration in YAML\nDESCRIPTION: Provides a comprehensive example of a FlashRAG configuration file in YAML format. This includes global paths, environment settings, retrieval settings, generator settings, and evaluation configurations.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/configuration.md#2025-04-07_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# basic settings\n\n# ------------------------------------------------Global Paths------------------------------------------------#\n# Paths to various models\nmodel2path:\n  e5: \"intfloat/e5-base-v2\"\n  bge: \"intfloat/e5-base-v2\"\n  contriever: \"facebook/contriever\"\n  llama2-7B-chat: \"meta-llama/Llama-2-7b-chat-hf\"\n  llama2-7B: \"meta-llama/Llama-2-7b-hf\"\n  llama2-13B: \"meta-llama/Llama-2-13b-hf\"\n  llama2-13B-chat: \"meta-llama/Llama-2-13b-chat-hf\"\n  \n# Pooling methods for each embedding model\nmodel2pooling:\n  e5: \"mean\"\n  bge: \"cls\"\n  contriever: \"mean\"\n  jina: 'mean'\n  dpr: cls\n\n# Indexes path for retrieval models\nmethod2index:\n  e5: ~\n  bm25: ~\n  contriever: ~\n\n# ------------------------------------------------Environment Settings------------------------------------------------#\n# Directory paths for data and outputs\ndata_dir: \"dataset/\"\nsave_dir: \"output/\"\n\ngpu_id: \"0,1,2,3\"\ndataset_name: \"nq\" # name of the dataset in data_dir\nsplit: [\"test\"]  # dataset split to load (e.g. train,dev,test)\n\n# Sampling configurations for testing\ntest_sample_num: ~  # number of samples to test (only work in dev/test split), if None, test all samples\nrandom_sample: False # whether to randomly sample the test samples\n\n# Seed for reproducibility\nseed: 2024\n\n# Whether save intermediate data\nsave_intermediate_data: True\nsave_note: 'experiment'\n\n# -------------------------------------------------Retrieval Settings------------------------------------------------#\n# If set the name, the model path will be find in global paths\nretrieval_method: \"e5\"  # name or path of the retrieval model. \nretrieval_model_path: ~ # path to the retrieval model\nindex_path: ~ # set automatically if not provided. \nfaiss_gpu: False # whether use gpu to hold index\ncorpus_path: ~  # path to corpus in '.jsonl' format that store the documents\n\nuse_sentence_transformer: False # If set, the retriever will be load through `sentence transformer` library\nretrieval_topk: 5 # number of retrieved documents\nretrieval_batch_size: 256  # batch size for retrieval\nretrieval_use_fp16: True  # whether to use fp16 for retrieval model\nretrieval_query_max_length: 128  # max length of the query\nsave_retrieval_cache: True # whether to save the retrieval cache\nuse_retrieval_cache: False # whether to use the retrieval cache\nretrieval_cache_path: ~ # path to the retrieval cache\nretrieval_pooling_method: ~ # set automatically if not provided\n\nuse_reranker: False # whether to use reranker\nrerank_model_name: ~ # same as retrieval_method\nrerank_model_path: ~ # path to reranker model, path will be automatically find in `model2path`\nrerank_pooling_method: ~\nrerank_topk: 5  # number of remain documents after reranking\nrerank_max_length: 512 \nrerank_batch_size: 256 # batch size for reranker\nrerank_use_fp16: True\n\n# -------------------------------------------------Generator Settings------------------------------------------------#\nframework: fschat # inference frame work of LLM, supporting: 'hf','vllm','fschat', 'openai'\ngenerator_model: \"llama3-8B-instruct\" # name or path of the generator model\n# setting for openai model, only valid in openai framework\nopenai_setting:\n  api_key: ~\n  base_url: ~\n\ngenerator_model_path: ~\ngenerator_max_input_len: 1024  # max length of the input\ngenerator_batch_size: 4 # batch size for generation, invalid for vllm\ngeneration_params:  \n  #do_sample: false\n  max_tokens: 32\n  #temperature: 1.0\n  #top_p: 1.0\nuse_fid: False # whether to use FID, only valid in encoder-decoder model\n\n# -------------------------------------------------Evaluation Settings------------------------------------------------#\n# Metrics to evaluate the result\nmetrics: ['em','f1','acc,'precision','recall'] \n# Specify setting for metric, will be called within certain metrics\nmetric_setting: \n  retrieval_recall_topk: 5\nsave_metric_score: True #　whether to save the metric score into txt file\n```\n\n----------------------------------------\n\nTITLE: Configuring Retrieval Settings in YAML for FlashRAG\nDESCRIPTION: This YAML snippet defines various parameters for the retriever and reranker in FlashRAG. It includes settings for the retrieval method, model paths, corpus details, and caching options. It also configures reranking parameters if a reranker is used.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/configuration.md#2025-04-07_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nretrieval_method: \"e5\"  # name or path of the retrieval model. \nretrieval_model_path: ~ # path to the retrieval model\nindex_path: ~ # set automatically if not provided. \nfaiss_gpu: False # whether use gpu to hold index\ncorpus_path: ~  # path to corpus in '.jsonl' format that store the documents\n\nuse_sentence_transformer: False # If set, the retriever will be load through `sentence transformer` library\nretrieval_topk: 5 # number of retrieved documents\nretrieval_batch_size: 256  # batch size for retrieval\nretrieval_use_fp16: True  # whether to use fp16 for retrieval model\nretrieval_query_max_length: 128  # max length of the query\nsave_retrieval_cache: True # whether to save the retrieval cache\nuse_retrieval_cache: False # whether to use the retrieval cache\nretrieval_cache_path: ~ # path to the retrieval cache\nretrieval_pooling_method: ~ # set automatically if not provided\n\nuse_reranker: False # whether to use reranker\nrerank_model_name: ~ # same as retrieval_method\nrerank_model_path: ~ # path to reranker model, path will be automatically find in `model2path`\nrerank_pooling_method: ~\nrerank_topk: 5  # number of remain documents after reranking\nrerank_max_length: 512 \nrerank_batch_size: 256 # batch size for reranker\nrerank_use_fp16: True\n```\n\n----------------------------------------\n\nTITLE: Configuring Generator Settings in YAML for FlashRAG\nDESCRIPTION: This YAML snippet defines settings for the generator in FlashRAG. It includes parameters for the inference framework, model selection, OpenAI settings (if applicable), and generation parameters. It also specifies input length limits and batch size for generation.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/configuration.md#2025-04-07_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nframework: fschat # inference frame work of LLM, supporting: 'hf','vllm','fschat', 'openai'\ngenerator_model: \"llama3-8B-instruct\" # name or path of the generator model\n# setting for openai model, only valid in openai framework\nopenai_setting:\n  api_key: ~\n  base_url: ~\ngenerator_model_path: ~\ngenerator_max_input_len: 1024  # max length of the input\ngenerator_batch_size: 4 # batch size for generation, invalid for vllm\ngeneration_params:  \n  max_tokens: 32\nuse_fid: False # whether to use FID, only valid in encoder-decoder model\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Retrievers in YAML for FlashRAG\nDESCRIPTION: This YAML configuration snippet demonstrates how to set up multiple retrievers in FlashRAG. It includes options for merge method, top-k results, and individual retriever settings.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/multi_retriever_usage.md#2025-04-07_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nuse_multi_retriever: True # whether to use multi retrievers\nmulti_retriever_setting:\n  merge_method: \"concat\" # support 'concat', 'rrf', 'rerank'\n  topk: 5 # final remaining documents, only used in 'rrf' and 'rerank' merge\n  rerank_model_name: ~\n  rerank_model_path: ~\n  retriever_list:\n    - retrieval_method: \"e5\"\n      retrieval_topk: 5\n      index_path: ~\n      retrieval_model_path: ~\n    - retrieval_method: \"bm25\"\n      retrieval_topk: 5\n      index_path: ~\n      retrieval_model_path: ~\n```\n\n----------------------------------------\n\nTITLE: Loading Configuration for FlashRAG Pipeline in Python\nDESCRIPTION: Initializes the configuration for the RAG process by setting paths to dataset, index, corpus, models, and defining parameters like retrieval method, generator model, evaluation metrics, and other settings.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/introduction_for_beginners_en.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom flashrag.config import Config\n\nconfig_dict = { \n    'data_dir': 'dataset/',\n    'index_path': 'indexes/e5_Flat.index',\n    'corpus_path': 'indexes/general_knowledge.jsonl',\n    'model2path': {'e5': <retriever_path>, 'llama2-7B-chat': <generator_path>},\n    'generator_model': 'llama2-7B-chat',\n    'retrieval_method': 'e5',\n    'metrics': ['em', 'f1', 'acc'],\n    'retrieval_topk': 1,\n    'save_intermediate_data': True\n}\n\nconfig = Config(config_dict=config_dict)\n```\n\n----------------------------------------\n\nTITLE: Configuration Setup in FlashRAG\nDESCRIPTION: Demonstrates how to initialize configuration using both YAML files and dictionary inputs with variable precedence.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/basic_usage.md#2025-04-07_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom flashrag.config import Config\n\nconfig_dict = {\"retrieval_method\": \"bge\"}\nconfig = Config('my_config.yaml', config_dict = config_dict)\nprint(config['retrieval_method'])\n```\n\n----------------------------------------\n\nTITLE: Initializing FlashRAG Config with Dictionary in Python\nDESCRIPTION: Demonstrates how to initialize a FlashRAG Config object using a parameter dictionary. This method allows for flexible configuration setup directly in Python code.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/configuration.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom flashrag.config import Config\nconfig_dict = {'generator_model': 'llama2-7B'}\nconfig = Config(config_dict=config_dict)\nmodel_name = config['generator_model']\n```\n\n----------------------------------------\n\nTITLE: Loading FlashRAG Config from YAML File in Python\nDESCRIPTION: Shows how to load a FlashRAG configuration from a YAML file. This method is useful for managing complex configurations externally.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/configuration.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom flashrag.config import Config\nconfig = Config(config_file_path='myconfig.yaml')\n```\n\n----------------------------------------\n\nTITLE: Initializing FlashRAG Pipeline\nDESCRIPTION: Python code for loading configuration and initializing the FlashRAG pipeline.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom flashrag.config import Config\n\n# hybrid load configs\nconfig_dict = {'data_dir': 'dataset/'}\nmy_config = Config(\n    config_file_path = 'my_config.yaml',\n    config_dict = config_dict\n```\n\n----------------------------------------\n\nTITLE: Loading Dataset and Pipeline Components in Python\nDESCRIPTION: Loads the dataset from the configured path and initializes the SequentialPipeline for the Standard RAG process. The pipeline automatically handles loading of retriever and generator components based on the configuration.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/introduction_for_beginners_en.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom flashrag.utils import get_dataset\nfrom flashrag.pipeline import SequentialPipeline\n\nall_split = get_dataset(config)\ntest_data = all_split['test']\npipeline = SequentialPipeline(config)\n```\n\n----------------------------------------\n\nTITLE: Using Multiple Retrievers in Python with FlashRAG\nDESCRIPTION: This Python code snippet demonstrates how to use the multi-retriever feature in FlashRAG. It includes configuration setup, retriever initialization, and performing a batch search with multiple retrievers.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/multi_retriever_usage.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom flashrag.utils import get_retriever\nfrom flashrag.config import Config\n\nconfig_dict = {\n    \"gpu_id\": \"1\",\n    \"use_multi_retriever\": True,\n    \"multi_retriever_setting\": {\n        \"merge_method\": \"rerank\",\n        \"topk\": 5,\n        'rerank_model_name': 'bge-reranker',\n        'rerank_model_path': 'bge-reranker-m3',\n        \"retriever_list\": [\n            {\n                \"retrieval_method\": \"bm25\",\n                \"corpus_path\": \"general_knowledge.jsonl\",\n                \"index_path\": \"indexes/general_knowledge/bm25\",\n                \"retrieval_topk\": 3,\n                \"bm25_backend\": \"pyserini\",\n            },\n            {\n                \"retrieval_method\": \"e5\",\n                \"corpus_path\": \"general_knowledge.jsonl\",\n                \"index_path\": \"indexes/general_knowledge/e5_Flat.index\",\n                \"retrieval_topk\": 1,\n            },\n        ],\n    },\n}\nconfig = Config(\"my_config.yaml\", config_dict=config_dict)\nretriever = get_retriever(config)\nquery_list = ['who is the president of USA?']\n\noutput, score = retriever.batch_search(query_list, return_score=True)\nfor item,s in zip(output, score):\n    print(item, s)\n    print(\"----\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up Complete FlashRAG Pipeline\nDESCRIPTION: Python code showing complete pipeline setup with dataset loading and configuration.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom flashrag.utils import get_dataset\nfrom flashrag.pipeline import SequentialPipeline\nfrom flashrag.prompt import PromptTemplate\nfrom flashrag.config import Config\n\nconfig_dict = {'data_dir': 'dataset/'}\nmy_config = Config(\n    config_file_path = 'my_config.yaml',\n    config_dict = config_dict\n)\nall_split = get_dataset(my_config)\ntest_data = all_split['test']\n\npipeline = SequentialPipeline(my_config)\n```\n\n----------------------------------------\n\nTITLE: Complete FlashRAG Standard RAG Pipeline Implementation in Python\nDESCRIPTION: End-to-end implementation of the RAG process using the FlashRAG framework. Includes configuration, dataset loading, pipeline initialization, and execution with evaluation. The pipeline returns a dataset containing the model's predictions and intermediate results.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/introduction_for_beginners_en.md#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom flashrag.config import Config\nfrom flashrag.utils import get_dataset\nfrom flashrag.pipeline import SequentialPipeline\n\nconfig_dict = { \n                'data_dir': 'dataset/',\n                'index_path': 'indexes/e5_Flat.index',\n                'corpus_path': 'indexes/general_knowledge.jsonl',\n                'model2path': {'e5': <retriever_path>, 'llama2-7B-chat': <generator_path>},\n                'generator_model': 'llama2-7B-chat',\n                'retrieval_method': 'e5',\n                'metrics': ['em','f1','acc'],\n                'retrieval_topk': 1,\n                'save_intermediate_data': True\n            }\n\nconfig = Config(config_dict = config_dict)\n\nall_split = get_dataset(config)\ntest_data = all_split['test']\npipeline = SequentialPipeline(config)\n\noutput_dataset = pipeline.run(test_data,do_eval=True)\nprint(\"---generation output---\")\nprint(output_dataset.pred)\n```\n\n----------------------------------------\n\nTITLE: Configuring Evaluation Settings in YAML for FlashRAG\nDESCRIPTION: This YAML snippet defines evaluation settings for FlashRAG. It specifies which metrics to use for evaluation, allows for custom metric settings, and determines whether to save metric scores. The 'metrics' list includes standard evaluation metrics like EM, F1, accuracy, precision, and recall.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/configuration.md#2025-04-07_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n# Metrics to evaluate the result\nmetrics: ['em','f1','acc','precision','recall'] \n# Specify setting for metric, will be called within certain metrics\nmetric_setting: \n  retrieval_recall_topk: 5\nsave_metric_score: True #　whether to save the metric score into txt file\n```\n\n----------------------------------------\n\nTITLE: Initializing Retriever in FlashRAG\nDESCRIPTION: Creates a retriever instance using the get_retriever utility function which sets up either BM25 or Dense retrieval based on configuration.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/basic_usage.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nretriever = get_retriever(config)\n```\n\n----------------------------------------\n\nTITLE: Initializing Generator in FlashRAG\nDESCRIPTION: Creates a generator instance using the get_generator utility function which loads the appropriate generator model based on configuration.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/basic_usage.md#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ngenerator = get_generator(config)\n```\n\n----------------------------------------\n\nTITLE: Performing Batch Search with FlashRAG Retriever\nDESCRIPTION: Demonstrates how to perform batch search operations with the retriever, showing both score-returning and non-score-returning variants.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/basic_usage.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# if you set `return_scores=True`\nretrieval_results, scores = self.retriever.batch_search(input_query_list, return_scores=True)\n\n# if you set `return_scores=False`\nretrieval_results = self.retriever.batch_search(input_query_list, return_scores=False)\n```\n\n----------------------------------------\n\nTITLE: Building Dense Retrieval Index with Embedding Models\nDESCRIPTION: Command to build a dense retrieval index using embedding models with FAISS. Parameters can be customized for the specific model, corpus location, and indexing options like batch size, pooling method, and precision level.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/building-index.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n    --retrieval_method e5 \\\n    --model_path /model/e5-base-v2/ \\\n    --corpus_path indexes/sample_corpus.jsonl \\\n    --save_dir indexes/ \\\n    --use_fp16 \\\n    --max_length 512 \\\n    --batch_size 256 \\\n    --pooling_method mean \\\n    --faiss_type Flat \n```\n\n----------------------------------------\n\nTITLE: Building Dense Retrieval Index with Sentence Transformers Support\nDESCRIPTION: Command to build a dense retrieval index with models that support the sentence_transformers library. This approach simplifies the process by handling pooling methods automatically.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/building-index.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n    --retrieval_method e5 \\\n    --model_path /model/e5-base-v2/ \\\n    --corpus_path indexes/sample_corpus.jsonl \\\n    --save_dir indexes/ \\\n    --use_fp16 \\\n    --max_length 512 \\\n    --batch_size 256 \\\n    --pooling_method mean \\\n    --sentence_transformer \\\n    --faiss_type Flat \n```\n\n----------------------------------------\n\nTITLE: Building Dense Text Retrieval Index with E5 Model\nDESCRIPTION: Script for building dense retrieval indexes using embedding models like E5 or BGE. Supports various pooling methods and uses FAISS for index construction. Can be configured with FP16 precision and custom batch sizes.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/zh-cn/data_preparation/build-index.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n    --retrieval_method e5 \\\n    --model_path /model/e5-base-v2/ \\\n    --corpus_path indexes/sample_corpus.jsonl \\\n    --save_dir indexes/ \\\n    --use_fp16 \\\n    --max_length 512 \\\n    --batch_size 256 \\\n    --pooling_method mean \\\n    --faiss_type Flat\n```\n\n----------------------------------------\n\nTITLE: Building Dense Text Retrieval Index with Sentence Transformers\nDESCRIPTION: Alternative approach for building dense retrieval indexes using the sentence-transformers library. This method automatically handles pooling and is compatible with models that support the sentence-transformers format.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/zh-cn/data_preparation/build-index.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n    --retrieval_method e5 \\\n    --model_path /model/e5-base-v2/ \\\n    --corpus_path indexes/sample_corpus.jsonl \\\n    --save_dir indexes/ \\\n    --use_fp16 \\\n    --max_length 512 \\\n    --batch_size 256 \\\n    --pooling_method mean \\\n    --sentence_transformer \\\n    --faiss_type Flat\n```\n\n----------------------------------------\n\nTITLE: Building Dense Retrieval Index\nDESCRIPTION: Command for building dense retrieval index using E5 model with configurable parameters.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n  --retrieval_method e5 \\\n  --model_path /model/e5-base-v2/ \\\n  --corpus_path indexes/sample_corpus.jsonl \\\n  --save_dir indexes/ \\\n  --use_fp16 \\\n  --max_length 512 \\\n  --batch_size 256 \\\n  --pooling_method mean \\\n  --faiss_type Flat\n```\n\n----------------------------------------\n\nTITLE: Building BM25 Index with BM25s\nDESCRIPTION: Command for building sparse retrieval index using BM25s backend.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n  --retrieval_method bm25 \\\n  --corpus_path indexes/sample_corpus.jsonl \\\n  --bm25_backend bm25s \\\n  --save_dir indexes/\n```\n\n----------------------------------------\n\nTITLE: Building BM25 Index with Pyserini\nDESCRIPTION: Command for building sparse retrieval index using Pyserini backend.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n  --retrieval_method bm25 \\\n  --corpus_path indexes/sample_corpus.jsonl \\\n  --bm25_backend pyserini \\\n  --save_dir indexes/\n```\n\n----------------------------------------\n\nTITLE: Building BM25 Index with BM25s Backend\nDESCRIPTION: Command to build a sparse retrieval BM25 index using the BM25s backend. This approach doesn't require a model path since it's based on statistical term frequency rather than embeddings.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/building-index.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n    --retrieval_method bm25 \\\n    --corpus_path indexes/sample_corpus.jsonl \\\n    --bm25_backend bm25s \\\n    --save_dir indexes/ \n```\n\n----------------------------------------\n\nTITLE: Building BM25 Index with Pyserini Backend\nDESCRIPTION: Command to build a sparse retrieval BM25 index using the Pyserini backend which creates Lucene inverted indexes. This alternative BM25 implementation might be preferred for certain use cases.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/building-index.md#2025-04-07_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n    --retrieval_method bm25 \\\n    --corpus_path indexes/sample_corpus.jsonl \\\n    --bm25_backend pyserini \\\n    --save_dir indexes/ \n```\n\n----------------------------------------\n\nTITLE: Building BM25 Index with BM25s Backend\nDESCRIPTION: Script for building sparse retrieval indexes using the BM25s backend. This is a lightweight implementation without Java dependencies, suitable for simple deployments.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/zh-cn/data_preparation/build-index.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n    --retrieval_method bm25 \\\n    --corpus_path indexes/sample_corpus.jsonl \\\n    --bm25_backend bm25s \\\n    --save_dir indexes/\n```\n\n----------------------------------------\n\nTITLE: Building BM25 Index with Pyserini Backend\nDESCRIPTION: Script for building sparse retrieval indexes using the Pyserini backend. Requires Java installation but provides better stability and Chinese language support.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/zh-cn/data_preparation/build-index.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n    --retrieval_method bm25 \\\n    --corpus_path indexes/sample_corpus.jsonl \\\n    --bm25_backend pyserini \\\n    --save_dir indexes/\n```\n\n----------------------------------------\n\nTITLE: Configuring SKR Judger in YAML\nDESCRIPTION: YAML configuration for the SKR (Selective Knowledge Retrieval) judger, specifying training data path, embedding model path, and other parameters\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/zh-cn/component/judger.md#2025-04-07_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\njudger_name: skr \njudger_config:\n    training_data_path: FlashRAG/examples/methods/sample_data/skr_training.json  # 填写训练数据路径\n    model_path: model/sup-simcse-bert-base-uncased  # 填写嵌入模型路径\n    topk: 5\n    batch_size: 64\n    max_length: 128  # 填写嵌入模型的最大长度\n```\n\n----------------------------------------\n\nTITLE: Configuring Adaptive Judger in YAML\nDESCRIPTION: YAML configuration for the Adaptive judger, specifying the classification model path and processing parameters\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/zh-cn/component/judger.md#2025-04-07_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\njudger_name: adaptive \njudger_config:\n    model_path: illuminoplanet/adaptive-rag-classifier  # 填写分类模型路径\n    batch_size: 16\n    max_length: 512\n```\n\n----------------------------------------\n\nTITLE: Loading Judger in Python\nDESCRIPTION: Python code to load a judger instance using the configuration file\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/zh-cn/component/judger.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom flashrag.utils import get_judger\nconfig = Config('myconfig.yaml')\njudger = get_judger(config)\n```\n\n----------------------------------------\n\nTITLE: Using Judger for Query Classification\nDESCRIPTION: Example of using the judger to classify a query, demonstrating the judge interface with a list input\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/zh-cn/component/judger.md#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\noutput = judger.judge(['who is the president of the united states?'])\n# 期望输出: [True]\nprint(output)\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Prompt Template\nDESCRIPTION: Example of creating custom prompt template for the FlashRAG pipeline.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nprompt_templete = PromptTemplate(\n    config,\n    system_prompt = \"Answer the question based on the given document. Only give me the answer and do not output any other words.\\nThe following are given documents.\\n\\n{reference}\",\n    user_prompt = \"Question: {question}\\nAnswer:\"\n)\npipeline = SequentialPipeline(\n  my_config,\n  prompt_template = prompt_templete\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Pipeline Class\nDESCRIPTION: Example of creating a custom pipeline class by inheriting from BasicPipeline.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom flashrag.pipeline import BasicPipeline\nfrom flashrag.utils import get_retriever, get_generator\n\nclass ToyPipeline(BasicPipeline):\n  def __init__(self, config, prompt_templete=None):\n    # Load your own components\n    pass\n\n  def run(self, dataset, do_eval=True):\n    # Complete your own process logic\n\n    # get attribute in dataset using `.`\n    input_query = dataset.question\n    ...\n    # use `update_output` to save intermeidate data\n    dataset.update_output(\"pred\",pred_answer_list)\n    dataset = self.evaluate(dataset, do_eval=do_eval)\n    return dataset\n```\n\n----------------------------------------\n\nTITLE: Retrieval Results Structure Example\nDESCRIPTION: Shows the nested list structure of retrieval results returned by the batch_search method.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/basic_usage.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n[\n    [doc1, doc2, ...],  # doc items for query1\n    [doc1, doc2, ....],  # doc items for query2\n    ...\n]\n```\n\n----------------------------------------\n\nTITLE: Basic Text Generation with FlashRAG\nDESCRIPTION: Demonstrates basic text generation using a list of input prompts.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/basic_usage.md#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ninput_list = ['who is taylor swift?', 'who is jack ma?']\nresult = generator.generate(input_list)\n```\n\n----------------------------------------\n\nTITLE: Generation with Token Probabilities\nDESCRIPTION: Shows how to generate text while also obtaining token generation probabilities.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/basic_usage.md#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nresult, scores = generator.generate(input_list, return_scores=True)\n```\n\n----------------------------------------\n\nTITLE: Customized Generation Parameters\nDESCRIPTION: Example of text generation with custom generation parameters like top_p and max_tokens.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/basic_usage.md#2025-04-07_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nresult = generator.generate(input_list, top_p=1.0, max_tokens=32)\n```\n\n----------------------------------------\n\nTITLE: Running FlashRAG Pipeline\nDESCRIPTION: Code for executing the FlashRAG pipeline and obtaining results.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_12\n\nLANGUAGE: python\nCODE:\n```\noutput_dataset = pipeline.run(test_data, do_eval=True)\n```\n\n----------------------------------------\n\nTITLE: Multimodal Document Structure Example\nDESCRIPTION: Example JSON structure for multimodal documents containing both text and image data, used as input for index building.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/zh-cn/data_preparation/build-index.md#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n{\n    'id': str,\n    'text': str,\n    'image': str # image byte stream data\n}\n```\n\n----------------------------------------\n\nTITLE: Building Multimodal CLIP Index\nDESCRIPTION: Script for building multimodal indexes using CLIP models. Supports indexing text and image modalities separately or together, using FAISS for storage.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/zh-cn/data_preparation/build-index.md#2025-04-07_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython -m flashrag.retriever.index_builder \\\n    --retrieval_method jina-clip-v2 \\\n    --model_path model/jina-clip-v2 \\\n    --corpus_path datasets/mathvista/train.parquet \\\n    --save_dir indexes/mathvista \\\n    --max_length 512 \\\n    --batch_size 512 \\\n    --faiss_type Flat \\\n    --index_modal all\n```\n\n----------------------------------------\n\nTITLE: Defining System Prompt for FlashRAG Benchmark\nDESCRIPTION: Defines the system prompt template used across all benchmark experiments. The prompt instructs the model to answer questions based on the provided documents, with placeholders for retrieved document content.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/baseline_details.md#2025-04-07_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nAnswer the question based on the given document. Only give me the answer and do not output any other words. The following are given documents:{retrieval documents}\n```\n\n----------------------------------------\n\nTITLE: Formatting Retrieval Documents for FlashRAG Prompt\nDESCRIPTION: Demonstrates the format used to present retrieved documents within the system prompt. Each document is numbered and includes both title and content.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/baseline_details.md#2025-04-07_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nDoc 1 (Title:{title}) {content} \nDoc 2 (Title:{title}) {content}\n```\n\n----------------------------------------\n\nTITLE: Defining User Prompt for FlashRAG Benchmark\nDESCRIPTION: Defines the user prompt template used across all benchmark experiments. The simple format includes only the question to be answered.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/baseline_details.md#2025-04-07_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\nQuestion:{question}\n```\n\n----------------------------------------\n\nTITLE: Defining Dataset Structure in Python for FlashRAG\nDESCRIPTION: This snippet illustrates the JSON structure used for datasets in FlashRAG. Each dataset is saved as a jsonl file where each line contains a dictionary with fields for id, question, golden_answers, and metadata.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n{\n  'id': str,\n  'question': str,\n  'golden_answers': List[str],\n  'metadata': dict\n}\n```\n\n----------------------------------------\n\nTITLE: Document Corpus Format in JSONL for FlashRAG\nDESCRIPTION: This snippet shows the JSONL format used for retrieval document collections in FlashRAG. Each line represents a document with an ID and contents field, where contents is essential for building the retrieval index.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_16\n\nLANGUAGE: jsonl\nCODE:\n```\n{\"id\":\"0\", \"contents\": \"...\"}\n{\"id\":\"1\", \"contents\": \"...\"}\n```\n\n----------------------------------------\n\nTITLE: Formatting JSONL Corpus Data for FlashRAG\nDESCRIPTION: Example of the required JSONL format for corpus data where each line represents a document with an ID and contents field. This format is necessary before building any index in FlashRAG.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/building-index.md#2025-04-07_snippet_0\n\nLANGUAGE: jsonl\nCODE:\n```\n{\"id\": \"0\", \"contents\": \"contents for building index\"}\n{\"id\": \"1\", \"contents\": \"contents for building index\"}\n```\n\n----------------------------------------\n\nTITLE: Corpus Structure Example\nDESCRIPTION: Example JSONL format for document corpus with ID and contents fields.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_5\n\nLANGUAGE: jsonl\nCODE:\n```\n{\"id\": \"0\", \"contents\": \"...\"}\n{\"id\": \"1\", \"contents\": \"...\"}\n```\n\n----------------------------------------\n\nTITLE: JSONL Document Corpus Input Format\nDESCRIPTION: The expected input format for the document corpus as a JSONL file, where each line represents a document with an ID and contents field. The contents field contains the document in 'title\\ntext' format.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/chunk-doc-corpus(legacy).md#2025-04-07_snippet_0\n\nLANGUAGE: jsonl\nCODE:\n```\n{ \"id\": 0, \"contents\": \"...\" }\n{ \"id\": 1, \"contents\": \"...\" }\n{ \"id\": 2, \"contents\": \"...\" }\n...\n```\n\n----------------------------------------\n\nTITLE: JSONL Document Corpus Output Format\nDESCRIPTION: The resulting output format after chunking, where each chunk has its own ID while maintaining a reference to the original document through doc_id. Each chunk also preserves the document title for context.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/chunk-doc-corpus(legacy).md#2025-04-07_snippet_2\n\nLANGUAGE: jsonl\nCODE:\n```\n{ \"id\": 0, \"doc_id\": 0, \"title\": ..., \"contents\": ... }\n{ \"id\": 1, \"doc_id\": 0, \"title\": ..., \"contents\": ... }\n{ \"id\": 2, \"doc_id\": 0, \"title\": ..., \"contents\": ... }\n...\n```\n\n----------------------------------------\n\nTITLE: Launching FlashRAG Web Interface\nDESCRIPTION: Commands to start the FlashRAG web-based user interface for configuring and experimenting with RAG methods. Requires navigating to the webui directory before launching the Python interface script.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ncd webui\npython interface.py\n```\n\n----------------------------------------\n\nTITLE: Running FlashRAG Experiment on NQ Dataset\nDESCRIPTION: This bash command demonstrates how to run a FlashRAG experiment on the NQ dataset using the 'naive' method. It specifies the test split, dataset name, and GPU IDs to use.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/reproduce_experiment.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython run_exp.py --method_name 'naive' \\\n                  --split 'test' \\\n                  --dataset_name 'nq' \\\n                  --gpu_id '0,1,2,3'\n```\n\n----------------------------------------\n\nTITLE: Downloading Wikipedia XML Dump using wget\nDESCRIPTION: Command to download a Wikipedia XML dump file from archive.org. This example downloads the English Wikipedia dump from December 2018.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/process-wiki.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nwget https://archive.org/download/enwiki-20181220/enwiki-20181220-pages-articles.xml.bz2\n```\n\n----------------------------------------\n\nTITLE: Processing Wiki Dump to JSONL Format\nDESCRIPTION: Python script execution command to convert Wikipedia XML dump to JSONL format. The script allows customization of chunk size, chunking method, and parallel processing through worker threads.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/process-wiki.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd scripts\npython preprocess_wiki.py --dump_path ../enwikinews-20240420-pages-articles.xml.bz2  \\\n                        --save_path ../test_sample.jsonl \\\n                        --chunk_by sentence \\\n                        --chunk_size 512 \\\n                        --num_workers 1\n```\n\n----------------------------------------\n\nTITLE: Running Document Chunking Script in Bash\nDESCRIPTION: Command to execute the Python script for chunking documents. It specifies the input and output paths, the chunking method (sentence-based), and the desired chunk size of 512 units.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/chunk-doc-corpus(legacy).md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd scripts\npython chunk_doc_corpus.py --input_path input.jsonl \\\n                          --output_path output.jsonl \\\n                          --chunk_by sentence \\\n                          --chunk_size 512\n```\n\n----------------------------------------\n\nTITLE: Installing FlashRAG Project and Dependencies with Bash\nDESCRIPTION: Commands for cloning the FlashRAG repository and installing the project dependencies. Users may need to modify the requirements.txt file if they encounter issues with certain packages like vllm, fschat, or pyserini.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/original_docs/introduction_for_beginners_en.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/RUC-NLPIR/FlashRAG.git\ncd FlashRAG\npip install -e .\n```\n\n----------------------------------------\n\nTITLE: Installing FlashRAG from GitHub source\nDESCRIPTION: Commands to clone the FlashRAG repository from GitHub and install it locally. This method requires Python 3.10 or higher.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/RUC-NLPIR/FlashRAG.git\ncd FlashRAG\npip install -e .\n```\n\n----------------------------------------\n\nTITLE: Installing FlashRAG optional dependencies\nDESCRIPTION: Command to install optional dependencies for FlashRAG, including vllm, sentence-transformers, and pyserini. The full command is not provided in the snippet.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install\n```\n\n----------------------------------------\n\nTITLE: Installing FlashRAG Dependencies\nDESCRIPTION: Commands for installing required packages including flashrag-dev, vllm, sentence-transformers, and pyserini.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install flashrag-dev[full]\npip install vllm>=0.4.1\npip install sentence-transformers\npip install pyserini\n```\n\n----------------------------------------\n\nTITLE: Installing FAISS with Conda\nDESCRIPTION: Conda commands for installing FAISS CPU or GPU versions, with version 1.8.0 specified.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# CPU-only version\nconda install -c pytorch faiss-cpu=1.8.0\n\n# GPU(+CPU) version\nconda install -c pytorch -c nvidia faiss-gpu=1.8.0\n```\n\n----------------------------------------\n\nTITLE: Installing FlashRAG via pip\nDESCRIPTION: Command to install the FlashRAG package using pip. This installs the pre-release version of the package.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flashrag-dev --pre\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies List\nDESCRIPTION: A comprehensive list of Python package dependencies required for the FlashRAG project, including version specifications for certain packages. The dependencies cover areas like NLP (nltk, spacy), machine learning (torch, transformers), text processing (jieba), and UI frameworks (streamlit, gradio).\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/requirements.txt#2025-04-07_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ndatasets\nbase58\nnltk\nnumpy\nlangid\nopenai\npeft\nPyYAML\nrank_bm25\nrouge\nspacy\ntiktoken\ntorch\ntqdm\ntransformers>=4.40.0\nbm25s[core]==0.2.0\nfschat\nstreamlit\nchonkie>=0.4.0\ngradio>=5.0.0\nrouge-chinese\njieba\n```\n\n----------------------------------------\n\nTITLE: Citing FlashRAG in BibTeX Format\nDESCRIPTION: This BibTeX entry provides the citation information for the FlashRAG paper. It includes details such as authors, title, journal, volume, year, and arXiv information for properly crediting the toolkit in academic research.\nSOURCE: https://github.com/RUC-NLPIR/FlashRAG/blob/main/docs/en-us/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bibtex\nCODE:\n```\n@article{FlashRAG,\n    author={Jiajie Jin and\n            Yutao Zhu and\n            Xinyu Yang and\n            Chenghao Zhang and\n            Zhicheng Dou},\n    title={FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research},\n    journal={CoRR},\n    volume={abs/2405.13576},\n    year={2024},\n    url={https://arxiv.org/abs/2405.13576},\n    eprinttype={arXiv},\n    eprint={2405.13576}\n}\n```"
  }
]