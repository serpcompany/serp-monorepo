[
  {
    "owner": "langchain-ai",
    "repo": "langchain-mcp-adapters",
    "content": "TITLE: Connecting to MCP Server and Creating an Agent\nDESCRIPTION: Python code that demonstrates connecting to an MCP server using stdio transport, loading MCP tools, and creating a LangGraph React agent with those tools. It uses OpenAI's GPT-4o model as the base for the agent.\nSOURCE: https://github.com/langchain-ai/langchain-mcp-adapters/blob/main/README.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create server parameters for stdio connection\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\n\nfrom langchain_mcp_adapters.tools import load_mcp_tools\nfrom langgraph.prebuilt import create_react_agent\n\nfrom langchain_openai import ChatOpenAI\nmodel = ChatOpenAI(model=\"gpt-4o\")\n\nserver_params = StdioServerParameters(\n    command=\"python\",\n    # Make sure to update to the full absolute path to your math_server.py file\n    args=[\"/path/to/math_server.py\"],\n)\n\nasync with stdio_client(server_params) as (read, write):\n    async with ClientSession(read, write) as session:\n        # Initialize the connection\n        await session.initialize()\n\n        # Get tools\n        tools = await load_mcp_tools(session)\n\n        # Create and run the agent\n        agent = create_react_agent(model, tools)\n        agent_response = await agent.ainvoke({\"messages\": \"what's (3 + 5) x 12?\"})\n```\n\n----------------------------------------\n\nTITLE: Connecting to Multiple MCP Servers\nDESCRIPTION: Python code demonstrating how to connect to multiple MCP servers simultaneously using the MultiServerMCPClient. It connects to both the math and weather servers using different transport types and creates an agent that can use tools from both servers.\nSOURCE: https://github.com/langchain-ai/langchain-mcp-adapters/blob/main/README.md#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langgraph.prebuilt import create_react_agent\n\nfrom langchain_openai import ChatOpenAI\nmodel = ChatOpenAI(model=\"gpt-4o\")\n\nasync with MultiServerMCPClient(\n    {\n        \"math\": {\n            \"command\": \"python\",\n            # Make sure to update to the full absolute path to your math_server.py file\n            \"args\": [\"/path/to/math_server.py\"],\n            \"transport\": \"stdio\",\n        },\n        \"weather\": {\n            # make sure you start your weather server on port 8000\n            \"url\": \"http://localhost:8000/sse\",\n            \"transport\": \"sse\",\n        }\n    }\n) as client:\n    agent = create_react_agent(model, client.get_tools())\n    math_response = await agent.ainvoke({\"messages\": \"what's (3 + 5) x 12?\"})\n    weather_response = await agent.ainvoke({\"messages\": \"what is the weather in nyc?\"})\n```\n\n----------------------------------------\n\nTITLE: Integrating MCP Tools with LangGraph API Server\nDESCRIPTION: Python code showing how to create a graph factory for the LangGraph API server that connects to multiple MCP servers. It uses an async context manager to properly manage the lifecycle of the MCP client connections.\nSOURCE: https://github.com/langchain-ai/langchain-mcp-adapters/blob/main/README.md#2025-04-17_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# graph.py\nfrom contextlib import asynccontextmanager\nfrom langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langgraph.prebuilt import create_react_agent\nfrom langchain_anthropic import ChatAnthropic\n\nmodel = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n\n@asynccontextmanager\nasync def make_graph():\n    async with MultiServerMCPClient(\n        {\n            \"math\": {\n                \"command\": \"python\",\n                # Make sure to update to the full absolute path to your math_server.py file\n                \"args\": [\"/path/to/math_server.py\"],\n                \"transport\": \"stdio\",\n            },\n            \"weather\": {\n                # make sure you start your weather server on port 8000\n                \"url\": \"http://localhost:8000/sse\",\n                \"transport\": \"sse\",\n            }\n        }\n    ) as client:\n        agent = create_react_agent(model, client.get_tools())\n        yield agent\n```\n\n----------------------------------------\n\nTITLE: Creating a Math MCP Server\nDESCRIPTION: Python code to create an MCP server that provides math tools for adding and multiplying numbers. It uses the FastMCP framework to define and expose tools through Model Context Protocol.\nSOURCE: https://github.com/langchain-ai/langchain-mcp-adapters/blob/main/README.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# math_server.py\nfrom mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"Math\")\n\n@mcp.tool()\ndef add(a: int, b: int) -> int:\n    \"\"\"Add two numbers\"\"\"\n    return a + b\n\n@mcp.tool()\ndef multiply(a: int, b: int) -> int:\n    \"\"\"Multiply two numbers\"\"\"\n    return a * b\n\nif __name__ == \"__main__\":\n    mcp.run(transport=\"stdio\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Weather MCP Server\nDESCRIPTION: Python code that defines an MCP server providing a weather tool. This server uses Server-Sent Events (SSE) transport instead of stdio, demonstrating a different connection method.\nSOURCE: https://github.com/langchain-ai/langchain-mcp-adapters/blob/main/README.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# weather_server.py\nfrom typing import List\nfrom mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"Weather\")\n\n@mcp.tool()\nasync def get_weather(location: str) -> str:\n    \"\"\"Get weather for location.\"\"\"\n    return \"It's always sunny in New York\"\n\nif __name__ == \"__main__\":\n    mcp.run(transport=\"sse\")\n```\n\n----------------------------------------\n\nTITLE: Setting up MCP Client and Dependencies\nDESCRIPTION: Commands to install required dependencies and set the OpenAI API key for using LangChain MCP adapters with LangGraph and LangChain.\nSOURCE: https://github.com/langchain-ai/langchain-mcp-adapters/blob/main/README.md#2025-04-17_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install langchain-mcp-adapters langgraph langchain-openai\n\nexport OPENAI_API_KEY=<your_api_key>\n```\n\n----------------------------------------\n\nTITLE: LangGraph API Server Configuration\nDESCRIPTION: JSON configuration file for the LangGraph API server specifying the entrypoint for the graph. This connects the MCP-enabled agent to the LangGraph server infrastructure.\nSOURCE: https://github.com/langchain-ai/langchain-mcp-adapters/blob/main/README.md#2025-04-17_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"agent\": \"./graph.py:make_graph\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running the Weather Server\nDESCRIPTION: Command to start the weather server that will listen for connections using SSE transport.\nSOURCE: https://github.com/langchain-ai/langchain-mcp-adapters/blob/main/README.md#2025-04-17_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython weather_server.py\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain MCP Adapters Package\nDESCRIPTION: Command to install the langchain-mcp-adapters package using pip.\nSOURCE: https://github.com/langchain-ai/langchain-mcp-adapters/blob/main/README.md#2025-04-17_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install langchain-mcp-adapters\n```"
  }
]