[
  {
    "owner": "farama-foundation",
    "repo": "gymnasium-robotics",
    "content": "TITLE: Demonstrating Multi-goal API Usage in Gymnasium Robotics\nDESCRIPTION: This snippet shows how to use the Multi-goal API in a Gymnasium Robotics environment. It demonstrates registering environments, creating an instance, taking a step, and using the exposed functions to compute rewards and termination conditions with different goals.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/content/multi-goal_api.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gymnasium as gym\nimport gymnasium_robotics\n\ngym.register_envs(gymnasium_robotics)\n\nenv = gym.make(\"FetchReach-v3\")\nenv.reset()\nobs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n\n# The following always has to hold:\nassert reward == env.compute_reward(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\nassert truncated == env.compute_truncated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\nassert terminated == env.compute_terminated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\n\n# However goals can also be substituted:\nsubstitute_goal = obs[\"achieved_goal\"].copy()\nsubstitute_reward = env.compute_reward(obs[\"achieved_goal\"], substitute_goal, info)\nsubstitute_terminated = env.compute_terminated(obs[\"achieved_goal\"], substitute_goal, info)\nsubstitute_truncated = env.compute_truncated(obs[\"achieved_goal\"], substitute_goal, info)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Multi-goal API Usage in Gymnasium-Robotics\nDESCRIPTION: Example code showing how to use the Multi-goal API to compute rewards, termination, and truncation conditions with both original and substitute goals. Demonstrates the GoalEnv class functionality with dictionary observation space containing observation, desired_goal, and achieved_goal.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gymnasium as gym\n\nenv = gym.make(\"FetchReach-v3\")\nenv.reset()\nobs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n\n# The following always has to hold:\nassert reward == env.compute_reward(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\nassert truncated == env.compute_truncated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\nassert terminated == env.compute_terminated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\n\n# However goals can also be substituted:\nsubstitute_goal = obs[\"achieved_goal\"].copy()\nsubstitute_reward = env.compute_reward(obs[\"achieved_goal\"], substitute_goal, info)\nsubstitute_terminated = env.compute_terminated(obs[\"achieved_goal\"], substitute_goal, info)\nsubstitute_truncated = env.compute_truncated(obs[\"achieved_goal\"], substitute_goal, info)\n```\n\n----------------------------------------\n\nTITLE: Basic Gymnasium-Robotics Environment Usage\nDESCRIPTION: Demonstrates how to create and interact with a Gymnasium-Robotics environment using the Gymnasium API. Shows environment initialization, action loop, and proper cleanup.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/index.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gymnasium as gym\nimport gymnasium_robotics\n\ngym.register_envs(gymnasium_robotics)\n\nenv = gym.make(\"FetchPickAndPlace-v3\", render_mode=\"human\")\nobservation, info = env.reset(seed=42)\nfor _ in range(1000):\n   action = policy(observation)  # User-defined policy function\n   observation, reward, terminated, truncated, info = env.step(action)\n\n   if terminated or truncated:\n      observation, info = env.reset()\nenv.close()\n```\n\n----------------------------------------\n\nTITLE: Instantiating Shadow Hand Environment with Touch Sensors in Python\nDESCRIPTION: Example code showing how to import gymnasium and gymnasium_robotics modules, register environments, and create a HandManipulateEgg environment with Boolean touch sensors. This demonstrates the proper way to instantiate touch-enabled variants of the Shadow Hand environments.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/shadow_dexterous_hand/index.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gymnasium as gym\nimport gymnasium_robotics\n\ngym.register_envs(gymnasium_robotics)\n\nenv = gym.make('HandManipulateEgg_BooleanTouchSensors-v1')\n```\n\n----------------------------------------\n\nTITLE: Initializing Franka Kitchen Environment with Specific Tasks in Python\nDESCRIPTION: This code snippet demonstrates how to register and initialize the Franka Kitchen environment with specific tasks to complete. The example shows how to select the 'microwave' and 'kettle' tasks when creating the environment.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/franka_kitchen/index.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gymnasium as gym\nimport gymnasium_robotics\n\ngym.register_envs(gymnasium_robotics)\n\nenv = gym.make('FrankaKitchen-v1', tasks_to_complete=['microwave', 'kettle'])\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Agent Factorization for Ant-v5 Environment\nDESCRIPTION: Example demonstrating how to create a custom '8x1' agent factorization for the Ant-v5 environment, where each agent controls a single joint/action.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/index.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> from gymnasium_robotics.mamujoco_v1 import get_parts_and_edges\n>>> unpartioned_nodes, edges, global_nodes = get_parts_and_edges('Ant-v5', None)\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> unpartioned_nodes\n[(hip1, ankle1, hip2, ankle2, hip3, ankle3, hip4, ankle4)]\n>>> partioned_nodes = [(unpartioned_nodes[0][0],), (unpartioned_nodes[0][1],), (unpartioned_nodes[0][2],), (unpartioned_nodes[0][3],), (unpartioned_nodes[0][4],), (unpartioned_nodes[0][5],), (unpartioned_nodes[0][6],), (unpartioned_nodes[0][7],)]\n>>> partioned_nodes\n[(hip1,), (ankle1,), (hip2,), (ankle2,), (hip3,), (ankle3,), (hip4,), (ankle4,)]\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> my_agent_factorization = {\"partition\": partioned_nodes, \"edges\": edges, \"globals\": global_nodes}\n>>> gym_env = mamujoco_v1('Ant', '8x1', agent_factorization=my_agent_factorization)\n```\n\n----------------------------------------\n\nTITLE: Initializing Default Ant Environment in MaMuJoCo\nDESCRIPTION: Code snippet showing how to initialize the default Ant environment with a single agent that controls all eight joints (both hip and ankle joints for all four legs).\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_ant.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"Ant\", None)\n```\n\n----------------------------------------\n\nTITLE: Initializing 4x2 Partitioned Ant Environment in MaMuJoCo\nDESCRIPTION: Code snippet showing how to initialize the Ant environment with a '4x2' partitioning scheme where the ant is split into four agents - each controlling a single leg of the ant.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_ant.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"Ant\", \"4x2\")\n```\n\n----------------------------------------\n\nTITLE: Initializing 2x4 Partitioned Ant Environment in MaMuJoCo\nDESCRIPTION: Code snippet showing how to initialize the Ant environment with a '2x4' partitioning scheme where the ant is split into two agents - one controlling the front legs and the other controlling the back legs.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_ant.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"Ant\", \"2x4\")\n```\n\n----------------------------------------\n\nTITLE: Instantiating Coupled Half Cheetah Environment with 1p1 Partitioning in Python\nDESCRIPTION: This code snippet demonstrates how to instantiate the Coupled Half Cheetah environment with 1p1 partitioning, creating two separate agents, each controlling one cheetah.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_coupled_half_cheetah.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"CoupledHalfCheetah\", \"1p1\")\n```\n\n----------------------------------------\n\nTITLE: Complex Custom Factorization for Boston Dynamics Spot Arm\nDESCRIPTION: Example showing how to create a custom 'quadruped|arm' factorization for a Boston Dynamics Spot robot with arm, splitting control between locomotion and manipulation components.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/index.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom gymnasium_robotics import mamujoco_v1\nfrom gymnasium_robotics.envs.multiagent_mujoco.obsk import Node, HyperEdge\n\n# Define the factorization graph\nfreejoint = Node(\n    \"freejoint\",\n    None,\n    None,\n    None,\n    extra_obs={\n        \"qpos\": lambda data: data.qpos[2:7],\n        \"qvel\": lambda data: data.qvel[:6],\n    },\n)\nfl_hx = Node(\"fl_hx\", -19, -19, 0)\nfl_hy = Node(\"fl_hy\", -18, -18, 1)\nfl_kn = Node(\"fl_kn\", -17, -17, 2)\nfr_hx = Node(\"fr_hx\", -16, -16, 3)\nfr_hy = Node(\"fr_hy\", -15, -15, 4)\nfr_kn = Node(\"fr_kn\", -14, -14, 5)\nhl_hx = Node(\"hl_hx\", -13, -13, 6)\nhl_hy = Node(\"hl_hy\", -12, -12, 7)\nhl_kn = Node(\"hl_kn\", -11, -11, 8)\nhr_hx = Node(\"hr_hx\", -10, -10, 9)\nhr_hy = Node(\"hr_hy\", -9, -9, 10)\nhr_kn = Node(\"hr_kn\", -8, -8, 11)\narm_sh0 = Node(\"arm_sh0\", -7, -7, 12)\narm_sh1 = Node(\"arm_sh1\", -6, -6, 13)\narm_el0 = Node(\"arm_el0\", -5, -5, 14)\narm_el1 = Node(\"arm_el1\", -4, -4, 15)\narm_wr0 = Node(\"arm_wr0\", -3, -3, 16)\narm_wr1 = Node(\"arm_wr1\", -2, -2, 17)\narm_f1x = Node(\"arm_f1x\", -1, -1, 18)\n\nparts = [\n    (  # Locomoting Quadruped Component\n        fl_hx,\n        fl_hy,\n        fl_kn,\n        fr_hx,\n        fr_hy,\n        fr_kn,\n        hl_hx,\n        hl_hy,\n        hl_kn,\n        hr_hx,\n        hr_hy,\n        hr_kn,\n    ),\n    (  # Arm Manipulator Component\n        arm_sh0,\n        arm_sh1,\n        arm_el0,\n        arm_el1,\n        arm_wr0,\n        arm_wr1,\n        arm_f1x,\n    ),\n]\n\nedges = [\n    HyperEdge(fl_hx, fl_hy, fl_kn),\n    HyperEdge(fr_hx, fr_hy, fr_kn),\n    HyperEdge(hl_hx, hl_hy, hl_kn),\n    HyperEdge(hr_hx, hr_hy, hr_kn),\n    HyperEdge(  # Main \"body\" connections\n        fl_hx,\n        fl_hy,\n        fr_hx,\n        fr_hy,\n        hl_hx,\n        hl_hy,\n        hr_hx,\n        hr_hy,\n        arm_sh0,\n        arm_sh1,\n    ),\n    HyperEdge(arm_sh0, arm_sh1, arm_el0, arm_el1),\n    HyperEdge(arm_el0, arm_el1, arm_wr0, arm_wr1),\n    HyperEdge(arm_wr0, arm_wr1, arm_f1x),\n]\n\nglobal_nodes = [freejoint]\n\nmy_agent_factorization = {\"partition\": parts, \"edges\": edges, \"globals\": global_nodes}\nenv = mamujoco_v1.parallel_env(\n    \"Ant\",\n    \"quadruped|arm\",\n    agent_factorization=my_agent_factorization,\n    xml_file=\"./mujoco_menagerie/boston_dynamics_spot/scene_arm.xml\",\n)\n```\n\n----------------------------------------\n\nTITLE: Instantiating Coupled Half Cheetah Environment with No Partitioning in Python\nDESCRIPTION: This code snippet shows how to instantiate the Coupled Half Cheetah environment with no partitioning, resulting in a single agent controlling both cheetahs.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_coupled_half_cheetah.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"CoupledHalfCheetah\", None)\n```\n\n----------------------------------------\n\nTITLE: Initializing Half Cheetah Environment with 2x3 Partitioning in Python\nDESCRIPTION: This code snippet demonstrates how to create the Half Cheetah environment with a 2x3 partitioning, dividing control between front and back legs.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_half_cheetah.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"HalfCheetah\", \"2x3\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Pusher Environment without Partitioning in Python\nDESCRIPTION: This code snippet shows how to instantiate the Pusher environment without partitioning. It creates a single agent with a 7-dimensional action space.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_pusher.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"Pusher\", None)\n```\n\n----------------------------------------\n\nTITLE: Initializing Multi-Agent Humanoid Environment (9|8 Partition)\nDESCRIPTION: Creates a two-agent Humanoid environment where one agent controls the upper body (9 dimensions) and another controls the lower body (8 dimensions).\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_humanoid.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"Humanoid\", \"3x1\")\n```\n\n----------------------------------------\n\nTITLE: Initializing 2x4d Diagonal Partitioned Ant Environment in MaMuJoCo\nDESCRIPTION: Code snippet showing how to initialize the Ant environment with a '2x4d' partitioning scheme where the ant is split diagonally into two agents - each controlling a pair of diagonal legs.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_ant.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"Ant\", \"2x4d\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Multi-Agent Reacher Environment\nDESCRIPTION: Code to instantiate a partitioned (2x1) Reacher environment with two agents, each controlling one joint of the reacher arm.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_reacher.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"Reacher\", \"2x1\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Half Cheetah Environment with No Partitioning in Python\nDESCRIPTION: This code snippet shows how to instantiate the Half Cheetah environment without partitioning, resulting in a single agent controlling all joints.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_half_cheetah.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"HalfCheetah\", None)\n```\n\n----------------------------------------\n\nTITLE: Initializing Pusher Environment with 3-Part Partitioning in Python\nDESCRIPTION: This code snippet demonstrates how to instantiate the Pusher environment with 3-part partitioning. It creates three agents with different action spaces corresponding to the shoulder, elbow, and wrist.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_pusher.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"Pusher\", \"3p\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Half Cheetah Environment with 6x1 Partitioning in Python\nDESCRIPTION: This code snippet shows how to instantiate the Half Cheetah environment with a 6x1 partitioning, where each joint is controlled by a separate agent.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_half_cheetah.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"HalfCheetah\", \"6x1\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Partitioned Humanoid Environment\nDESCRIPTION: Code example showing how to instantiate the Humanoid Standup environment with a 9|8 partitioning scheme that splits control between upper and lower body across two agents.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_humanoid_standup.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"HumanoidStandup\", \"3x1\")\n```\n\n----------------------------------------\n\nTITLE: Instantiating ManySegmentSwimmer Environment\nDESCRIPTION: Code example showing how to create a ManySegmentSwimmer environment instance with configurable number of agents and segments per agent.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_multiagentswimmer.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"ManySegmentSwimmer\", ${Number Of Agents}x${Number Of Segments per Agent})\n```\n\n----------------------------------------\n\nTITLE: Initializing Single Agent Humanoid Environment\nDESCRIPTION: Code example showing how to instantiate the Humanoid Standup environment with no partitioning, resulting in a single agent controlling all 17 joints.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_humanoid_standup.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"HumanoidStandup\", None)\n```\n\n----------------------------------------\n\nTITLE: Initializing Single-Agent Reacher Environment\nDESCRIPTION: Code to instantiate a single-agent Reacher environment with no partitioning, maintaining the original Gymnasium MuJoCo/Reacher action space configuration.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_reacher.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"Reacher\", None)\n```\n\n----------------------------------------\n\nTITLE: Initializing Single-Agent Humanoid Environment\nDESCRIPTION: Creates a single-agent Humanoid environment with a 17-dimensional action space controlling all body parts.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_humanoid.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nenv = mamujoco_v1.parallel_env(\"Humanoid\", None)\n```\n\n----------------------------------------\n\nTITLE: Instantiating MaMuJoCo Single Action Environments in Python\nDESCRIPTION: Demonstrates how to create instances of InvertedDoublePendulum and InvertedPendulum environments using MaMuJoCo. These environments are initialized without a partition, resulting in single-agent environments using PettingZoo APIs.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_single.md#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nenv = mamujoco_v0.parallel_env(\"InvertedDoublePendulum\", None)\n```\n\nLANGUAGE: Python\nCODE:\n```\nenv = mamujoco_v0.parallel_env(\"InvertedPendulum\", None)\n```\n\n----------------------------------------\n\nTITLE: Mapping Functions in MaMuJoCo Framework\nDESCRIPTION: This section displays the core mapping functions provided by the MaMuJoCo framework, which allow conversion between global and local actions/observations.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/index.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n.. autofunction:: gymnasium_robotics.mamujoco_v1.parallel_env.map_local_actions_to_global_action\n```\n\nLANGUAGE: python\nCODE:\n```\n.. autofunction:: gymnasium_robotics.mamujoco_v1.parallel_env.map_global_action_to_local_actions\n```\n\nLANGUAGE: python\nCODE:\n```\n.. autofunction:: gymnasium_robotics.mamujoco_v1.parallel_env.map_global_state_to_local_observations\n```\n\nLANGUAGE: python\nCODE:\n```\n.. autofunction:: gymnasium_robotics.mamujoco_v1.parallel_env.map_local_observations_to_global_state\n```\n\nLANGUAGE: python\nCODE:\n```\n.. autofunction:: gymnasium_robotics.mamujoco_v1.get_parts_and_edges\n```\n\n----------------------------------------\n\nTITLE: Environment Initialization in MaMuJoCo\nDESCRIPTION: Documentation for the initialization function of MaMuJoCo parallel environments, showing the available parameters and options.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/index.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n.. autofunction:: gymnasium_robotics.mamujoco_v1.parallel_env.__init__\n```\n\n----------------------------------------\n\nTITLE: Installing Gymnasium-Robotics Package via pip\nDESCRIPTION: Command to install the main Gymnasium-Robotics package using pip package manager. This installs the latest version with modern MuJoCo bindings.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/content/installation.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install gymnasium-robotics\n```\n\n----------------------------------------\n\nTITLE: Installing Legacy Gymnasium-Robotics with mujoco-py\nDESCRIPTION: Command to install Gymnasium-Robotics with legacy mujoco-py dependency for compatibility with older versions of the environments.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/content/installation.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install gymnasium-robotics[mujoco-py]\n```\n\n----------------------------------------\n\nTITLE: Observation Categories Configuration in Gymnasium Robotics\nDESCRIPTION: Defines the default local and global observation categories for the multi-agent Humanoid environment, including position, velocity, inertia, external forces, and actuator forces.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/MaMuJoCo/ma_humanoid_standup.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n[\"qpos\", \"qvel\", \"cinert\", \"cvel\", \"qfrc_actuator\", \"cfrc_ext\"], [\"qpos\"]]\n```\n\nLANGUAGE: markdown\nCODE:\n```\n(\"qpos\", \"qvel\", \"cinert\", \"cvel\", \"qfrc_actuator\", \"cfrc_ext\")\n```\n\nLANGUAGE: markdown\nCODE:\n```\n\"qpos\", \"qvel\", \"cinert\", \"cvel\", \"qfrc_actuator\", \"cfrc_ext\"\n```\n\n----------------------------------------\n\nTITLE: Citation for Shadow Hand Touch Sensor Environments in BibTeX Format\nDESCRIPTION: BibTeX citation information for the paper by Melnik et al. that introduced touch-enabled variants of the Shadow Hand environments. This citation should be used when referencing the touch sensor variants in academic work.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/shadow_dexterous_hand/index.md#2025-04-23_snippet_2\n\nLANGUAGE: bibtex\nCODE:\n```\n@article{melnik2021using,\n  title={Using tactile sensing to improve the sample efficiency and performance of deep deterministic policy gradients for simulated in-hand manipulation tasks},\n  author={Melnik, Andrew and Lach, Luca and Plappert, Matthias and Korthals, Timo and Haschke, Robert and Ritter, Helge},\n  journal={Frontiers in Robotics and AI},\n  pages={57},\n  year={2021},\n  publisher={Frontiers}\n}\n```\n\n----------------------------------------\n\nTITLE: Citation for Shadow Hand Environments in BibTeX Format\nDESCRIPTION: BibTeX citation information for the original Shadow Hand environments paper by Plappert et al. This citation should be used when referencing the base Shadow Hand environments in academic work.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/shadow_dexterous_hand/index.md#2025-04-23_snippet_1\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{1802.09464,\n  Author = {Matthias Plappert and Marcin Andrychowicz and Alex Ray and Bob McGrew and Bowen Baker and Glenn Powell and Jonas Schneider and Josh Tobin and Maciek Chociej and Peter Welinder and Vikash Kumar and Wojciech Zaremba},\n  Title = {Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research},\n  Year = {2018},\n  Eprint = {arXiv:1802.09464},\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Documentation\nDESCRIPTION: Commands to install the required packages for building the Gymnasium-Robotics documentation, including the requirements specified in requirements.txt and Gym itself.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\npip install gym\n```\n\n----------------------------------------\n\nTITLE: Building Documentation Once\nDESCRIPTION: Commands to build the documentation one time using the make utility with the dirhtml target, which generates the output in directory HTML format.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nmake dirhtml\n```\n\n----------------------------------------\n\nTITLE: Rebuilding Documentation Automatically\nDESCRIPTION: Commands to set up automatic rebuilding of documentation whenever changes are detected using sphinx-autobuild, which runs a local server that watches for file changes.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nsphinx-autobuild -b dirhtml . _build\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Structure with Sphinx Toctree\nDESCRIPTION: Multiple toctree directives organizing documentation sections for Introduction, Environments, and Development. Sets up navigation hierarchy and page organization.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/index.md#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:hidden:\n:titlesonly:\n:caption: Introduction\ncontent/installation\ncontent/multi-goal_api\n```\n\nLANGUAGE: rst\nCODE:\n```\n:hidden:\n:caption: Environments\nenvs/fetch/index\nenvs/shadow_dexterous_hand/index\nenvs/maze/index\nenvs/adroit_hand/index\nenvs/franka_kitchen/index\nenvs/MaMuJoCo/index\n```\n\nLANGUAGE: rst\nCODE:\n```\n:hidden:\n:caption: Development\n\nGithub <https://github.com/Farama-Foundation/Gymnasium-Robotics>\nrelease_notes/index\n```\n\n----------------------------------------\n\nTITLE: Citation for Fetch Environments in BibTeX\nDESCRIPTION: BibTeX entry for citing the paper 'Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research' when using Fetch environments.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/fetch/index.md#2025-04-23_snippet_0\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{1802.09464,\n  Author = {Matthias Plappert and Marcin Andrychowicz and Alex Ray and Bob McGrew and Bowen Baker and Glenn Powell and Jonas Schneider and Josh Tobin and Maciek Chociej and Peter Welinder and Vikash Kumar and Wojciech Zaremba},\n  Title = {Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research},\n  Year = {2018},\n  Eprint = {arXiv:1802.09464},\n}\n```\n\n----------------------------------------\n\nTITLE: Citation Reference for Adroit Hand Paper\nDESCRIPTION: BibTeX citation for the original paper 'Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations' that introduced these environments.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/adroit_hand/index.md#2025-04-23_snippet_0\n\nLANGUAGE: bibtex\nCODE:\n```\n@article{rajeswaran2017learning,\n  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},\n  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},\n  journal={arXiv preprint arXiv:1709.10087},\n  year={2017}\n}\n```\n\n----------------------------------------\n\nTITLE: Citation Format for Relay Policy Learning Paper\nDESCRIPTION: BibTeX citation format for the original paper introducing these environments: 'Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning' by Gupta et al.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/franka_kitchen/index.md#2025-04-23_snippet_1\n\nLANGUAGE: bibtex\nCODE:\n```\n@article{gupta2019relay,\n  title={Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning},\n  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},\n  journal={arXiv preprint arXiv:1910.11956},\n  year={2019}\n}\n```\n\n----------------------------------------\n\nTITLE: Citation Format for D4RL Paper\nDESCRIPTION: BibTeX citation format for the paper that modified these environments: 'D4RL: Datasets for Deep Data-Driven Reinforcement Learning' by Fu et al.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/franka_kitchen/index.md#2025-04-23_snippet_2\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{fu2020d4rl,\n    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},\n    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},\n    year={2020},\n    eprint={2004.07219},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}\n```\n\n----------------------------------------\n\nTITLE: Citing D4RL Maze Environments in BibTeX Format\nDESCRIPTION: BibTeX citation for the paper \"D4RL: Datasets for Deep Data-Driven Reinforcement Learning\" that introduced the maze environments. This citation should be used when referencing these environments in academic work.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/envs/maze/index.md#2025-04-23_snippet_0\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{fu2020d4rl,\n    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},\n    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},\n    year={2020},\n    eprint={2004.07219},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Changelog Generation with RST Directive for Gymnasium-Robotics\nDESCRIPTION: This code snippet configures the automatic generation of release notes using an RST directive. It specifies GitHub repository releases and PyPI package links as sources for the changelog information.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/release_notes/index.md#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. changelog::\n    :github: https://github.com/Farama-Foundation/Gymnasium-Robotics/releases\n    :pypi: https://pypi.org/project/gymnasium-robotics/\n    :changelog-url:\n```\n\n----------------------------------------\n\nTITLE: Generating Release Notes using eval-rst Directive in reStructuredText\nDESCRIPTION: This code snippet uses the eval-rst directive to generate release notes for the Gymnasium-Robotics project. It pulls information from GitHub releases and PyPI versions to create an automated changelog.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/release_notes.md#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. changelog::\n    :github: https://github.com/Farama-Foundation/Gymnasium-Robotics/releases\n    :pypi: https://pypi.org/project/gymnasium-robotics/\n    :changelog-url:\n```\n\n----------------------------------------\n\nTITLE: Listing Documentation Dependencies for Gymnasium Robotics\nDESCRIPTION: A requirements file that lists the Python packages needed to build the documentation for the Gymnasium Robotics project. It includes documentation generators, parsers, themes, and utilities.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/docs/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nsphinx\nmyst-parser\ngit+https://github.com/Farama-Foundation/Celshast#egg=furo\ntqdm\nsphinx_github_changelog\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Terms and Conditions\nDESCRIPTION: Full text of the Apache License 2.0 that governs the usage, reproduction, and distribution of the ShadowHand robot model implementation.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/gymnasium_robotics/envs/assets/LICENSE.md#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity...[truncated for brevity]\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Boilerplate Notice Template\nDESCRIPTION: A template for the copyright notice that should be included in projects using the Apache License 2.0. The template includes placeholders for copyright year and owner information.\nSOURCE: https://github.com/farama-foundation/gymnasium-robotics/blob/main/gymnasium_robotics/envs/assets/kitchen_franka/franka_assets/LICENSE.md#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n```"
  }
]