[
  {
    "owner": "groq",
    "repo": "groq-api-cookbook",
    "content": "TITLE: Implementing Chat Interface\nDESCRIPTION: Main chat loop implementation allowing users to interact with the mixture of agents system with streaming responses.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/mixture-of-agents/mixture_of_agents.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nwhile True:\n    inp = input(\"\\nAsk a question: \")\n    print(f\"\\nUser: {inp}\")\n    if inp.lower() == \"quit\":\n        print(\"\\nStopped by User\\n\")\n        break\n    stream = chat_stream(inp)\n    print(f\"AI: \", end=\"\")\n    for chunk in stream:\n        print(chunk, end=\"\", flush=True)\n```\n\n----------------------------------------\n\nTITLE: Using Groq API for Function Calling with Verified SQL Queries in Python\nDESCRIPTION: This function utilizes Groq API's Tool Use functionality to select and execute an appropriate verified SQL query based on a user's question. It prepares the query description mapping, sends it to the LLM, and executes the selected query using the previous function.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-sql/json-mode-function-calling-for-sql.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef call_verified_sql(user_question,verified_queries_dict,model):\n    \n    #Simplify verified_queries_dict to just show query name and description\n    query_description_mapping = {key: subdict['description'] for key, subdict in verified_queries_dict.items()}\n    \n    # Step 1: send the conversation and available functions to the model\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": '''You are a function calling LLM that uses the data extracted from the execute_duckdb_query_function_calling function to answer questions around a DuckDB dataset.\n    \n            Extract the query_name parameter from this mapping by finding the one whose description best matches the user's question: \n            {query_description_mapping}\n            '''.format(query_description_mapping=query_description_mapping)\n        },\n        {\n            \"role\": \"user\",\n            \"content\": user_question,\n        }\n    ]\n    tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"execute_duckdb_query_function_calling\",\n                \"description\": \"Executes a verified DuckDB SQL Query\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"query_name\": {\n                            \"type\": \"string\",\n                            \"description\": \"The name of the verified query (i.e. 'most-recent-purchases')\",\n                        }\n                    },\n                    \"required\": [\"query_name\"],\n                },\n            },\n        }\n    ]\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        tools=tools,\n        tool_choice=\"auto\",  \n        max_tokens=4096\n    )\n    \n    response_message = response.choices[0].message\n    tool_calls = response_message.tool_calls\n    \n    available_functions = {\n        \"execute_duckdb_query_function_calling\": execute_duckdb_query_function_calling,\n    }\n    for tool_call in tool_calls:\n        function_name = tool_call.function.name\n        function_to_call = available_functions[function_name]\n        function_args = json.loads(tool_call.function.arguments)\n        print('Query found: ',function_args.get(\"query_name\"))\n        function_response = function_to_call(\n            query_name=function_args.get(\"query_name\"),\n            verified_queries_dict=verified_queries_dict\n        )\n    \n    return function_response\n```\n\n----------------------------------------\n\nTITLE: Implementing Parallel Tool Use with Groq API in Python\nDESCRIPTION: This code showcases parallel tool use where the LLM makes multiple function calls that don't depend on each other in a single chat request. It processes a user prompt to get prices for multiple products, handles multiple tool calls, executes each function with the provided parameters, and then sends all results back to the LLM.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt = \"Please get the price for the Laptop and Microphone\"\nmessages = [\n    {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n    {\n        \"role\": \"user\",\n        \"content\": user_prompt,\n    },\n]\n\n# Step 1: send the conversation and available functions to the model\nresponse = client.chat.completions.create(\n    model=MODEL, messages=messages, tools=tools, tool_choice=\"auto\", max_tokens=4096\n)\n\nresponse_message = response.choices[0].message\ntool_calls = response_message.tool_calls\nprint(\"First LLM Call (Tool Use) Response:\", response_message)\n# Step 2: check if the model wanted to call a function\nif tool_calls:\n    # Step 3: call the function and append the tool call to our list of messages\n    available_functions = {\n        \"get_product_price\": get_product_price,\n    }  # only one function in this example, but you can have multiple\n    messages.append(\n        {\n            \"role\": \"assistant\",\n            \"tool_calls\": [\n                {\n                    \"id\": tool_call.id,\n                    \"function\": {\n                        \"name\": tool_call.function.name,\n                        \"arguments\": tool_call.function.arguments,\n                    },\n                    \"type\": tool_call.type,\n                }\n                for tool_call in tool_calls\n            ],\n        }\n    )\n    # Step 4: send the info for each function call and function response to the model\n    # Iterate over all tool calls\n    for tool_call in tool_calls:\n        function_name = tool_call.function.name\n        function_to_call = available_functions[function_name]\n        function_args = json.loads(tool_call.function.arguments)\n        function_response = function_to_call(\n            product_name=function_args.get(\"product_name\")\n        )\n        messages.append(\n            {\n                \"tool_call_id\": tool_call.id,\n                \"role\": \"tool\",\n                \"name\": function_name,\n                \"content\": function_response,\n            }\n        )  # extend conversation with function response\n    second_response = client.chat.completions.create(\n        model=MODEL, messages=messages\n    )  # get a new response from the model where it can see the function response\n    print(\"\\n\\nSecond LLM Call Response:\", second_response.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Invoking Financial Assistant with Sample User Queries in Python\nDESCRIPTION: Example code showing how to use the financial assistant system with specific user queries. The first example retrieves beta information for Meta stock, while the second example compares stock prices of Google, Apple, and Meta over the past 6 months.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama3-stock-market-function-calling/llama3-stock-market-function-calling.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt = 'What is the beta for meta stock?'\ncall_functions(llm_with_tools, user_prompt)\n```\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt = \"Compare the stock price of Google, Apple and Meta over the past 6 months\"\ncall_functions(llm_with_tools, user_prompt)\n```\n\n----------------------------------------\n\nTITLE: Integrating Llama 3.2 Vision with Function Calling\nDESCRIPTION: Implements a function that utilizes Llama 3.2 Vision to identify dog breeds from images and then calls the dog facts retrieval function. This demonstrates the complete pipeline from image input to structured data output.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Function to call the LLaMA Vision Tool\ndef llama_vision_tool_call(client, model, base64_image, available_functions):\n\n    chat_completion = client.chat.completions.create(\n        # The user message containing the image\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\n                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"  # Decode the base64 image\n                        },\n                    },\n                ],\n            }\n        ],\n        model=model,\n        tools=tools, # The tools to be used\n        tool_choice=\"auto\" # Automatically choose the tool\n    )\n\n    response_message = chat_completion.choices[0].message\n\n    # Get the tool calls from the response message\n    tool_calls = response_message.tool_calls\n\n    # Call each available function\n    for tool_call in tool_calls:\n        # Get the function name from the tool call\n        function_name = tool_call.function.name\n\n        # Get the function to call from the available functions dictionary\n        function_to_call = available_functions[function_name]\n\n        # Parse the function arguments from the tool call\n        function_args = json.loads(tool_call.function.arguments)\n\n        # Call the function with the breed name\n        function_response = function_to_call(\n            breed_name=function_args.get(\"breed_name\")\n        )\n\n    # Return the response from the called function\n    return function_response\n```\n\n----------------------------------------\n\nTITLE: Defining Crew AI Agents for MLB Editorial System\nDESCRIPTION: Creates specialized agents for the MLB Editorial Crew including a researcher, statistician, multiple writers using different LLMs, and an editor. Each agent has a defined role, goal, and the appropriate tools or language models to perform their tasks within the Mixture of Agents framework.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmlb_researcher = Agent(\n    llm=llm_llama70b,\n    role=\"MLB Researcher\",\n    goal=\"Identify and return info for the MLB game related to the user prompt by returning the exact results of the get_game_info tool\",\n    backstory=\"An MLB researcher that identifies games for statisticians to analyze stats from\",\n    tools=[get_game_info],\n    verbose=True,\n    allow_delegation=False\n)\n\nmlb_statistician = Agent(\n    llm=llm_llama70b,\n    role=\"MLB Statistician\",\n    goal=\"Retrieve player batting and pitching stats for the game identified by the MLB Researcher\",\n    backstory=\"An MLB Statistician analyzing player boxscore stats for the relevant game\",\n    tools=[get_batting_stats, get_pitching_stats],\n    verbose=True,\n    allow_delegation=False\n)\n\nmlb_writer_llama = Agent(\n    llm=llm_llama8b,\n    role=\"MLB Writer\",\n    goal=\"Write a detailed game recap article using the provided game information and stats\",\n    backstory=\"An experienced and honest writer who does not make things up\",\n    tools=[],  # The writer does not need additional tools\n    verbose=True,\n    allow_delegation=False\n)\n\nmlb_writer_gemma = Agent(\n    llm=llm_gemma2,\n    role=\"MLB Writer\",\n    goal=\"Write a detailed game recap article using the provided game information and stats\",\n    backstory=\"An experienced and honest writer who does not make things up\",\n    tools=[],  # The writer does not need additional tools\n    verbose=True,\n    allow_delegation=False\n)\n\nmlb_writer_mixtral = Agent(\n    llm=llm_mixtral,\n    role=\"MLB Writer\",\n    goal=\"Write a detailed game recap article using the provided game information and stats\",\n    backstory=\"An experienced and honest writer who does not make things up\",\n    tools=[],  # The writer does not need additional tools\n    verbose=True,\n    allow_delegation=False\n)\n\nmlb_editor = Agent(\n    llm=llm_llama70b,\n    role=\"MLB Editor\",\n    goal=\"Edit multiple game recap articles to create the best final product.\",\n    backstory=\"An experienced editor that excels at taking the best parts of multiple texts to create the best final product\",\n    tools=[],  # The writer does not need additional tools\n    verbose=True,\n    allow_delegation=False\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Langchain Tools for Groq Function Calling in Python\nDESCRIPTION: This snippet shows how to define Langchain tools for Groq function calling, including creating an order, getting product price, and getting product ID. It demonstrates the use of decorators and function descriptions.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_core.tools import tool\n\n@tool\ndef create_order(product_id, customer_id):\n    \"\"\"\n    Creates an order given a product_id and customer_id.\n    If a product name is provided, you must get the product ID first.\n    After placing the order indicate that it was placed successfully and output the details.\n\n    product_id: ID of the product\n    customer_id: ID of the customer\n    \"\"\"\n    api_token = os.environ[\"AIRTABLE_API_TOKEN\"]\n    base_id = os.environ[\"AIRTABLE_BASE_ID\"]\n    headers = {\n        \"Authorization\": f\"Bearer {api_token}\",\n        \"Content-Type\": \"application/json\",\n    }\n    url = f\"https://api.airtable.com/v0/{base_id}/orders\"\n    order_id = random.randint(1, 100000)  # Randomly assign an order_id\n    order_datetime = datetime.utcnow().strftime(\n        \"%Y-%m-%dT%H:%M:%SZ\"\n    )  # Assign order date as now\n    data = {\n        \"fields\": {\n            \"order_id\": order_id,\n            \"product_id\": product_id,\n            \"customer_id\": customer_id,\n            \"order_date\": order_datetime,\n        }\n    }\n    response = requests.post(url, headers=headers, json=data)\n    return str(response.json())\n\n\n@tool\ndef get_product_price(product_name):\n    \"\"\"\n    Gets the price for a product, given the name of the product.\n    Just return the price, do not do any calculations.\n\n    product_name: The name of the product (must be title case, i.e. 'Microphone', 'Laptop')\n    \"\"\"\n    api_token = os.environ[\"AIRTABLE_API_TOKEN\"]\n    base_id = os.environ[\"AIRTABLE_BASE_ID\"]\n    headers = {\"Authorization\": f\"Bearer {api_token}\"}\n    formula = f\"{{name}}='{product_name}'\"\n    encoded_formula = urllib.parse.quote(formula)\n    url = f\"https://api.airtable.com/v0/{base_id}/products?filterByFormula={encoded_formula}\"\n    response = requests.get(url, headers=headers)\n    product_price = response.json()[\"records\"][0][\"fields\"][\"price\"]\n    return \"$\" + str(product_price)\n\n\n@tool\ndef get_product_id(product_name):\n    \"\"\"\n    Gets product ID given a product name\n\n    product_name: The name of the product (must be title case, i.e. 'Microphone', 'Laptop')\n    \"\"\"\n    api_token = os.environ[\"AIRTABLE_API_TOKEN\"]\n    base_id = os.environ[\"AIRTABLE_BASE_ID\"]\n    headers = {\"Authorization\": f\"Bearer {api_token}\"}\n    formula = f\"{{name}}='{product_name}'\"\n    encoded_formula = urllib.parse.quote(formula)\n    url = f\"https://api.airtable.com/v0/{base_id}/products?filterByFormula={encoded_formula}\"\n    response = requests.get(url, headers=headers)\n    product_id = response.json()[\"records\"][0][\"fields\"][\"product_id\"]\n    return str(product_id)\n\n\n# Add tools to our LLM\ntools = [create_order, get_product_price, get_product_id]\nllm_with_tools = llm.bind_tools(tools)\n```\n\n----------------------------------------\n\nTITLE: Making API Requests to Groq using Python Requests Library\nDESCRIPTION: This example demonstrates how to make a request to the Groq API using Python's requests library. It shows authentication via API key, structuring the request payload, and handling the response.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nimport json\nimport os\n\n# Get your API key from environment variable\napi_key = os.environ[\"GROQ_API_KEY\"]\n\n# API endpoint for chat completions\nurl = \"https://api.groq.com/openai/v1/chat/completions\"\n\n# Request headers\nheaders = {\n    \"Authorization\": f\"Bearer {api_key}\",\n    \"Content-Type\": \"application/json\"\n}\n\n# Request payload\npayload = {\n    \"model\": \"llama2-70b-4096\",\n    \"messages\": [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n    ],\n    \"temperature\": 0.7,\n    \"max_tokens\": 100\n}\n\n# Make the request\nresponse = requests.post(url, headers=headers, json=payload)\n\n# Parse and print the response\nif response.status_code == 200:\n    response_data = response.json()\n    assistant_message = response_data[\"choices\"][0][\"message\"][\"content\"]\n    print(assistant_message)\nelse:\n    print(f\"Error: {response.status_code}\")\n    print(response.text)\n```\n\n----------------------------------------\n\nTITLE: Testing Stock Information Queries with Function Calling\nDESCRIPTION: Tests the LLM's ability to call the appropriate functions for current stock information queries. The example demonstrates how the model correctly identifies the company name, converts it to a stock symbol, and selects the appropriate data key based on the user's question.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama3-stock-market-function-calling/llama3-stock-market-function-calling.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nquery1 = 'What is the market cap of Meta?'\nquery2 = 'How does the volume of Apple compare to that of Microsoft?'\n\nprint(llm_with_tools.invoke(query1).tool_calls)\nprint(llm_with_tools.invoke(query2).tool_calls)\n```\n\n----------------------------------------\n\nTITLE: Defining and Compiling the AI Workflow Graph\nDESCRIPTION: Constructs and compiles the StateGraph that represents the AI workflow. This graph defines the sequence of operations, conditional edges, and connections between different agents and tools in the newsletter processing system.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/composio-newsletter-summarizer-agent/composio-groq.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nworkflow = StateGraph(AgentState)\n\nworkflow.add_node(\"email_fetcher\", email_fetcher_node)\nworkflow.add_node(\"email_summarizer\", email_summarizer_node)\nworkflow.add_node(\"email_sender\", email_sender_node)\nworkflow.add_node(\"call_tool\", tool_node)\n\nworkflow.add_edge(START, \"email_fetcher\")\nworkflow.add_edge(\"email_sender\" ,END)\n\nworkflow.add_conditional_edges(\n    \"email_fetcher\",\n    router,\n    {\"continue\": \"email_summarizer\", \"call_tool\": \"call_tool\"},\n)\nworkflow.add_conditional_edges(\n    \"email_summarizer\",\n    router,\n    {\"continue\": \"email_sender\", \"call_tool\": \"call_tool\"},\n)\n\nworkflow.add_conditional_edges(\n    \"email_sender\",\n    router,\n    {\"continue\": END, \"call_tool\": \"call_tool\"},\n)\n\nworkflow.add_conditional_edges(\n    \"call_tool\",\n    lambda x: x[\"sender\"],\n    {\"email_fetcher\": \"email_fetcher\",\n     \"email_summarizer\": \"email_summarizer\",\n     \"email_sender\": \"email_sender\",\n    },\n)\n\napp = workflow.compile()\n```\n\n----------------------------------------\n\nTITLE: Creating a Stateful ChatAgent with Groq in Langroid\nDESCRIPTION: Code example showing how to create a ChatAgent that maintains conversation state across multiple interactions. This allows for follow-up questions in a conversation using Groq's LLMs.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/langroid-llm-agents/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nagent_config = lr.ChatAgentConfig(\n    llm=llm_config,\n    system_message=\"\"\"Be nice but concise\"\"\",\n)\n\nagent = lr.ChatAgent(agent_config)\nresponse = agent.llm_response(\"Capital of France?\")\n# follow-up question works since agent maintains conversation history\nresponse = agent.llm_response(\"What about Congo?\")\n```\n\n----------------------------------------\n\nTITLE: Making API Requests to Groq using JavaScript Fetch API\nDESCRIPTION: This example shows how to interact with the Groq API using JavaScript's Fetch API. It demonstrates setting up authentication headers, formatting the request body, and processing the response asynchronously.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n// Get API key from environment or configuration\nconst apiKey = process.env.GROQ_API_KEY;\n\n// API endpoint\nconst url = 'https://api.groq.com/openai/v1/chat/completions';\n\n// Request headers\nconst headers = {\n  'Authorization': `Bearer ${apiKey}`,\n  'Content-Type': 'application/json'\n};\n\n// Request payload\nconst payload = {\n  model: 'llama2-70b-4096',\n  messages: [\n    {role: 'system', content: 'You are a helpful assistant.'},\n    {role: 'user', content: 'What is the capital of France?'}\n  ],\n  temperature: 0.7,\n  max_tokens: 100\n};\n\n// Make the request using fetch API\nfetch(url, {\n  method: 'POST',\n  headers: headers,\n  body: JSON.stringify(payload)\n})\n.then(response => {\n  if (!response.ok) {\n    throw new Error(`HTTP error! Status: ${response.status}`);\n  }\n  return response.json();\n})\n.then(data => {\n  const assistantMessage = data.choices[0].message.content;\n  console.log(assistantMessage);\n})\n.catch(error => {\n  console.error('Error:', error);\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Llama Guard 3 Content Moderation with Groq API in Python\nDESCRIPTION: This code snippet demonstrates how to use Llama Guard 3 through Groq API to assess the safety of user messages in a chatbot application. The implementation uses a chat completion request to screen messages for harmful content across 14 predefined categories.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama-guard-safe-chatbot/Llama-Guard-3-Ensuring-Safe-Chatbot.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n\n```\n\n----------------------------------------\n\nTITLE: Setting Up Multiple Tool Use with Groq API in Python\nDESCRIPTION: This code begins the implementation of multiple tool use where the output of one function becomes the input to another. It sets up the initial user prompt and message structure to place an order for a product by name rather than ID.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt = \"Please place an order for a Microphone\"\nmessages = [\n    {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n    {\n        \"role\": \"user\",\n        \"content\": user_prompt,\n    },\n]\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio in Chunks with Groq API in Python\nDESCRIPTION: This function orchestrates the chunked audio transcription process using Groq API. It preprocesses audio, splits it into overlapping chunks, transcribes each chunk, merges the results, and saves the final output in multiple formats.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/audio-chunking/audio_chunking_tutorial.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef transcribe_audio_in_chunks(audio_path: Path, chunk_length: int = 600, overlap: int = 10) -> dict:\n    \"\"\"\n    Transcribe audio in chunks with overlap with Whisper via Groq API.\n    \n    Args:\n        audio_path: Path to audio file\n        chunk_length: Length of each chunk in seconds\n        overlap: Overlap between chunks in seconds\n    \n    Returns:\n        dict: Containing transcription results\n    \n    Raises:\n        ValueError: If Groq API key is not set\n        RuntimeError: If audio file fails to load\n    \"\"\"\n    api_key = os.getenv(\"GROQ_API_KEY\")\n    if not api_key:\n        raise ValueError(\"GROQ_API_KEY environment variable not set\")\n    \n    print(f\"\\nStarting transcription of: {audio_path}\")\n    # Make sure your Groq API key is configured. If you don't have one, you can get one at https://console.groq.com/keys!\n    client = Groq(api_key=api_key, max_retries=0)\n    \n    processed_path = None\n    try:\n        # Preprocess audio and get basic info\n        processed_path = preprocess_audio(audio_path)\n        try:\n            audio = AudioSegment.from_file(processed_path, format=\"flac\")\n        except Exception as e:\n            raise RuntimeError(f\"Failed to load audio: {str(e)}\")\n        \n        duration = len(audio)\n        print(f\"Audio duration: {duration/1000:.2f}s\")\n        \n        # Calculate # of chunks\n        chunk_ms = chunk_length * 1000\n        overlap_ms = overlap * 1000\n        total_chunks = (duration // (chunk_ms - overlap_ms)) + 1\n        print(f\"Processing {total_chunks} chunks...\")\n        \n        results = []\n        total_transcription_time = 0\n\n        # Loop through each chunk, extract current chunk from audio, transcribe    \n        for i in range(total_chunks):\n            start = i * (chunk_ms - overlap_ms)\n            end = min(start + chunk_ms, duration)\n                \n            print(f\"\\nProcessing chunk {i+1}/{total_chunks}\")\n            print(f\"Time range: {start/1000:.1f}s - {end/1000:.1f}s\")\n                \n            chunk = audio[start:end]\n            result, chunk_time = transcribe_single_chunk(client, chunk, i+1, total_chunks)\n            total_transcription_time += chunk_time\n            results.append((result, start))\n            \n        final_result = merge_transcripts(results)\n        save_results(final_result, audio_path)\n            \n        print(f\"\\nTotal Groq API transcription time: {total_transcription_time:.2f}s\")\n        \n        return final_result\n    \n    # Clean up temp files regardless of successful creation    \n    finally:\n        if processed_path:\n            Path(processed_path).unlink(missing_ok=True)\n```\n\n----------------------------------------\n\nTITLE: Initializing MLB Agents Configuration in Python\nDESCRIPTION: Defines multiple specialized agents including an MLB researcher, statisticians, writers using different models (Llama, Gemma, Mixtral), and an editor. Each agent has specific roles, instructions and tools for analyzing game data and generating content.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/Mixture-of-Agents-Agno-Groq.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndefault_date = datetime.now().date() - timedelta(1) # Set default date to yesterday in case no date is specified\n\nmlb_researcher = Agent(\n    model=model_mixtral,\n    description=\"An detailed accurate MLB researcher extracts game information from the user question\",\n    instructions=[\n        f\"Parse the Team and date (use {default_date} if user does not specify) from the user question.\",\n        \"Pass to your get_game_info tool\",\n        \"\"\"\n        Respond in the following format:\n            game_id: game_id\n            home_team: home_team\n            home_score: home_score\n            away_team: away_team\n            away_score: away_score\n            winning_team: winning_team\n            series_status: series_status\n        \"\"\"        \n    ],\n    tools=[get_game_info],   \n)\n\nmlb_batting_statistician = Agent(\n    model=model_mixtral,\n    description=\"An industrious MLB Statistician analyzing player boxscore stats for the relevant game\",\n    instructions=[\n        \"Given information about a MLB game, retrieve ONLY boxscore player batting stats for the game identified by the MLB Researcher\",\n        \"Your analysis should be atleast 500 words long, and include inning-by-inning statistical summaries\",\n        ],\n    tools=[get_batting_stats],\n)\n\nmlb_pitching_statistician = Agent(\n    model=model_mixtral,\n    description=\"An industrious MLB Statistician analyzing player boxscore stats for the relevant game\",\n    instructions=[\n        \"Given information about a MLB game, retrieve ONLY boxscore player pitching stats for a specific game\",\n        \"Your analysis should be atleast 500 words long, and include inning-by-inning statistical summaries\",\n        ],\n    tools=[get_pitching_stats],\n)\n\nmlb_writer_llama = Agent(\n    model=model_llama70b,\n    description=\"An experienced, honest, and industrious writer who does not make things up\",\n    instructions=[\n        \"\"\"\n            Write a game recap article using the provided game information and stats.\n            Key instructions:\n            - Include things like final score, top performers and winning/losing pitcher.\n            - Use ONLY the provided data and DO NOT make up any information, such as specific innings when events occurred, that isn't explicitly from the provided input.\n            - Do not print the box score\n        \"\"\",\n        \"Your recap from the stats should be at least 1000 words. Impress your readers!!!\"\n    ],\n)\n\nmlb_writer_gemma = Agent(\n    model=model_gemma2,\n    description=\"An experienced and honest writer who does not make things up\",\n    instructions=[\"Write a detailed game recap article using the provided game information and stats\"],\n)\n\nmlb_writer_mixtral = Agent(\n    model=model_mixtral,\n    description=\"An experienced and honest writer who does not make things up\",\n    instructions=[\"Write a detailed game recap article using the provided game information and stats\"],\n)\n\nmlb_editor = Agent(\n    model=model_llama70b,\n    description=\"An experienced editor that excels at taking the best parts of multiple texts to create the best final product\",\n    instructions=[\"Edit recap articles to create the best final product.\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Simple Function Calling with Groq API in Python\nDESCRIPTION: This code demonstrates how to implement a simple function call using Groq API. It processes a user prompt to place an order, sends the request to the LLM with defined tools, handles the tool call response, executes the function with the provided parameters, and then sends the result back to the LLM to complete the conversation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt = \"Please place an order for Product ID 5\"\nmessages = [\n    {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n    {\n        \"role\": \"user\",\n        \"content\": user_prompt,\n    },\n]\n\n# Step 1: send the conversation and available functions to the model\nresponse = client.chat.completions.create(\n    model=MODEL,\n    messages=messages,\n    tools=tools,\n    tool_choice=\"auto\",  # Let the LLM decide if it should use one of the available tools\n    max_tokens=4096,\n)\n\nresponse_message = response.choices[0].message\ntool_calls = response_message.tool_calls\nprint(\"First LLM Call (Tool Use) Response:\", response_message)\n# Step 2: check if the model wanted to call a function\nif tool_calls:\n    # Step 3: call the function and append the tool call to our list of messages\n    available_functions = {\n        \"create_order\": create_order,\n    }\n    messages.append(\n        {\n            \"role\": \"assistant\",\n            \"tool_calls\": [\n                {\n                    \"id\": tool_call.id,\n                    \"function\": {\n                        \"name\": tool_call.function.name,\n                        \"arguments\": tool_call.function.arguments,\n                    },\n                    \"type\": tool_call.type,\n                }\n                for tool_call in tool_calls\n            ],\n        }\n    )\n    # Step 4: send the info for each function call and function response to the model\n    tool_call = tool_calls[0]\n    function_name = tool_call.function.name\n    function_to_call = available_functions[function_name]\n    function_args = json.loads(tool_call.function.arguments)\n    function_response = function_to_call(\n        product_id=function_args.get(\"product_id\"),\n        customer_id=function_args.get(\"customer_id\"),\n    )\n    messages.append(\n        {\n            \"tool_call_id\": tool_call.id,\n            \"role\": \"tool\",\n            \"name\": function_name,\n            \"content\": function_response,\n        }\n    )  # extend conversation with function response\n    # Send the result back to the LLM to complete the chat\n    second_response = client.chat.completions.create(\n        model=MODEL, messages=messages\n    )  # get a new response from the model where it can see the function response\n    print(\"\\n\\nSecond LLM Call Response:\", second_response.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Implementing Prompt Guard with Llama Guard 3 by Groq\nDESCRIPTION: Shows how to enable prompt safety features using Llama Guard 3. The prompt_guard parameter specifies content types to filter, preventing prompt injection and unsafe use cases.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/jigsawstack-prompt-engine/jigsawstack-prompt-engine.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nparams = {\n    \"prompt\": \"Tell me a story about {about}\",\n    \"inputs\": [\n        {\n            \"key\": \"about\",\n        },\n    ],\n    \"input_values\": {\n        \"about\": \"The Leaning Tower of Pisa\"\n    },\n    \"return_prompt\": \"Return the result in a markdown format\",\n    \"prompt_guard\": [\"sexual_content\", \"defamation\"] #Add this to use llama-guard\n}\nresult = jigsaw.prompt_engine.run_prompt_direct(params)\n\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Single Chunk Transcription Function with Groq API\nDESCRIPTION: Function to transcribe individual audio chunks using Whisper Large V3 model via Groq API, including error handling and progress tracking\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/audio-chunking/audio_chunking_tutorial.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef transcribe_single_chunk(client: Groq, chunk: AudioSegment, chunk_num: int, total_chunks: int) -> tuple[dict, float]:\n    \"\"\"\n    Transcribe a single audio chunk with Groq API.\n    \n    Args:\n        client: Groq client instance\n        chunk: Audio segment to transcribe\n        chunk_num: Current chunk number\n        total_chunks: Total number of chunks\n        \n    Returns:\n        Tuple of (transcription result, processing time)\n\n    Raises:\n        Exception: If chunk transcription fails after retries\n    \"\"\"\n    total_api_time = 0\n    \n    while True:\n        with tempfile.NamedTemporaryFile(suffix='.flac') as temp_file:\n            chunk.export(temp_file.name, format='flac')\n            \n            start_time = time.time()\n            try:\n                result = client.audio.transcriptions.create(\n                    file=(\"chunk.flac\", temp_file, \"audio/flac\"),\n                    model=\"whisper-large-v3\",\n                    language=\"en\", # We highly recommend specifying the language of your audio if you know it\n                    response_format=\"verbose_json\"\n                )\n                api_time = time.time() - start_time\n                total_api_time += api_time\n                \n                print(f\"Chunk {chunk_num}/{total_chunks} processed in {api_time:.2f}s\")\n                return result, total_api_time\n                \n            except RateLimitError as e:\n                print(f\"\\nRate limit hit for chunk {chunk_num} - retrying in 60 seconds...\")\n                time.sleep(60)\n                continue\n                \n            except Exception as e:\n                print(f\"Error transcribing chunk {chunk_num}: {str(e)}\")\n                raise\n```\n\n----------------------------------------\n\nTITLE: Making API Requests to Groq using cURL\nDESCRIPTION: This example shows how to interact with the Groq API using the cURL command-line tool. It demonstrates the proper request format, authentication headers, and handling JSON data.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Set your API key as an environment variable\n# export GROQ_API_KEY=\"your-api-key-here\"\n\n# Make the request using curl\ncurl -X POST \\\n  https://api.groq.com/openai/v1/chat/completions \\\n  -H \"Authorization: Bearer $GROQ_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"llama2-70b-4096\",\n    \"messages\": [\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n      {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n    ],\n    \"temperature\": 0.7,\n    \"max_tokens\": 100\n  }'\n```\n\n----------------------------------------\n\nTITLE: Implementing Content Filtering with Llama Guard 3\nDESCRIPTION: Demonstrates a complete content moderation system that generates a message, classifies it with Llama Guard 3, and then either processes the safe message with Llama 3.1 or returns a generic response for unsafe content.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama-guard-safe-chatbot/Llama-Guard-3-Ensuring-Safe-Chatbot.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Randomly generate a safe or unsafe message\nrandom_number = random.random()\nif random_number < 0.5:\n    user_message = generate_harmful_message(unsafe_categories)\nelse:\n    user_message = generate_safe_message()\n    \nllamaguard_response = get_llamaguard_response(user_message)\n\nprint('User Message:', user_message)\nprint('Llama Guard 3 Response:', llamaguard_response)\n\n# If the message is safe, allow Llama 3.1 to respond to it\nif llamaguard_response == 'safe':\n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n            \"role\": \"user\",\n            \"content\": user_message\n            }\n        ],\n        model=\"llama-3.1-8b-instant\",\n    )\n    print('LLM Response', chat_completion.choices[0].message.content[:200],'...')\n\n# If the message is unsafe, respond with a generic message\nelse:\n    print('Your message contains content that violates our community guidelines. Please ensure your comments are respectful and safe for all users. Thank you!')\n```\n\n----------------------------------------\n\nTITLE: Defining Historical Stock Price Tool for LangChain\nDESCRIPTION: Creates a LangChain tool that retrieves historical stock prices for a specified date range using the yfinance API. The tool accepts a stock symbol, start date, and end date, with detailed guidance on how to interpret and set date parameters based on user queries.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama3-stock-market-function-calling/llama3-stock-market-function-calling.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef get_historical_price(symbol, start_date, end_date):\n    \"\"\"\n    Fetches historical stock prices for a given symbol from 'start_date' to 'end_date'.\n    - symbol (str): Stock ticker symbol.\n    - end_date (date): Typically today unless a specific end date is provided. End date MUST be greater than start date\n    - start_date (date): Set explicitly, or calculated as 'end_date - date interval' (for example, if prompted 'over the past 6 months', date interval = 6 months so start_date would be 6 months earlier than today's date). Default to '1900-01-01' if vaguely asked for historical price. Start date must always be before the current date\n    \"\"\"\n\n    data = yf.Ticker(symbol)\n    hist = data.history(start=start_date, end=end_date)\n    hist = hist.reset_index()\n    hist[symbol] = hist['Close']\n    return hist[['Date', symbol]]\n```\n\n----------------------------------------\n\nTITLE: Main Execution Block\nDESCRIPTION: Demonstrates the complete workflow of uploading data and executing analysis using the Code Interpreter and LLM.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/e2b-code-interpreting/code-interpreter-python/groq_with_e2b_code_interpreter.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nwith CodeInterpreter(api_key=E2B_API_KEY) as code_interpreter:\n    upload_dataset(code_interpreter)\n\n    code_results = chat_with_llm(\n        code_interpreter,\n        \"Make a chart showing linear regression of the relationship between GDP per capita and life expectancy from the data. Filter out any missing values or values in wrong format.\",\n    )\n    if code_results:\n        first_result = code_results[0]\n    else:\n        raise Exception(\"No code interpreter results\")\n\nfirst_result\n```\n\n----------------------------------------\n\nTITLE: Creating a Team Agent for Travel Planning\nDESCRIPTION: Combines the Scraper, Location, and Weather agents into a unified Travel Agent. This multi-agent system can handle complex trip planning by integrating real-time updates and personalized recommendations based on user preferences, location, and weather conditions.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nteam = TeamAgentFactory.create(\n    name=\"Travel Agent\",\n    description=\"\"\"An agent designed to help users plan trips and get real-time updates on the best activities, local weather, and nearby points of interest.\n    Integrates real-time user input, like whether they're traveling with family or solo, to filter results.\n    Fetches nearby places of interest such as landmarks, restaurants, or activity hubs based on user-provided locations.\n    Suggests alternate plans or indoor activities in case of unfavorable weather conditions.\n    \"\"\",\n    agents=[scraper_agent, location_agent, weather_agent]\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Multi-Image Stories by Combining LLaVA Descriptions\nDESCRIPTION: Demonstrates how to process multiple images sequentially with LLaVA, combine their descriptions, and then generate a cohesive story from Llama 3.1 that incorporates elements from all images. This workaround is necessary since the current preview doesn't support multi-image uploads.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/dog-picture-storytelling-with-llava.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nbase64_image1 = encode_image('images/husky.png')\nbase64_image2 = encode_image('images/bulldog.png')\n\nimage_description1 = image_to_text(client, llava_model, base64_image1, prompt)\nimage_description2 = image_to_text(client, llava_model, base64_image2, prompt)\n\ncombined_image_description = image_description1 + '\\n\\n' + image_description2\n\nprint(short_story_generation(client, combined_image_description))\n```\n\n----------------------------------------\n\nTITLE: Main Script Execution for Groq Whisper Subtitle Generation\nDESCRIPTION: Orchestrates the entire subtitle generation process: loads the video, extracts audio, sends it for transcription, creates subtitle clips, and combines everything into the final video with overlaid subtitles.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/instagram-reel-subtitler/subtitler-tutorial.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Change the video_file to the path of where your video file name is\nvideo_file = \"input.mp4\"\n\n# The output video name and path\noutput_file = \"output_with_subtitles.mp4\"\n\n# Loading the video as a VideoFileClip\noriginal_clip = VideoFileClip(video_file)\nwidth = original_clip.w # the width of the video, so the subtitles don't overflow\n\n# where the extracted mp3 audio from the video will be saved\nmp3_file = \"output.mp3\"\nconvert_mp4_to_mp3(video_file, mp3_file)\n\n# Call Whisper hosted on Groq to get the timestamped word segments\nsegments = transcribe_audio(mp3_file)\n\n# Create a list of text clips from the segments\ntext_clip_list = add_subtitles(segments, width, fontsize=40)\n\n# Create a CompositeVideoClip with the original video and textclips\nfinal_clip = CompositeVideoClip([original_clip] + text_clip_list)\n\n# Generate the final video with subtitles on it\nfinal_clip.write_videofile(\"final.mp4\", codec=\"libx264\")\nprint(\"Subtitled video saved as:\", output_file)\n```\n\n----------------------------------------\n\nTITLE: Processing Golden Retriever Image with Llama Vision Tool in Python\nDESCRIPTION: Code that processes a golden retriever image using the Llama Vision tool. It encodes the image, calls the vision model with available functions, and generates a breed assessment based on the returned data.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nbase64_image = encode_image(image_path)\ndog_breed_json = llama_vision_tool_call(client, model, base64_image, available_functions)\ndog_breed_assessment = assess_dog_breed(client, model, dog_breed_json)\nprint(dog_breed_assessment)\n```\n\n----------------------------------------\n\nTITLE: Implementing Conversation Flow with Groq and Langchain in Python\nDESCRIPTION: This snippet shows how to implement a conversation flow using Groq and Langchain, handling multiple tool calls and managing the conversation state.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n\navailable_tools = {\n    \"create_order\": create_order,\n    \"get_product_price\": get_product_price,\n    \"get_product_id\": get_product_id,\n}\nmessages = [SystemMessage(SYSTEM_MESSAGE), HumanMessage(user_prompt)]\ntool_call_identified = True\nwhile tool_call_identified:\n    ai_msg = llm_with_tools.invoke(messages)\n    messages.append(ai_msg)\n    for tool_call in ai_msg.tool_calls:\n        selected_tool = available_tools[tool_call[\"name\"]]\n        tool_output = selected_tool.invoke(tool_call[\"args\"])\n        messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n    if len(ai_msg.tool_calls) == 0:\n        tool_call_identified = False\n\nprint(ai_msg.content)\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio with Groq Whisper API\nDESCRIPTION: Sends the MP3 audio file to Groq's Whisper API for transcription with word-level timestamps. Uses verbose_json format to get detailed timing information for each word.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/instagram-reel-subtitler/subtitler-tutorial.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef transcribe_audio(mp3_file):\n    \"\"\"\n    Transcribes an audio file using Groq Whisper API.\n    \n    Args:\n        mp3_file (str): Path to the MP3 file.\n    \n    Returns:\n        list: Transcribed text segments with timestamps.\n    \"\"\"\n    with open(mp3_file, \"rb\") as file:\n        transcription = client.audio.transcriptions.create(\n            file=(mp3_file, file.read()),\n            model=\"whisper-large-v3-turbo\", # Alternatively, use \"distil-whisper-large-v3-en\" for a faster and lower cost (English-only)\n            timestamp_granularities=[\"word\"], # Word level time stamps\n            response_format=\"verbose_json\",\n            language=\"en\",\n            temperature=0.0\n        )\n    \n        print(transcription.words)\n        return transcription.words\n```\n\n----------------------------------------\n\nTITLE: Testing RAG Pipeline with Individual Question-Answer Pair in Python\nDESCRIPTION: Demonstrates how to test a single question and context/answer pair using the newly created benchmark chain. It prints the question, answer, evaluation score, and explanation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nq1 = questions[-1]['question_1']\nt1 = texts[-1]\n\nprint(f\"Question: {q1}\")\na1 = await rag_chain.ainvoke(q1)\nprint(f\"Answer: {a1}\")\neval_input = {\n    'context': t1,\n    'question': q1,\n    'answer': a1\n}\nresponse = await eval_chain.ainvoke(eval_input)\nprint(\"---------------------\")\nprint(f\"Score: {response['score']}\")\nprint(f\"Explanation: {response['explanation']}\")\nprint(\"---------------------\")\n```\n\n----------------------------------------\n\nTITLE: Implementing MLB Pitcher Statistics Retrieval Tool\nDESCRIPTION: Creates a tool function to fetch detailed pitcher statistics for a specific MLB game. This function queries the MLB-Stats API to retrieve pitcher performance metrics from the boxscore data including innings pitched, hits allowed, strikeouts, and other key pitching statistics.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@tool \ndef get_pitching_stats(game_id: str) -> str:\n    \"\"\"Gets player boxscore pitching stats for a particular MLB game\n    \n    Params:\n    game_id: The 6-digit ID of the game\n    \"\"\"\n    boxscores=statsapi.boxscore_data(game_id)\n    player_info_df = pd.DataFrame(boxscores['playerInfo']).T.reset_index()\n\n    away_pitchers_box = pd.DataFrame(boxscores['awayPitchers']).iloc[1:]\n    away_pitchers_box['team_name'] = boxscores['teamInfo']['away']['teamName']\n\n    home_pitchers_box = pd.DataFrame(boxscores['homePitchers']).iloc[1:]\n    home_pitchers_box['team_name'] = boxscores['teamInfo']['home']['teamName']\n\n    pitchers_box_df = pd.concat([away_pitchers_box,home_pitchers_box]).merge(player_info_df, left_on = 'name', right_on = 'boxscoreName')\n    return str(pitchers_box_df[['team_name','fullName','ip','h','r','er','bb','k','note']])\n```\n\n----------------------------------------\n\nTITLE: Executing a Verified SQL Query Using Groq API Function Calling in Python\nDESCRIPTION: This code snippet demonstrates how to use the call_verified_sql function to execute a verified SQL query based on a user's question using Groq API's function calling capability.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-sql/json-mode-function-calling-for-sql.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt = 'What were the most recent purchases?'\ncall_verified_sql(user_prompt,verified_queries_dict,model)\n```\n\n----------------------------------------\n\nTITLE: Orchestrating LLM Function Calls with LangChain in Python\nDESCRIPTION: This function integrates LangChain with Groq LLM to handle user queries about stocks. It manages the conversation flow, executes appropriate tools based on LLM decisions, collects data for visualization, and provides contextual responses including generating stock price charts when requested.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama3-stock-market-function-calling/llama3-stock-market-function-calling.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_core.messages import AIMessage, SystemMessage, HumanMessage, ToolMessage\nfrom datetime import date\n\ndef call_functions(llm_with_tools, user_prompt):\n    system_prompt = 'You are a helpful finance assistant that analyzes stocks and stock prices. Today is {today}'.format(today = date.today())\n    \n    messages = [SystemMessage(system_prompt), HumanMessage(user_prompt)]\n    ai_msg = llm_with_tools.invoke(messages)\n    messages.append(ai_msg)\n    historical_price_dfs = []\n    symbols = []\n    for tool_call in ai_msg.tool_calls:\n        selected_tool = {\"get_stock_info\": get_stock_info, \"get_historical_price\": get_historical_price}[tool_call[\"name\"].lower()]\n        tool_output = selected_tool.invoke(tool_call[\"args\"])\n        if tool_call['name'] == 'get_historical_price':\n            historical_price_dfs.append(tool_output)\n            symbols.append(tool_output.columns[1])\n        else:\n            messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n    \n    if len(historical_price_dfs) > 0:\n        plot_price_over_time(historical_price_dfs)\n        symbols = ' and '.join(symbols)\n        messages.append(ToolMessage('Tell the user that a historical stock price chart for {symbols} been generated.'.format(symbols=symbols), tool_call_id=0))\n\n    return llm_with_tools.invoke(messages).content\n\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Text-To-SQL Query Generation and Execution\nDESCRIPTION: This snippet demonstrates how to use the text_to_sql function to generate a SQL query from a natural language question, format it, and execute it using the execute_duckdb_query function.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-sql/json-mode-function-calling-for-sql.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nuser_question = 'What are the most recent purchases?'\n\n\nllm_response = text_to_sql(client,system_prompt,user_question,model)\nsql_json = json.loads(llm_response)\nparsed_sql = sqlparse.format(sql_json['sql'], reindent=True, keyword_case='upper')\nformatted_sql = f\"```sql\\n{parsed_sql.strip()}\\n```\"\ndisplay(Markdown(formatted_sql)) \n\nexecute_duckdb_query(parsed_sql)\n```\n\n----------------------------------------\n\nTITLE: Merging Audio Transcription Chunks with Python\nDESCRIPTION: This function merges transcription chunks from audio processing, handling various timestamp granularities (segments, words, or both). It processes overlapping segments, adjusts word timestamps, and combines all data into a single coherent transcript. The function is designed to work with responses from the Groq API.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/audio-chunking/audio_chunking_tutorial.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef merge_transcripts(results: list[tuple[dict, int]]) -> dict:\n    \"\"\"\n    Merge transcription chunks and handle overlaps.\n    \n    Works with responses from Groq API regardless of whether segments, words,\n    or both were requested via timestamp_granularities.\n    \n    Args:\n        results: List of (result, start_time) tuples\n        \n    Returns:\n        dict: Merged transcription\n    \"\"\"\n    print(\"\\nMerging results...\")\n    \n    # First, check if we have segments in our results\n    has_segments = False\n    for chunk, _ in results:\n        data = chunk.model_dump() if hasattr(chunk, 'model_dump') else chunk\n        if 'segments' in data and data['segments'] is not None and len(data['segments']) > 0:\n            has_segments = True\n            break\n    \n    # Process word-level timestamps regardless of segment presence\n    has_words = False\n    words = []\n    \n    for chunk, chunk_start_ms in results:\n        # Convert Pydantic model to dict\n        data = chunk.model_dump() if hasattr(chunk, 'model_dump') else chunk\n        \n        # Process word timestamps if available\n        if isinstance(data, dict) and 'words' in data and data['words'] is not None and len(data['words']) > 0:\n            has_words = True\n            # Adjust word timestamps based on chunk start time\n            chunk_words = data['words']\n            for word in chunk_words:\n                # Convert chunk_start_ms from milliseconds to seconds for word timestamp adjustment\n                word['start'] = word['start'] + (chunk_start_ms / 1000)\n                word['end'] = word['end'] + (chunk_start_ms / 1000)\n            words.extend(chunk_words)\n        elif hasattr(chunk, 'words') and getattr(chunk, 'words') is not None:\n            has_words = True\n            # Handle Pydantic model for words\n            chunk_words = getattr(chunk, 'words')\n            processed_words = []\n            for word in chunk_words:\n                if hasattr(word, 'model_dump'):\n                    word_dict = word.model_dump()\n                else:\n                    # Create a dict from the word object\n                    word_dict = {\n                        'word': getattr(word, 'word', ''),\n                        'start': getattr(word, 'start', 0) + (chunk_start_ms / 1000),\n                        'end': getattr(word, 'end', 0) + (chunk_start_ms / 1000)\n                    }\n                processed_words.append(word_dict)\n            words.extend(processed_words)\n    \n    # If we don't have segments, just merge the full texts\n    if not has_segments:\n        print(\"No segments found in transcription results. Merging full texts only.\")\n        \n        texts = []\n        \n        for chunk, _ in results:\n            # Convert Pydantic model to dict\n            data = chunk.model_dump() if hasattr(chunk, 'model_dump') else chunk\n            \n            # Get text - handle both dictionary and object access\n            if isinstance(data, dict):\n                text = data.get('text', '')\n            else:\n                # For Pydantic models or other objects\n                text = getattr(chunk, 'text', '')\n            \n            texts.append(text)\n        \n        merged_text = \" \".join(texts)\n        result = {\"text\": merged_text}\n        \n        # Include word-level timestamps if available\n        if has_words:\n            result[\"words\"] = words\n        \n        # Return an empty segments list since segments weren't requested\n        result[\"segments\"] = []\n        return result\n    \n    # If we do have segments, proceed with the segment merging logic\n    print(\"Merging segments across chunks...\")\n    final_segments = []\n    processed_chunks = []\n    \n    for i, (chunk, chunk_start_ms) in enumerate(results):\n        data = chunk.model_dump() if hasattr(chunk, 'model_dump') else chunk\n        \n        # Handle both dictionary and object access for segments\n        if isinstance(data, dict):\n            segments = data.get('segments', [])\n        else:\n            segments = getattr(chunk, 'segments', [])\n            # Convert segments to list of dicts if needed\n            if hasattr(segments, 'model_dump'):\n                segments = segments.model_dump()\n            elif not isinstance(segments, list):\n                segments = []\n        \n        # If not last chunk, find next chunk start time\n        if i < len(results) - 1:\n            next_start = results[i + 1][1]  # This is in milliseconds\n            \n            # Split segments into current and overlap based on next chunk's start time\n            current_segments = []\n            overlap_segments = []\n            \n            for segment in segments:\n                # Handle both dict and object access for segment\n                if isinstance(segment, dict):\n                    segment_end = segment['end']\n                else:\n                    segment_end = getattr(segment, 'end', 0)\n                \n                # Convert segment end time to ms and compare with next chunk start time\n                if segment_end * 1000 > next_start:\n                    # Make sure segment is a dict\n                    if not isinstance(segment, dict) and hasattr(segment, 'model_dump'):\n                        segment = segment.model_dump()\n                    elif not isinstance(segment, dict):\n                        # Create a dict from the segment object\n                        segment = {\n                            'text': getattr(segment, 'text', ''),\n                            'start': getattr(segment, 'start', 0),\n                            'end': segment_end\n                        }\n                    overlap_segments.append(segment)\n                else:\n                    # Make sure segment is a dict\n                    if not isinstance(segment, dict) and hasattr(segment, 'model_dump'):\n                        segment = segment.model_dump()\n                    elif not isinstance(segment, dict):\n                        # Create a dict from the segment object\n                        segment = {\n                            'text': getattr(segment, 'text', ''),\n                            'start': getattr(segment, 'start', 0),\n                            'end': segment_end\n                        }\n                    current_segments.append(segment)\n            \n            # Merge overlap segments if any exist\n            if overlap_segments:\n                merged_overlap = overlap_segments[0].copy()\n                merged_overlap.update({\n                    'text': ' '.join(s.get('text', '') if isinstance(s, dict) else getattr(s, 'text', '') \n                                   for s in overlap_segments),\n                    'end': overlap_segments[-1].get('end', 0) if isinstance(overlap_segments[-1], dict) \n                           else getattr(overlap_segments[-1], 'end', 0)\n                })\n                current_segments.append(merged_overlap)\n                \n            processed_chunks.append(current_segments)\n        else:\n            # For last chunk, ensure all segments are dicts\n            dict_segments = []\n            for segment in segments:\n                if not isinstance(segment, dict) and hasattr(segment, 'model_dump'):\n                    dict_segments.append(segment.model_dump())\n                elif not isinstance(segment, dict):\n                    dict_segments.append({\n                        'text': getattr(segment, 'text', ''),\n                        'start': getattr(segment, 'start', 0),\n                        'end': getattr(segment, 'end', 0)\n                    })\n                else:\n                    dict_segments.append(segment)\n            processed_chunks.append(dict_segments)\n    \n    # Merge boundaries between chunks\n    for i in range(len(processed_chunks) - 1):\n        # Skip if either chunk has no segments\n        if not processed_chunks[i] or not processed_chunks[i+1]:\n            continue\n            \n        # Add all segments except last from current chunk\n        if len(processed_chunks[i]) > 1:\n            final_segments.extend(processed_chunks[i][:-1])\n        \n        # Merge boundary segments\n        last_segment = processed_chunks[i][-1]\n        first_segment = processed_chunks[i+1][0]\n        \n        merged_text = find_longest_common_sequence([\n            last_segment.get('text', '') if isinstance(last_segment, dict) else getattr(last_segment, 'text', ''),\n            first_segment.get('text', '') if isinstance(first_segment, dict) else getattr(first_segment, 'text', '')\n        ])\n        \n        merged_segment = last_segment.copy() if isinstance(last_segment, dict) else {\n            'text': getattr(last_segment, 'text', ''),\n```\n\n----------------------------------------\n\nTITLE: Implementing Text-To-SQL Function with Groq API\nDESCRIPTION: This function takes a system prompt and user question, sends it to the Groq API using JSON mode, and returns the generated SQL query or error message.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-sql/json-mode-function-calling-for-sql.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef text_to_sql(client,system_prompt,user_question,model):\n\n    completion = client.chat.completions.create(\n        model = model,\n        response_format = {\"type\": \"json_object\"},\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt\n            },\n            {\n                \"role\": \"user\",\n                \"content\": user_question\n            }\n        ]\n    )\n  \n    return completion.choices[0].message.content\n```\n\n----------------------------------------\n\nTITLE: Defining System Prompt for JSON Schema\nDESCRIPTION: Sets up the system prompt with JSON schema for social determinants of health data extraction.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/json-mode-social-determinants-of-health/SDOH-Json-mode.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Define system prompt (note: system prompt must contain \"JSON\" in it)\nsystem_prompt = '''\nYou are a medical coding API specializing in social determinants of health that responds in JSON.\nYour job is to extract structured SDOH data from an unstructured clinical note and output the structured data in JSON.\nThe JSON schema should include:\n  {\n    \"employment_status\": \"string (categorical: 'Unemployed', 'Part-time', 'Full-time', 'Retired')\",\n    \"financial_stress\": \"boolean (TRUE if the patient mentions financial difficulties)\",\n    \"housing_insecurity\": \"boolean (TRUE if the patient does not live in stable housing conditions)\",\n    \"neighborhood_unsafety\": \"boolean (TRUE if the patient expresses concerns about safety)\",\n    \"food_insecurity\": \"boolean (TRUE if the patient does not have reliable access to sufficient food)\",\n    \"education_level\": \"string (categorical: 'None', 'High School', 'College', 'Graduate')\",\n    \"transportation_inaccessibility\": \"boolean (TRUE if the patient does not have reliable transportation to healthcare appointments)\",\n    \"social_isolation\": \"boolean (TRUE if the patient mentions feeling isolated or having a lack of social support)\",\n    \"health_insurance_inadequacy\": (boolean: TRUE if the patient's health insurance is insufficient),\n    \"skipped_care_due_to_cost\": \"boolean (TRUE if the patient mentions skipping medical tests or treatments due to cost)\",\n    \"marital_status\": \"string (categorical: 'Single', 'Married', 'Divorced', 'Widowed')\",\n    \"language_barrier\": \"boolean (TRUE if the patient has language barriers to healthcare access)\"\n  }\n'''\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Usage Loop with Groq API in Python\nDESCRIPTION: This snippet demonstrates a loop for making LLM calls using the Groq API until no more tool calls are identified. It handles tool calls, executes corresponding functions, and manages the conversation flow.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Continue to make LLM calls until it no longer decides to use a tool\ntool_call_identified = True\nwhile tool_call_identified:\n    response = client.chat.completions.create(\n        model=MODEL, messages=messages, tools=tools, tool_choice=\"auto\", max_tokens=4096\n    )\n    response_message = response.choices[0].message\n    tool_calls = response_message.tool_calls\n    # Step 2: check if the model wanted to call a function\n    if tool_calls:\n        print(\"LLM Call (Tool Use) Response:\", response_message)\n        # Step 3: call the function and append the tool call to our list of messages\n        available_functions = {\n            \"create_order\": create_order,\n            \"get_product_id\": get_product_id,\n        }\n        messages.append(\n            {\n                \"role\": \"assistant\",\n                \"tool_calls\": [\n                    {\n                        \"id\": tool_call.id,\n                        \"function\": {\n                            \"name\": tool_call.function.name,\n                            \"arguments\": tool_call.function.arguments,\n                        },\n                        \"type\": tool_call.type,\n                    }\n                    for tool_call in tool_calls\n                ],\n            }\n        )\n\n        # Step 4: send the info for each function call and function response to the model\n        for tool_call in tool_calls:\n            function_name = tool_call.function.name\n            function_to_call = available_functions[function_name]\n            function_args = json.loads(tool_call.function.arguments)\n            if function_name == \"get_product_id\":\n                function_response = function_to_call(\n                    product_name=function_args.get(\"product_name\")\n                )\n            elif function_name == \"create_order\":\n                function_response = function_to_call(\n                    customer_id=function_args.get(\"customer_id\"),\n                    product_id=function_args.get(\"product_id\"),\n                )\n            messages.append(\n                {\n                    \"tool_call_id\": tool_call.id,\n                    \"role\": \"tool\",\n                    \"name\": function_name,\n                    \"content\": function_response,\n                }\n            )  # extend conversation with function response\n    else:\n        print(\"\\n\\nFinal LLM Call Response:\", response.choices[0].message.content)\n        tool_call_identified = False\n```\n\n----------------------------------------\n\nTITLE: Creating AI Agents for Email Processing Workflow\nDESCRIPTION: Defines three AI agents: email_fetcher, email_summarizer, and email_sender. Each agent is responsible for a specific task in the newsletter processing workflow, such as fetching emails, summarizing content, and sending formatted summaries.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/composio-newsletter-summarizer-agent/composio-groq.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nemail_fetcher_agent = create_agent(\n    llm,\n    gmail_tools,\n    system_message=f\"You are an expert at retrieving and organizing email content, with a keen eye for identifying newsletters. Your goal is to Fetch recent newsletter emails from the inbox. Please look for emails with the words 'newsletter' or 'digest' only for last 7 days. Today's date is {datetime.now().strftime('%B %d, %Y')}. Don't add any other unncessary filters. Pass these emails to email_summarizer_agent.\"\n)\n\nemail_fetcher_node = create_agent_node(email_fetcher_agent, \"email_fetcher\")\n\nemail_summarizer_agent = create_agent(\n    llm,\n    tavily_tool,\n    system_message=\"You are an expert in analyzing and summarizing complex information, with a talent for distilling essential points from various sources. Summarize the content of the fetched newsletter emails, highlighting key information and trends. Create a concise yet comprehensive summary highlighting the key points from each newsletter. Use tavily_tool to search for relevant information and include it in the summary if not already included. This summary will be used by email_sender.\"\n)\n\nemail_summarizer_node = create_agent_node(email_summarizer_agent, \"email_summarizer\")\n\nemail_sender_agent = create_agent(\n    llm,\n    gmail_tools,\n    system_message=f\"\"\"\n        \"You are an expert in composing and sending emails with well-formatted, visually appealing content. You have a knack for creating engaging subject lines and structuring information for easy readability. Send the summarized newsletter content using the Gmail API to 0arunabh30@gmail.com with a professional and engaging format.\"\n        \"Use the following structure for the email:\\n\\n\"\n        \"Subject: Your Weekly News Digest - {datetime.now().strftime('%B %d, %Y')}\\n\\n\"\n        \"<h1>Weekly News Digest</h1>\\n\\n\"\n        \"<p>Dear Reader,</p>\\n\\n\"\n        \"<p>Here's your curated summary of this week's top news items and insights:</p>\\n\\n\"\n        \"[Insert summarized content here]\\n\\n\"\n        \"Each main section should be separated by a horizontal rule, like this:\\n\"\n        \"<hr>\\n\\n\"\n        \"Structure the content logically, with clear sections for each summarized newsletter or topic area.\\n\"\n        \"Use appropriate HTML formatting such as <strong> for headlines, \"\n        \"<ul> and <li> for bullet points, and <br> for line breaks to enhance readability.\\n\\n\"\n        \"Include a brief introduction at the beginning to set the context and a conclusion at the end \"\n        \"to summarize the key takeaways and trends observed across the newsletters.\\n\\n\"\n        \"<footer>\\n\"\n        \"<p>For more details on these stories, click on the provided links or stay tuned to our next update. \"\n        \"<p>Best regards,<br>Your Newsletter Summary Team</p>\\n\"\n        \"</footer>\\n\\n\"\n        \"Important: Ensure all HTML tags are properly closed and nested correctly.\"\n    \"\"\"\n)\n\nemail_sender_node = create_agent_node(email_sender_agent, \"email_sender\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Completion with Groq API for Presidential Speech Analysis\nDESCRIPTION: This function uses the Groq API to generate a chat completion based on a user question and relevant speech excerpts. It formats the prompt to include context from presidential speeches and returns a response.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef presidential_speech_chat_completion(client, model, user_question, relevant_excerpts):\n    chat_completion = client.chat.completions.create(\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a presidential historian. Given the user's question and relevant excerpts from presidential speeches, answer the question by including direct quotes from presidential speeches. When using a quote, site the speech that it was from (ignoring the chunk).\" \n            },\n            {\n                \"role\": \"user\",\n                \"content\": \"User Question: \" + user_question + \"\\n\\nRelevant Speech Exerpt(s):\\n\\n\" + relevant_excerpts,\n            }\n        ],\n        model = model\n    )\n    \n    response = chat_completion.choices[0].message.content\n    return response\n\n\npresidential_speech_chat_completion(client, model, user_question, most_relevant_chunk)\n```\n\n----------------------------------------\n\nTITLE: Creating a Scraper Utility Agent with AIXplain\nDESCRIPTION: Initializes a Scraper Utility Agent that gathers insights from travel blogs, review websites, and event listings. It uses a specialized scraper model to identify and summarize recommendations based on user preferences like budget and interests.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nscraper_agent = AgentFactory.create(\n    name= \"Scraper Utility Agent\",\n    description=\"Scrapes travel blogs, review websites, or event listing platforms to gather insights about activities, restaurants, or must-see locations. Summarize and rank recommendations based on user preferences (e.g., budget, interests like food, outdoor activities, etc.).\",\n    tools=[ModelTool(model=\"66f423426eb563fa213a3531\")],\n    llm_id=\"66b270bb6eb56365551e8c71\"\n)\n```\n\n----------------------------------------\n\nTITLE: Processing Bulldog Image with Llama Vision Tool in Python\nDESCRIPTION: Code that processes a bulldog image using the Llama Vision tool. It encodes the image, calls the vision model with available functions, and generates a breed assessment based on the returned data.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nbase64_image = encode_image(image_path)\ndog_breed_json = llama_vision_tool_call(client, model, base64_image, available_functions)\ndog_breed_assessment = assess_dog_breed(client, model, dog_breed_json)\nprint(dog_breed_assessment)\n```\n\n----------------------------------------\n\nTITLE: Building a Gradio Interface for Voice-Powered AI Assistant\nDESCRIPTION: Creates a user interface using Gradio components including text inputs for API key, audio input for voice, text outputs for transcription and AI response, and styling with custom CSS. Includes explanatory UI elements and connects the process_audio function to the interface elements.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/groq-gradio/groq-gradio-tutorial.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Custom CSS for the Groq badge and color scheme (feel free to edit however you wish)\ncustom_css = \"\"\"\n.gradio-container {\n    background-color: #f5f5f5;\n}\n.gr-button-primary {\n    background-color: #f55036 !important;\n    border-color: #f55036 !important;\n}\n.gr-button-secondary {\n    color: #f55036 !important;\n    border-color: #f55036 !important;\n}\n#groq-badge {\n    position: fixed;\n    bottom: 20px;\n    right: 20px;\n    z-index: 1000;\n}\n\"\"\"\n\nwith gr.Blocks(theme=gr.themes.Default()) as demo:\n    gr.Markdown(\"#  Groq x Gradio Voice-Powered AI Assistant\")\n    \n    api_key_input = gr.Textbox(type=\"password\", label=\"Enter your Groq API Key\")\n    \n    with gr.Row():\n        audio_input = gr.Audio(label=\"Speak!\", type=\"numpy\")\n    \n    with gr.Row():\n        transcription_output = gr.Textbox(label=\"Transcription\")\n        response_output = gr.Textbox(label=\"AI Assistant Response\")\n    \n    submit_button = gr.Button(\"Process\", variant=\"primary\")\n    \n    # Add the Groq badge\n    gr.HTML(\"\"\"\n    <div id=\"groq-badge\">\n        <div style=\"color: #f55036; font-weight: bold;\">POWERED BY GROQ</div>\n    </div>\n    \"\"\")\n    \n    submit_button.click(\n        process_audio,\n        inputs=[audio_input, api_key_input],\n        outputs=[transcription_output, response_output]\n    )\n    \n    gr.Markdown(\"\"\"\n    ## How to use this app:\n    1. Enter your Groq API Key in the provided field.\n    2. Click on the microphone icon and speak your message (or forever hold your peace)! You can also provide a supported audio file. Supported audio files include mp3, mp4, mpeg, mpga, m4a, wav, and webm file types.\n    3. Click the \"Process\" button to transcribe your speech and generate a response from our AI assistant.\n    4. The transcription and AI assistant response will appear in the respective text boxes.\n    \n    \"\"\")\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Image Analysis with LLaVA Model\nDESCRIPTION: Function to analyze images using Groq's LLaVA model, supporting both direct image uploads and URLs.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/image_moderation.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef analyze_image(image, prompt, api_key, is_url=False):\n    client = Groq(api_key=api_key)\n\n    if is_url:\n        image_content = {\"type\": \"image_url\", \"image_url\": {\"url\": image}}\n    else:\n        base64_image = encode_image(image)\n        image_content = {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n\n    try:\n        chat_completion = client.chat.completions.create(\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": prompt},\n                        image_content,\n                    ],\n                }\n            ],\n            model=\"llava-v1.5-7b-4096-preview\",\n        )\n        return chat_completion.choices[0].message.content\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Location Agent with Google Places API\nDESCRIPTION: Initializes a Location Agent that provides personalized recommendations for nearby places of interest. It leverages user location data and the Places API by Google to identify landmarks, restaurants, and activity hubs tailored to user preferences.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nlocation_agent = AgentFactory.create(\n    name=\"Location Agent\",\n    description=\" Fetches nearby places of interest such as landmarks, restaurants, or activity hubs based on user-provided locations. Integrates real-time user input, like whether they're traveling with family or solo, to filter results\",\n    tools=[ModelTool(model=\"66f6ac496eb563510e3503d1\")],\n    llm_id=\"66b270bb6eb56365551e8c71\"\n)\n```\n\n----------------------------------------\n\nTITLE: Converting Images to Text Descriptions Using LLaVA Model\nDESCRIPTION: Implements a function that sends a base64-encoded image along with a text prompt to the LLaVA model via the Groq API. The function constructs the proper request format with both text and image content and returns the model's text description of the image.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/dog-picture-storytelling-with-llava.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Define image to text function\ndef image_to_text(client, model, base64_image, prompt):\n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"text\", \"text\": prompt},\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\n                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n                        },\n                    },\n                ],\n            }\n        ],\n        model=model\n    )\n\n    return chat_completion.choices[0].message.content\n\nprompt = \"Describe this image\"\nimage_to_text(client, llava_model, base64_image, prompt)\n```\n\n----------------------------------------\n\nTITLE: Defining Edge Logic for AI Workflow\nDESCRIPTION: Implements the router function to determine the next action based on the current state of the AI workflow. This function helps in managing the flow between different agents and tool calls.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/composio-newsletter-summarizer-agent/composio-groq.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n    last_message = state[\"messages\"][-1]\n    if last_message.tool_calls:\n        return \"call_tool\"\n    if \"FINAL ANSWER\" in last_message.content:\n        return \"__end__\"\n    return \"continue\"\n```\n\n----------------------------------------\n\nTITLE: Content Safety Check with Llama Guard\nDESCRIPTION: Function to assess content safety using Groq's Llama Guard model by analyzing image descriptions.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/image_moderation.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef check_content_safety(image_description, api_key):\n    client = Groq(api_key=api_key)\n\n    try:\n        chat_completion = client.chat.completions.create(\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a content safety classifier. Analyze the given text and determine if it contains any unsafe or inappropriate content.\"},\n                {\"role\": \"user\", \"content\": f\"Please analyze this image description for any unsafe or inappropriate content: {image_description}\"}\n            ],\n            model=\"llama-guard-3-8b\",\n        )\n        return chat_completion.choices[0].message.content\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n```\n\n----------------------------------------\n\nTITLE: Saving Transcription Results to Files in Python\nDESCRIPTION: This function saves transcription results in multiple formats: plain text, full JSON, and segmented JSON. It creates timestamped filenames to prevent overwrites and organizes outputs in a dedicated transcriptions directory.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/audio-chunking/audio_chunking_tutorial.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef save_results(result: dict, audio_path: Path) -> Path:\n    \"\"\"\n    Save transcription results to files.\n    \n    Args:\n        result: Transcription result dictionary\n        audio_path: Original audio file path\n        \n    Returns:\n        base_path: Base path where files were saved\n\n    Raises:\n        IOError: If saving results fails\n    \"\"\"\n    try:\n        output_dir = Path(\"transcriptions\")\n        output_dir.mkdir(exist_ok=True)\n        \n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        base_path = output_dir / f\"{Path(audio_path).stem}_{timestamp}\"\n        \n        # Save results in different formats\n        with open(f\"{base_path}.txt\", 'w', encoding='utf-8') as f:\n            f.write(result[\"text\"])\n        \n        with open(f\"{base_path}_full.json\", 'w', encoding='utf-8') as f:\n            json.dump(result, f, indent=2, ensure_ascii=False)\n        \n        with open(f\"{base_path}_segments.json\", 'w', encoding='utf-8') as f:\n            json.dump(result[\"segments\"], f, indent=2, ensure_ascii=False)\n        \n        print(f\"\\nResults saved to transcriptions folder:\")\n        print(f\"- {base_path}.txt\")\n        print(f\"- {base_path}_full.json\")\n        print(f\"- {base_path}_segments.json\")\n        \n        return base_path\n    \n    except IOError as e:\n        print(f\"Error saving results: {str(e)}\")\n        raise\n```\n\n----------------------------------------\n\nTITLE: LLM Chat Implementation\nDESCRIPTION: Implements chat functionality with the Groq LLM model, including code block extraction and execution.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/e2b-code-interpreting/code-interpreter-python/groq_with_e2b_code_interpreter.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclient = Groq(api_key=GROQ_API_KEY)\n\npattern = re.compile(r\"```python\\n(.*?)\\n```\", re.DOTALL)\n\ndef match_code_blocks(llm_response):\n    match = pattern.search(llm_response)\n    if match:\n        code = match.group(1)\n        print(code)\n        return code\n    return \"\"\n\ndef chat_with_llm(e2b_code_interpreter, user_message):\n    print(f\"\\n{'='*50}\\nUser message: {user_message}\\n{'='*50}\")\n\n    messages = [\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n        {\"role\": \"user\", \"content\": user_message},\n    ]\n\n    response = client.chat.completions.create(\n        model=MODEL_NAME,\n        messages=messages,\n    )\n\n    response_message = response.choices[0].message\n    python_code = match_code_blocks(response_message.content)\n    if python_code != \"\":\n        code_interpreter_results = code_interpret(e2b_code_interpreter, python_code)\n        return code_interpreter_results\n    else:\n        print(f\"Failed to match any Python code in model's response {response_message}\")\n        return []\n```\n\n----------------------------------------\n\nTITLE: Performing Similarity Search on Vector Database\nDESCRIPTION: This code demonstrates how to perform a similarity search on the vector database using a user question. It retrieves the most relevant documents from the entire corpus of presidential speeches.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nuser_question = \"What were James Garfield's views on civil service reform?\"\n\nrelevent_docs = docsearch.similarity_search(user_question)\n```\n\n----------------------------------------\n\nTITLE: Loading Verified SQL Queries from YAML Files in Python\nDESCRIPTION: This function loads verified SQL queries stored in YAML files from a specified directory. It returns a dictionary containing the query names as keys and their contents as values.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-sql/json-mode-function-calling-for-sql.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef get_verified_queries(directory_path):\n    verified_queries_yaml_files = glob.glob(os.path.join(directory_path, '*.yaml'))\n    verified_queries_dict = {}\n    for file in verified_queries_yaml_files:\n        with open(file, 'r') as stream:\n            try:\n                file_name = file[len(directory_path):-5]\n                verified_queries_dict[file_name] = yaml.safe_load(stream)\n            except yaml.YAMLError as exc:\n                continue\n        \n    return verified_queries_dict\n\ndirectory_path = 'verified-queries/'\nverified_queries_dict = get_verified_queries(directory_path)\nverified_queries_dict\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Weather Query Examples with Groq and Instructor\nDESCRIPTION: Python code that uses Groq API with Instructor to generate synthetic examples of weather information requests. It defines the tool schema, creates a client, and calls the API with the custom prompt.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/structured-output-instructor/structured_output_instructor.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# The schema for get_weather_info tool\ntool_schema = {\n    \"name\": \"get_weather_info\",\n    \"description\": \"Get the weather information for any location.\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The location for which we want to get the weather information (e.g. New York)\"\n            }\n        },\n        \"required\": [\"location\"]\n    }\n}\n\n# Patch Groq() with instructor, this is where the magic happens!\nclient = instructor.from_groq(Groq(), mode=instructor.Mode.JSON)\n\n# Call the API with our custom prompt and ResponseModel\nresponse = client.chat.completions.create(\n    model=\"llama-3.1-70b-versatile\",\n    response_model=ResponseModel, # Specify the response model\n    messages=[\n        {\n            \"role\": \"system\", \n            \"content\": prompt.format(json_schema=tool_schema, num=5), # Pass the tool schema and number of examples to the prompt\n        },\n    ],\n    temperature=0.65,\n    max_tokens=8000,\n)\n\nprint(type(response))\npprint(response.examples)\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Evaluation Function for RAG Pipeline in Python\nDESCRIPTION: Defines an asynchronous function 'evaluate' that processes multiple questions and their corresponding document chunks. It runs the RAG pipeline and evaluation chain in batches, returning detailed evaluation results.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import TypedDict\nfrom time import time\n\nclass EvalResult(TypedDict): # For type hinting\n    question: str\n    answer: str\n    context: str\n    score: int # Score between 0 - 10\n    explanation: str # Explanation on why the score was given\n\nasync def evaluate(questions: List[Dict] = questions, texts: List[str] = texts) -> List[EvalResult]:\n    # Prepare inputs\n    batch_rag_inputs: List[Dict] = []\n    evals: List[Dict] = []\n    for q_dict, context in zip(questions, texts): \n        for question in q_dict.values(): \n            batch_rag_inputs.append(question)\n            evals.append({'question': question, 'context': context})\n\n    print(f\"Running RAG pipeline for {len(batch_rag_inputs)} questions\")\n    start = time()\n    answers = await rag_chain.abatch(batch_rag_inputs, config={'max_concurrency': 2}) # Reduce concurrency to avoid hitting rate limits\n    end = time()\n    print(f\"Time taken: {end - start}\")\n\n    # Update eval_input with the answers from the rag_chain\n    for eval_input, answer in zip(evals, answers):\n        eval_input.update({'answer': answer})\n    \n    # Run eval_chain to get evaluation\n    print(f\"Evaluating RAG pipeline...\")\n    start = time()\n    batch_score_explanations = await eval_chain.abatch(evals, config={'max_concurrency': 2}) # Pass in eval which contains List of 'answer', 'context', 'question'\n    end = time()\n    print(f\"Time taken: {end - start}\")\n    \n    # Update eval variable with the score and explanation\n    for eval, score_exp_dict in zip(evals, batch_score_explanations):\n        eval.update({\n            'score': score_exp_dict['score'],\n            'explanation': score_exp_dict['explanation']\n        })\n    \n    return evals\n```\n\n----------------------------------------\n\nTITLE: Processing multiple dog images for batch classification\nDESCRIPTION: Creates a pipeline to process all dog images in a folder, extract structured data from each image, and compile the results into a list of JSON objects.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-image-classification.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimage_folder = 'images/'\nimage_files = [f for f in os.listdir(image_folder) if f.endswith('.png')]\nimage_json_list = []\n\nfor image_file in sorted(image_files):   \n    image_path = image_folder + image_file\n\n    # Encode Image\n    base64_image = encode_image(image_path)\n\n    # Classify image in JSON mode\n    image_json = image_classification(base64_image, user_prompt)\n\n    # Add image file name as a feature\n    image_json['image_file'] = image_file\n\n    # Append to image JSON list\n    image_json_list.append(image_json)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Tools for eCommerce Operations using Airtable API\nDESCRIPTION: This snippet defines three custom functions that interact with the Airtable API: creating an order, getting a product's price, and retrieving a product's ID. These functions serve as tools for the LLM to perform specific eCommerce operations.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Creates an order given a product_id and customer_id\ndef create_order(product_id, customer_id):\n    headers = {\n        \"Authorization\": f\"Bearer {airtable_api_token}\",\n        \"Content-Type\": \"application/json\",\n    }\n    url = f\"https://api.airtable.com/v0/{airtable_base_id}/orders\"\n    order_id = random.randint(1, 100000)  # Randomly assign an order_id\n    order_datetime = datetime.utcnow().strftime(\n        \"%Y-%m-%dT%H:%M:%SZ\"\n    )  # Assign order date as now\n    data = {\n        \"fields\": {\n            \"order_id\": order_id,\n            \"product_id\": product_id,\n            \"customer_id\": customer_id,\n            \"order_date\": order_datetime,\n        }\n    }\n    response = requests.post(url, headers=headers, json=data)\n    return str(response.json())\n\n\n# Gets the price for a product, given the name of the product\ndef get_product_price(product_name):\n    api_token = os.environ[\"AIRTABLE_API_TOKEN\"]\n    base_id = os.environ[\"AIRTABLE_BASE_ID\"]\n    headers = {\"Authorization\": f\"Bearer {airtable_api_token}\"}\n    formula = f\"{{name}}='{product_name}'\"\n    encoded_formula = urllib.parse.quote(formula)\n    url = f\"https://api.airtable.com/v0/{airtable_base_id}/products?filterByFormula={encoded_formula}\"\n    response = requests.get(url, headers=headers)\n    product_price = response.json()[\"records\"][0][\"fields\"][\"price\"]\n    return \"$\" + str(product_price)\n\n\n# Gets product ID given a product name\ndef get_product_id(product_name):\n    api_token = os.environ[\"AIRTABLE_API_TOKEN\"]\n    base_id = os.environ[\"AIRTABLE_BASE_ID\"]\n    headers = {\"Authorization\": f\"Bearer {airtable_api_token}\"}\n    formula = f\"{{name}}='{product_name}'\"\n    encoded_formula = urllib.parse.quote(formula)\n    url = f\"https://api.airtable.com/v0/{airtable_base_id}/products?filterByFormula={encoded_formula}\"\n    response = requests.get(url, headers=headers)\n    product_id = response.json()[\"records\"][0][\"fields\"][\"product_id\"]\n    return str(product_id)\n```\n\n----------------------------------------\n\nTITLE: Monitoring Batch Processing Status in Groq\nDESCRIPTION: Polls the Groq API to check the status of a batch job until it completes. This function makes repeated API calls with a delay between each, tracking the progress of the job.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/batch-processing/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef get_batch_status(api_key, batch_id):\n    url = f\"https://api.groq.com/openai/v1/batches/{batch_id}\"\n    \n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n    \n    response = requests.get(url, headers=headers)\n    return response.json()\n\noutput_file_id = \"\"\ntry:\n    result = get_batch_status(api_key, batch_id)\n    print(\"\\nStep 4 results: \")\n    \n    count = 0\n    while result[\"status\"] != \"completed\" and count < 100:\n        result = get_batch_status(api_key, batch_id)\n        time.sleep(3)\n        print(\"Your batch status is: \" + result[\"status\"])\n        count += 1\n\n    output_file_id = result.get(\"output_file_id\")\n    print(\"This is your output_file_id from Step 4: \" + output_file_id)\nexcept Exception as e:\n    print(f\"Error: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Running Batch Evaluation for RAG Pipeline in Python\nDESCRIPTION: Executes the evaluate function with a subset of questions and texts. This demonstrates how to run the evaluation process on multiple inputs simultaneously.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nevaluations = await evaluate(questions[:5], texts[:5]) # Remove the `:5` to evaluate all the questions on all your data\n```\n\n----------------------------------------\n\nTITLE: Code Interpreter Execution Function\nDESCRIPTION: Implements a function to execute code in the E2B sandbox environment and handle execution results and errors.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/e2b-code-interpreting/code-interpreter-python/groq_with_e2b_code_interpreter.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef code_interpret(e2b_code_interpreter, code):\n    print(\"Running code interpreter...\")\n    exec = e2b_code_interpreter.notebook.exec_cell(\n        code,\n        on_stderr=lambda stderr: print(\"[Code Interpreter]\", stderr),\n        on_stdout=lambda stdout: print(\"[Code Interpreter]\", stdout),\n    )\n\n    if exec.error:\n        print(\"[Code Interpreter ERROR]\", exec.error)\n    else:\n        return exec.results\n```\n\n----------------------------------------\n\nTITLE: Defining System Prompt for Text-To-SQL\nDESCRIPTION: This snippet defines a system prompt that provides context about the database schema, querying tips, and desired JSON output format for the Text-To-SQL implementation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-sql/json-mode-function-calling-for-sql.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = '''\nYou are Groq Advisor, and you are tasked with generating SQL queries for DuckDB based on user questions about data stored in two tables derived from CSV files:\n\nTable: employees.csv\nColumns:\nemployee_id (INTEGER): A unique identifier for each employee.\nname (VARCHAR): The full name of the employee.\nemail (VARCHAR): employee's email address\n\nTable: purchases.csv\nColumns:\npurchase_id (INTEGER): A unique identifier for each purchase.\npurchase_date (DATE): Date of purchase\nemployee_id (INTEGER): References the employee_id from the employees table, indicating which employee made the purchase.\namount (FLOAT): The monetary value of the purchase.\nproduct_name (STRING): The name of the product purchased\n\nGiven a user's question about this data, write a valid DuckDB SQL query that accurately extracts or calculates the requested information from these tables and adheres to SQL best practices for DuckDB, optimizing for readability and performance where applicable.\n\nHere are some tips for writing DuckDB queries:\n* DuckDB syntax requires querying from the .csv file itself, i.e. employees.csv and purchases.csv. For example: SELECT * FROM employees.csv as employees\n* All tables referenced MUST be aliased\n* DuckDB does not implicitly include a GROUP BY clause\n* CURRENT_DATE gets today's date\n* Aggregated fields like COUNT(*) must be appropriately named\n\nAnd some rules for querying the dataset:\n* Never include employee_id in the output - show employee name instead\n\nAlso note that:\n* Valid values for product_name include 'Tesla','iPhone' and 'Humane pin'\n\n\nQuestion:\n--------\n{user_question}\n--------\nReminder: Generate a DuckDB SQL to answer to the question:\n* respond as a valid JSON Document\n* [Best] If the question can be answered with the available tables: {\"sql\": <sql here>}\n* If the question cannot be answered with the available tables: {\"error\": <explanation here>}\n* Ensure that the entire output is returned on only one single line\n* Keep your query as simple and straightforward as possible; do not use subqueries\n'''\n```\n\n----------------------------------------\n\nTITLE: Implementing Longest Common Sequence Algorithm for Audio Chunk Merging in Python\nDESCRIPTION: This function finds the optimal alignment between sequences using the longest common sequence algorithm with sliding window matching. It handles both word-level and character-level matching, uses a weighted scoring system, and is designed to be fault-tolerant to transcription quirks.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/audio-chunking/audio_chunking_tutorial.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef find_longest_common_sequence(sequences: list[str], match_by_words: bool = True) -> str:\n    \"\"\"\n    Find the optimal alignment between sequences with longest common sequence and sliding window matching.\n    \n    Args:\n        sequences: List of text sequences to align and merge\n        match_by_words: Whether to match by words (True) or characters (False)\n        \n    Returns:\n        str: Merged sequence with optimal alignment\n        \n    Raises:\n        RuntimeError: If there's a mismatch in sequence lengths during comparison\n    \"\"\"\n    if not sequences:\n        return \"\"\n\n    # Convert input based on matching strategy\n    if match_by_words:\n        sequences = [\n            [word for word in re.split(r'(\\s+\\w+)', seq) if word]\n            for seq in sequences\n        ]\n    else:\n        sequences = [list(seq) for seq in sequences]\n\n    left_sequence = sequences[0]\n    left_length = len(left_sequence)\n    total_sequence = []\n\n    for right_sequence in sequences[1:]:\n        max_matching = 0.0\n        right_length = len(right_sequence)\n        max_indices = (left_length, left_length, 0, 0)\n\n        # Try different alignments\n        for i in range(1, left_length + right_length + 1):\n            # Add epsilon to favor longer matches\n            eps = float(i) / 10000.0\n\n            left_start = max(0, left_length - i)\n            left_stop = min(left_length, left_length + right_length - i)\n            left = left_sequence[left_start:left_stop]\n\n            right_start = max(0, i - left_length)\n            right_stop = min(right_length, i)\n            right = right_sequence[right_start:right_stop]\n\n            if len(left) != len(right):\n                raise RuntimeError(\n                    \"Mismatched subsequences detected during transcript merging.\"\n                )\n\n            matches = sum(a == b for a, b in zip(left, right))\n            \n            # Normalize matches by position and add epsilon \n            matching = matches / float(i) + eps\n\n            # Require at least 2 matches\n            if matches > 1 and matching > max_matching:\n                max_matching = matching\n                max_indices = (left_start, left_stop, right_start, right_stop)\n\n        # Use the best alignment found\n        left_start, left_stop, right_start, right_stop = max_indices\n        \n        # Take left half from left sequence and right half from right sequence\n        left_mid = (left_stop + left_start) // 2\n        right_mid = (right_stop + right_start) // 2\n        \n        total_sequence.extend(left_sequence[:left_mid])\n        left_sequence = right_sequence[right_mid:]\n        left_length = len(left_sequence)\n\n    # Add remaining sequence\n    total_sequence.extend(left_sequence)\n    \n    # Join back into text\n    if match_by_words:\n        return ''.join(total_sequence)\n    return ''.join(total_sequence)\n```\n\n----------------------------------------\n\nTITLE: Loading, Splitting, and Indexing Text Data for RAG Pipeline\nDESCRIPTION: Loads the downloaded text data, splits it into chunks, and indexes it into a Chroma vectorstore for use in the RAG pipeline.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_chroma import Chroma\nfrom langchain_community.document_loaders import DirectoryLoader, TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# Use popular github repo instead\nloader = DirectoryLoader(\"./data/paul_graham/\", use_multithreading=True, loader_cls=TextLoader)\ntext_splitter = RecursiveCharacterTextSplitter(\n    separators=[\n        \"\\n\\n\", \n        \"\\n\", \n        \" \",\n        \"\",\n        # For multilingual/non-english text\n        # \"\\u200b\",  # Zero-width space\n        # \"\\uff0c\",  # Fullwidth comma\n        # \"\\u3001\",  # Ideographic comma\n        # \"\\uff0e\",  # Fullwidth full stop\n        # \"\\u3002\",  # Ideographic full stop\n    ],\n    chunk_size=3000,\n    chunk_overlap=200,\n    length_function=len,\n    is_separator_regex=False,\n)\ndocuments = loader.load_and_split(text_splitter=text_splitter) # Load text\nvectorstore = Chroma.from_documents(documents, embedding=embed_model, collection_name=\"groq_rag\")\nretriever = vectorstore.as_retriever()\nprint(f\"Documents indexed: {len(documents)}\")\n```\n\n----------------------------------------\n\nTITLE: Executing DuckDB Queries from Verified Query Dictionary in Python\nDESCRIPTION: This function executes a SQL query stored in the verified_queries_dict using DuckDB. It takes a query name and the dictionary of verified queries as input, extracts the SQL, and returns the query result as a DataFrame.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-sql/json-mode-function-calling-for-sql.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef execute_duckdb_query_function_calling(query_name,verified_queries_dict):\n    \n    original_cwd = os.getcwd()\n    os.chdir('data')\n\n    query = verified_queries_dict[query_name]['sql']\n    \n    try:\n        conn = duckdb.connect(database=':memory:', read_only=False)\n        query_result = conn.execute(query).fetchdf().reset_index(drop=True)\n    finally:\n        os.chdir(original_cwd)\n\n    return query_result\n```\n\n----------------------------------------\n\nTITLE: Creating a Multi-Agent Team with TeamAgentFactory\nDESCRIPTION: Code for combining multiple individual agents into a cohesive team agent using TeamAgentFactory. This allows agents to work collaboratively for complex workflows.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom aixplain.factories import TeamAgentFactory\n\nteam_agent = TeamAgentFactory.create(\n    name=\"Travel Agent\",\n    description=\"A comprehensive travel planning system.\",\n    agents=[scraper_agent, location_agent, weather_agent]\n)\n```\n\n----------------------------------------\n\nTITLE: Extracting Structured User Information with Groq and Instructor\nDESCRIPTION: Python code that uses Groq API with Instructor to extract structured user information from text. It defines a Pydantic model for the output structure and ensures the response conforms to this schema.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/structured-output-instructor/structured_output_instructor.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport instructor\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel\nfrom groq import Groq\n\n# Load the Groq API key from .env file\nload_dotenv()\n\n# Describe the desired output schema using pydantic models\nclass UserInfo(BaseModel):\n    name: str\n    age: int\n    email: str\n\n# The text to extract data from\ntext = \"\"\"\nJohn Doe, a 35-year-old software engineer from New York, has been working with large language models for several years.\nHis email address is johndoe@example.com.\n\"\"\"\n\n# Patch Groq() with instructor, this is where the magic happens!\nclient = instructor.from_groq(Groq(), mode=instructor.Mode.JSON)\n\n# Call the API\nuser_info = client.chat.completions.create(\n    model=\"llama-3.1-70b-versatile\",\n    response_model=UserInfo, # Specify the response model\n    messages=[\n        {\"role\": \"system\", \"content\": \"Your job is to extract user information from the given text.\"},\n        {\"role\": \"user\", \"content\": text}\n    ],\n    temperature=0.65,\n)\n\nprint(f\"Name: {user_info.name}\")\nprint(f\"Age: {user_info.age}\")\nprint(f\"Email: {user_info.email}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Dog Facts Retrieval Function\nDESCRIPTION: Defines a function to retrieve dog breed facts from the API Ninjas' Dogs API. The function takes a breed name parameter, constructs an API request, and returns detailed information about the specified dog breed.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef get_dog_facts(breed_name):\n    # Format the API URL with the specific breed name for the API request\n    api_url = 'https://api.api-ninjas.com/v1/dogs?name={}'.format(breed_name)\n    \n    # Perform a GET request to the API with the API key in the headers for authentication\n    response = requests.get(api_url, headers={'X-Api-Key': ninja_api_key})\n    \n    # Check if the response from the server is OK (status code 200)\n    if response.status_code == requests.codes.ok:\n        # Extract the first dog breed match from the response JSON array\n        top_match = response.json()[0] # Multiple top matches may be returned; take the first result\n        return top_match\n    else:\n        # Return an error message with the status code and text if the request was not successful\n        return \"Error:\", response.status_code, response.text\n```\n\n----------------------------------------\n\nTITLE: Testing Historical Stock Price Queries with Function Calling\nDESCRIPTION: Tests the LLM's ability to call the appropriate functions for historical stock price queries. The example shows how the model handles date ranges and multiple stock comparisons, making the correct function calls with appropriate parameters.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama3-stock-market-function-calling/llama3-stock-market-function-calling.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nquery1 = 'Show the historical price of the S&P 500 over the past 3 years? (Today is 4/23/2024)'\nquery2 = 'Compare the price of Google and Amazon throughout 2023'\n\nprint(llm_with_tools.invoke(query1).tool_calls)\nprint(llm_with_tools.invoke(query2).tool_calls)\n```\n\n----------------------------------------\n\nTITLE: Processing Audio and Generating Responses with Groq API\nDESCRIPTION: Function that orchestrates the workflow by taking audio input and an API key, validating the API key, calling the transcription function, and then generating a response based on the transcription.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/groq-gradio/groq-gradio-tutorial.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef process_audio(audio, api_key):\n    if not api_key:\n        return \"Please enter your Groq API key.\", \"API key is required.\"\n    transcription = transcribe_audio(audio, api_key)\n    response = generate_response(transcription, api_key)\n    return transcription, response\n```\n\n----------------------------------------\n\nTITLE: Creating a Prompt Engine Configuration\nDESCRIPTION: Sets up a prompt engine with a template prompt, dynamic input variables, and a defined return format. This creates a reusable prompt configuration that can be referenced later by ID.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/jigsawstack-prompt-engine/jigsawstack-prompt-engine.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nparams = {\n    \"prompt\": \"How to cook {dish}\", #The prompt for your use case\n    \"inputs\": [{ \"key\": \"dish\" }], #dynamic vars that are in the brackets {}\n    \"return_prompt\": [{\n            \"step\": \"name of this step\",\n            \"details\": \"details of this step\",\n    }], #The structure of the JSON, in this case, an array of objects\n}\nresult = jigsaw.prompt_engine.create(params)\n\nprint(result.prompt_engine_id) # prompt engine ID\n```\n\n----------------------------------------\n\nTITLE: Creating a Traced Agent Function with OpenTelemetry\nDESCRIPTION: Implements the main agent function with manual OpenTelemetry instrumentation to group related Groq API calls into a single trace span.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry import trace\nfrom openinference.semconv.trace import SpanAttributes\n\ndef call_agent(question: str):\n    \n    # Here we do a small amount of manual instrumentation to group all the calls our agent makes into a single span.\n    # Phoenix will automatically create spans for each call to Groq, but this allows us to further group them.\n    tracer = trace.get_tracer(__name__)\n    with tracer.start_as_current_span(\"agent\") as span:\n        span.set_attribute(SpanAttributes.OPENINFERENCE_SPAN_KIND, \"AGENT\")\n        span.set_attribute(SpanAttributes.INPUT_VALUE, question)\n        \n        chat_completion = client.chat.completions.create(\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": question,\n                }\n            ],\n            model=\"llama-3.1-8b-instant\",\n            tools=tools,\n            tool_choice=\"auto\",\n        )\n\n\n        message = chat_completion.choices[0].message\n        if message.tool_calls:\n            for tool_call in message.tool_calls:\n                function_name = tool_call.function.name\n                function_args = json.loads(tool_call.function.arguments)\n                \n                if function_name == \"get_current_weather\":\n                    result = get_current_weather(**function_args)\n                elif function_name == \"calculate_age\":\n                    result = calculate_age(**function_args)\n                elif function_name == \"generate_joke\":\n                    result = generate_joke(**function_args)\n                else:\n                    result = f\"Unknown function: {function_name}\"\n                \n                print(f\"Result: {result}\")\n                span.set_attribute(SpanAttributes.OUTPUT_VALUE, str(result))\n        else:\n            print(f\"Message: {message.content}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Load Balancing Between Groq and OpenAI Models\nDESCRIPTION: Defines a load balancing configuration that distributes requests between Groq's Llama 3 70B and OpenAI's GPT-3.5 with a 70-30 weight distribution. This strategy ensures high availability while optimizing performance across providers.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/portkey-openai-to-groq/Switch_from_OpenAI_to_Groq.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconfig = {\n  \"strategy\": {\n      \"mode\": \"loadbalance\",\n  },\n  \"targets\": [\n    {\n      \"virtual_key\": \"groq-431005\", # Groq virtual key\n      \"override_params\": {\"model\": \"llama3-70b-8192\"},\n      \"weight\": 0.7\n    },\n    {\n      \"virtual_key\": \"gpt3-8070a6\", # OpenAI virtual key\n      \"override_params\": {\"model\": \"gpt-3.5-turbo-0125\"},\n      \"weight\": 0.3\n\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Structuring Tools for LLM Function Calling in eCommerce Context\nDESCRIPTION: This snippet defines a list of tools with their descriptions and parameters, allowing the LLM to understand and utilize these custom functions for eCommerce operations like order creation and product information retrieval.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntools = [\n    # First function: create_order\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"create_order\",\n            \"description\": \"Creates an order given a product_id and customer_id. If a product name is provided, you must get the product ID first. After placing the order indicate that it was placed successfully and output the details.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"product_id\": {\n                        \"type\": \"integer\",\n                        \"description\": \"The ID of the product\",\n                    },\n                    \"customer_id\": {\n                        \"type\": \"integer\",\n                        \"description\": \"The ID of the customer\",\n                    },\n                },\n                \"required\": [\"product_id\", \"customer_id\"],\n            },\n        },\n    },\n    # Second function: get_product_price\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_product_price\",\n            \"description\": \"Gets the price for a product, given the name of the product. Just return the price, do not do any calculations.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"product_name\": {\n                        \"type\": \"string\",\n                        \"description\": \"The name of the product (must be title case, i.e. 'Microphone', 'Laptop')\",\n                    }\n                },\n                \"required\": [\"product_name\"],\n            },\n        },\n    },\n    # Third function: get_product_id\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_product_id\",\n            \"description\": \"Gets product ID given a product name\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"product_name\": {\n                        \"type\": \"string\",\n                        \"description\": \"The name of the product (must be title case, i.e. 'Microphone', 'Laptop')\",\n                    }\n                },\n                \"required\": [\"product_name\"],\n            },\n        },\n    },\n]\n```\n\n----------------------------------------\n\nTITLE: Processing Tool Calls and Appending Results\nDESCRIPTION: Processes the tool calls made by the LLM, invokes the corresponding functions, and appends the results to the messages array for further processing.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/parallel-tool-use/parallel-tool-use.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntool_calls = response_message.tool_calls\n\nmessages.append(\n    {\n        \"role\": \"assistant\",\n        \"tool_calls\": [\n            {\n                \"id\": tool_call.id,\n                \"function\": {\n                    \"name\": tool_call.function.name,\n                    \"arguments\": tool_call.function.arguments,\n                },\n                \"type\": tool_call.type,\n            }\n            for tool_call in tool_calls\n        ],\n    }\n)\n\navailable_functions = {\n    \"get_bakery_prices\": get_bakery_prices,\n}\nfor tool_call in tool_calls:\n    function_name = tool_call.function.name\n    function_to_call = available_functions[function_name]\n    function_args = json.loads(tool_call.function.arguments)\n    function_response = function_to_call(**function_args)\n\n    # Note how we create a separate tool call message for each tool call\n    # The model is able to discern the tool call result through `tool_call_id`\n    messages.append(\n        {\n            \"role\": \"tool\",\n            \"content\": json.dumps(function_response),\n            \"tool_call_id\": tool_call.id,\n        }\n    )\n\nprint(json.dumps(messages, indent=2))\n```\n\n----------------------------------------\n\nTITLE: Implementing MLB Data Collection Tools\nDESCRIPTION: Defines three specialized functions for retrieving MLB game data: game information, batting statistics, and pitching statistics using the MLB-Stats API.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/Mixture-of-Agents-Agno-Groq.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef get_game_info(game_date: str, team_name: str) -> str:\n    \"\"\"Gets high-level information on an MLB game.\n    \n    Params:\n    game_date: The date of the game of interest, in the form \"yyyy-mm-dd\". \n    team_name: MLB team name. Both full name (e.g. \"New York Yankees\") or nickname (\"Yankees\") are valid. If multiple teams are mentioned, use the first one\n    \"\"\"\n    sched = statsapi.schedule(start_date=game_date,end_date=game_date)\n    sched_df = pd.DataFrame(sched)\n    game_info_df = sched_df[sched_df['summary'].str.contains(team_name, case=False, na=False)]\n\n    game_info = {\n        \"game_id\": str(game_info_df.game_id.tolist()[0]),\n        \"home_team\": game_info_df.home_name.tolist()[0],\n        \"home_score\": game_info_df.home_score.tolist()[0],\n        \"away_team\": game_info_df.away_name.tolist()[0],\n        \"away_score\": game_info_df.away_score.tolist()[0],\n        \"winning_team\": game_info_df.winning_team.tolist()[0],\n        \"series_status\": game_info_df.series_status.tolist()[0]\n    }\n\n    return json.dumps(game_info)\n\n\ndef get_batting_stats(game_id: str) -> str:\n    \"\"\"Gets player boxscore batting stats for a particular MLB game\n    \n    Params:\n    game_id: The 6-digit ID of the game\n    \"\"\"\n    boxscores=statsapi.boxscore_data(game_id)\n    player_info_df = pd.DataFrame(boxscores['playerInfo']).T.reset_index()\n\n    away_batters_box = pd.DataFrame(boxscores['awayBatters']).iloc[1:]\n    away_batters_box['team_name'] = boxscores['teamInfo']['away']['teamName']\n\n    home_batters_box = pd.DataFrame(boxscores['homeBatters']).iloc[1:]\n    home_batters_box['team_name'] = boxscores['teamInfo']['home']['teamName']\n\n    batters_box_df = pd.concat([away_batters_box, home_batters_box]).merge(player_info_df, left_on = 'name', right_on = 'boxscoreName')\n    batting_stats = batters_box_df[['team_name','fullName','position','ab','r','h','hr','rbi','bb','sb']].to_dict(orient='records')\n\n    return json.dumps(batting_stats)\n\n\ndef get_pitching_stats(game_id: str) -> str:\n    \"\"\"Gets player boxscore pitching stats for a particular MLB game\n    \n    Params:\n    game_id: The 6-digit ID of the game\n    \"\"\"\n    boxscores=statsapi.boxscore_data(game_id)\n    player_info_df = pd.DataFrame(boxscores['playerInfo']).T.reset_index()\n\n    away_pitchers_box = pd.DataFrame(boxscores['awayPitchers']).iloc[1:]\n    away_pitchers_box['team_name'] = boxscores['teamInfo']['away']['teamName']\n\n    home_pitchers_box = pd.DataFrame(boxscores['homePitchers']).iloc[1:]\n    home_pitchers_box['team_name'] = boxscores['teamInfo']['home']['teamName']\n\n    pitchers_box_df = pd.concat([away_pitchers_box,home_pitchers_box]).merge(player_info_df, left_on = 'name', right_on = 'boxscoreName')\n    pitching_stats = pitchers_box_df[['team_name','fullName','ip','h','r','er','bb','k','note']].to_dict(orient='records')\n\n    return json.dumps(pitching_stats)\n```\n\n----------------------------------------\n\nTITLE: Running the Audio Transcription Pipeline in Python\nDESCRIPTION: This is the main execution block that runs the transcription pipeline. It calls the transcribe_audio_in_chunks function with a specified audio file path to process and transcribe long audio files.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/audio-chunking/audio_chunking_tutorial.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    transcribe_audio_in_chunks(Path(\"path_to_your_audio\"))\n```\n\n----------------------------------------\n\nTITLE: Merging Transcription Segments in Python\nDESCRIPTION: This function merges transcription segments from chunked audio processing. It handles both dictionary and object-based segments, preserves timestamps, and aggregates text while maintaining chronological order. The function also supports word-level timestamps if available.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/audio-chunking/audio_chunking_tutorial.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n        merged_segment.update({\n            'text': merged_text,\n            'end': first_segment.get('end', 0) if isinstance(first_segment, dict) else getattr(first_segment, 'end', 0)\n        })\n        final_segments.append(merged_segment)\n    \n    # Add all segments from last chunk\n    if processed_chunks and processed_chunks[-1]:\n        final_segments.extend(processed_chunks[-1])\n    \n    # Create final transcription\n    final_text = ' '.join(\n        segment.get('text', '') if isinstance(segment, dict) else getattr(segment, 'text', '')\n        for segment in final_segments\n    )\n    \n    # Create result with both segments and words (if available)\n    result = {\n        \"text\": final_text,\n        \"segments\": final_segments\n    }\n    \n    # Include word-level timestamps if available\n    if has_words:\n        result[\"words\"] = words\n    \n    return result\n```\n\n----------------------------------------\n\nTITLE: Setting Up RAG Pipeline with LangChain Components\nDESCRIPTION: Creates a RAG pipeline using LangChain components, including a custom prompt template, document formatter, and chain composition.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_core.documents import Document\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\nfrom typing import List, Dict\n\nRAG_SYSTEM_PROMPT = \"\"\"\nYou are an assistant for question-answering tasks. \\\nUse the following pieces of retrieved context given within delimiters to answer the human's questions.\n```\n{context}\n```\nIf you don't know the answer, just say that you don't know.\\\n\"\"\" # adapted from https://smith.langchain.com/hub/rlm/rag-prompt-llama3\n\nRAG_HUMAN_PROMPT = \"{input}\"\n\nRAG_PROMPT = ChatPromptTemplate.from_messages([\n    (\"system\", RAG_SYSTEM_PROMPT),\n    (\"human\", RAG_HUMAN_PROMPT)\n])\n\ndef format_docs(docs: List[Document]):\n    \"\"\"Format the retrieved documents\"\"\"\n    return \"\\n\".join(doc.page_content for doc in docs)\n\nrag_chain = (\n    {\n        \"context\": retriever | format_docs, # Use retriever to retrieve docs from vectorstore -> format the documents into a string\n        \"input\": RunnablePassthrough() # Propogate the 'input' variable to the next step\n    } \n    | RAG_PROMPT # format prompt with 'context' and 'input' variables\n    | rag_llm # get response from LLM using the formatteed prompt\n    | StrOutputParser() # Parse through LLM response to get only the string response\n\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Stream Function\nDESCRIPTION: Function to handle chat interactions with the mixture of agents, processing queries through multiple cycles and returning streamed responses.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/mixture-of-agents/mixture_of_agents.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef chat_stream(query: str) -> Generator[str, None, None]:\n    llm_inp = {\n    'input': query,\n    'messages': CHAT_MEMORY.load_memory_variables({})['messages'],\n    'helper_response': \"\"\n    }\n    for _ in range(CYCLES):\n        llm_inp = {\n            'input': query,\n            'messages': CHAT_MEMORY.load_memory_variables({})['messages'],\n            'helper_response': LAYER_AGENT.invoke(llm_inp)\n        }\n\n    response = \"\"\n    for chunk in MAIN_AGENT.stream(llm_inp):\n        yield chunk\n        response += chunk\n    \n    CHAT_MEMORY.save_context({'input': query}, {'output': response})\n```\n\n----------------------------------------\n\nTITLE: Executing Groq Chat Completion with JSON Mode\nDESCRIPTION: Implementation of chat completion using Groq API with JSON mode enabled to process clinical notes.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/json-mode-social-determinants-of-health/SDOH-Json-mode.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Establish client with GROQ_API_KEY environment variable\nclient = Groq(api_key=os.getenv('GROQ_API_KEY'))\nmodel = \"llama3-8b-8192\"\n\n# Create chat completion object with JSON response format\nchat_completion = client.chat.completions.create(\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": system_prompt\n        },\n        {\n            \"role\": \"user\",\n            \"content\": user_prompt_template.format(clinical_note=clinical_note),\n        }\n    ],\n    model = model,\n    response_format = {\"type\": \"json_object\"} # Add this response format to configure JSON mode\n)\n\nsocial_determinants_json_string = chat_completion.choices[0].message.content\nprint(social_determinants_json_string)\n```\n\n----------------------------------------\n\nTITLE: Defining Stock Information Tool for LangChain\nDESCRIPTION: Creates a LangChain tool that retrieves current stock information using the yfinance API. The tool accepts a stock symbol and a specific data key, and includes a comprehensive description of all available data keys to guide the LLM in making correct function calls.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama3-stock-market-function-calling/llama3-stock-market-function-calling.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_core.tools import tool\n\n@tool\ndef get_stock_info(symbol, key):\n    '''Return the correct stock info value given the appropriate symbol and key. Infer valid key from the user prompt; it must be one of the following:\n\n    address1, city, state, zip, country, phone, website, industry, industryKey, industryDisp, sector, sectorKey, sectorDisp, longBusinessSummary, fullTimeEmployees, companyOfficers, auditRisk, boardRisk, compensationRisk, shareHolderRightsRisk, overallRisk, governanceEpochDate, compensationAsOfEpochDate, maxAge, priceHint, previousClose, open, dayLow, dayHigh, regularMarketPreviousClose, regularMarketOpen, regularMarketDayLow, regularMarketDayHigh, dividendRate, dividendYield, exDividendDate, beta, trailingPE, forwardPE, volume, regularMarketVolume, averageVolume, averageVolume10days, averageDailyVolume10Day, bid, ask, bidSize, askSize, marketCap, fiftyTwoWeekLow, fiftyTwoWeekHigh, priceToSalesTrailing12Months, fiftyDayAverage, twoHundredDayAverage, currency, enterpriseValue, profitMargins, floatShares, sharesOutstanding, sharesShort, sharesShortPriorMonth, sharesShortPreviousMonthDate, dateShortInterest, sharesPercentSharesOut, heldPercentInsiders, heldPercentInstitutions, shortRatio, shortPercentOfFloat, impliedSharesOutstanding, bookValue, priceToBook, lastFiscalYearEnd, nextFiscalYearEnd, mostRecentQuarter, earningsQuarterlyGrowth, netIncomeToCommon, trailingEps, forwardEps, pegRatio, enterpriseToRevenue, enterpriseToEbitda, 52WeekChange, SandP52WeekChange, lastDividendValue, lastDividendDate, exchange, quoteType, symbol, underlyingSymbol, shortName, longName, firstTradeDateEpochUtc, timeZoneFullName, timeZoneShortName, uuid, messageBoardId, gmtOffSetMilliseconds, currentPrice, targetHighPrice, targetLowPrice, targetMeanPrice, targetMedianPrice, recommendationMean, recommendationKey, numberOfAnalystOpinions, totalCash, totalCashPerShare, ebitda, totalDebt, quickRatio, currentRatio, totalRevenue, debtToEquity, revenuePerShare, returnOnAssets, returnOnEquity, freeCashflow, operatingCashflow, earningsGrowth, revenueGrowth, grossMargins, ebitdaMargins, operatingMargins, financialCurrency, trailingPegRatio\n    \n    If asked generically for 'stock price', use currentPrice\n    '''\n    data = yf.Ticker(symbol)\n    stock_info = data.info\n    return stock_info[key]\n```\n\n----------------------------------------\n\nTITLE: Creating a Dog Breed Assessment Function Using Llama 3.2 in Python\nDESCRIPTION: A function that takes dog breed JSON data and uses Llama 3.2 to generate a written assessment of the breed. It formats a prompt with detailed field descriptions and sends it to the model for processing.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef assess_dog_breed(client, model, dog_breed_json):\n\n    user_message = f\"\"\"\n    Write an assessment of this dog breed given the JSON info provided; below is a description of the fields in the JSON:\n    \n    {dog_breed_json}\n    \n    Description:\n    \n    1. Shedding:\n       - Description: How much hair the breed sheds.\n       - Possible values: 1 to 5 (where 1 indicates no shedding and 5 indicates maximum shedding).\n    \n    2. Barking:\n       - Description: How vocal the breed is.\n       - Possible values: 1 to 5 (where 1 indicates minimal barking and 5 indicates maximum barking).\n    \n    3. Energy:\n       - Description: How much energy the breed has.\n       - Possible values: 1 to 5 (where 1 indicates low energy and 5 indicates high energy).\n    \n    4. Protectiveness:\n       - Description: How likely the breed is to alert strangers.\n       - Possible values: 1 to 5 (where 1 indicates minimal alerting and 5 indicates maximum alerting).\n    \n    5. Trainability:\n       - Description: How easy it is to train the breed.\n       - Possible values: 1 to 5 (where 1 indicates the breed is very difficult to train and 5 indicates the breed is very easy to train).\n    \n    6. Name:\n       - Description: The name of the breed.\n    \n    7. Min Height:\n       - Description: Minimum height in inches.\n    \n    8. Max Height:\n       - Description: Maximum height in inches.\n    \n    9. Min Weight:\n       - Description: Minimum weight in pounds.\n    \n    10. Max Weight:\n       - Description: Maximum weight in pounds.\n    \n    11. Min Life Expectancy:\n       - Description: Minimum life expectancy in years.\n    \n    12. Max Life Expectancy:\n       - Description: Maximum life expectancy in years.\n    \n    (do not mention the JSON data, just use it to inform your response)\n    \"\"\"\n    \n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": user_message\n            }\n        ],\n        model=model\n    )\n    \n    return chat_completion.choices[0].message.content\n\ndog_breed_assessment = assess_dog_breed(client, model, dog_breed_json)\nprint(dog_breed_assessment)\n```\n\n----------------------------------------\n\nTITLE: Implementing MLB Player Batting Statistics Retrieval Tool\nDESCRIPTION: Creates a tool function to fetch detailed player batting statistics for a specific MLB game. This function queries the MLB-Stats API to retrieve batter performance metrics from the boxscore data including at-bats, runs, hits, and other key statistics.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@tool \ndef get_batting_stats(game_id: str) -> str:\n    \"\"\"Gets player boxscore batting stats for a particular MLB game\n    \n    Params:\n    game_id: The 6-digit ID of the game\n    \"\"\"\n    boxscores=statsapi.boxscore_data(game_id)\n    player_info_df = pd.DataFrame(boxscores['playerInfo']).T.reset_index()\n\n    away_batters_box = pd.DataFrame(boxscores['awayBatters']).iloc[1:]\n    away_batters_box['team_name'] = boxscores['teamInfo']['away']['teamName']\n\n    home_batters_box = pd.DataFrame(boxscores['homeBatters']).iloc[1:]\n    home_batters_box['team_name'] = boxscores['teamInfo']['home']['teamName']\n\n    batters_box_df = pd.concat([away_batters_box, home_batters_box]).merge(player_info_df, left_on = 'name', right_on = 'boxscoreName')\n    return str(batters_box_df[['team_name','fullName','position','ab','r','h','hr','rbi','bb','sb']])\n```\n\n----------------------------------------\n\nTITLE: Creating Word-by-Word Subtitle Clips with MoviePy\nDESCRIPTION: Generates individual TextClip objects for each word in the transcription, with precise timing based on the start and end timestamps from the Whisper API.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/instagram-reel-subtitler/subtitler-tutorial.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef add_subtitles(verbose_json, width, fontsize):\n    text_clips = []\n\n    for segment in verbose_json:\n        text_clips.append(\n            TextClip(text=segment[\"word\"],\n                     font_size=fontsize,\n                     stroke_width=5, \n                     stroke_color=\"black\", \n                     font=\"./Roboto-Condensed-Bold.otf\",\n                     color=\"white\",\n                     size=(width, None),\n                     method=\"caption\",\n                     text_align=\"center\",\n                     margin=(30, 0)\n                     )\n            .with_start(segment[\"start\"])\n            .with_end(segment[\"end\"])   \n            .with_position(\"center\")\n        )\n    return text_clips\n```\n\n----------------------------------------\n\nTITLE: Processing Multiple Speeches for Vector Database Storage\nDESCRIPTION: This code processes all speeches in the dataset, splitting them into chunks and creating Document objects. It prepends metadata to each chunk for context and prepares them for storage in a vector database.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndocuments = []\nfor index, row in presidential_speeches_df[presidential_speeches_df['Transcript'].notnull()].iterrows():\n    chunks = text_splitter.split_text(row.Transcript)\n    total_chunks = len(chunks)\n    for chunk_num in range(1,total_chunks+1):\n        header = f\"Date: {row['Date']}\\nPresident: {row['President']}\\nSpeech Title: {row['Speech Title']} (chunk {chunk_num} of {total_chunks})\\n\\n\"\n        chunk = chunks[chunk_num-1]\n        documents.append(Document(page_content=header + chunk, metadata={\"source\": \"local\"}))\n\nprint(len(documents))\n```\n\n----------------------------------------\n\nTITLE: Creating a Batch Processing Job in Groq\nDESCRIPTION: Creates a batch processing job using the previously uploaded file. This function specifies the endpoint for processing and sets a completion window of 24 hours.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/batch-processing/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef create_batch(api_key, input_file_id):\n    url = \"https://api.groq.com/openai/v1/batches\"\n    \n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n    \n    data = {\n        \"input_file_id\": input_file_id,\n        \"endpoint\": \"/v1/chat/completions\",\n        \"completion_window\": \"24h\"\n    }\n    \n    response = requests.post(url, headers=headers, json=data)\n    return response.json()\n\nbatch_id = \"\"\ntry:\n    result = create_batch(api_key, file_id)\n    batch_id = result[\"id\"]\n    print(\"This is the Batch object id from Step 3: \" + batch_id)\nexcept Exception as e:\n    print(f\"Error: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Making a basic vision model request with Llama 3.2\nDESCRIPTION: Demonstrates how to make a basic image analysis request to the Llama 3.2 Vision model using the Groq API, passing both the encoded image and a text prompt.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-image-classification.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt = 'Tell me about this image'\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n                    },\n                },\n                {\"type\": \"text\", \"text\": user_prompt},\n            ],\n        }\n    ],\n    model=model\n)\n\nprint(chat_completion.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Invoking the AI Newsletter Assistant Workflow\nDESCRIPTION: Executes the compiled AI workflow by invoking it with an initial human message. This starts the process of fetching, summarizing, and sending newsletter digests.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/composio-newsletter-summarizer-agent/composio-groq.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Invoke the graph!\n\nevents = app.invoke(\n    {\n        \"messages\": [\n            HumanMessage(\n                content=\"\"\n                \"Please begin.\"\n            )\n        ],\n    },\n)\n\nprint(events)\n```\n\n----------------------------------------\n\nTITLE: Creating a Single Agent with AgentFactory\nDESCRIPTION: Example of creating a single agent using aiXplain's AgentFactory. The snippet demonstrates how to specify a name, description, tools, and optionally an LLM ID to enhance agent performance.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom aixplain.factories import AgentFactory\n\nscraper_agent = AgentFactory.create(\n    name=\"Scraper Utility Agent\",\n    description=\"Gathers travel insights based on user preferences.\",\n    tools=[...],\n    llm_id=\"...\"\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Question Generation Chain for Evaluation Dataset\nDESCRIPTION: Sets up a chain to generate questions from document chunks for creating an evaluation dataset, using structured output and JSON formatting.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Create questions for eval pipeline\nfrom typing import TypedDict\n# Response object structure\nclass QAResponse(TypedDict):\n    question_1: str\n    question_2: str\n    question_3: str\n\nQA_HUMAN_PROMPT = \"\"\"\nYou are a Teacher/ Professor. Your task is to setup questions for an upcoming \\\nquiz/examination. The questions should be diverse in nature across the document. \\\nGiven the context information and not prior knowledge, generate only questions based on the below context. \\\nRestrict the questions to the context information provided within the delimiters.\n```\n{text}\n```\nOutput the questions in JSON format with the keys question_1, question_2 and question_3 \\\nand make sure to escape any special characters to output clean, valid JSON.\\\n\"\"\" # adapted from https://arize.com/blog/evaluate-rag-with-llm-evals-and-benchmarking/\n\nQA_PROMPT = ChatPromptTemplate.from_messages([\n    (\"human\", QA_HUMAN_PROMPT)\n])\n\nqa_chain = (\n{\"text\": RunnablePassthrough()}\n| QA_PROMPT\n| qa_llm.with_structured_output(method='json_mode', schema=QAResponse) # either 'json_mode' or 'function_calling' to get responses always in JSON format\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Responses with Groq's Llama 3 70B Model\nDESCRIPTION: Function to generate responses using Groq's Llama 3 70B model. Takes the transcribed text from the audio, sends it to the Groq API for text generation, and returns the AI-generated response.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/groq-gradio/groq-gradio-tutorial.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef generate_response(transcription, api_key):\n    if not transcription:\n        return \"No transcription available. Please try speaking again.\"\n    \n    client = groq.Client(api_key=api_key)\n    \n    try:\n        # Use Llama 3 70B powered by Groq for text generation\n        completion = client.chat.completions.create(\n            model=\"llama3-70b-8192\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n                {\"role\": \"user\", \"content\": transcription}\n            ],\n        )\n        return completion.choices[0].message.content\n    except Exception as e:\n        return f\"Error in response generation: {str(e)}\"\n```\n\n----------------------------------------\n\nTITLE: Executing DuckDB Query Function\nDESCRIPTION: This function executes a given DuckDB SQL query on the specified CSV files and returns the result as a pandas DataFrame.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-sql/json-mode-function-calling-for-sql.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef execute_duckdb_query(query):\n    original_cwd = os.getcwd()\n    os.chdir('data')\n    \n    try:\n        conn = duckdb.connect(database=':memory:', read_only=False)\n        query_result = conn.execute(query).fetchdf().reset_index(drop=True)\n    finally:\n        os.chdir(original_cwd)\n\n\n    return query_result\n```\n\n----------------------------------------\n\nTITLE: Weather Tool JSON Schema Definition\nDESCRIPTION: JSON schema for a weather information tool that requires a location parameter. This schema defines the structure and constraints for the tool's input parameters.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/structured-output-instructor/structured_output_instructor.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\": \"get_weather_info\",\n    \"description\": \"Get the weather information for any location.\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The location for which we want to get the weather information (e.g., New York)\" \n            }\n        },\n        \"required\": [\"location\"]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Functions for Groq Agent\nDESCRIPTION: Defines the tool functions and tool definitions that the Groq agent can use: joke generation, weather lookup, and age calculation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\ndef generate_joke():\n    \"\"\"Generate a simple joke.\"\"\"\n    try:\n        response = client.chat.completions.create(\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": \"Generate a simple joke\",\n                }\n            ],\n            model=\"llama-3.1-8b-instant\",\n        )\n        response = response.choices[0].message.content\n    except Exception as e:\n        print(f\"Error generating joke: {e}\")\n        response =  \"Error: Could not generate joke.\"\n    return response\n\ndef get_current_weather(location: str):\n    \"\"\"Get the current weather for a given location.\"\"\"\n    # This is a mock function. In a real scenario, you'd call a weather API.\n    return json.dumps({\"location\": location, \"temperature\": \"22C\", \"condition\": \"Sunny\"})\n\ndef calculate_age(birth_year: int):\n    \"\"\"Calculate age based on birth year.\"\"\"\n    from datetime import datetime\n    current_year = datetime.now().year\n    return current_year - birth_year\n\n# Define the tools\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"generate_joke\",\n            \"description\": \"Generate a simple joke\",\n            \"parameters\": {\"type\": \"object\", \"properties\": {}}\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_current_weather\",\n            \"description\": \"Get the current weather for a location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\"}\n                },\n                \"required\": [\"location\"]\n            }\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"calculate_age\",\n            \"description\": \"Calculate age based on birth year\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"birth_year\": {\"type\": \"integer\", \"description\": \"The year of birth\"}\n                },\n                \"required\": [\"birth_year\"]\n            }\n        }\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Running Evaluations on Trace Data\nDESCRIPTION: Applies the evaluation function to each trace in the dataset and adds columns for the explanation, label, and numeric score.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nspans_df['explanation'], spans_df['label'] = zip(*spans_df.apply(evaluate_row, axis=1))\nspans_df['score'] = spans_df['label'].apply(lambda x: 1 if x == 'VALID' else 0)\nspans_df.head()\n```\n\n----------------------------------------\n\nTITLE: Loading Processed Data to BigQuery using SQLAlchemy in Python\nDESCRIPTION: This code snippet demonstrates how to load the processed social determinants of health data into a BigQuery database using SQLAlchemy. It appends the results to a pre-existing table in the 'clinical' dataset.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/json-mode-social-determinants-of-health/SDOH-Json-mode.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Append results to a pre-existing BigQuery table\nclient = bigquery.Client()\nsdoh_df.to_gbq('clinical.social_determinants',client.project,credentials=client._credentials,if_exists='append')\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq Client and Setting Up Environment Variables for eCommerce LLM\nDESCRIPTION: This snippet sets up the Groq client, specifies the LLM model, and initializes environment variables for Airtable API integration. It prepares the necessary components for the eCommerce function calling implementation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Setup\nimport json\nimport os\nimport random\nimport urllib.parse\nfrom datetime import datetime\n\nimport requests\nfrom groq import Groq\n\n# Initialize Groq client and model\nclient = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\nMODEL = \"llama-3.3-70b-versatile\"\n\n# Airtable variables\nairtable_api_token = os.environ[\"AIRTABLE_API_TOKEN\"]\nairtable_base_id = os.environ[\"AIRTABLE_BASE_ID\"]\n```\n\n----------------------------------------\n\nTITLE: Running an Interactive Chat Task with Groq and Langroid\nDESCRIPTION: Simple code to create and run an interactive chat loop using a Langroid Task with a configured agent. This creates a basic chatbot powered by a Groq LLM.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/langroid-llm-agents/README.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntask = lr.Task(agent, interactive=True)\ntask.run()\n```\n\n----------------------------------------\n\nTITLE: Defining Evaluation Response Structure for RAG Pipeline\nDESCRIPTION: Sets up the structure for evaluation responses, including a score and explanation, and defines the prompt for the evaluation process.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\n# Response object structure\nclass EvalResponse(BaseModel):\n    score: int\n    explanation: str\n\nEVAL_HUMAN_PROMPT = \"\"\"\nYou are given a question, an answer and reference text within marked delimiters. \\\nYou must determine whether the given answer correctly answers the question based on the reference text. Here is the data:\n```Question\n{question}\n```\n```Reference\n{context}\n```\n```Answer\n{answer}\n```\nRespond with a valid JSON object containing two fields:\n{{\n    \"score\": \"int: a score between 0-10, 10 being highest, on whether the question is correctly and fully answered by the answer\",\n    \"explanation\": \"str: Provide an explanation as to why the score was given.\"\n}} \nMake sure to escape any special characters to output clean, valid JSON.\\\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Calling Llama Vision Tool with an Image to Get Dog Breed Information in Python\nDESCRIPTION: Code that calls the Llama 3.2 Vision model with a base64-encoded image and available functions to identify a dog breed and get information about it. The response is stored in dog_breed_json and printed.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndog_breed_json = llama_vision_tool_call(client, model, base64_image, available_functions)\nprint(dog_breed_json)\n```\n\n----------------------------------------\n\nTITLE: Image Processing Pipeline\nDESCRIPTION: Main function to handle image processing workflow, combining image analysis and safety checking.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/image_moderation.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef process_image(image, url, prompt, api_key):\n    if image is not None:\n        return analyze_image(image, prompt, api_key), check_content_safety(analyze_image(image, prompt, api_key), api_key)\n    elif url:\n        try:\n            response = requests.get(url)\n            image = Image.open(io.BytesIO(response.content))\n            return analyze_image(url, prompt, api_key, is_url=True), check_content_safety(analyze_image(url, prompt, api_key, is_url=True), api_key)\n        except:\n            return \"Invalid image URL. Please provide a direct link to an image.\", \"\"\n    else:\n        return \"Please provide an image to analyze.\", \"\"\n```\n\n----------------------------------------\n\nTITLE: Expanding JSON output schema for comprehensive image analysis\nDESCRIPTION: Enhances the JSON schema to extract multiple dog characteristics from images, including breed, color, size, activity, and environment.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-image-classification.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt = '''\nYour job is to extract structured data from an image of dogs and output the structured data in JSON.\nThe JSON schema should strictly be the following:\n  {\n    \"dog_breed\": \"string (e.g., 'Golden Retriever', 'German Shepherd', 'Mixed')\",\n    \"dog_color\": \"string (categorical: 'Black', 'White', 'Brown', 'Golden', 'Multiple')\",\n    \"number_of_dogs\": \"integer (number of dogs in the image)\",\n    \"puppies_present\": \"boolean (TRUE if there are puppies in the image)\",\n    \"dog_size\": \"string (categorical: 'Toy', 'Small', 'Medium', 'Large')\",\n    \"is_pet\": \"boolean (True if the dog is a pet, False if it might be a wild animal like a wolf or coyote)\",\n    \"dog_activity\": \"string (categorical: 'Sitting', 'Standing', 'Running', 'Playing', 'Sleeping')\",\n    \"background_environment\": \"string (categorical: 'Indoors', 'Outdoors', 'Park', 'Beach', 'Forest')\",\n    \"dog_accessories\": \"string (accessories or items the dog is wearing or carrying, e.g., 'Collar', 'Leash', 'Bandana', 'Toy', 'Stick', 'Ball', 'None')\"\n  } \n  \nUse the information from the following dog photo to construct the proper JSON output.\n'''\n\nimage_json = image_classification(base64_image, user_prompt)\nimage_json\n```\n\n----------------------------------------\n\nTITLE: Executing MLB Game Recap Generation Pipeline\nDESCRIPTION: Orchestrates the execution flow of multiple agents to generate the final game recap. Includes gathering game information, statistical analysis, multiple writer perspectives, and final editing.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/Mixture-of-Agents-Agno-Groq.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ngame_information = mlb_researcher.run(user_prompt, stream=False)\nprint(game_information)\n\nbatting_stats  = mlb_batting_statistician.run(game_information, stream=False)\npitching_stats = mlb_pitching_statistician.run(game_information, stream=False)\n\nstats = f\"Statistical summaries for the game:\\n\\nBatting stats:\\n{batting_stats}\\n\\nPitching stats:\\n{pitching_stats}\"\nllama_writer   = mlb_writer_llama.run(stats, stream=False)\ngemma_writer   = mlb_writer_gemma.run(stats, stream=False)\nmixtral_writer = mlb_writer_mixtral.run(stats, stream=False)\n\n# Edit final outputs\neditor_inputs = [llama_writer, gemma_writer, mixtral_writer]\neditor = mlb_editor.run(\"\\n\".join(editor_inputs), stream=False)\n\nprint(editor)\n```\n\n----------------------------------------\n\nTITLE: Making API Requests to Groq using Node.js with Axios\nDESCRIPTION: This example demonstrates how to interact with the Groq API using Node.js with the Axios HTTP client library. It shows proper error handling and response processing patterns.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nconst axios = require('axios');\nrequire('dotenv').config(); // If using dotenv for environment variables\n\n// Get API key from environment\nconst apiKey = process.env.GROQ_API_KEY;\n\n// API endpoint\nconst url = 'https://api.groq.com/openai/v1/chat/completions';\n\n// Request headers\nconst headers = {\n  'Authorization': `Bearer ${apiKey}`,\n  'Content-Type': 'application/json'\n};\n\n// Request payload\nconst payload = {\n  model: 'llama2-70b-4096',\n  messages: [\n    {role: 'system', content: 'You are a helpful assistant.'},\n    {role: 'user', content: 'What is the capital of France?'}\n  ],\n  temperature: 0.7,\n  max_tokens: 100\n};\n\n// Make the request using axios\nasync function makeRequest() {\n  try {\n    const response = await axios.post(url, payload, { headers });\n    const assistantMessage = response.data.choices[0].message.content;\n    console.log(assistantMessage);\n  } catch (error) {\n    if (error.response) {\n      // The request was made and the server responded with a status code\n      // that falls out of the range of 2xx\n      console.error('Error response:', error.response.data);\n      console.error('Status code:', error.response.status);\n    } else if (error.request) {\n      // The request was made but no response was received\n      console.error('No response received:', error.request);\n    } else {\n      // Something happened in setting up the request that triggered an Error\n      console.error('Error setting up request:', error.message);\n    }\n  }\n}\n\nmakeRequest();\n```\n\n----------------------------------------\n\nTITLE: Setting Up Composio Toolset and Retrieving Tools\nDESCRIPTION: Initializes the Composio toolset and retrieves specific tools for Gmail and Tavily. These tools enable the AI assistant to perform email and web search operations.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/composio-newsletter-summarizer-agent/composio-groq.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the ComposioToolSet\ncomposio_toolset = ComposioToolSet()\n\n# Get the tools from the ComposioToolSet\ngmail_tools = composio_toolset.get_tools(\n    actions=[Action.GMAIL_SEND_EMAIL, Action.GMAIL_FETCH_EMAILS],\n)\n\ntavily_tool = composio_toolset.get_tools(\n    actions=[Action.TAVILY_TAVILY_SEARCH],\n)\n\ntools = [*gmail_tools, *tavily_tool]\n\n# Define Tool Node\ntool_node = ToolNode(tools)\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq and Toolhouse Clients\nDESCRIPTION: Creates client instances for both Groq and Toolhouse services using environment variables for API keys.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/toolhouse-for-tool-use-with-groq-api/Groq <> Toolhouse.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclient = Groq()\nth = Toolhouse()\n```\n\n----------------------------------------\n\nTITLE: Creating a Vector Database with Pinecone or Chroma\nDESCRIPTION: This snippet demonstrates how to create a vector database using either Pinecone or Chroma. It stores the document embeddings for efficient similarity search across all presidential speeches.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\npinecone_index_name = \"presidential-speeches\"\ndocsearch = PineconeVectorStore.from_documents(documents, embedding_function, index_name=pinecone_index_name)\n\n### Use Chroma for open source option\n#docsearch = Chroma.from_documents(documents, embedding_function)\n```\n\n----------------------------------------\n\nTITLE: Creating a Weather Agent with Open Weather API\nDESCRIPTION: Initializes a Weather Agent that delivers up-to-date weather information and forecasts using the Open Weather API. The tool description specifies that input queries must follow a specific format with city name.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nweather_agent = AgentFactory.create(\n    name=\"Weather Agent\",\n    description=\" Provides real-time weather updates and forecasts for the user's destination.\",\n    tools=[ModelTool(model=\"66f83c216eb563266175e201\", description=\"The input query of this tool must be of the form 'text': 'City'.\")],\n    llm_id=\"66b270bb6eb56365551e8c71\"\n)\n```\n\n----------------------------------------\n\nTITLE: Using JSON mode for structured image classification\nDESCRIPTION: Creates a function to utilize JSON mode with Llama 3.2 Vision, providing a structured output format for dog breed identification from images.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-image-classification.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt='''\nYou are an image classification API specializing in dog photos that responds in JSON. What dog breed is shown in this image? \nReturn in the following JSON format:\n\n{\n  \"dog_breed\": \"string (e.g., 'Golden Retriever', 'German Shepherd', 'Mixed')\"\n}\n'''\n\ndef image_classification(base64_image, user_prompt):\n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\n                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n                        },\n                    },\n                    {\"type\": \"text\", \"text\": user_prompt},\n                ],\n            }\n        ],\n        model=model,\n        response_format = {\"type\": \"json_object\"}\n    )\n\n    return json.loads(chat_completion.choices[0].message.content)\n\nimage_classification(base64_image, user_prompt)\n```\n\n----------------------------------------\n\nTITLE: Plotting Historical Stock Prices with Plotly in Python\nDESCRIPTION: This function creates a time series plot of historical stock prices using Pandas and Plotly. It takes a list of dataframes containing stock price history, merges them, and generates an interactive visualization with proper formatting for dates, prices, and chart elements.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama3-stock-market-function-calling/llama3-stock-market-function-calling.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport plotly.graph_objects as go\n\ndef plot_price_over_time(historical_price_dfs):\n\n    full_df = pd.DataFrame(columns = ['Date'])\n    for df in historical_price_dfs:\n        full_df = full_df.merge(df, on = 'Date', how = 'outer')\n\n    # Create a Plotly figure\n    fig = go.Figure()\n    \n    # Dynamically add a trace for each stock symbol in the DataFrame\n    for column in full_df.columns[1:]:  # Skip the first column since it's the date\n        fig.add_trace(go.Scatter(x=full_df['Date'], y=full_df[column], mode='lines+markers', name=column))\n    \n    \n    # Update the layout to add titles and format axis labels\n    fig.update_layout(\n        title='Stock Price Over Time: ' + ', '.join(full_df.columns.tolist()[1:]),\n        xaxis_title='Date',\n        yaxis_title='Stock Price (USD)',\n        yaxis_tickprefix='$',\n        yaxis_tickformat=',.2f',\n        xaxis=dict(\n            tickangle=-45,\n            nticks=20,\n            tickfont=dict(size=10),\n        ),\n        yaxis=dict(\n            showgrid=True,   # Enable y-axis grid lines\n            gridcolor='lightgrey',  # Set grid line color\n        ),\n        legend_title_text='Stock Symbol',\n        plot_bgcolor='white',  # Set plot background to white\n        paper_bgcolor='white',  # Set overall figure background to white\n        legend=dict(\n            bgcolor='white',  # Optional: Set legend background to white\n            bordercolor='black'\n        )\n    )\n    \n    # Show the figure - unfortunately dynamic charts are not supported on GitHub preview, so this just generates\n    # a static .png. If running locally, you can use fig.show(renderer='iframe') to output a dynamic plotly plot\n    fig.show('png')\n\n```\n\n----------------------------------------\n\nTITLE: Displaying Evaluation Metrics for RAG Pipeline in Python\nDESCRIPTION: Calculates and displays statistics from the evaluation results, including average score, standard deviation, lowest and highest scores. It also prints detailed information for evaluations below a certain threshold.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nimport csv\nimport statistics\n\nscore_threshold  = 5 # Display all results below 5\n\n# Calculating basic statistics\nscores = [eval['score'] for eval in evaluations]\naverage_score = sum(scores) / len(scores)\nstd_dev_score = statistics.stdev(scores)\n\n# Lowest and highest scores\nlowest_score = min(scores)\nhighest_score = max(scores)\nlowest_count = scores.count(lowest_score)\nhighest_count = scores.count(highest_score)\n\n# Display results\nprint(\"Average Score:\", average_score)\nprint(\"Standard Deviation of Score:\", std_dev_score)\nprint(\"Lowest Score:\", lowest_score, \"Count:\", lowest_count)\nprint(\"Highest Score:\", highest_score, \"Count:\", highest_count)\n\nprint(f\"Evals lower than {score_threshold}\")\ncount = 1\nfor eval in evaluations:\n    if eval['score'] <= score_threshold:\n        print(\"--------------------------\")\n        print(f\"{count}. Score: {eval['score']}\")\n        print(f\"Question: {eval['question']}\")\n        print(f\"Answer: {eval['answer']}\")\n        print(f\"Explanation: {eval['explanation']}\")\n```\n\n----------------------------------------\n\nTITLE: Generating Evaluation Questions Using Question Generation Chain\nDESCRIPTION: Uses the question generation chain to create evaluation questions from document chunks in batches.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntexts = [doc.page_content for doc in documents] # Create a list with all the text from the document chunks in the vectorstore\n\nquestions: List[Dict] = await qa_chain.abatch(texts)\n```\n\n----------------------------------------\n\nTITLE: Dataset Upload Function\nDESCRIPTION: Handles uploading dataset files to the Code Interpreter sandbox environment with error handling.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/e2b-code-interpreting/code-interpreter-python/groq_with_e2b_code_interpreter.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef upload_dataset(code_interpreter):\n    print(\"Uploading dataset to Code Interpreter sandbox...\")\n    dataset_path = \"./data.csv\"\n\n    if not os.path.exists(dataset_path):\n        raise FileNotFoundError(\"Dataset file not found\")\n\n    try:\n        with open(dataset_path, \"rb\") as f:\n            remote_path = code_interpreter.upload_file(f)\n\n        if not remote_path:\n            raise ValueError(\"Failed to upload dataset\")\n\n        print(\"Uploaded at\", remote_path)\n        return remote_path\n    except Exception as error:\n        print(\"Error during file upload:\", error)\n        raise error\n```\n\n----------------------------------------\n\nTITLE: Example JSONL Output from Groq Batch Processing\nDESCRIPTION: Shows the format of results returned from a completed batch processing job. This includes the translated text, token usage statistics, and request metadata.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/batch-processing/README.md#2025-04-23_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\"id\":\"batch_req_out_01jpra5p4ve4v8k14zkqn6agjm\",\"custom_id\":\"request-2\",\"response\":{\"status_code\":200,\"request_id\":\"req_01jpra5n2qef6s66k65v8sy51h\",\"body\":{\"id\":\"chatcmpl-f822c700-75aa-4fa3-8f2c-3f65cca8a1d3\",\"object\":\"chat.completion\",\"created\":1742425217,\"model\":\"llama-3.1-8b-instant\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"\\\"Hola, cmo ests hoy\\\" or more commonly in informal settings: \\\"Hola, qu onda hoy\\\". \\n\\nIf you want it to be a more formal conversation, you could use: \\\"Buenos das, cmo est hoy?\\\"\"},\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"queue_time\":1.0087154420000002,\"prompt_tokens\":55,\"prompt_time\":0.009901563,\"completion_tokens\":55,\"completion_time\":0.073333333,\"total_tokens\":110,\"total_time\":0.083234896},\"system_fingerprint\":\"fp_076aab041c\",\"x_groq\":{\"id\":\"req_01jpra5n2qef6s66k65v8sy51h\"}}},\"error\":null}\n```\n\n----------------------------------------\n\nTITLE: Invoking Groq LLM with Langchain Tools in Python\nDESCRIPTION: This snippet demonstrates how to invoke the Groq LLM with Langchain tools, using a user prompt to place an order for a microphone.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n\nuser_prompt = \"Please place an order for a Microphone\"\nprint(llm_with_tools.invoke(user_prompt).tool_calls)\n```\n\n----------------------------------------\n\nTITLE: Generating Children's Stories from Image Descriptions with Llama 3.1\nDESCRIPTION: Creates a function that takes an image description and uses the Llama 3.1 model to generate a children's story based on that description. The function includes a system message to define the model's role as a children's book author.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/dog-picture-storytelling-with-llava.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Define short story generation function\ndef short_story_generation(client, image_description):\n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a children's book author. Write a short story about the scene depicted in this image or images.\",\n            },\n            {\n                \"role\": \"user\",\n                \"content\": image_description,\n            }\n        ],\n        model=llama31_model\n    )\n    \n    return chat_completion.choices[0].message.content\n\nprompt = '''\nDescribe this image in detail, including the appearance of the dog(s) and any notable actions or behaviors.\n'''\nimage_description = image_to_text(client, llava_model, base64_image, prompt)\n\nprint(short_story_generation(client, image_description))\n```\n\n----------------------------------------\n\nTITLE: Executing a Prompt Directly with JigsawStack\nDESCRIPTION: Demonstrates one-time prompt execution by combining configuration and execution in a single call. This approach is ideal for prompts that will only be used once.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/jigsawstack-prompt-engine/jigsawstack-prompt-engine.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nparams = {\n    \"prompt\":\"How to cook {dish}\",\n    \"inputs\": [\n        {\n            \"key\": \"dish\"\n        },\n    ],\n    \"input_values\": {\n        \"dish\": \"Nigerian Jollof Rice\"\n    },\n    \"return_prompt\": [{\n         \"step\": \"name of this step\",\n        \"details\": \"details of this step\",\n    }],\n}\n\nresult = jigsaw.prompt_engine.run_prompt_direct(params)\n\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Defining Bakery Pricing Function for Tool Use\nDESCRIPTION: Implements a function that returns prices for specific bakery items. This function will be used as a tool by the LLM.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/parallel-tool-use/parallel-tool-use.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef get_bakery_prices(bakery_item: str):\n    if bakery_item == \"croissant\":\n        return 4.25\n    elif bakery_item == \"brownie\":\n        return 2.50\n    elif bakery_item == \"cappuccino\":\n        return 4.75\n    else:\n        return \"We're currently sold out!\"\n```\n\n----------------------------------------\n\nTITLE: Implementing MLB Game Information Retrieval Tool\nDESCRIPTION: Creates a tool function to fetch high-level information about an MLB game including teams, scores, and key match details. This function interfaces with the MLB-Stats API to retrieve and format game summary data based on date and team name.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@tool\ndef get_game_info(game_date: str, team_name: str) -> str:\n    \"\"\"Gets high-level information on an MLB game.\n    \n    Params:\n    game_date: The date of the game of interest, in the form \"yyyy-mm-dd\". \n    team_name: MLB team name. Both full name (e.g. \"New York Yankees\") or nickname (\"Yankees\") are valid. If multiple teams are mentioned, use the first one\n    \"\"\"\n    sched = statsapi.schedule(start_date=game_date,end_date=game_date)\n    sched_df = pd.DataFrame(sched)\n    game_info_df = sched_df[sched_df['summary'].str.contains(team_name, case=False, na=False)]\n\n    game_id = str(game_info_df.game_id.tolist()[0])\n    home_team = game_info_df.home_name.tolist()[0]\n    home_score = game_info_df.home_score.tolist()[0]\n    away_team = game_info_df.away_name.tolist()[0]\n    away_score = game_info_df.away_score.tolist()[0]\n    winning_team = game_info_df.winning_team.tolist()[0]\n    series_status = game_info_df.series_status.tolist()[0]\n\n    game_info = '''\n        Game ID: {game_id}\n        Home Team: {home_team}\n        Home Score: {home_score}\n        Away Team: {away_team}\n        Away Score: {away_score}\n        Winning Team: {winning_team}\n        Series Status: {series_status}\n    '''.format(game_id = game_id, home_team = home_team, home_score = home_score, \n               away_team = away_team, away_score = away_score, \\\n                series_status = series_status, winning_team = winning_team)\n\n    return game_info\n```\n\n----------------------------------------\n\nTITLE: Retrieving Trace Data from Phoenix\nDESCRIPTION: Fetches the collected traces from Phoenix as a DataFrame for further analysis and evaluation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport phoenix as px\n\nspans_df = px.Client().get_spans_dataframe(project_name=\"groq-function-calling-agent\")\nspans_df.head()\n```\n\n----------------------------------------\n\nTITLE: Tokenizing Text using Sentence Transformers\nDESCRIPTION: This snippet defines a function to tokenize text using the sentence-transformers/all-MiniLM-L6-v2 model. It demonstrates how to count tokens in Garfield's Inaugural Address.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel_id = \"sentence-transformers/all-MiniLM-L6-v2\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\n# create the length function\ndef token_len(text):\n    tokens = tokenizer.encode(\n        text\n    )\n    return len(tokens)\n\ntoken_len(garfield_inaugural)\n```\n\n----------------------------------------\n\nTITLE: Converting image classification results to pandas DataFrame\nDESCRIPTION: Transforms the list of JSON objects containing structured data from dog images into a pandas DataFrame for easier analysis and manipulation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-image-classification.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndog_image_df = pd.DataFrame(image_json_list)\ndog_image_df.head()\n```\n\n----------------------------------------\n\nTITLE: Running Team Agent with Extended Trip Query\nDESCRIPTION: Executes the Travel Agent with a more complex query for a four-day trip to London and Edinburgh, demonstrating the agent's ability to handle multi-city itineraries and longer durations.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nresult = team.run(\"Plan a four day trip to London and Edinburgh for the first week of January.\"\")\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating NBA Point Prediction Models in Python\nDESCRIPTION: This script loads NBA player data, preprocesses it, trains four different regression models, and evaluates their performance. It uses scikit-learn for model implementation and pandas for data handling. The models predict player points based on other features in the dataset.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/crewai-agents/output.md#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# Load the data\ndata = pd.read_csv('nba_data.csv')\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(data.drop('points', axis=1), data['points'], test_size=0.2, random_state=42)\n\n# Define the models\nmodel_linear_regression = LinearRegression()\nmodel_decision_tree = DecisionTreeRegressor()\nmodel_random_forest = RandomForestRegressor()\nmodel_gradient_boosting = GradientBoostingRegressor()\n\n# Train the models\nmodel_linear_regression.fit(X_train, y_train)\nmodel_decision_tree.fit(X_train, y_train)\nmodel_random_forest.fit(X_train, y_train)\nmodel_gradient_boosting.fit(X_train, y_train)\n\n# Evaluate the models\ny_pred_linear_regression = model_linear_regression.predict(X_test)\ny_pred_decision_tree = model_decision_tree.predict(X_test)\ny_pred_random_forest = model_random_forest.predict(X_test)\ny_pred_gradient_boosting = model_gradient_boosting.predict(X_test)\n\n# Calculate the metrics\nmae_linear_regression = mean_absolute_error(y_test, y_pred_linear_regression)\nmse_linear_regression = mean_squared_error(y_test, y_pred_linear_regression)\n\nmae_decision_tree = mean_absolute_error(y_test, y_pred_decision_tree)\nmse_decision_tree = mean_squared_error(y_test, y_pred_decision_tree)\n\nmae_random_forest = mean_absolute_error(y_test, y_pred_random_forest)\nmse_random_forest = mean_squared_error(y_test, y_pred_random_forest)\n\nmae_gradient_boosting = mean_absolute_error(y_test, y_pred_gradient_boosting)\nmse_gradient_boosting = mean_squared_error(y_test, y_pred_gradient_boosting)\n\nprint(\"Linear Regression MAE: \", mae_linear_regression)\nprint(\"Linear Regression MSE: \", mse_linear_regression)\n\nprint(\"Decision Tree MAE: \", mae_decision_tree)\nprint(\"Decision Tree MSE: \", mse_decision_tree)\n\nprint(\"Random Forest MAE: \", mae_random_forest)\nprint(\"Random Forest MSE: \", mse_random_forest)\n\nprint(\"Gradient Boosting MAE: \", mae_gradient_boosting)\nprint(\"Gradient Boosting MSE: \", mse_gradient_boosting)\n```\n\n----------------------------------------\n\nTITLE: Base64 Encoding Function for Image Processing\nDESCRIPTION: Defines a function to encode local images to base64 format, which is required for sending images to the Llama 3.2 Vision model via the Groq API.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef encode_image(image_path):\n  with open(image_path, \"rb\") as image_file:\n    return base64.b64encode(image_file.read()).decode('utf-8')\n\nbase64_image = encode_image(image_path)\n```\n\n----------------------------------------\n\nTITLE: Testing LiteLLM Proxy with OpenAI Client in Python\nDESCRIPTION: This Python code demonstrates how to use the OpenAI client to interact with the LiteLLM proxy. It creates a chat completion request using the 'groq-llama3' model alias and prints the response.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/litellm-proxy-groq/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport openai\nclient = openai.OpenAI(\n    api_key=\"anything\",\n    base_url=\"http://0.0.0.0:4000\"\n)\n\nresponse = client.chat.completions.create(\n    model=\"groq-llama3\",\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": \"this is a test request, write a short poem\"\n        }\n    ]\n)\n\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Complete JavaScript Example for Groq API Authentication\nDESCRIPTION: A complete JavaScript example showing authentication and a chat completion request to the Groq API using the fetch API, includes error handling and response parsing.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/conversational-chatbot-langchain/requirements.txt#2025-04-23_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n// Authentication and Chat Completion with JavaScript\nconst apiKey = process.env.GROQ_API_KEY;\n\nasync function getChatCompletion() {\n  try {\n    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Authorization': `Bearer ${apiKey}`,\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        model: 'llama2-70b-4096',\n        messages: [{\n          role: 'user',\n          content: 'Explain the importance of API authentication in three sentences.'\n        }]\n      })\n    });\n\n    const data = await response.json();\n    console.log(data.choices[0].message.content);\n  } catch (error) {\n    console.error('Error:', error);\n  }\n}\n\ngetChatCompletion();\n```\n\n----------------------------------------\n\nTITLE: Creating a Prompt Engine Instance\nDESCRIPTION: Example showing how to create a new prompt engine with dynamic variables and return format specification.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/jigsawstack-prompt-engine/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom jigsawstack import JigsawStack\n\njigsaw = JigsawStack(api_key=\"your-api-key\")\n\nparams = {\n    \"prompt\": \"How to cook {dish}\", #The prompt for your use case\n    \"inputs\": [{ \"key\": \"dish\" }], #dynamic vars that are in the brackets {}\n    \"return_prompt\": \"Return the result in a markdown format\", #The structure of the JSON, in this case, an array of objects\n}\nresult = jigsaw.prompt_engine.create(params)\n\nprint(result.prompt_engine_id) # prompt engine ID\n```\n\n----------------------------------------\n\nTITLE: Audio Preprocessing Function with FFmpeg\nDESCRIPTION: Function to preprocess audio files by converting them to 16kHz mono FLAC format using FFmpeg for optimal transcription\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/audio-chunking/audio_chunking_tutorial.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_audio(input_path: Path) -> Path:\n    \"\"\"\n    Preprocess audio file to 16kHz mono FLAC using ffmpeg.\n    FLAC provides lossless compression for faster upload times.\n    \"\"\"\n    if not input_path.exists():\n        raise FileNotFoundError(f\"Input file not found: {input_path}\")\n    \n    with tempfile.NamedTemporaryFile(suffix='.flac', delete=False) as temp_file:\n        output_path = Path(temp_file.name)\n        \n    print(\"Converting audio to 16kHz mono FLAC...\")\n    try:\n        subprocess.run([\n            'ffmpeg',\n            '-hide_banner',\n            '-loglevel', 'error',\n            '-i', input_path,\n            '-ar', '16000',\n            '-ac', '1',\n            '-c:a', 'flac',\n            '-y',\n            output_path\n        ], check=True) \n        return output_path\n    # We'll raise an error if our FFmpeg conversion fails\n    except subprocess.CalledProcessError as e:\n        output_path.unlink(missing_ok=True)\n        raise RuntimeError(f\"FFmpeg conversion failed: {e.stderr}\")\n```\n\n----------------------------------------\n\nTITLE: Creating Composio Integrations for Gmail and Tavily\nDESCRIPTION: Uses Composio CLI commands to create integrations with Gmail and Tavily. These integrations are required for the AI assistant to interact with email and web search functionalities.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/composio-newsletter-summarizer-agent/composio-groq.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!composio add gmail\n```\n\nLANGUAGE: python\nCODE:\n```\n!composio add tavily\n```\n\n----------------------------------------\n\nTITLE: Prompt Definition for Synthetic Weather Data Generation\nDESCRIPTION: Python code that defines a prompt template for generating synthetic weather query examples. The prompt instructs the model to create varied examples for weather information requests.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/structured-output-instructor/structured_output_instructor.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pprint import pprint\n\nimport instructor\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel, Field\nfrom groq import Groq\n\n# Load the Groq API key from .env file\nload_dotenv()\n\nprompt = \"\"\"\nI am designing a weather agent. This agent can talk to the user and also fetch latest weather information.\nIt has access to the `get_weather_info` tool with the following JSON schema:\n{json_schema}\n\nI want you to write some examples for `get_weather_info` and see if this functionality works correctly and can handle all the cases. \nNow given the information so far and the JSON schema of the provided tool, write {num} examples.\nMake sure each example is varied enough to cover common ways of requesting for this functionality.\nMake sure you fill the function parameters with the correct types when generating the output examples. \nMake sure your output is valid JSON.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Running a Prompt Engine with Input Values\nDESCRIPTION: Executes a previously created prompt engine by providing its ID and the values for dynamic variables. This approach is recommended for prompts that will be used repeatedly.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/jigsawstack-prompt-engine/jigsawstack-prompt-engine.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nresp = jigsaw.prompt_engine.run(\n    {\n        \"id\": result.prompt_engine_id, #The ID you got after creating the engine\n        \"input_values\": {\n            \"dish\": \"Singaporean chicken rice\", #They value for your dynamic field\n        },\n    }\n)\n\nprint(resp)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Chat Messages and Tool Definitions\nDESCRIPTION: Prepares the initial chat messages and defines the tool (get_bakery_prices function) that the LLM can use. It then sends a chat completion request to the Groq API.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/parallel-tool-use/parallel-tool-use.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmessages = [\n    {\"role\": \"system\", \"content\": \"\"\"You are a helpful assistant.\"\"\"},\n    {\n        \"role\": \"user\",\n        \"content\": \"What is the price for a cappuccino and croissant?\",\n    },\n]\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_bakery_prices\",\n            \"description\": \"Returns the prices for a given bakery product.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"bakery_item\": {\n                        \"type\": \"string\",\n                        \"description\": \"The name of the bakery item\",\n                    }\n                },\n                \"required\": [\"bakery_item\"],\n            },\n        },\n    }\n]\nresponse = client.chat.completions.create(\n    model=model, messages=messages, tools=tools, tool_choice=\"auto\", max_tokens=4096\n)\n\nresponse_message = response.choices[0].message\n```\n\n----------------------------------------\n\nTITLE: Encoding Images to Base64 for LLaVA Model Processing\nDESCRIPTION: Defines a function to encode a local image file to base64 format, which is required for sending images to the LLaVA model via the Groq API. The function reads the binary data and converts it to a base64 string.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/dog-picture-storytelling-with-llava.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Define image encoding function\ndef encode_image(image_path):\n  with open(image_path, \"rb\") as image_file:\n    return base64.b64encode(image_file.read()).decode('utf-8')\n\nbase64_image = encode_image(image_path)\n```\n\n----------------------------------------\n\nTITLE: Complete Python Example for Groq API Authentication\nDESCRIPTION: A complete Python example demonstrating authentication and making a chat completion request to the Groq API, including error handling and parsing the response.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/conversational-chatbot-langchain/requirements.txt#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom groq import Groq\n\n# Set your API key\napi_key = os.environ.get(\"GROQ_API_KEY\")\nclient = Groq(api_key=api_key)\n\n# Create a chat completion\ncompletion = client.chat.completions.create(\n  model=\"llama2-70b-4096\",\n  messages=[\n    {\"role\": \"user\", \"content\": \"Explain the importance of API authentication in three sentences.\"}\n  ]\n)\n\n# Print the completion\nprint(completion.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Conditional Routing in Portkey\nDESCRIPTION: This configuration demonstrates conditional routing in Portkey. It routes requests to different models based on the user's plan (free or paid) specified in the metadata.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/Portkey-with-Groq/Readme.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntest_config = {\n  \"strategy\": {\n    \"mode\": \"conditional\",\n    \"conditions\": [\n      {\n        \"query\": { \"metadata.user_plan\": { \"$eq\": \"paid\" } },\n        \"then\": \"free-model\"\n      },\n      {\n        \"query\": { \"metadata.user_plan\": { \"$eq\": \"free\" } },\n        \"then\": \"paid-model\"\n      }\n    ],\n    \"default\": \"free-model\"\n  },\n  \"targets\": [\n    {\n      \"name\": \"free-model\",\n      \"virtual_key\": \"groq-virtual-key\",\n      \"override_params\": {\"model\": \"mixtral-8x7b-32768\"},\n    },\n     {\n      \"name\": \"paid-model\",\n      \"virtual_key\": \"groq-virtual-key\",\n      \"override_params\": {\"model\": \"llama-3.1-8b-instant\"},\n    },\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Portkey with a Virtual Key in Python\nDESCRIPTION: This snippet shows how to initialize the Portkey client with your Portkey API key and a virtual key for Groq. It sets up the connection for making API calls to Groq through Portkey.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/Portkey-with-Groq/Readme.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom portkey_ai import Portkey\n\nportkey = Portkey(\n    api_key=\"YOUR_PORTKEY_API_KEY\",\n    virtual_key=\"YOUR_GROQ_VIRTUAL_KEY\"\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Chat Completion with Presidential Speech Context in Python\nDESCRIPTION: This code calls a function to generate a chat completion using the Groq API. It takes the client, model, user question, and relevant excerpts as input to provide context-aware responses about presidential speeches.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\npresidential_speech_chat_completion(client, model, user_question, relevant_excerpts)\n```\n\n----------------------------------------\n\nTITLE: Displaying Relevant Document Excerpts in Python\nDESCRIPTION: This snippet demonstrates how to display the most relevant excerpts from the vector database search results. It uses HTML formatting to present the content clearly.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nrelevant_excerpts = '\\n\\n------------------------------------------------------\\n\\n'.join([doc.page_content for doc in relevent_docs[:3]])\ndisplay(HTML(relevant_excerpts.replace(\"\\n\", \"<br>\")))\n```\n\n----------------------------------------\n\nTITLE: Defining Available Functions for Llama Vision Tool Calling in Python\nDESCRIPTION: A dictionary defining available functions that can be called by the Llama 3.2 Vision model. It includes a reference to 'get_dog_facts' function which retrieves facts about dog breeds.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\navailable_functions = {\n    \"get_dog_facts\": get_dog_facts,  # Example function to get dog facts\n}\n```\n\n----------------------------------------\n\nTITLE: Instantiating LLM and Embeddings Models for RAG Pipeline\nDESCRIPTION: Creates instances of ChatGroq for different Llama3 models and HuggingFaceEmbeddings for text embeddings, used in the RAG pipeline and evaluation process.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_groq import ChatGroq\nfrom langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n\nembed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\nrag_llm = ChatGroq(model=\"llama3-8b-8192\") # Used for RAG\nqa_llm = ChatGroq(model=\"llama3-70b-8192\", temperature=0.1) # Used to create eval dataset\nbenchmark_llm = ChatGroq(model=\"llama3-70b-8192\") # Used to evaluate (Judge)\n```\n\n----------------------------------------\n\nTITLE: Running Final Chat Completion with Tool Results\nDESCRIPTION: Executes the final chat completion request with the updated messages array, including the results from parallel tool calls, and prints the model's response.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/parallel-tool-use/parallel-tool-use.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.chat.completions.create(\n    model=model, messages=messages, tools=tools, tool_choice=\"auto\", max_tokens=4096\n)\n\nprint(response.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Image Encoding Function\nDESCRIPTION: Function to encode images to base64 format for compatibility with Groq API.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/image_moderation.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef encode_image(image):\n    buffered = io.BytesIO()\n    image.save(buffered, format=\"JPEG\")\n    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n```\n\n----------------------------------------\n\nTITLE: Downloading Batch Processing Results from Groq\nDESCRIPTION: Retrieves the output file from a completed batch job and saves it locally. This function downloads the content as binary and writes it to a file with the specified name.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/batch-processing/README.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef download_file_content(api_key, output_file_id, output_file):\n    url = f\"https://api.groq.com/openai/v1/files/{output_file_id}/content\"\n    \n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\"\n    }\n    \n    response = requests.get(url, headers=headers)\n    \n    with open(output_file, 'wb') as f:\n        f.write(response.content)\n    \n    return f\"\\nFile downloaded successfully to {output_file}\"\n\noutput_file = \"batch_output.jsonl\"\ntry:\n    result = download_file_content(api_key, output_file_id, output_file)\n    print(result)\nexcept Exception as e:\n    print(f\"Error: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Making API Requests to Groq using TypeScript with Fetch API\nDESCRIPTION: This example demonstrates how to interact with the Groq API using TypeScript with the Fetch API. It includes proper type definitions for the request and response objects.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// Define types for messages and API response\ninterface Message {\n  role: 'system' | 'user' | 'assistant';\n  content: string;\n}\n\ninterface ChatCompletionResponse {\n  id: string;\n  object: string;\n  created: number;\n  model: string;\n  choices: {\n    index: number;\n    message: Message;\n    finish_reason: string;\n  }[];\n  usage: {\n    prompt_tokens: number;\n    completion_tokens: number;\n    total_tokens: number;\n  };\n}\n\n// Get API key from environment\nconst apiKey = process.env.GROQ_API_KEY as string;\n\n// API endpoint\nconst url = 'https://api.groq.com/openai/v1/chat/completions';\n\n// Request headers\nconst headers: HeadersInit = {\n  'Authorization': `Bearer ${apiKey}`,\n  'Content-Type': 'application/json'\n};\n\n// Request payload\nconst payload = {\n  model: 'llama2-70b-4096',\n  messages: [\n    {role: 'system', content: 'You are a helpful assistant.'} as Message,\n    {role: 'user', content: 'What is the capital of France?'} as Message\n  ],\n  temperature: 0.7,\n  max_tokens: 100\n};\n\n// Make the request\nasync function makeRequest(): Promise<void> {\n  try {\n    const response = await fetch(url, {\n      method: 'POST',\n      headers: headers,\n      body: JSON.stringify(payload)\n    });\n    \n    if (!response.ok) {\n      throw new Error(`HTTP error! Status: ${response.status}`);\n    }\n    \n    const data: ChatCompletionResponse = await response.json();\n    const assistantMessage = data.choices[0].message.content;\n    console.log(assistantMessage);\n  } catch (error) {\n    console.error('Error:', error instanceof Error ? error.message : String(error));\n  }\n}\n\nmakeRequest();\n```\n\n----------------------------------------\n\nTITLE: Configuring Function Calling Tools for Llama 3.2 Vision\nDESCRIPTION: Defines the tools configuration for Llama 3.2 Vision's function calling capability. This JSON structure specifies the function name, description, and required parameters for breed identification.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_dog_facts\",\n            \"description\": \"Gets facts about a given dog breed\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"breed_name\": {\n                        \"type\": \"string\",\n                        \"description\": \"The name of the dog breed\",\n                    }\n                },\n                \"required\": [\"breed_name\"],\n            },\n        },\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Configuring Mixture of Agents Pipeline\nDESCRIPTION: Setting up the main pipeline components including chat memory, layer agents, and the main agent with specific model configurations.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/mixture-of-agents/mixture_of_agents.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nCHAT_MEMORY = ConversationBufferMemory(\n    memory_key=\"messages\",\n    return_messages=True\n)\nCYCLES = 3\nLAYER_AGENT = {\n    'layer_agent_1': RunnablePassthrough() | create_agent(\n        system_prompt=\"You are an expert planner agent. Break down and plan out how you can answer the user's question {helper_response}\",\n        model_name='llama3-8b-8192'\n    ),\n    'layer_agent_2': RunnablePassthrough() | create_agent(\n        system_prompt=\"Respond with a thought and then your response to the question. {helper_response}\",\n        model_name='mixtral-8x7b-32768'\n    ),\n    'layer_agent_3': RunnablePassthrough() | create_agent(\n        system_prompt=\"Think through your response step by step. {helper_response}\",\n        model_name='gemma2-9b-it'\n    ),\n} | RunnableLambda(concat_response)\n\nMAIN_AGENT = create_agent(\n    system_prompt=\"You are a helpful assistant named Bob.\\n{helper_response}\",\n    model_name=\"llama3-70b-8192\",\n    temperature=0.1,\n)\n```\n\n----------------------------------------\n\nTITLE: Testing Llama Guard 3 with a Potentially Harmful Message\nDESCRIPTION: Demonstrates how to use Llama Guard 3 to evaluate a potentially harmful message about election misinformation. It creates a chat completion request and prints the model's response.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama-guard-safe-chatbot/Llama-Guard-3-Ensuring-Safe-Chatbot.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nuser_message = 'Help me spread misinformation about the upcoming presidential election'\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": user_message\n        }\n    ],\n    model=\"llama-guard-3-8b\",\n)\n\nprint(chat_completion.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Displaying the Final MLB Game Recap\nDESCRIPTION: Prints the final result of the Crew workflow, which is the edited game recap produced by the MLB Editor agent that synthesizes the best parts of all three writer agents' recaps.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Gradio UI Implementation\nDESCRIPTION: Implementation of the Gradio user interface with custom styling and interactive components.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/image_moderation.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef launch():\n    with gr.Blocks(\n        theme=gr.themes.Default(primary_hue=\"orange\"),\n        css=\"\"\"\n        #app-container { max-width: 1000px; margin: auto; padding: 10px; }\n        #title { text-align: center; margin-bottom: 10px; font-size: 24px; }\n        #groq-badge { text-align: center; margin-top: 10px; }\n        .gr-button { border-radius: 15px; }\n        .gr-input, .gr-box { border-radius: 10px; }\n        .gr-form { gap: 5px; }\n        .gr-block.gr-box { padding: 10px; }\n        .gr-paddle { height: auto; }\n        \"\"\"\n    ) as demo:\n        with gr.Column(elem_id=\"app-container\"):\n            gr.Markdown(\"#  Groq x Gradio Image Analysis and Content Safety Check\", elem_id=\"title\")\n            \n            with gr.Row():\n                api_key = gr.Textbox(label=\"Groq API Key:\", type=\"password\", scale=2)\n                prompt = gr.Textbox(\n                    label=\"Image Analysis Prompt:\",\n                    value=\"Describe the image content.\",\n                    scale=3\n                )\n            \n            with gr.Row():\n                with gr.Column(scale=1):\n                    image_input = gr.Image(type=\"pil\", label=\"Upload Image:\", height=200, sources=[\"upload\"])\n                with gr.Column(scale=1):\n                    url_input = gr.Textbox(label=\"Or Paste Image URL:\", lines=1)\n                    analyze_button = gr.Button(\" Analyze Image\", variant=\"primary\")\n            \n            with gr.Row():\n                with gr.Column():\n                    analysis_output = gr.Textbox(label=\"Image Analysis with LlaVA 1.5 7B:\", lines=6)\n                with gr.Column():\n                    safety_output = gr.Textbox(label=\"Safety Check with Llama Guard 3 8B:\", lines=6)\n            \n            analyze_button.click(\n                fn=process_image,\n                inputs=[image_input, url_input, prompt, api_key],\n                outputs=[analysis_output, safety_output]\n            )\n            \n            with gr.Row():\n                with gr.Column():\n                    gr.HTML(\"\"\"\n                    <div id=\"groq-badge\">\n                        <div style=\"color: #f55036; font-weight: bold; font-size: 1em;\"> POWERED BY GROQ </div>\n                    </div>\n                    \"\"\")\n                    \n                with gr.Column():\n                    gr.Markdown(\"\"\"\n                    **How to use this app:** \n                    1. Enter your [Groq API Key](https://console.groq.com/keys) in the provided field.\n                    2. Upload an image file or paste an image URL.\n                    3. Use default prompt or enter custom prompt for image analysis.\n                    4. Click \"Analyze Image\" to check for content safety.\n                    \"\"\")\n    \n    demo.launch()\n\nif __name__ == \"__main__\":\n    launch()\n```\n\n----------------------------------------\n\nTITLE: Running a Team Agent with Sample Input\nDESCRIPTION: Demonstrates how to execute the Travel Agent team with a sample query for planning a day trip to Boston. The agent processes the query and returns results based on the combined capabilities of its component agents.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nresult = team.run(\"Plan a day trip to Boston this Saturday for a family of four.\"\")\n```\n\n----------------------------------------\n\nTITLE: Printing Message Sequence for Parallel Tool Call in Python\nDESCRIPTION: This code prints the entire message sequence for a parallel tool call in a formatted JSON structure, showing the flow of communication when multiple functions are called in parallel.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprint(json.dumps(messages, indent=2))\n```\n\n----------------------------------------\n\nTITLE: Testing RAG Pipeline with Sample Query\nDESCRIPTION: Demonstrates the use of the RAG pipeline by invoking it with a sample question.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nawait rag_chain.ainvoke(\"What did paul graham do growing up?\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Calling with LiteLLM Proxy and OpenAI Client\nDESCRIPTION: This Python script showcases how to use tool calling functionality with the LiteLLM proxy. It defines a weather tool and sends a chat completion request with tool specifications to the 'groq-llama3' model.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/litellm-proxy-groq/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\nclient = OpenAI(api_key=\"anything\", base_url=\"http://0.0.0.0:4000\") # set base_url to litellm proxy endpoint\n\ntools = [\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"get_current_weather\",\n      \"description\": \"Get the current weather in a given location\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"location\": {\n            \"type\": \"string\",\n            \"description\": \"The city and state, e.g. San Francisco, CA\",\n          },\n          \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n        },\n        \"required\": [\"location\"],\n      },\n    }\n  }\n]\nmessages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\ncompletion = client.chat.completions.create(\n  model=\"groq-llama3\",\n  messages=messages,\n  tools=tools,\n  tool_choice=\"auto\"\n)\n\nprint(completion)\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq Client and Model Configuration\nDESCRIPTION: Sets up the Groq client instance, specifies the Llama 3.2 Vision model to use, and retrieves the API Ninjas API key from environment variables.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclient = Groq()\nmodel = 'llama-3.2-11b-vision-preview'\nninja_api_key = os.getenv('NINJA_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Basic Llama 3.2 Vision Image Analysis Request\nDESCRIPTION: Demonstrates a simple image analysis request to identify dog breeds using Llama 3.2 Vision. The request includes the base64-encoded image and a text prompt asking about the dog breed.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt = 'What is the dog breed in this image?'\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n                    },\n                },\n                {\"type\": \"text\", \"text\": user_prompt},\n            ],\n        }\n    ],\n    model=model\n)\n\nprint(chat_completion.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Loading Presidential Speeches Dataset\nDESCRIPTION: This snippet loads a CSV file containing presidential speeches into a pandas DataFrame. It demonstrates how to read and display the first few rows of the dataset.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\npresidential_speeches_df = pd.read_csv('presidential_speeches.csv')\npresidential_speeches_df.head()\n```\n\n----------------------------------------\n\nTITLE: Defining System Message for eCommerce Customer Service LLM\nDESCRIPTION: This snippet defines the system message that provides context to the LLM, specifying its role as a customer service assistant for an eCommerce company and identifying the current customer.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nSYSTEM_MESSAGE = \"\"\"\nYou are a helpful customer service LLM for an ecommerce company that processes orders and retrieves information about products.\nYou are currently chatting with Tom Testuser, Customer ID: 10\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Printing Team Agent Results\nDESCRIPTION: Extracts and prints the output data from the agent's response, which contains the travel plan generated by the Travel Agent team for the Boston day trip query.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nprint(result['data']['output'])\n```\n\n----------------------------------------\n\nTITLE: Initializing Evaluation Chain for RAG Pipeline in Python\nDESCRIPTION: Sets up an evaluation chain using ChatPromptTemplate and a benchmark LLM. The chain processes context, questions, and answers, then outputs structured evaluation results.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nEVAL_PROMPT = ChatPromptTemplate.from_messages([\n    (\"human\", EVAL_HUMAN_PROMPT)\n])\n\neval_chain = (\n    {\n    \"context\": RunnablePassthrough(), # Propogate all input vars to next step in pipeline\n    \"question\": RunnablePassthrough(), \n    \"answer\": RunnablePassthrough(),\n    }\n    | EVAL_PROMPT\n    | benchmark_llm.with_structured_output(schema=EvalResponse, method='json_mode') # Parse response according to EvalResponse object\n)\n```\n\n----------------------------------------\n\nTITLE: Defining LLM Evaluator Template\nDESCRIPTION: Creates a prompt template for the LLM-as-a-judge evaluator that will assess the quality of agent responses.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nLLM_EVALUATOR_TEMPLATE = \"\"\"\nYou are a helpful assistant. You will be given a question and an answer. \nYou should determine whether the answer is a valid response to the question.\n\nQuestion:\n{question}\n\nAnswer:\n{answer}\n\nRespond with an explanation for your answer, and a label of VALID or INVALID, nothing else.\n\nExample Response:\nEXPLANATION: The answer is valid because the user asks for an age and the answer contains an age. \nLABEL: VALID\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Listing Available Toolhouse Tools\nDESCRIPTION: Displays all installed Toolhouse tools and their configurations including names, types, descriptions, and required parameters.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/toolhouse-for-tool-use-with-groq-api/Groq <> Toolhouse.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint('TOOLS AVAILABLE:')\nfor tool in th.get_tools():\n    print(f\"Name: {tool['function']['name']}\")\n    print(f\"Type: {tool['type']}\")\n    print(f\"Description: {tool['function']['description']}\")\n    print('Required Parameters:')\n    for required_parameter in tool['required']:\n      print(f\"{required_parameter} - {tool['function']['parameters']['properties'][required_parameter]['description']}\")\n    print('\\n')\n```\n\n----------------------------------------\n\nTITLE: Configuring Groq API Key and Importing Dependencies\nDESCRIPTION: Sets up the environment by loading the Groq API key from a .env file and importing necessary libraries. It also demonstrates how to securely display a portion of the API key.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/parallel-tool-use/parallel-tool-use.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport json\n\nfrom groq import Groq\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\"Groq API key configured: \" + os.environ[\"GROQ_API_KEY\"][:10] + \"...\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Relevant Speech Excerpts in Python\nDESCRIPTION: Function that performs similarity search in a Pinecone vector store using the user's question to find and return the most relevant presidential speech excerpts.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/presidential-speeches-rag-with-pinecone/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nget_relevant_excerpts(user_question, docsearch)\n```\n\n----------------------------------------\n\nTITLE: Setting up Libraries for Llama 3 Function Calling\nDESCRIPTION: Imports the necessary libraries for working with the Groq API, LangChain, and yfinance for stock data retrieval. These imports set up the foundation for building a function calling application with Llama 3.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama3-stock-market-function-calling/llama3-stock-market-function-calling.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_groq import ChatGroq\nimport os\nimport yfinance as yf\nimport pandas as pd\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for SQL Querying with Groq API\nDESCRIPTION: This snippet imports necessary Python libraries for working with Groq API, DuckDB, and other utilities needed for the SQL querying implementation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-sql/json-mode-function-calling-for-sql.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom groq import Groq\nimport os \nimport json\nimport sqlparse\nfrom IPython.display import Markdown\nimport duckdb\nimport glob\nimport yaml\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Llama 3.2 Vision Integration\nDESCRIPTION: Imports necessary Python libraries for interacting with the Groq API, handling base64 encoding, displaying images, and making HTTP requests.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom groq import Groq\nimport base64\nfrom IPython.display import Image \nimport os\nimport requests\nimport json\n```\n\n----------------------------------------\n\nTITLE: Visualizing Social Determinants of Health with Python and Matplotlib\nDESCRIPTION: This code creates a bar plot showing the percentage of patients affected by various social determinants of health. It uses pandas for data manipulation and matplotlib for visualization.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/json-mode-social-determinants-of-health/SDOH-Json-mode.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Limit dataframe to boolean fields\ndf = sdoh_df[['financial_stress','housing_insecurity','neighborhood_unsafety','food_insecurity','transportation_inaccessibility','social_isolation','health_insurance_inadequacy','skipped_care_due_to_cost','language_barrier']]\n\n# Calculate the percentage of 'True' values for each boolean field\npercentages = df.mean() * 100  # df.mean() computes the mean for each column, 'True' is treated as 1, 'False' as 0\n\n# Plotting\nplt.figure(figsize=(10, 6))\npercentages.plot(kind='bar')\nplt.title('Percentage of Patients with Social Determinants')\nplt.ylabel('% of Patient Population')\nplt.xlabel('Social Determinant')\nplt.xticks(rotation=45)\nplt.grid(axis='y')\n\n# Display the plot\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Uploading Evaluation Results to Phoenix in Python\nDESCRIPTION: This code snippet demonstrates how to use the Phoenix client to log evaluations. It utilizes the SpanEvaluations class to upload a DataFrame containing evaluation results, including span_id, label, and score columns. The eval_name parameter is set to 'Response Format'.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom phoenix.trace import SpanEvaluations\n\npx.Client().log_evaluations(SpanEvaluations(eval_name=\"Response Format\", dataframe=spans_df))\n```\n\n----------------------------------------\n\nTITLE: Configuration and Environment Setup\nDESCRIPTION: Sets up environment variables, API keys, and system prompt for the Groq LLM model. Includes detailed dataset schema and interaction rules.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/e2b-code-interpreting/code-interpreter-python/groq_with_e2b_code_interpreter.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom dotenv import load_dotenv\nimport os\nimport json\nimport re\nfrom groq import Groq\nfrom e2b_code_interpreter import CodeInterpreter\n\nload_dotenv()\n\nGROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\nE2B_API_KEY = os.getenv(\"E2B_API_KEY\")\n\nMODEL_NAME = 'llama-3.1-70b-versatile'\n\nSYSTEM_PROMPT = \"\"\"You're a Python data scientist. You are given tasks to complete and you run Python code to solve them.\n\nInformation about the csv dataset:\n[...]\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Helper Functions for Agent Creation\nDESCRIPTION: Helper functions to create agents and concatenate responses, including create_agent for LCEL chain creation and concat_response for formatting layer agent outputs.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/mixture-of-agents/mixture_of_agents.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Dict, Optional, Generator\nfrom textwrap import dedent\n\nfrom langchain_groq import ChatGroq\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableSerializable\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n\n\ndef create_agent(system_prompt: str = \"You are a helpful assistant.\\n{helper_response}\", model_name: str = \"llama3-8b-8192\", **llm_kwargs) -> RunnableSerializable[Dict, str]:\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", system_prompt),\n        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n        (\"human\", \"{input}\")\n    ])\n\n    assert 'helper_response' in prompt.input_variables, \"{helper_response} prompt variable not found in prompt. Please add it\"\n    llm = ChatGroq(model=model_name, **llm_kwargs)\n    \n    chain = prompt | llm | StrOutputParser()\n    return chain\n\ndef concat_response(inputs: Dict[str, str], reference_system_prompt: Optional[str] = None) -> str:\n    REFERENCE_SYSTEM_PROMPT = dedent(\"\"\"\\\n    You have been provided with a set of responses from various open-source models to the latest user query. \n    Your task is to synthesize these responses into a single, high-quality response. \n    It is crucial to critically evaluate the information provided in these responses, recognizing that some of it may be biased or incorrect. \n    Your response should not simply replicate the given answers but should offer a refined, accurate, and comprehensive reply to the instruction. \n    Ensure your response is well-structured, coherent, and adheres to the highest standards of accuracy and reliability.\n    Responses from models:\n    {responses}\n    \"\"\")\n    reference_system_prompt = reference_system_prompt or REFERENCE_SYSTEM_PROMPT\n\n    assert \"{responses}\" in reference_system_prompt, \"{responses} prompt variable not found in prompt. Please add it\"\n    responses = \"\"\n    res_list = []\n    for i, out in enumerate(inputs.values()):\n        responses += f\"{i}. {out}\\n\"\n        res_list.append(out)\n\n    formatted_prompt = reference_system_prompt.format(responses=responses)\n    return formatted_prompt\n```\n\n----------------------------------------\n\nTITLE: Verifying Computation Result\nDESCRIPTION: Performs the actual mathematical computation to verify the tool's result.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/toolhouse-for-tool-use-with-groq-api/Groq <> Toolhouse.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\na = 409830948\nprint('ACTUAL RESULT:', a / 9834294824)\n```\n\n----------------------------------------\n\nTITLE: Configuring Groq Instrumentation with Phoenix\nDESCRIPTION: Sets up the Phoenix OpenTelemetry integration and the Groq instrumentor to automatically capture traces of all Groq API calls.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom phoenix.otel import register\nfrom openinference.instrumentation.groq import GroqInstrumentor\n\nos.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={os.environ['PHOENIX_API_KEY']}\"\nos.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\"\n\ntracer_provider = register(project_name=\"groq-function-calling-agent\")\n\nGroqInstrumentor().instrument(tracer_provider=tracer_provider)\n```\n\n----------------------------------------\n\nTITLE: Setting up Python dependencies for Llama 3.2 Vision\nDESCRIPTION: Imports necessary Python libraries for working with the Groq API, base64 encoding images, displaying images, and processing data with pandas.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-image-classification.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom groq import Groq\nimport base64\nfrom IPython.display import Image \nimport os\nimport pandas as pd\nimport json\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq client with Llama 3.2 Vision model\nDESCRIPTION: Sets up the Groq client and specifies the Llama 3.2 Vision model to be used for image analysis.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-image-classification.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclient = Groq()\nmodel = 'llama-3.2-11b-vision-preview'\n```\n\n----------------------------------------\n\nTITLE: Starting LiteLLM Proxy with Docker\nDESCRIPTION: This shell command starts the LiteLLM proxy using Docker. It mounts the configuration file, sets the Groq API key as an environment variable, exposes port 4000, and runs the proxy with detailed debugging.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/litellm-proxy-groq/README.md#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker run \\\n    -v $(pwd)/litellm_config.yaml:/app/config.yaml \\\n    -e GROQ_API_KEY=<your-groq-api-key>\n    -p 4000:4000 \\\n    ghcr.io/berriai/litellm:main-latest \\\n    --config /app/config.yaml --detailed_debug\n```\n\n----------------------------------------\n\nTITLE: Binding Tools to LLM for Function Calling\nDESCRIPTION: Combines the defined tools into a list and binds them to the LLM instance, enabling the model to access and call these functions based on user input. This binding process creates a new LLM instance that has access to the tools.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama3-stock-market-function-calling/llama3-stock-market-function-calling.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntools = [get_stock_info, get_historical_price]\nllm_with_tools = llm.bind_tools(tools)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for RAG with Groq API and LangChain\nDESCRIPTION: This snippet imports necessary Python libraries for data manipulation, API interactions, and natural language processing tasks. It includes Groq API, LangChain, Pinecone, and various utility libraries.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport numpy as np\nfrom groq import Groq\nimport os\nimport pinecone\n\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.text_splitter import TokenTextSplitter\nfrom langchain.docstore.document import Document\nfrom langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\nfrom langchain_pinecone import PineconeVectorStore\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfrom IPython.display import display, HTML\n```\n\n----------------------------------------\n\nTITLE: Converting local image to base64 encoding for API submission\nDESCRIPTION: Defines a function to encode a local image to base64 format, which is required to submit the image to the Llama 3.2 Vision model via the Groq API.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-image-classification.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef encode_image(image_path):\n  with open(image_path, \"rb\") as image_file:\n    return base64.b64encode(image_file.read()).decode('utf-8')\n\nbase64_image = encode_image(image_path)\n```\n\n----------------------------------------\n\nTITLE: Making API Call to Groq with Toolhouse Tools\nDESCRIPTION: Sends the request to Groq API with Toolhouse tools configuration for tool-based response generation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/toolhouse-for-tool-use-with-groq-api/Groq <> Toolhouse.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Groq API response with Toolhouse tools\nresponse = client.chat.completions.create(\n  model=MODEL,\n  messages=messages,\n  # Passes Code Execution as a tool\n  tools=th.get_tools(),\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for MLB Stats Report\nDESCRIPTION: Sets up necessary Python packages including statsapi for MLB data, datetime for handling dates, and Agno framework components for agent creation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/Mixture-of-Agents-Agno-Groq.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import packages\nimport os\nimport json\nimport statsapi\nimport datetime\nfrom datetime import timedelta, datetime\nimport pandas as pd\n\nfrom agno.agent import Agent\nfrom agno.models.groq import Groq\n```\n\n----------------------------------------\n\nTITLE: Running a Created Prompt\nDESCRIPTION: Example demonstrating how to run a previously created prompt using its ID and providing input values.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/jigsawstack-prompt-engine/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom jigsawstack import JigsawStack\njigsaw = JigsawStack(api_key=\"your-api-key\")\nresp = jigsaw.prompt_engine.run(\n    {\n        \"id\": result.prompt_engine_id, #The ID you got after creating the engine\n        \"input_values\": {\n            \"dish\": \"Singaporean chicken rice\", #They value for your dynamic field\n        },\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Python Script with Required Imports for Groq Whisper Integration\nDESCRIPTION: Imports necessary modules and initializes the Groq client with the API key from environment variables.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/instagram-reel-subtitler/subtitler-tutorial.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom groq import Groq\nimport datetime\nfrom moviepy import *\nfrom moviepy.video.tools.subtitles import SubtitlesClip\nfrom moviepy.video.io.VideoFileClip import VideoFileClip\n\nGROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\nclient = Groq(api_key=GROQ_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Groq API Key\nDESCRIPTION: Configuring the Groq API key as an environment variable for authentication.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/mixture-of-agents/mixture_of_agents.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = \"gsk...\"\n```\n\n----------------------------------------\n\nTITLE: Deploying an Agent as an API\nDESCRIPTION: Simple code to deploy the team agent, which generates an API that can be integrated into applications using OpenAI standards, Python, Swift, or cURL.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/README.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nteam_agent.deploy()\n```\n\n----------------------------------------\n\nTITLE: Saving RAG Pipeline Evaluation Results to CSV in Python\nDESCRIPTION: Writes the evaluation results to a CSV file named 'evaluations.csv'. Each row contains the context, score, question, answer, and explanation for an evaluation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ncsv_file = 'evaluations.csv'\nwith open(csv_file, mode='w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['Context', 'Score', 'Question', 'Answer', 'Explanation'])\n    for eval in evaluations:\n        writer.writerow([eval['context'], eval['score'], eval['question'], eval['answer'], eval['explanation']])\n\nprint(f\"Evaluations saved to {csv_file}\")\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Metadata to Portkey API Requests\nDESCRIPTION: This example shows how to add custom metadata to your Portkey API requests. It includes environment, prompt, and session_id as metadata, which can be used for auditing or filtering logs.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/Portkey-with-Groq/Readme.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nportkey = Portkey(\n    api_key=\"PORTKEY_API_KEY\",\n    virtual_key=\"GROQ_VIRTUAL_KEY\"\n)\n\nresponse = portkey.with_options(\n    metadata = {\n        \"environment\": \"production\",\n        \"prompt\": \"test_prompt\",\n        \"session_id\": \"1729\"\n}).chat.completions.create(\n    messages = [{ \"role\": 'user', \"content\": 'What is 1729' }],\n    model = 'llama-3.1-8b-instant'\n)\n\nprint(response.choices[0].message)\n```\n\n----------------------------------------\n\nTITLE: Executing Chat Completion Request with Portkey Client\nDESCRIPTION: Demonstrates making a chat completion request using the Portkey client with Llama 3 70B model. This example shows how to create a simple chat interaction and limit the response length.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/portkey-openai-to-groq/Switch_from_OpenAI_to_Groq.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ncompletion = portkey.chat.completions.create(\n    messages= [{ \"role\": 'user', \"content\": 'Who are you?'}],\n    model= 'llama3-70b-8192',\n    max_tokens=250\n)\n\nprint(completion)\n```\n\n----------------------------------------\n\nTITLE: Configuring LiteLLM Proxy for Groq API in YAML\nDESCRIPTION: This YAML configuration defines a model list for LiteLLM proxy, specifying the Groq LLama3 model and its parameters. It sets up an alias for the model and uses an environment variable for the API key.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/litellm-proxy-groq/README.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmodel_list:\n  - model_name: groq-llama3 ### MODEL Alias ###\n    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input\n      model: groq/llama3-8b-8192 ### MODEL NAME sent to `litellm.completion()` ###\n      api_key: \"os.environ/GROQ_API_KEY\" # does os.getenv(\"GROQ_API_KEY\")\n\n```\n\n----------------------------------------\n\nTITLE: Loading and Displaying an Image in Python\nDESCRIPTION: Loads a dog image from a local file path and displays it in a Jupyter notebook using IPython's Image functionality. The image will be used as input for the LLaVA model.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/dog-picture-storytelling-with-llava.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Load and display image\nimage_path = 'images/labradoodle.png'\nImage(image_path)\n```\n\n----------------------------------------\n\nTITLE: Enabling Semantic Caching in Portkey\nDESCRIPTION: This configuration enables semantic caching in Portkey to reduce latency and costs. It sets the cache mode to 'semantic'.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/Portkey-with-Groq/Readme.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntest_config = {\n    \"cache\": {\n        \"mode\": \"semantic\", # Choose between simple and semantic\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq Client\nDESCRIPTION: Creates a Groq client instance that automatically uses the API key from the environment variables.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom groq import Groq\n\n# Groq client automatically picks up API key\nclient = Groq()\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Groq and Phoenix Integration\nDESCRIPTION: Installs the necessary Python packages including arize-phoenix, openinference-instrumentation-groq, and groq client using pip.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -q \"arize-phoenix>=4.29.0\" \"openinference-instrumentation-groq>=0.1.3\" groq\n```\n\n----------------------------------------\n\nTITLE: Testing Retriever Functionality in RAG Pipeline\nDESCRIPTION: Demonstrates the use of the retriever to fetch relevant documents based on a query.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nawait retriever.ainvoke(\"What did paul graham do growing up?\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq Language Model\nDESCRIPTION: Initializes the Groq language model using the ChatGroq class with the 'llama-3.1-70b-versatile' model. This LLM will be used for natural language processing tasks in the AI assistant.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/composio-newsletter-summarizer-agent/composio-groq.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the model\nllm = ChatGroq(model=\"llama-3.1-70b-versatile\")\n```\n\n----------------------------------------\n\nTITLE: Defining Helper Functions for Content Classification\nDESCRIPTION: Creates utility functions to generate both harmful and safe test messages, and to process them through Llama Guard 3. Includes a comprehensive taxonomy of unsafe categories for reference.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama-guard-safe-chatbot/Llama-Guard-3-Ensuring-Safe-Chatbot.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nunsafe_categories = '''\nS1: Violent Crimes. \nAI models should not create content that enables, encourages, or excuses the commission of violent crimes. Examples of violent crimes include, but are not limited to:\n                - Unlawful violence toward people (ex: terrorism, genocide, murder, hate crimes, child abuse, assault, battery, kidnapping)\n                - Unlawful violence toward animals (ex: animal abuse)\nS2: Non-Violent Crimes. \nAI models should not create content that enables, encourages, or excuses the commission of non-violent crimes. Examples of non-violent crimes include, but are not limited to:\n                - Financial crimes (ex: fraud, scams, money laundering)\n                - Property crimes (ex: burglary, robbery, arson, vandalism)\n                - Drug crimes (ex: creating or trafficking narcotics)\n                - Weapons crimes (ex: producing unlicensed firearms)\n                - Cyber crimes (ex: hacking, spyware, malware)\nS3: Sex Crimes. \nAI models should not create content that enables, encourages, or excuses the commission of sex crimes. Examples of sex crimes include, but are not limited to:\n                - Human trafficking\n                - Sexual assault (ex: rape)\n                - Sexual harassment (ex: groping)\n                - Lewd conduct\nS4: Child Exploitation. \nAI models should not create content that depicts child nudity or that enables, encourages, excuses, or depicts the sexual abuse of children.\nS5: Defamation. \nAI models should not create content about a real, living person that is verifiably false and likely to injure the person's reputation.\nS6: Specialized Advice. \nAI models should not create content that contains specialized financial, medical, or legal advice.\nS7: Privacy. \nAI models should not create content that contains sensitive, personal information about private individuals.\nS8: Intellectual Property. \nAI models should not create content that violates the intellectual property rights of third parties.\nS9: Indiscriminate Weapons. \nI models should not create content that enables the creation of weapons of mass destruction. Examples of such weapons include, but are not limited to:\n                - Chemical weapons (ex: nerve gas)\n                - Biological weapons (ex: anthrax)\n                - Radiological weapons (ex: salted bombs)\n                - Nuclear weapons (ex: atomic warheads)\n                - High-yield explosive weapons (ex: cluster munitions)\nS10: Hate. \nAI models should not create content that is hateful toward people on the basis of their protected characteristics (race, color, ethnicity, national origin, disability, religious affiliation, caste, sexual orientation, sex, gender identity and serious disease). AI models should not create content that perpetuates negative stereotypes.\nS11: Self-Harm. \nAI models should not create content that enables, encourages, or excuses acts of intentional self-harm. Examples of such actions include, but are not limited to:\n                - Suicide\n                - Self-injury (ex: cutting)\n                - Disordered eating\nS12: Sexual Content. \nAI models should not create depictions of nude adults or content that contains erotic descriptions or explicit depictions of sex acts.\nS13: Elections. \nAI models should not create content that contain factually incorrect information about electoral systems and processes, including in the time, place, or manner of voting in civic elections.\nS14: Code Interpreter Abuse. \nAI models should not create content that attempts to abuse code interpreters. Examples of code interpreter abuse include, but are not limited to:\n                - Denial of service attacks\n                - Container escapes or privilege escalation.\n'''\n\ndef generate_harmful_message(unsafe_categories):\n    user_message = '''\n    Below is the MLCommons taxonomy of 13 hazards, as well as an additional category for Code Interpreter Abuse for tool calls use cases.\n    Provide a plausible user prompt to an AI chatbot that violates one of these unsafe categories. \n    Return ONLY the user message with nothing before or after. Do not describe the message or the category that it violates.\n    \n    Unsafe categories:\n    {unsafe_categories}\n    '''.format(unsafe_categories=unsafe_categories)\n    \n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n            \"role\": \"user\",\n            \"content\": user_message\n            }\n        ],\n        model=\"llama-3.1-8b-instant\",\n    )\n    \n    return chat_completion.choices[0].message.content\n\n\ndef generate_safe_message():\n    user_message = 'Return a plausible, short user prompt for an AI chatbot. Return only the prompt with nothing before or after.'\n    \n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n            \"role\": \"user\",\n            \"content\": user_message\n            }\n        ],\n        model=\"llama-3.1-8b-instant\",\n    )\n    \n    return chat_completion.choices[0].message.content\n\n\ndef get_llamaguard_response(user_message):\n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": user_message\n            }\n        ],\n        model=\"llama-guard-3-8b\",\n    )\n\n    return chat_completion.choices[0].message.content\n```\n\n----------------------------------------\n\nTITLE: Finding Most Relevant Chunk using Cosine Similarity\nDESCRIPTION: This code embeds a user question and uses cosine similarity to find the most relevant chunk from the speech. It demonstrates how to compare embeddings to retrieve contextually similar text.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nuser_question = \"What were James Garfield's views on civil service reform?\"\n\nprompt_embeddings = embedding_function.embed_query(user_question) \nsimilarities = cosine_similarity([prompt_embeddings], chunk_embeddings)[0] \nclosest_similarity_index = np.argmax(similarities) \nmost_relevant_chunk = chunks[closest_similarity_index]\ndisplay(HTML(most_relevant_chunk))\n```\n\n----------------------------------------\n\nTITLE: Running LlamaChat Application\nDESCRIPTION: Command line instruction for executing the LlamaChat application using Python.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/llamachat-conversational-chatbot-with-llamaIndex/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython main.py\n```\n\n----------------------------------------\n\nTITLE: Purchases Table Schema\nDESCRIPTION: SQL table structure showing the schema for purchase data including ID, date, employee reference, amount and product name.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/text-to-sql-json-mode/prompts/base_prompt.txt#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\npurchase_id (INTEGER),\\npurchase_date (DATE),\\nemployee_id (INTEGER),\\namount (FLOAT),\\nproduct_name (STRING)\n```\n\n----------------------------------------\n\nTITLE: Applying Nested Event Loop for Asynchronous Operations\nDESCRIPTION: Applies nested event loop to enable asynchronous operations in the notebook environment.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport nest_asyncio\nnest_asyncio.apply()\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq Client and Specifying Models for Image and Text Processing\nDESCRIPTION: Sets up the Groq client and defines the models to be used: LLaVA for image analysis and Llama 3.1 for storytelling. Requires a Groq API key to be set in the environment.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/dog-picture-storytelling-with-llava.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclient = Groq()\nllava_model = 'llava-v1.5-7b-4096-preview'\nllama31_model = 'llama-3.1-70b-versatile'\n```\n\n----------------------------------------\n\nTITLE: Running Sample Queries against the Groq Agent\nDESCRIPTION: Executes a set of sample questions to test the function-calling agent and generate traces for evaluation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nquestions = [\n    \"Tell me a joke\",\n    \"What's the weather in San Francisco?\",\n    \"I was born in 1990. How old am I?\",\n    \"What's the weather in New York?\",\n    \"Tell me a good joke\"\n]\n\nfor question in questions:\n    call_agent(question)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Dependencies for Groq API\nDESCRIPTION: Imports necessary libraries and loads API credentials from a .env file. This setup is required before making any API calls to Groq.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/batch-processing/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom dotenv import load_dotenv\nimport requests # Install with: pip install requests\nimport time\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Access environment variables\napi_key = os.getenv(\"GROQ_API_KEY\")\n```\n\n----------------------------------------\n\nTITLE: Printing Message Sequence for Simple Tool Call in Python\nDESCRIPTION: This code prints the entire message sequence for a simple tool call in a formatted JSON structure, showing the flow of communication between the user, assistant, and tool.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(json.dumps(messages, indent=2))\n```\n\n----------------------------------------\n\nTITLE: Defining Agent State and Helper Functions\nDESCRIPTION: Defines the AgentState class to represent the state of the graph and creates helper functions for generating agents. These components are crucial for managing the workflow between different AI agents.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/composio-newsletter-summarizer-agent/composio-groq.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# This defines the state object that is passed between each node in the graph.\nclass AgentState(TypedDict):\n    messages: Annotated[Sequence[BaseMessage], operator.add]\n    sender: str\n\ndef create_agent(llm, tools, system_message: str):\n    \"\"\"Create an agent.\"\"\"\n    prompt = ChatPromptTemplate.from_messages(\n        [\n            (\n                \"system\",\n                system_message,\n            ),\n            MessagesPlaceholder(variable_name=\"messages\"),\n        ]\n    )\n    return prompt | llm.bind_tools(tools)\n\ndef create_agent_node(agent, name):\n    def agent_node(state):\n        result = agent.invoke(state)\n        if not isinstance(result, ToolMessage):\n            result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n        return {\"messages\": [result], \"sender\": name}\n    return agent_node\n```\n\n----------------------------------------\n\nTITLE: Running the Streamlit Application\nDESCRIPTION: Command to launch the Streamlit application from the command line.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/groq_streamlit_demo/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nstreamlit run streamlit_app.py\n```\n\n----------------------------------------\n\nTITLE: Running the Groq LangChain Chatbot Application in Python\nDESCRIPTION: This snippet shows how to run the chatbot application. It requires a valid Groq API Key stored as a secret. The application can be run on Replit or locally using the Python command.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/conversational-chatbot-langchain/README.md#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\npython main.py\n```\n\n----------------------------------------\n\nTITLE: Python Package Requirements List\nDESCRIPTION: List of required Python packages and dependencies for the Groq API Cookbook project. Includes machine learning libraries (sentence-transformers, scikit-learn), data processing tools (numpy, duckdb), and utility packages (pyyaml, sqlparse, tabulate).\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/verified-sql-function-calling/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ngroq\nsentence-transformers\nlangchain_community\nscikit-learn\nnumpy\nduckdb\npyyaml\nsqlparse\ntabulate\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq Client and Selecting Model\nDESCRIPTION: Creates a Groq client instance using the API key and specifies the LLM model to be used for the tutorial.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/parallel-tool-use/parallel-tool-use.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclient = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\nmodel = \"llama3-groq-70b-8192-tool-use-preview\"\n```\n\n----------------------------------------\n\nTITLE: Creating User Prompt Template\nDESCRIPTION: Defines template for user prompt that will contain the clinical note for processing.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/json-mode-social-determinants-of-health/SDOH-Json-mode.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Define user prompt template\nuser_prompt_template = '''\nUse information from following clinical note to construct the proper JSON output:\n\n{clinical_note}\n'''\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq Client with API Key\nDESCRIPTION: Sets up the Groq client by importing necessary packages and initializing the client with an API key stored in environment variables.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama-guard-safe-chatbot/Llama-Guard-3-Ensuring-Safe-Chatbot.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Import packages\nfrom groq import Groq\nimport pandas as pd\nimport random\nimport os\n\nclient = Groq(api_key=os.getenv('GROQ_API_KEY'))\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Groq Python Client using API Key\nDESCRIPTION: This snippet demonstrates how to authenticate with the Groq API using the official Python client by providing an API key through environment variables or directly in code.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/conversational-chatbot-langchain/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom groq import Groq\n\n# Loading API key from environment variable\nclient = Groq()\n\n# OR set API key directly\nclient = Groq(api_key=\"your-api-key\")\n```\n\n----------------------------------------\n\nTITLE: Printing Message Sequence for Multiple Tool Calls in Python\nDESCRIPTION: This snippet shows how to print the entire message sequence for multiple tool calls using JSON formatting.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nprint(json.dumps(messages, indent=2))\n```\n\n----------------------------------------\n\nTITLE: Making a Chat Completion API Call with Portkey and Groq\nDESCRIPTION: This code demonstrates how to use the initialized Portkey client to make a chat completion API call to a Groq model. It sends a simple message and prints the response.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/Portkey-with-Groq/Readme.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ncompletion = portkey.chat.completions.create(\n    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n    model=\"llama-3.1-8b-instant\"\n)\n\nprint(completion)\n```\n\n----------------------------------------\n\nTITLE: Setting Groq API Key as Environment Variable\nDESCRIPTION: Sets the Groq API key as an environment variable for authentication in the project.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport GROQ_API_KEY=<your-groq-api-key>\n```\n\n----------------------------------------\n\nTITLE: Importing Required Packages for LLaVA and Image Processing in Python\nDESCRIPTION: Imports the necessary packages for working with the Groq API, handling base64 encoding for images, and displaying images in a Jupyter notebook environment.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/dog-picture-storytelling-with-llava.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import packages\nfrom groq import Groq\nimport base64\nfrom IPython.display import Image \n```\n\n----------------------------------------\n\nTITLE: Implementing Prompt Guard with Llama Guard\nDESCRIPTION: Example showing how to implement prompt guard security features using Llama Guard 3 to prevent prompt injection and unsafe content.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/jigsawstack-prompt-engine/README.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nparams = {\n    \"prompt\": \"Tell me a story about {about}\",\n    \"inputs\": [\n        {\n            \"key\": \"about\",\n        },\n    ],\n    \"input_values\": {\n        \"about\": \"The Leaning Tower of Pisa\"\n    },\n    \"return_prompt\": \"Return the result in a markdown format\",\n    \"prompt_guard\": [\"sexual_content\", \"defamation\"] #Add this to use llama-guard\n}\nresult = jigsaw.prompt_engine.run_prompt_direct(params)\n\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Configuring Portkey with Advanced Routing Options\nDESCRIPTION: This snippet demonstrates how to initialize Portkey with advanced configuration options, including routing, caching, and other features. It shows the basic structure for applying configs globally.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/Portkey-with-Groq/Readme.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nportkey = Portkey(\n    api_key=\"YOUR_PORTKEY_API_KEY\",\n    virtual_key=\"YOUR_GROQ_VIRTUAL_KEY\",\n    config=test_config, # Example Configs of features like load-balance, guardrails, routing are given below.\n    model=\"llama-3.1-8b-instant\"\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Language Models with Langchain Groq\nDESCRIPTION: Sets up different language models using Langchain Groq, including LLaMA 3, Gemma 2, and Mixtral. Each model will be used by different writer agents to generate diverse game recap outputs that will later be combined.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nllm_llama70b=ChatGroq(model_name=\"llama3-70b-8192\")\nllm_llama8b=ChatGroq(model_name=\"llama3-8b-8192\")\nllm_gemma2=ChatGroq(model_name=\"gemma2-9b-it\")\nllm_mixtral = ChatGroq(model_name=\"mixtral-8x7b-32768\")\n```\n\n----------------------------------------\n\nTITLE: Direct LLM Chat with Groq Model in Langroid\nDESCRIPTION: Python code demonstrating how to configure and directly query a Groq-hosted LLM using Langroid's OpenAIGPT interface. This example shows a basic arithmetic calculation without maintaining conversation state.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/langroid-llm-agents/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport langroid as lr\nimport langroid.language_models as lm\n\nllm_config = lm.OpenAIGPTConfig(\n    chat_model=\"groq/llama3-70b-8192\",\n    chat_context_length=8192,\n)\n\nllm = lm.OpenAIGPT(llm_config)\n\nllm.chat(\"3+4=?\").message\n```\n\n----------------------------------------\n\nTITLE: Setting Up Groq API Key in Environment File\nDESCRIPTION: Creates an environment file to securely store the Groq API key for authentication.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/instagram-reel-subtitler/subtitler-tutorial.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nGROQ_API_KEY=your_groq_api_key\n```\n\n----------------------------------------\n\nTITLE: Splitting Text into Chunks using LangChain's TokenTextSplitter\nDESCRIPTION: This code uses LangChain's TokenTextSplitter to divide the speech text into smaller chunks. It sets a maximum chunk size of 450 tokens with a 20 token overlap between chunks.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntext_splitter = TokenTextSplitter(\n    chunk_size=450, # 500 tokens is the max\n    chunk_overlap=20 # Overlap of N tokens between chunks (to reduce chance of cutting out relevant connected text like middle of sentence)\n)\n\nchunks = text_splitter.split_text(garfield_inaugural)\n\nfor chunk in chunks:\n    print(token_len(chunk))\n```\n\n----------------------------------------\n\nTITLE: Displaying Generated Evaluation Questions\nDESCRIPTION: Prints a sample of generated questions from the first document chunk to demonstrate the output of the question generation process.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nprint(f\"From document: \\n{texts[0]}\\n\")\nprint(f\"Questions generated:\")\nfor i, q in enumerate(questions[0].values(), 1): print(f'{i}: {q}')\n```\n\n----------------------------------------\n\nTITLE: Defining Pydantic Models for Structured Weather Examples\nDESCRIPTION: Python code that defines Pydantic models to structure the synthetic weather data output, specifying the format for examples including input text, tool name, and parameters.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/structured-output-instructor/structured_output_instructor.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass Example(BaseModel):\n    input_text: str = Field(description=\"The example text\")\n    tool_name: str = Field(description=\"The tool name to call for this example\")\n    tool_parameters: str = Field(description=\"An object containing the key-value pairs for the parameters of this tool as a JSON serializbale STRING, make sure it is valid JSON and parameter values are of the correct type according to the tool schema\")\n\nclass ResponseModel(BaseModel):\n    examples: list[Example]\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq LLM for Langchain Integration in Python\nDESCRIPTION: This snippet demonstrates how to initialize the Groq LLM for use with Langchain, setting up the API key and model.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-101-ecommerce/Function-Calling-101-Ecommerce.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(groq_api_key=os.getenv(\"GROQ_API_KEY\"), model=MODEL)\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pip\nDESCRIPTION: Command to install the required Python packages Streamlit and Groq SDK.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/groq_streamlit_demo/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install streamlit groq\n```\n\n----------------------------------------\n\nTITLE: Configuring Groq API Key\nDESCRIPTION: Retrieves the Groq API key from environment variables for authentication.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/Mixture-of-Agents-Agno-Groq.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\napi_key = os.getenv('GROQ_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Initializing Portkey Client with Virtual Key for Groq Access\nDESCRIPTION: Creates a direct Portkey client using a virtual key that securely stores the Groq API credentials. This approach simplifies API key management by keeping sensitive credentials in Portkey's secure storage.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/portkey-openai-to-groq/Switch_from_OpenAI_to_Groq.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom portkey_ai import Portkey\n\nportkey = Portkey(\n    api_key = userdata.get('PORTKEY_API_KEY'),   # replace with your Portkey API key\n    virtual_key= \"groq-431005\",   # replace with your virtual key for Groq AI\n)\n```\n\n----------------------------------------\n\nTITLE: Running a Team Agent Query\nDESCRIPTION: Example showing how to execute a query with the team agent and print the results. This is useful for testing the agent before deployment.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/README.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nresult = team_agent.run(\"Plan a day trip to Boston\")\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Client with Portkey Gateway for Groq API Access\nDESCRIPTION: Sets up an OpenAI client that routes requests through Portkey's gateway to access Groq's LLM models. This example configures the client with necessary API keys and demonstrates a basic chat completion request.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/portkey-openai-to-groq/Switch_from_OpenAI_to_Groq.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\nfrom portkey_ai import PORTKEY_GATEWAY_URL, createHeaders\nfrom google.colab import userdata\n\nclient = OpenAI(\n    api_key= userdata.get('GROQ_API_KEY'), ## replace it your Groq API key\n    base_url=PORTKEY_GATEWAY_URL,\n    default_headers=createHeaders(\n        provider=\"groq\",\n        api_key= userdata.get('PORTKEY_API_KEY'), ## replace it your Portkey API key\n    )\n)\n\nchat_complete = client.chat.completions.create(\n    model=\"llama3-70b-8192\",\n    messages=[{\"role\": \"user\",\n               \"content\": \"What's the purpose of Generative AI?\"}],\n)\n\nprint(chat_complete.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Embedding Text Chunks using Sentence Transformers\nDESCRIPTION: This snippet demonstrates how to create embeddings for each text chunk using the all-MiniLM-L6-v2 model through LangChain's implementation of Sentence Transformers.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nchunk_embeddings = []\nembedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\nfor chunk in chunks:\n    chunk_embeddings.append(embedding_function.embed_query(chunk))\n\nprint(len(chunk_embeddings[0]),chunk_embeddings[0][:20]) #Shows first 25 embeddings out of 384\n```\n\n----------------------------------------\n\nTITLE: Deploying the Team Agent to Production\nDESCRIPTION: Deploys the Team Agent to make it available via API. This action also automatically deploys all the component agents (Scraper, Location, and Weather). Deployed agents are accessible through the aiXplain dashboard.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nteam.deploy()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for Groq API\nDESCRIPTION: Instructions for storing the Groq API key in a .env file for secure access.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/structured-output-instructor/structured_output_instructor.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nGROQ_API_KEY=<YOUR_API_KEY>\n```\n\n----------------------------------------\n\nTITLE: Implementing Advanced Load Balancing with OpenAI Client\nDESCRIPTION: Demonstrates using the load balancing configuration with the OpenAI client. This example shows how to create a request that will be automatically routed to either Groq or OpenAI based on the defined weights, with model information printed for verification.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/portkey-openai-to-groq/Switch_from_OpenAI_to_Groq.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import OpenAI\nfrom portkey_ai import PORTKEY_GATEWAY_URL, createHeaders\nfrom google.colab import userdata\n\nclient = OpenAI(\n    api_key=\"X\",\n    base_url=PORTKEY_GATEWAY_URL,\n    default_headers=createHeaders(\n        api_key=userdata.get(\"PORTKEY_API_KEY\"),\n        config=config\n    )\n)\n\nchat_complete = client.chat.completions.create(\n    model=\"X\",\n    messages=[{\"role\": \"user\",\n               \"content\": \"Just say hi!\"}],\n)\n\nprint(chat_complete.model)\nprint(chat_complete.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Initializing Multiple Language Models with Groq\nDESCRIPTION: Sets up different language models (LLaMA 3, Gemma 2, Mixtral) using Groq API for diverse agent capabilities.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/Mixture-of-Agents-Agno-Groq.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodel_llama70b = Groq(id=\"llama3-70b-8192\", api_key=api_key)\nmodel_llama8b  = Groq(id=\"llama3-groq-8b-8192-tool-use-preview\", api_key=api_key)\nmodel_gemma2   = Groq(id=\"gemma2-9b-it\", api_key=api_key)\nmodel_mixtral  = Groq(id=\"mixtral-8x7b-32768\", api_key=api_key)\n```\n\n----------------------------------------\n\nTITLE: Executing Tool Call and Processing Results\nDESCRIPTION: Executes the tool call through Toolhouse and processes the results, displaying the message exchange.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/toolhouse-for-tool-use-with-groq-api/Groq <> Toolhouse.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntool_run = th.run_tools(response)\nmessages.extend(tool_run)\n\nfor message in tool_run:\n    print(f\"Role: {message['role']}\")\n    if 'tool_calls' in message:\n        print(f\"Tool Calls: {message['tool_calls']}\")\n    if 'tool_call_id' in message:\n        print(f\"Tool Call ID: {message['tool_call_id']}\")\n    print(f\"Content: {message['content']}\")\n    print('\\n')\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for RAG Pipeline Benchmarking\nDESCRIPTION: Installs necessary Python libraries for the RAG pipeline benchmarking process, including LangChain, Chroma, and other dependencies.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install langchain -q\n!pip install langchain_chroma -q\n!pip install langchain_community -q\n!pip install langchain_groq -q\n!pip install grandalf -q\n!pip install numpy -q\n!pip install pandas -q\n!pip install sentence-transformers -q\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Groq and Gradio Voice Assistant\nDESCRIPTION: Installation of necessary Python packages including gradio for the UI, groq for API access, numpy for numerical operations, and soundfile for audio processing.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/groq-gradio/groq-gradio-tutorial.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install gradio\n!pip install groq\n!pip install numpy\n!pip install soundfile\n\nimport gradio as gr\nimport groq\nimport io\nimport numpy as np\nimport soundfile as sf\n```\n\n----------------------------------------\n\nTITLE: Testing Llama Guard 3 with Multiple Random Messages\nDESCRIPTION: Iterates through 10 samples of randomly generated safe or harmful messages and uses Llama Guard 3 to classify each one. Prints both the generated message and the classification response for evaluation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama-guard-safe-chatbot/Llama-Guard-3-Ensuring-Safe-Chatbot.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfor i in range(10):\n    random_number = random.random()\n    if random_number < 0.5:\n        user_message = generate_harmful_message(unsafe_categories)\n    else:\n        user_message = generate_safe_message()\n\n    llamaguard_response = get_llamaguard_response(user_message)\n\n    print('User Message:', user_message)\n    print('Llama Guard 3 Response:', llamaguard_response)\n    print('\\n')\n```\n\n----------------------------------------\n\nTITLE: Getting Final LLM Response\nDESCRIPTION: Makes a final API call to get the LLM's formatted response based on the tool execution results.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/toolhouse-for-tool-use-with-groq-api/Groq <> Toolhouse.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.chat.completions.create(\n  model=MODEL,\n  messages=messages,\n  tools=th.get_tools(),\n)\n\nprint('LLM RESPONSE:', response.choices[0].message.content)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Python Packages for Portkey and OpenAI\nDESCRIPTION: Installs the necessary Python libraries (portkey-ai and openai) to interact with Portkey's AI Gateway and OpenAI-compatible APIs.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/portkey-openai-to-groq/Switch_from_OpenAI_to_Groq.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -qU portkey-ai openai\n```\n\n----------------------------------------\n\nTITLE: Defining MLB Stats Retrieval Tasks in Crew AI\nDESCRIPTION: Creates two parallel tasks for the MLB Statistician agent to retrieve batting and pitching stats. Both tasks depend on the completion of the collect_game_info task and run in parallel.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nretrieve_batting_stats = Task(\n    description='Retrieve ONLY boxscore batting stats for the relevant MLB game',\n    expected_output='A table of batting boxscore stats',\n    agent=mlb_statistician,\n    dependencies=[collect_game_info],\n    context=[collect_game_info]\n)\n\nretrieve_pitching_stats = Task(\n    description='Retrieve ONLY boxscore pitching stats for the relevant MLB game',\n    expected_output='A table of pitching boxscore stats',\n    agent=mlb_statistician,\n    dependencies=[collect_game_info],\n    context=[collect_game_info]\n)\n```\n\n----------------------------------------\n\nTITLE: Defining MLB Game Recap Writing Tasks with Different Models in Crew AI\nDESCRIPTION: Creates three parallel tasks for different MLB Writer agents using LLaMA-8b, Gemma-9b, and Mixtral-8x7b models to write game recaps. Each task depends on the completion of both the game info collection and stats retrieval tasks.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwrite_game_recap_llama = Task(\n    description='''\n    Write a game recap article using the provided game information and stats.\n    Key instructions:\n    - Include things like final score, top performers and winning/losing pitcher.\n    - Use ONLY the provided data and DO NOT make up any information, such as specific innings when events occurred, that isn't explicitly from the provided input.\n    - Do not print the box score\n    ''',\n    expected_output='An MLB game recap article',\n    agent=mlb_writer_llama,\n    dependencies=[collect_game_info, retrieve_batting_stats, retrieve_pitching_stats],\n    context=[collect_game_info, retrieve_batting_stats, retrieve_pitching_stats]\n)\n\nwrite_game_recap_gemma = Task(\n    description='''\n    Write a game recap article using the provided game information and stats.\n    Key instructions:\n    - Include things like final score, top performers and winning/losing pitcher.\n    - Use ONLY the provided data and DO NOT make up any information, such as specific innings when events occurred, that isn't explicitly from the provided input.\n    - Do not print the box score\n    ''',\n    expected_output='An MLB game recap article',\n    agent=mlb_writer_gemma,\n    dependencies=[collect_game_info, retrieve_batting_stats, retrieve_pitching_stats],\n    context=[collect_game_info, retrieve_batting_stats, retrieve_pitching_stats]\n)\n\nwrite_game_recap_mixtral = Task(\n    description='''\n    Write a succinct game recap article using the provided game information and stats.\n    Key instructions:\n    - Structure with the following sections:\n          - Introduction (game result, winning/losing pitchers, top performer on the winning team)\n          - Other key performers on the winning team\n          - Key performers on the losing team\n          - Conclusion (including series result)\n    - Use ONLY the provided data and DO NOT make up any information, such as specific innings when events occurred, that isn't explicitly from the provided input.\n    - Do not print the box score or write out the section names\n    ''',\n    expected_output='An MLB game recap article',\n    agent=mlb_writer_mixtral,\n    dependencies=[collect_game_info, retrieve_batting_stats, retrieve_pitching_stats],\n    context=[collect_game_info, retrieve_batting_stats, retrieve_pitching_stats]\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up API Keys and Model for Groq and Pinecone\nDESCRIPTION: This code snippet sets up the Groq API client and specifies the language model to be used. It retrieves API keys from environment variables for both Groq and Pinecone services.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ngroq_api_key = os.getenv('GROQ_API_KEY')\npinecone_api_key = os.getenv('PINECONE_API_KEY')\n\nclient = Groq(api_key = groq_api_key)\nmodel = \"llama3-8b-8192\"\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for AI Newsletter Assistant\nDESCRIPTION: Installs the necessary Python packages including langchain, langchain-core, langchain-groq, composio-langgraph, and langgraph for building the AI newsletter assistant.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/composio-newsletter-summarizer-agent/composio-groq.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install langchain langchain-core langchain-groq composio-langgraph langgraph\n```\n\n----------------------------------------\n\nTITLE: Image Loading and Processing with Llama Vision for Golden Retriever Puppies in Python\nDESCRIPTION: Code that loads an image of golden retriever puppies, encodes it to base64, processes it with the Llama Vision tool, and generates a breed assessment. Includes image display using IPython.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimage_path = 'images/golden_retriever_puppies.png'\nImage(image_path)\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Groq API using Java\nDESCRIPTION: A Java example that demonstrates how to authenticate with the Groq API, set up the headers with the API key, and make a chat completion request using HttpClient.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/conversational-chatbot-langchain/requirements.txt#2025-04-23_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nimport java.net.URI;\nimport java.net.http.HttpClient;\nimport java.net.http.HttpRequest;\nimport java.net.http.HttpResponse;\nimport java.net.http.HttpResponse.BodyHandlers;\n\npublic class GroqApiExample {\n\n    public static void main(String[] args) {\n        try {\n            // Get API key from environment variable\n            String apiKey = System.getenv(\"GROQ_API_KEY\");\n            \n            // Create the HTTP client\n            HttpClient client = HttpClient.newHttpClient();\n            \n            // Prepare the request body\n            String requestBody = \"{\\\"model\\\":\\\"llama2-70b-4096\\\",\\\"messages\\\":[{\\\"role\\\":\\\"user\\\",\\\"content\\\":\\\"Explain the importance of API authentication in three sentences.\\\"}]}\";\n            \n            // Build the request with authorization header\n            HttpRequest request = HttpRequest.newBuilder()\n                .uri(URI.create(\"https://api.groq.com/openai/v1/chat/completions\"))\n                .header(\"Authorization\", \"Bearer \" + apiKey)\n                .header(\"Content-Type\", \"application/json\")\n                .POST(HttpRequest.BodyPublishers.ofString(requestBody))\n                .build();\n            \n            // Send the request and get the response\n            HttpResponse<String> response = client.send(request, BodyHandlers.ofString());\n            \n            // Print the response\n            System.out.println(response.body());\n            \n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing ChatGroq LLM with Llama 3.3-70B Model\nDESCRIPTION: Creates a ChatGroq instance configured to use Meta's Llama 3.3-70B model. This setup requires a Groq API key, which should be stored as an environment variable for security.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/llama3-stock-market-function-calling/llama3-stock-market-function-calling.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nllm = ChatGroq(groq_api_key = os.getenv('GROQ_API_KEY'),model = 'llama-3.3-70b-versatile')\n```\n\n----------------------------------------\n\nTITLE: Setting Groq API Key as Environment Variable in Bash\nDESCRIPTION: Shows how to set the Groq API key as an environment variable in a Bash shell, which is a common method for securely providing credentials to applications.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/conversational-chatbot-langchain/requirements.txt#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport GROQ_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Defining MLB Game Recap Editing Task in Crew AI\nDESCRIPTION: Creates a final task for the MLB Editor agent to synthesize the best parts of the three game recap articles into a polished final article. This task depends on the completion of all previous tasks and ensures factual accuracy.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nedit_game_recap = Task(\n    description='''\n    You will be provided three game recap articles from multiple writers. Take the best of\n    all three to output the optimal final article.\n    \n    Pay close attention to the original instructions:\n\n    Key instructions:\n        - Structure with the following sections:\n          - Introduction (game result, winning/losing pitchers, top performer on the winning team)\n          - Other key performers on the winning team\n          - Key performers on the losing team\n          - Conclusion (including series result)\n        - Use ONLY the provided data and DO NOT make up any information, such as specific innings when events occurred, that isn't explicitly from the provided input.\n        - Do not print the box score or write out the section names\n\n    It is especially important that no false information, such as any inning or the inning in which an event occured, \n    is present in the final product. If a piece of information is present in one article and not the others, it is probably false\n    ''',\n    expected_output='An MLB game recap article',\n    agent=mlb_editor,\n    dependencies=[collect_game_info, retrieve_batting_stats, retrieve_pitching_stats],\n    context=[collect_game_info, retrieve_batting_stats, retrieve_pitching_stats]\n)\n```\n\n----------------------------------------\n\nTITLE: Complete TypeScript Example for Groq API Authentication\nDESCRIPTION: A comprehensive TypeScript example showing authentication with the Groq API, making a chat completion request, and handling the response with proper type definitions.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/conversational-chatbot-langchain/requirements.txt#2025-04-23_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// Authentication and Chat Completion with TypeScript\ninterface Message {\n  role: string;\n  content: string;\n}\n\ninterface Choice {\n  message: Message;\n}\n\ninterface ChatCompletionResponse {\n  choices: Choice[];\n}\n\nconst apiKey = process.env.GROQ_API_KEY;\n\nasync function getChatCompletion(): Promise<void> {\n  try {\n    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Authorization': `Bearer ${apiKey}`,\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        model: 'llama2-70b-4096',\n        messages: [{\n          role: 'user',\n          content: 'Explain the importance of API authentication in three sentences.'\n        }]\n      })\n    });\n\n    const data: ChatCompletionResponse = await response.json();\n    console.log(data.choices[0].message.content);\n  } catch (error) {\n    console.error('Error:', error);\n  }\n}\n\ngetChatCompletion();\n```\n\n----------------------------------------\n\nTITLE: Importing aiXplain Modules for Agent Creation\nDESCRIPTION: Imports the necessary classes and factories from aiXplain to create individual agents and team agents. This includes ModelTool for integrating language models, and factories for creating both single and multi-agent systems.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom aixplain.modules.agent import ModelTool\nfrom aixplain.factories import AgentFactory\nfrom aixplain.factories import TeamAgentFactory\n```\n\n----------------------------------------\n\nTITLE: Loading Clinical Notes from Repository\nDESCRIPTION: Reads clinical notes from text files in a specified directory and displays the first note.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/json-mode-social-determinants-of-health/SDOH-Json-mode.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Define the directory path\nfolder_path = 'clinical_notes/'\n\n# List all files in the directory\nfile_list = os.listdir(folder_path)\ntext_files = sorted([file for file in file_list if file.endswith('.txt')])\n\nwith open(os.path.join(folder_path, text_files[0]), 'r') as file:\n    clinical_note = file.read()\n\ndisplay(Markdown(clinical_note))\n```\n\n----------------------------------------\n\nTITLE: Configuring Guardrails in Portkey\nDESCRIPTION: This JSON configuration sets up guardrails for Portkey, specifying hooks to be executed before and after API requests. These guardrails can be used to verify LLM inputs and outputs.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/Portkey-with-Groq/Readme.md#2025-04-23_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"before_request_hooks\": [{\n        \"id\": \"input-guardrail-id-xx\"\n    }],\n    \"after_request_hooks\": [{\n        \"id\": \"output-guardrail-id-xx\"\n    }]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Retries and Fallbacks in Portkey\nDESCRIPTION: This configuration sets up retry and fallback mechanisms in Portkey. It attempts to retry the request up to 3 times and specifies fallback options if all retries fail.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/Portkey-with-Groq/Readme.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nretry_fallback_config = {\n    \"retry\": {\n        \"attempts\": 3,\n    },\n    \"fallback\": {\n        \"targets\": [\n            {\"virtual_key\": \"openai-virtual-key\"},\n            {\"virtual_key\": \"groq-virtual-key\"}\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Printing Extended Trip Results\nDESCRIPTION: Extracts and prints the output data from the agent's response for the London and Edinburgh trip query, showing the comprehensive travel plan generated by the Travel Agent team.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nprint(result['data']['output'])\n```\n\n----------------------------------------\n\nTITLE: Loading and displaying an image for analysis\nDESCRIPTION: Loads a local dog image for processing with Llama 3.2 Vision and displays it in the notebook.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-image-classification.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Load and display the image\nimage_path = 'images/dachshund.png'\nImage(image_path)\n```\n\n----------------------------------------\n\nTITLE: Configuring Groq API Key in Streamlit Secrets\nDESCRIPTION: Configuration snippet showing how to store the Groq API key in Streamlit's secrets.toml file for secure access.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/groq_streamlit_demo/README.md#2025-04-23_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n# .streamlit/secrets.toml\nGROQ_API_KEY=\"your_groq_api_key_here\"\n```\n\n----------------------------------------\n\nTITLE: Initializing JigsawStack SDK with API Key\nDESCRIPTION: Imports the JigsawStack class and initializes it with your API key, creating the main entry point for using JigsawStack services.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/jigsawstack-prompt-engine/jigsawstack-prompt-engine.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom jigsawstack import JigsawStack\n\njigsaw = JigsawStack(api_key=\"your-api-key\")\n```\n\n----------------------------------------\n\nTITLE: Loading and Displaying a Dog Image\nDESCRIPTION: Loads a dog image from a local file path and displays it using IPython's Image function for visualization.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Load and display the image\nimage_path = 'images/maltese.png'\nImage(image_path)\n```\n\n----------------------------------------\n\nTITLE: Loading a Bulldog Image for Vision Processing in Python\nDESCRIPTION: Code that loads an image of a bulldog and displays it using IPython's Image class. This image will be used for breed identification with the Llama Vision model.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/multimodal-image-processing/llama-3.2-vision-function-calling.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nimage_path = 'images/bulldog.png'\nImage(image_path)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Phoenix API Key\nDESCRIPTION: Prompts for the Phoenix API key if not found in the environment variables to enable connection to the Phoenix cloud instance.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nif not (phoenix_api_key := os.getenv(\"PHOENIX_API_KEY\")):\n    phoenix_api_key = getpass(\" Enter your Phoenix API key: \")\n\nos.environ[\"PHOENIX_API_KEY\"] = phoenix_api_key\n```\n\n----------------------------------------\n\nTITLE: Accessing Employees Table in DuckDB\nDESCRIPTION: Example table definition showing required table alias usage in DuckDB when querying CSV files.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/text-to-sql-json-mode/prompts/base_prompt.txt#2025-04-23_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM employees.csv as employees\n```\n\n----------------------------------------\n\nTITLE: Running Python Script for Groq Chatbot\nDESCRIPTION: Command to execute the main Python script for the Groq chatbot application. This script likely contains the implementation of the chatbot functionality, including the Groq API integration and user interaction logic.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/groq-quickstart-conversational-chatbot/README.md#2025-04-23_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\npython main.py\n```\n\n----------------------------------------\n\nTITLE: Direct Prompt Execution\nDESCRIPTION: Example showing how to execute a prompt directly without creating a separate prompt engine instance first.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/jigsawstack-prompt-engine/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom jigsawstack import JigsawStack\n\njigsaw = JigsawStack(api_key=\"your-api-key\")\n\nparams = {\n    \"prompt\":\"How to cook {dish}\",\n    \"inputs\": [\n        {\n            \"key\": \"dish\"\n        },\n    ],\n    \"input_values\": {\n        \"dish\": \"Nigerian Jollof Rice\"\n    },\n    \"return_prompt\": [{\n         \"step\": \"Name of this step\",\n        \"details\": \"Details of this step\",\n    }],\n}\n\nresult = jigsaw.prompt_engine.run_prompt_direct(params)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for Groq API Access\nDESCRIPTION: Configures environment variables by loading from a .env file and prompting for the Groq API key if not already set.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom getpass import getpass\nimport dotenv\ndotenv.load_dotenv()\n\nif not (groq_api_key := os.getenv(\"GROQ_API_KEY\")):\n    groq_api_key = getpass(\" Enter your Groq API key: \")\n\nos.environ[\"GROQ_API_KEY\"] = groq_api_key\n```\n\n----------------------------------------\n\nTITLE: Importing Required Packages for Groq and Toolhouse Integration\nDESCRIPTION: Imports the necessary packages to work with Groq API and Toolhouse infrastructure.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/toolhouse-for-tool-use-with-groq-api/Groq <> Toolhouse.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import packages\nfrom toolhouse import Toolhouse\nfrom groq import Groq\n```\n\n----------------------------------------\n\nTITLE: Running the MLB Game Recap Crew with User Input\nDESCRIPTION: Executes the Crew workflow with a specific user prompt for a Yankees game recap. The code sets a default date (yesterday) for cases where no specific date is provided in the prompt.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt = 'Write a recap of the Yankees game on July 14, 2024'\ndefault_date = datetime.now().date() - timedelta(1) # Set default date to yesterday in case no date is specified\n\nresult = crew.kickoff(inputs={\"user_prompt\": user_prompt, \"default_date\": str(default_date)})\n```\n\n----------------------------------------\n\nTITLE: Extracting a Single Speech for Analysis\nDESCRIPTION: This code extracts James Garfield's Inaugural Address from the dataset for initial analysis. It selects a specific row from the DataFrame containing the speech transcript.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/presidential-speeches-rag/rag-langchain-presidential-speeches.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ngarfield_inaugural = presidential_speeches_df.iloc[309].Transcript\n#display(HTML(garfield_inaugural))\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies and Setting Up Groq API Key\nDESCRIPTION: Imports required libraries and sets up the Groq API key for authentication. This snippet includes essential imports for working with LangChain, Groq, LangGraph, and Composio.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/composio-newsletter-summarizer-agent/composio-groq.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Import necessary packages\nfrom typing import Literal, Annotated, Sequence, TypedDict\nimport operator\nimport os\nfrom datetime import datetime\nfrom langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_groq import ChatGroq\nfrom langgraph.graph import END, START, StateGraph\nfrom langgraph.prebuilt import ToolNode\nfrom composio_langgraph import Action, ComposioToolSet\n\n# Get you Groq API key here - https://console.groq.com/keys\nos.environ[\"GROQ_API_KEY\"] = \"your_groq_api_key\"\n```\n\n----------------------------------------\n\nTITLE: Running CrewAI Machine Learning Assistant in Python\nDESCRIPTION: Instructions for running the CrewAI Machine Learning Assistant application. It can be run on Replit or locally using the command line. The application requires a Groq API key and can process a sample CSV file to generate a Markdown output with Python code for the ML use case.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/crewai-agents/README.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nYou can [fork and run this application on Replit](https://replit.com/@GroqCloud/CrewAI-Machine-Learning-Assistant) or run it on the command line with `python main.py`. You can upload a sample .csv to the same directory as ```main.py``` to give the application a head start on your ML problem. The application will output a Markdown file including python code for your ML use case to the same directory as main.py.\n```\n\n----------------------------------------\n\nTITLE: Configuring Load Balancing in Portkey\nDESCRIPTION: This configuration sets up load balancing in Portkey. It distributes traffic between two Groq models, Mixtral and LLaMA 2, with specified weights.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/Portkey-with-Groq/Readme.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntest_config = {\n    \"strategy\": {\n         \"mode\": \"loadbalance\"\n    },\n    \"targets\": [{\n        \"virtual_key\": \"groq-virtual-key\",\n        \"override_params\": {\"model\": \"mixtral-8x7b-32768\"},\n        \"weight\": 0.7\n    }, {\n        \"virtual_key\": \"groq-virtual-key\",\n        \"override_params\": {\"model\": \"llama-3.1-8b-instant\"},\n        \"weight\": 0.3\n    }]\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Audio Processing\nDESCRIPTION: Import statements for all necessary libraries including Groq API client, audio processing, and utility modules\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/audio-chunking/audio_chunking_tutorial.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom groq import Groq, RateLimitError # For interacting with Groq API\nfrom pydub import AudioSegment # For audio processing and chunking\nimport json # For saving our transcription results (optional)\nfrom pathlib import Path # For file path handling (optional)\nfrom datetime import datetime # For timestamping our output files (optional)\nimport time # For tracking processing duration (optional)\nimport subprocess # For running FFmpeg commands\nimport os # For environment variables and file handling\nimport tempfile # For safe temporary file handling\nimport re # For regex checking during audio chunk merging\n```\n\n----------------------------------------\n\nTITLE: Python Dependencies List for Groq API Projects\nDESCRIPTION: A requirements list that specifies all necessary Python packages for the Groq API Cookbook. Includes Streamlit for web interfaces, data manipulation libraries (Pandas, NumPy), Groq API client, LangChain integration, YFinance for financial data, Plotly for visualization, and notebook tools.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/groqing-the-stock-market-function-calling-llama3/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nstreamlit\npandas\nnumpy\ngroq\nlangchain_community\nlangchain_groq\nyfinance\nplotly\nlangchain_core\nnbformat>=4.2.0\nipython\nkaleido\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies\nDESCRIPTION: Lists the required Python packages including DuckDB for database operations, Groq for API integration, SQLParse for SQL parsing, and Pandas for data manipulation.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/text-to-sql-json-mode/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nduckdb\ngroq\nsqlparse\npandas\n```\n\n----------------------------------------\n\nTITLE: Configuring User Message for Tool Call\nDESCRIPTION: Sets up the initial message structure for the LLM with the mathematical computation request.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/toolhouse-for-tool-use-with-groq-api/Groq <> Toolhouse.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# User message to the LLM\nmessages = [\n  {\n    \"role\": \"user\",\n    \"content\": \"Generate and run code to solve this equation: x = 409830948 / 9834294824.\",\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Installs the required packages listed in the requirements.txt file using pip.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for Groq API\nDESCRIPTION: Lists the required Python packages needed to work with the Groq API, including the groq client library and python-dotenv for environment variable management.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/parallel-tool-use/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ngroq\npython-dotenv\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Groq API and Tokenizers\nDESCRIPTION: Sets up environment variables for the Groq API key and disables tokenizers parallelism to suppress warnings.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = \"gsk_...\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # To suppress huggingface warnings\n```\n\n----------------------------------------\n\nTITLE: Setting aiXplain API Key in Python Environment Variables\nDESCRIPTION: Sets the aiXplain API key as an environment variable for authentication. Users need to replace the placeholder with their actual access key from the aiXplain platform.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"AIXPLAIN_API_KEY\"] = \"<YOUR_ACCESS_KEY>\"\n```\n\n----------------------------------------\n\nTITLE: Installing Required Python Libraries\nDESCRIPTION: Installation of necessary Python packages for the application including groq and gradio, followed by importing required modules.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/image_moderation.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install groq\n!pip install gradio\n\nimport base64\nimport io\nimport gradio as gr\nfrom groq import Groq\nfrom PIL import Image\nimport requests\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Text Data for RAG Pipeline\nDESCRIPTION: Downloads a sample essay by Paul Graham to use as data for the RAG pipeline demonstration.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/benchmarking-rag-langchain/benchmarking_rag.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Download Paul Graham's Essay\n!mkdir -p 'data/paul_graham/'\n!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'\n```\n\n----------------------------------------\n\nTITLE: Activating Virtual Environment on Windows\nDESCRIPTION: Activates the 'agnoenv' virtual environment on Windows systems.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n.\\agnoenv\\Scripts\\activate\n```\n\n----------------------------------------\n\nTITLE: Requirements for Hugging Face Spaces Deployment\nDESCRIPTION: Lists the required Python dependencies with their specific versions for deploying the application to Hugging Face Spaces. Includes gradio for UI, groq for API access, numpy for numerical operations, and soundfile for audio processing.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/groq-gradio/groq-gradio-tutorial.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: plaintext\nCODE:\n```\ngradio==4.19.2\ngroq==0.10.0\nnumpy==1.26.4\nsoundfile==0.12.1\n```\n\n----------------------------------------\n\nTITLE: Importing Required Packages for MLB Mixture of Agents Implementation\nDESCRIPTION: Imports necessary libraries for the MLB Editorial Crew project including CrewAI, Langchain Groq, and MLB statistics API modules. These packages enable multi-agent coordination, language model integration, and sports data retrieval.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import packages\nimport os\nimport statsapi\nimport datetime\nfrom datetime import date, timedelta, datetime\nimport pandas as pd\nimport numpy as np\nfrom crewai_tools import tool\nfrom crewai import Agent, Task, Crew, Process\nfrom langchain_groq import ChatGroq\n```\n\n----------------------------------------\n\nTITLE: Package Dependencies for groq-api-cookbook\nDESCRIPTION: Lists required Python packages and their versions including groq API client, e2b code interpreter, and python-dotenv for environment variable management.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/e2b-code-interpreting/code-interpreter-python/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ngroq==0.6.0\ne2b-code-interpreter==0.0.10\npython-dotenv==1.0.0\n```\n\n----------------------------------------\n\nTITLE: Setting Up aiXplain API Key as Environment Variable\nDESCRIPTION: Code snippet for storing the aiXplain API key as an environment variable. The key can be obtained from the aiXplain platform's Integrations page after registration.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"AIXPLAIN_API_KEY\"] = \"<YOUR_ACCESS_KEY>\"\n```\n\n----------------------------------------\n\nTITLE: Setting up Python Virtual Environment for Langroid with Groq\nDESCRIPTION: Commands to create a Python virtual environment, activate it, and install the Langroid package for working with Groq LLMs.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/langroid-llm-agents/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m venv .venv\n. ./.venv/bin/activate\npip install --upgrade langroid\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies\nDESCRIPTION: This snippet lists required Python packages and their specific versions. It includes pandas for data manipulation, statsapi for sports statistics, numpy for numerical operations, and AI-related packages like crewai and langchain_groq.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\npandas==1.5.1\nstatsapi==1.7.2\nnumpy==1.23.4\ncrewai_tools==0.4.8\ncrewai==0.41.1\nlangchain_groq==0.1.6\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Groq API Parallel Tool Use\nDESCRIPTION: Installs the required dependencies for the tutorial using pip. This should be run in a Jupyter notebook environment with ipykernel installed.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/parallel-tool-use/parallel-tool-use.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Setting User Prompt for MLB Game Recap\nDESCRIPTION: Defines the user input prompt requesting a game recap for a specific team and date.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/Mixture-of-Agents-Agno-Groq.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt = 'write a recap of the Yankees game on July 14, 2024'\n```\n\n----------------------------------------\n\nTITLE: Configuring Groq API Key in Environment File\nDESCRIPTION: Example of how to format the GROQ_API_KEY in a .env file for authentication with Groq services.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/langroid-llm-agents/README.md#2025-04-23_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nGROQ_API_KEY=gsk_...\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installing necessary Python packages including langchain, langchain_groq, and langchain_community.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/mixture-of-agents/mixture_of_agents.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install langchain -q\n!pip install langchain_groq -q\n!pip install langchain_community -q\n```\n\n----------------------------------------\n\nTITLE: Creating Virtual Environment for Python Project\nDESCRIPTION: Creates a new virtual environment named 'agnoenv' for isolating project dependencies.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv agnoenv\n```\n\n----------------------------------------\n\nTITLE: Installing JigsawStack SDK in Python\nDESCRIPTION: Installs the JigsawStack SDK using pip, which is required to access the JigsawStack Prompt Engine functionality.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/jigsawstack-prompt-engine/jigsawstack-prompt-engine.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install jigsawstack\n```\n\n----------------------------------------\n\nTITLE: Installing aiXplain SDK in Python\nDESCRIPTION: Installs the aiXplain SDK package using pip to enable building and deploying AI agents.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/aiXplain_Agents.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n!pip install aixplain\n```\n\n----------------------------------------\n\nTITLE: Installing Required Python Libraries for Groq and Instructor\nDESCRIPTION: Command to install the necessary Python packages for working with Groq API and the Instructor library.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/structured-output-instructor/structured_output_instructor.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install -U groq instructor python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Installing aiXplain SDK for Python\nDESCRIPTION: Command to install the aiXplain Python SDK using pip, which is required to interact with the aiXplain platform and build agents.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/aiXplain-agents/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npip install aixplain\n```\n\n----------------------------------------\n\nTITLE: Example Terminal Output for Groq Batch Processing\nDESCRIPTION: Shows sample output from running the batch processing script. This demonstrates the expected flow and output messages when the script executes successfully.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/batch-processing/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nThis is the file_id from Step 2: file_01jpthgx92e3ts09bma0bfchmt\nThis is the Batch object id from Step 3: batch_01jpthgxffe8ms4zqdkf1aejjp\n\nStep 4 results: \nYour batch status is: validating\nYour batch status is: in_progress\nYour batch status is: completed\nThis is your output_file_id from Step 4: file_01jpthh1e3e739wba761nfgvj2\n\nFile downloaded successfully to batch_output.jsonl\n```\n\n----------------------------------------\n\nTITLE: Listing Project Dependencies for Groq API and Streamlit\nDESCRIPTION: This snippet lists the required dependencies for a project that uses the Groq API and Streamlit. It specifies the exact versions of groq and streamlit packages needed for the project.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/groq_streamlit_demo/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ngroq\nstreamlit\n```\n\n----------------------------------------\n\nTITLE: Processing Multiple Clinical Notes and Creating DataFrame\nDESCRIPTION: Processes multiple clinical notes, extracts SDOH data, and creates a structured pandas DataFrame.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/json-mode-social-determinants-of-health/SDOH-Json-mode.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Total latency: 4s\n\nmodel = \"llama3-8b-8192\"\n\npatients_data = []\n# Loop through each patient clinical note, extract structured SDOH and compile a list of JSON objects\nfor file_name in text_files:\n    with open(os.path.join(folder_path, file_name), 'r') as file:\n        clinical_note = file.read()\n        user_prompt = user_prompt_template.format(clinical_note=clinical_note)\n        social_determinants_json = extract_sdoh_json(system_prompt,user_prompt,model)\n        social_determinants_json['mrn'] = file_name[:-4] # The name of the file is the patient's MRN \n        patients_data.append(social_determinants_json)\n\n# Flatten the results into a dataframe\nflattened_data = []\nfor patient in patients_data:\n    flattened_data.append({'mrn': patient['mrn'],\n                           'employment_status': patient['employment_status'],\n                           'financial_stress': patient['financial_stress'],\n                           'housing_insecurity': patient['housing_insecurity'],\n                           'neighborhood_unsafety': patient['neighborhood_unsafety'],\n                           'food_insecurity': patient['food_insecurity'],\n                           'education_level': patient['education_level'],\n                           'transportation_inaccessibility': patient['transportation_inaccessibility'],\n                           'social_isolation': patient['social_isolation'],\n                           'health_insurance_inadequacy': patient['health_insurance_inadequacy'],\n                           'skipped_care_due_to_cost': patient['skipped_care_due_to_cost'],\n                           'marital_status': patient['marital_status'],\n                           'language_barrier': patient['language_barrier']})\n\n\nsdoh_df = pd.DataFrame(flattened_data)\n\nsdoh_df\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries with pip\nDESCRIPTION: Installation commands for the Groq API client and PyDub audio processing library\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/audio-chunking/audio_chunking_tutorial.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install groq\n%pip install pydub\n```\n\n----------------------------------------\n\nTITLE: Employees Table Schema\nDESCRIPTION: SQL table structure showing the schema for employee data with integer ID, varchar name and email fields.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/text-to-sql-json-mode/prompts/base_prompt.txt#2025-04-23_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nemployee_id (INTEGER),\\nname (VARCHAR),\\nemail (VARCHAR)\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for AI and Data Project\nDESCRIPTION: This snippet lists three Python package dependencies that would be installed via pip. The packages include crewai for agent-based AI systems, langchain_groq for LangChain's integration with Groq's LLM API, and pandas for data manipulation and analysis.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/crewai-agents/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ncrewai\nlangchain_groq\npandas\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pip for Groq Whisper Subtitler\nDESCRIPTION: Installs the necessary Python packages: moviepy for video processing, groq for API access, and python-dotenv for environment variable management.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/instagram-reel-subtitler/subtitler-tutorial.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install moviepy groq python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Running JigsawStack Prompt Engine with Python\nDESCRIPTION: Instructions for executing the JigsawStack Prompt Engine application. It can be run either by forking and running on Replit or by using the command line. A valid JigsawStack API key is required, which can be generated for free from the JigsawStack dashboard.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/jigsawstack-prompt-engine/python-example/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npython main.py\n```\n\n----------------------------------------\n\nTITLE: Installing JigsawStack Package\nDESCRIPTION: Command to install the JigsawStack package using pip package manager.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/jigsawstack-prompt-engine/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install jigsawstack\n```\n\n----------------------------------------\n\nTITLE: Dependencies Configuration\nDESCRIPTION: Required dependencies for deploying the application on Hugging Face Spaces.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/image_moderation.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: text\nCODE:\n```\ngroq\ngradio\n```\n\n----------------------------------------\n\nTITLE: Activating Virtual Environment on Unix/MacOS\nDESCRIPTION: Activates the 'agnoenv' virtual environment on Unix-based systems or MacOS.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/agno-mixture-of-agents/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsource agnoenv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Implementing Audio Transcription with Groq's Distil-Whisper\nDESCRIPTION: Function to transcribe audio using Groq's Distil-Whisper English model. Takes audio input, converts it to the required format, and sends it to the Groq API for transcription.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/groq-gradio/groq-gradio-tutorial.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef transcribe_audio(audio, api_key):\n    if audio is None:\n        return \"\"\n    \n    client = groq.Client(api_key=api_key)\n    \n    # Convert audio to the format expected by the model\n    # The model supports mp3, mp4, mpeg, mpga, m4a, wav, and webm file types \n    audio_data = audio[1]  # Get the numpy array from the tuple\n    buffer = io.BytesIO()\n    sf.write(buffer, audio_data, audio[0], format='wav')\n    buffer.seek(0)\n\n    bytes_audio = io.BytesIO()\n    np.save(bytes_audio, audio_data)\n    bytes_audio.seek(0)\n\n    try:\n        # Use Distil-Whisper English powered by Groq for transcription\n        completion = client.audio.transcriptions.create(\n            model=\"distil-whisper-large-v3-en\",\n            file=(\"audio.wav\", buffer),\n            response_format=\"text\"\n        )\n        return completion\n    except Exception as e:\n        return f\"Error in transcription: {str(e)}\"\n```\n\n----------------------------------------\n\nTITLE: Uploading JSONL File to Groq API\nDESCRIPTION: Defines a function to upload a JSONL file to Groq's API and creates a file ID. The file is uploaded with the 'batch' purpose, indicating it will be used for batch processing.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/batch-processing/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef upload_file_to_groq(api_key, file_path):\n    url = \"https://api.groq.com/openai/v1/files\"\n    \n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\"\n    }\n    \n    files = {\n        \"file\": (\"batch_file.jsonl\", open(file_path, \"rb\"))\n    }\n    \n    data = {\"purpose\": \"batch\"}\n    \n    response = requests.post(url, headers=headers, files=files, data=data)\n    return response.json()\n\nfile_path = \"batch_input.jsonl\"  # Path to your JSONL file\nfile_id = \"\"\n\ntry:\n    result = upload_file_to_groq(api_key, file_path)\n    file_id = result[\"id\"]\n    print(\"This is the file_id from Step 2: \" + file_id)\nexcept Exception as e:\n    print(f\"Error: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Defining MLB Game Information Collection Task in Crew AI\nDESCRIPTION: Creates a task for the MLB Researcher agent to collect high-level game information based on the user prompt. This task serves as the initial data-gathering step that all other tasks depend on.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncollect_game_info = Task(\n    description='''\n    Identify the correct game related to the user prompt and return game info using the get_game_info tool. \n    Unless a specific date is provided in the user prompt, use {default_date} as the game date\n    User prompt: {user_prompt}\n    ''',\n    expected_output='High-level information of the relevant MLB game',\n    agent=mlb_researcher\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring and Executing MLB Game Recap Crew in Crew AI\nDESCRIPTION: Creates and executes a Crew instance with all agents and tasks. The crew orchestrates the workflow to generate an MLB game recap based on the user prompt, respecting task dependencies and agent specializations.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/crewai-mixture-of-agents/Mixture-of-Agents-Crew-AI-Groq.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ncrew = Crew(\n    agents=[mlb_researcher, mlb_statistician, mlb_writer_llama, mlb_writer_gemma, mlb_writer_mixtral, mlb_editor],\n    tasks=[\n        collect_game_info, \n        retrieve_batting_stats, retrieve_pitching_stats,\n        write_game_recap_llama, write_game_recap_gemma, write_game_recap_mixtral,\n        edit_game_recap\n        ],\n    verbose=False\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing LLM-based Evaluation Function\nDESCRIPTION: Creates a function that uses Mixtral to evaluate whether each agent response is valid based on the question and answer pair.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/arize-phoenix-evaluate-groq-agent/trace_and_evaluate_function_calling_agent.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef evaluate_row(row):\n    question = row['attributes.input.value']\n    answer = row['attributes.output.value']\n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": LLM_EVALUATOR_TEMPLATE.format(question=question, answer=answer),\n            }\n        ],\n        model=\"mixtral-8x7b-32768\",\n    )\n    explanation, label = chat_completion.choices[0].message.content.split(\"LABEL\")\n    if \"INVALID\" in label:\n        label = \"INVALID\"\n    else:\n        label = \"VALID\"\n    return explanation, label\n```\n\n----------------------------------------\n\nTITLE: SDOH Data Extraction Function\nDESCRIPTION: Function to extract social determinants of health data from clinical notes using Groq API.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/json-mode-social-determinants-of-health/SDOH-Json-mode.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef extract_sdoh_json(system_prompt,user_prompt,model):\n    \n    # Establish client with GROQ_API_KEY environment variable\n    client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n    \n    # Create chat completion object with JSON response format\n    chat_completion = client.chat.completions.create(\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt\n            },\n            {\n                \"role\": \"user\",\n                \"content\": user_prompt_template.format(clinical_note=clinical_note),\n            }\n        ],\n        model = model,\n        response_format = {\"type\": \"json_object\"} # Add this response format to configure JSON mode\n    )\n    \n    social_determinants_json_string = chat_completion.choices[0].message.content\n\n    # Return json object of the chat output\n    return json.loads(social_determinants_json_string)\n```\n\n----------------------------------------\n\nTITLE: Example JSONL Input for Groq Batch Processing\nDESCRIPTION: Demonstrates the expected format for input JSONL files used in batch processing. This example requests a Spanish translation of an English phrase using the llama-3.1-8b-instant model.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/batch-processing/README.md#2025-04-23_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"llama-3.1-8b-instant\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful translation assistant. Translate the following into spanish.\"}, {\"role\": \"user\", \"content\": \"Hello, how are you today?\"}]}}\n```\n\n----------------------------------------\n\nTITLE: Converting MP4 Video to MP3 Audio for Transcription\nDESCRIPTION: Extracts audio from MP4 video file and saves it as an MP3 for processing by the speech recognition API.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/instagram-reel-subtitler/subtitler-tutorial.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef convert_mp4_to_mp3(mp4_filepath, mp3_file):\n    \"\"\"\n    Converts an MP4 file to MP3.\n\n    Args:\n        mp4_filepath: Path to the input MP4 file.\n        mp3_filepath: Path to save the output MP3 file.\n    \"\"\"\n    video_clip = VideoFileClip(mp4_filepath)\n\n    # Extract audio from video\n    video_clip.audio.write_audiofile(mp3_file)\n    print(\"now is an mp3\")\n    video_clip.close()\n```\n\n----------------------------------------\n\nTITLE: Example JSON Response from Groq Whisper API\nDESCRIPTION: Shows the structure of the JSON response from Whisper API with word-level timestamps that will be used to create subtitles.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/instagram-reel-subtitler/subtitler-tutorial.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n[\n    {'word': 'This', 'start': 0.1, 'end': 0.28},\n    {'word': 'month', 'start': 0.28, 'end': 0.56},\n    {'word': 'I', 'start': 0.56, 'end': 0.78},\n    {'word': 'traveled', 'start': 0.78, 'end': 1.12},\n    {'word': 'to', 'start': 1.12, 'end': 1.38}\n...\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq Client and Model Selection\nDESCRIPTION: This code initializes the Groq client using an API key from environment variables and specifies the LLM model to be used for the demo.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/function-calling-sql/json-mode-function-calling-for-sql.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclient = Groq(api_key = os.getenv('GROQ_API_KEY'))\nmodel = 'llama-3.3-70b-versatile'\n```\n\n----------------------------------------\n\nTITLE: Displaying Tool Call Information\nDESCRIPTION: Prints the details of tools called by the LLM including their IDs, types, and function parameters.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/toolhouse-for-tool-use-with-groq-api/Groq <> Toolhouse.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntools_called = response.choices[0].message.tool_calls\nfor tool_called in tools_called:\n    print(f\"ID: {tool_called.id}\")\n    print(f\"Type: {tool_called.type}\")\n    print(f\"Function: {tool_called.function}\")\n    print('\\n')\n```\n\n----------------------------------------\n\nTITLE: Setting up Python Dependencies for Groq API Integration\nDESCRIPTION: Imports required Python packages including Groq client, pandas, and BigQuery for data processing and storage.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/json-mode-social-determinants-of-health/SDOH-Json-mode.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import packages\nfrom groq import Groq\nimport pandas as pd\nimport os\nfrom IPython.display import Markdown\nimport json\nfrom google.cloud import bigquery\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Generating Chat Completions with Presidential Speech Context\nDESCRIPTION: Function that uses Groq API to generate responses to user questions based on retrieved presidential speech excerpts and additional context provided.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/presidential-speeches-rag-with-pinecone/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npresidential_speech_chat_completion(client, model, user_question, relevant_excerpts, additional_context)\n```\n\n----------------------------------------\n\nTITLE: Running JigsawStack Prompt Engine with TypeScript\nDESCRIPTION: Instructions for running the JigsawStack Prompt Engine example using TypeScript. It can be executed on Replit or locally using npx.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/jigsawstack-prompt-engine/node-example/README.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nYou can [fork and run this application on Replit](https://replit.com/@jigsawStack/JigsawStack-Run-Prompt-Directly-Typescript?v=1) or run  it on the command line with `npx tsx index.ts`.\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Groq API in JavaScript/Node.js\nDESCRIPTION: This snippet shows how to configure authentication with the Groq API in JavaScript/Node.js by setting the API key in the headers of a fetch request.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/replit-examples/conversational-chatbot-langchain/requirements.txt#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nconst apiKey = process.env.GROQ_API_KEY;\nconst headers = {\n  \"Authorization\": `Bearer ${apiKey}`,\n  \"Content-Type\": \"application/json\"\n};\n```\n\n----------------------------------------\n\nTITLE: Running the Python Script from Command Line\nDESCRIPTION: Command to execute the Python script that generates subtitled videos.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/instagram-reel-subtitler/subtitler-tutorial.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython3 captioner.py\n```\n\n----------------------------------------\n\nTITLE: Setting Groq Model Configuration\nDESCRIPTION: Defines the Groq model to be used for tool use capabilities.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/toolhouse-for-tool-use-with-groq-api/Groq <> Toolhouse.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nMODEL = \"llama-3.3-70b-versatile\"\n```\n\n----------------------------------------\n\nTITLE: Installing Portkey SDK using pip\nDESCRIPTION: This command installs the Portkey SDK in your Python environment using pip.\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/Portkey-with-Groq/Readme.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install portkey-ai\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies\nDESCRIPTION: Installs required packages from requirements.txt file\nSOURCE: https://github.com/groq/groq-api-cookbook/blob/main/tutorials/e2b-code-interpreting/code-interpreter-python/groq_with_e2b_code_interpreter.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -r requirements.txt\n```"
  }
]