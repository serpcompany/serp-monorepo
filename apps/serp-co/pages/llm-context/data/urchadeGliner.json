[
  {
    "owner": "urchade",
    "repo": "gliner",
    "content": "TITLE: Basic Entity Recognition with GLiNER\nDESCRIPTION: Complete example demonstrating how to initialize a GLiNER model, specify entity types to extract, and predict entities from a text. The example uses the pre-trained medium-sized model to identify people, awards, dates, competitions, and teams in a text about Cristiano Ronaldo.\nSOURCE: https://github.com/urchade/gliner/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom gliner import GLiNER\n\n# Initialize GLiNER with the base model\nmodel = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n\n# Sample text for entity prediction\ntext = \"\"\"\nCristiano Ronaldo dos Santos Aveiro (Portuguese pronunciation: [kɾiʃˈtjɐnu ʁɔˈnaldu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al Nassr and the Portugal national team. Widely regarded as one of the greatest players of all time, Ronaldo has won five Ballon d'Or awards,[note 3] a record three UEFA Men's Player of the Year Awards, and four European Golden Shoes, the most by a European player. He has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues, the UEFA European Championship and the UEFA Nations League. Ronaldo holds the records for most appearances (183), goals (140) and assists (42) in the Champions League, goals in the European Championship (14), international goals (128) and international appearances (205). He is one of the few players to have made over 1,200 professional career appearances, the most by an outfield player, and has scored over 850 official senior career goals for club and country, making him the top goalscorer of all time.\n\"\"\"\n\n# Labels for entity prediction\n# Most GLiNER models should work best when entity types are in lower case or title case\nlabels = [\"Person\", \"Award\", \"Date\", \"Competitions\", \"Teams\"]\n\n# Perform entity prediction\nentities = model.predict_entities(text, labels, threshold=0.5)\n\n# Display predicted entities and their labels\nfor entity in entities:\n    print(entity[\"text\"], \"=>\", entity[\"label\"])\n```\n\n----------------------------------------\n\nTITLE: Using GLiNER for Named Entity Recognition\nDESCRIPTION: Complete example demonstrating how to use GLiNER for entity recognition in text. This includes model initialization, providing input text and entity labels, and processing the results.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom gliner import GLiNER\n\n# Initialize GLiNER with the base model\nmodel = GLiNER.from_pretrained(\"urchade/gliner_mediumv2.1\")\n\n# Sample text for entity prediction\ntext = \"\"\"\nCristiano Ronaldo dos Santos Aveiro (Portuguese pronunciation: [kɾiʃˈtjɐnu ʁɔˈnaldu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al Nassr and the Portugal national team. Widely regarded as one of the greatest players of all time, Ronaldo has won five Ballon d'Or awards,[note 3] a record three UEFA Men's Player of the Year Awards, and four European Golden Shoes, the most by a European player. He has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues, the UEFA European Championship and the UEFA Nations League. Ronaldo holds the records for most appearances (183), goals (140) and assists (42) in the Champions League, goals in the European Championship (14), international goals (128) and international appearances (205). He is one of the few players to have made over 1,200 professional career appearances, the most by an outfield player, and has scored over 850 official senior career goals for club and country, making him the top goalscorer of all time.\n\"\"\"\n\n# Labels for entity prediction\nlabels = [\"Person\", \"Award\", \"Date\", \"Competitions\", \"Teams\"]\n\n# Perform entity prediction\nentities = model.predict_entities(text, labels, threshold=0.5)\n\n# Display predicted entities and their labels\nfor entity in entities:\n    print(entity[\"text\"], \"=>\", entity[\"label\"])\n```\n\n----------------------------------------\n\nTITLE: Predicting Named Entities with GLiNER in Python\nDESCRIPTION: Demonstrates how to use the GLiNER model to predict named entities in a text sample. The code defines custom entity labels, processes the text, and outputs each detected entity with its corresponding label.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/quickstart.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntext = \"\"\"\nLibretto by Marius Petipa, based on the 1822 novella ``Trilby, ou Le Lutin d'Argail`` by Charles Nodier, first presented by the Ballet of the Moscow Imperial Bolshoi Theatre on January 25/February 6 (Julian/Gregorian calendar dates), 1870, in Moscow with Polina Karpakova as Trilby and Ludiia Geiten as Miranda and restaged by Petipa for the Imperial Ballet at the Imperial Bolshoi Kamenny Theatre on January 17–29, 1871 in St. Petersburg with Adèle Grantzow as Trilby and Lev Ivanov as Count Leopold.\n\"\"\"\n\nlabels = [\"person\", \"book\", \"location\", \"date\", \"actor\", \"character\"]\n\nentities = model.predict_entities(text, labels, threshold=0.4)\n\nfor entity in entities:\n    print(entity[\"text\"], \"=>\", entity[\"label\"])\n```\n\n----------------------------------------\n\nTITLE: Performing Entity Recognition with GLiNER\nDESCRIPTION: Demonstrates how to use the trained model for named entity recognition on a sample text about Cristiano Ronaldo. The code identifies 'Person' and 'Award' entities and displays the results.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/finetune.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntext = \"\"\"\nCristiano Ronaldo dos Santos Aveiro (Portuguese pronunciation: [kɾiʃˈtjɐnu ʁɔˈnaldu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al Nassr and the Portugal national team. Widely regarded as one of the greatest players of all time, Ronaldo has won five Ballon d'Or awards,[note 3] a record three UEFA Men's Player of the Year Awards, and four European Golden Shoes, the most by a European player. He has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues, the UEFA European Championship and the UEFA Nations League. Ronaldo holds the records for most appearances (183), goals (140) and assists (42) in the Champions League, goals in the European Championship (14), international goals (128) and international appearances (205). He is one of the few players to have made over 1,200 professional career appearances, the most by an outfield player, and has scored over 850 official senior career goals for club and country, making him the top goalscorer of all time.\n\"\"\"\n\n# Labels for entity prediction\nlabels = [\"Person\", \"Award\"] # for v2.1 use capital case for better performance\n\n# Perform entity prediction\nentities = trained_model.predict_entities(text, labels, threshold=0.5)\n\n# Display predicted entities and their labels\nfor entity in entities:\n    print(entity[\"text\"], \"=>\", entity[\"label\"])\n```\n\n----------------------------------------\n\nTITLE: Predicting Entities with ONNX Model\nDESCRIPTION: Performs entity recognition on a literary text sample using the ONNX model, identifying entities like persons, books, locations, dates, actors, and characters with a confidence threshold of 0.4.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntext = \"\"\"\nLibretto by Marius Petipa, based on the 1822 novella ``Trilby, ou Le Lutin d'Argail`` by Charles Nodier, first presented by the Ballet of the Moscow Imperial Bolshoi Theatre on January 25/February 6 (Julian/Gregorian calendar dates), 1870, in Moscow with Polina Karpakova as Trilby and Ludiia Geiten as Miranda and restaged by Petipa for the Imperial Ballet at the Imperial Bolshoi Kamenny Theatre on January 17–29, 1871 in St. Petersburg with Adèle Grantzow as Trilby and Lev Ivanov as Count Leopold.\n\"\"\"\n\nlabels = [\"person\", \"book\", \"location\", \"date\", \"actor\", \"character\"]\n\nentities = model.predict_entities(text, labels, threshold=0.4)\n\nfor entity in entities:\n    print(entity[\"text\"], \"=>\", entity[\"label\"])\n```\n\n----------------------------------------\n\nTITLE: Extracting Company Information from Text using GLiNER in Python\nDESCRIPTION: Process a text sample to extract company entities using the GLiNER relation extractor. The example identifies companies from a text about Elon Musk and filters for the 'company' label.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ntext = \"Elon Musk founded SpaceX in 2002 to reduce space transportation costs. Also Elon is founder of Tesla, NeuroLink and many other companies.\"\nlabels = ['company']\npredictions = relation_extractor(text, labels=labels)\nprint(predictions)\n```\n\n----------------------------------------\n\nTITLE: Installing GLiNER via Pip\nDESCRIPTION: Command to install the GLiNER Python library using pip package manager. The basic version installs the core functionality without GPU support.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install gliner\n```\n\n----------------------------------------\n\nTITLE: Initializing GLiNEROpenExtractor for Information Extraction in Python\nDESCRIPTION: Load a pretrained GLiNER model and initialize the GLiNEROpenExtractor for extracting information from text. The example uses a multitask model and sets a prompt to extract companies related to space technologies.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nfrom gliner import GLiNER\nfrom gliner.multitask import GLiNEROpenExtractor\n\nmodel_id = 'knowledgator/gliner-multitask-v1.0'\nmodel = GLiNER.from_pretrained(model_id)\nextractor = GLiNEROpenExtractor(model=model, prompt=\"Extract all companies related to space technologies\")\n```\n\n----------------------------------------\n\nTITLE: Classifying Text with GLiNERClassifier\nDESCRIPTION: Example showing how to classify a text into predefined labels using the GLiNERClassifier.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntext = \"SpaceX successfully launched a new rocket into orbit.\"\nlabels = ['science', 'technology', 'business', 'sports']\npredictions = classifier(text, classes=labels, multi_label=False)\nprint(predictions)\n```\n\n----------------------------------------\n\nTITLE: Initializing GLiNERQuestionAnswerer\nDESCRIPTION: Example of initializing the GLiNERQuestionAnswerer pipeline for question-answering tasks using a pre-trained GLiNER multitask model.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom gliner import GLiNER\nfrom gliner.multitask import GLiNERQuestionAnswerer\n\nmodel_id = 'knowledgator/gliner-multitask-v1.0'\nmodel = GLiNER.from_pretrained(model_id)\nanswerer = GLiNERQuestionAnswerer(model=model)\n```\n\n----------------------------------------\n\nTITLE: Extracting Answers with GLiNERQuestionAnswerer\nDESCRIPTION: Example demonstrating how to extract an answer from text using GLiNERQuestionAnswerer.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ntext = \"SpaceX successfully launched a new rocket into orbit.\"\nquestion = 'Which company launched a new rocker?'\npredictions = answerer(text, questions=question)\nprint(predictions)\n```\n\n----------------------------------------\n\nTITLE: Loading Pretrained GLiNER Model\nDESCRIPTION: Sets up the device (GPU if available, otherwise CPU) and loads the pretrained small GLiNER model from Hugging Face for fine-tuning.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/finetune.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndevice = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n\nmodel = GLiNER.from_pretrained(\"urchade/gliner_small\")\n```\n\n----------------------------------------\n\nTITLE: Evaluating Question-Answering Model with GLiNERSquadEvaluator\nDESCRIPTION: Example of initializing and using GLiNERSquadEvaluator to evaluate a model on the SQuAD dataset.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom gliner.multitask import GLiNERSquadEvaluator\nmodel_id = 'knowledgator/gliner-multitask-v1.0'\nevaluator = GLiNERSquadEvaluator(model_id=model_id)\nmetrics = evaluator.evaluate( threshold=0.25)\nprint(metrics)\n```\n\n----------------------------------------\n\nTITLE: Running Relations Extraction Pipeline with UTCA\nDESCRIPTION: Example demonstrating how to run a relations extraction pipeline created with UTCA, specifying entity types, relation parameters, and processing text.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nr = pipe.run({\n    \"text\": text, # Text to process\n    \"labels\": [\"organisation\", \"founder\", \"position\", \"date\"],\n    \"relations\": [{ # Relation parameters\n        \"relation\": \"founder\", # Relation label. Required parameter.\n        \"pairs_filter\": [(\"organisation\", \"founder\")], # Optional parameter. It specifies possible members of relations by their entity labels.\n        \"distance_threshold\": 100, # Optional parameter. It specifies the max distance between spans in the text (i.e., the end of the span that is closer to the start of the text and the start of the next one).\n    }, {\n        \"relation\": \"inception date\",\n        \"pairs_filter\": [(\"organisation\", \"date\")],\n    }, {\n        \"relation\": \"held position\",\n        \"pairs_filter\": [(\"founder\", \"position\")],\n    }]\n})\n\nprint(r[\"output\"])\n```\n\n----------------------------------------\n\nTITLE: Loading Pretrained GLiNER Model\nDESCRIPTION: Loads a pretrained GLiNER model from the community repository\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/load_local_model.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# first load your model\n\nmodel = GLiNER.from_pretrained(\"gliner-community/gliner_medium-v2.5\")\n```\n\n----------------------------------------\n\nTITLE: Initializing GLiNERSummarizer for Text Summarization in Python\nDESCRIPTION: Load a pretrained GLiNER model and initialize the GLiNERSummarizer for text summarization tasks. The summarizer uses extraction processes to identify the most important information in text.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nfrom gliner import GLiNER\nfrom gliner.multitask import GLiNERSummarizer\n\nmodel_id = 'knowledgator/gliner-multitask-v1.0'\nmodel = GLiNER.from_pretrained(model_id)\nsummarizer = GLiNERSummarizer(model=model)\n```\n\n----------------------------------------\n\nTITLE: Testing GLiNER Entity Recognition\nDESCRIPTION: Example usage of loaded GLiNER model for entity recognition on a sample text with specific entity labels\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/load_local_model.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntext = \"\"\"\nLibretto by Marius Petipa, based on the 1822 novella ``Trilby, ou Le Lutin d'Argail`` by Charles Nodier, first presented by the Ballet of the Moscow Imperial Bolshoi Theatre on January 25/February 6 (Julian/Gregorian calendar dates), 1870, in Moscow with Polina Karpakova as Trilby and Ludiia Geiten as Miranda and restaged by Petipa for the Imperial Ballet at the Imperial Bolshoi Kamenny Theatre on January 17–29, 1871 in St. Petersburg with Adèle Grantzow as Trilby and Lev Ivanov as Count Leopold.\n\"\"\"\n\nlabels = [\"person\", \"book\", \"location\", \"date\", \"actor\", \"character\"]\n\nentities = loaded_model.predict_entities(text, labels, threshold=0.4)\n\nfor entity in entities:\n    print(entity[\"text\"], \"=>\", entity[\"label\"])\n```\n\n----------------------------------------\n\nTITLE: Initializing LLM with Parallel Processing\nDESCRIPTION: Creates an LLM instance with the specified model, configuring it to use multiple GPUs in parallel and half-precision to optimize memory usage.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nllm = LLM(model=LLM_MODEL, tensor_parallel_size=NUM_GPUs, dtype=\"half\")\n```\n\n----------------------------------------\n\nTITLE: Setting up spaCy Pipeline with Gliner\nDESCRIPTION: Loads a base spaCy model and adds the Gliner NER component to the processing pipeline. This enables entity recognition functionality using the Gliner model.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/gliner_spacy_demo.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nnlp = spacy.load(\"en_core_web_sm\")\nnlp.add_pipe(\"gliner_spacy\")\n```\n\n----------------------------------------\n\nTITLE: Initializing GLiNERRelationExtractor\nDESCRIPTION: Example of initializing the GLiNERRelationExtractor pipeline for extracting relationships between entities using a pre-trained GLiNER multitask model.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nfrom gliner import GLiNER\nfrom gliner.multitask import GLiNERRelationExtractor\n\nmodel_id = 'knowledgator/gliner-multitask-v1.0'\nmodel = GLiNER.from_pretrained(model_id)\nrelation_extractor = GLiNERRelationExtractor(model=model)\n```\n\n----------------------------------------\n\nTITLE: Converting GLiNER Model to ONNX Format\nDESCRIPTION: Exports the GLiNER model to ONNX format with dynamic axes definitions for both token_level and span-based modes. This allows the model to be used across different deep learning frameworks.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nif gliner_model.config.span_mode == 'token_level':\n    all_inputs =  (inputs['input_ids'], inputs['attention_mask'], \n                    inputs['words_mask'], inputs['text_lengths'])\n    input_names = ['input_ids', 'attention_mask', 'words_mask', 'text_lengths']\n    dynamic_axes={\n        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n        \"words_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n        \"text_lengths\": {0: \"batch_size\", 1: \"value\"},\n        \"logits\": {0: \"position\", 1: \"batch_size\", 2: \"sequence_length\", 3: \"num_classes\"},\n    }\nelse:\n    all_inputs =  (inputs['input_ids'], inputs['attention_mask'], \n                    inputs['words_mask'], inputs['text_lengths'],\n                    inputs['span_idx'], inputs['span_mask'])\n    input_names = ['input_ids', 'attention_mask', 'words_mask', 'text_lengths', 'span_idx', 'span_mask']\n    dynamic_axes={\n        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n        \"words_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n        \"text_lengths\": {0: \"batch_size\", 1: \"value\"},\n        \"span_idx\": {0: \"batch_size\", 1: \"num_spans\", 2: \"idx\"},\n        \"span_mask\": {0: \"batch_size\", 1: \"num_spans\"},\n        \"logits\": {0: \"batch_size\", 1: \"sequence_length\", 2: \"num_spans\", 3: \"num_classes\"},\n    }\nprint('Converting the model...')\nall_inputs = dict(zip(input_names,all_inputs))\n\ntorch.onnx.export(\n    gliner_model.model,\n    all_inputs,\n    f=onnx_save_path,\n    input_names=input_names,\n    output_names=[\"logits\"],\n    dynamic_axes=dynamic_axes,\n    opset_version=14,\n)\n```\n\n----------------------------------------\n\nTITLE: Extracting Relations with GLiNERRelationExtractor\nDESCRIPTION: Example demonstrating how to extract relationships between entities in a text using GLiNERRelationExtractor with specified relation types and entity types.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ntext = \"Elon Musk founded SpaceX in 2002 to reduce space transportation costs.\"\nrelations = ['founded', 'owns', 'works for']\nentities = ['person', 'company', 'year']\npredictions = relation_extractor(text, entities=entities, relations=relations)\nprint(predictions)\n```\n\n----------------------------------------\n\nTITLE: Loading Pre-trained GLiNER Model in Python\nDESCRIPTION: Loads a pre-trained GLiNER model from Hugging Face Hub and prepares it for inference by setting it to evaluation mode.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/quickstart.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# available models: https://huggingface.co/urchade\n\nmodel = GLiNER.from_pretrained(\"urchade/gliner_medium\")\nmodel.eval()\nprint(\"ok\")\n```\n\n----------------------------------------\n\nTITLE: Configuring and Running GLiNER Model Training\nDESCRIPTION: Sets up training parameters including learning rates, batch sizes, and optimization strategies. Initializes the trainer with the model, datasets, and training arguments, then starts the training process.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/finetune.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# calculate number of epochs\nnum_steps = 500\nbatch_size = 8\ndata_size = len(train_dataset)\nnum_batches = data_size // batch_size\nnum_epochs = max(1, num_steps // num_batches)\n\ntraining_args = TrainingArguments(\n    output_dir=\"models\",\n    learning_rate=5e-6,\n    weight_decay=0.01,\n    others_lr=1e-5,\n    others_weight_decay=0.01,\n    lr_scheduler_type=\"linear\", #cosine\n    warmup_ratio=0.1,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    focal_loss_alpha=0.75,\n    focal_loss_gamma=2,\n    num_train_epochs=num_epochs,\n    evaluation_strategy=\"steps\",\n    save_steps = 100,\n    save_total_limit=10,\n    dataloader_num_workers = 0,\n    use_cpu = False,\n    report_to=\"none\",\n    )\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=model.data_processor.transformer_tokenizer,\n    data_collator=data_collator,\n)\n\ntrainer.train()\n```\n\n----------------------------------------\n\nTITLE: Constructing Relations Extraction Pipeline with UTCA\nDESCRIPTION: Example showing how to construct a relations extraction pipeline using the UTCA framework with GLiNER. This demonstrates initializing a predictor and creating a pipeline that combines NER and relation extraction.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom utca.core import RenameAttribute\nfrom utca.implementation.predictors import (\n    GLiNERPredictor,\n    GLiNERPredictorConfig\n)\nfrom utca.implementation.tasks import (\n    GLiNER,\n    GLiNERPreprocessor,\n    GLiNERRelationExtraction,\n    GLiNERRelationExtractionPreprocessor,\n)\n\npredictor = GLiNERPredictor( # Predictor manages the model that will be used by tasks\n    GLiNERPredictorConfig(\n        model_name = \"knowledgator/gliner-multitask-v1.0\", # Model to use\n        device = \"cuda:0\", # Device to use\n    )\n)\n\npipe = (\n    GLiNER( # GLiNER task produces classified entities that will be at the \"output\" key.\n        predictor=predictor,\n        preprocess=GLiNERPreprocessor(threshold=0.7) # Entities threshold\n    ) \n    | RenameAttribute(\"output\", \"entities\") # Rename output entities from GLiNER task to use them as inputs in GLiNERRelationExtraction\n    | GLiNERRelationExtraction( # GLiNERRelationExtraction is used for relation extraction.\n        predictor=predictor,\n        preprocess=(\n            GLiNERPreprocessor(threshold=0.5) # Relations threshold\n            | GLiNERRelationExtractionPreprocessor()\n        )\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Loading Pre-trained GLiNER Model\nDESCRIPTION: Imports and loads a pre-trained GLiNER model from Hugging Face model repository, and moves it to the appropriate device (CUDA GPU if available, otherwise CPU).\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/exal_example_conll.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Load the pre-trained GLiNER model\nfrom gliner import GLiNER\nimport torch\n\nmodel = GLiNER.from_pretrained(\"urchade/gliner_small\", load_tokenizer=True) #true if a model was trained from scratch with new code base\n\nif torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\n\nmodel = model.to(device)\n```\n\n----------------------------------------\n\nTITLE: Evaluating GLiNER Model on Dataset\nDESCRIPTION: Evaluates the GLiNER model on the first 100 samples of the processed dataset, specifying that flat NER evaluation should be used with the defined entity types.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/exal_example_conll.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Evaluate the model on the first 100 samples\nevaluation_results = model.evaluate(\n    gliner_data_conll[:100], flat_ner=True, entity_types=[\"person\", \"organization\", \"location\", \"others\"]\n)\n```\n\n----------------------------------------\n\nTITLE: Loading ONNX Model for Inference\nDESCRIPTION: Loads the exported ONNX model for inference, specifying to use the ONNX runtime and to load the tokenizer.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# load onnx model\nmodel = GLiNER.from_pretrained(\"gliner_medium\", load_onnx_model=True, load_tokenizer=True)\n```\n\n----------------------------------------\n\nTITLE: Evaluating GLiNERRelationExtractor on a Dataset\nDESCRIPTION: Example showing how to evaluate the GLiNERRelationExtractor on a relation extraction dataset from Hugging Face.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfrom datasets import load_dataset\n\ndataset = load_dataset('docred', split='test')\nmetrics = relation_extractor.evaluate(dataset=dataset)\nprint(metrics)\n```\n\n----------------------------------------\n\nTITLE: Loading Trained GLiNER Model Checkpoint\nDESCRIPTION: Loads a previously saved model checkpoint from the training process. This allows for using the trained model for inference without retraining.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/finetune.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntrained_model = GLiNER.from_pretrained(\"models/checkpoint-100\", load_tokenizer=True)\n```\n\n----------------------------------------\n\nTITLE: Converting Training Data to GLiNER Format\nDESCRIPTION: Applies the ner_tags_to_spans function to each sample in the training dataset to convert the data from BIO tag format to span format required by GLiNER.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/exal_example_conll.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Convert NER tags to spans for the training data\ngliner_data_conll = [ner_tags_to_spans(i, tag_to_id) for i in dataset['train']]\n```\n\n----------------------------------------\n\nTITLE: Iterating Through Detected Entities\nDESCRIPTION: Loops through all entities found in the processed document and prints each entity's text along with its assigned label type. This allows for programmatic access to the entity recognition results.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/gliner_spacy_demo.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfor ent in doc.ents:\n    print(ent.text, ent.label_)\n```\n\n----------------------------------------\n\nTITLE: Moving Model to GPU\nDESCRIPTION: Transfers the model to the selected device (GPU or CPU) for training. This step is crucial for utilizing GPU acceleration if available.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/finetune.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Optional: compile model for faster training\nmodel.to(device)\nprint(\"done\")\n```\n\n----------------------------------------\n\nTITLE: Loading CoNLL-2003 Dataset\nDESCRIPTION: Loads the CoNLL-2003 dataset using the datasets library. This dataset is commonly used for training and evaluating NER models.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/exal_example_conll.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# step 1: load data\ndataset = load_dataset(\"eriktks/conll2003\")\n```\n\n----------------------------------------\n\nTITLE: Installing GLiNER via pip\nDESCRIPTION: Command to install the GLiNER package using pip. This is the first step required before using the model in your Python environment.\nSOURCE: https://github.com/urchade/gliner/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install gliner\n```\n\n----------------------------------------\n\nTITLE: Loading, Shuffling, and Splitting the Dataset\nDESCRIPTION: Loads the dataset from a JSON file, shuffles it for randomization, and splits it into training (90%) and testing (10%) sets for model evaluation.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/finetune.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntrain_path = \"data.json\"\n\nwith open(train_path, \"r\") as f:\n    data = json.load(f)\n\nprint('Dataset size:', len(data))\n\nrandom.shuffle(data)\nprint('Dataset is shuffled...')\n\ntrain_dataset = data[:int(len(data)*0.9)]\ntest_dataset = data[int(len(data)*0.9):]\n\nprint('Dataset is splitted...')\n```\n\n----------------------------------------\n\nTITLE: Converting NER Tags to Spans Function\nDESCRIPTION: Defines a function that converts BIO-tagged NER data into spans with start position, end position, and entity type. This prepares the data for use with the GLiNER model.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/exal_example_conll.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef ner_tags_to_spans(samples, tag_to_id):\n    \"\"\"\n    Converts NER tags in the dataset samples to spans (start, end, entity type).\n    \n    Args:\n        samples (dict): A dictionary containing the tokens and NER tags.\n        tag_to_id (dict): A dictionary mapping NER tags to IDs.\n    \n    Returns:\n        dict: A dictionary containing tokenized text and corresponding NER spans.\n    \"\"\"\n    ner_tags = samples[\"ner_tags\"]\n    id_to_tag = {v: k for k, v in tag_to_id.items()}\n    spans = []\n    start_pos = None\n    entity_name = None\n\n    for i, tag in enumerate(ner_tags):\n        if tag == 0:  # 'O' tag\n            if entity_name is not None:\n                spans.append((start_pos, i - 1, entity_name))\n                entity_name = None\n                start_pos = None\n        else:\n            tag_name = id_to_tag[tag]\n            if tag_name.startswith('B-'):\n                if entity_name is not None:\n                    spans.append((start_pos, i - 1, entity_name))\n                entity_name = tag_name[2:]\n                start_pos = i\n            elif tag_name.startswith('I-'):\n                continue\n\n    # Handle the last entity if the sentence ends with an entity\n    if entity_name is not None:\n        spans.append((start_pos, len(samples[\"tokens\"]) - 1, entity_name))\n    \n    return {\"tokenized_text\": samples[\"tokens\"], \"ner\": spans}\n```\n\n----------------------------------------\n\nTITLE: Evaluating GLiNERClassifier on a Dataset\nDESCRIPTION: Example showing how to evaluate the GLiNERClassifier on a Hugging Face dataset.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmetrics = classifier.evaluate('dair-ai/emotion')\nprint(metrics)\n```\n\n----------------------------------------\n\nTITLE: Creating Batch Prompts for Job Ad Generation\nDESCRIPTION: Creates multiple prompts for generating job advertisements by randomly sampling job sectors and countries, then formatting them as inputs to the LLM.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# create prompts\nNUM_SAMPLES = 100\n\nimport random\n\nall_prompts = []\n\nfor i in range(NUM_SAMPLES):\n    # sample\n    job_sector = random.choice(job_sectors)\n    country = random.choice(countries)\n    \n    prompt = create_json_prompt_for_synthetic_data(language=\"english\", \n                                                   types_of_text=\"detailled job ads\", \n                                                   sector=job_sector, \n                                                   country=country)\n    all_prompts.append(prompt)\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Data from Prompts\nDESCRIPTION: Creates a function to generate synthetic data using the LLM. It sends the formatted prompt to the model and parses the JSON response.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\ndef generate(**kwargs):\n    outputs = llm.generate([create_json_prompt_for_synthetic_data(**kwargs)], sampling_params)\n    return json.loads(outputs[0].outputs[0].text)\n```\n\n----------------------------------------\n\nTITLE: Printing Evaluation Results\nDESCRIPTION: Prints the evaluation results returned by the GLiNER model, which typically include metrics such as precision, recall, and F1 score for the NER task.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/exal_example_conll.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(evaluation_results)\n```\n\n----------------------------------------\n\nTITLE: Implementing Text Processing and Entity Extraction Functions\nDESCRIPTION: Defines functions for tokenizing text and extracting entity spans from the generated data. The output is formatted for NER training with tokenized text and entity spans.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# post processing functions\n\nimport re\n\ndef tokenize_text(text):\n    \"\"\"Tokenize the input text into a list of tokens.\"\"\"\n    return re.findall(r'\\w+(?:[-_]\\w+)*|\\S', text)\n\ndef extract_entities(data):\n    all_examples = []\n\n    for dt in data:\n\n        # Attempt to extract entities; skip current record on failure\n        try:\n            tokens = tokenize_text(dt['text'])\n            ents = [(k[\"entity\"], k[\"types\"]) for k in dt['entities']]\n        except:\n            continue\n\n        spans = []\n        for entity in ents:\n            entity_tokens = tokenize_text(str(entity[0]))\n\n            # Find the start and end indices of each entity in the tokenized text\n            for i in range(len(tokens) - len(entity_tokens) + 1):\n                if \" \".join(tokens[i:i + len(entity_tokens)]).lower() == \" \".join(entity_tokens).lower():\n                    for el in entity[1]:\n                        spans.append((i, i + len(entity_tokens) - 1, el.lower().replace('_', ' ')))\n\n        # Append the tokenized text and its corresponding named entity recognition data\n        all_examples.append({\"tokenized_text\": tokens, \"ner\": spans})\n\n    return all_examples\n\n# generation functions\ndef generate_from_prompts(prompts, llm, sampling_params):\n    outputs = llm.generate(prompts, sampling_params)\n\n    all_outs = []\n    \n    for output in outputs:\n        try:\n            js = json.loads(output.outputs[0].text.strip())\n        except:\n            continue\n            \n        all_outs.append(js)\n\n    return all_outs, extract_entities(all_outs)\n```\n\n----------------------------------------\n\nTITLE: Initializing GLiNERClassifier for Text Classification\nDESCRIPTION: Example of initializing the GLiNERClassifier pipeline for text classification tasks using a pre-trained GLiNER multitask model.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom gliner import GLiNER\nfrom gliner.multitask import GLiNERClassifier\n\nmodel_id = 'knowledgator/gliner-multitask-v1.0'\nmodel = GLiNER.from_pretrained(model_id)\nclassifier = GLiNERClassifier(model=model)\n```\n\n----------------------------------------\n\nTITLE: Importing spaCy and Gliner Extension\nDESCRIPTION: Imports the necessary libraries for using Gliner NER with spaCy, including the core spaCy library and the GlinerSpacy pipeline component.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/gliner_spacy_demo.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport spacy\nfrom gliner_spacy.pipeline import GlinerSpacy\n```\n\n----------------------------------------\n\nTITLE: Loading GLiNER Model from Local Directory\nDESCRIPTION: Loads the previously saved GLiNER model from the local directory, also loading the tokenizer along with the model.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ngliner_model = GLiNER.from_pretrained(\"gliner_medium\", load_tokenizer=True)\n```\n\n----------------------------------------\n\nTITLE: Defining Sample Data for Job Ad Generation\nDESCRIPTION: Creates lists of countries and job sectors to use as parameters for generating diverse synthetic job advertisements with entities.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# I have used GPT-4 to generate these\n\n# List of countries\ncountries = [\n    \"Madagascar\", \"Taiwan\", \"USA\", \"Germany\", \"France\", \"Spain\", \"Russia\", \"China\", \n    \"Japan\", \"Brazil\", \"India\", \"Egypt\", \"South Africa\", \"Australia\", \"Canada\", \n    \"Mexico\", \"Indonesia\", \"Nigeria\", \"Turkey\", \"United Kingdom\", \"Italy\", \"Poland\", \n    \"Argentina\", \"Netherlands\", \"Belgium\", \"Switzerland\", \"Sweden\", \"Norway\", \"Finland\",\n    \"Denmark\", \"Portugal\", \"Greece\", \"Iran\", \"Thailand\", \"Philippines\", \"Vietnam\", \n    \"South Korea\", \"Saudi Arabia\", \"Israel\", \"UAE\", \"New Zealand\", \"Ireland\", \"Malaysia\",\n    \"Singapore\", \"Hong Kong\", \"Czech Republic\", \"Hungary\", \"Romania\", \"Colombia\", \n    \"Peru\", \"Venezuela\", \"Chile\", \"Morocco\", \"Algeria\", \"Tunisia\", \"Nepal\", \"Pakistan\", \"Bangladesh\", \n    \"Kazakhstan\", \"Ukraine\", \"Austria\", \"Croatia\", \"Serbia\", \"Kenya\", \"Ghana\", \"Zimbabwe\",\n    \"Cuba\", \"Panama\", \"Fiji\", \"Mongolia\", \"North Korea\", \"Myanmar\", \"Ethiopia\", \"Tanzania\",\n    \"Algeria\", \"Libya\", \"Jordan\", \"Qatar\", \"Oman\", \"Kuwait\", \"Lebanon\", \"Bulgaria\", \"Slovakia\",\n    \"Lithuania\", \"Latvia\", \"Estonia\", \"Cyprus\", \"Luxembourg\", \"Macao\", \"Bhutan\", \"Maldives\",\n    \"Angola\", \"Cameroon\", \"Senegal\", \"Mali\", \"Zambia\", \"Uganda\", \"Namibia\", \"Botswana\",\n    \"Mozambique\", \"Ivory Coast\", \"Burkina Faso\", \"Malawi\", \"Gabon\", \"Lesotho\", \"Gambia\",\n    \"Guinea\", \"Cape Verde\", \"Rwanda\", \"Benin\", \"Burundi\", \"Somalia\", \"Eritrea\", \"Djibouti\",\n    \"Togo\", \"Seychelles\", \"Chad\", \"Central African Republic\", \"Liberia\", \"Mauritania\", \"Sri Lanka\",\n    \"Sierra Leone\", \"Equatorial Guinea\", \"Swaziland\", \"Congo (Kinshasa)\", \"Congo (Brazzaville)\"\n]\n\n# job sectors\njob_sectors = [\n    # Finance Sector Specializations\n    \"Investment Banking\",\n    \"Corporate Finance\",\n    \"Asset Management\",\n    \"Risk Management\",\n    \"Quantitative Analysis\",\n    \"Financial Planning\",\n    \n    # Machine Learning and AI Specializations\n    \"Natural Language Processing\",\n    \"Computer Vision\",\n    \"Deep Learning\",\n    \"Reinforcement Learning\",\n    \"Predictive Analytics\",\n    \"Algorithm Development\",\n    \n    # Healthcare Sector Specializations\n    \"Medical Research\",\n    \"Clinical Trials\",\n    \"Health Informatics\",\n    \"Biomedical Engineering\",\n    \"Public Health Administration\",\n    \"Pharmaceuticals\",\n    \n    # Education Sector Specializations\n    \"Curriculum Development\",\n    \"Educational Technology\",\n    \"Special Education\",\n    \"Higher Education Administration\",\n    \"Educational Policy\",\n    \"Language Instruction\",\n    \n    # Manufacturing Sector Specializations\n    \"Process Engineering\",\n    \"Quality Control\",\n    \"Industrial Design\",\n    \"Supply Chain Optimization\",\n    \"Robotics Manufacturing\",\n    \"Lean Manufacturing\",\n    \n    # Energy Sector Specializations\n    \"Renewable Energy Systems\",\n    \"Oil and Gas Exploration\",\n    \"Energy Efficiency Consulting\",\n    \"Nuclear Engineering\",\n    \"Smart Grid Technology\",\n    \"Energy Policy\",\n    \n    # Environmental Sector Specializations\n    \"Wildlife Conservation\",\n    \"Environmental Science\",\n    \"Water Resource Management\",\n    \"Sustainability Strategy\",\n    \"Climate Change Analysis\",\n    \"Environmental Law\",\n    \n    # Media and Communications Specializations\n    \"Digital Marketing\",\n    \"Journalism\",\n    \"Public Relations\",\n    \"Film Production\",\n    \"Broadcasting\",\n    \"Content Strategy\",\n    \n    # Legal Sector Specializations\n    \"Corporate Law\",\n    \"International Law\",\n    \"Intellectual Property\",\n    \"Environmental Law\",\n    \"Civil Litigation\",\n    \"Criminal Defense\",\n    \n    # Retail Sector Specializations\n    \"E-commerce Strategy\",\n    \"Store Management\",\n    \"Merchandise Planning\",\n    \"Customer Experience Management\",\n    \"Retail Analytics\",\n    \"Supply Chain Logistics\"\n]\n```\n\n----------------------------------------\n\nTITLE: Creating Data Collator for GLiNER\nDESCRIPTION: Initializes a data collator that will be used during training to prepare batches of data. This specific collator mimics the original implementation but is less memory efficient.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/finetune.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# use it for better performance, it mimics original implementation but it's less memory efficient\ndata_collator = DataCollator(model.config, data_processor=model.data_processor, prepare_labels=True)\n```\n\n----------------------------------------\n\nTITLE: Loading GLiNER Pretrained Model\nDESCRIPTION: Loads a pretrained GLiNER model from the Hugging Face Hub, specifically the 'gliner_medium' variant provided by 'urchade'.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodel = GLiNER.from_pretrained(\"urchade/gliner_medium\")\n```\n\n----------------------------------------\n\nTITLE: Installing GLiNER with GPU Support\nDESCRIPTION: Command to install GLiNER with GPU capabilities, which includes the onnxruntime-gpu dependency for GPU-accelerated inference.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n!pip install gliner[gpu]\n```\n\n----------------------------------------\n\nTITLE: Summarizing Text with GLiNER in Python\nDESCRIPTION: Extract important information from a given text and construct a summary using the GLiNER summarizer. The example uses a threshold parameter to control the amount of information included in the summary.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\ntext = \"Microsoft was founded by Bill Gates and Paul Allen on April 4, 1975 to develop and sell BASIC interpreters for the Altair 8800. During his career at Microsoft, Gates held the positions of chairman, chief executive officer, president and chief software architect, while also being the largest individual shareholder until May 2014.\"\nsummary = relation_extractor(text, threshold=0.1)\nprint(summary)\n```\n\n----------------------------------------\n\nTITLE: Quantizing ONNX Model for Efficiency\nDESCRIPTION: Applies dynamic quantization to the ONNX model to reduce its size and improve inference speed. The weights are quantized to 8-bit unsigned integers.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n#quantize model\nfrom onnxruntime.quantization import quantize_dynamic, QuantType\n\nquantized_save_path = os.path.join(\"gliner_medium\", \"model_quantized.onnx\")\n# Quantize the ONNX model\nprint(\"Quantizing the model...\")\nquantize_dynamic(\n    onnx_save_path,  # Input model\n    quantized_save_path,  # Output model\n    weight_type=QuantType.QUInt8  # Quantize weights to 8-bit integers\n)\n```\n\n----------------------------------------\n\nTITLE: Importing GLiNER Dependencies\nDESCRIPTION: Initial imports required for using GLiNER with PyTorch\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/load_local_model.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom gliner import GLiNER\n```\n\n----------------------------------------\n\nTITLE: Git Tag Commands\nDESCRIPTION: Commands for creating and pushing version tags to the repository.\nSOURCE: https://github.com/urchade/gliner/blob/main/RELEASE.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit tag v<VERSION>\ngit push --tags origin main\n```\n\n----------------------------------------\n\nTITLE: Preparing Model Inputs for ONNX Conversion\nDESCRIPTION: Prepares sample inputs for the model using text and labels, which will be used for tracing the model during ONNX conversion.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntext = \"ONNX is an open-source format designed to enable the interoperability of AI models across various frameworks and tools.\"\nlabels = ['format', 'model', 'tool', 'cat']\n\ninputs, _ = gliner_model.prepare_model_inputs([text], labels)\n```\n\n----------------------------------------\n\nTITLE: Importing GLiNER Dependencies and Setting Environment Variables\nDESCRIPTION: Sets up the environment variable for tokenizer parallelism and imports necessary modules from the GLiNER library including the model, trainer, and data processing utilities.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/finetune.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n\nimport torch\nfrom gliner import GLiNERConfig, GLiNER\nfrom gliner.training import Trainer, TrainingArguments\nfrom gliner.data_processing.collator import DataCollatorWithPadding, DataCollator\nfrom gliner.utils import load_config_as_namespace\nfrom gliner.data_processing import WordsSplitter, GLiNERDataset\n```\n\n----------------------------------------\n\nTITLE: Generating and Processing Synthetic Job Ad Data\nDESCRIPTION: Executes the generation of synthetic job advertisements by sending the batch of prompts to the LLM and processes the outputs into a format suitable for NER training.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\noutput, processed_output = generate_from_prompts(all_prompts, llm, sampling_params)\n```\n\n----------------------------------------\n\nTITLE: Integrating GLiNER with spaCy Pipeline\nDESCRIPTION: Example showing how to add GLiNER to a blank English spaCy pipeline. The code demonstrates configuration options, initialization, and processing text for entity detection.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport spacy\nfrom gliner_spacy.pipeline import GlinerSpacy\n\n# Configuration for GLiNER integration\ncustom_spacy_config = {\n    \"gliner_model\": \"urchade/gliner_mediumv2.1\",\n    \"chunk_size\": 250,\n    \"labels\": [\"person\", \"organization\", \"email\"],\n    \"style\": \"ent\",\n    \"threshold\": 0.3,\n    \"map_location\": \"cpu\" # only available in v.0.0.7\n}\n\n# Initialize a blank English spaCy pipeline and add GLiNER\nnlp = spacy.blank(\"en\")\nnlp.add_pipe(\"gliner_spacy\", config=custom_spacy_config)\n\n# Example text for entity detection\ntext = \"This is a text about Bill Gates and Microsoft.\"\n\n# Process the text with the pipeline\ndoc = nlp(text)\n\n# Output detected entities\nfor ent in doc.ents:\n    print(ent.text, ent.label_, ent._.score) # ent._.score only available in v. 0.0.7\n```\n\n----------------------------------------\n\nTITLE: Custom Model Save/Load Functions - Option 2\nDESCRIPTION: Defines custom functions for saving and loading GLiNER models using state dictionaries and configuration\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/load_local_model.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef save_model(current_model, path):\n    config = current_model.config\n    dict_save = {\"model_weights\": current_model.state_dict(), \"config\": config}\n    torch.save(dict_save, path)\n\n\ndef load_model(path, model_name=None):\n    \n    dict_load = torch.load(path, map_location=torch.device('cpu'))\n    config = dict_load[\"config\"]\n\n    print(f\"'{config.model_name}' should be available for local processing\")\n\n    if model_name is not None:\n        config.model_name = model_name\n\n    loaded_model = GLiNER(config)\n    loaded_model.load_state_dict(dict_load[\"model_weights\"])\n    return loaded_model\n```\n\n----------------------------------------\n\nTITLE: Loading LLM with vLLM for Synthetic Data Generation\nDESCRIPTION: Imports the LLM class and SamplingParams from vLLM, which is used to load and interact with the Mistral-7B-Instruct-v0.2 language model.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom vllm import LLM, SamplingParams\n```\n\n----------------------------------------\n\nTITLE: Test PyPI Upload with Config\nDESCRIPTION: Command to upload to Test PyPI using the configuration file.\nSOURCE: https://github.com/urchade/gliner/blob/main/RELEASE.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ntwine upload dist/* -r gliner_test\n```\n\n----------------------------------------\n\nTITLE: Loading Model Weights - Option 2\nDESCRIPTION: Example of loading model weights using the custom load_model function\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/load_local_model.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# load model weight\n\nloaded_model = load_model(\"model_weight.pt\")\nprint(\"success !!\")\n```\n\n----------------------------------------\n\nTITLE: Loading Quantized ONNX Model for Inference\nDESCRIPTION: Loads the quantized ONNX model for inference, specifying the filename of the quantized model to use.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# load quantized model\nmodel = GLiNER.from_pretrained(\"gliner_medium\", load_onnx_model=True, load_tokenizer=True, onnx_model_file=\"model_quantized.onnx\")\n```\n\n----------------------------------------\n\nTITLE: Defining NER Tag-to-ID Mapping\nDESCRIPTION: Creates a mapping between NER tags (in BIO format) and their corresponding ID numbers, which is necessary for processing the dataset.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/exal_example_conll.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Step 2: Define NER tag-to-ID mapping\ntag_to_id = {\n    'O': 0, 'B-person': 1, 'I-person': 2, 'B-organization': 3, 'I-organization': 4,\n    'B-location': 5, 'I-location': 6, 'B-others': 7, 'I-others': 8\n}\n```\n\n----------------------------------------\n\nTITLE: Predicting Entities with Quantized ONNX Model\nDESCRIPTION: Performs entity recognition on the same literary text sample using the quantized ONNX model to demonstrate its functionality is equivalent to the non-quantized version.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntext = \"\"\"\nLibretto by Marius Petipa, based on the 1822 novella ``Trilby, ou Le Lutin d'Argail`` by Charles Nodier, first presented by the Ballet of the Moscow Imperial Bolshoi Theatre on January 25/February 6 (Julian/Gregorian calendar dates), 1870, in Moscow with Polina Karpakova as Trilby and Ludiia Geiten as Miranda and restaged by Petipa for the Imperial Ballet at the Imperial Bolshoi Kamenny Theatre on January 17–29, 1871 in St. Petersburg with Adèle Grantzow as Trilby and Lev Ivanov as Count Leopold.\n\"\"\"\n\nlabels = [\"person\", \"book\", \"location\", \"date\", \"actor\", \"character\"]\n\nentities = model.predict_entities(text, labels, threshold=0.4)\n\nfor entity in entities:\n    print(entity[\"text\"], \"=>\", entity[\"label\"])\n```\n\n----------------------------------------\n\nTITLE: Utility Function for Saving Data to JSON in Python\nDESCRIPTION: This function saves processed data to a JSON file. It takes a data object and filepath as parameters and writes the data as JSON to the specified file.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Save to JSON\ndef save_data_to_file(data, filepath):\n    \"\"\"Saves the processed data to a JSON file.\"\"\"\n    with open(filepath, 'w') as f:\n        json.dump(data, f)\n```\n\n----------------------------------------\n\nTITLE: Creating Prompts for Synthetic Data Generation\nDESCRIPTION: Defines a function that creates JSON-formatted prompts for generating synthetic annotated text data. The function accepts dynamic attributes that are incorporated into the prompt template.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef create_json_prompt_for_synthetic_data(**kwargs):\n    \n    # Use dictionary comprehension to filter out 'n/a' values and to keep the code flexible\n    attributes = {key: value for key, value in kwargs.items() if value != \"n/a\"}\n    \n    # Building the initial part of the prompt\n    prompt = \"\"\"\n**Objective:**\nProduce realistic text passages that include clearly identified named entities. Each entity should be meticulously labeled according to its type for straightforward extraction.\n\n**Format Requirements:**\n- The output should be formatted in JSON, containing the text and the corresponding entities list.\n- Each entity in the text should be accurately marked and annotated in the 'entities' list.\n- Meticulously follow all the listed attributes.\n\n**Entity Annotation Details:**\n- All entity types must be in lowercase. For example, use \"type\" not \"TYPE\".\n- Entity types can be multiwords separate by space. For instance, use \"entity type\" rather than \"entity_type\".\n- Entities spans can be nested within other entities.\n- A single entity may be associated with multiple types. list them in the key \"types\".\n\n**Output Schema:**\n\n<start attribute_1=\"value1\" attribute_2=\"value2\" ...>\n{\n  \"text\": \"{text content}\",\n  \"entities\": [\n    {\"entity\": \"entity name\", \"types\": [\"type 1\", \"type 2\", ...]},\n    ...\n  ]\n}\n<end>\n\n**Here are some real world examples**:\"\"\"\n\n    # Create a string of attributes for the <start> tag, excluding any 'n/a' values\n    attributes_string = \" \".join([f'{key}=\"{value}\"' for key, value in attributes.items()])\n\n    # Adding the dynamically created attributes string to the prompt\n    prompt += f\"\"\"\n<start {attributes_string}>\n\"\"\"\n\n    return prompt\n```\n\n----------------------------------------\n\nTITLE: Package Installation Commands\nDESCRIPTION: Commands to install the package and its dependencies from Test PyPI.\nSOURCE: https://github.com/urchade/gliner/blob/main/RELEASE.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython -m pip install torch transformers huggingface_hub flair tqdm\npython -m pip install -i https://testpypi.python.org/pypi gliner\n```\n\n----------------------------------------\n\nTITLE: Saving Processed Output to JSON File in Python\nDESCRIPTION: This snippet defines an output filename and uses the previously defined save_data_to_file function to save the processed NER data to a JSON file for training.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\noutput_file = \"job_ads_data_gliner.json\"\n\nsave_data_to_file(processed_output, output_file)\n```\n\n----------------------------------------\n\nTITLE: Loading ONNX-Converted GLiNER Models in Python\nDESCRIPTION: Load a GLiNER model that has been converted to ONNX format. The code specifies the load_onnx_model parameter to load the ONNX version instead of PyTorch, and includes the tokenizer with any custom tokens.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nfrom gliner import GLiNER\n\nmodel = GLiNER.from_pretrained(\"path_to_your_model\", load_onnx_model=True, load_tokenizer=True)\n```\n\n----------------------------------------\n\nTITLE: Configuring LLM Model and Hardware\nDESCRIPTION: Specifies the model to use (Mistral-7B-Instruct-v0.2) and sets the number of GPUs for tensor parallelism when loading the model.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nLLM_MODEL = \"mistralai/Mistral-7B-Instruct-v0.2\" # you can use a better model\nNUM_GPUs = 4\n```\n\n----------------------------------------\n\nTITLE: Loading Saved GLiNER Model - Option 1\nDESCRIPTION: Loads a locally saved GLiNER model with tokenizer using from_pretrained method\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/load_local_model.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# load\n\nloaded_model = GLiNER.from_pretrained(\"gliner_Med\", load_tokenizer = True, local_files_only=True)\n```\n\n----------------------------------------\n\nTITLE: Downloading Training Data for NER\nDESCRIPTION: Downloads a JSON dataset from Hugging Face that contains synthetic PII (Personally Identifiable Information) data for named entity recognition training.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/finetune.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# download data\n! wget https://huggingface.co/datasets/urchade/synthetic-pii-ner-mistral-v1/resolve/main/data.json\n```\n\n----------------------------------------\n\nTITLE: Verifying GLiNER Installation\nDESCRIPTION: Python code snippet to verify the successful installation of GLiNER by importing the library and printing its version.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport gliner\nprint(gliner.__version__)\n```\n\n----------------------------------------\n\nTITLE: Saving Model Weights - Option 2\nDESCRIPTION: Example of saving model weights using the custom save_model function\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/load_local_model.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# save the model weight\n\nsave_model(model, \"model_weight.pt\")\n```\n\n----------------------------------------\n\nTITLE: Viewing a Generated Job Ad Example\nDESCRIPTION: Displays the first generated job advertisement complete with text and entity annotations to verify the output format.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\noutput[0]\n```\n\n----------------------------------------\n\nTITLE: Saving GLiNER Model Locally\nDESCRIPTION: Saves the loaded pretrained GLiNER model to a local directory named 'gliner_medium' for later use.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# save\n\nmodel.save_pretrained(\"gliner_medium\")\n```\n\n----------------------------------------\n\nTITLE: Finding Top 10 Entity Types with Counter in Python\nDESCRIPTION: This snippet uses the Counter collection to identify the 10 most common entity types from the previously collected entities list.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Top 10 entity types\n\nfrom collections import Counter\nCounter(unique_entities).most_common()[:10]\n```\n\n----------------------------------------\n\nTITLE: Importing GLiNER and PyTorch Libraries\nDESCRIPTION: Imports the PyTorch library and the GLiNER class, which is used for entity recognition tasks.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom gliner import GLiNER\n```\n\n----------------------------------------\n\nTITLE: Importing spaCy Visualization Tool\nDESCRIPTION: Imports the displacy module from spaCy, which provides visualization capabilities for displaying recognized entities in text.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/gliner_spacy_demo.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom spacy import displacy\n```\n\n----------------------------------------\n\nTITLE: Saving GLiNER Model - Option 1\nDESCRIPTION: Direct method to save a GLiNER model using built-in save_pretrained function\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/load_local_model.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# save\n\nmodel.save_pretrained(\"gliner_Med\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up a Virtual Environment for GLiNER\nDESCRIPTION: Commands to create and activate a Python virtual environment for isolated GLiNER installation and its dependencies.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv venv\nsource venv/bin/activate   # On Windows use: venv\\Scripts\\activate\n```\n\n----------------------------------------\n\nTITLE: Setting LLM Sampling Parameters\nDESCRIPTION: Configures the generation parameters for the LLM, including top-k and top-p sampling, maximum token output, and a stop sequence to ensure properly formatted responses.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# sampling parameters\nsampling_params = SamplingParams(top_k=100, max_tokens=1000, top_p=0.8, stop=\"<end>\")\n```\n\n----------------------------------------\n\nTITLE: Installing GLiNER from Source\nDESCRIPTION: Command to install the GLiNER package locally using the setup script in the repository directory.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npip install .\n```\n\n----------------------------------------\n\nTITLE: Importing GLiNER Library in Python\nDESCRIPTION: Imports the GLiNER class from the gliner package, which is the main entry point for using the named entity recognition functionality.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/quickstart.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom gliner import GLiNER\n```\n\n----------------------------------------\n\nTITLE: Installing GLiNER spaCy Integration via pip\nDESCRIPTION: Command to install the gliner-spacy package which enables seamless integration with the spaCy NLP framework.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npip install gliner-spacy\n```\n\n----------------------------------------\n\nTITLE: Converting GLiNER Model to ONNX Format using Bash\nDESCRIPTION: Command line example for converting a pretrained GLiNER model to ONNX format. The script supports optional quantization to IntU8 format to reduce model size and improve inference speed.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_27\n\nLANGUAGE: bash\nCODE:\n```\npython convert_to_onnx.py --model_path /path/to/your/model --save_path /path/to/save/onnx --quantize True\n```\n\n----------------------------------------\n\nTITLE: Installing Datasets Library\nDESCRIPTION: Installs the 'datasets' library which is required for loading the CoNLL-2003 dataset used in the NER task.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/exal_example_conll.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install datasets\n```\n\n----------------------------------------\n\nTITLE: Installing GLiNER and Accelerate Libraries\nDESCRIPTION: Installs the GLiNER library and updates the Accelerate library, which are required for the named entity recognition model.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/finetune.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n! pip install gliner\n! pip install accelerate -U\n```\n\n----------------------------------------\n\nTITLE: Importing Dataset Loading Functionality\nDESCRIPTION: Imports the load_dataset function from the datasets library which will be used to load the CoNLL-2003 dataset.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/exal_example_conll.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom datasets import load_dataset\n```\n\n----------------------------------------\n\nTITLE: GLiNER Usage Example\nDESCRIPTION: Example code demonstrating basic usage of the GLiNER package for entity recognition.\nSOURCE: https://github.com/urchade/gliner/blob/main/RELEASE.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom gliner import GLiNER\n\nmodel = GLiNER.from_pretrained(\"urchade/gliner_base\")\n\ntext = \"\"\"\nCristiano Ronaldo dos Santos Aveiro (Portuguese pronunciation: [kɾiʃˈtjɐnu ʁɔˈnaldu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al Nassr and the Portugal national team. Widely regarded as one of the greatest players of all time, Ronaldo has won five Ballon d'Or awards,[note 3] a record three UEFA Men's Player of the Year Awards, and four European Golden Shoes, the most by a European player. He has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues, the UEFA European Championship and the UEFA Nations League. Ronaldo holds the records for most appearances (183), goals (140) and assists (42) in the Champions League, goals in the European Championship (14), international goals (128) and international appearances (205). He is one of the few players to have made over 1,200 professional career appearances, the most by an outfield player, and has scored over 850 official senior career goals for club and country, making him the top goalscorer of all time.\n\"\"\"\n\nlabels = [\"person\", \"award\", \"date\", \"competitions\", \"teams\"]\n\nentities = model.predict_entities(text, labels, threshold=0.5)\n\nfor entity in entities:\n    print(entity[\"text\"], \"=>\", entity[\"label\"])\n```\n\n----------------------------------------\n\nTITLE: Visualizing Named Entities with displaCy\nDESCRIPTION: Renders the processed document using spaCy's displacy visualization tool with the entity style to highlight identified named entities in the text.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/gliner_spacy_demo.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndisplacy.render(doc, style=\"ent\")\n```\n\n----------------------------------------\n\nTITLE: Installing ONNX Package\nDESCRIPTION: Comment showing the pip command to install the ONNX package, which is required for model conversion to ONNX format.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# !pip install onnx\n```\n\n----------------------------------------\n\nTITLE: Installing GLiNER via Conda\nDESCRIPTION: Command to install the GLiNER package using the conda package manager from the conda-forge channel.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nconda install -c conda-forge gliner\n```\n\n----------------------------------------\n\nTITLE: Git Commands for Release\nDESCRIPTION: Commands for committing version changes and creating release tags in git.\nSOURCE: https://github.com/urchade/gliner/blob/main/RELEASE.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit add gliner\ngit commit -m \"Release: v{VERSION}\"\ngit push -u origin main\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for gliner Project\nDESCRIPTION: This requirements list specifies the necessary Python packages and their version constraints for the gliner project. It includes deep learning libraries like PyTorch and Transformers, along with utilities for model loading, tokenization, and progress tracking.\nSOURCE: https://github.com/urchade/gliner/blob/main/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntorch>=2.0.0\ntransformers>=4.38.2,<=4.45.2\nhuggingface_hub>=0.21.4\nonnxruntime-gpu\nsentencepiece\ntqdm\n```\n\n----------------------------------------\n\nTITLE: Package Build Command\nDESCRIPTION: Command to build the distribution packages.\nSOURCE: https://github.com/urchade/gliner/blob/main/RELEASE.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython -m build\n```\n\n----------------------------------------\n\nTITLE: Installing GLiNER Dependencies\nDESCRIPTION: Command to install the required dependencies for GLiNER from the requirements.txt file in the repository.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: PyPI Test Upload Command\nDESCRIPTION: Command to upload the package to Test PyPI for verification.\nSOURCE: https://github.com/urchade/gliner/blob/main/RELEASE.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ntwine upload dist/* -r pypitest --repository-url=https://test.pypi.org/legacy/\n```\n\n----------------------------------------\n\nTITLE: Citation in BibTeX Format for GLiNER\nDESCRIPTION: BibTeX citation information for the GLiNER research paper. This citation should be used when referencing the GLiNER model in academic or research work.\nSOURCE: https://github.com/urchade/gliner/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bibtex\nCODE:\n```\n@inproceedings{zaratiana-etal-2024-gliner,\n    title = \"{GL}i{NER}: Generalist Model for Named Entity Recognition using Bidirectional Transformer\",\n    author = \"Zaratiana, Urchade  and\n      Tomeh, Nadi  and\n      Holat, Pierre  and\n      Charnois, Thierry\",\n    editor = \"Duh, Kevin  and\n      Gomez, Helena  and\n      Bethard, Steven\",\n    booktitle = \"Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = jun,\n    year = \"2024\",\n    address = \"Mexico City, Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.naacl-long.300\",\n    doi = \"10.18653/v1/2024.naacl-long.300\",\n    pages = \"5364--5376\",\n    abstract = \"Named Entity Recognition (NER) is essential in various Natural Language Processing (NLP) applications. Traditional NER models are effective but limited to a set of predefined entity types. In contrast, Large Language Models (LLMs) can extract arbitrary entities through natural language instructions, offering greater flexibility. However, their size and cost, particularly for those accessed via APIs like ChatGPT, make them impractical in resource-limited scenarios. In this paper, we introduce a compact NER model trained to identify any type of entity. Leveraging a bidirectional transformer encoder, our model, GLiNER, facilitates parallel entity extraction, an advantage over the slow sequential token generation of LLMs. Through comprehensive testing, GLiNER demonstrate strong performance, outperforming both ChatGPT and fine-tuned LLMs in zero-shot evaluations on various NER benchmarks.\",\n}\n```\n\n----------------------------------------\n\nTITLE: PyPI Upload Command\nDESCRIPTION: Command to upload the final package to PyPI production.\nSOURCE: https://github.com/urchade/gliner/blob/main/RELEASE.md#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ntwine upload dist/* -r pypi\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Number of Entities in Python\nDESCRIPTION: This snippet calculates the average number of named entities per document by counting entities in each document's 'ner' field and computing the average.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nlen_ner = []\n\nfor d in processed_output:\n    len_ner.append(len(d[\"ner\"]))\n        \nprint(\"Avg num of entities:\", sum(len_ner) / len(len_ner))\n```\n\n----------------------------------------\n\nTITLE: Counting Unique Entity Types in Python\nDESCRIPTION: This snippet extracts and counts the total number of unique entity types from the processed NER data by iterating through each document's entity annotations.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nunique_entities = []\n\nfor d in processed_output:\n    for n in d[\"ner\"]:\n        unique_entities.append((str(n[2]).lower()))\n\nprint(\"Unique entity types:\", len(unique_entities))\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Token Length in Python\nDESCRIPTION: This snippet calculates the average number of tokens in the processed output by iterating through each document, getting the length of tokenized text, and computing the average.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/synthetic_data_generation.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nlengths = []\n\nfor d in processed_output:\n    lengths.append(len(d[\"tokenized_text\"]))\n\nprint(\"Avg num tokens:\", sum(lengths) / len(lengths))\n```\n\n----------------------------------------\n\nTITLE: Setting Up ONNX Export Path\nDESCRIPTION: Imports the os module and defines the file path where the ONNX version of the model will be saved.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/convert_to_onnx.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nonnx_save_path = os.path.join(\"gliner_medium\", \"model.onnx\")\n```\n\n----------------------------------------\n\nTITLE: Importing JSON and Random Libraries\nDESCRIPTION: Imports the necessary Python libraries for data handling (json) and randomization (random) which will be used in data preparation.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/finetune.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport json\nimport random\n```\n\n----------------------------------------\n\nTITLE: Cloning the GLiNER Repository\nDESCRIPTION: Command to clone the GLiNER GitHub repository to a local machine for source installation.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/urchade/GLiNER\n```\n\n----------------------------------------\n\nTITLE: Navigating to GLiNER Project Directory\nDESCRIPTION: Command to change the current working directory to the GLiNER repository folder after cloning.\nSOURCE: https://github.com/urchade/gliner/blob/main/README_Extended.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd GLiNER\n```\n\n----------------------------------------\n\nTITLE: Version Update Diff in __init__.py\nDESCRIPTION: Shows how to update the version number in the package's __init__.py file from development to release version.\nSOURCE: https://github.com/urchade/gliner/blob/main/RELEASE.md#2025-04-23_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n- __version__ = \"0.4.0.dev\"\n+ __version__ = \"0.4.0\"\n```\n\n----------------------------------------\n\nTITLE: Build Directory Cleanup\nDESCRIPTION: Command to clean previous build artifacts before creating a new release.\nSOURCE: https://github.com/urchade/gliner/blob/main/RELEASE.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nrm -rf build && rm -rf dist\n```\n\n----------------------------------------\n\nTITLE: PyPI Configuration File\nDESCRIPTION: Example configuration for ~/.pypirc file to store PyPI credentials.\nSOURCE: https://github.com/urchade/gliner/blob/main/RELEASE.md#2025-04-23_snippet_6\n\nLANGUAGE: text\nCODE:\n```\n[distutils]\n  index-servers =\n    gliner_test\n\n[gliner_test]\n  repository = https://test.pypi.org/legacy/\n  username = __token__\n  password = pypi-...\n```\n\n----------------------------------------\n\nTITLE: Processing Text with Gliner NER\nDESCRIPTION: Defines a sample text containing potential named entities and processes it through the spaCy pipeline with the Gliner NER component to identify entities.\nSOURCE: https://github.com/urchade/gliner/blob/main/examples/gliner_spacy_demo.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntext = \"This is a text about Bill Gates and Microsoft.\"\ndoc = nlp(text)\n```"
  }
]