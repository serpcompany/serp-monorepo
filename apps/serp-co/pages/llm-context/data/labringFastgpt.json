[
  {
    "owner": "labring",
    "repo": "fastgpt",
    "content": "TITLE: Configuring Cloudflare Worker for OpenAI API Proxy in JavaScript\nDESCRIPTION: This code sets up a Cloudflare Worker to proxy requests to the OpenAI API. It includes authentication, request modification, and CORS handling. The worker intercepts fetch events, validates an auth code, and forwards the request to the OpenAI API endpoint.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/proxy/cloudflare.md#2025-04-10_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nconst TELEGRAPH_URL = 'https://api.openai.com';\n\naddEventListener('fetch', (event) => {\n  event.respondWith(handleRequest(event.request));\n});\n\nasync function handleRequest(request) {\n  // 安全校验\n  if (request.headers.get('auth') !== 'auth_code') {\n    return new Response('UnAuthorization', { status: 403 });\n  }\n\n  const url = new URL(request.url);\n  url.host = TELEGRAPH_URL.replace(/^https?:\\/\\//, '');\n\n  const modifiedRequest = new Request(url.toString(), {\n    headers: request.headers,\n    method: request.method,\n    body: request.body,\n    redirect: 'follow'\n  });\n\n  const response = await fetch(modifiedRequest);\n  const modifiedResponse = new Response(response.body, response);\n\n  // 添加允许跨域访问的响应头\n  modifiedResponse.headers.set('Access-Control-Allow-Origin', '*');\n\n  return modifiedResponse;\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring FastGPT System and Model Parameters in JSON\nDESCRIPTION: This JSON configuration file defines system environment variables and frontend configurations for FastGPT version 4.8.20+. It includes settings for vector processing, question-answering, VLM processing, token calculation, vector search parameters, and custom PDF parsing services.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/configuration.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"feConfigs\": {\n    \"lafEnv\": \"https://laf.dev\"\n  },\n  \"systemEnv\": {\n    \"vectorMaxProcess\": 15,\n    \"qaMaxProcess\": 15,\n    \"vlmMaxProcess\": 15,\n    \"tokenWorkers\": 50,\n    \"hnswEfSearch\": 100,\n    \"customPdfParse\": {\n      \"url\": \"\",\n      \"key\": \"\",\n      \"doc2xKey\": \"\",\n      \"price\": 0\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: 使用createHmac进行加密的JavaScript代码\nDESCRIPTION: 展示如何在FastGPT代码运行节点中使用内置的createHmac函数进行HMAC加密，返回签名和时间戳。该函数与Node.js中crypto模块的createHmac方法功能一致。\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/workbench/workflow/sandbox.md#2025-04-10_snippet_4\n\nLANGUAGE: js\nCODE:\n```\nfunction main({secret}){\n    const {sign,timestamp} = createHmac('sha256',secret)\n\n    return {\n        sign,timestamp\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Performing Speech Recognition using ModelScope Pipeline with SenseVoice\nDESCRIPTION: This snippet demonstrates how to use the ModelScope pipeline to perform automatic speech recognition with the SenseVoice Small model. It loads the model and processes an audio file URL to generate recognition results.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/SenseVoiceSmall/README.md#2025-04-10_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom modelscope.pipelines import pipeline\nfrom modelscope.utils.constant import Tasks\n\ninference_pipeline = pipeline(\n    task=Tasks.auto_speech_recognition,\n    model='iic/SenseVoiceSmall',\n    model_revision=\"master\")\n\nrec_result = inference_pipeline('https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav')\nprint(rec_result)\n```\n\n----------------------------------------\n\nTITLE: Direct Inference with SenseVoice Small Model\nDESCRIPTION: This code demonstrates how to directly use the SenseVoice Small model for speech recognition without using the ModelScope pipeline. It loads the pretrained model and processes an audio file with customizable language detection and ITN settings.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/SenseVoiceSmall/README.md#2025-04-10_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom model import SenseVoiceSmall\n\nmodel_dir = \"iic/SenseVoiceSmall\"\nm, kwargs = SenseVoiceSmall.from_pretrained(model=model_dir)\n\n\nres = m.inference(\n    data_in=\"https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav\",\n    language=\"auto\", # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n    use_itn=False,\n    **kwargs,\n)\n\nprint(res)\n```\n\n----------------------------------------\n\nTITLE: Adding Batch Data to a Collection in FastGPT\nDESCRIPTION: This snippet demonstrates how to add multiple data entries to a collection. It supports up to 200 data entries per request and includes options for custom indexing and training types.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://api.fastgpt.in/api/core/dataset/data/pushData' \\\n--header 'Authorization: Bearer apikey' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"collectionId\": \"64663f451ba1676dbdef0499\",\n    \"trainingType\": \"chunk\",\n    \"prompt\": \"可选。qa 拆分引导词，chunk 模式下忽略\",\n    \"billId\": \"可选。如果有这个值，本次的数据会被聚合到一个订单中，这个值可以重复使用。可以参考 [创建训练订单] 获取该值。\",\n    \"data\": [\n        {\n            \"q\": \"你是谁？\",\n            \"a\": \"我是FastGPT助手\"\n        },\n        {\n            \"q\": \"你会什么？\",\n            \"a\": \"我什么都会\",\n            \"indexes\": [\n                {\n                    \"text\":\"自定义索引1\"\n                },\n                {\n                    \"text\":\"自定义索引2\"\n                }\n            ]\n        }\n    ]\n}'\n```\n\n----------------------------------------\n\nTITLE: FastGPT Workflow Configuration JSON for Movie Assistant Chatbot\nDESCRIPTION: A comprehensive JSON configuration for a FastGPT workflow that creates an AI assistant for the movie 'Interstellar'. The workflow includes nodes for user input, system settings with welcome text, templated replies, and an AI chat module connected to a knowledge base.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/fixingEvidence.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"nodes\": [\n    {\n      \"nodeId\": \"7z5g5h\",\n      \"name\": \"流程开始\",\n      \"intro\": \"\",\n      \"avatar\": \"/imgs/workflow/userChatInput.svg\",\n      \"flowNodeType\": \"workflowStart\",\n      \"position\": {\n        \"x\": -269.50851681351924,\n        \"y\": 1657.6123698022448\n      },\n      \"inputs\": [\n        {\n          \"key\": \"userChatInput\",\n          \"renderTypeList\": [\n            \"reference\",\n            \"textarea\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"问题输入\",\n          \"required\": true,\n          \"toolDescription\": \"用户问题\",\n          \"type\": \"systemInput\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0,\n          \"value\": [\n            \"7z5g5h\",\n            \"userChatInput\"\n          ]\n        }\n      ],\n      \"outputs\": [\n        {\n          \"id\": \"userChatInput\",\n          \"type\": \"static\",\n          \"key\": \"userChatInput\",\n          \"valueType\": \"string\",\n          \"label\": \"core.module.input.label.user question\"\n        }\n      ]\n    },\n    {\n      \"nodeId\": \"nlfwkc\",\n      \"name\": \"AI 对话\",\n      \"intro\": \"AI 大模型对话\",\n      \"avatar\": \"/imgs/workflow/AI.png\",\n      \"flowNodeType\": \"chatNode\",\n      \"showStatus\": true,\n      \"position\": {\n        \"x\": 907.2058332478431,\n        \"y\": 1348.9992737142143\n      },\n      \"inputs\": [\n        {\n          \"key\": \"model\",\n          \"renderTypeList\": [\n            \"settingLLMModel\",\n            \"reference\"\n          ],\n          \"label\": \"core.module.input.label.aiModel\",\n          \"valueType\": \"string\",\n          \"type\": \"selectLLMModel\",\n          \"required\": true,\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"value\": \"gpt-3.5-turbo\",\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"temperature\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"value\": 0,\n          \"valueType\": \"number\",\n          \"min\": 0,\n          \"max\": 10,\n          \"step\": 1,\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"maxToken\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"value\": 2000,\n          \"valueType\": \"number\",\n          \"min\": 100,\n          \"max\": 4000,\n          \"step\": 50,\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"isResponseAnswerText\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"value\": true,\n          \"valueType\": \"boolean\",\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"quoteTemplate\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"valueType\": \"string\",\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"quotePrompt\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"valueType\": \"string\",\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"systemPrompt\",\n          \"renderTypeList\": [\n            \"textarea\",\n            \"reference\"\n          ],\n          \"max\": 300,\n          \"valueType\": \"string\",\n          \"label\": \"core.ai.Prompt\",\n          \"description\": \"core.app.tip.chatNodeSystemPromptTip\",\n          \"placeholder\": \"core.app.tip.chatNodeSystemPromptTip\",\n          \"type\": \"textarea\",\n          \"showTargetInApp\": true,\n          \"showTargetInPlugin\": true,\n          \"value\": \"\",\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"history\",\n          \"renderTypeList\": [\n            \"numberInput\",\n            \"reference\"\n          ],\n          \"valueType\": \"chatHistory\",\n          \"label\": \"core.module.input.label.chat history\",\n          \"required\": true,\n          \"min\": 0,\n          \"max\": 30,\n          \"value\": 6,\n          \"type\": \"numberInput\",\n          \"showTargetInApp\": true,\n          \"showTargetInPlugin\": true,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"userChatInput\",\n          \"renderTypeList\": [\n            \"reference\",\n            \"textarea\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"问题输入\",\n          \"required\": true,\n          \"toolDescription\": \"用户问题\",\n          \"type\": \"custom\",\n          \"showTargetInApp\": true,\n          \"showTargetInPlugin\": true,\n          \"connected\": true,\n          \"selectedTypeIndex\": 0,\n          \"value\": [\n            \"7z5g5h\",\n            \"userChatInput\"\n          ]\n        },\n        {\n          \"key\": \"quoteQA\",\n          \"renderTypeList\": [\n            \"settingDatasetQuotePrompt\"\n          ],\n          \"label\": \"\",\n          \"debugLabel\": \"知识库引用\",\n          \"description\": \"core.module.Dataset quote.Input description\",\n          \"valueType\": \"datasetQuote\",\n          \"type\": \"target\",\n          \"showTargetInApp\": true,\n          \"showTargetInPlugin\": true,\n          \"connected\": true,\n          \"selectedTypeIndex\": 0,\n          \"value\": [\n            \"fljhzy\",\n            \"quoteQA\"\n          ]\n        }\n      ],\n      \"outputs\": [\n        {\n          \"id\": \"answerText\",\n          \"type\": \"static\",\n          \"key\": \"answerText\",\n          \"valueType\": \"string\",\n          \"label\": \"core.module.output.label.Ai response content\",\n          \"description\": \"core.module.output.description.Ai response content\"\n        },\n        {\n          \"id\": \"history\",\n          \"type\": \"static\",\n          \"key\": \"history\",\n          \"valueType\": \"chatHistory\",\n          \"label\": \"core.module.output.label.New context\",\n          \"description\": \"core.module.output.description.New context\"\n        }\n      ]\n    },\n    {\n      \"nodeId\": \"q9equb\",\n      \"name\": \"core.module.template.App system setting\",\n      \"intro\": \"可以配置应用的系统参数。\",\n      \"avatar\": \"/imgs/workflow/userGuide.png\",\n      \"flowNodeType\": \"userGuide\",\n      \"position\": {\n        \"x\": -275.92529567956024,\n        \"y\": 1094.1001488133452\n      },\n      \"inputs\": [\n        {\n          \"key\": \"welcomeText\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"core.app.Welcome Text\",\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"value\": \"你好，我是电影《星际穿越》 AI 助手，有什么可以帮助你的？\\n[导演是谁]\\n[剧情介绍]\\n[票房分析]\",\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"variables\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"core.module.Variable\",\n          \"value\": [],\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"questionGuide\",\n          \"valueType\": \"boolean\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"type\": \"switch\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"tts\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"\",\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"whisper\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"\"\n        },\n        {\n          \"key\": \"scheduleTrigger\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"\",\n          \"value\": null\n        }\n      ],\n      \"outputs\": []\n    },\n    {\n      \"nodeId\": \"tc90wz\",\n      \"name\": \"指定回复\",\n      \"intro\": \"该模块可以直接回复一段指定的内容。常用于引导、提示。非字符串内容传入时，会转成字符串进行输出。\",\n      \"avatar\": \"/imgs/workflow/reply.png\",\n      \"flowNodeType\": \"answerNode\",\n      \"position\": {\n        \"x\": 159.49274056478237,\n        \"y\": 1621.4635230667668\n      },\n      \"inputs\": [\n        {\n          \"key\": \"text\",\n          \"renderTypeList\": [\n            \"textarea\",\n            \"reference\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"core.module.input.label.Response content\",\n          \"description\": \"core.module.input.description.Response content\",\n          \"placeholder\": \"core.module.input.description.Response content\",\n          \"type\": \"textarea\",\n          \"showTargetInApp\": true,\n          \"showTargetInPlugin\": true,\n          \"value\": \"这是开头\\\\n\",\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        }\n      ],\n      \"outputs\": []\n    },\n    {\n      \"nodeId\": \"U5T3dMVY4wj7\",\n      \"name\": \"指定回复\",\n      \"intro\": \"该模块可以直接回复一段指定的内容。常用于引导、提示。非字符串内容传入时，会转成字符串进行输出。\",\n      \"avatar\": \"/imgs/workflow/reply.png\",\n      \"flowNodeType\": \"answerNode\",\n      \"position\": {\n        \"x\": 1467.0625486167608,\n        \"y\": 1597.346243737531\n      },\n      \"inputs\": [\n        {\n\n```\n\n----------------------------------------\n\nTITLE: Configuring FastGPT Workflow for AI-powered Subtitle Translation\nDESCRIPTION: This JSON configuration defines a FastGPT workflow for translating subtitles. It includes system settings, workflow start parameters, and an AI translation node with detailed instructions for a four-step translation process.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/translate-subtitle-using-gpt.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"nodes\": [\n    {\n      \"nodeId\": \"userGuide\",\n      \"name\": \"系统配置\",\n      \"intro\": \"可以配置应用的系统参数\",\n      \"avatar\": \"core/workflow/template/systemConfig\",\n      \"flowNodeType\": \"userGuide\",\n      \"position\": {\n        \"x\": -1453.0815298642474,\n        \"y\": 269.10239463914263\n      },\n      \"version\": \"481\",\n      \"inputs\": [\n        {\n          \"key\": \"welcomeText\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"core.app.Welcome Text\",\n          \"value\": \"\"\n        },\n        {\n          \"key\": \"variables\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"core.app.Chat Variable\",\n          \"value\": []\n        },\n        {\n          \"key\": \"questionGuide\",\n          \"valueType\": \"boolean\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"core.app.Question Guide\",\n          \"value\": false\n        },\n        {\n          \"key\": \"tts\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"\",\n          \"value\": {\n            \"type\": \"web\"\n          }\n        },\n        {\n          \"key\": \"whisper\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"\",\n          \"value\": {\n            \"open\": false,\n            \"autoSend\": false,\n            \"autoTTSResponse\": false\n          }\n        },\n        {\n          \"key\": \"scheduleTrigger\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"\",\n          \"value\": null\n        }\n      ],\n      \"outputs\": []\n    },\n    {\n      \"nodeId\": \"448745\",\n      \"name\": \"流程开始\",\n      \"intro\": \"\",\n      \"avatar\": \"core/workflow/template/workflowStart\",\n      \"flowNodeType\": \"workflowStart\",\n      \"position\": {\n        \"x\": -1458.2511936623089,\n        \"y\": 1218.2790943636066\n      },\n      \"version\": \"481\",\n      \"inputs\": [\n        {\n          \"key\": \"userChatInput\",\n          \"renderTypeList\": [\n            \"reference\",\n            \"textarea\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"用户问题\",\n          \"required\": true,\n          \"toolDescription\": \"用户问题\"\n        }\n      ],\n      \"outputs\": [\n        {\n          \"id\": \"userChatInput\",\n          \"key\": \"userChatInput\",\n          \"label\": \"core.module.input.label.user question\",\n          \"type\": \"static\",\n          \"valueType\": \"string\"\n        }\n      ]\n    },\n    {\n      \"nodeId\": \"yjFO3YcM7KG2\",\n      \"name\": \"LLM 翻译\",\n      \"intro\": \"AI 大模型对话\",\n      \"avatar\": \"core/workflow/template/aiChat\",\n      \"flowNodeType\": \"chatNode\",\n      \"showStatus\": true,\n      \"position\": {\n        \"x\": 2569.420973631976,\n        \"y\": 909.4127366971411\n      },\n      \"version\": \"481\",\n      \"inputs\": [\n        {\n          \"key\": \"model\",\n          \"renderTypeList\": [\n            \"settingLLMModel\",\n            \"reference\"\n          ],\n          \"label\": \"core.module.input.label.aiModel\",\n          \"valueType\": \"string\",\n          \"selectedTypeIndex\": 0,\n          \"value\": \"claude-3-5-sonnet-20240620\"\n        },\n        {\n          \"key\": \"temperature\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"value\": 3,\n          \"valueType\": \"number\",\n          \"min\": 0,\n          \"max\": 10,\n          \"step\": 1\n        },\n        {\n          \"key\": \"maxToken\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"value\": 4000,\n          \"valueType\": \"number\",\n          \"min\": 100,\n          \"max\": 4000,\n          \"step\": 50\n        },\n        {\n          \"key\": \"isResponseAnswerText\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"value\": false,\n          \"valueType\": \"boolean\"\n        },\n        {\n          \"key\": \"quoteTemplate\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"valueType\": \"string\"\n        },\n        {\n          \"key\": \"quotePrompt\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"valueType\": \"string\"\n        },\n        {\n          \"key\": \"systemPrompt\",\n          \"renderTypeList\": [\n            \"textarea\",\n            \"reference\"\n          ],\n          \"max\": 3000,\n          \"valueType\": \"string\",\n          \"label\": \"core.ai.Prompt\",\n          \"description\": \"core.app.tip.chatNodeSystemPromptTip\",\n          \"placeholder\": \"core.app.tip.chatNodeSystemPromptTip\",\n          \"value\": \"# Role: 资深字幕翻译专家\\n\\n## Background:\\n你是一位经验丰富的{{source_lang}}和{{target_lang}}字幕翻译专家,精通{{source_lang}}和{{target_lang}}互译,尤其擅长将{{source_lang}}字幕译成流畅易懂的{{target_lang}}字幕。你曾多次带领团队完成大型商业电影的字幕翻译项目,所翻译的字幕广受好评。\\n\\n## Attention:\\n- 翻译过程中要始终坚持\\\"信、达、雅\\\"的原则,但\\\"达\\\"尤为重要\\n- 翻译的字幕要符合{{target_lang}}的表达习惯,通俗易懂,连贯流畅\\n- 避免使用过于文绉绉的表达和晦涩难懂的典故引用 \\n- 诗词歌词等内容需按原文换行和节奏分行,不破坏原排列格式  \\n- 翻译对象是字幕，请进入整段文本的语境中对需要翻译的文本段进行翻译\\n- <T>是标识每一帧字幕的标签,请严格按照<T>对文本的分割逐帧翻译，每一帧字幕末尾不要加 \\\\n 回车标识，且第一帧字幕开头不需要加<T>标识\\n\\n## Constraints:\\n- 必须严格遵循四轮翻译流程:直译、意译、反思、提升\\n- 译文要忠实原文,准确无误,不能遗漏或曲解原意\\n- 最终译文使用Markdown的代码块呈现,但是不用输出markdown这个单词\\n- <T>是标识每一帧字幕的标签,请严格按照<T>对文本的分割逐帧翻译，每一帧字幕末尾不要加 \\\\n 回车标识，且第一帧字幕开头不需要加<T>标识\\n\\n## Goals:\\n- 通过四轮翻译流程,将{{source_lang}}字幕译成高质量的{{target_lang}}字幕\\n- 翻译的字幕要准确传达原字幕意思,语言表达力求浅显易懂,朗朗上口  \\n\\n## Workflow:\\n1. 第一轮直译:严格按照<T>逐句翻译,不遗漏任何信息\\n2. 第二轮意译:在直译的基础上用通俗流畅的{{target_lang}}意译原文,逐句翻译,保留<T>标识标签\\n3. 第三轮反思:仔细审视译文,分点列出一份建设性的批评和有用的建议清单以改进翻译，对每一句话提出建议，从以下四个角度展开\\n    (i) 准确性（纠正添加、误译、遗漏或未翻译的文本错误），\\n    (ii) 流畅性（应用{{target_lang}}的语法、拼写和标点规则，并确保没有不必要的重复），\\n    (iii) 风格（确保翻译反映源文本的风格并考虑其文化背景），\\n    (iv) 术语（确保术语使用一致且反映源文本所在领域，注意确保使用{{target_lang}}中的等效习语）\\n4. 第四轮提升:严格遵循第三轮提出的建议对翻译修改,定稿出一个简洁畅达、符合大众观影习惯的字幕译文,保留<T>标识标签\\n\\n## OutputFormat:\\n- 每一轮前用【思考】说明该轮要点\\n- 第一轮和第二轮翻译后用【翻译】呈现译文\\n- 第三轮输出建议清单，分点列出，在每一点前用*xxx*标识这条建议对应的要点，如*风格*;建议前用【思考】说明该轮要点，建议后用【建议】呈现建议\\n- 第四轮在\\`\\`\\`代码块中展示最终{{target_lang}}字幕文件内容，如\\`\\`\\`xxx\\`\\`\\`\\n\\n## Suggestions:\\n- 直译时力求忠实原文,但注意控制每帧字幕的字数,必要时进行精简压缩\\n- 意译时在准确表达原意的基础上,用最朴实无华的{{target_lang}}来表达\\n- 反思环节重点关注译文是否符合{{target_lang}}表达习惯,是否通俗易懂,是否准确流畅,是否术语一致\\n- 提升环节采用反思环节的建议对意译环节的翻译进行修改，适度采用一些口语化的表达、网络流行语等,增强字幕的亲和力\\n- 注意<T>是很重要的标识标签，请确保标签能在正确位置输出\"\n        },\n        {\n          \"key\": \"history\",\n          \"renderTypeList\": [\n            \"numberInput\",\n            \"reference\"\n          ],\n          \"valueType\": \"chatHistory\",\n          \"label\": \"core.module.input.label.chat history\",\n          \"description\": \"最多携带多少轮对话记录\",\n          \"required\": true,\n          \"min\": 0,\n          \"max\": 50,\n          \"value\": 6\n        },\n        {\n          \"key\": \"userChatInput\",\n          \"renderTypeList\": [\n            \"reference\",\n            \"textarea\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"用户问题\",\n          \"required\": true,\n          \"toolDescription\": \"用户问题\",\n          \"value\": [\n            \"bxz97Vg4Omux\",\n            \"system_text\"\n          ]\n        },\n        {\n          \"key\": \"quoteQA\",\n          \"renderTypeList\": [\n            \"settingDatasetQuotePrompt\"\n          ],\n          \"label\": \"\",\n          \"debugLabel\": \"知识库引用\",\n          \"description\": \"\",\n          \"valueType\": \"datasetQuote\"\n        }\n      ],\n      \"outputs\": [\n        {\n          \"id\": \"history\",\n          \"key\": \"history\",\n          \"required\": true,\n          \"label\": \"core.module.output.label.New context\",\n          \"description\": \"core.module.output.description.New context\",\n          \"valueType\": \"chatHistory\",\n          \"type\": \"static\"\n        },\n        {\n          \"id\": \"answerText\",\n          \"key\": \"answerText\",\n          \"required\": true,\n          \"label\": \"core.module.output.label.Ai response content\",\n          \"description\": \"core.module.output.description.Ai response content\",\n          \"valueType\": \"string\",\n          \"type\": \"static\"\n        }\n      ]\n    },\n    {\n      \"nodeId\": \"bxz97Vg4Omux\",\n      \"name\": \"LLM 翻译提示词\",\n      \"intro\": \"可对固定或传入的文本进行加工后输出，非字符串类型数据最终会转成字符串类型。\",\n      \"avatar\": \"core/workflow/template/textConcat\",\n      \"flowNodeType\": \"textEditor\",\n      \"position\": {\n        \"x\": 1893.11421220213,\n        \"y\": 1065.1299598362698\n      },\n      \"version\": \"486\",\n      \"inputs\": [\n        {\n          \"key\": \"system_addInputParam\",\n          \"renderTypeList\": [\n            \"addInputParam\"\n          ],\n          \"valueType\": \"dynamic\",\n          \"label\": \"\",\n          \"required\": false,\n          \"description\": \"可以引用其他节点的输出，作为文本拼接的变量，通过 {{字段名}} 来引用变量\",\n          \"customInputConfig\": {\n            \"selectValueTypeList\": [\n              \"string\",\n              \"number\",\n              \"boolean\",\n              \"object\",\n              \"arrayString\",\n              \"arrayNumber\",\n              \"arrayBoolean\",\n              \"arrayObject\",\n              \"any\",\n              \"chatHistory\",\n              \"datasetQuote\",\n              \"dynamic\",\n              \"selectApp\",\n              \"selectDataset\"\n            ],\n            \"showDescription\": false,\n            \"showDefaultValue\": false\n          }\n        },\n        {\n          \"key\": \"system_textareaInput\",\n          \"renderTypeList\": [\n            \"textarea\"\n          ],\n          \"valueType\": \"string\",\n          \"required\": true,\n          \"label\": \"拼接文本\",\n          \"placeholder\": \"可通过 {{字段名}} 来引用变量\",\n          \"value\": \"你的任务是将文本从{{source_lang}}翻译成{{target_lang}}\\n\\n源文本如下,由XML标签<SOURCE_TEXT>和</SOURCE_TEXT>分隔:\\n\\n<SOURCE_TEXT>\\n\\n{{tagged_text}}\\n\\n</SOURCE_TEXT>\\n\\n仅翻译源文本中由<TRANSLATE_THIS>和</TRANSLATE_THIS>分隔的部分,将其余的源文本作为上下文\\n\\n重申一下,你应该只翻译文本的这一部分,这里再次显示在<TRANSLATE_THIS>和</TRANSLATE_THIS>之间:\\n\\n<TRANSLATE_THIS>\\n\\n{{chunk_to_translate}}\\n\\n</TRANSLATE_THIS>\"\n        },\n        {\n          \"renderTypeList\": [\n            \"reference\"\n          ],\n          \"valueType\": \"string\",\n          \"canEdit\": true,\n\n```\n\n----------------------------------------\n\nTITLE: Setting FastGPT Environment Variables for Cloudflare Worker Proxy\nDESCRIPTION: These environment variables configure FastGPT to use the Cloudflare Worker as a proxy for OpenAI API requests. OPENAI_BASE_URL is set to the Cloudflare Worker URL, and OPENAI_BASE_URL_AUTH is set to the authentication code used in the worker.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/proxy/cloudflare.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_BASE_URL=https://xxxxxx/v1\nOPENAI_BASE_URL_AUTH=auth_code\n```\n\n----------------------------------------\n\nTITLE: Real-Time Speech Recognition with FunASR in Python\nDESCRIPTION: This Python script demonstrates real-time speech recognition using the FunASR AutoModel, processing audio in chunks for streaming applications.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/README.md#2025-04-10_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom funasr import AutoModel\nimport soundfile\nimport os\n\nchunk_size = [0, 10, 5] #[0, 10, 5] 600ms, [0, 8, 4] 480ms\nencoder_chunk_look_back = 4\ndecoder_chunk_look_back = 1\n\nmodel = AutoModel(model=\"paraformer-zh-streaming\", model_revision=\"v2.0.4\")\n\nwav_file = os.path.join(model.model_path, \"example/asr_example.wav\")\nspeech, sample_rate = soundfile.read(wav_file)\nchunk_stride = chunk_size[1] * 960 # 600ms\n\ncache = {}\ntotal_chunk_num = int(len((speech)-1)/chunk_stride+1)\nfor i in range(total_chunk_num):\n    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]\n    is_final = i == total_chunk_num - 1\n    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size, encoder_chunk_look_back=encoder_chunk_look_back, decoder_chunk_look_back=decoder_chunk_look_back)\n    print(res)\n```\n\n----------------------------------------\n\nTITLE: Deleting a Collection in FastGPT\nDESCRIPTION: This snippet shows how to delete a collection using its ID. It sends a DELETE request to the API endpoint with the collection ID as a query parameter.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request DELETE 'http://localhost:3000/api/core/dataset/collection/delete?id=65aa2a64e6cb9b8ccdc00de8' \\\n--header 'Authorization: Bearer {{authorization}}' \\\n```\n\n----------------------------------------\n\nTITLE: Sample Tool Call Response Structure in JSON\nDESCRIPTION: A JSON example showing the expected response format when a model successfully processes a tool call request. This includes the tool_calls array with function details.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/faq.md#2025-04-10_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"id\": \"chatcmpl-A7kwo1rZ3OHYSeIFgfWYxu8X2koN3\",\n    \"object\": \"chat.completion.chunk\",\n    \"created\": 1726412126,\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"system_fingerprint\": \"fp_483d39d857\",\n    \"choices\": [\n        {\n            \"index\": 0,\n            \"delta\": {\n                \"role\": \"assistant\",\n                \"content\": null,\n                \"tool_calls\": [\n                    {\n                        \"index\": 0,\n                        \"id\": \"call_0n24eiFk8OUyIyrdEbLdirU7\",\n                        \"type\": \"function\",\n                        \"function\": {\n                            \"name\": \"mEYIcFl84rYC\",\n                            \"arguments\": \"\"\n                        }\n                    }\n                ],\n                \"refusal\": null\n            },\n            \"logprobs\": null,\n            \"finish_reason\": null\n        }\n    ],\n    \"usage\": null\n}\n```\n\n----------------------------------------\n\nTITLE: Non-Real-Time Speech Recognition with FunASR in Python\nDESCRIPTION: This Python code demonstrates how to use the FunASR AutoModel for non-real-time speech recognition, including VAD and punctuation models, processing a single audio file.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/README.md#2025-04-10_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom funasr import AutoModel\n\nmodel = AutoModel(model=\"paraformer-zh\", model_revision=\"v2.0.4\",\n                  vad_model=\"fsmn-vad\", vad_model_revision=\"v2.0.4\",\n                  punc_model=\"ct-punc-c\", punc_model_revision=\"v2.0.4\")\nres = model.generate(input=f\"{model.model_path}/example/asr_example.wav\", \n            batch_size_s=300, \n            hotword='魔搭')\nprint(res)\n```\n\n----------------------------------------\n\nTITLE: Testing ChatGLM2 Completions Model with cURL\nDESCRIPTION: Example of using cURL to test the ChatGLM2 chat completions API endpoint. The request sends a simple user message and specifies the ChatGLM2 model.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/chatglm2-m3e.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://domain/v1/chat/completions' \\\n--header 'Authorization: Bearer sk-aaabbbcccdddeeefffggghhhiiijjjkkk' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n  \"model\": \"chatglm2\",\n  \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]\n}'\n```\n\n----------------------------------------\n\nTITLE: Configuring Model Mapping in JSON for AI Proxy\nDESCRIPTION: Example of how to map FastGPT model requests to specific provider models using JSON configuration in AI Proxy.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/modelConfig/ai-proxy.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"gpt-4o-test\": \"gpt-4o\"\n}\n```\n\n----------------------------------------\n\nTITLE: Non-Real-Time Voice Activity Detection with FunASR in Python\nDESCRIPTION: This Python code shows how to perform non-real-time voice activity detection using the FunASR AutoModel on a single audio file.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/README.md#2025-04-10_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom funasr import AutoModel\n\nmodel = AutoModel(model=\"fsmn-vad\", model_revision=\"v2.0.4\")\n\nwav_file = f\"{model.model_path}/example/asr_example.wav\"\nres = model.generate(input=wav_file)\nprint(res)\n```\n\n----------------------------------------\n\nTITLE: Configuring FastGPT with ChatGLM2 and M3E Models in config.json\nDESCRIPTION: JSON configuration for adding ChatGLM2 language model and M3E embedding model to FastGPT's config.json file. Includes model parameters like maximum tokens, pricing, and temperature settings.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/chatglm2-m3e.md#2025-04-10_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n\"llmModels\": [\n  //其他对话模型\n  {\n    \"model\": \"chatglm2\",\n    \"name\": \"chatglm2\",\n    \"maxToken\": 8000,\n    \"price\": 0,\n    \"quoteMaxToken\": 4000,\n    \"maxTemperature\": 1.2,\n    \"defaultSystemChatPrompt\": \"\"\n  }\n],\n\"vectorModels\": [\n    {\n      \"model\": \"text-embedding-ada-002\",\n      \"name\": \"Embedding-2\",\n      \"price\": 0.2,\n      \"defaultToken\": 500,\n      \"maxToken\": 3000\n    },\n    {\n      \"model\": \"m3e\",\n      \"name\": \"M3E（测试使用）\",\n      \"price\": 0.1,\n      \"defaultToken\": 500,\n      \"maxToken\": 1800\n    }\n],\n```\n\n----------------------------------------\n\nTITLE: Parsing JSON Response for Non-Streaming, Non-Detailed Request in FastGPT API v2\nDESCRIPTION: This snippet shows the JSON structure of a response for a non-streaming, non-detailed request in FastGPT API v2. It includes the model information, token usage, and the AI's response.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/chat.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"id\": \"\",\n    \"model\": \"\",\n    \"usage\": {\n        \"prompt_tokens\": 1,\n        \"completion_tokens\": 1,\n        \"total_tokens\": 1\n    },\n    \"choices\": [\n        {\n            \"message\": {\n                \"role\": \"assistant\",\n                \"content\": \"我是一个人工智能助手，旨在回答问题和提供信息。如果你有任何问题或者需要帮助，随时问我！\"\n            },\n            \"finish_reason\": \"stop\",\n            \"index\": 0\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Batch Processing with FunASR and SenseVoice\nDESCRIPTION: This code snippet demonstrates how to optimize inference speed for batch processing of short audio files using FunASR with SenseVoice. It removes the VAD model for efficiency and sets a batch size for parallel processing.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/SenseVoiceSmall/README.md#2025-04-10_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel = AutoModel(model=model_dir, trust_remote_code=True, device=\"cuda:0\")\n\nres = model.generate(\n    input=input_file,\n    cache={},\n    language=\"auto\", # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n    use_itn=False,\n    batch_size=64,\n)\n```\n\n----------------------------------------\n\nTITLE: Embedding HTML in FastGPT Markdown\nDESCRIPTION: This snippet demonstrates how to embed an HTML code block within a Markdown document in FastGPT. It shows a simple HTML structure with a navigation menu, which will be rendered as an interactive iframe in the FastGPT interface.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/DialogBoxes/htmlRendering.md#2025-04-10_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```html\n<!DOCTYPE html>\n<html lang=\"zh-CN\">\n  <head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <title>欢迎使用FastGPT</title>\n  </head>\n  <body>\n    <nav>\n      <ul>\n        <li><a href=\"#home\">首页</a></li>\n        <li><a href=\"#about\">关于我们</a></li>\n        <li><a href=\"#contact\">联系我们</a></li>\n        <li><a href=\"#gallery\">图库</a></li>\n      </ul>\n    </nav>\n  </body>\n</html>\n```\n```\n\n----------------------------------------\n\nTITLE: Executing FunASR VAD Model via Command Line\nDESCRIPTION: This shell command demonstrates how to run the FunASR VAD model from the command line, combining it with ASR and punctuation models for processing a single audio file.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/README.md#2025-04-10_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nfunasr ++model=paraformer-zh ++vad_model=\"fsmn-vad\" ++punc_model=\"ct-punc\" ++input=vad_example.wav\n```\n\n----------------------------------------\n\nTITLE: Text Array Processing in JavaScript\nDESCRIPTION: A function that processes an array of text by grouping elements into chunks of size 20 and joining them with a delimiter. Takes a textArray input parameter and returns an object with the processed result array.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/translate-subtitle-using-gpt.md#2025-04-10_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nfunction main({textArray}){\n const groupSize = 20\n const delimiter = '<T>'\n\n  const result = [];\n\n  for (let i = 0; i < textArray.length; i += groupSize) {\n    result.push(textArray.slice(i, i + groupSize).join(delimiter));\n  }\n\n  return {result};\n}\n```\n\n----------------------------------------\n\nTITLE: Timestamp Prediction with FunASR in Python\nDESCRIPTION: This Python code shows how to use the FunASR AutoModel for timestamp prediction, processing both audio and text inputs to generate timing information.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/README.md#2025-04-10_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom funasr import AutoModel\n\nmodel = AutoModel(model=\"fa-zh\", model_revision=\"v2.0.4\")\n\nwav_file = f\"{model.model_path}/example/asr_example.wav\"\ntext_file = f\"{model.model_path}/example/text.txt\"\nres = model.generate(input=(wav_file, text_file), data_type=(\"sound\", \"text\"))\nprint(res)\n```\n\n----------------------------------------\n\nTITLE: Creating a Text Collection in FastGPT\nDESCRIPTION: API request to create a text-based collection by providing raw text content. The text will be processed according to specified training type and chunk settings.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'http://localhost:3000/api/core/dataset/collection/create/text' \\\n--header 'Authorization: Bearer {{authorization}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"text\":\"xxxxxxxx\",\n    \"datasetId\":\"6593e137231a2be9c5603ba7\",\n    \"parentId\": null,\n    \"name\":\"测试训练\",\n\n    \"trainingType\": \"qa\",\n    \"chunkSettingMode\": \"auto\",\n    \"qaPrompt\":\"\",\n\n    \"metadata\":{}\n}'\n```\n\n----------------------------------------\n\nTITLE: Creating Laboratory Appointment Records in TypeScript\nDESCRIPTION: This function creates a new laboratory appointment record. It validates required fields, checks for existing appointments, and adds a new record to the database.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/lab_appointment.md#2025-04-10_snippet_5\n\nLANGUAGE: TypeScript\nCODE:\n```\nasync function createRecord({ name, time, labname }: RequestType) {\n  const missData = []\n  if (!name) missData.push(\"你的姓名\")\n  if (!time) missData.push(\"需要预约的时间\")\n  if (!labname) missData.push(\"实验室名名称\")\n\n  if (missData.length > 0) {\n    return {\n      result: `请提供: ${missData.join(\"、\")}`\n    }\n  }\n\n  const { data: record } = await db.collection(\"LabAppointment\").where({\n    name, status: \"unStart\"\n  }).getOne()\n\n  if (record) {\n    return {\n      result: `您已经有一个预约记录了:\n姓名：${record.name}\n时间: ${record.time}\n实验室名: ${record.labname}\n\n每人仅能同时预约一个实验室名。\n      `\n    }\n  }\n\n  await db.collection(\"LabAppointment\").add({\n    name, time, labname, status: \"unStart\"\n  })\n\n  return {\n    result: `预约成功。\n  姓名：${name}\n  时间: ${time}\n  实验室名: ${labname}\n  ` }\n}\n```\n\n----------------------------------------\n\nTITLE: Inferencing VAD Model with ModelScope Pipeline in Python\nDESCRIPTION: This snippet demonstrates how to use the ModelScope pipeline to perform voice activity detection on an audio file URL. It loads the FSMN VAD model and processes the input to detect speech segments.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/README.md#2025-04-10_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom modelscope.pipelines import pipeline\nfrom modelscope.utils.constant import Tasks\n\ninference_pipeline = pipeline(\n    task=Tasks.voice_activity_detection,\n    model='iic/speech_fsmn_vad_zh-cn-16k-common-pytorch',\n    model_revision=\"v2.0.4\",\n)\n\nsegments_result = inference_pipeline(input='https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/vad_example.wav')\nprint(segments_result)\n```\n\n----------------------------------------\n\nTITLE: Punctuation Restoration with FunASR in Python\nDESCRIPTION: This Python code demonstrates how to use the FunASR AutoModel for punctuation restoration on a given text input.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/README.md#2025-04-10_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom funasr import AutoModel\n\nmodel = AutoModel(model=\"ct-punc\", model_revision=\"v2.0.4\")\n\nres = model.generate(input=\"那今天的会就到这里吧 happy new year 明年见\")\nprint(res)\n```\n\n----------------------------------------\n\nTITLE: Creating a Link Collection in FastGPT\nDESCRIPTION: API request to create a collection from a web link. FastGPT will fetch the content from the URL and process it according to the specified settings.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'http://localhost:3000/api/core/dataset/collection/create/link' \\\n--header 'Authorization: Bearer {{authorization}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"link\":\"https://doc.tryfastgpt.ai/docs/course/quick-start/\",\n    \"datasetId\":\"6593e137231a2be9c5603ba7\",\n    \"parentId\": null,\n\n    \"trainingType\": \"chunk\",\n    \"chunkSettingMode\": \"auto\",\n    \"qaPrompt\":\"\",\n\n    \"metadata\":{\n        \"webPageSelector\":\".docs-content\"\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Executing FastGPT V4.8.6 Initialization via HTTP Request (Bash)\nDESCRIPTION: This curl command sends a POST request to initialize FastGPT v4.8.6. It requires replacing {{rootkey}} with the environment variable 'rootkey' and {{host}} with the FastGPT domain. The initialization process sets up application inheritance permissions.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/486.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv486' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Defining Extraction Requirements in FastGPT\nDESCRIPTION: Examples of how to set extraction requirements for the FastGPT content extraction module. These examples show how to instruct the model to extract specific information from conversations.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/workbench/workflow/content_extract.md#2025-04-10_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n> 你是实验室预约助手，从对话中提取出姓名，预约时间，实验室号。当前时间 {{cTime}}\n\n> 你是谷歌搜索助手，从对话中提取出搜索关键词\n\n> 将我的问题直接翻译成英文，不要回答问题\n```\n\n----------------------------------------\n\nTITLE: Processing Pre-loaded Audio Data with ModelScope VAD Pipeline\nDESCRIPTION: This snippet shows how to use the ModelScope pipeline for voice activity detection on pre-loaded audio data using the soundfile library.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/README.md#2025-04-10_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport soundfile\n\nwaveform, sample_rate = soundfile.read(\"vad_example_zh.wav\")\nsegments_result = inference_pipeline(input=waveform)\nprint(segments_result)\n```\n\n----------------------------------------\n\nTITLE: Initializing FastGPT Business Version V4.8.4 via HTTP Request\nDESCRIPTION: HTTP POST request to initialize the business version of FastGPT 4.8.4. Requires replacing {{rootkey}} with the environment variable rootkey and {{host}} with the FastGPT business version domain name.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/484.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/init/484' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Processing PCM Audio with ModelScope VAD Pipeline\nDESCRIPTION: This code snippet shows how to use the ModelScope pipeline for voice activity detection on PCM format audio, specifying the sampling rate as an additional parameter.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/README.md#2025-04-10_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nsegments_result = inference_pipeline(input='https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/vad_example.pcm', fs=16000)\n```\n\n----------------------------------------\n\nTITLE: Migrating from OneAPI to AI Proxy using cURL\nDESCRIPTION: Bash command to migrate data from OneAPI to AI Proxy using a cURL request. It requires the AI Proxy host address and admin key, and the OneAPI MySQL connection string.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/modelConfig/ai-proxy.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST '{{host}}/api/channels/import/oneapi' \\\n--header 'Authorization: Bearer {{admin_key}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"dsn\": \"mysql://root:s5mfkwst@tcp(dbconn.sealoshzh.site:33123)/mydb\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Using FunASR for Speech Recognition with SenseVoice\nDESCRIPTION: This snippet shows how to use the FunASR framework with SenseVoice for speech recognition. It includes VAD (Voice Activity Detection) integration for processing audio of any length with automatic segmentation and supports batch processing.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/SenseVoiceSmall/README.md#2025-04-10_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom funasr import AutoModel\n\nmodel_dir = \"iic/SenseVoiceSmall\"\ninput_file = (\n    \"https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav\"\n)\n\nmodel = AutoModel(model=model_dir,\n                  vad_model=\"fsmn-vad\",\n                  vad_kwargs={\"max_single_segment_time\": 30000},\n                  trust_remote_code=True, device=\"cuda:0\")\n\nres = model.generate(\n    input=input_file,\n    cache={},\n    language=\"auto\", # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n    use_itn=False,\n    batch_size_s=0,\n)\n\nprint(res)\n```\n\n----------------------------------------\n\nTITLE: Batch Processing WAV Files with ModelScope VAD Pipeline\nDESCRIPTION: This example demonstrates how to process multiple WAV files listed in a .scp file using the ModelScope pipeline for voice activity detection, saving the results to an output directory.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/README.md#2025-04-10_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ninference_pipeline(input=\"wav.scp\", output_dir='./output_dir')\n```\n\n----------------------------------------\n\nTITLE: Text Collection Creation Response in FastGPT\nDESCRIPTION: JSON response for a successful text-based collection creation. Returns the collection ID and processing results including the number of inserted chunks.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_13\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"code\": 200,\n  \"statusText\": \"\",\n  \"message\": \"\",\n  \"data\": {\n      \"collectionId\": \"65abcfab9d1448617cba5f0d\",\n      \"results\": {\n          \"insertLen\": 5, // 分割成多少段\n          \"overToken\": [],\n          \"repeat\": [],\n          \"error\": []\n      }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing GPU Dependencies - PaddlePaddle\nDESCRIPTION: Installs PaddlePaddle GPU version for additional GPU support.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mineru/README.md#2025-04-10_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install paddlepaddle-gpu==2.6.1\n```\n\n----------------------------------------\n\nTITLE: Updating Collection Information in FastGPT\nDESCRIPTION: This snippet demonstrates how to update collection information using either the collection ID or external file ID. It includes parameters for modifying the collection name, tags, parent ID, and other attributes.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request PUT 'http://localhost:3000/api/core/dataset/collection/update' \\\n--header 'Authorization: Bearer {{authorization}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"id\":\"65abcfab9d1448617cba5f0d\",\n    \"parentId\": null,\n    \"name\": \"测2222试\",\n    \"tags\": [\"tag1\", \"tag2\"],\n    \"forbid\": false,\n    \"createTime\": \"2024-01-01T00:00:00.000Z\"\n}'\n```\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request PUT 'http://localhost:3000/api/core/dataset/collection/update' \\\n--header 'Authorization: Bearer {{authorization}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"datasetId\":\"6593e137231a2be9c5603ba7\",\n    \"externalFileId\":\"1111\",\n    \"parentId\": null,\n    \"name\": \"测2222试\",\n    \"tags\": [\"tag1\", \"tag2\"],\n    \"forbid\": false,\n    \"createTime\": \"2024-01-01T00:00:00.000Z\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Downloading SenseVoice Model using ModelScope SDK\nDESCRIPTION: This snippet shows how to download the SenseVoice Small model using the ModelScope SDK. It installs the ModelScope package and then downloads the model using the snapshot_download function.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/SenseVoiceSmall/README.md#2025-04-10_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n#安装ModelScope\npip install modelscope\n```\n\nLANGUAGE: python\nCODE:\n```\n#SDK模型下载\nfrom modelscope import snapshot_download\nmodel_dir = snapshot_download('iic/SenseVoiceSmall')\n```\n\n----------------------------------------\n\nTITLE: Executing Initialization API Call for FastGPT V4.4.7 Upgrade using cURL\nDESCRIPTION: A cURL command to execute the initialization API for FastGPT V4.4.7 upgrade. The command sends a POST request to the initv447 endpoint with the rootkey header for authentication. This script initializes PostgreSQL indexes and converts empty file_id objects to manual objects.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/447.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv447' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Testing Tool Calling Support with CURL - First Round\nDESCRIPTION: A CURL command for testing if a model supports tool calling by sending a request with tool definitions to the OneAPI chat completions endpoint.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/faq.md#2025-04-10_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://oneapi.xxx/v1/chat/completions' \\\n--header 'Authorization: Bearer sk-xxxx' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n  \"model\": \"gpt-4o-mini\",\n  \"temperature\": 0.01,\n  \"max_tokens\": 8000,\n  \"stream\": true,\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"几点了\"\n    }\n  ],\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"hCVbIY\",\n        \"description\": \"获取用户当前时区的时间。\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {},\n          \"required\": []\n        }\n      }\n    }\n  ],\n  \"tool_choice\": \"auto\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Parsing PDF with JavaScript/Axios using PDF-Mistral Plugin\nDESCRIPTION: This JavaScript snippet shows how to use Axios to send a PDF file to the PDF-Mistral plugin API and handle the response.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mistral/README.md#2025-04-10_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nconst formData = new FormData();\nformData.append('file', pdfFile);\n\nconst response = await axios.post('http://localhost:7231/v1/parse/file', formData, {\n  headers: {\n    'Content-Type': 'multipart/form-data'\n  }\n});\n\nif (response.data.error) {\n  console.error('错误:', response.data.error);\n} else {\n  console.log('页数:', response.data.pages);\n  console.log('Markdown:', response.data.markdown);\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Initialization API Request with cURL in Bash\nDESCRIPTION: This code snippet demonstrates how to send an HTTP POST request to initialize FastGPT V4.4.5 using cURL. The request requires the rootkey environment variable to be included in the headers for authentication.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/445.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv445' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Defining AI Conversation Node in JSON\nDESCRIPTION: This snippet configures an AI conversation node in the workflow. It specifies the node's properties, inputs (including AI model settings), and outputs for managing AI-based conversations.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/google_search.md#2025-04-10_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"nodeId\": \"EX0g9oK3sCOC\",\n  \"name\": \"AI 对话\",\n  \"intro\": \"AI 大模型对话\",\n  \"avatar\": \"/imgs/workflow/AI.png\",\n  \"flowNodeType\": \"chatNode\",\n  \"showStatus\": true,\n  \"position\": {\n    \"x\": 3199.17223136331,\n    \"y\": -100.06379812849427\n  },\n  \"inputs\": [\n    {\n      \"key\": \"model\",\n      \"renderTypeList\": [\n        \"settingLLMModel\",\n        \"reference\"\n      ],\n      \"label\": \"core.module.input.label.aiModel\",\n      \"valueType\": \"string\",\n      \"value\": \"gpt-3.5-turbo\"\n    },\n    {\n      \"key\": \"temperature\",\n      \"renderTypeList\": [\n        \"hidden\"\n      ],\n      \"label\": \"\",\n      \"value\": 0,\n      \"valueType\": \"number\",\n      \"min\": 0,\n      \"max\": 10,\n      \"step\": 1\n    }\n  ],\n  \"outputs\": [\n    {\n      \"id\": \"history\",\n      \"key\": \"history\",\n      \"label\": \"core.module.output.label.New context\",\n      \"description\": \"core.module.output.description.New context\",\n      \"valueType\": \"chatHistory\",\n      \"type\": \"static\"\n    },\n    {\n      \"id\": \"answerText\",\n      \"key\": \"answerText\",\n      \"label\": \"core.module.output.label.Ai response content\",\n      \"description\": \"core.module.output.description.Ai response content\",\n      \"valueType\": \"string\",\n      \"type\": \"static\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Nginx Proxy for OpenAI API\nDESCRIPTION: Nginx configuration file that sets up a reverse proxy to route requests to OpenAI API. Includes settings for handling both streaming and regular responses, buffer sizes, and timeout configurations.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/proxy/nginx.md#2025-04-10_snippet_0\n\nLANGUAGE: nginx\nCODE:\n```\nuser nginx;\nworker_processes auto;\nworker_rlimit_nofile 51200;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    resolver 8.8.8.8;\n    proxy_ssl_server_name on;\n\n    access_log off;\n    server_names_hash_bucket_size 512;\n    client_header_buffer_size 64k;\n    large_client_header_buffers 4 64k;\n    client_max_body_size 50M;\n\n    proxy_connect_timeout       240s;\n    proxy_read_timeout          240s;\n    proxy_buffer_size 128k;\n    proxy_buffers 4 256k;\n\n    server {\n        listen 80;\n        server_name tgohwtdlrmer.cloud.sealos.io;\n\n        location ~ /openai/(.*) {\n            proxy_pass https://api.openai.com/$1$is_args$args;\n            proxy_set_header Host api.openai.com;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header Connection '';\n            proxy_http_version 1.1;\n            chunked_transfer_encoding off;\n            proxy_buffering off;\n            proxy_cache off;\n            proxy_buffer_size 128k;\n            proxy_buffers 4 256k;\n            proxy_busy_buffers_size 256k;\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Dependencies Configuration for FastGPT Helm Chart\nDESCRIPTION: Specifies the required Helm chart dependencies including MongoDB and PostgreSQL from Bitnami charts repository.\nSOURCE: https://github.com/labring/FastGPT/blob/main/deploy/helm/fastgpt/README.md#2025-04-10_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n| Repository | Name | Version |\n|------------|------|----------|\n| oci://registry-1.docker.io/bitnamicharts | mongodb | 15.0.1 |\n| oci://registry-1.docker.io/bitnamicharts | postgresql | 15.0.0 |\n```\n\n----------------------------------------\n\nTITLE: Generating Question Guide in FastGPT (Pre-4.8.16 Version, Bash/cURL)\nDESCRIPTION: This snippet demonstrates how to generate a question guide using the old version of the FastGPT API (pre-4.8.16). It requires an array of message objects representing the conversation history.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/chat.md#2025-04-10_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'http://localhost:3000/api/core/ai/agent/createQuestionGuide' \\\n--header 'Authorization: Bearer {{apikey}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"messages\":[\n        {\n            \"role\": \"user\",\n            \"content\": \"你好\"\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"你好！有什么我可以帮助你的吗？\"\n        }\n    ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Defining FastGPT API Template Structure in TypeScript\nDESCRIPTION: Defines a template API structure for FastGPT including metadata, type definitions for query parameters, request body, and response. Uses Next.js API routing with custom middleware. The template includes documentation for key parameters and establishes a standardized API structure.\nSOURCE: https://github.com/labring/FastGPT/blob/main/scripts/openapi/template.md#2025-04-10_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport type { ApiRequestProps, ApiResponseType } from '@fastgpt/service/type/next';\nimport { NextAPI } from '@/service/middleware/entry';\n\n// This should be at the top of the file after the imports\nexport const ApiMetadata = {\n  name: 'template example api',\n  author: 'Finley',\n  version: '0.1.0',\n}\n\nexport type TemplateQuery = {\n  // The App's ID\n  appId?: string[],\n  // The App's Name\n  name: string,\n  // The App's Description\n  description: string | Something<AppDetailType>,\n};\n\nexport type TemplateBody = {\n  // The App's Name\n  name: string,\n};\n\n// This is the response type for the API\nexport type TemplateResponse = AppDetailType;\n\n// This is the template API for FASTGPT NextAPI\nasync function handler(\n  req: ApiRequestProps<TemplateBody, TemplateQuery>,\n  res: ApiResponseType<any>,\n): Promise<TemplateResponse> {\n\n  return {}\n}\n\nexport default NextAPI(handler);\n```\n\n----------------------------------------\n\nTITLE: API Usage Example with cURL\nDESCRIPTION: Demonstrates how to make a POST request to the PDF parsing service using cURL, including file upload and authentication.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mineru/README.md#2025-04-10_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST \"http://localhost:7231/v1/parse/file\" \\\n--header \"Authorization: Bearer your_access_token\" \\\n--form \"file=@./file/chinese_test.pdf\"\n```\n\n----------------------------------------\n\nTITLE: Creating an Empty Collection in FastGPT\nDESCRIPTION: API request to create an empty collection within a knowledge base. Parameters include dataset ID, parent ID, name, type, and optional metadata.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'http://localhost:3000/api/core/dataset/collection/create' \\\n--header 'Authorization: Bearer {{authorization}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"datasetId\":\"6593e137231a2be9c5603ba7\",\n    \"parentId\": null,\n    \"name\":\"测试\",\n    \"type\":\"virtual\",\n    \"metadata\":{\n      \"test\":111\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Executing FastGPT V4.6.3 Initialization API Call using cURL\nDESCRIPTION: This cURL command sends a POST request to initialize FastGPT V4.6.3. It requires the host domain and rootkey to be replaced with actual values. The initialization process updates fields in the Mongo database for dataset, collection, and data.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/463.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv463' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Response Format for Question Guide Generation (JSON)\nDESCRIPTION: This snippet shows the expected JSON response format when generating a question guide in FastGPT. It includes a status code and an array of suggested questions.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/chat.md#2025-04-10_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"code\": 200,\n    \"statusText\": \"\",\n    \"message\": \"\",\n    \"data\": [\n        \"你对AI有什么看法？\",\n        \"想了解AI的应用吗？\",\n        \"你希望AI能做什么？\"\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Updating LLMModel Configuration with Provider Field in JSON\nDESCRIPTION: Example of updated configuration for LLMModel with the new 'provider' field that helps categorize models. The example shows a GPT-4o model configuration with various capability settings and parameters.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/4816.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"provider\": \"OpenAI\", // 这是新增的\n    \"model\": \"gpt-4o\",\n    \"name\": \"gpt-4o\",\n    \"maxContext\": 125000,\n    \"maxResponse\": 4000,\n    \"quoteMaxToken\": 120000,\n    \"maxTemperature\": 1.2,\n    \"charsPointsPrice\": 0,\n    \"censor\": false,\n    \"vision\": true,\n    \"datasetProcess\": true,\n    \"usedInClassify\": true,\n    \"usedInExtractFields\": true,\n    \"usedInToolCall\": true,\n    \"usedInQueryExtension\": true,\n    \"toolChoice\": true,\n    \"functionCall\": false,\n    \"customCQPrompt\": \"\",\n    \"customExtractPrompt\": \"\",\n    \"defaultSystemChatPrompt\": \"\",\n    \"defaultConfig\": {},\n    \"fieldMap\": {}\n}\n```\n\n----------------------------------------\n\nTITLE: Parsing JSON Response for Detailed, Non-Streaming Request in FastGPT API v2\nDESCRIPTION: This snippet illustrates the JSON structure of a response for a detailed, non-streaming request in FastGPT API v2. It includes workflow information, token usage, and the AI's response with additional context.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/chat.md#2025-04-10_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"responseData\": [\n        {\n            \"id\": \"iSol79OFrBH1I9kC\",\n            \"nodeId\": \"448745\",\n            \"moduleName\": \"common:core.module.template.work_start\",\n            \"moduleType\": \"workflowStart\",\n            \"runningTime\": 0\n        },\n        {\n            \"id\": \"t1T94WCy6Su3BK4V\",\n            \"nodeId\": \"fjLpE3XPegmoGtbU\",\n            \"moduleName\": \"AI 对话\",\n            \"moduleType\": \"chatNode\",\n            \"runningTime\": 1.46,\n            \"totalPoints\": 0,\n            \"model\": \"GPT-4o-mini\",\n            \"tokens\": 64,\n            \"inputTokens\": 10,\n            \"outputTokens\": 54,\n            \"query\": \"你是谁\",\n            \"reasoningText\": \"\",\n            \"historyPreview\": [\n                {\n                    \"obj\": \"Human\",\n                    \"value\": \"你是谁\"\n                },\n                {\n                    \"obj\": \"AI\",\n                    \"value\": \"我是一个人工智能助手，旨在帮助回答问题和提供信息。如果你有任何问题或需要帮助，请告诉我！\"\n                }\n            ],\n            \"contextTotalLen\": 2\n        }\n    ],\n    \"newVariables\": {\n\n    },\n    \"id\": \"\",\n    \"model\": \"\",\n    \"usage\": {\n        \"prompt_tokens\": 1,\n        \"completion_tokens\": 1,\n        \"total_tokens\": 1\n    },\n    \"choices\": [\n        {\n            \"message\": {\n                \"role\": \"assistant\",\n                \"content\": \"我是一个人工智能助手，旨在帮助回答问题和提供信息。如果你有任何问题或需要帮助，请告诉我！\"\n            },\n            \"finish_reason\": \"stop\",\n            \"index\": 0\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Updating User Feedback in FastGPT (Bash/cURL)\nDESCRIPTION: This snippet demonstrates how to update user feedback (thumbs down/up) for a chat interaction in FastGPT using cURL. It requires the app ID, chat ID, data ID, and optionally the user's bad feedback information.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/chat.md#2025-04-10_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'http://localhost:3000/api/core/chat/feedback/updateUserFeedback' \\\n--header 'Authorization: Bearer {{apikey}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"appId\": \"appId\",\n    \"chatId\": \"chatId\",\n    \"dataId\": \"dataId\",\n    \"userBadFeedback\": \"yes\"\n}'\n```\n\n----------------------------------------\n\nTITLE: API Response Format for PDF-Mistral Plugin\nDESCRIPTION: These JSON snippets demonstrate the expected response format for successful and error cases when using the PDF-Mistral plugin API.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mistral/README.md#2025-04-10_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"pages\": 5,\n  \"markdown\": \"...\",\n  \"duration\": 10.5\n}\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"pages\": 0,\n  \"markdown\": \"\",\n  \"error\": \"错误信息\"\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Collection Data List in FastGPT\nDESCRIPTION: This snippet shows how to retrieve a list of data entries from a collection. It includes pagination parameters and supports text search. Two versions of the API are provided for different FastGPT versions.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'http://localhost:3000/api/core/dataset/data/v2/list' \\\n--header 'Authorization: Bearer {{authorization}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"offset\": 0,\n    \"pageSize\": 10,\n    \"collectionId\":\"65abd4ac9d1448617cba6171\",\n    \"searchText\":\"\"\n}'\n```\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'http://localhost:3000/api/core/dataset/data/list' \\\n--header 'Authorization: Bearer {{authorization}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"pageNum\":1,\n    \"pageSize\": 10,\n    \"collectionId\":\"65abd4ac9d1448617cba6171\",\n    \"searchText\":\"\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Running FastGPT v4.8.20 Upgrade Script with cURL\nDESCRIPTION: HTTP POST request to initialize FastGPT v4.8.20 upgrade. Requires rootkey from environment variables and FastGPT domain. The script automatically loads original configuration file models into the new model configuration system.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/4820.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv4820' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Retrieving Knowledge Base Details in FastGPT\nDESCRIPTION: API request to get detailed information about a specific knowledge base using its ID.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request GET 'http://localhost:3000/api/core/dataset/detail?id=6593e137231a2be9c5603ba7' \\\n--header 'Authorization: Bearer {{authorization}}' \\\n```\n\n----------------------------------------\n\nTITLE: Defining Reference Template for Knowledge Base Formatting\nDESCRIPTION: This snippet shows an example of a reference template used to format knowledge base entries. It demonstrates how to incorporate variables like question, answer, source, and other metadata into a structured format for AI processing.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/course/ai_settings.md#2025-04-10_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{instruction:\"{{q}}\",output:\"{{a}}\",source:\"{{source}}\"}\n```\n\n----------------------------------------\n\nTITLE: Creating a Knowledge Base in FastGPT\nDESCRIPTION: API request to create a new knowledge base. Parameters include parent ID, type, name, introduction, avatar, vector model, and agent model.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'http://localhost:3000/api/core/dataset/create' \\\n--header 'Authorization: Bearer {{authorization}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"parentId\": null,\n    \"type\": \"dataset\",\n    \"name\":\"测试\",\n    \"intro\":\"介绍\",\n    \"avatar\": \"\",\n    \"vectorModel\": \"text-embedding-ada-002\",\n    \"agentModel\": \"gpt-3.5-turbo-16k\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Parsing Streaming Response for Detailed Request in FastGPT API v2\nDESCRIPTION: This snippet shows the structure of a streaming response for a detailed request in FastGPT API v2. It demonstrates how the API returns workflow information, partial responses, and node status updates in a stream format.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/chat.md#2025-04-10_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nevent: flowNodeResponse\ndata: {\"id\":\"iYv2uA9rCWAtulWo\",\"nodeId\":\"workflowStartNodeId\",\"moduleName\":\"流程开始\",\"moduleType\":\"workflowStart\",\"runningTime\":0}\n\nevent: flowNodeStatus\ndata: {\"status\":\"running\",\"name\":\"AI 对话\"}\n\nevent: answer\ndata: {\"id\":\"\",\"object\":\"\",\"created\":0,\"model\":\"\",\"choices\":[{\"delta\":{\"role\":\"assistant\",\"content\":\"你好\"},\"index\":0,\"finish_reason\":null}]}\n\nevent: answer\ndata: {\"id\":\"\",\"object\":\"\",\"created\":0,\"model\":\"\",\"choices\":[{\"delta\":{\"role\":\"assistant\",\"content\":\"！\"},\"index\":0,\"finish_reason\":null}]}\n\nevent: answer\ndata: {\"id\":\"\",\"object\":\"\",\"created\":0,\"model\":\"\",\"choices\":[{\"delta\":{\"role\":\"assistant\",\"content\":\"今天\"},\"index\":0,\"finish_reason\":null}]}\n\nevent: answer\ndata: {\"id\":\"\",\"object\":\"\",\"created\":0,\"model\":\"\",\"choices\":[{\"delta\":{\"role\":\"assistant\",\"content\":\"过得怎么样？\"},\"index\":0,\"finish_reason\":null}]}\n\nevent: flowNodeResponse\ndata: {\"id\":\"pVzLBF7M3Ol4n7s6\",\"nodeId\":\"ixe20AHN3jy74pKf\",\"moduleName\":\"AI 对话\",\"moduleType\":\"chatNode\",\"runningTime\":1.48,\"totalPoints\":0.0042,\"model\":\"Qwen-plus\",\"tokens\":28,\"inputTokens\":8,\"outputTokens\":20,\"query\":\"你好\",\"reasoningText\":\"\",\"historyPreview\":[{\"obj\":\"Human\",\"value\":\"你好\"},{\"obj\":\"AI\",\"value\":\"你好！今天过得怎么样？\"}],\"contextTotalLen\":2}\n\nevent: answer\ndata: {\"id\":\"\",\"object\":\"\",\"created\":0,\"model\":\"\",\"choices\":[{\"delta\":{\"role\":\"assistant\",\"content\":null},\"index\":0,\"finish_reason\":\"stop\"}]}\n\nevent: answer\ndata: [DONE]\n```\n\n----------------------------------------\n\nTITLE: Parsing Streaming Response for Non-Detailed Request in FastGPT API v2\nDESCRIPTION: This snippet demonstrates the structure of a streaming response for a non-detailed request in FastGPT API v2. It shows how the API returns partial responses in a stream format.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/chat.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndata: {\"id\":\"\",\"object\":\"\",\"created\":0,\"model\":\"\",\"choices\":[{\"delta\":{\"role\":\"assistant\",\"content\":\"你好\"},\"index\":0,\"finish_reason\":null}]}\n\ndata: {\"id\":\"\",\"object\":\"\",\"created\":0,\"model\":\"\",\"choices\":[{\"delta\":{\"role\":\"assistant\",\"content\":\"！\"},\"index\":0,\"finish_reason\":null}]}\n\ndata: {\"id\":\"\",\"object\":\"\",\"created\":0,\"model\":\"\",\"choices\":[{\"delta\":{\"role\":\"assistant\",\"content\":\"今天\"},\"index\":0,\"finish_reason\":null}]}\n\ndata: {\"id\":\"\",\"object\":\"\",\"created\":0,\"model\":\"\",\"choices\":[{\"delta\":{\"role\":\"assistant\",\"content\":\"过得怎么样？\"},\"index\":0,\"finish_reason\":null}]}\n\ndata: {\"id\":\"\",\"object\":\"\",\"created\":0,\"model\":\"\",\"choices\":[{\"delta\":{\"role\":\"assistant\",\"content\":null},\"index\":0,\"finish_reason\":\"stop\"}]}\n\ndata: [DONE]\n```\n\n----------------------------------------\n\nTITLE: Listing Knowledge Bases in FastGPT\nDESCRIPTION: API request to retrieve a list of knowledge bases. The parentId parameter can be used to specify a parent directory, or empty string/null for root directory knowledge bases.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'http://localhost:3000/api/core/dataset/list?parentId=' \\\n--header 'Authorization: Bearer xxxx' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"parentId\":\"\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Requirements\nDESCRIPTION: Specifies required Python packages and their versions, including PyTorch with CUDA 11.8 support, deep learning frameworks, audio processing libraries, and API dependencies. Contains conditional installations based on operating system platform.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/tts-cosevoice/requirements.txt#2025-04-10_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n--extra-index-url https://download.pytorch.org/whl/cu118\nconformer==0.3.2\ndeepspeed==0.15.1; sys_platform == 'linux'\ndiffusers==0.27.2\ngdown==5.1.0\ngradio==5.11.0\ngrpcio==1.57.0\ngrpcio-tools==1.57.0\nhydra-core==1.3.2\nHyperPyYAML==1.2.2\ninflect==7.3.1\nlibrosa==0.10.2\nlightning==2.3.3\nmatplotlib==3.7.5\nmodelscope==1.15.0\nnetworkx==3.1\nomegaconf==2.3.0\nonnxruntime-gpu; sys_platform == 'linux'\nonnxruntime; sys_platform == 'darwin' or sys_platform == 'windows'\nopenai-whisper==20231117\nprotobuf==4.25\npydantic==2.7.0\nrich==13.7.1\nsoundfile==0.12.1\ntensorboard\nwget==3.2\nfastapi==0.111.0\nfastapi-cli==0.0.4\nWeTextProcessing==1.0.3\n```\n\n----------------------------------------\n\nTITLE: Knowledge Base List Response in FastGPT\nDESCRIPTION: JSON response containing a list of knowledge bases with details including ID, name, type, permissions, and vector model information.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"code\": 200,\n    \"statusText\": \"\",\n    \"message\": \"\",\n    \"data\": [\n        {\n            \"_id\": \"65abc9bd9d1448617cba5e6c\",\n            \"parentId\": null,\n            \"avatar\": \"\",\n            \"name\": \"测试\",\n            \"intro\": \"\",\n            \"type\": \"dataset\",\n            \"permission\": \"private\",\n            \"canWrite\": true,\n            \"isOwner\": true,\n            \"vectorModel\": {\n                \"model\": \"text-embedding-ada-002\",\n                \"name\": \"Embedding-2\",\n                \"charsPointsPrice\": 0,\n                \"defaultToken\": 512,\n                \"maxToken\": 8000,\n                \"weight\": 100\n            }\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Successful Search Response Format\nDESCRIPTION: Example of successful search results returned in JSON format\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/plugins/searxng_plugin_guide.md#2025-04-10_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n{\\n  \\\"result\\\": \\\"[{\\\\\\\"title\\\\\\\":\\\\\\\"标题1\\\\\\\",\\\\\\\"link\\\\\\\":\\\\\\\"链接1\\\\\\\",\\\\\\\"snippet\\\\\\\":\\\\\\\"摘要1\\\\\\\"}, ...]\\\"\\n}\n```\n\n----------------------------------------\n\nTITLE: Knowledge Base Details Response in FastGPT\nDESCRIPTION: JSON response containing detailed information about a knowledge base, including ID, team information, models, permissions, and timestamps.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"code\": 200,\n    \"statusText\": \"\",\n    \"message\": \"\",\n    \"data\": {\n        \"_id\": \"6593e137231a2be9c5603ba7\",\n        \"parentId\": null,\n        \"teamId\": \"65422be6aa44b7da77729ec8\",\n        \"tmbId\": \"65422be6aa44b7da77729ec9\",\n        \"type\": \"dataset\",\n        \"status\": \"active\",\n        \"avatar\": \"/icon/logo.svg\",\n        \"name\": \"FastGPT test\",\n        \"vectorModel\": {\n            \"model\": \"text-embedding-ada-002\",\n            \"name\": \"Embedding-2\",\n            \"charsPointsPrice\": 0,\n            \"defaultToken\": 512,\n            \"maxToken\": 8000,\n            \"weight\": 100\n        },\n        \"agentModel\": {\n            \"model\": \"gpt-3.5-turbo-16k\",\n            \"name\": \"FastAI-16k\",\n            \"maxContext\": 16000,\n            \"maxResponse\": 16000,\n            \"charsPointsPrice\": 0\n        },\n        \"intro\": \"\",\n        \"permission\": \"private\",\n        \"updateTime\": \"2024-01-02T10:11:03.084Z\",\n        \"canWrite\": true,\n        \"isOwner\": true\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Initialization API for FastGPT V4.3 Upgrade\nDESCRIPTION: This cURL command sends a POST request to the initialization API endpoint for upgrading FastGPT to version 4.3. It requires the rootkey to be set in the headers for authentication.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/43.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv43' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Retrieving FastGPT Application URL in Kubernetes\nDESCRIPTION: This snippet provides a series of conditional commands to retrieve the application URL based on the deployment configuration. It covers scenarios for Ingress, NodePort, LoadBalancer, and ClusterIP service types, using kubectl commands and environment variables to construct the appropriate URL.\nSOURCE: https://github.com/labring/FastGPT/blob/main/deploy/helm/fastgpt/templates/NOTES.txt#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n{{- if .Values.ingress.enabled }}\n{{- range $host := .Values.ingress.hosts }}\n  {{- range .paths }}\n  http{{ if $.Values.ingress.tls }}s{{ end }}://{{ $host.host }}{{ .path }}\n  {{- end }}\n{{- end }}\n{{- else if contains \"NodePort\" .Values.service.type }}\n  export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath=\"{.spec.ports[0].nodePort}\" services {{ include \"fastgpt.fullname\" . }})\n  export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath=\"{.items[0].status.addresses[0].address}\")\n  echo http://$NODE_IP:$NODE_PORT\n{{- else if contains \"LoadBalancer\" .Values.service.type }}\n     NOTE: It may take a few minutes for the LoadBalancer IP to be available.\n           You can watch the status of by running 'kubectl get --namespace {{ .Release.Namespace }} svc -w {{ include \"fastgpt.fullname\" . }}'\n  export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ include \"fastgpt.fullname\" . }} --template \"{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}\")\n  echo http://$SERVICE_IP:{{ .Values.service.port }}\n{{- else if contains \"ClusterIP\" .Values.service.type }}\n  export POD_NAME=$(kubectl get pods --namespace {{ .Release.Namespace }} -l \"app.kubernetes.io/name={{ include \"fastgpt.name\" . }},app.kubernetes.io/instance={{ .Release.Name }}\" -o jsonpath=\"{.items[0].metadata.name}\")\n  export CONTAINER_PORT=$(kubectl get pod --namespace {{ .Release.Namespace }} $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\n  echo \"Visit http://127.0.0.1:8080 to use your application\"\n  kubectl --namespace {{ .Release.Namespace }} port-forward $POD_NAME 8080:$CONTAINER_PORT\n{{- end }}\n```\n\n----------------------------------------\n\nTITLE: Training Order Response in FastGPT\nDESCRIPTION: JSON response for a successful training order creation. Returns a bill ID that can be used for knowledge base data aggregation.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"code\": 200,\n  \"statusText\": \"\",\n  \"message\": \"\",\n  \"data\": \"65112ab717c32018f4156361\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Content Extraction Node in JSON\nDESCRIPTION: This snippet defines a content extraction node for the AI workflow. It specifies inputs for AI model selection, extraction requirements, and target fields to extract from the given text.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/google_search.md#2025-04-10_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"nodeId\": \"lG52GzzMm65z\",\n  \"name\": \"文本内容提取\",\n  \"intro\": \"可从文本中提取指定的数据，例如：sql语句、搜索关键词、代码等\",\n  \"avatar\": \"/imgs/workflow/extract.png\",\n  \"flowNodeType\": \"contentExtract\",\n  \"showStatus\": true,\n  \"position\": {\n    \"x\": 535.331344778598,\n    \"y\": -437.1382636373696\n  },\n  \"inputs\": [\n    {\n      \"key\": \"model\",\n      \"renderTypeList\": [\n        \"selectLLMModel\",\n        \"reference\"\n      ],\n      \"label\": \"core.module.input.label.aiModel\",\n      \"required\": true,\n      \"valueType\": \"string\",\n      \"llmModelType\": \"extractFields\",\n      \"value\": \"gpt-3.5-turbo\"\n    },\n    {\n      \"key\": \"description\",\n      \"renderTypeList\": [\n        \"textarea\",\n        \"reference\"\n      ],\n      \"valueType\": \"string\",\n      \"label\": \"提取要求描述\",\n      \"description\": \"给AI一些对应的背景知识或要求描述，引导AI更好的完成任务。\\n该输入框可使用全局变量。\",\n      \"placeholder\": \"例如: \\n1. 当前时间为: {{cTime}}。你是一个实验室预约助手，你的任务是帮助用户预约实验室，从文本中获取对应的预约信息。\\n2. 你是谷歌搜索助手，需要从文本中提取出合适的搜索词。\",\n      \"value\": \"你是谷歌搜索机器人，根据当前问题和对话记录生成搜索词。你需要自行判断是否需要进行网络实时查询：\\n- 如果需查询则生成搜索词。\\n- 如果不需要查询则不返回字段。\"\n    },\n    {\n      \"key\": \"extractKeys\",\n      \"renderTypeList\": [\n        \"custom\"\n      ],\n      \"label\": \"\",\n      \"valueType\": \"any\",\n      \"description\": \"由 '描述' 和 'key' 组成一个目标字段，可提取多个目标字段\",\n      \"value\": [\n        {\n          \"required\": false,\n          \"defaultValue\": \"\",\n          \"desc\": \"搜索词\",\n          \"key\": \"searchKey\",\n          \"enum\": \"\"\n        }\n      ]\n    }\n  ],\n  \"outputs\": [\n    {\n      \"id\": \"fields\",\n      \"key\": \"fields\",\n      \"label\": \"完整提取结果\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting FastGPT OpenAI Base URL\nDESCRIPTION: Environment variable configuration for FastGPT to use the Nginx proxy endpoint for OpenAI API requests.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/proxy/nginx.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_BASE_URL=https://tgohwtdlrmer.cloud.sealos.io/openai/v1\n```\n\n----------------------------------------\n\nTITLE: Empty Collection Creation Response in FastGPT\nDESCRIPTION: JSON response for a successful empty collection creation. Returns the ID of the newly created collection.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"code\": 200,\n  \"statusText\": \"\",\n  \"message\": \"\",\n  \"data\": \"65abcd009d1448617cba5ee1\"\n}\n```\n\n----------------------------------------\n\nTITLE: Knowledge Base Creation Response in FastGPT\nDESCRIPTION: JSON response for a successful knowledge base creation. Returns the ID of the newly created knowledge base.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"code\": 200,\n  \"statusText\": \"\",\n  \"message\": \"\",\n  \"data\": \"65abc9bd9d1448617cba5e6c\"\n}\n```\n\n----------------------------------------\n\nTITLE: Executing FastGPT V4.8.5 Initialization Script\nDESCRIPTION: This curl command sends a POST request to initialize FastGPT v4.8.5. It requires the rootkey for authentication and the FastGPT domain. This script merges plugin data tables into the application.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/485.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv485' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Creating a Training Order in FastGPT\nDESCRIPTION: API request to create a training usage order for a knowledge base. Requires an API key for authentication and accepts the knowledge base ID and an optional custom order name.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'http://localhost:3000/api/support/wallet/usage/createTrainingUsage' \\\n--header 'Authorization: Bearer {{apikey}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"datasetId\": \"知识库 ID\",\n    \"name\": \"可选，自定义订单名称，例如：文档训练-fastgpt.docx\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Language Comparison Function\nDESCRIPTION: JavaScript function that compares source and target languages to determine if they are the same. Returns a boolean result.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/translate-subtitle-using-gpt.md#2025-04-10_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nfunction main({source_lang, target_lang}){\n    \n    return {\n        result: source_lang === target_lang\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing GPU Dependencies - PyTorch\nDESCRIPTION: Installs specific versions of PyTorch and related packages for GPU acceleration support.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mineru/README.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install --force-reinstall torch==2.3.1 torchvision==0.18.1 \"numpy<2.0.0\" --index-url https://download.pytorch.org/whl/cu118\n```\n\n----------------------------------------\n\nTITLE: Generating Question Guide in FastGPT (Post-4.8.16 Version, Bash/cURL)\nDESCRIPTION: This snippet demonstrates how to generate a question guide using the new version of the FastGPT API (post-4.8.16). It requires the app ID and chat ID, and optionally allows custom configuration for the question guide generation.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/chat.md#2025-04-10_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'http://localhost:3000/api/core/ai/agent/v2/createQuestionGuide' \\\n--header 'Authorization: Bearer {{apikey}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"appId\": \"appId\",\n    \"chatId\": \"chatId\",\n    \"questionGuide\": {\n        \"open\": true,\n        \"model\": \"GPT-4o-mini\",\n        \"customPrompt\": \"你是一个智能助手，请根据用户的问题生成猜你想问。\"\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Installing Marker using Docker for FastGPT PDF Parsing\nDESCRIPTION: Docker commands to pull and run the Marker image for PDF parsing in FastGPT. This setup allows for GPU acceleration and configures the number of processes per GPU.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/marker.md#2025-04-10_snippet_0\n\nLANGUAGE: dockerfile\nCODE:\n```\ndocker pull crpi-h3snc261q1dosroc.cn-hangzhou.personal.cr.aliyuncs.com/marker11/marker_images:v0.2\ndocker run --gpus all -itd -p 7231:7232 --name model_pdf_v2 -e PROCESSES_PER_GPU=\"2\" crpi-h3snc261q1dosroc.cn-hangzhou.personal.cr.aliyuncs.com/marker11/marker_images:v0.2\n```\n\n----------------------------------------\n\nTITLE: Configuring FastGPT for PDF-Mistral Plugin\nDESCRIPTION: This JSON snippet shows how to configure the FastGPT configuration file to use the custom PDF parsing service provided by the PDF-Mistral plugin.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mistral/README.md#2025-04-10_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"xxx\": \"\",\n  \"systemEnv\": {\n    \"xxx\": \"\",\n    \"customPdfParse\": {\n      \"url\": \"http://localhost:7231/v1/parse/file\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Tool Calling Support with CURL - Second Round\nDESCRIPTION: A CURL command for testing the second round of tool calling, where the tool result is sent back to the model to continue the conversation.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/faq.md#2025-04-10_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://oneapi.xxxx/v1/chat/completions' \\\n--header 'Authorization: Bearer sk-xxx' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n  \"model\": \"gpt-4o-mini\",\n  \"temperature\": 0.01,\n  \"max_tokens\": 8000,\n  \"stream\": true,\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"几点了\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"tool_calls\": [\n        {\n          \"id\": \"kDia9S19c4RO\",\n          \"type\": \"function\",\n          \"function\": {\n            \"name\": \"hCVbIY\",\n            \"arguments\": \"{}\"\n          }\n        }\n      ]\n    },\n    {\n      \"tool_call_id\": \"kDia9S19c4RO\",\n      \"role\": \"tool\",\n      \"name\": \"hCVbIY\",\n      \"content\": \"{\\n  \\\"time\\\": \\\"2024-09-14 22:59:21 Sunday\\\"\\n}\"\n    }\n  ],\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"hCVbIY\",\n        \"description\": \"获取用户当前时区的时间。\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {},\n          \"required\": []\n        }\n      }\n    }\n  ],\n  \"tool_choice\": \"auto\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Starting the PDF-Mistral Plugin Server\nDESCRIPTION: These commands demonstrate how to start the server for the PDF-Mistral plugin using either Python directly or uvicorn.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mistral/README.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython api_mp.py\n```\n\nLANGUAGE: bash\nCODE:\n```\nuvicorn api_mp:app --host 0.0.0.0 --port 7231\n```\n\n----------------------------------------\n\nTITLE: Initializing FastGPT Commercial Version using HTTP Request\nDESCRIPTION: cURL command to initialize multi-tenant notification settings in FastGPT commercial version. Requires replacing {{rootkey}} with environment variable rootkey and {{host}} with the FastGPT commercial domain.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/489.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/init/489' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Configuring ReRank Models in FastGPT\nDESCRIPTION: This JSON configuration snippet shows how to set up ReRank models in FastGPT, specifically for integrating Cohere's rerank model. It includes the model name, request URL, and authentication key.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/47.md#2025-04-10_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"reRankModels\": [\n        {\n            \"model\": \"rerank-multilingual-v2.0\",\n            \"name\": \"检索重排\",\n            \"requestUrl\": \"https://api.cohere.ai/v1/rerank\",\n            \"requestAuth\": \"Coherer上申请的key\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Text-to-Speech Model Availability with CURL\nDESCRIPTION: A CURL command example for testing the TTS functionality by sending a text sample to the OpenAI speech API endpoint.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/faq.md#2025-04-10_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl https://api.openai.com/v1/audio/speech \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"tts-1\",\n    \"input\": \"The quick brown fox jumped over the lazy dog.\",\n    \"voice\": \"alloy\"\n  }' \\\n  --output speech.mp3\n```\n\n----------------------------------------\n\nTITLE: Testing Rerank Model Availability with CURL\nDESCRIPTION: A CURL command example for testing the reranking functionality by sending a query and document to a rerank API endpoint.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/faq.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://xxxx.com/api/v1/rerank' \\\n--header 'Authorization: Bearer {{ACCESS_TOKEN}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n  \"model\": \"bge-rerank-m3\",\n  \"query\": \"导演是谁\",\n  \"documents\": [\n    \"你是谁？\\n我是电影《铃芽之旅》助手\"\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for PDF-Mistral Plugin\nDESCRIPTION: This snippet shows how to set the Mistral API key in the .env file for the PDF-Mistral plugin.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mistral/README.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# 在 .env 文件中\nMISTRAL_API_KEY=你的-mistral-api-密钥\n```\n\n----------------------------------------\n\nTITLE: Configuring Vector Models in FastGPT\nDESCRIPTION: Shows how to modify the config.json file to add the M3E model to the list of available vector models in FastGPT, including model details and pricing.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/m3e.md#2025-04-10_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n\"vectorModels\": [\n    {\n      \"model\": \"text-embedding-ada-002\",\n      \"name\": \"Embedding-2\",\n      \"price\": 0.2,\n      \"defaultToken\": 500,\n      \"maxToken\": 3000\n    },\n    {\n      \"model\": \"m3e\",\n      \"name\": \"M3E（测试使用）\",\n      \"price\": 0.1,\n      \"defaultToken\": 500,\n      \"maxToken\": 1800\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Subtitle Information Extraction\nDESCRIPTION: JavaScript function that parses subtitle text to extract number information, timestamps, and text content. Splits input by newlines and categorizes content based on patterns.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/translate-subtitle-using-gpt.md#2025-04-10_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nfunction main({text}){\n  const lines = text.split('\\n');\n  const timePattern = /\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}/;\n  const numberInfo = [];\n  const timeInfo = [];\n  const textInfo = [];\n  let currentText = [];\n\n  // 提取序号、时间戳和文本信息\n  lines.forEach(line => {\n    if (/^\\d+$/.test(line.trim())) {\n      numberInfo.push(line.trim());\n    } else if (timePattern.test(line)) {\n      timeInfo.push(line);\n      if (currentText.length > 0) {\n        textInfo.push(currentText.join(' '));\n        currentText = [];\n      }\n    } else if (line.trim() === '') {\n      // Skip empty lines\n    } else {\n      currentText.push(line.trim());\n    }\n  });\n\n  if (currentText.length > 0) {\n    textInfo.push(currentText.join(' '));\n  }\n\n  return { numberInfo, timeInfo, textInfo };\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Upgrade Script for FastGPT v4.9.4 (Commercial Version)\nDESCRIPTION: This cURL command sends a POST request to initiate the v4.9.4 upgrade process for FastGPT commercial version. It requires the rootkey for authentication and the FastGPT domain. The script updates the site synchronization timer.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/494.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv494' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Formatting Subtitles in JavaScript\nDESCRIPTION: This function processes combined text, translated text, time information, and numbering to format subtitle content. It combines multiple inputs into a structured SRT format, handling line breaks and indexing.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/translate-subtitle-using-gpt.md#2025-04-10_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nfunction main({combinedText, transedText, timeInfo, currentIndex=0,numberInfo}){\n  const textLines = combinedText.split('<T>');\n  const resultLines = transedText.split('<T>');\n  const combinedLines = [];\n\n  resultLines.forEach((line, index) => {\n    combinedLines.push(numberInfo[currentIndex+index]);\n    combinedLines.push(timeInfo[currentIndex+index]);\n    combinedLines.push(line)\n    combinedLines.push(textLines[index]);\n    combinedLines.push('');\n  });\n\n  const srtContent = combinedLines.join('\\n');\n  \n\n    return {\n        srtContent,\n        currentIndex: currentIndex+textLines.length\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Data Cleanup Script - Bash HTTP Request\nDESCRIPTION: HTTP POST request to clear invalid data including files, images, knowledge base collections and vectors. Requires root key authentication and FastGPT host domain.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/471.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/clearInvalidData' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Extracting Translated Text from LLM Output in JavaScript\nDESCRIPTION: This function extracts the translated text from the output of a language model. It splits the input by code block delimiters and returns the last non-empty block, which is assumed to be the translated content.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/translate-subtitle-using-gpt.md#2025-04-10_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nfunction main({data1}){\n    const result = data1.split(\"```\").filter(item => !!item.trim())\n\n    if(result[result.length-1]) {\n        return {\n            result: result[result.length-1].trim() \n        }\n    }\n\n    return {\n        result: '未截取到翻译内容'\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Testing Whisper Model Availability with CURL\nDESCRIPTION: A CURL command example for testing the speech-to-text functionality by sending an audio file to the OpenAI transcription API endpoint.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/faq.md#2025-04-10_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl https://api.openai.com/v1/audio/transcriptions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/path/to/file/audio.mp3\" \\\n  -F model=\"whisper-1\"\n```\n\n----------------------------------------\n\nTITLE: Executing JavaScript to Check Processing Completion\nDESCRIPTION: This code snippet checks if the current chunk is the last one in the array, determining if processing is complete. It returns a boolean 'isEnd' and the next index 'i'.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/translate-subtitle-using-gpt.md#2025-04-10_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nfunction main({chunks, currentChunk}){\n    const findIndex = chunks.findIndex((item) => item === currentChunk)\n\n    return {\n        isEnd: chunks.length-1 === findIndex,\n        i: findIndex + 1,\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Qwen-Chat Model in FastGPT\nDESCRIPTION: JSON configuration to add the Qwen-Chat model to FastGPT's config.json file.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/xinference.md#2025-04-10_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"llmModels\": [\n    {\n      \"model\": \"qwen-chat\",\n      \"name\": \"Qwen\",\n      \"avatar\": \"/imgs/model/Qwen.svg\",\n      \"maxContext\": 125000,\n      \"maxResponse\": 4000,\n      \"quoteMaxToken\": 120000,\n      \"maxTemperature\": 1.2,\n      \"charsPointsPrice\": 0,\n      \"censor\": false,\n      \"vision\": true,\n      \"datasetProcess\": true,\n      \"usedInClassify\": true,\n      \"usedInExtractFields\": true,\n      \"usedInToolCall\": true,\n      \"toolChoice\": true,\n      \"functionCall\": false,\n      \"customCQPrompt\": \"\",\n      \"customExtractPrompt\": \"\",\n      \"defaultSystemChatPrompt\": \"\",\n      \"defaultConfig\": {}\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Laboratory Appointment Records in TypeScript\nDESCRIPTION: This function handles updating existing laboratory appointment records. It checks for required fields, retrieves the existing record, and updates it with new information.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/lab_appointment.md#2025-04-10_snippet_2\n\nLANGUAGE: TypeScript\nCODE:\n```\nasync function putRecord({ name, time, labname }: RequestType) {\n  const missData = []\n  if (!name) missData.push(\"你的姓名\")\n\n  if (missData.length > 0) {\n    return {\n      result: `请提供: ${missData.join(\"、\")}`\n    }\n  }\n\n  const { data: record } = await db.collection(\"LabAppointment\").where({\n    name, status: \"unStart\"\n  }).getOne()\n\n  if (!record) {\n    return {\n      result: `${name} 还没有预约记录`\n    }\n  }\n\n  const updateWhere = {\n    name,\n    time: time || record.time,\n    labname: labname || record.labname\n  }\n\n  await db.collection(\"LabAppointment\").where({\n    name, status: \"unStart\"\n  }).update(updateWhere)\n\n  return {\n    result: `修改预约成功。\n  姓名：${name}·\n  时间: ${updateWhere.time}\n  实验室名: ${updateWhere.labname}\n  ` }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Laboratory Appointment Records in TypeScript\nDESCRIPTION: This function retrieves a laboratory appointment record for a given name. It checks if the name is provided and returns the appointment details if found.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/lab_appointment.md#2025-04-10_snippet_3\n\nLANGUAGE: TypeScript\nCODE:\n```\nasync function getRecord({ name }: RequestType) {\n  if (!name) {\n    return {\n      result: \"请提供你的姓名\"\n    }\n  }\n  const { data } = await db.collection('LabAppointment').where({ name, status: \"unStart\" }).getOne()\n\n  if (!data) {\n    return {\n      result: `${name} 没有预约中的记录`\n    }\n  }\n  return {\n    result: `${name} 有一条预约记录：\n姓名：${data.name}\n时间: ${data.time}\n实验室名: ${data.labname}\n    `\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Text Processing Node in JSON\nDESCRIPTION: This snippet defines a text processing node in the workflow. It specifies the node's properties, position, inputs, and outputs for processing text data within the AI system.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/google_search.md#2025-04-10_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"nodeId\": \"FYLw1BokYUad\",\n  \"name\": \"文本加工\",\n  \"intro\": \"可对固定或传入的文本进行加工后输出，非字符串类型数据最终会转成字符串类型。\",\n  \"avatar\": \"/imgs/workflow/textEditor.svg\",\n  \"flowNodeType\": \"pluginModule\",\n  \"showStatus\": false,\n  \"position\": {\n    \"x\": 2479.5913201989906,\n    \"y\": 288.52613614690904\n  },\n  \"inputs\": [\n    {\n      \"key\": \"system_addInputParam\",\n      \"valueType\": \"dynamic\",\n      \"label\": \"动态外部数据\",\n      \"renderTypeList\": [\n        \"addInputParam\"\n      ],\n      \"required\": false,\n      \"description\": \"\",\n      \"canEdit\": false,\n      \"value\": \"\",\n      \"editField\": {\n        \"key\": true\n      },\n      \"dynamicParamDefaultValue\": {\n        \"inputType\": \"reference\",\n        \"valueType\": \"string\",\n        \"required\": true\n      }\n    }\n  ],\n  \"outputs\": [\n    {\n      \"id\": \"text\",\n      \"type\": \"static\",\n      \"key\": \"text\",\n      \"valueType\": \"string\",\n      \"label\": \"text\",\n      \"description\": \"\"\n    }\n  ],\n  \"pluginId\": \"community-textEditor\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining FastGPT Workflow Configuration in JSON\nDESCRIPTION: This JSON configuration defines the nodes and their connections in a FastGPT workflow for a lab appointment system. It includes user input handling, HTTP requests for appointment actions, and response generation.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/lab_appointment.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"nodes\": [\n    {\n      \"nodeId\": \"userChatInput\",\n      \"name\": \"流程开始\",\n      \"intro\": \"当用户发送一个内容后，流程将会从这个模块开始执行。\",\n      \"avatar\": \"/imgs/workflow/userChatInput.svg\",\n      \"flowNodeType\": \"workflowStart\",\n      \"position\": {\n        \"x\": 309.7143912167367,\n        \"y\": 1501.2761754220846\n      },\n      \"inputs\": [\n        {\n          \"key\": \"userChatInput\",\n          \"renderTypeList\": [\n            \"reference\",\n            \"textarea\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"问题输入\",\n          \"required\": true,\n          \"toolDescription\": \"用户问题\",\n          \"type\": \"systemInput\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0,\n          \"value\": [\n            \"userChatInput\",\n            \"userChatInput\"\n          ]\n        }\n      ],\n      \"outputs\": [\n        {\n          \"id\": \"userChatInput\",\n          \"type\": \"static\",\n          \"key\": \"userChatInput\",\n          \"valueType\": \"string\",\n          \"label\": \"core.module.input.label.user question\"\n        }\n      ]\n    },\n    {\n      \"nodeId\": \"eg5upi\",\n      \"name\": \"指定回复\",\n      \"intro\": \"该模块可以直接回复一段指定的内容。常用于引导、提示。非字符串内容传入时，会转成字符串进行输出。\",\n      \"avatar\": \"/imgs/workflow/reply.png\",\n      \"flowNodeType\": \"answerNode\",\n      \"position\": {\n        \"x\": 1962.729630445213,\n        \"y\": 2295.9791334948304\n      },\n      \"inputs\": [\n        {\n          \"key\": \"text\",\n          \"renderTypeList\": [\n            \"textarea\",\n            \"reference\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"core.module.input.label.Response content\",\n          \"description\": \"core.module.input.description.Response content\",\n          \"placeholder\": \"core.module.input.description.Response content\",\n          \"type\": \"textarea\",\n          \"showTargetInApp\": true,\n          \"showTargetInPlugin\": true,\n          \"connected\": true,\n          \"selectedTypeIndex\": 1,\n          \"value\": [\n            \"40clf3\",\n            \"result\"\n          ]\n        }\n      ],\n      \"outputs\": []\n    },\n    {\n      \"nodeId\": \"kge59i\",\n      \"name\": \"用户引导\",\n      \"intro\": \"可以配置应用的系统参数。\",\n      \"avatar\": \"/imgs/workflow/userGuide.png\",\n      \"flowNodeType\": \"userGuide\",\n      \"position\": {\n        \"x\": -327.218389965887,\n        \"y\": 1504.8056414948464\n      },\n      \"inputs\": [\n        {\n          \"key\": \"welcomeText\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"core.app.Welcome Text\",\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"value\": \"你好，我是实验室助手，请问有什么可以帮助你的么？如需预约或修改预约实验室，请提供姓名、时间和实验室名称。\\n[实验室介绍]\\n[开放时间]\\n[预约]\",\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"variables\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"core.module.Variable\",\n          \"value\": [\n            {\n              \"id\": \"gt9b23\",\n              \"key\": \"name\",\n              \"label\": \"name\",\n              \"type\": \"input\",\n              \"required\": true,\n              \"maxLen\": 50,\n              \"enums\": [\n                {\n                  \"value\": \"\"\n                }\n              ]\n            }\n          ],\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"questionGuide\",\n          \"valueType\": \"boolean\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"type\": \"switch\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"value\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"tts\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"\",\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"value\": {\n            \"type\": \"model\",\n            \"model\": \"tts-1\",\n            \"voice\": \"alloy\"\n          },\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"whisper\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"\",\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"scheduleTrigger\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"label\": \"\",\n          \"value\": null\n        }\n      ],\n      \"outputs\": []\n    },\n    {\n      \"nodeId\": \"40clf3\",\n      \"name\": \"HTTP请求\",\n      \"intro\": \"可以发出一个 HTTP 请求，实现更为复杂的操作（联网搜索、数据库查询等）\",\n      \"avatar\": \"/imgs/workflow/http.png\",\n      \"flowNodeType\": \"httpRequest468\",\n      \"showStatus\": true,\n      \"position\": {\n        \"x\": 1118.6532653446993,\n        \"y\": 1955.886106913907\n      },\n      \"inputs\": [\n        {\n          \"key\": \"system_httpMethod\",\n          \"renderTypeList\": [\n            \"custom\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"\",\n          \"value\": \"POST\",\n          \"required\": true,\n          \"type\": \"custom\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"valueType\": \"string\",\n          \"renderTypeList\": [\n            \"reference\"\n          ],\n          \"key\": \"action\",\n          \"label\": \"action\",\n          \"toolDescription\": \"预约行为，一共四种：\\nget - 查询预约情况\\nput - 更新预约\\npost - 新增预约\\ndelete - 删除预约\",\n          \"required\": true,\n          \"canEdit\": true,\n          \"editField\": {\n            \"key\": true,\n            \"description\": true\n          }\n        },\n        {\n          \"valueType\": \"string\",\n          \"renderTypeList\": [\n            \"reference\"\n          ],\n          \"key\": \"labname\",\n          \"label\": \"labname\",\n          \"toolDescription\": \"实验室名称\",\n          \"required\": false,\n          \"canEdit\": true,\n          \"editField\": {\n            \"key\": true,\n            \"description\": true\n          }\n        },\n        {\n          \"valueType\": \"string\",\n          \"renderTypeList\": [\n            \"reference\"\n          ],\n          \"key\": \"time\",\n          \"label\": \"time\",\n          \"toolDescription\": \"预约时间，按 YYYY/MM/DD HH:mm 格式返回\",\n          \"required\": false,\n          \"canEdit\": true,\n          \"editField\": {\n            \"key\": true,\n            \"description\": true\n          }\n        },\n        {\n          \"key\": \"system_httpReqUrl\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"\",\n          \"description\": \"core.module.input.description.Http Request Url\",\n          \"placeholder\": \"https://api.ai.com/getInventory\",\n          \"required\": false,\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"value\": \"https://d8dns0.laf.dev/appointment-lab\",\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"system_httpHeader\",\n          \"renderTypeList\": [\n            \"custom\"\n          ],\n          \"valueType\": \"any\",\n          \"value\": [],\n          \"label\": \"\",\n          \"description\": \"core.module.input.description.Http Request Header\",\n          \"placeholder\": \"core.module.input.description.Http Request Header\",\n          \"required\": false,\n          \"type\": \"custom\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"system_httpParams\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"value\": [],\n          \"label\": \"\",\n          \"required\": false,\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"system_httpJsonBody\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"value\": \"{\\r\\n  \\\"name\\\": \\\"{{name}}\\\",\\r\\n  \\\"time\\\": \\\"{{time}}\\\",\\r\\n  \\\"labname\\\": \\\"{{labname}}\\\",\\r\\n  \\\"action\\\": \\\"{{action}}\\\"\\r\\n}\",\n          \"label\": \"\",\n          \"required\": false,\n          \"type\": \"hidden\",\n          \"showTargetInApp\": false,\n          \"showTargetInPlugin\": false,\n          \"connected\": false,\n          \"selectedTypeIndex\": 0\n        },\n        {\n          \"key\": \"system_addInputParam\",\n          \"renderTypeList\": [\n            \"addInputParam\"\n          ],\n          \"valueType\": \"dynamic\",\n          \"label\": \"\",\n          \"required\": false,\n          \"description\": \"core.module.input.description.HTTP Dynamic Input\",\n          \"editField\": {\n            \"key\": true,\n            \"valueType\": true\n          }\n        }\n      ],\n      \"outputs\": [\n        {\n          \"id\": \"system_addOutputParam\",\n          \"type\": \"dynamic\",\n          \"key\": \"system_addOutputParam\",\n          \"valueType\": \"dynamic\",\n          \"label\": \"\",\n          \"editField\": {\n            \"key\": true,\n            \"valueType\": true\n          }\n        },\n        {\n          \"id\": \"result\",\n          \"type\": \"static\",\n          \"key\": \"result\",\n          \"valueType\": \"string\",\n          \"label\": \"result\",\n          \"description\": \"result\",\n          \"canEdit\": true,\n          \"editField\": {\n            \"key\": true,\n            \"name\": true,\n            \"description\": true,\n            \"dataType\": true\n          }\n        }\n      ]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Starting FastGPT Docker Containers\nDESCRIPTION: Command to start the FastGPT Docker containers using Docker Compose.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/docker.md#2025-04-10_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for BGE-Rerank Model\nDESCRIPTION: Docker Compose YAML configuration for deploying a BGE-Rerank model. It includes GPU support configuration, port mapping, and environment variable for access token authentication.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/bge-rerank.md#2025-04-10_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nversion: \"3\"\nservices:\n  reranker:\n    image: registry.cn-hangzhou.aliyuncs.com/fastgpt/bge-rerank-base:v0.1\n    container_name: reranker\n    # GPU运行环境，如果宿主机未安装，将deploy配置隐藏即可\n    deploy:\n      resources:\n        reservations:\n          devices:\n          - driver: nvidia\n            count: all\n            capabilities: [gpu]\n    ports:\n      - 6006:6006\n    environment:\n      - ACCESS_TOKEN=mytoken\n```\n\n----------------------------------------\n\nTITLE: Using curl to Parse PDF with PDF-Mistral Plugin\nDESCRIPTION: This bash command demonstrates how to use curl to send a PDF file to the PDF-Mistral plugin API for parsing.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mistral/README.md#2025-04-10_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST -F \"file=@path/to/your/document.pdf\" http://localhost:7231/v1/parse/file\n```\n\n----------------------------------------\n\nTITLE: Implementing Google Search API with Laf in TypeScript\nDESCRIPTION: This code snippet demonstrates how to create a Google Search API integration using Laf. The function accepts a search query, calls the Google Custom Search API, and returns the snippets from search results as a prompt for FastGPT to use.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/google_search.md#2025-04-10_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport cloud from '@lafjs/cloud'\n\nconst googleSearchKey = \"xxx\"\nconst googleCxId = \"3740cxxx\"\nconst baseurl = \"https://www.googleapis.com/customsearch/v1\"\n\ntype RequestType = {\n  searchKey: string\n}\n\nexport default async function (ctx: FunctionContext) {\n  const { searchKey } = ctx.body as RequestType\n  console.log(ctx.body)\n  if (!searchKey) {\n    return {\n      prompt: \"\"\n    }\n  }\n\n  try {\n    const { data } = await cloud.fetch.get(baseurl, {\n      params: {\n        q: searchKey,\n        cx: googleCxId,\n        key: googleSearchKey,\n        c2coff: 1,\n        start: 1,\n        end: 20,\n        dateRestrict: 'm[1]',\n      }\n    })\n    const result = data.items.map((item) => item.snippet).join('\\n');\n\n    return { prompt: result }\n  } catch (err) {\n    console.log(err)\n    ctx.response.status(500)\n    return {\n      message: \"异常\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating FastGPT Version\nDESCRIPTION: Commands to update the FastGPT version by pulling new Docker images and restarting containers.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/docker.md#2025-04-10_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose pull\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Configuring Chat History and User Input in JSON\nDESCRIPTION: This snippet defines input parameters for chat history and user input in an AI module. It specifies rendering types, value types, and labels for each input field.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/google_search.md#2025-04-10_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"key\": \"history\",\n  \"renderTypeList\": [\n    \"numberInput\",\n    \"reference\"\n  ],\n  \"valueType\": \"chatHistory\",\n  \"label\": \"core.module.input.label.chat history\",\n  \"required\": true,\n  \"min\": 0,\n  \"max\": 30,\n  \"value\": 6\n},\n{\n  \"key\": \"userChatInput\",\n  \"renderTypeList\": [\n    \"reference\",\n    \"textarea\"\n  ],\n  \"valueType\": \"string\",\n  \"label\": \"用户问题\",\n  \"required\": true,\n  \"toolDescription\": \"用户问题\",\n  \"value\": [\n    \"448745\",\n    \"userChatInput\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Output Parameters for AI Chat Module in JSON\nDESCRIPTION: This snippet specifies the output parameters for an AI chat module, including new context history and AI response content. It defines the value types and descriptions for each output.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/google_search.md#2025-04-10_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n\"outputs\": [\n  {\n    \"id\": \"history\",\n    \"key\": \"history\",\n    \"label\": \"core.module.output.label.New context\",\n    \"description\": \"core.module.output.description.New context\",\n    \"valueType\": \"chatHistory\",\n    \"type\": \"static\"\n  },\n  {\n    \"id\": \"answerText\",\n    \"key\": \"answerText\",\n    \"label\": \"core.module.output.label.Ai response content\",\n    \"description\": \"core.module.output.description.Ai response content\",\n    \"valueType\": \"string\",\n    \"type\": \"static\"\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Deleting a Knowledge Base in FastGPT\nDESCRIPTION: API request to delete a knowledge base using its ID. Requires authentication with an API key.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request DELETE 'http://localhost:3000/api/core/dataset/delete?id=65abc8729d1448617cba5df6' \\\n--header 'Authorization: Bearer {{authorization}}' \\\n```\n\n----------------------------------------\n\nTITLE: Configuring FastGPT Workflow for Feishu Webhook Integration\nDESCRIPTION: This JSON configuration defines a FastGPT workflow that integrates with Feishu webhooks. It includes nodes for user input, AI model interaction, HTTP requests to Feishu, and response handling. The workflow is designed to send notifications to Feishu and manage the tool calling process.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/feishu_webhook.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"nodes\": [\n    {\n      \"nodeId\": \"userGuide\",\n      \"name\": \"系统配置\",\n      \"intro\": \"可以配置应用的系统参数\",\n      \"avatar\": \"/imgs/workflow/userGuide.png\",\n      \"flowNodeType\": \"userGuide\",\n      \"position\": {\n        \"x\": 303.41163758039283,\n        \"y\": -552.297639861266\n      },\n      \"version\": \"481\",\n      \"inputs\": [],\n      \"outputs\": []\n    },\n    {\n      \"nodeId\": \"workflowStartNodeId\",\n      \"name\": \"流程开始\",\n      \"intro\": \"\",\n      \"avatar\": \"/imgs/workflow/userChatInput.svg\",\n      \"flowNodeType\": \"workflowStart\",\n      \"position\": {\n        \"x\": 529.3935295017156,\n        \"y\": 197.114018410347\n      },\n      \"version\": \"481\",\n      \"inputs\": [\n        {\n          \"key\": \"userChatInput\",\n          \"renderTypeList\": [\n            \"reference\",\n            \"textarea\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"用户问题\",\n          \"required\": true,\n          \"toolDescription\": \"用户问题\"\n        }\n      ],\n      \"outputs\": [\n        {\n          \"id\": \"userChatInput\",\n          \"key\": \"userChatInput\",\n          \"label\": \"core.module.input.label.user question\",\n          \"valueType\": \"string\",\n          \"type\": \"static\"\n        }\n      ]\n    },\n    {\n      \"nodeId\": \"u6IAOEssxoZT\",\n      \"name\": \"工具调用\",\n      \"intro\": \"通过AI模型自动选择一个或多个功能块进行调用，也可以对插件进行调用。\",\n      \"avatar\": \"/imgs/workflow/tool.svg\",\n      \"flowNodeType\": \"tools\",\n      \"showStatus\": true,\n      \"position\": {\n        \"x\": 1003.146243538873,\n        \"y\": 48.52327869406625\n      },\n      \"version\": \"481\",\n      \"inputs\": [\n        {\n          \"key\": \"model\",\n          \"renderTypeList\": [\n            \"settingLLMModel\",\n            \"reference\"\n          ],\n          \"label\": \"core.module.input.label.aiModel\",\n          \"valueType\": \"string\",\n          \"llmModelType\": \"all\",\n          \"value\": \"gpt-3.5-turbo\"\n        },\n        {\n          \"key\": \"temperature\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"value\": 0,\n          \"valueType\": \"number\",\n          \"min\": 0,\n          \"max\": 10,\n          \"step\": 1\n        },\n        {\n          \"key\": \"maxToken\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"label\": \"\",\n          \"value\": 2000,\n          \"valueType\": \"number\",\n          \"min\": 100,\n          \"max\": 4000,\n          \"step\": 50\n        },\n        {\n          \"key\": \"systemPrompt\",\n          \"renderTypeList\": [\n            \"textarea\",\n            \"reference\"\n          ],\n          \"max\": 3000,\n          \"valueType\": \"string\",\n          \"label\": \"core.ai.Prompt\",\n          \"description\": \"core.app.tip.chatNodeSystemPromptTip\",\n          \"placeholder\": \"core.app.tip.chatNodeSystemPromptTip\"\n        },\n        {\n          \"key\": \"history\",\n          \"renderTypeList\": [\n            \"numberInput\",\n            \"reference\"\n          ],\n          \"valueType\": \"chatHistory\",\n          \"label\": \"core.module.input.label.chat history\",\n          \"description\": \"最多携带多少轮对话记录\",\n          \"required\": true,\n          \"min\": 0,\n          \"max\": 50,\n          \"value\": 6\n        },\n        {\n          \"key\": \"userChatInput\",\n          \"renderTypeList\": [\n            \"reference\",\n            \"textarea\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"用户问题\",\n          \"required\": true,\n          \"value\": [\n            \"workflowStartNodeId\",\n            \"userChatInput\"\n          ]\n        }\n      ],\n      \"outputs\": [\n        {\n          \"id\": \"answerText\",\n          \"key\": \"answerText\",\n          \"label\": \"core.module.output.label.Ai response content\",\n          \"description\": \"core.module.output.description.Ai response content\",\n          \"valueType\": \"string\",\n          \"type\": \"static\"\n        }\n      ]\n    },\n    {\n      \"nodeId\": \"fvY5hb0K646V\",\n      \"name\": \"工具调用终止\",\n      \"intro\": \"该模块需配置工具调用使用。当该模块被执行时，本次工具调用将会强制结束，并且不再调用AI针对工具调用结果回答问题。\",\n      \"avatar\": \"/imgs/workflow/toolStop.svg\",\n      \"flowNodeType\": \"stopTool\",\n      \"position\": {\n        \"x\": 2367.838362362707,\n        \"y\": 732.355988936165\n      },\n      \"version\": \"481\",\n      \"inputs\": [],\n      \"outputs\": []\n    },\n    {\n      \"nodeId\": \"x9rN2a4WnZmt\",\n      \"name\": \"HTTP 请求\",\n      \"intro\": \"向飞书发送一个webhooks通知信息。\",\n      \"avatar\": \"/imgs/workflow/http.png\",\n      \"flowNodeType\": \"httpRequest468\",\n      \"showStatus\": true,\n      \"position\": {\n        \"x\": 1623.9214305901633,\n        \"y\": 22.777089001645862\n      },\n      \"version\": \"486\",\n      \"inputs\": [\n        {\n          \"key\": \"system_addInputParam\",\n          \"renderTypeList\": [\n            \"addInputParam\"\n          ],\n          \"valueType\": \"dynamic\",\n          \"label\": \"\",\n          \"required\": false,\n          \"description\": \"core.module.input.description.HTTP Dynamic Input\",\n          \"editField\": {\n            \"key\": true,\n            \"valueType\": true\n          }\n        },\n        {\n          \"valueType\": \"string\",\n          \"renderTypeList\": [\n            \"reference\"\n          ],\n          \"key\": \"text\",\n          \"label\": \"text\",\n          \"toolDescription\": \"发送的消息\",\n          \"required\": true,\n          \"canEdit\": true,\n          \"editField\": {\n            \"key\": true,\n            \"description\": true\n          }\n        },\n        {\n          \"key\": \"system_httpMethod\",\n          \"renderTypeList\": [\n            \"custom\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"\",\n          \"value\": \"POST\",\n          \"required\": true\n        },\n        {\n          \"key\": \"system_httpReqUrl\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"string\",\n          \"label\": \"\",\n          \"description\": \"core.module.input.description.Http Request Url\",\n          \"placeholder\": \"https://api.ai.com/getInventory\",\n          \"required\": false,\n          \"value\": \"\"\n        },\n        {\n          \"key\": \"system_httpHeader\",\n          \"renderTypeList\": [\n            \"custom\"\n          ],\n          \"valueType\": \"any\",\n          \"value\": [],\n          \"label\": \"\",\n          \"description\": \"core.module.input.description.Http Request Header\",\n          \"placeholder\": \"core.module.input.description.Http Request Header\",\n          \"required\": false\n        },\n        {\n          \"key\": \"system_httpParams\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"value\": [],\n          \"label\": \"\",\n          \"required\": false\n        },\n        {\n          \"key\": \"system_httpJsonBody\",\n          \"renderTypeList\": [\n            \"hidden\"\n          ],\n          \"valueType\": \"any\",\n          \"value\": \"{\\r\\n    \\\"msg_type\\\": \\\"text\\\",\\r\\n    \\\"content\\\": {\\r\\n        \\\"text\\\": \\\"{{text}}\\\"\\r\\n    }\\r\\n}\",\n          \"label\": \"\",\n          \"required\": false\n        }\n      ],\n      \"outputs\": [\n        {\n          \"id\": \"system_addOutputParam\",\n          \"key\": \"system_addOutputParam\",\n          \"type\": \"dynamic\",\n          \"valueType\": \"dynamic\",\n          \"label\": \"\",\n          \"editField\": {\n            \"key\": true,\n            \"valueType\": true\n          }\n        },\n        {\n          \"id\": \"error\",\n          \"key\": \"error\",\n          \"label\": \"请求错误\",\n          \"description\": \"HTTP请求错误信息，成功时返回空\",\n          \"valueType\": \"object\",\n          \"type\": \"static\"\n        },\n        {\n          \"id\": \"httpRawResponse\",\n          \"key\": \"httpRawResponse\",\n          \"label\": \"原始响应\",\n          \"required\": true,\n          \"description\": \"HTTP请求的原始响应。只能接受字符串或JSON类型响应数据。\",\n          \"valueType\": \"any\",\n          \"type\": \"static\"\n        }\n      ]\n    },\n    {\n      \"nodeId\": \"aGHGqH2oUupj\",\n      \"name\": \"指定回复\",\n      \"intro\": \"该模块可以直接回复一段指定的内容。常用于引导、提示。非字符串内容传入时，会转成字符串进行输出。\",\n      \"avatar\": \"/imgs/workflow/reply.png\",\n      \"flowNodeType\": \"answerNode\",\n      \"position\": {\n        \"x\": 2350.7077940158674,\n        \"y\": 107.32448732713493\n      },\n      \"version\": \"481\",\n      \"inputs\": [\n        {\n          \"key\": \"text\",\n          \"renderTypeList\": [\n            \"textarea\",\n            \"reference\"\n          ],\n          \"valueType\": \"any\",\n          \"required\": true,\n          \"label\": \"core.module.input.label.Response content\",\n          \"description\": \"core.module.input.description.Response content\",\n          \"placeholder\": \"core.module.input.description.Response content\",\n          \"value\": \"嘻嘻，发送成功\"\n        }\n      ],\n      \"outputs\": []\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"workflowStartNodeId\",\n      \"target\": \"u6IAOEssxoZT\",\n      \"sourceHandle\": \"workflowStartNodeId-source-right\",\n      \"targetHandle\": \"u6IAOEssxoZT-target-left\"\n    },\n    {\n      \"source\": \"u6IAOEssxoZT\",\n      \"target\": \"x9rN2a4WnZmt\",\n      \"sourceHandle\": \"selectedTools\",\n      \"targetHandle\": \"selectedTools\"\n    },\n    {\n      \"source\": \"x9rN2a4WnZmt\",\n      \"target\": \"fvY5hb0K646V\",\n      \"sourceHandle\": \"x9rN2a4WnZmt-source-right\",\n      \"targetHandle\": \"fvY5hb0K646V-target-left\"\n    },\n    {\n      \"source\": \"x9rN2a4WnZmt\",\n      \"target\": \"aGHGqH2oUupj\",\n      \"sourceHandle\": \"x9rN2a4WnZmt-source-right\",\n      \"targetHandle\": \"aGHGqH2oUupj-target-left\"\n    }\n  ],\n  \"chatConfig\": {\n    \"variables\": [\n      {\n        \"id\": \"txq1ca\",\n        \"key\": \"test\",\n        \"label\": \"测试\",\n        \"type\": \"custom\",\n        \"required\": true,\n        \"maxLen\": 50,\n        \"enums\": [\n          {\n            \"value\": \"\"\n          }\n        ]\n      }\n    ],\n    \"questionGuide\": false,\n    \"scheduledTriggerConfig\": {\n      \"cronString\": \"\",\n      \"timezone\": \"Asia/Shanghai\",\n      \"defaultPrompt\": \"\"\n    },\n    \"_id\": \"66715d4bf577287d39e35ecf\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies Declaration\nDESCRIPTION: Specifies the required Python packages and their versions for the FastGPT project. Includes FastAPI framework, transformers with sentencepiece, FlagEmbedding, Pydantic for data validation, Uvicorn ASGI server, and utility packages.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/rerank-bge/bge-reranker-v2-m3/requirements.txt#2025-04-10_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nfastapi==0.104.1\ntransformers[sentencepiece]\nFlagEmbedding==1.2.8\npydantic==1.10.13\nuvicorn==0.17.6\nitsdangerous\nprotobuf\n```\n\n----------------------------------------\n\nTITLE: Formatting Source Text Chunks for Translation\nDESCRIPTION: This JavaScript function formats source text chunks by adding XML-like tags around the current chunk to be translated. It returns the tagged text and the specific chunk to be translated.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/translate-subtitle-using-gpt.md#2025-04-10_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nfunction main({source_text_chunks, i=0}){\n    let before = source_text_chunks.slice(0, i).join(\"\");\n    let current = \" <TRANSLATE_THIS>\" + source_text_chunks[i] + \"</TRANSLATE_THIS>\";\n    let after = source_text_chunks.slice(i + 1).join(\"\");\n    let tagged_text = before + current + after;\n\n    return {\n        tagged_text,\n        chunk_to_translate: source_text_chunks[i],\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring FastGPT for Custom PDF Parsing with Marker\nDESCRIPTION: JSON configuration to be added to FastGPT's config.json file. This setup enables custom PDF parsing using Marker, including specifying the service URL, keys, and pricing.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/marker.md#2025-04-10_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  xxx\n  \"systemEnv\": {\n    xxx\n    \"customPdfParse\": {\n      \"url\": \"http://xxxx.com/v2/parse/file\", // 自定义 PDF 解析服务地址 marker v0.2\n      \"key\": \"\", // 自定义 PDF 解析服务密钥\n      \"doc2xKey\": \"\", // doc2x 服务密钥\n      \"price\": 0 // PDF 解析服务价格\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for WeChat Assistant Deployment\nDESCRIPTION: Environment variables needed for deploying the WeChat/Enterprise WeChat assistant service on Sealos. These include the AIBOTK_KEY and AIBOTK_SECRET from the WeChat Secretary service, and WORK_PRO_TOKEN for Enterprise WeChat integration.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/external-integration/wechat.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nAIBOTK_KEY=微秘书 APIKEY   \nAIBOTK_SECRET=微秘书 APISECRET   \nWORK_PRO_TOKEN=你申请的企微 token   （企业微信需要填写，私人微信不需要）\n```\n\n----------------------------------------\n\nTITLE: Configuring FastGPT Environment Variables for SiliconCloud\nDESCRIPTION: Environment variables needed to connect FastGPT to SiliconCloud. The configuration points to SiliconCloud's API endpoint and requires an API key from the SiliconCloud console.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/modelConfig/siliconCloud.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_BASE_URL=https://api.siliconflow.cn/v1\n# 填写 SiliconCloud 控制台提供的 Api Key\nCHAT_API_KEY=sk-xxxxxx\n```\n\n----------------------------------------\n\nTITLE: Configuring MongoDB Docker Container with Replica Set\nDESCRIPTION: Docker compose configuration for MongoDB 5.0.18 with replica set initialization and authentication setup. Includes environment variables, volume mounts, and startup scripts.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/468.md#2025-04-10_snippet_0\n\nLANGUAGE: yml\nCODE:\n```\nmongo:\n    image: mongo:5.0.18\n    # image: registry.cn-hangzhou.aliyuncs.com/fastgpt/mongo:5.0.18 # 阿里云\n    container_name: mongo\n    ports:\n      - 27017:27017\n    networks:\n      - fastgpt\n    command: mongod --keyFile /data/mongodb.key --replSet rs0\n    environment:\n      # 这里密码注意要和以前的一致\n      - MONGO_INITDB_ROOT_USERNAME=username\n      - MONGO_INITDB_ROOT_PASSWORD=password\n    volumes:\n      - ./mongo/data:/data/db\n    entrypoint:\n      - bash\n      - -c\n      - |\n        openssl rand -base64 128 > /data/mongodb.key\n        chmod 400 /data/mongodb.key\n        chown 999:999 /data/mongodb.key\n        echo 'const isInited = rs.status().ok === 1\n        if(!isInited){\n          rs.initiate({\n              _id: \"rs0\",\n              members: [\n                  { _id: 0, host: \"mongo:27017\" }\n              ]\n          })\n        }' > /data/initReplicaSet.js\n        # 启动MongoDB服务\n        exec docker-entrypoint.sh \"$@\" &\n\n        # 等待MongoDB服务启动\n        until mongo -u myusername -p mypassword --authenticationDatabase admin --eval \"print('waited for connection')\" > /dev/null 2>&1; do\n          echo \"Waiting for MongoDB to start...\"\n          sleep 2\n        done\n\n        # 执行初始化副本集的脚本\n        mongo -u myusername -p mypassword --authenticationDatabase admin /data/initReplicaSet.js\n\n        # 等待docker-entrypoint.sh脚本执行的MongoDB服务进程\n        wait $!\n```\n\n----------------------------------------\n\nTITLE: Creating Laf Cloud Function with TypeScript Interfaces for FastGPT\nDESCRIPTION: This code snippet demonstrates how to create a Laf cloud function with TypeScript interfaces for use with FastGPT. It defines the request body structure, system parameters, and response interface. The function logs the input data and returns a simple response.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/workbench/workflow/laf.md#2025-04-10_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport cloud from '@lafjs/cloud'\n\ninterface IRequestBody { // 自定义入参，FastGPT 传入的均为POST请求。\n  data1: string    // 必填参数\n  data2?: string    // 可选参数\n}\n\ninterface RequestProps extends IRequestBody { // 完整入参，这个无需改动。\n  systemParams: { // 这是FastGPT默认会传递过来的参数\n    appId: string,\n    variables: string,\n    histories: string,\n    cTime: string,\n    chatId: string,\n    responseChatItemId: string\n  }\n}\n\ninterface IResponse { // 响应内容\n  message: string // 必返回的参数\n  msg?: string; // 可选的返回参数\n}\n\nexport default async function (ctx: FunctionContext): Promise<IResponse> {  \n  const {\n    data1,\n    data2,\n    systemParams\n  }: RequestProps = ctx.body;\n  \n  console.log({\n    data1,\n    data2,\n    systemParams\n  });\n\n  return { \n    message: 'ok',\n    msg: 'msg'\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing FastGPT V4.6 - First Step\nDESCRIPTION: This cURL command sends a POST request to initialize FastGPT V4.6. It requires the rootkey for authentication and may take some time to complete. Ensure this step is successful before proceeding to the next initialization step.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/46.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv46' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: 使用延迟功能的JavaScript代码\nDESCRIPTION: 演示如何在FastGPT代码运行节点中使用内置的delay函数实现异步延迟。这段代码等待1秒后返回一个包含result键的对象。\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/workbench/workflow/sandbox.md#2025-04-10_snippet_1\n\nLANGUAGE: js\nCODE:\n```\nasync function main({data1, data2}){\n    await delay(1000)\n    return {\n        result: \"111\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies Definition\nDESCRIPTION: Lists required Python packages with specific version constraints. Includes web framework FastAPI, ASGI server Uvicorn, MistralAI SDK, PDF processing library PyMuPDF, and various utility packages for environment variables, logging, and HTTP requests.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mistral/requirements.txt#2025-04-10_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nfastapi==0.115.5\nuvicorn==0.32.1\nmistralai>=1.5.0\nPyMuPDF==1.24.14\npython-multipart==0.0.18\npython-dotenv==1.0.1\nloguru==0.7.2\nrequests==2.32.3\n```\n\n----------------------------------------\n\nTITLE: 使用strToBase64转换字符串的JavaScript代码\nDESCRIPTION: 演示如何使用FastGPT 4.8.11版本新增的strToBase64函数将字符串(如SVG图片)转换为base64格式。函数接受原始字符串和可选的base64前缀作为参数。\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/workbench/workflow/sandbox.md#2025-04-10_snippet_3\n\nLANGUAGE: js\nCODE:\n```\nfunction main({input}){\n     \n    return {\n        /* \n            param1: input 需要转换的字符串\n            param2: base64 prefix 前缀\n        */\n        result: strToBase64(input,'data:image/svg+xml;base64,')\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for HTTP Proxy in FastGPT\nDESCRIPTION: These environment variables configure FastGPT to use an HTTP proxy for API requests. AXIOS_PROXY_HOST specifies the proxy server address, while AXIOS_PROXY_PORT defines the port number.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/proxy/http_proxy.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nAXIOS_PROXY_HOST=\nAXIOS_PROXY_PORT=\n```\n\n----------------------------------------\n\nTITLE: Executing Initialization API Call for FastGPT V4.4.1 Upgrade\nDESCRIPTION: This cURL command sends a POST request to initialize the FastGPT system for version 4.4.1. It requires the rootkey from environment variables to be included in the request headers. The API call initializes the Mongo dataset.files, setting all data as available.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/441.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv441' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Executing API Initialization for FastGPT V4.4.2 Upgrade\nDESCRIPTION: This cURL command sends a POST request to initialize the API for FastGPT V4.4.2 upgrade. It requires the rootkey from environment variables in the header for authentication. The request initializes the MongoDB Bill table index, correcting a previous issue with expiration times.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/442.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv442' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: 使用countToken统计token的JavaScript代码\nDESCRIPTION: 展示如何使用FastGPT代码运行节点中的内置countToken函数来统计输入文本的token数量，并将结果作为返回对象的result值。\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/workbench/workflow/sandbox.md#2025-04-10_snippet_2\n\nLANGUAGE: js\nCODE:\n```\nfunction main({input}){\n    return {\n        result: countToken(input)\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Link Collection Creation Response in FastGPT\nDESCRIPTION: JSON response for a successful link-based collection creation. Returns the collection ID and processing results including the number of inserted chunks.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_15\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"code\": 200,\n    \"statusText\": \"\",\n    \"message\": \"\",\n    \"data\": {\n        \"collectionId\": \"65abd0ad9d1448617cba6031\",\n        \"results\": {\n            \"insertLen\": 1,\n            \"overToken\": [],\n            \"repeat\": [],\n            \"error\": []\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Embedding FastGPT Content Using iframe in HTML\nDESCRIPTION: A basic HTML iframe implementation for embedding FastGPT content into other websites or applications. The iframe tag provides a way to include FastGPT within another webpage.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/external-integration/iframe_integration.md#2025-04-10_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe src=\"YOUR_FASTGPT_URL\" frameborder=\"0\" width=\"100%\" height=\"600px\"></iframe>\n```\n\n----------------------------------------\n\nTITLE: Composing AI Dialogue Messages in JSON Format\nDESCRIPTION: This code snippet demonstrates the structure of messages passed to the AI model in FastGPT. It shows the order of different components including built-in prompts, system prompts, conversation history, and the user's question combined with reference prompts and templates.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/course/ai_settings.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n[\n    内置提示词（config.json 配置，一般为空）\n    系统提示词 （用户输入的提示词）\n    历史记录\n    问题（由引用提示词、引用模板和用户问题组成）\n]\n```\n\n----------------------------------------\n\nTITLE: Running FastGPT Upgrade Script\nDESCRIPTION: Bash command for executing the FastGPT v4.9.0 upgrade script via a POST request. Requires replacing placeholders with actual values for rootkey and host.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/490.md#2025-04-10_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv490' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Executing FastGPT v4.9.1 Upgrade Script using cURL\nDESCRIPTION: HTTP POST request to initiate the v4.9.1 upgrade process. Requires replacing {{rootkey}} with environment variable rootkey and {{host}} with FastGPT domain. The script updates Jieba word segmentation library.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/491.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv491' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: 对话引导问题API响应格式\nDESCRIPTION: API返回的问题引导数据结构。响应包含状态码与data数组，该数组最多包含5个与搜索关键字匹配的预设问题。\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/course/chat_input_guide.md#2025-04-10_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"code\": 200,\n  \"statusText\": \"\",\n  \"message\": \"\",\n  \"data\": [\n    \"是你\",\n    \"你是谁呀\",\n    \"你好好呀\",\n    \"你好呀\",\n    \"你是谁！\",\n    \"你好\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting SANDBOX_URL Environment Variable for FastGPT\nDESCRIPTION: Configuration for FastGPT environment variable that points to the internal network address of the sandbox application. This setup is required when upgrading to FastGPT V4.8.2.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/482.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSANDBOX_URL=内网地址\n```\n\n----------------------------------------\n\nTITLE: 查询对话引导问题的API请求示例\nDESCRIPTION: 使用curl发送GET请求获取问题引导列表。此API请求包含appId参数（应用ID）和searchKey参数（搜索关键字），用于动态查询预设的引导问题。\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/course/chat_input_guide.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request GET 'http://localhost:3000/api/core/chat/inputGuide/query?appId=663c75302caf8315b1c00194&searchKey=你'\n```\n\n----------------------------------------\n\nTITLE: Downloading FastGPT Configuration Files on Linux\nDESCRIPTION: Bash commands to create a directory for FastGPT, download the configuration file and Docker Compose file for different vector database versions.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/docker.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir fastgpt\ncd fastgpt\ncurl -O https://raw.githubusercontent.com/labring/FastGPT/main/projects/app/data/config.json\n\n# pgvector 版本(测试推荐，简单快捷)\ncurl -o docker-compose.yml https://raw.githubusercontent.com/labring/FastGPT/main/deploy/docker/docker-compose-pgvector.yml\n# milvus 版本\n# curl -o docker-compose.yml https://raw.githubusercontent.com/labring/FastGPT/main/deploy/docker/docker-compose-milvus.yml\n# zilliz 版本\n# curl -o docker-compose.yml https://raw.githubusercontent.com/labring/FastGPT/main/deploy/docker/docker-compose-zilliz.yml\n```\n\n----------------------------------------\n\nTITLE: Running the V4.8.17 Upgrade Script with cURL\nDESCRIPTION: This bash command executes the upgrade script for FastGPT V4.8.17 via HTTP request. The script moves user-linked OpenAI accounts to their teams. Replace {{rootkey}} with your environment's rootkey value and {{host}} with your FastGPT domain.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/4817.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv4817' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Executing FastGPT V4.8.18 Upgrade Script via cURL\nDESCRIPTION: This cURL command sends a POST request to initiate the FastGPT v4.8.18 upgrade process. It requires the FastGPT domain and root key to be replaced in the URL and headers respectively. The script migrates the full-text search table, which may take some time and temporarily disable full-text search functionality.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/4818.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv4818' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: OAuth2.0 Standard Configuration\nDESCRIPTION: Configuration example for standard OAuth2.0 integration with FastGPT SSO service.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/admin/sso.md#2025-04-10_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nfastgpt-sso:\n   image: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-sso-service:v4.9.0\n   container_name: fastgpt-sso\n   restart: always\n   networks:\n      - fastgpt\n   environment:\n      - AUTH_TOKEN=xxxxx\n      - SSO_PROVIDER=oauth2\n      - OAUTH2_AUTHORIZE_URL=\n      - OAUTH2_TOKEN_URL=\n      - OAUTH2_USER_INFO_URL=\n      - OAUTH2_USERNAME_MAP=\n      - OAUTH2_AVATAR_MAP=\n      - OAUTH2_MEMBER_NAME_MAP=\n      - OAUTH2_CONTACT_MAP=\n```\n\n----------------------------------------\n\nTITLE: Setting FastGPT Environment Variables for Local Proxy\nDESCRIPTION: These environment variables configure FastGPT to use a local HTTP proxy running on port 7890. This setup is typically used in conjunction with the Clash configuration provided earlier.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/proxy/http_proxy.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nAXIOS_PROXY_HOST=127.0.0.1\nAXIOS_PROXY_PORT=7890\n```\n\n----------------------------------------\n\nTITLE: WeChat Work SSO Service Configuration\nDESCRIPTION: Complete configuration example for setting up WeChat Work (WeCom) SSO integration.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/admin/sso.md#2025-04-10_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nfastgpt-sso:\n   image: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-sso-service:v4.9.0\n   container_name: fastgpt-sso\n   restart: always\n   networks:\n      - fastgpt\n   environment:\n      - AUTH_TOKEN=xxxxx\n      - SSO_PROVIDER=wecom\n      - WECOM_TARGET_URL_OAUTH=https://open.weixin.qq.com/connect/oauth2/authorize\n      - WECOM_TARGET_URL_SSO=https://login.work.weixin.qq.com/wwlogin/sso/login\n      - WECOM_GET_USER_ID_URL=https://qyapi.weixin.qq.com/cgi-bin/auth/getuserinfo\n      - WECOM_GET_USER_INFO_URL=https://qyapi.weixin.qq.com/cgi-bin/auth/getuserdetail\n      - WECOM_GET_USER_NAME_URL=https://qyapi.weixin.qq.com/cgi-bin/user/get\n      - WECOM_GET_DEPARTMENT_LIST_URL=https://qyapi.weixin.qq.com/cgi-bin/department/list\n      - WECOM_GET_USER_LIST_URL=https://qyapi.weixin.qq.com/cgi-bin/user/list_id\n      - WECOM_CORPID=\n      - WECOM_AGENTID=\n      - WECOM_APP_SECRET=\n      - WECOM_SYNC_SECRET=\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for FastGPT\nDESCRIPTION: This snippet lists the required Python packages and their specific versions for the FastGPT project. It includes surya-ocr for OCR functionality, FastAPI for building the web API, and uvicorn as the ASGI server.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/ocr-surya/requirements.txt#2025-04-10_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nsurya-ocr==0.5.0\nfastapi==0.104.1\nuvicorn==0.17.6\n```\n\n----------------------------------------\n\nTITLE: Initializing FastGPT V4.8.1 via HTTP Request\nDESCRIPTION: This bash script sends an HTTP POST request to initialize FastGPT V4.8.1. It requires the rootkey from environment variables and the FastGPT domain. The script resets table names and should be run when the dataset.trainings table is empty to avoid data conflicts.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/481.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv481' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Feishu SSO Service Configuration\nDESCRIPTION: Complete configuration example for setting up Feishu SSO integration with FastGPT.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/admin/sso.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nfastgpt-sso:\n    image: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-sso-service:v4.9.0\n    container_name: fastgpt-sso\n    restart: always\n    networks:\n      - fastgpt\n    environment:\n      - SSO_PROVIDER=example\n      - AUTH_TOKEN=xxxxx\n      - SSO_PROVIDER=feishu\n      - SSO_TARGET_URL=https://accounts.feishu.cn/open-apis/authen/v1/authorize\n      - FEISHU_TOKEN_URL=https://open.feishu.cn/open-apis/authen/v2/oauth/token\n      - FEISHU_GET_USER_INFO_URL=https://open.feishu.cn/open-apis/authen/v1/user_info\n      - FEISHU_REDIRECT_URI=xxx\n      - FEISHU_APP_ID=xxx\n      - FEISHU_APP_SECRET=xxx\n```\n\n----------------------------------------\n\nTITLE: Running Docker-Compose Updates for FastGPT\nDESCRIPTION: Commands for updating FastGPT using Docker-Compose. This snippet shows how to pull the latest images and restart the containers after updating the image tags in the docker-compose.yml file.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/intro.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose pull\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: FastGPT Pro Environment Configuration\nDESCRIPTION: Environment variable configuration for FastGPT Pro to connect with the SSO service.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/admin/sso.md#2025-04-10_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nenv:\n   - EXTERNAL_USER_SYSTEM_BASE_URL=http://fastgpt-sso:3000\n   - EXTERNAL_USER_SYSTEM_AUTH_TOKEN=xxxxx\n```\n\n----------------------------------------\n\nTITLE: Configuration field update for OpenAI tools mode\nDESCRIPTION: Configuration change replacing 'functionCall' field with 'toolChoice'. Models with toolChoice set to true will use OpenAI's tools mode, while false or unset will use prompt generation mode. Also adds new 'ReRankModels' array field.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/465.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"toolChoice\": true,\n  \"ReRankModels\": []\n}\n```\n\n----------------------------------------\n\nTITLE: Fixing FastGPT V4.6 Data Import Issue\nDESCRIPTION: This cURL command sends a POST request to fix a data import issue in FastGPT V4.6. It addresses a problem where imported knowledge base data was not displaying correctly due to a missing field.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/46.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv46-fix' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Initializing Fields in MongoDB Collections for FastGPT V4\nDESCRIPTION: MongoDB commands to update the 'chats', 'collections', and 'outlinks' collections. These commands add missing fields and update existing ones to match the new schema required for FastGPT V4.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/40.md#2025-04-10_snippet_1\n\nLANGUAGE: mongodb\nCODE:\n```\ndb.chats.find({appId: {$exists: false}}).forEach(function(item){\n  db.chats.updateOne(\n    {\n      _id: item._id,\n    },\n    { \"$set\": {\"appId\":item.modelId}}\n  )\n})\n\ndb.collections.find({appId: {$exists: false}}).forEach(function(item){\n  db.collections.updateOne(\n    {\n      _id: item._id,\n    },\n    { \"$set\": {\"appId\":item.modelId}}\n  )\n})\n\ndb.outlinks.find({shareId: {$exists: false}}).forEach(function(item){\n   db.outlinks.updateOne(\n     {\n       _id: item._id,\n    },\n    { \"$set\": {\"shareId\":item._id.toString(),\"appId\":item.modelId}}\n   )\n})\n```\n\n----------------------------------------\n\nTITLE: Setting Chat API Key Environment Variable for FastGPT\nDESCRIPTION: Sets the Chat API key environment variable in FastGPT to use the token provided by OneAPI. This authenticates requests from FastGPT to OneAPI.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/modelConfig/ppio.md#2025-04-10_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nCHAT_API_KEY=sk-UyVQcpQWMU7ChTVl74B562C28e3c46Fe8f16E6D8AeF8736e\n```\n\n----------------------------------------\n\nTITLE: FastGPT Python Dependencies\nDESCRIPTION: Specifies the required Python packages and their versions for the FastGPT project. Includes FastAPI for API development, transformers with sentencepiece for NLP tasks, FlagEmbedding for embeddings, and other utility packages.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/rerank-bge/bge-reranker-large/requirements.txt#2025-04-10_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\nfastapi==0.104.1\ntransformers[sentencepiece]\nFlagEmbedding==1.2.8\npydantic==1.10.13\nuvicorn==0.17.6\nitsdangerous\nprotobuf\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for M3E Docker Image\nDESCRIPTION: Defines the environment variable for setting the security credential (channel key) in the M3E Docker image.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/m3e.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# 设置安全凭证（即oneapi中的渠道密钥）\n默认值：sk-aaabbbcccdddeeefffggghhhiiijjjkkk\n也可以通过环境变量引入：sk-key。有关docker环境变量引入的方法请自寻教程，此处不再赘述。\n```\n\n----------------------------------------\n\nTITLE: Running BGE-Rerank Python Application\nDESCRIPTION: Command to start the BGE-Rerank model service using Python. After running this command, the model service will be available at the displayed address (http://0.0.0.0:6006).\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/bge-rerank.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython app.py\n```\n\n----------------------------------------\n\nTITLE: Initializing Laf Cloud Function for Laboratory Appointment Management\nDESCRIPTION: This code snippet sets up the main function to handle different CRUD operations for laboratory appointments. It uses the Laf cloud database and defines a RequestType interface for input validation.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/lab_appointment.md#2025-04-10_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport cloud from '@lafjs/cloud'\nconst db = cloud.database()\n\ntype RequestType = {\n    name: string;\n    time?: string;\n    labname?: string;\n    action: 'post' | 'delete' | 'put' | 'get'\n}\n\nexport default async function (ctx: FunctionContext) {\n  try {\n    const {   action,...body  } = ctx.body as RequestType\n\n    if (action === 'get') {\n      return await getRecord(ctx.body)\n    }\n    if (action === 'post') {\n      return await createRecord(ctx.body)\n    }\n    if (action === 'put') {\n      return await putRecord(ctx.body)\n    }\n    if (action === 'delete') {\n      return await removeRecord(ctx.body)\n    }\n\n\n    return {\n      result: \"异常\"\n    }\n  } catch (err) {\n    return {\n      result: \"异常\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running BGE-Rerank Model with Docker\nDESCRIPTION: Docker command to run a BGE-Rerank model container with GPU support. The command specifies the access token for authentication, maps port 6006, and uses the base model from the FastGPT registry.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/bge-rerank.md#2025-04-10_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\n# auth token 为mytoken\ndocker run -d --name reranker -p 6006:6006 -e ACCESS_TOKEN=mytoken --gpus all registry.cn-hangzhou.aliyuncs.com/fastgpt/bge-rerank-base:v0.1\n```\n\n----------------------------------------\n\nTITLE: Deleting Laboratory Appointment Records in TypeScript\nDESCRIPTION: This function removes a laboratory appointment record for a given name. It checks if the name is provided and deletes the record if found.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/app-cases/lab_appointment.md#2025-04-10_snippet_4\n\nLANGUAGE: TypeScript\nCODE:\n```\nasync function removeRecord({ name }: RequestType) {\n  if (!name) {\n    return {\n      result: \"请提供你的姓名\"\n    }\n  }\n  const { deleted } = await db.collection('LabAppointment').where({ name, status: \"unStart\" }).remove()\n\n  if (deleted > 0) {\n    return {\n      result: `取消预约记录成功: ${name}`\n    }\n  }\n  return {\n    result: ` ${name} 没有预约中的记录`\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Deploying FastGPT SSO Service Docker Configuration\nDESCRIPTION: Basic docker-compose configuration for deploying the FastGPT SSO service with example environment variables.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/admin/sso.md#2025-04-10_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n  fastgpt-sso:\n    image: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-sso-service:v4.9.0\n    container_name: fastgpt-sso\n    restart: always\n    networks:\n      - fastgpt\n    environment:\n      - SSO_PROVIDER=example\n      - AUTH_TOKEN=xxxxx # Authentication token used by fastgpt-pro\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for BGE-Rerank Models\nDESCRIPTION: Command to install the required Python dependencies for BGE-Rerank models using pip package manager. This should be run after downloading the model code from the repository.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/bge-rerank.md#2025-04-10_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Launching Qwen-Chat Model via Command Line\nDESCRIPTION: Command to launch the Qwen-Chat model using Xinference's command-line tool.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/xinference.md#2025-04-10_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nxinference launch -n qwen-chat -s 14 -f pytorch\n```\n\n----------------------------------------\n\nTITLE: Installing and Running Older Version of Marker for FastGPT\nDESCRIPTION: Docker commands to install and run an older version of Marker (v0.1) for PDF parsing in FastGPT. This is applicable for FastGPT versions prior to V4.9.0.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/marker.md#2025-04-10_snippet_2\n\nLANGUAGE: dockerfile\nCODE:\n```\ndocker pull crpi-h3snc261q1dosroc.cn-hangzhou.personal.cr.aliyuncs.com/marker11/marker_images:v0.1\ndocker run --gpus all -itd -p 7231:7231 --name model_pdf_v1 -e PROCESSES_PER_GPU=\"2\" crpi-h3snc261q1dosroc.cn-hangzhou.personal.cr.aliyuncs.com/marker11/marker_images:v0.1\n```\n\n----------------------------------------\n\nTITLE: JSON结果输出示例\nDESCRIPTION: 展示代码运行节点的结果输出格式，返回一个包含result和data2键的JSON对象。自定义输出可以通过添加变量名来获取对象中对应键的值。\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/workbench/workflow/sandbox.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  result: data1,\n  data2\n}\n```\n\n----------------------------------------\n\nTITLE: Modifying Docker Compose Configuration for MongoDB\nDESCRIPTION: YAML configuration snippet to modify the Docker Compose file for MongoDB, including key file mounting and replica set initialization.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/docker.md#2025-04-10_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nmongo:\n  #  image: mongo:5.0.18\n  # image: registry.cn-hangzhou.aliyuncs.com/fastgpt/mongo:5.0.18 # 阿里云\n  container_name: mongo\n  ports:\n    - 27017:27017\n  networks:\n    - fastgpt\n  command: mongod --keyFile /data/mongodb.key --replSet rs0\n  environment:\n    # 默认的用户名和密码，只有首次允许有效\n    - MONGO_INITDB_ROOT_USERNAME=myusername\n    - MONGO_INITDB_ROOT_PASSWORD=mypassword\n  volumes:\n    - ./mongo/data:/data/db\n    - ./mongodb.key:/data/mongodb.key\n```\n\n----------------------------------------\n\nTITLE: Testing M3E Embeddings Model with cURL\nDESCRIPTION: Example of using cURL to test the M3E embeddings model API endpoint. The request sends text to be embedded and specifies the M3E model.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/chatglm2-m3e.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://domain/v1/embeddings' \\\n--header 'Authorization: Bearer sk-aaabbbcccdddeeefffggghhhiiijjjkkk' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n  \"model\": \"m3e\",\n  \"input\": [\"laf是什么\"]\n}'\n```\n\n----------------------------------------\n\nTITLE: 创建测试数组示例 (JavaScript)\nDESCRIPTION: 使用代码运行节点创建一个包含三段简短文本的测试数组，作为批量运行节点的输入数据源。这个数组将被遍历处理，每个元素会依次通过后续配置的节点进行处理。\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/workbench/workflow/loop.md#2025-04-10_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nconst texts = [\n  \"这是第一段文本\",\n  \"这是第二段文本\",\n  \"这是第三段文本\"\n];\nreturn { textArray: texts };\n```\n\n----------------------------------------\n\nTITLE: Setting Docker Environment Variables for ChatGLM2-m3e Model\nDESCRIPTION: Default security credential settings for the ChatGLM2-m3e Docker container. The security key can be set using environment variables in Docker.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/chatglm2-m3e.md#2025-04-10_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n# 设置安全凭证（即oneapi中的渠道密钥）\n默认值：sk-aaabbbcccdddeeefffggghhhiiijjjkkk\n也可以通过环境变量引入：sk-key。有关docker环境变量引入的方法请自寻教程，此处不再赘述。\n```\n\n----------------------------------------\n\nTITLE: Downloading Model Weights\nDESCRIPTION: Installs modelscope and downloads the required model weights using a Python script.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mineru/README.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install modelscope\nwget https://gcore.jsdelivr.net/gh/opendatalab/MinerU@master/scripts/download_models.py -O download_models.py\npython download_models.py\n```\n\n----------------------------------------\n\nTITLE: Installing Xinference with CTransformers\nDESCRIPTION: Commands to install Xinference and CTransformers for personal devices.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/xinference.md#2025-04-10_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install xinference\npip install ctransformers\n```\n\n----------------------------------------\n\nTITLE: Starting Xinference Local Service\nDESCRIPTION: Command to start the Xinference service locally, allowing non-local clients to access via IP address.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/xinference.md#2025-04-10_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nxinference-local -H 0.0.0.0\n```\n\n----------------------------------------\n\nTITLE: Knowledge Base Deletion Response in FastGPT\nDESCRIPTION: JSON response for a successful knowledge base deletion. The data field is null on success.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/dataset.md#2025-04-10_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"code\": 200,\n    \"statusText\": \"\",\n    \"message\": \"\",\n    \"data\": null\n}\n```\n\n----------------------------------------\n\nTITLE: Testing One API Integration with Curl\nDESCRIPTION: Curl command to test the integration of Xinference model with One API.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/xinference.md#2025-04-10_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://<oneapi_url>/v1/chat/completions' \\\n--header 'Authorization: Bearer <oneapi_token>' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n  \"model\": \"qwen-chat\",\n  \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]\n}'\n```\n\n----------------------------------------\n\nTITLE: Empty Search Response Format\nDESCRIPTION: Example of response when no search results are found\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/plugins/searxng_plugin_guide.md#2025-04-10_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n{\\n  \\\"result\\\": \\\"[]\\\"\\n  \\\"error\\\": {\\n    \\\"message\\\": \\\"No search results\\\",\\n    \\\"code\\\": 500\\n  }\\n}\n```\n\n----------------------------------------\n\nTITLE: PgVector 0.5 Upgrade SQL Commands - Docker-compose Deployment\nDESCRIPTION: SQL commands for upgrading PgVector extension and creating HNSW index in Docker-compose deployment. Includes steps for plugin upgrade, memory configuration, database reindexing, and index creation.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/45.md#2025-04-10_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- 升级插件名\nALTER EXTENSION vector UPDATE;\n-- 插件是否升级成功，成功的话，vector插件版本为 0.5.0，旧版的为 0.4.2\n\\dx\n\n-- 下面两个语句会设置 pg 在构建索引时可用的内存大小，需根据自身的数据库规格来动态配置，可配置为 1/4 的内存大小\nalter system set maintenance_work_mem = '2400MB'; \nselect pg_reload_conf();\n\n-- 重构数据库索引和排序\nREINDEX DATABASE postgres;\nALTER DATABASE postgres REFRESH COLLATION VERSION;\n\n-- 开始构建索引，该索引构建时间非常久，直接关掉终端即可，不要使用 ctrl+c 关闭\nCREATE INDEX CONCURRENTLY vector_index ON modeldata USING hnsw (vector vector_ip_ops) WITH (m = 16, ef_construction = 64);\n-- 可以再次连接数据库，输入下方命令。如果看到 \"vector_index\" hnsw (vector vector_ip_ops) WITH (m='16', ef_construction='64') 则代表构建完成（注意，后面没有 INVALID）\n\\d modeldata\n```\n\n----------------------------------------\n\nTITLE: Installing Xinference with Docker\nDESCRIPTION: Command to install and start Xinference service using Docker, enabling GPU acceleration.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/xinference.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run  -p 9997:9997 --gpus all xprobe/xinference:latest xinference-local -H 0.0.0.0\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Dependencies for FastGPT\nDESCRIPTION: This snippet lists the required Python packages and their versions for the FastGPT project. It includes FastAPI for web framework, NumPy and scikit-learn for numerical computations, sentence-transformers and transformers for NLP tasks, and other utility libraries.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/llm-ChatGLM2/requirements.txt#2025-04-10_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nfastapi==0.101.1\nnumpy==1.24.3\npydantic==1.10.7\nscikit_learn==1.2.2\nsentence_transformers==2.2.2\nsse_starlette==1.6.5\nstarlette==0.27.0\ntiktoken==0.4.0\ntorch==2.4.0\ntransformers==4.48.0\nuvicorn==0.23.2\n```\n\n----------------------------------------\n\nTITLE: Installing Xinference with Transformers and vLLM\nDESCRIPTION: Pip commands to install Xinference with Transformers and vLLM as inference engine backends.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/xinference.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install \"xinference[transformers]\"\npip install \"xinference[vllm]\"\npip install \"xinference[transformers,vllm]\" # install both\n```\n\n----------------------------------------\n\nTITLE: Additional Search Engines Configuration\nDESCRIPTION: Optional configuration for adding more search engines like DuckDuckGo and Google when deployed outside mainland China\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/plugins/searxng_plugin_guide.md#2025-04-10_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n  - name: duckduckgo\\n    engine: duckduckgo\\n    shortcut: ddg\\n\\n  - name: google\\n    engine: google\\n    shortcut: go\n```\n\n----------------------------------------\n\nTITLE: Renaming MongoDB Collections for FastGPT V4 Upgrade\nDESCRIPTION: MongoDB commands to rename the 'models' collection to 'apps' and 'sharechats' collection to 'outlinks'. These commands should be executed after deleting any existing empty tables with these names.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/40.md#2025-04-10_snippet_0\n\nLANGUAGE: mongodb\nCODE:\n```\ndb.models.renameCollection(\"apps\")\ndb.sharechats.renameCollection(\"outlinks\")\n```\n\n----------------------------------------\n\nTITLE: Testing Model Error Debugging with CURL\nDESCRIPTION: A CURL command for debugging model errors by sending a detailed request body to the OpenAI chat completions API. This is useful when troubleshooting stream mode issues.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/faq.md#2025-04-10_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://api.openai.com/v1/chat/completions' \\\n--header 'Authorization: Bearer sk-xxxx' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n  \"model\": \"xxx\",\n  \"temperature\": 0.01,\n  \"max_tokens\": 1000,\n  \"stream\": true,\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \" 你是饿\"\n    }\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Displaying Team Mode Comparison Table in Markdown\nDESCRIPTION: This markdown code snippet creates a table comparing different team modes in FastGPT. It shows how each mode handles team creation and assignment for various registration methods.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/admin/teamMode.md#2025-04-10_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<table class=\"table-hover table-striped-columns\" style=\"text-align: center;\">\n  <tr>\n    <th rowspan=\"2\">团队模式</th>\n    <th colspan=\"2\">短信/邮箱 注册</th>\n    <th colspan=\"2\">管理员直接添加</th>\n    <th colspan=\"2\">SSO 注册</th>\n  </tr>\n  <tr>\n    <th>是否创建默认团队</th>\n    <th>是否加入 Root 团队</th>\n    <th>是否创建默认团队</th>\n    <th>是否加入 Root 团队</th>\n    <th>是否创建默认团队</th>\n    <th>是否加入 Root 团队</th>\n  </tr>\n  <tr>\n    <td>单团队模式</td>\n    <td>❌</td>\n    <td>✅</td>\n    <td>❌</td>\n    <td>✅</td>\n    <td>❌</td>\n    <td>✅</td>\n  </tr>\n  <tr>\n    <td>多团队模式</td>\n    <td>✅</td>\n    <td>❌</td>\n    <td>✅</td>\n    <td>❌</td>\n    <td>✅</td>\n    <td>❌</td>\n  </tr>\n  <tr>\n    <td>同步模式</td>\n    <td>❌</td>\n    <td>❌</td>\n    <td>❌</td>\n    <td>✅</td>\n    <td>❌</td>\n    <td>✅</td>\n  </tr>\n</table>\n```\n\n----------------------------------------\n\nTITLE: Testing Embedding Model Availability with CURL\nDESCRIPTION: A CURL command example for testing the embedding functionality by sending a text sample to the OpenAI embeddings API endpoint.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/faq.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl https://api.openai.com/v1/embeddings \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"input\": \"The food was delicious and the waiter...\",\n    \"model\": \"text-embedding-ada-002\",\n    \"encoding_format\": \"float\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: Response Format for Updating User Feedback (JSON)\nDESCRIPTION: This snippet shows the expected JSON response format when updating user feedback in FastGPT. It includes a status code and optional message fields.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/openapi/chat.md#2025-04-10_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"code\": 200,\n    \"statusText\": \"\",\n    \"message\": \"\",\n    \"data\": null\n}\n```\n\n----------------------------------------\n\nTITLE: Building Docker Images for FastGPT\nDESCRIPTION: This snippet provides commands for building Docker images for FastGPT. It includes options for building with and without a proxy, using both Docker and Make commands.\nSOURCE: https://github.com/labring/FastGPT/blob/main/dev.md#2025-04-10_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\n# Docker cmd: Build image, not proxy\ndocker build -f ./projects/app/Dockerfile -t registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.8.1 . --build-arg name=app\n# Make cmd: Build image, not proxy\nmake build name=app image=registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.8.1\n\n# Docker cmd: Build image with proxy\ndocker build -f ./projects/app/Dockerfile -t registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.8.1 . --build-arg name=app --build-arg proxy=taobao\n# Make cmd: Build image with proxy\nmake build name=app image=registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.8.1 proxy=taobao\n```\n\n----------------------------------------\n\nTITLE: Testing LLM Model Availability with CURL\nDESCRIPTION: A CURL command example for testing the availability and functionality of an LLM model by sending a simple chat completion request to the OpenAI API.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/faq.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4o\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a helpful assistant.\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\n      }\n    ]\n  }'\n```\n\n----------------------------------------\n\nTITLE: Restarting MongoDB Container\nDESCRIPTION: Commands to restart the MongoDB container after configuration updates using docker-compose.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/468.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# 重启 Mongo\ndocker-compose down\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Configuring Clash for Selective Proxy Routing to OpenAI API\nDESCRIPTION: This Clash configuration example sets up a proxy specifically for api.openai.com, while allowing direct connections for other requests. It includes DNS settings, proxy group setup, and routing rules.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/proxy/http_proxy.md#2025-04-10_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nmixed-port: 7890\nallow-lan: false\nbind-address: '*'\nmode: rule\nlog-level: warning\ndns:  \n  enable: true  \n  ipv6: false  \n  nameserver:  \n    - 8.8.8.8\n    - 8.8.4.4 \n  cache-size: 400\nproxies:\n    - \nproxy-groups:\n  - { name: '♻️ 自动选择', type: url-test,  proxies: [香港V01×1.5], url: 'https://api.openai.com', interval: 3600}\nrules:\n  - 'DOMAIN-SUFFIX,api.openai.com,♻️ 自动选择'\n  - 'MATCH,DIRECT'\n```\n\n----------------------------------------\n\nTITLE: 配置FastGPT海外版所需的IP白名单\nDESCRIPTION: 这段代码提供了FastGPT海外版(cloud.tryfastgpt.ai)所需添加的IP白名单列表，用于微信公众号接入时配置IP白名单。这些IP是FastGPT服务器的出口IP，需要添加到微信公众平台的IP白名单中。\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/external-integration/official_account.md#2025-04-10_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n35.240.227.100\n34.124.237.188\n34.143.240.160\n34.87.51.146\n34.87.79.202\n35.247.163.68\n34.87.102.86\n35.198.192.104\n34.126.163.205\n34.124.189.116\n34.143.149.171\n34.87.173.252\n34.142.157.52\n34.87.180.104\n34.87.20.189\n34.87.110.152\n34.87.44.74\n34.87.152.33\n35.197.149.75\n35.247.161.35\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for SearXNG Docker Container\nDESCRIPTION: Environment variables configuration to limit concurrency and memory usage for the SearXNG container\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/plugins/searxng_plugin_guide.md#2025-04-10_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nUWSGI_WORKERS=4\\nUWSGI_THREADS=4\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for FastGPT Pro\nDESCRIPTION: Environment variable configuration for logging in FastGPT Pro deployment\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/4810.md#2025-04-10_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nLOG_LEVEL=debug\nSTORE_LOG_LEVEL=warn\n```\n\n----------------------------------------\n\nTITLE: 配置FastGPT国内版所需的IP白名单\nDESCRIPTION: 这段代码提供了FastGPT国内版(fastgpt.cn)所需添加的IP白名单列表，用于微信公众号接入时配置IP白名单。这些IP是FastGPT服务器的出口IP，需要添加到微信公众平台的IP白名单中。\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/use-cases/external-integration/official_account.md#2025-04-10_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n47.97.1.240\n121.43.105.217\n121.41.178.7\n121.40.65.187\n47.97.59.172\n101.37.205.32\n120.55.195.90\n120.26.229.115\n120.55.193.112\n47.98.190.173\n112.124.41.79\n121.196.235.183\n121.41.75.88\n121.43.108.48\n112.124.12.6\n121.43.52.222\n121.199.162.43\n121.199.162.102\n120.55.94.163\n47.99.59.223\n112.124.46.5\n121.40.46.247\n120.26.145.73\n120.26.147.199\n121.43.125.163\n121.196.228.45\n121.43.126.202\n120.26.144.37\n```\n\n----------------------------------------\n\nTITLE: FastGPT v4.8.10 Initialization Command\nDESCRIPTION: cURL command to initialize FastGPT v4.8.10 with rootkey authentication. Replace {{rootkey}} with environment variable value and {{host}} with FastGPT domain.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/4810.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv4810' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: FastGPT Requirements Configuration\nDESCRIPTION: Specifies required Python packages and their versions for the FastGPT project. Includes major dependencies like transformers, PyTorch, FastAPI, and various optimization libraries for machine learning and web serving capabilities.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/llm-Baichuan2/requirements.txt#2025-04-10_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nprotobuf\ntransformers==4.48.0\ncpm_kernels\ntorch>=2.0\ngradio\nmdtex2html\nsentencepiece\naccelerate\nsse-starlette\nfastapi==0.99.1\npydantic==1.10.7\nuvicorn==0.21.1\nxformers\nbitsandbytes\n```\n\n----------------------------------------\n\nTITLE: Generating MongoDB Replica Set Key\nDESCRIPTION: Commands to generate a MongoDB replica set key and set appropriate permissions for manual initialization.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/docker.md#2025-04-10_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nopenssl rand -base64 756 > ./mongodb.key\nchmod 600 ./mongodb.key\n# 修改密钥权限，部分系统是admin，部分是root\nchown 999:root ./mongodb.key\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI o1 Models in FastGPT\nDESCRIPTION: JSON configuration for adding OpenAI o1-mini and o1-preview models to FastGPT. Includes model settings like context limits, temperature, and capabilities for various AI functions.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/4811.md#2025-04-10_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"model\": \"o1-mini\",\n    \"name\": \"o1-mini\",\n    \"avatar\": \"/imgs/model/openai.svg\",\n    \"maxContext\": 125000,\n    \"maxResponse\": 65000,\n    \"quoteMaxToken\": 120000,\n    \"maxTemperature\": 1.2,\n    \"charsPointsPrice\": 0,\n    \"censor\": false,\n    \"vision\": false,\n    \"datasetProcess\": true,\n    \"usedInClassify\": true,\n    \"usedInExtractFields\": true,\n    \"usedInToolCall\": true,\n    \"toolChoice\": false,\n    \"functionCall\": false,\n    \"customCQPrompt\": \"\",\n    \"customExtractPrompt\": \"\",\n    \"defaultSystemChatPrompt\": \"\",\n    \"defaultConfig\": {\n        \"temperature\": 1\n    }\n},\n{\n    \"model\": \"o1-preview\",\n    \"name\": \"o1-preview\",\n    \"avatar\": \"/imgs/model/openai.svg\",\n    \"maxContext\": 125000,\n    \"maxResponse\": 32000,\n    \"quoteMaxToken\": 120000,\n    \"maxTemperature\": 1.2,\n    \"charsPointsPrice\": 0,\n    \"censor\": false,\n    \"vision\": false,\n    \"datasetProcess\": true,\n    \"usedInClassify\": true,\n    \"usedInExtractFields\": true,\n    \"usedInToolCall\": true,\n    \"toolChoice\": false,\n    \"functionCall\": false,\n    \"customCQPrompt\": \"\",\n    \"customExtractPrompt\": \"\",\n    \"defaultSystemChatPrompt\": \"\",\n    \"defaultConfig\": {\n        \"temperature\": 1\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI Base URL Environment Variable for FastGPT\nDESCRIPTION: Configures the OpenAI base URL environment variable in FastGPT to point to the OneAPI endpoint. This allows FastGPT to route requests through OneAPI to access different models.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/modelConfig/ppio.md#2025-04-10_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nOPENAI_BASE_URL= http://OneAPI-IP:OneAPI-PORT/v1\n```\n\n----------------------------------------\n\nTITLE: Initializing FastGPT Commercial Version via API\nDESCRIPTION: cURL command to initialize the FastGPT commercial version by making an HTTP POST request. Requires replacing placeholders for rootkey and host with actual environment variables.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/4811.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/init/4811' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Creating Python Environment for Xinference\nDESCRIPTION: Commands to create a Python 3.11 environment using Conda for running Xinference.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/xinference.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nconda create --name py311 python=3.11\nconda activate py311\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable for Commercial Version\nDESCRIPTION: Example of setting the PRO_URL environment variable for the commercial version of FastGPT. The URL should point to the commercial image address without the /api suffix.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/466.md#2025-04-10_snippet_0\n\nLANGUAGE: properties\nCODE:\n```\nPRO_URL=http://fastgpt-plugin.ns-hsss5d.svc.cluster.local:3000\n```\n\n----------------------------------------\n\nTITLE: Executing FastGPT v4.8.22 Upgrade Script\nDESCRIPTION: HTTP POST request to run the upgrade script for FastGPT v4.8.22. Requires rootkey authentication and FastGPT domain. The script migrates contact information to corresponding user tables. Only required for commercial version users providing SaaS services.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/4822.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv4822' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Installing llama-cpp-python for Different Hardware\nDESCRIPTION: Commands to install llama-cpp-python with specific compilation parameters for different hardware platforms.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/custom-models/xinference.md#2025-04-10_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nCMAKE_ARGS=\"-DLLAMA_METAL=on\" pip install llama-cpp-python\nCMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python\nCMAKE_ARGS=\"-DLLAMA_HIPBLAS=on\" pip install llama-cpp-python\n```\n\n----------------------------------------\n\nTITLE: Executing FastGPT V4.8.5 Commercial Version Initialization Script\nDESCRIPTION: This curl command sends a POST request to initialize the commercial version of FastGPT v4.8.5. It requires the rootkey for authentication and the commercial version's domain. This script resets the knowledge base permission system.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/485.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/init/485' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Installing Base Environment with Conda and Pip\nDESCRIPTION: Sets up the base Python environment using Conda and installs the required magic-pdf package with specific index URLs.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mineru/README.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconda create -n mineru python=3.10\nconda activate mineru\npip install -U \"magic-pdf[full]\" --extra-index-url https://wheels.myhloli.com -i https://mirrors.aliyun.com/pypi/simple\n```\n\n----------------------------------------\n\nTITLE: Starting the PDF Parser Service\nDESCRIPTION: Launches the PDF parser service using Python.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mineru/README.md#2025-04-10_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython pdf_parser_mineru.py\n```\n\n----------------------------------------\n\nTITLE: Executing FastGPT v4.8.8 Initialization Request\nDESCRIPTION: HTTP POST request to initialize knowledge base inheritance permissions for FastGPT v4.8.8 upgrade. Requires root key authentication and FastGPT domain name.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/488.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv488' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Adding AI Proxy Environment Variables to FastGPT Container\nDESCRIPTION: YAML configuration snippet for adding AI Proxy related environment variables to the FastGPT container in Docker Compose.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/490.md#2025-04-10_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n# AI Proxy 的地址，如果配了该地址，优先使用\n- AIPROXY_API_ENDPOINT=http://aiproxy:3000\n# AI Proxy 的 Admin Token，与 AI Proxy 中的环境变量 ADMIN_KEY\n- AIPROXY_API_TOKEN=aiproxy\n```\n\n----------------------------------------\n\nTITLE: SearXNG YAML Configuration\nDESCRIPTION: Complete YAML configuration file for SearXNG including server settings, search parameters, and engine configurations\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/guide/plugins/searxng_plugin_guide.md#2025-04-10_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ngeneral:\\n  debug: false\\n  instance_name: \\\"searxng\\\"\\n  privacypolicy_url: false\\n  donation_url: false\\n  contact_url: false\\n  enable_metrics: true\\n  open_metrics: ''\\n\\nbrand:\\n  new_issue_url: https://github.com/searxng/searxng/issues/new\\n  docs_url: https://docs.searxng.org/\\n  public_instances: https://searx.space\\n  wiki_url: https://github.com/searxng/searxng/wiki\\n  issue_url: https://github.com/searxng/searxng/issues\\n\\nsearch:\\n  safe_search: 0\\n  autocomplete: \\\"\\\"\\n  autocomplete_min: 4\\n  default_lang: \\\"auto\\\"\\n  ban_time_on_fail: 5\\n  max_ban_time_on_fail: 120\\n  formats:\\n    - html\\n\\nserver:\\n  port: 8080\\n  bind_address: \\\"0.0.0.0\\\"\\n  base_url: false\\n  limiter: false\\n  public_instance: false\\n  secret_key: \\\"example\\\"\\n  image_proxy: false\\n  http_protocol_version: \\\"1.0\\\"\\n  method: \\\"POST\\\"\\n  default_http_headers:\\n    X-Content-Type-Options: nosniff\\n    X-Download-Options: noopen\\n    X-Robots-Tag: noindex, nofollow\\n    Referrer-Policy: no-referrer\\n\\nredis:\\n  url: false\\n\\nui:\\n  static_path: \\\"\\\"\\n  static_use_hash: false\\n  templates_path: \\\"\\\"\\n  default_theme: simple\\n  default_locale: \\\"\\\"\\n  query_in_title: false\\n  infinite_scroll: false\\n  center_alignment: false\\n  theme_args:\\n    simple_style: auto\\n\\noutgoing:\\n  request_timeout: 30.0\\n  max_request_timeout: 40.0\\n  pool_connections: 200\\n  pool_maxsize: 50\\n  enable_http2: false\\n  retries: 5\\n\\nengines:\\n\\n  - name: bing\\n    engine: bing\\n    shortcut: bi\\n\\ndoi_resolvers:\\n  oadoi.org: 'https://oadoi.org/'\\n  doi.org: 'https://doi.org/'\\n  doai.io: 'https://dissem.in/'\\n  sci-hub.se: 'https://sci-hub.se/'\\n  sci-hub.st: 'https://sci-hub.st/'\\n  sci-hub.ru: 'https://sci-hub.ru/'\\n\\ndefault_doi_resolver: 'oadoi.org'\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for PDF-Mistral Plugin\nDESCRIPTION: This command installs the required packages for the PDF-Mistral plugin using pip.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mistral/README.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Configuring AI Proxy in Docker Compose YAML\nDESCRIPTION: YAML configuration for setting up AI Proxy service and its PostgreSQL database in Docker Compose. Includes environment variables and healthcheck settings.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/490.md#2025-04-10_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n  # AI Proxy\n  aiproxy:\n    image: 'ghcr.io/labring/aiproxy:latest'\n    container_name: aiproxy\n    restart: unless-stopped\n    depends_on:\n      aiproxy_pg:\n        condition: service_healthy\n    networks:\n      - fastgpt\n    environment:\n      # 对应 fastgpt 里的AIPROXY_API_TOKEN\n      - ADMIN_KEY=aiproxy\n      # 错误日志详情保存时间（小时）\n      - LOG_DETAIL_STORAGE_HOURS=1\n      # 数据库连接地址\n      - SQL_DSN=postgres://postgres:aiproxy@aiproxy_pg:5432/aiproxy\n      # 最大重试次数\n      - RETRY_TIMES=3\n      # 不需要计费\n      - BILLING_ENABLED=false\n      # 不需要严格检测模型\n      - DISABLE_MODEL_CONFIG=true\n    healthcheck:\n      test: ['CMD', 'curl', '-f', 'http://localhost:3000/api/status']\n      interval: 5s\n      timeout: 5s\n      retries: 10\n  aiproxy_pg:\n    image: pgvector/pgvector:0.8.0-pg15 # docker hub\n    # image: registry.cn-hangzhou.aliyuncs.com/fastgpt/pgvector:v0.8.0-pg15 # 阿里云\n    restart: unless-stopped\n    container_name: aiproxy_pg\n    volumes:\n      - ./aiproxy_pg:/var/lib/postgresql/data\n    networks:\n      - fastgpt\n    environment:\n      TZ: Asia/Shanghai\n      POSTGRES_USER: postgres\n      POSTGRES_DB: aiproxy\n      POSTGRES_PASSWORD: aiproxy\n    healthcheck:\n      test: ['CMD', 'pg_isready', '-U', 'postgres', '-d', 'aiproxy']\n      interval: 5s\n      timeout: 5s\n      retries: 10\n```\n\n----------------------------------------\n\nTITLE: Setting FILE_TOKEN_KEY Environment Variable for FastGPT V4.3\nDESCRIPTION: This snippet shows how to set the FILE_TOKEN_KEY environment variable, which is used to generate file preview links with a 30-minute expiration time in FastGPT V4.3.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/43.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nFILE_TOKEN_KEY=filetokenkey\n```\n\n----------------------------------------\n\nTITLE: Executing OneAPI to AI Proxy Migration Script\nDESCRIPTION: Bash commands for executing the migration script to transfer data from OneAPI to AI Proxy. Includes steps for both networked and non-networked environments.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/490.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# 进入 aiproxy 容器\ndocker exec -it aiproxy sh\n# 安装 curl\napk add curl\n# 执行脚本\ncurl --location --request POST 'http://localhost:3000/api/channels/import/oneapi' \\\n--header 'Authorization: Bearer aiproxy' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n    \"dsn\": \"mysql://root:oneapimmysql@tcp(mysql:3306)/oneapi\"\n}'\n# 返回 {\"data\":[],\"success\":true} 代表成功\n```\n\n----------------------------------------\n\nTITLE: Values Configuration for FastGPT Helm Chart\nDESCRIPTION: Comprehensive configuration values for deploying FastGPT, including container image settings, service configuration, database settings, and deployment parameters.\nSOURCE: https://github.com/labring/FastGPT/blob/main/deploy/helm/fastgpt/README.md#2025-04-10_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n| Key | Type | Default | Description |\n|-----|------|---------|-------------|\n| affinity | object | `{}` |  |\n| autoscaling.enabled | bool | `false` |  |\n| autoscaling.maxReplicas | int | `100` |  |\n| autoscaling.minReplicas | int | `1` |  |\n| autoscaling.targetCPUUtilizationPercentage | int | `80` |  |\n| fullnameOverride | string | `\"\"` |  |\n| image.pullPolicy | string | `\"IfNotPresent\"` |  |\n| image.repository | string | `\"ghcr.io/labring/fastgpt\"` |  |\n| image.tag | string | `\"\"` |  |\n| imagePullSecrets | list | `[]` |  |\n| ingress.annotations | object | `{}` |  |\n| ingress.className | string | `\"\"` |  |\n| ingress.enabled | bool | `false` |  |\n| ingress.hosts[0].host | string | `\"chart-example.local\"` |  |\n| ingress.hosts[0].paths[0].path | string | `\"/\"` |  |\n| ingress.hosts[0].paths[0].pathType | string | `\"ImplementationSpecific\"` |  |\n| ingress.tls | list | `[]` |  |\n| livenessProbe.httpGet.path | string | `\"/\"` |  |\n| livenessProbe.httpGet.port | string | `\"http\"` |  |\n| mongodb.architecture | string | `\"replicaset\"` |  |\n| mongodb.auth.rootPassword | string | `\"123456\"` |  |\n| mongodb.auth.rootUser | string | `\"root\"` |  |\n| mongodb.enabled | bool | `true` | Enable or disable the built-in MangoDB |\n| nameOverride | string | `\"\"` |  |\n| nodeSelector | object | `{}` |  |\n| podAnnotations | object | `{}` |  |\n| podLabels | object | `{}` |  |\n| podSecurityContext | object | `{}` |  |\n| postgresql.enabled | bool | `true` | Enable or disable the built-in PostgreSQL |\n| postgresql.global.postgresql.auth.database | string | `\"postgres\"` | The default database of PostgreSQL |\n| postgresql.global.postgresql.auth.postgresPassword | string | `\"postgres\"` | The password of PostgreSQL, default username is `postgres` |\n| postgresql.image.repository | string | `\"linuxsuren/pgvector\"` | The PostgreSQL image which include the pgvector extension. See also the source code from https://github.com/LinuxSuRen/pgvector-docker |\n| postgresql.image.tag | string | `\"v0.0.1\"` |  |\n| readinessProbe.httpGet.path | string | `\"/\"` |  |\n| readinessProbe.httpGet.port | string | `\"http\"` |  |\n| replicaCount | int | `1` |  |\n| resources | object | `{}` |  |\n| securityContext | object | `{}` |  |\n| service.port | int | `3000` |  |\n| service.type | string | `\"ClusterIP\"` |  |\n| serviceAccount.annotations | object | `{}` |  |\n| serviceAccount.automount | bool | `true` |  |\n| serviceAccount.create | bool | `true` |  |\n| serviceAccount.name | string | `\"\"` |  |\n| tolerations | list | `[]` |  |\n| volumeMounts | list | `[]` |  |\n| volumes | list | `[]` |  |\n```\n\n----------------------------------------\n\nTITLE: Downloading SenseVoice Model using Git\nDESCRIPTION: This command demonstrates how to download the SenseVoice Small model using Git. It clones the model repository from ModelScope.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/iic/SenseVoiceSmall/README.md#2025-04-10_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n#Git模型下载\ngit clone https://www.modelscope.cn/iic/SenseVoiceSmall.git\n```\n\n----------------------------------------\n\nTITLE: PgVector 0.5 Upgrade SQL Commands - Sealos Deployment\nDESCRIPTION: SQL commands for upgrading PgVector extension and creating HNSW index in Sealos deployment. Includes steps for plugin upgrade, memory configuration, and index creation.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/45.md#2025-04-10_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n-- 升级插件名\nALTER EXTENSION vector UPDATE;\n-- 插件是否升级成功，成功的话，vector插件版本为 0.5.0，旧版的为 0.4.1\n\\dx\n\n-- 下面两个语句会设置 pg 在构建索引时可用的内存大小，需根据自身的数据库规格来动态配置，可配置为 1/4 的内存大小\nalter system set maintenance_work_mem = '2400MB'; \nselect pg_reload_conf();\n\n-- 重构数据库索引和排序\nREINDEX DATABASE postgres;\n\n-- 开始构建索引，该索引构建时间非常久，直接点击右上角的叉，退出 Terminal 即可\nCREATE INDEX CONCURRENTLY vector_index ON modeldata USING hnsw (vector vector_ip_ops) WITH (m = 16, ef_construction = 64);\n-- 可以再次点击一键链接，进入 Terminal，输入下方命令，如果看到 \"vector_index\" hnsw (vector vector_ip_ops) WITH (m='16', ef_construction='64') 则代表构建完成（注意，后面没有 INVALID）\n\\d modeldata\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM for NestJS Project in Bash\nDESCRIPTION: Command to install all required dependencies for a NestJS project using PNPM package manager.\nSOURCE: https://github.com/labring/FastGPT/blob/main/projects/sandbox/README.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pnpm install\n```\n\n----------------------------------------\n\nTITLE: Executing FastGPT V4.5.1 Initialization API with curl\nDESCRIPTION: This command executes the initialization API for FastGPT V4.5.1. It requires replacing {{host}} with your domain name and {{rootkey}} with the root key from your environment variables. The initialization process renames database fields, initializes MongoDB APP table knowledge base fields, and sets up collections for files in both PostgreSQL and MongoDB.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/451.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv451' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies\nDESCRIPTION: Lists required Python packages numpy and pandas that need to be installed for the FastGPT project.\nSOURCE: https://github.com/labring/FastGPT/blob/main/projects/sandbox/requirements.txt#2025-04-10_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\nnumpy\npandas\n```\n\n----------------------------------------\n\nTITLE: Cloning the FastGPT Repository\nDESCRIPTION: Command to clone the forked FastGPT repository from GitHub to the local machine.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/intro.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:<github_username>/FastGPT.git\n```\n\n----------------------------------------\n\nTITLE: Executing Initialization API for FastGPT V4.6.2 Upgrade\nDESCRIPTION: This cURL command sends a POST request to initialize the FastGPT V4.6.2 upgrade. It requires the host domain and rootkey as environment variables. The primary purpose is to initialize the full-text index feature.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/462.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv462' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Running Tests for NestJS Application with PNPM in Bash\nDESCRIPTION: Commands for running unit tests, end-to-end tests, and generating test coverage reports for a NestJS application using PNPM.\nSOURCE: https://github.com/labring/FastGPT/blob/main/projects/sandbox/README.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# unit tests\n$ pnpm run test\n\n# e2e tests\n$ pnpm run test:e2e\n\n# test coverage\n$ pnpm run test:cov\n```\n\n----------------------------------------\n\nTITLE: Updating Environment Variables for Commercial Version in FastGPT\nDESCRIPTION: Add OneAPI address and token to the environment variables for the commercial version of FastGPT. This includes setting the OPENAI_BASE_URL to the OneAPI endpoint and the CHAT_API_KEY for authentication.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/469.md#2025-04-10_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nOPENAI_BASE_URL=http://oneapi:3000/v1\nCHAT_API_KEY=sk-fastgpt\n```\n\n----------------------------------------\n\nTITLE: Describing FastGPT Workflow Plugins Package in Markdown\nDESCRIPTION: This Markdown snippet describes the purpose of the package, which is to store workflow system plugins for the FastGPT project. It provides a brief explanation of the package's contents and its role in the project structure.\nSOURCE: https://github.com/labring/FastGPT/blob/main/packages/plugins/README.md#2025-04-10_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n# Package 说明\n\n该 package 存放工作流系统插件。\n```\n\n----------------------------------------\n\nTITLE: Installing OrbStack on macOS using Homebrew\nDESCRIPTION: Command to install OrbStack, a Docker alternative, on macOS using Homebrew package manager.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/docker.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbrew install orbstack\n```\n\n----------------------------------------\n\nTITLE: Executing Initialization Script for FastGPT V4.6.9 Upgrade\nDESCRIPTION: Send an HTTP POST request to initialize the upgrade process for FastGPT V4.6.9. This script resets the metering table and performs data cleanup. Replace {{rootkey}} with the environment variable rootkey and {{host}} with your domain.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/469.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv469' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Defining Hugo Front Matter in YAML\nDESCRIPTION: This code snippet defines the front matter for a Hugo blog post using YAML syntax. It includes a dynamically generated title, the current date, and sets the draft status to true.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/archetypes/default.md#2025-04-10_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: \"{{ replace .Name \"-\" \" \" | title }}\"\ndate: {{ .Date }}\ndraft: true\n---\n```\n\n----------------------------------------\n\nTITLE: Initializing FastGPT V4.6 - Second Step\nDESCRIPTION: This cURL command sends a POST request to complete the second part of FastGPT V4.6 initialization. It should only be executed after the first initialization step has completed successfully.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/46.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv46-2' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Fetching Specific Namespace Translations in getServerSideProps\nDESCRIPTION: This TypeScript snippet demonstrates how to fetch specific namespace translations in the getServerSideProps function for Next.js pages. It uses the serverSideTranslations function to load translations for 'publish' and 'user' namespaces.\nSOURCE: https://github.com/labring/FastGPT/blob/main/dev.md#2025-04-10_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// pages/yourPage.tsx\nexport async function getServerSideProps(context: any) {\n  return {\n    props: {\n      currentTab: context?.query?.currentTab || TabEnum.info,\n      ...(await serverSideTranslations(context.locale, ['publish', 'user']))\n    }\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Commercial Version Initialization API Call\nDESCRIPTION: cURL command to initialize the commercial version of FastGPT v4.6.8 with root key authentication.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/468.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/init/v468' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Using useTranslation Hook in React Component\nDESCRIPTION: This TypeScript snippet shows how to use the useTranslation hook from next-i18next in a React component. It demonstrates translating a button label using the 't' function with a namespace.\nSOURCE: https://github.com/labring/FastGPT/blob/main/dev.md#2025-04-10_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// pages/yourPage.tsx\nimport { useTranslation } from 'next-i18next';\n\nconst YourComponent = () => {\n  const { t } = useTranslation();\n\n  return (\n    <Button\n      variant=\"outline\"\n      size=\"sm\"\n      mr={2}\n      onClick={() => setShowSelected(false)}\n    >\n      {t('common:close')}\n    </Button>\n  );\n};\n\nexport default YourComponent;\n```\n\n----------------------------------------\n\nTITLE: Executing Initialization Script for FastGPT V4.7\nDESCRIPTION: This bash command sends an HTTP POST request to initialize FastGPT V4.7 after upgrading. It requires replacing {{rootkey}} with the environment variable 'rootkey' and {{host}} with the user's domain.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/47.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/initv47' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image for Surya OCR\nDESCRIPTION: Command to locally build the Surya OCR Docker image with tag v0.1.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/ocr-surya/README.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t surya_ocr:v0.1 .\n```\n\n----------------------------------------\n\nTITLE: Cleaning Invalid Data in FastGPT V4.8.1 via HTTP Request\nDESCRIPTION: This bash script sends an HTTP POST request to clean up invalid data in FastGPT V4.8.1. It should be executed after initialization to address issues with previous data cleanup timers. It requires the rootkey from environment variables and the FastGPT domain.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/upgrading/481.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request POST 'https://{{host}}/api/admin/clearInvalidData' \\\n--header 'rootkey: {{rootkey}}' \\\n--header 'Content-Type: application/json'\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for FastGPT\nDESCRIPTION: Commands to install all dependencies for FastGPT, including root package, projects, and packages.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/intro.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npnpm i\n```\n\n----------------------------------------\n\nTITLE: Building FastGPT Docker Image\nDESCRIPTION: Docker and Make commands to build the FastGPT Docker image, with options for using a proxy.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/intro.md#2025-04-10_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Docker cmd: Build image, not proxy\ndocker build -f ./projects/app/Dockerfile -t registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.8.1 . --build-arg name=app\n# Make cmd: Build image, not proxy\nmake build name=app image=registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.8.1\n\n# Docker cmd: Build image with proxy\ndocker build -f ./projects/app/Dockerfile -t registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.8.1 . --build-arg name=app --build-arg proxy=taobao\n# Make cmd: Build image with proxy\nmake build name=app image=registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.8.1 proxy=taobao\n```\n\n----------------------------------------\n\nTITLE: Running FastGPT Locally\nDESCRIPTION: Commands to run FastGPT locally using either direct pnpm command or Make command.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/intro.md#2025-04-10_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Non-Make run\ncd projects/app\npnpm dev\n\n# Make run\nmake dev name=app\n```\n\n----------------------------------------\n\nTITLE: Installing Docker and Docker Compose on Linux\nDESCRIPTION: Commands to install Docker and Docker Compose on a Linux system, including verification steps.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/docker.md#2025-04-10_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# 安装 Docker\ncurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun\nsystemctl enable --now docker\n# 安装 docker-compose\ncurl -L https://github.com/docker/compose/releases/download/v2.20.3/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\n# 验证安装\ndocker -v\ndocker-compose -v\n# 如失效，自行百度~\n```\n\n----------------------------------------\n\nTITLE: Restarting Docker Compose Services\nDESCRIPTION: Commands to stop and restart Docker Compose services after configuration changes.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/docker.md#2025-04-10_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose down\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Initializing MongoDB Replica Set\nDESCRIPTION: Commands to enter the MongoDB container, connect to the database, and initialize the replica set.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/development/docker.md#2025-04-10_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# 查看 mongo 容器是否正常运行\ndocker ps \n# 进入容器\ndocker exec -it mongo bash\n\n# 连接数据库（这里要填Mongo的用户名和密码）\nmongo -u myusername -p mypassword --authenticationDatabase admin\n\n# 初始化副本集。如果需要外网访问，mongo:27017 。如果需要外网访问，需要增加Mongo连接参数：directConnection=true\nrs.initiate({\n  _id: \"rs0\",\n  members: [\n    { _id: 0, host: \"mongo:27017\" }\n  ]\n})\n# 检查状态。如果提示 rs0 状态，则代表运行成功\nrs.status()\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for Surya OCR\nDESCRIPTION: Docker Compose YAML configuration for running the Surya OCR service with GPU support, port mapping, and environment variables for customization.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/ocr-surya/README.md#2025-04-10_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nversion: '3'\nservices:\n  surya-ocr:\n    image: surya_ocr:v0.1\n    container_name: surya-ocr\n    # GPU运行环境，如果宿主机未安装，将deploy配置隐藏即可\n    deploy:\n      resources:\n        reservations:\n          devices:\n          - driver: nvidia\n            count: all\n            capabilities: [gpu]\n    ports:\n      - 7230:7230\n    environment:\n      - BATCH_SIZE=32\n      - ACCESS_TOKEN=YOUR_ACCESS_TOKEN\n      - LANGS='[\"zh\",\"en\"]'\n```\n\n----------------------------------------\n\nTITLE: Changing Directory to Plugin Location\nDESCRIPTION: Navigates to the pdf-mineru plugin directory.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mineru/README.md#2025-04-10_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncd /plugins/model/pdf-mineru/\n```\n\n----------------------------------------\n\nTITLE: Cloning FastGPT Project\nDESCRIPTION: Clones the FastGPT repository from GitHub.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/pdf-mineru/README.md#2025-04-10_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/labring/FastGPT.git\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for FastGPT\nDESCRIPTION: List of required Python packages and their specific versions needed to run the FastGPT project. Includes web framework FastAPI, transformer models, embedding functionality, and server components.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/rerank-bge/bge-reranker-base/requirements.txt#2025-04-10_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\nfastapi==0.104.1\ntransformers[sentencepiece]\nFlagEmbedding==1.2.8\npydantic==1.10.13\nuvicorn==0.17.6\nitsdangerous\nprotobuf\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for FastGPT\nDESCRIPTION: This snippet specifies the required Python packages and their versions for the FastGPT project. It includes PyTorch 1.13 or higher, torchaudio, FunASR 1.1.1 or higher, FastAPI, and modelscope.\nSOURCE: https://github.com/labring/FastGPT/blob/main/plugins/model/stt-sensevoice/app/requirements.txt#2025-04-10_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ntorch>=1.13\ntorchaudio\nfunasr>=1.1.1\nfastapi\nmodelscope\n```\n\n----------------------------------------\n\nTITLE: Running NestJS Application in Different Modes with PNPM in Bash\nDESCRIPTION: Commands for running a NestJS application in development mode, watch mode for auto-reloading during development, and production mode using PNPM.\nSOURCE: https://github.com/labring/FastGPT/blob/main/projects/sandbox/README.md#2025-04-10_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# development\n$ pnpm run start\n\n# watch mode\n$ pnpm run start:dev\n\n# production mode\n$ pnpm run start:prod\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies and Running FastGPT in Development Mode\nDESCRIPTION: This snippet shows how to install project dependencies and run FastGPT in development mode. It includes commands for both standard and 'make' setups, as well as a note for Node versions >= 20.\nSOURCE: https://github.com/labring/FastGPT/blob/main/dev.md#2025-04-10_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n# Give automatic script code execution permission (on non-Linux systems, you can manually execute the postinstall.sh file content)\nchmod -R +x ./scripts/\n# Executing under the code root directory installs all dependencies within the root package, projects, and packages\npnpm i\n\n# Not make cmd\ncd projects/app\npnpm dev\n\n# Make cmd\nmake dev name=app\n```\n\nLANGUAGE: sh\nCODE:\n```\nNODE_OPTIONS=--no-node-snapshot pnpm i\n```\n\n----------------------------------------\n\nTITLE: Handling Static File Translations in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to handle static file translations using a custom i18nT function. It creates a staticContent object with translated values for use in the application.\nSOURCE: https://github.com/labring/FastGPT/blob/main/dev.md#2025-04-10_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// utils/i18n.ts\nimport { i18nT } from '@fastgpt/web/i18n/utils';\n\nconst staticContent = {\n  id: 'simpleChat',\n  avatar: 'core/workflow/template/aiChat',\n  name: i18nT('app:template.simple_robot'),\n};\n\nexport default staticContent;\n```\n\n----------------------------------------\n\nTITLE: Contributors Table with Dynamic Images in HTML\nDESCRIPTION: HTML table structure displaying contributor statistics and graphs using responsive images that adapt to light/dark color schemes\nSOURCE: https://github.com/labring/FastGPT/blob/main/README_en.md#2025-04-10_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<table>\n    <tr>\n      <th colspan=\"2\">\n        <br><img src=\"https://contrib.rocks/image?repo=labring/FastGPT\"><br><br>\n      </th>\n    </tr>\n    <tr>\n      <td>\n        <picture>\n          <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&period=past_28_days&owner_id=102226726&repo_ids=605673387&image_size=2x3&color_scheme=dark\">\n          <img alt=\"Active participants of labring - past 28 days\" src=\"https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&period=past_28_days&owner_id=102226726&repo_ids=605673387&image_size=2x3&color_scheme=light\">\n        </picture>\n      </td>\n      <td rowspan=\"2\">\n        <picture>\n          <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=new&period=past_28_days&owner_id=102226726&repo_ids=605673387&image_size=4x7&color_scheme=dark\">\n          <img alt=\"New trends of labring\" src=\"https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=new&period=past_28_days&owner_id=102226726&repo_ids=605673387&image_size=4x7&color_scheme=light\">\n        </picture>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <picture>\n          <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&period=past_28_days&owner_id=102226726&repo_ids=605673387&image_size=2x3&color_scheme=dark\">\n          <img alt=\"New participants of labring - past 28 days\" src=\"https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&period=past_28_days&owner_id=102226726&repo_ids=605673387&image_size=2x3&color_scheme=light\">\n        </picture>\n      </td>\n    </tr>\n  </table>\n```\n\n----------------------------------------\n\nTITLE: Star History Graph in HTML\nDESCRIPTION: HTML structure for displaying project star history using responsive images that adapt to light/dark color schemes\nSOURCE: https://github.com/labring/FastGPT/blob/main/README_en.md#2025-04-10_snippet_1\n\nLANGUAGE: HTML\nCODE:\n```\n<picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=labring/FastGPT&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=labring/FastGPT&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=labring/FastGPT&type=Date\" />\n  </picture>\n```\n\n----------------------------------------\n\nTITLE: YAML Front Matter for Pricing Page\nDESCRIPTION: This YAML front matter defines metadata for a pricing documentation page in FastGPT. It sets the page weight for sorting (1100), title ('收费说明' meaning 'Payment Instructions'), description, icon, draft status, and image configuration.\nSOURCE: https://github.com/labring/FastGPT/blob/main/docSite/content/zh-cn/docs/shopping_cart/_index.md#2025-04-10_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\nweight: 1100\ntitle: '收费说明'\ndescription: 'FastGPT 收费说明'\nicon: 'shopping_cart'\ndraft: false\nimages: []\n---\n```"
  }
]