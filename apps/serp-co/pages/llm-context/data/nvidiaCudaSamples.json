[
  {
    "owner": "nvidia",
    "repo": "cuda-samples",
    "content": "TITLE: Cloning the CUDA Samples Repository using Git\nDESCRIPTION: Command to clone the NVIDIA CUDA Samples repository from GitHub. This gives you access to all sample code for CUDA Toolkit 12.8.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/NVIDIA/cuda-samples.git\n```\n\n----------------------------------------\n\nTITLE: Building CUDA Samples on Linux\nDESCRIPTION: Sequence of commands to build CUDA samples on Linux using CMake. This creates a build directory, configures the project, and compiles the samples using all available processor cores.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir build && cd build\ncmake ..\nmake -j$(nproc)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Conjugate Gradient Sample\nDESCRIPTION: Sets up a CMake project for building a CUDA-accelerated conjugate gradient solver. Configures CUDA architecture targets, includes necessary dependencies, and links CUDA libraries including cudart, cublas, and cusparse. Enables C++17 and CUDA 17 standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/conjugateGradient/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(conjugateGradient LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for conjugateGradient\nadd_executable(conjugateGradient main.cpp)\n\ntarget_compile_options(conjugateGradient PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(conjugateGradient PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(conjugateGradient PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(conjugateGradient PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(conjugateGradient PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n    CUDA::cusparse\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Device Query Project with CMake\nDESCRIPTION: A complete CMake configuration file for building a CUDA deviceQuery application. It specifies CUDA architecture targets, compiler flags, include directories, and dependencies. The script ensures proper linking with CUDA libraries and sets up C++17 and CUDA 17 standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/deviceQuery/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(deviceQuery LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for deviceQuery\nadd_executable(deviceQuery deviceQuery.cpp)\n\ntarget_compile_options(deviceQuery PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(deviceQuery PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(deviceQuery PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(deviceQuery PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(deviceQuery PUBLIC\n    CUDA::cudart\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA Device Query API Usage\nDESCRIPTION: Lists the key CUDA Runtime and Driver APIs used for querying device properties including device count, version information, peer access capabilities, and detailed device characteristics.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/deviceQuery/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### [CUDA Driver API]\ncuDeviceGetAttribute, cuSafeCallNoSync\n\n### [CUDA Runtime API]\ncudaRuntimeGetVersion, cudaGetErrorString, cudaDeviceCanAccessPeer, cudaSetDevice, cudaGetDeviceCount, cudaDriverGetVersion, cudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Utilizing CUDA Runtime API for GPU Operations\nDESCRIPTION: This snippet demonstrates the use of key CUDA Runtime API functions for memory management and device property queries. It includes cudaMalloc for GPU memory allocation, cudaMemcpy for data transfer, cudaGetDeviceProperties for querying GPU characteristics, and cudaFree for releasing GPU memory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTemplates/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMalloc\ncudaMemcpy\ncudaGetDeviceProperties\ncudaFree\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Matrix Multiplication Project\nDESCRIPTION: Configures a CMake project for building a CUDA matrix multiplication sample. It sets the minimum CMake version, defines project languages, configures CUDA architecture targets from compute capability 5.0 to 12.0, and creates an executable with C++17 and CUDA 17 standards support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/matrixMul/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(matrixMul LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for asyncAPI\nadd_executable(matrixMul matrixMul.cu)\n\ntarget_compile_options(matrixMul PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(matrixMul PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(matrixMul PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Build for CUDA IMMA Tensor Core Sample\nDESCRIPTION: Comprehensive CMake configuration that sets up a CUDA project for Tensor Core GEMM operations. Configures CUDA architectures (Ampere and later), enables C++17 features, and sets up build properties including separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/immaTensorCoreGemm/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(immaTensorCoreGemm LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for immaTensorCoreGemm\nadd_executable(immaTensorCoreGemm immaTensorCoreGemm.cu)\n\ntarget_compile_options(immaTensorCoreGemm PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(immaTensorCoreGemm PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(immaTensorCoreGemm PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Project with CMake for Conjugate Gradient Preconditioner\nDESCRIPTION: This CMake script sets up a CUDA project for conjugate gradient preconditioner implementation. It configures multiple CUDA architecture targets (50-120), links against CUDA libraries (cudart, cublas, cusparse), and enables C++17 and CUDA 17 features. The script also enables lambda functions in CUDA code and position-independent code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/conjugateGradientPrecond/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(conjugateGradientPrecond LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for conjugateGradientPrecond\nadd_executable(conjugateGradientPrecond main.cpp)\n\ntarget_compile_options(conjugateGradientPrecond PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(conjugateGradientPrecond PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(conjugateGradientPrecond PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(conjugateGradientPrecond PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(conjugateGradientPrecond PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n    CUDA::cusparse\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring NVVM 'simple' Example Application in CMake\nDESCRIPTION: Complete CMake configuration for building a simple NVVM example. Sets up runtime paths, defines the executable target, configures testing, handles platform-specific linking flags, and ensures required files are copied to the build directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/simple/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_INSTALL_RPATH ${LIBNVVM_HOME})\nset(CMAKE_INCLUDE_CURRENT_DIR YES)\n\nadd_executable(simple simple.c)\n\nadd_test(NAME simple COMMAND simple WORKING_DIRECTORY \"${CMAKE_CURRENT_BINARY_DIR}\")\n\ntarget_link_libraries(simple ${NVVM_LIB} ${CUDA_LIB})\n\nif (WIN32)\n  set_target_properties(simple PROPERTIES COMPILE_FLAGS \"/wd4996\")\nelse (WIN32)\n  set_target_properties(simple PROPERTIES\n                        LINK_FLAGS \"-Wl,-rpath,${LIBNVVM_RPATH}\")\nendif (WIN32)\n\ninstall(TARGETS simple DESTINATION bin)\ninstall(FILES simple-gpu64.ll DESTINATION bin)\n\n# 'simple' will load simple-gpu64.ll from the current working directory. That\n# .ll file should be present where tests are executed (the build directory).\nadd_custom_command(\n    TARGET simple\n    POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n            \"${CMAKE_CURRENT_SOURCE_DIR}/simple-gpu64.ll\" \"$<TARGET_FILE_DIR:simple>\"\n)\nif (WIN32)\n  add_custom_command(\n      TARGET simple\n      POST_BUILD\n      COMMAND ${CMAKE_COMMAND} -E copy_if_different\n              \"${CMAKE_BINARY_DIR}/nvvm64_40_0.dll\" \"$<TARGET_FILE_DIR:simple>\"\n  )\nendif ()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Project for Image Denoising with CMake\nDESCRIPTION: Sets up a CUDA project for image denoising, configuring CUDA architectures, compiler flags, and required packages. It defines the main executable target with necessary compile options, include directories, and linked libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/imageDenoising/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(imageDenoising LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\n\nfind_package(OpenGL)\nfind_package(GLUT)\n\n# Source file\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        # Add target for imageDenoising\n        add_executable(imageDenoising bmploader.cpp imageDenoising.cu imageDenoisingGL.cpp)\n\n        target_compile_options(imageDenoising PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(imageDenoising PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(imageDenoising PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(imageDenoising PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(imageDenoising\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n\n        # Copy data files to the output directory\n        add_custom_command(TARGET imageDenoising POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_directory\n            ${CMAKE_CURRENT_SOURCE_DIR}/data\n            ${CMAKE_CURRENT_BINARY_DIR}/data\n        )\n\n        if(WIN32)\n            target_link_libraries(imageDenoising\n                ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n                ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n            )\n\n            add_custom_command(TARGET imageDenoising\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n\n            add_custom_command(TARGET imageDenoising\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n        endif()\n\n    else()\n        message(STATUS \"GLUT not found - will not build sample 'imageDenoising'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'imageDenoising'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation for EGLStream CUDA Cross-GPU\nDESCRIPTION: Documentation outlining the setup, requirements, and API usage for implementing CUDA and EGL Streams interoperability across different GPUs. Details supported architectures, operating systems, and required CUDA APIs.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# EGLStream_CUDA_CrossGPU - EGLStream_CUDA_CrossGPU\n\n## Description\n\nDemonstrates CUDA and EGL Streams interop, where consumer's EGL Stream is on one GPU and producer's on other and both consumer-producer are different processes.\n\n## Key Concepts\n\nEGLStreams Interop\n\n## Supported SM Architectures\n\n[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.9 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)\n```\n\n----------------------------------------\n\nTITLE: CUDA API Functions Reference for Tensor Core GEMM\nDESCRIPTION: List of essential CUDA Runtime API functions used in the implementation of Tensor Core GEMM operations, including memory management, event handling, and device property queries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cudaTensorCoreGemm/README.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncudaMemcpy, cudaFree, cudaGetErrorString, cudaGetLastError, cudaEventSynchronize, cudaFuncSetAttribute, cudaEventRecord, cudaMemset, cudaMalloc, cudaEventElapsedTime, cudaGetDeviceProperties, cudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Advanced Quicksort Project\nDESCRIPTION: This CMake configuration sets up the project environment, specifies CUDA architectures based on the system processor, configures compiler flags, and defines the build target for the cdpAdvancedQuicksort executable. It includes settings for different build types and CUDA-specific options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpAdvancedQuicksort/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cdpAdvancedQuicksort LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    # Need to differentiate Tegra_aarch64 and other aarch64 systems(sbsa_aarch64) as they have different CUDA_ARCHITECTURES list\n    if(${BUILD_TEGRA})\n        set(CMAKE_CUDA_ARCHITECTURES 72 87 101)\n    else()\n        set(CMAKE_CUDA_ARCHITECTURES 61 70 75 80 86 90)\n    endif()\nelse()\n    set(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 75 80 86 89 90 100 101 120)\nendif()\n\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for cdpAdvancedQuicksort\nadd_executable(cdpAdvancedQuicksort cdpAdvancedQuicksort.cu cdpBitonicSort.cu)\n\ntarget_compile_options(cdpAdvancedQuicksort PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cdpAdvancedQuicksort PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cdpAdvancedQuicksort PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Tensor Core GEMM Project Build\nDESCRIPTION: CMake configuration that sets up a CUDA project for Tensor Core GEMM operations. Specifies CUDA architectures from Volta (70) to Hopper (120), enables C++17 and CUDA 17 features, and configures build properties including separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/dmmaTensorCoreGemm/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(dmmaTensorCoreGemm LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for dmmaTensorCoreGemm\nadd_executable(dmmaTensorCoreGemm dmmaTensorCoreGemm.cu)\n\ntarget_compile_options(dmmaTensorCoreGemm PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(dmmaTensorCoreGemm PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(dmmaTensorCoreGemm PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Project Build Settings with CMake\nDESCRIPTION: Comprehensive CMake configuration for a CUDA project that sets minimum CMake version, defines project languages, configures CUDA architectures, and establishes build parameters. Includes setup for GPU architecture targets, compiler flags, and C++17/CUDA 17 language standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/interval/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(interval LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for interval\nadd_executable(interval interval.cu)\n\ntarget_compile_options(interval PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(interval PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(interval PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(interval PUBLIC\n    ${CMAKE_CURRENT_SOURCE_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Project Documentation and Requirements\nDESCRIPTION: Documentation detailing the project requirements, supported architectures, and CUDA API dependencies. Includes information about SM architectures, operating systems, CPU architectures, and required CUDA Runtime API functions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/jacobiCudaGraphs/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# jacobiCudaGraphs - Jacobi CUDA Graphs\n\n## Description\n\nDemonstrates Instantiated CUDA Graph Update with Jacobi Iterative Method using cudaGraphExecKernelNodeSetParams() and cudaGraphExecUpdate() approach.\n\n## Key Concepts\n\nCUDA Graphs, Stream Capture, Instantiated CUDA Graph Update, Cooperative Groups\n\n## Supported SM Architectures\n\n## Supported OSes\n\nLinux, Windows\n\n## Supported CPU Architecture\n\nx86_64, armv7l\n\n## CUDA APIs involved\n\n### [CUDA Runtime API](http://docs.nvidia.com/cuda/cuda-runtime-api/index.html)\ncudaExtent, cudaGraphLaunch, cudaGraphAddMemcpyNode, cudaMallocHost, cudaPitchedPtr, cudaStreamEndCapture, cudaGraphCreate, cudaFreeHost, cudaMemsetAsync, cudaMemcpyAsync, cudaGraphExecKernelNodeSetParams, cudaStreamCreateWithFlags, cudaGraphInstantiate, cudaStreamBeginCapture, cudaFree, cudaGraphExecUpdate, cudaGraphAddKernelNode, cudaPos, cudaStreamSynchronize, cudaGraphAddMemsetNode, cudaMalloc, cudaGraphExecDestroy\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA Vector Addition\nDESCRIPTION: Sets up a CMake project for a CUDA vector addition sample with specific CUDA architecture targets, compiler flags, and build options. The configuration supports multiple CUDA compute capabilities and enables modern C++ and CUDA features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/vectorAdd/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(vectorAdd LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for vectorAdd\nadd_executable(vectorAdd vectorAdd.cu)\n\ntarget_compile_options(vectorAdd PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(vectorAdd PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(vectorAdd PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring nvJPEG CUDA Sample Build with CMake\nDESCRIPTION: A complete CMake build configuration for the nvJPEG CUDA sample. It sets compiler requirements, CUDA architecture targets, includes necessary dependencies, and creates build targets. The script also includes platform detection to skip building on unsupported architectures (aarch64).\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/nvJPEG/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(nvJPEG LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    message(STATUS \"Will not build sample nvJPEG - not supported on aarch64\")\nelse()\n\n    # Source file\n    # Add target for nvJPEG\n    add_executable(nvJPEG nvJPEG.cpp)\n\n    target_compile_options(nvJPEG PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(nvJPEG PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(nvJPEG PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n    target_include_directories(nvJPEG PRIVATE\n        ${CUDAToolkit_INCLUDE_DIRS}\n    )\n\n    target_link_libraries(nvJPEG PRIVATE\n        CUDA::cudart\n        CUDA::nvjpeg\n    )\n\n    # Copy data to the output directory\n    add_custom_command(TARGET nvJPEG POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy_directory\n        ${CMAKE_CURRENT_SOURCE_DIR}/images\n        ${CMAKE_CURRENT_BINARY_DIR}/images\n    )\n\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA NV12toBGRandResize Project with CMake\nDESCRIPTION: Comprehensive CMake configuration for building a CUDA project that converts NV12 format to BGR and performs resize operations. The configuration sets up CUDA architectures, compiler flags, dependencies, and ensures data files are copied to the build directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/NV12toBGRandResize/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(NV12toBGRandResize LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for NV12toBGRandResize\nadd_executable(NV12toBGRandResize bgr_resize.cu nv12_resize.cu nv12_to_bgr_planar.cu resize_convert_main.cpp utils.cu)\n\ntarget_compile_options(NV12toBGRandResize PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(NV12toBGRandResize PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(NV12toBGRandResize PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(NV12toBGRandResize PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\nadd_custom_command(TARGET NV12toBGRandResize POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Volume Rendering\nDESCRIPTION: This snippet sets up the CMake configuration for building a CUDA volume rendering project. It specifies minimum CMake version, project name, and languages. Essential libraries like CUDAToolkit, OpenGL, and GLUT are found if available. The setup defines CUDA architectures and manages various compile settings and post-build commands, including Windows-specific adjustments. Dependencies include the Cmake 3.20+ version, CUDAToolkit, OpenGL, and optionally GLUT for compiling.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/volumeRender/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(volumeRender LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n\n# Source file\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        # Add target for volumeRender\n        add_executable(volumeRender volumeRender_kernel.cu volumeRender.cpp)\n\n        target_compile_options(volumeRender PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(volumeRender PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(volumeRender PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(volumeRender PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(volumeRender\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n\n        add_custom_command(TARGET volumeRender POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_directory\n            ${CMAKE_CURRENT_SOURCE_DIR}/data\n            ${CMAKE_CURRENT_BINARY_DIR}/data\n        )\n\n        if(WIN32)\n            target_link_libraries(volumeRender\n                ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n                ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n            )\n\n            add_custom_command(TARGET volumeRender\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n\n            add_custom_command(TARGET volumeRender\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n        endif()\n\n    else()\n        message(STATUS \"GLUT not found - will not build sample 'volumeRender'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'volumeRender'\")\nendif()\n\n```\n\n----------------------------------------\n\nTITLE: Describing bandwidthTest Utility in Markdown\nDESCRIPTION: This snippet describes the bandwidthTest utility, which measures GPU memcopy bandwidth and PCI-e transfer speeds for various memory types and directions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n### [bandwidthTest](./bandwidthTest)\nThis is a simple test program to measure the memcopy bandwidth of the GPU and memcpy bandwidth across PCI-e. This test application is capable of measuring device to device copy bandwidth, host to device copy bandwidth for pageable and page-locked memory, and device to host copy bandwidth for pageable and page-locked memory.\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime APIs used in simpleP2P application\nDESCRIPTION: A comprehensive list of CUDA Runtime API functions utilized in the simpleP2P application, including memory management, device control, peer access, and event handling functions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleP2P/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaMemcpy, cudaMalloc, cudaFree, cudaMallocHost, cudaEventCreateWithFlags, cudaSetDevice, cudaEventSynchronize, cudaDeviceDisablePeerAccess, cudaGetDeviceCount, cudaDeviceSynchronize, cudaEventRecord, cudaFreeHost, cudaGetDeviceProperties, cudaDeviceEnablePeerAccess, cudaEventDestroy, cudaEventElapsedTime, cudaDeviceCanAccessPeer\n```\n\n----------------------------------------\n\nTITLE: CMake Project Configuration for CUDA FFT Convolution\nDESCRIPTION: Configures a CMake project for building a CUDA-based 2D FFT convolution sample. Sets minimum CMake version, project languages, CUDA architecture targets, and compiler flags. Links against CUDA's CUFFT library and configures C++17/CUDA 17 features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/convolutionFFT2D/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(convolutionFFT2D LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for convolutionFFT2D\nadd_executable(convolutionFFT2D convolutionFFT2D.cu convolutionFFT2D_gold.cpp main.cpp)\n\ntarget_compile_options(convolutionFFT2D PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(convolutionFFT2D PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(convolutionFFT2D PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(convolutionFFT2D PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(convolutionFFT2D PUBLIC\n    CUDA::cufft\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA NvSciBuf Multiplanar Executable Target\nDESCRIPTION: Creates and configures the main executable target with CUDA lambda support, C++17/CUDA 17 standards, and separable compilation. Links required libraries and includes necessary header directories.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cudaNvSciBufMultiplanar/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\n        add_executable(cudaNvSciBufMultiplanar imageKernels.cu cudaNvSciBufMultiplanar.cpp main.cpp)\n\n        target_compile_options(cudaNvSciBufMultiplanar PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(cudaNvSciBufMultiplanar PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(cudaNvSciBufMultiplanar PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(cudaNvSciBufMultiplanar PUBLIC\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${NVSCIBUF_INCLUDE_DIR}\n            ${NVSCISYNC_INCLUDE_DIR}\n        )\n\n        target_link_libraries(cudaNvSciBufMultiplanar\n            CUDA::cuda_driver\n            ${NVSCIBUF_LIB}\n            ${NVSCISYNC_LIB}\n        )\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA and OpenGL Project\nDESCRIPTION: This CMake script configures the build environment for the fluidsGL project. It sets the minimum required CMake version, lists necessary paths for CMake modules, and specifies the target languages as C, C++, and CUDA. It locates the CUDA Toolkit, ensures position-independent code for the project, and sets CUDA architecture and flags. It checks for OpenGL and GLUT, setting up include directories and libraries accordingly. Conditional logic handles building specifics on Windows, such as library directories and custom post-build steps to copy DLLs and data files. Dependencies include CMake, CUDA Toolkit, OpenGL, and GLUT.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fluidsGL/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(fluidsGL LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n\n# Source file\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        # Add target for fluidsGL\n        add_executable(fluidsGL fluidsGL_kernels.cu fluidsGL.cpp)\n\n        target_compile_options(fluidsGL PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(fluidsGL PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(fluidsGL PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(fluidsGL PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(fluidsGL\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n            CUDA::cufft\n        )\n\n        # Copy data files to the output directory\n        add_custom_command(TARGET fluidsGL POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_directory\n            ${CMAKE_CURRENT_SOURCE_DIR}/data\n            ${CMAKE_CURRENT_BINARY_DIR}/data\n        )\n\n        if(WIN32)\n            target_link_libraries(fluidsGL\n                ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n                ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n            )\n\n            add_custom_command(TARGET fluidsGL\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n\n            add_custom_command(TARGET fluidsGL\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n        endif()\n\n    else()\n        message(STATUS \"GLUT not found - will not build sample 'fluidsGL'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'fluidsGL'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA Conjugate Gradient Multi-Block Sample\nDESCRIPTION: Complete CMake configuration that sets up the build environment for a CUDA sample implementing conjugate gradient algorithm. It specifies CUDA architectures (compute capabilities 60-120), enables extended lambda support, and links against CUDA libraries cublas and cusparse.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(conjugateGradientMultiBlockCG LANGUAGES CUDA CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for conjugateGradientMultiBlockCG\nadd_executable(conjugateGradientMultiBlockCG conjugateGradientMultiBlockCG.cu)\n\ntarget_compile_options(conjugateGradientMultiBlockCG PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(conjugateGradientMultiBlockCG PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(conjugateGradientMultiBlockCG PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_link_libraries(conjugateGradientMultiBlockCG PRIVATE\n    CUDA::cublas\n    CUDA::cusparse\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing CUDA GPU Device for DGEMM Computation\nDESCRIPTION: This snippet initializes the CUDA GPU device and prints its name and compute capability. It then sets up the matrix dimensions for the DGEMM operation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_dmmaTensorCoreGemm.txt#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\nInitializing...\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nM: 8192 (8 x 1024)\nN: 8192 (8 x 1024)\nK: 4096 (4 x 1024)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA simpleTemplates Project\nDESCRIPTION: Complete CMake configuration for building a CUDA sample project. It defines supported CUDA architectures (from compute capability 5.0 to 12.0), sets compiler flags, and configures the build target with extended lambda support and modern C++/CUDA standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTemplates/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleTemplates LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleTemplates\nadd_executable(simpleTemplates simpleTemplates.cu)\n\ntarget_compile_options(simpleTemplates PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleTemplates PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleTemplates PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Linking with LLVM\nDESCRIPTION: The snippet checks the LLVM version and conditionally builds the cuda-c-linking sample depending on the version range. It synthesizes CMake commands to create an executable and a test target while linking necessary libraries. This setup assumes LLVM development libraries between versions 7 to 14 are installed, as opaque pointers are not yet supported in libNVVM.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/cuda-c-linking/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nmessage(STATUS \"Found LLVM Version ${LLVM_PACKAGE_VERSION}\")\nif (LLVM_PACKAGE_VERSION VERSION_GREATER_EQUAL \"15\" OR\n    LLVM_PACKAGE_VERSION VERSION_LESS \"7\")\n  message(STATUS \"The cuda-c-linking sample is expected to build with \"\n                 \"LLVM development libraries v7 to v14, opaque pointers are \"\n                 \"not yet supported in libNVVM.\")\n  return()\nendif ()\n\nadd_executable(cuda-c-linking cuda-c-linking.cpp)\n\nadd_test(NAME cuda-c-linking\n   COMMAND cuda-c-linking\n   WORKING_DIRECTORY \"${CMAKE_CURRENT_BINARY_DIR}\")\ntarget_link_libraries(cuda-c-linking ${NVVM_LIB} ${CUDA_LIB})\n\n# See https://llvm.org/docs/CMake.html#developing-llvm-passes-out-of-source\nseparate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS})\nadd_definitions(${LLVM_DEFINITIONS_LIST})\ninclude_directories(${LLVM_INCLUDE_DIRS})\nllvm_map_components_to_libnames(llvm_libs core support)\ntarget_link_libraries(cuda-c-linking ${llvm_libs})\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA globalToShmemAsyncCopy Project\nDESCRIPTION: Sets up the CMake project for globalToShmemAsyncCopy, including CUDA toolkit requirements, compiler flags, and target properties. It specifies CUDA architectures, enables C++17 and CUDA 17 standards, and configures separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/globalToShmemAsyncCopy/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(globalToShmemAsyncCopy LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for globalToShmemAsyncCopy\nadd_executable(globalToShmemAsyncCopy globalToShmemAsyncCopy.cu)\n\ntarget_compile_options(globalToShmemAsyncCopy PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(globalToShmemAsyncCopy PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(globalToShmemAsyncCopy PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Project\nDESCRIPTION: This snippet configures the CMake setup for a CUDA project, specifying the minimum required version, including necessary modules, and defining the CUDA architectures. It sets the build type and compiles options specific to the CUDA language, like extended lambdas and standard versions. Dependencies include CMake and CUDAToolkit, and it requires CUDA 5.0 or newer.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(p2pBandwidthLatencyTest LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for p2pBandwidthLatencyTest\nadd_executable(p2pBandwidthLatencyTest p2pBandwidthLatencyTest.cu)\n\ntarget_compile_options(p2pBandwidthLatencyTest PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(p2pBandwidthLatencyTest PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(p2pBandwidthLatencyTest PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Describing deviceQuery Utility in Markdown\nDESCRIPTION: This snippet describes the deviceQuery utility, which enumerates the properties of CUDA devices present in the system.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/README.md#2025-04-21_snippet_1\n\nLANGUAGE: Markdown\nCODE:\n```\n### [deviceQuery](./deviceQuery)\nThis sample enumerates the properties of the CUDA devices present in the system.\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for simpleVulkanMMAP Project\nDESCRIPTION: This CMake script sets up the simpleVulkanMMAP project by defining the minimum required CMake version, adding module paths, and specifying the required packages such as CUDAToolkit, Vulkan, and OpenGL. It configures the CUDA architectures and flags, checks for specific headers, includes directories, and sets up the build rules depending on the availability of dependencies. The script is designed to conditionally compile and link the executable if all dependencies are found, ensuring a smooth build process for both Windows and other platforms.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkanMMAP/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleVulkanMMAP LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nfind_package(Vulkan)\nfind_package(OpenGL)\n\n# Include the check_include_file macro\ninclude(CheckIncludeFile)\n\n# Check for the GLFW/glfw3.h header\ncheck_include_file(\"GLFW/glfw3.h\" HAVE_GLFW3_H)\n\n# Find GLFW header and lib for Windows\nif(WIN32)\n    find_file(GLFW3_H \"GLFW/glfw3.h\" PATH \"${GLFW_INCLUDE_DIR}\")\n    find_library(GLFW3_LIB \"glfw3\" PATH \"${GLFW_LIB_DIR}\")\n    if(GLFW3_H AND GLFW3_LIB) \n        message(STATUS \"Found GLFW/glfw3.h and GLFW library.\")\n        set(HAVE_GLFW3_H 1)\n    endif()\nendif()\n\n# Source file\nif(${Vulkan_FOUND})\n    if(${OPENGL_FOUND})\n        if(${HAVE_GLFW3_H})\n            # Add target for simpleVulkanMMAP\n            add_executable(simpleVulkanMMAP ../../../Common/helper_multiprocess.cpp MonteCarloPi.cu VulkanBaseApp.cpp main.cpp)\n\n            target_compile_options(simpleVulkanMMAP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n            target_compile_features(simpleVulkanMMAP PRIVATE cxx_std_17 cuda_std_17)\n\n            set_target_properties(simpleVulkanMMAP PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n            target_include_directories(simpleVulkanMMAP PUBLIC\n                ${Vulkan_INCLUDE_DIRS}\n                ${CUDAToolkit_INCLUDE_DIRS}\n            )\n            target_link_libraries(simpleVulkanMMAP\n                ${Vulkan_LIBRARIES}\n                OpenGL::GL\n                CUDA::cuda_driver\n            )\n            if(WIN32)\n                target_include_directories(simpleVulkanMMAP PUBLIC\n                    ${GLFW_INCLUDE_DIR}\n                )\n                target_link_libraries(simpleVulkanMMAP\n                    ${GLFW3_LIB}\n                )\n            else()\n                target_link_libraries(simpleVulkanMMAP\n                    glfw\n                )\n            endif()\n            add_custom_command(TARGET simpleVulkanMMAP POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy_if_different\n                ${CMAKE_CURRENT_SOURCE_DIR}/montecarlo.frag\n                ${CMAKE_CURRENT_SOURCE_DIR}/montecarlo.vert\n                ${CMAKE_CURRENT_SOURCE_DIR}/vert.spv\n                ${CMAKE_CURRENT_SOURCE_DIR}/frag.spv\n                ${CMAKE_CURRENT_BINARY_DIR}\n            )\n        else()\n            message(STATUS \"glfw3 not found - will not build sample 'simpleVulkanMMAP'\")\n        endif()\n    else()\n        message(STATUS \"GLFW not found - will not build sample 'simpleVulkanMMAP'\")\n    endif()\nelse()\n    message(STATUS \"Vulkan not found - will not build sample 'simpleVulkanMMAP'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Compressible Memory Project with CMake\nDESCRIPTION: Sets up a CUDA project with specific architecture targets, compiler flags, and dependencies. It includes configuration for debug builds, position-independent code, and C++17/CUDA 17 features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cudaCompressibleMemory/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cudaCompressibleMemory LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for cudaCompressibleMemory\nadd_executable(cudaCompressibleMemory compMalloc.cpp saxpy.cu)\n\ntarget_compile_options(cudaCompressibleMemory PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cudaCompressibleMemory PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cudaCompressibleMemory PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(cudaCompressibleMemory PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(cudaCompressibleMemory PRIVATE\n    CUDA::cuda_driver\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up CMake for CUDA Sample Project\nDESCRIPTION: This snippet initializes a CMake project called 'warpAggregatedAtomicsCG', setting up the minimum required version and including essential directories and libraries. It specifies the CUDA architectures and compiler options necessary for building the CUDA project while enabling position-independent code. The snippet customizes the build configurations for different build types, particularly focusing on debug options and CUDA-specific features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(warpAggregatedAtomicsCG LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for warpAggregatedAtomicsCG\nadd_executable(warpAggregatedAtomicsCG warpAggregatedAtomicsCG.cu)\n\ntarget_compile_options(warpAggregatedAtomicsCG PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(warpAggregatedAtomicsCG PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(warpAggregatedAtomicsCG PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Line of Sight Project Build\nDESCRIPTION: Complete CMake configuration for building a CUDA Line of Sight sample. Specifies CUDA architectures, compiler flags, dependencies, and build targets. Enables C++17 and CUDA 17 features with separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/lineOfSight/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(lineOfSight LANGUAGES CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for lineOfSight\nadd_executable(lineOfSight lineOfSight.cu)\n\ntarget_compile_options(lineOfSight PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(lineOfSight PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(lineOfSight PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Performing LU Decomposition on GPU with CUDA\nDESCRIPTION: This snippet performs the LU decomposition on the GPU. After the computation, it copies the result back from GPU memory to host memory for verification.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleCUBLAS_LU.txt#2025-04-21_snippet_3\n\nLANGUAGE: CUDA\nCODE:\n```\n> performing LU decomposition..\n> copying data from GPU memory to host memory..\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Build for cuSolverSp_LinearSolver CUDA Application\nDESCRIPTION: Complete CMake configuration that sets up a CUDA-based linear solver application. It defines CUDA architecture targets, required libraries (cudart, cublas, cusolver), compilation options, and ensures data files are copied to the build directory for runtime use.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cuSolverSp_LinearSolver LANGUAGES C CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for cuSolverSp_LinearSolver\nadd_executable(cuSolverSp_LinearSolver cuSolverSp_LinearSolver.cpp mmio.c mmio_wrapper.cpp)\n\ntarget_compile_options(cuSolverSp_LinearSolver PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cuSolverSp_LinearSolver PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cuSolverSp_LinearSolver PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(cuSolverSp_LinearSolver PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(cuSolverSp_LinearSolver PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n    CUDA::cusolver\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET cuSolverSp_LinearSolver POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/lap2D_5pt_n100.mtx\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET cuSolverSp_LinearSolver POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/lap3D_7pt_n20.mtx\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA and D3D11\nDESCRIPTION: This snippet sets the minimum required version for CMake, defines the project, and finds the CUDA toolkit. It configures the project to generate specific CUDA architectures and includes necessary directories and link libraries for building a simple D3D11 application.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleD3D11/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleD3D11 LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nif(WIN32)\n    # Source file\n    # Add target for simpleD3D11\n    add_executable(simpleD3D11\n        simpleD3D11.cpp\n        sinewave_cuda.cu\n        ../../../Common/rendercheck_d3d11.cpp\n    )\n\n    target_compile_options(simpleD3D11 PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(simpleD3D11 PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(simpleD3D11 PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n    target_include_directories(simpleD3D11 PRIVATE\n        ${CUDAToolkit_INCLUDE_DIRS}\n    )\n\n    target_link_libraries(simpleD3D11 PRIVATE\n        d3d11\n        dxgi\n        dxguid\n        d3dcompiler\n    )\n\n    add_custom_command(TARGET simpleD3D11 POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy_directory\n        ${CMAKE_CURRENT_SOURCE_DIR}/data\n        ${CMAKE_CURRENT_BINARY_DIR}/data\n    )\nelse()\n    message(STATUS \"Sample 'simpleD3D11' is Windows-only - skipping\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Histogram Project with CMake\nDESCRIPTION: Sets up a CUDA project for histogram computation using CMake. Configures CUDA architectures, compiler flags, and defines project structure including source files and dependencies. Requires CMake 3.20+ and CUDA Toolkit.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/histogram/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(histogram LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for histogram\nadd_executable(histogram histogram256.cu histogram64.cu histogram_gold.cpp main.cpp)\n\ntarget_compile_options(histogram PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(histogram PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(histogram PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(histogram PUBLIC\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Sample Build with CMake\nDESCRIPTION: Complete CMake configuration for building the inlinePTX_nvrtc CUDA sample. Sets up CUDA architecture targets, compiler flags, dependencies, and build parameters. Includes post-build steps for copying kernel files.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(inlinePTX_nvrtc LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for inlinePTX_nvrtc\nadd_executable(inlinePTX_nvrtc inlinePTX.cpp)\n\ntarget_compile_options(inlinePTX_nvrtc PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(inlinePTX_nvrtc PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(inlinePTX_nvrtc PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_link_libraries(inlinePTX_nvrtc PRIVATE\n    CUDA::nvrtc\n    CUDA::cuda_driver\n)\n\n# Copy clock_kernel.cu to the output directory\nadd_custom_command(TARGET inlinePTX_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/inlinePTX_kernel.cu ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Describing topologyQuery Utility in Markdown\nDESCRIPTION: This snippet describes the topologyQuery utility, which demonstrates how to query the topology of a system with multiple GPUs.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/README.md#2025-04-21_snippet_3\n\nLANGUAGE: Markdown\nCODE:\n```\n### [topologyQuery](./topologyQuery)\nA simple example on how to query the topology of a system with multiple GPU\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Vector Addition with NVRTC Runtime Compilation\nDESCRIPTION: Sets up a CMake project for CUDA Vector Addition using NVRTC, which allows runtime compilation of CUDA kernels. The configuration specifies multiple CUDA architectures, links against NVRTC and CUDA driver libraries, and copies the kernel source file to the build directory for runtime access.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/vectorAdd_nvrtc/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(vectorAdd_nvrtc LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add sample target executable\nadd_executable(vectorAdd_nvrtc vectorAdd.cpp)\n\ntarget_compile_options(vectorAdd_nvrtc PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(vectorAdd_nvrtc PRIVATE cxx_std_17 cuda_std_17)\n\ntarget_link_libraries(vectorAdd_nvrtc PRIVATE\n    CUDA::nvrtc\n    CUDA::cuda_driver\n)\n\n# Copy vectorAdd_kernel.cu to the output directory\nadd_custom_command(TARGET vectorAdd_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/vectorAdd_kernel.cu ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Vulkan and CUDA Project with CMake\nDESCRIPTION: This CMake script sets up a project environment for compiling a CUDA application with Vulkan image rendering capabilities. It checks for required libraries, includes necessary directories, and links the appropriate libraries. Dependencies include the CUDA toolkit, Vulkan, OpenGL, and potentially GLFW. It handles different configurations for Windows and Unix operating systems.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/vulkanImageCUDA/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(vulkanImageCUDA LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nfind_package(Vulkan)\nfind_package(OpenGL)\n\n# Include the check_include_file macro\ninclude(CheckIncludeFile)\n\n# Check for the GLFW/glfw3.h header\ncheck_include_file(\"GLFW/glfw3.h\" HAVE_GLFW3_H)\n\n# Find GLFW header and lib for Windows\nif(WIN32)\n    find_file(GLFW3_H \"GLFW/glfw3.h\" PATH \"${GLFW_INCLUDE_DIR}\")\n    find_file(GLFW3_LIB \"glfw3\" PATH \"${GLFW_LIB_DIR}\")\n    if(GLFW3_H AND GLFW3_LIB) \n        message(STATUS \"Found GLFW/glfw3.h and GLFW library.\")\n        set(HAVE_GLFW3_H 1)\n    endif()\nendif()\n\n# Source file\nif(${Vulkan_FOUND})\n    if(${OPENGL_FOUND})\n        if(${HAVE_GLFW3_H})\n            # Add target for vulkanImageCUDA\n            add_executable(vulkanImageCUDA vulkanImageCUDA.cu)\n\n            target_compile_options(vulkanImageCUDA PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n            target_compile_features(vulkanImageCUDA PRIVATE cxx_std_17 cuda_std_17)\n\n            set_target_properties(vulkanImageCUDA PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n            target_include_directories(vulkanImageCUDA PUBLIC\n                ${Vulkan_INCLUDE_DIRS}\n                ${CUDAToolkit_INCLUDE_DIRS}\n            )\n            target_link_libraries(vulkanImageCUDA\n                ${Vulkan_LIBRARIES}\n                OpenGL::GL\n            )\n            if(WIN32)\n                target_include_directories(vulkanImageCUDA PUBLIC\n                    ${GLFW_INCLUDE_DIR}\n                )\n                target_link_libraries(vulkanImageCUDA\n                    ${GLFW3_LIB}\n                )\n            else()\n                target_link_libraries(vulkanImageCUDA\n                    glfw\n                )\n            endif()\n            add_custom_command(TARGET vulkanImageCUDA POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy_if_different\n                ${CMAKE_CURRENT_SOURCE_DIR}/shader.frag\n                ${CMAKE_CURRENT_SOURCE_DIR}/shader.vert\n                ${CMAKE_CURRENT_SOURCE_DIR}/vert.spv\n                ${CMAKE_CURRENT_SOURCE_DIR}/frag.spv\n                ${CMAKE_CURRENT_SOURCE_DIR}/teapot1024.ppm\n                ${CMAKE_CURRENT_BINARY_DIR}\n            )\n        else()\n            message(STATUS \"glfw3 not found - will not build sample 'vulkanImageCUDA'\")\n        endif()\n    else()\n        message(STATUS \"OpenGL not found - will not build sample 'vulkanImageCUDA'\")\n    endif()\nelse()\n    message(STATUS \"Vulkan not found - will not build sample 'vulkanImageCUDA'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Build for CUDA simpleAWBarrier Project\nDESCRIPTION: Complete CMake configuration for building the simpleAWBarrier CUDA sample. It sets up CUDA architecture targets (70 through 120), enables C++17 and CUDA 17 standards, configures include paths, and enables extended lambda support for CUDA compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleAWBarrier/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleAWBarrier LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleAWBarrier\nadd_executable(simpleAWBarrier simpleAWBarrier.cu)\n\ntarget_compile_options(simpleAWBarrier PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleAWBarrier PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleAWBarrier PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring Executable Target for Simple D3D11 Texture\nDESCRIPTION: In this snippet, an executable target named 'simpleD3D11Texture' is configured, including its source files and linking necessary libraries. It also specifies compile options and establishes properties for separable compilation, making it suitable for CUDA development.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleD3D11Texture/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nif(WIN32)\n    # Source file\n    # Add target for simpleD3D11Texture\n    add_executable(simpleD3D11Texture\n        simpleD3D11Texture.cpp\n        ../../../Common/rendercheck_d3d11.cpp\n        texture_2d.cu\n        texture_3d.cu\n        texture_cube.cu\n    )\n\n    target_compile_options(simpleD3D11Texture PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(simpleD3D11Texture PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(simpleD3D11Texture PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n    target_include_directories(simpleD3D11Texture PRIVATE\n        ${CUDAToolkit_INCLUDE_DIRS}\n    )\n\n    target_link_libraries(simpleD3D11Texture PRIVATE\n        d3d11\n        dxgi\n        dxguid\n        d3dcompiler\n    )\n\n    add_custom_command(TARGET simpleD3D11Texture POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy_directory\n        ${CMAKE_CURRENT_SOURCE_DIR}/data\n        ${CMAKE_CURRENT_BINARY_DIR}/data\n    )\nelse()\n    message(STATUS \"Sample 'simpleD3D11Texture' is Windows-only - skipping\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA DLA Error Reporting Build with CMake\nDESCRIPTION: Configures build settings for a CUDA DLA error reporting application including CUDA architectures, compiler flags, and library dependencies. The build is restricted to Linux platforms and requires the CUDLA library. Sets up C++17 and CUDA 17 standards with extended lambda support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLAErrorReporting/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../../cmake/Modules\")\n\nproject(cuDLAErrorReporting LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../../Common)\n\nfind_library(CUDLA_LIB cudla PATHS ${CUDAToolkit_LIBRARY_DIR})\n\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    if(CUDLA_LIB)\n        # Source file\n        # Add target for cuDLAErrorReporting\n        add_executable(cuDLAErrorReporting main.cu)\n\n        target_compile_options(cuDLAErrorReporting PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(cuDLAErrorReporting PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(cuDLAErrorReporting PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(cuDLAErrorReporting PUBLIC\n            ${CUDAToolkit_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(cuDLAErrorReporting\n            ${CUDLA_LIB}\n        )\n    else()\n        message(STATUS \"CUDLA not found - will not build sample 'cuDLAErrorReporting'\")\n    endif()\nelse()\n    message(STATUS \"Will not build sample cuDLAErrorReporting - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Environment for CUDA simpleHyperQ Sample\nDESCRIPTION: Complete CMake configuration for building the simpleHyperQ CUDA sample. It sets minimum CMake version, defines CUDA architecture targets, configures compiler flags, and sets up the executable target with appropriate compilation features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleHyperQ/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleHyperQ LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleHyperQ\nadd_executable(simpleHyperQ simpleHyperQ.cu)\n\ntarget_compile_options(simpleHyperQ PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleHyperQ PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleHyperQ PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Initializing Monte Carlo Option Pricing with Multi-GPU Support in CUDA\nDESCRIPTION: This snippet outlines the key CUDA Runtime API functions used in the MonteCarloMultiGPU sample. It includes memory management, device properties, event handling, and stream operations for multi-GPU execution.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/MonteCarloMultiGPU/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaStreamDestroy, cudaMalloc, cudaFree, cudaMallocHost, cudaSetDevice, cudaEventSynchronize, cudaGetDeviceProperties, cudaDeviceSynchronize, cudaEventRecord, cudaFreeHost, cudaMemset, cudaStreamSynchronize, cudaEventDestroy, cudaMemcpyAsync, cudaStreamCreate, cudaGetDeviceCount, cudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Eigenvalues Project Build\nDESCRIPTION: Complete CMake configuration for building a CUDA eigenvalues computation project. Sets up CUDA architectures, compiler flags, includes dependencies, and configures data file copying. Requires CMake 3.20+ and CUDA toolkit.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/eigenvalues/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(eigenvalues LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for eigenvalues\nadd_executable(eigenvalues bisect_large.cu bisect_small.cu bisect_util.cu gerschgorin.cpp main.cu matlab.cpp)\n\ntarget_compile_options(eigenvalues PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(eigenvalues PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(eigenvalues PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n# Copy data files to output directory\nadd_custom_command(TARGET eigenvalues POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/diagonal.dat\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET eigenvalues POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/superdiagonal.dat\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET eigenvalues POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/reference.dat\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for matrixMulCUBLAS CUDA Sample\nDESCRIPTION: Defines the CMake configuration for building the matrixMulCUBLAS sample that demonstrates matrix multiplication using cuBLAS. It specifies CUDA architectures to target, sets up compiler flags, and links required CUDA libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/matrixMulCUBLAS/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(matrixMulCUBLAS LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for matrixMulCUBLAS\nadd_executable(matrixMulCUBLAS matrixMulCUBLAS.cpp)\n\ntarget_compile_options(matrixMulCUBLAS PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(matrixMulCUBLAS PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(matrixMulCUBLAS PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(matrixMulCUBLAS PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(matrixMulCUBLAS PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA SimpleCUBLASXT Project Build\nDESCRIPTION: Sets up a CMake build configuration for a CUDA project using cuBLASXT library. Specifies CUDA architectures, compiler flags, and links required CUDA libraries. Includes debug configuration options and C++17/CUDA 17 language features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUBLASXT/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCUBLASXT LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleCUBLASXT\nadd_executable(simpleCUBLASXT simpleCUBLASXT.cpp)\n\ntarget_compile_options(simpleCUBLASXT PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleCUBLASXT PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleCUBLASXT PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(simpleCUBLASXT PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(simpleCUBLASXT PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Conjugate Gradient Multi-Device Sample\nDESCRIPTION: Complete CMake configuration for building the conjugate gradient multi-device CUDA sample. It specifies required CUDA architecture targets, compiler flags, dependencies (CUDA Toolkit with cuBLAS and cuSPARSE), and enables advanced CUDA features like extended lambda support and separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(conjugateGradientMultiDeviceCG LANGUAGES CUDA CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for conjugateGradientMultiDeviceCG\nadd_executable(conjugateGradientMultiDeviceCG conjugateGradientMultiDeviceCG.cu)\n\ntarget_compile_options(conjugateGradientMultiDeviceCG PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(conjugateGradientMultiDeviceCG PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(conjugateGradientMultiDeviceCG PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_link_libraries(conjugateGradientMultiDeviceCG PRIVATE\n    CUDA::cublas\n    CUDA::cusparse\n)\n```\n\n----------------------------------------\n\nTITLE: Initial CMake and CUDA Configuration\nDESCRIPTION: Sets up basic CMake requirements, project languages, and CUDA architecture targets. Configures CUDA compilation flags and debug settings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cudaNvSciNvMedia/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../../cmake/Modules\")\n\nproject(cudaNvSciNvMedia LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Using CUDA Runtime API for HyperQ Sample\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the simpleHyperQ sample. These functions are essential for memory management, stream creation, event handling, and device property querying in CUDA programming.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleHyperQ/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMemcpy\ncudaStreamDestroy\ncudaMalloc\ncudaFree\ncudaMallocHost\ncudaEventSynchronize\ncudaEventRecord\ncudaFreeHost\ncudaGetDevice\ncudaEventDestroy\ncudaEventElapsedTime\ncudaStreamCreate\ncudaGetDeviceProperties\ncudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Calls Example\nDESCRIPTION: Core CUDA Runtime API functions used in the sample including device synchronization and error string retrieval. These APIs are fundamental for CUDA program flow control and error handling.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleCooperativeGroups/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaDeviceSynchronize();\ncudaGetErrorString();\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Project\nDESCRIPTION: Defines the minimum CMake version, sets up the CMake module path, and specifies the CUDA toolkit requirement. Configures CUDA architectures, special flags, and target properties needed for compiling a CUDA project. The configuration enables position-independent code and sets CUDA separable compilation properties for the 'simpleCudaGraphs' executable target.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/simpleCudaGraphs/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCudaGraphs LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleCudaGraphs\nadd_executable(simpleCudaGraphs simpleCudaGraphs.cu)\n\ntarget_compile_options(simpleCudaGraphs PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleCudaGraphs PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleCudaGraphs PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Stream Ordered Allocation P2P Project\nDESCRIPTION: Sets up the CMake project with CUDA support, specifies CUDA architectures, and configures compiler flags. It also defines the target executable and its properties.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(streamOrderedAllocationP2P LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for streamOrderedAllocationP2P\nadd_executable(streamOrderedAllocationP2P streamOrderedAllocationP2P.cu)\n\ntarget_compile_options(streamOrderedAllocationP2P PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(streamOrderedAllocationP2P PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(streamOrderedAllocationP2P PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Compilation Settings\nDESCRIPTION: Sets CUDA architecture targets, compilation flags, and optional debug settings. It also includes necessary directories for the project.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/vectorAddMMAP/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Configuring OceanFFT Target\nDESCRIPTION: Sets up the main executable target with necessary compiler options, features, and links required libraries. Includes configuration for CUDA separate compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/oceanFFT/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nadd_executable(oceanFFT oceanFFT.cpp oceanFFT_kernel.cu)\n\ntarget_compile_options(oceanFFT PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(oceanFFT PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(oceanFFT PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(oceanFFT PUBLIC\n    ${OPENGL_INCLUDE_DIR}\n    ${CUDAToolkit_INCLUDE_DIRS}\n    ${GLUT_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(oceanFFT\n    ${OPENGL_LIBRARIES}\n    ${GLUT_LIBRARIES}\n    CUDA::cufft\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Project Build Settings with CMake\nDESCRIPTION: Sets up a CUDA project build configuration including minimum CMake version, project languages, CUDA architectures, and compilation settings. Configures build for FP16 scalar product implementation with CUDA support for various GPU architectures from compute capability 6.0 to 12.0.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/fp16ScalarProduct/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(fp16ScalarProduct LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 60 61 70 72 75 80 86 87 89 90 100 101 120)\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for asyncAPI\nadd_executable(fp16ScalarProduct fp16ScalarProduct.cu)\n\ntarget_compile_options(fp16ScalarProduct PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(fp16ScalarProduct PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(fp16ScalarProduct PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Required CUDA Runtime API Functions\nDESCRIPTION: List of CUDA Runtime API functions used in the implementation of bicubic texture interpolation, including memory management, graphics resource handling, and texture operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bicubicTexture/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaGraphicsUnmapResources, cudaCreateChannelDesc, cudaMallocArray, cudaFreeArray, cudaFree, cudaMemcpy, cudaGraphicsResourceGetMappedPointer, cudaGraphicsMapResources, cudaDestroyTextureObject, cudaDeviceSynchronize, cudaCreateTextureObject, cudaGraphicsUnregisterResource, cudaMalloc, cudaGraphicsGLRegisterBuffer, cudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Build with CMake\nDESCRIPTION: Sets up a CMake build configuration for a CUDA application with specific architecture targets and compiler settings. Configures C++17 and CUDA 17 standards, enables extended lambda support, and sets up separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/shfl_scan/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(shfl_scan LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for shfl_scan\nadd_executable(shfl_scan shfl_scan.cu)\n\ntarget_compile_options(shfl_scan PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(shfl_scan PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(shfl_scan PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Setting Up CUDA Project with CMake\nDESCRIPTION: Configures a CMake build for a CUDA project with specific architecture targets, compiler flags, and C++17/CUDA 17 requirements. Includes settings for debug builds, extended lambda support, and separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/asyncAPI/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(asyncAPI LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for asyncAPI\nadd_executable(asyncAPI asyncAPI.cu)\n\ntarget_compile_options(asyncAPI PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(asyncAPI PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(asyncAPI PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Utilizing CUDA Runtime API for Multi-GPU Operations\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the sample. These functions are essential for device management, memory allocation, stream operations, and data transfer in a multi-GPU environment.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleMultiGPU/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaStreamDestroy, cudaFree, cudaMallocHost, cudaSetDevice, cudaFreeHost, cudaStreamSynchronize, cudaMalloc, cudaMemcpyAsync, cudaStreamCreate, cudaGetDeviceCount\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA RadixSort Project with CMake\nDESCRIPTION: CMake configuration that sets up a CUDA project for radix sort implementation using Thrust. Specifies CUDA architectures from compute capability 5.0 to 12.0, enables C++17 features, and configures build properties including separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/radixSortThrust/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(radixSortThrust LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for radixSortThrust\nadd_executable(radixSortThrust radixSortThrust.cu)\n\ntarget_compile_options(radixSortThrust PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(radixSortThrust PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(radixSortThrust PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: CUDA Driver API Function References\nDESCRIPTION: List of CUDA Driver API functions used in the sample for querying device properties and information\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/deviceQueryDrv/README.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncuDeviceGetName, cuDeviceGetAttribute, cuDeviceTotalMem, cuDeviceCanAccessPeer, cuDeviceGetCount, cuDriverGetVersion, cuInit\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Multi-GPU Project in CMake\nDESCRIPTION: Sets up a CMake project for a CUDA-based multi-GPU application. It configures CUDA architecture targets, compiler flags, and defines the build target for the simpleMultiGPU executable. The project uses C++17 and CUDA 17 standards and enables extended lambda support for CUDA.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleMultiGPU/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleMultiGPU LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleMultiGPU\nadd_executable(simpleMultiGPU simpleMultiGPU.cu)\n\ntarget_compile_options(simpleMultiGPU PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleMultiGPU PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleMultiGPU PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Binary Partition CG Project with CMake\nDESCRIPTION: This CMake script sets up a CUDA project named 'binaryPartitionCG'. It configures CUDA architecture targets, compiler flags, and includes necessary dependencies. The script also sets up the main executable target with specific compile options and features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/binaryPartitionCG/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(binaryPartitionCG LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for binaryPartitionCG\nadd_executable(binaryPartitionCG binaryPartitionCG.cu)\n\ntarget_compile_options(binaryPartitionCG PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(binaryPartitionCG PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(binaryPartitionCG PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Compilation Settings\nDESCRIPTION: Specifies the CUDA architectures to compile for, sets CUDA flags including warnings, and optionally enables CUDA debugging. It also includes necessary directories for the project.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUFFT_callback/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Atomic Intrinsics Sample\nDESCRIPTION: Sets up the CMake project for a CUDA sample demonstrating atomic intrinsics. It configures CUDA architectures, compiler flags, and links necessary CUDA libraries. The project uses NVRTC for runtime compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleAtomicIntrinsics_nvrtc LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add sample target executable\nadd_executable(simpleAtomicIntrinsics_nvrtc simpleAtomicIntrinsics_cpu.cpp simpleAtomicIntrinsics.cpp)\n\ntarget_compile_options(simpleAtomicIntrinsics_nvrtc PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleAtomicIntrinsics_nvrtc PRIVATE cxx_std_17 cuda_std_17)\n\ntarget_link_libraries(simpleAtomicIntrinsics_nvrtc PRIVATE\n    CUDA::nvrtc\n    CUDA::cuda_driver\n)\n\n# Copy clock_kernel.cu to the output directory\nadd_custom_command(TARGET simpleAtomicIntrinsics_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/simpleAtomicIntrinsics_kernel.cuh\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Sample Projects with CMake\nDESCRIPTION: CMake configuration that adds subdirectories for various CUDA sample applications. Each subdirectory contains a separate CUDA sample demonstrating different GPU computing capabilities including graphics processing, computational finance, physics simulations, and image processing algorithms.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(BlackScholes)\nadd_subdirectory(BlackScholes_nvrtc)\nadd_subdirectory(FDTD3d)\nadd_subdirectory(HSOpticalFlow)\nadd_subdirectory(Mandelbrot)\nadd_subdirectory(MonteCarloMultiGPU)\nadd_subdirectory(NV12toBGRandResize)\nadd_subdirectory(SobelFilter)\nadd_subdirectory(SobolQRNG)\nadd_subdirectory(bicubicTexture)\nadd_subdirectory(bilateralFilter)\nadd_subdirectory(binomialOptions)\nadd_subdirectory(binomialOptions_nvrtc)\nadd_subdirectory(convolutionFFT2D)\nadd_subdirectory(dwtHaar1D)\nadd_subdirectory(dxtc)\nadd_subdirectory(fastWalshTransform)\nadd_subdirectory(fluidsGL)\nadd_subdirectory(marchingCubes)\nadd_subdirectory(nbody)\nadd_subdirectory(p2pBandwidthLatencyTest)\nadd_subdirectory(postProcessGL)\nadd_subdirectory(quasirandomGenerator)\nadd_subdirectory(quasirandomGenerator_nvrtc)\nadd_subdirectory(recursiveGaussian)\nadd_subdirectory(simpleD3D11)\nadd_subdirectory(simpleD3D11Texture)\nadd_subdirectory(simpleD3D12)\nadd_subdirectory(simpleGL)\nadd_subdirectory(simpleVulkan)\nadd_subdirectory(simpleVulkanMMAP)\nadd_subdirectory(smokeParticles)\nadd_subdirectory(stereoDisparity)\nadd_subdirectory(volumeFiltering)\nadd_subdirectory(volumeRender)\nadd_subdirectory(vulkanImageCUDA)\n```\n\n----------------------------------------\n\nTITLE: Initializing CUDA Runtime API for Multi-GPU CUFFT\nDESCRIPTION: This snippet demonstrates the key CUDA Runtime API functions used in the project for multi-GPU CUFFT operations. It includes device management, memory allocation, and synchronization.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaXtFree\ncudaSetDevice\ncudaGetDeviceCount\ncudaDeviceSynchronize\ncudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Using CUDA Driver API for Vector Addition\nDESCRIPTION: This sample shows how to perform vector addition using the CUDA Driver API with NVRTC runtime compilation. It includes memory management with cuMemAlloc/Free, data transfer with cuMemcpyHtoD/DtoH, and kernel execution with cuLaunchKernel.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/vectorAdd_nvrtc/README.md#2025-04-21_snippet_0\n\n\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA conjugateGradientUM\nDESCRIPTION: This CMake script configures the build environment for the conjugateGradientUM CUDA sample. It sets the minimum CMake version, configures CUDA architectures (from Compute Capability 5.0 to 12.0), and defines the executable target with its dependencies on CUDA runtime, cuBLAS, and cuSPARSE libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/conjugateGradientUM/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(conjugateGradientUM LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for conjugateGradientUM\nadd_executable(conjugateGradientUM main.cpp)\n\ntarget_compile_options(conjugateGradientUM PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(conjugateGradientUM PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(conjugateGradientUM PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(conjugateGradientUM PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(conjugateGradientUM PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n    CUDA::cusparse\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Dependencies\nDESCRIPTION: List of required CUDA Runtime API functions used in the implementation including memory management, stream handling, and device property queries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpSimpleQuicksort/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaStreamCreateWithFlags, cudaMemcpy, cudaStreamDestroy, cudaFree, cudaDeviceSynchronize, cudaDeviceSetLimit, cudaMalloc, cudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Defining Managed Global Variables in NVVM IR\nDESCRIPTION: Shows how to define a global variable in address space 1 and mark it as managed using metadata in NVVM IR. The metadata attribute enables the variable to be accessed directly from both host and device code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/uvmlite/README.md#2025-04-21_snippet_0\n\nLANGUAGE: IR\nCODE:\n```\n@xxx = internal addrspace(1) global i32 10, align 4\n\n...\n\n!1 = !{i32 addrspace(1)* @xxx, !\"managed\", i32 1}\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Function Calls for Ocean Simulation\nDESCRIPTION: Core CUDA runtime API functions used for graphics resource management, memory operations, and custom kernels for ocean simulation. Includes functions for graphics mapping, memory allocation, and height map generation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/oceanFFT/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaGraphicsUnmapResources\ncudaMemcpy\ncudaMalloc\ncudaFree\ncudaGraphicsResourceGetMappedPointer\ncudaCalculateSlopeKernel\ncudaGraphicsMapResources\ncudaUpdateHeightmapKernel\ncudaGraphicsUnregisterResource\ncudaGenerateSpectrumKernel\ncudaGraphicsGLRegisterBuffer\ncudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Functions\nDESCRIPTION: Core CUDA Runtime API functions used for topology querying - cudaGetDeviceCount for enumerating available GPUs and cudaDeviceGetAttribute for getting specific device attributes.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/topologyQuery/README.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncudaGetDeviceCount, cudaDeviceGetAttribute\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA simpleP2P Sample\nDESCRIPTION: Complete CMake configuration for building the CUDA simpleP2P sample. It sets minimum CMake version, defines CUDA architectures, configures compiler flags, and conditionally builds the executable except on aarch64 platforms. The script enables C++17 and CUDA 17 standards with separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleP2P/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleP2P LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleP2P\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    message(STATUS \"Will not build sample simpleP2P - not supported on aarch64\")\nelse()\n    add_executable(simpleP2P simpleP2P.cu)\n\n    target_compile_options(simpleP2P PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(simpleP2P PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(simpleP2P PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Tensor Core GEMM Project\nDESCRIPTION: Sets up the CMake project for CUDA Tensor Core GEMM, including CUDA toolkit discovery, architecture settings, and compiler flags. It also defines the executable target and its properties.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cudaTensorCoreGemm/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cudaTensorCoreGemm LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for cudaTensorCoreGemm\nadd_executable(cudaTensorCoreGemm cudaTensorCoreGemm.cu)\n\ntarget_compile_options(cudaTensorCoreGemm PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cudaTensorCoreGemm PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cudaTensorCoreGemm PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA simpleZeroCopy Project\nDESCRIPTION: Sets up a CMake project for a CUDA sample application that demonstrates zero-copy memory operations. It configures CUDA architecture targets from Compute Capability 5.0 to 12.0, sets necessary compiler flags, and creates an executable with C++17 and CUDA 17 support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleZeroCopy/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleZeroCopy LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleZeroCopy\nadd_executable(simpleZeroCopy simpleZeroCopy.cu)\n\ntarget_compile_options(simpleZeroCopy PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleZeroCopy PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleZeroCopy PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA simpleCubemapTexture Project\nDESCRIPTION: This CMake script configures the build environment for a CUDA sample application. It sets the minimum CMake version, defines project languages, configures CUDA architecture targets (from Compute Capability 5.0 to 12.0), adds compiler flags, and sets up the executable target with C++17 and CUDA 17 support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleCubemapTexture/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCubemapTexture LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleCubemapTexture\nadd_executable(simpleCubemapTexture simpleCubemapTexture.cu)\n\ntarget_compile_options(simpleCubemapTexture PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleCubemapTexture PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleCubemapTexture PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA-based Sobol QRNG\nDESCRIPTION: This snippet sets up the CMake project, specifies language requirements, and configures CUDA-specific settings. It sets the minimum CMake version, defines the project name and languages, and configures CUDA architecture targets and compiler flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/SobolQRNG/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(SobolQRNG LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting up CUDA architecture targets for Mandelbrot sample\nDESCRIPTION: Configures the CUDA architectures supported by the build and sets CUDA compiler flags. Targets a range of CUDA compute capabilities from 5.0 to 12.0 and disables deprecated GPU target warnings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/Mandelbrot/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Defining CMake Targets and Properties for CUDA\nDESCRIPTION: This snippet demonstrates adding an executable target for the Tensor Core GEMM CUDA sample, specifying source files, setting compile options, and enabling specific compile features for CUDA and C++. It ensures that the compilation process takes advantage of advanced C++ and CUDA features and enables separable compilation for CUDA.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/tf32TensorCoreGemm/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for tf32TensorCoreGemm\nadd_executable(tf32TensorCoreGemm tf32TensorCoreGemm.cu)\n\ntarget_compile_options(tf32TensorCoreGemm PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(tf32TensorCoreGemm PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(tf32TensorCoreGemm PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Function List\nDESCRIPTION: List of CUDA Runtime API functions used in the NVJPEG encoder sample, including memory management, event handling, and device property queries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/nvJPEG_encoder/README.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncudaFree, cudaGetErrorString, cudaEventSynchronize, cudaDeviceSynchronize, cudaEventRecord, cudaMalloc, cudaEventElapsedTime, cudaGetDeviceProperties, cudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Build Properties\nDESCRIPTION: Sets up CUDA-specific build properties including compiler flags, debug options, and compilation features. Enables extended lambda support and C++17/CUDA 17 standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpSimplePrint/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\ntarget_compile_options(cdpSimplePrint PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cdpSimplePrint PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cdpSimplePrint PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Multi-GPU CUFFT Project Build\nDESCRIPTION: CMake configuration that sets up a CUDA project for 2D FFT operations on multiple GPUs. Defines CUDA architecture targets from compute capability 5.0 to 12.0, enables C++17 and CUDA 17 features, and links against the CUFFT library. Includes debug options and platform-specific adjustments for MSVC.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCUFFT_2d_MGPU LANGUAGES CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleCUFFT_2d_MGPU\nadd_executable(simpleCUFFT_2d_MGPU simpleCUFFT_2d_MGPU.cu)\n\nif(MSVC)\n    add_compile_definitions(_USE_MATH_DEFINES)\nendif()\n\ntarget_compile_options(simpleCUFFT_2d_MGPU PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleCUFFT_2d_MGPU PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleCUFFT_2d_MGPU PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_link_libraries(simpleCUFFT_2d_MGPU PRIVATE\n    CUDA::cufft\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Sample Project with CMake\nDESCRIPTION: Sets up the CMake project for cuSolverSp_LowlevelCholesky, including CUDA toolkit, compiler flags, and target properties. It also configures the executable target with necessary include directories and libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cuSolverSp_LowlevelCholesky LANGUAGES C CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for cuSolverSp_LowlevelCholesky\nadd_executable(cuSolverSp_LowlevelCholesky cuSolverSp_LowlevelCholesky.cpp mmio.c mmio_wrapper.cpp)\n\ntarget_compile_options(cuSolverSp_LowlevelCholesky PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cuSolverSp_LowlevelCholesky PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cuSolverSp_LowlevelCholesky PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(cuSolverSp_LowlevelCholesky PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(cuSolverSp_LowlevelCholesky PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n    CUDA::cusolver\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Dependencies\nDESCRIPTION: List of CUDA Runtime API functions required for the implementation of advanced quicksort algorithm with Dynamic Parallelism. These APIs handle memory management, event handling, stream creation, and device properties.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpAdvancedQuicksort/README.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncudaStreamCreateWithFlags, cudaMemcpy, cudaMemcpyAsync, cudaFree, cudaGetErrorString, cudaGetLastError, cudaPeekAtLastError, cudaDeviceSynchronize, cudaEventRecord, cudaMemset, cudaMalloc, cudaEventElapsedTime, cudaGetDeviceProperties, cudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Utilizing CUDA Runtime API for FDTD3d Implementation\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the FDTD3d sample. These functions handle memory management, device properties, synchronization, event handling, and symbol copying, which are essential for implementing the 3D FDTD algorithm efficiently on CUDA-enabled GPUs.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/FDTD3d/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA C\nCODE:\n```\ncudaMemcpy, cudaMalloc, cudaFree, cudaFuncGetAttributes, cudaSetDevice, cudaGetDeviceProperties, cudaDeviceSynchronize, cudaEventRecord, cudaMemcpyToSymbol, cudaEventDestroy, cudaEventElapsedTime, cudaGetDeviceCount, cudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Configuring Target Build with Dependencies for cuDLALayerwiseStatsStandalone\nDESCRIPTION: Creates and configures the executable target when all dependencies are found. Sets compiler options, C++/CUDA standards, CUDA compilation properties, include directories, and links against required libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLALayerwiseStatsStandalone/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\n        if(NVSCIBUF_LIB AND NVSCISYNC_LIB AND NVSCIBUF_INCLUDE_DIR AND NVSCISYNC_INCLUDE_DIR)\n            # Source file\n            # Add target for cuDLALayerwiseStatsStandalone\n            add_executable(cuDLALayerwiseStatsStandalone main.cpp)\n\n            target_compile_options(cuDLALayerwiseStatsStandalone PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n            target_compile_features(cuDLALayerwiseStatsStandalone PRIVATE cxx_std_17 cuda_std_17)\n\n            set_target_properties(cuDLALayerwiseStatsStandalone PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n            target_include_directories(cuDLALayerwiseStatsStandalone PUBLIC\n                ${CUDAToolkit_INCLUDE_DIRS}\n                ${NVSCIBUF_INCLUDE_DIR}\n                ${NVSCISYNC_INCLUDE_DIR}\n            )\n\n            target_link_libraries(cuDLALayerwiseStatsStandalone\n                ${CUDLA_LIB}\n                ${NVSCIBUF_LIB}\n                ${NVSCISYNC_LIB}\n            )\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Functions for Segmentation Tree Implementation\nDESCRIPTION: Core CUDA Runtime API functions used in the implementation of segmentation tree construction. These functions handle memory management, event synchronization, and timing operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMemcpy\ncudaMemGetInfo\ncudaEventSynchronize\ncudaEventRecord\ncudaMemset\ncudaEventElapsedTime\ncudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Function Usage\nDESCRIPTION: Core CUDA Runtime API functions used in the merge sort implementation including memory allocation, synchronization, data transfer, and cleanup.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/mergeSort/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMalloc\ncudaDeviceSynchronize\ncudaMemcpy\ncudaFree\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Clock Sample with CMake\nDESCRIPTION: Complete CMake configuration for building the clock_nvrtc CUDA sample. It sets up CUDA architectures, compiler flags, and dependencies including NVRTC for runtime compilation. The configuration also ensures the CUDA kernel file is copied to the build directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/clock_nvrtc/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(clock_nvrtc LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add sample target executable\nadd_executable(clock_nvrtc clock.cpp)\n\ntarget_compile_options(clock_nvrtc PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(clock_nvrtc PRIVATE cxx_std_17 cuda_std_17)\n\ntarget_link_libraries(clock_nvrtc PRIVATE\n    CUDA::nvrtc\n    CUDA::cuda_driver\n)\n\n# Copy clock_kernel.cu to the output directory\nadd_custom_command(TARGET clock_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/clock_kernel.cu ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture Targets and Compiler Flags\nDESCRIPTION: Configures CUDA architecture targets, compilation flags, and debug settings. Supports multiple CUDA compute capabilities from SM 5.0 to SM 12.0.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simplePrintf/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Sample Project with CMake\nDESCRIPTION: This CMake script sets up a CUDA project named 'inlinePTX'. It configures CUDA compilation flags, sets target architectures, and defines build options. The script also sets up include directories and creates an executable target.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/inlinePTX/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(inlinePTX LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for inlinePTX\nadd_executable(inlinePTX inlinePTX.cu)\n\ntarget_compile_options(inlinePTX PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(inlinePTX PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(inlinePTX PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Project with CMake\nDESCRIPTION: Sets up a CUDA project named 'newdelete' with specific CUDA architectures, compiler flags, and build options. It includes necessary modules, sets CUDA flags, and configures an executable target with C++17 and CUDA 17 standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/newdelete/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(newdelete LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for newdelete\nadd_executable(newdelete newdelete.cu)\n\ntarget_compile_options(newdelete PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(newdelete PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(newdelete PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architecture Targets for conjugateGradientCudaGraphs\nDESCRIPTION: Sets the target CUDA architectures for compilation, supporting a wide range of NVIDIA GPU generations from compute capability 5.0 to 12.0. Also disables warnings for deprecated GPU targets.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: CUDA Graph Memory Management Documentation\nDESCRIPTION: Documentation for a CUDA sample that demonstrates graph memory node behavior, including memory allocation, deallocation, and reuse patterns. The sample works across multiple SM architectures and operating systems.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/graphMemoryFootprint/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# graphMemoryFootprint - Graph Memory Footprint\n\n## Description\n\nThis sample demonstrates how graph memory nodes re-use virtual addresses and physical memory.\n\n## Key Concepts\n\nCUDA Runtime API, Performance Strategies, CUDA Graphs\n\n## Supported SM Architectures\n\n[SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.9 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)\n\n## Supported OSes\n\nLinux, Windows\n\n## Supported CPU Architecture\n\nx86_64, armv7l\n```\n\n----------------------------------------\n\nTITLE: Verifying LU Decomposition Result in CUDA\nDESCRIPTION: This section verifies the result of the LU decomposition. It reports a successful test with a precision of 1e-15, indicating high accuracy in the computation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleCUBLAS_LU.txt#2025-04-21_snippet_4\n\nLANGUAGE: CUDA\nCODE:\n```\n> verifying the result..\n> TEST SUCCESSFUL, with precision: 1e-15\n```\n\n----------------------------------------\n\nTITLE: Configuring Build Target and Compiler Options\nDESCRIPTION: Defines the main executable target, sets up include directories, and configures compiler options including C++17 and CUDA 17 support with extended lambda features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(segmentationTreeThrust segmentationTree.cu)\n\ntarget_compile_options(segmentationTreeThrust PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(segmentationTreeThrust PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(segmentationTreeThrust PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: CMake Project Configuration for CUDA Cooperative Groups\nDESCRIPTION: Complete CMake configuration for building a CUDA Cooperative Groups sample. Sets minimum CMake version, project languages, CUDA architectures, compiler flags, and target properties. Includes debug configuration options and C++17/CUDA 17 feature requirements.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleCooperativeGroups/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCooperativeGroups LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleCooperativeGroups\nadd_executable(simpleCooperativeGroups simpleCooperativeGroups.cu)\n\ntarget_compile_options(simpleCooperativeGroups PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleCooperativeGroups PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleCooperativeGroups PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions Used in UnifiedMemoryStreams\nDESCRIPTION: This code block lists the CUDA Runtime API functions utilized in the UnifiedMemoryStreams sample. These functions are essential for managing CUDA streams, device properties, and Unified Memory allocations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/UnifiedMemoryStreams/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\ncudaStreamDestroy, cudaFree, cudaMallocManaged, cudaStreamAttachMemAsync, cudaSetDevice, cudaDeviceSynchronize, cudaStreamSynchronize, cudaStreamCreate, cudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Finding Required Dependencies for nbody_opengles\nDESCRIPTION: Locates the necessary system libraries including EGL, X11, and OpenGL that are required for building the nbody_opengles sample. Also includes common header files from the CUDA samples directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/nbody_opengles/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../../Common)\n\nfind_package(EGL)\nfind_package(X11)\nfind_package(OpenGL)\n```\n\n----------------------------------------\n\nTITLE: CUDA API References for Zero Copy Memory Operations\nDESCRIPTION: List of CUDA Runtime API functions used for zero copy memory management, including memory allocation, device management, and host memory operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleZeroCopy/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaHostAlloc, cudaSetDeviceFlags, cudaHostRegister, cudaSetDevice, cudaGetDeviceCount, cudaHostGetDevicePointer, cudaDeviceSynchronize, cudaFreeHost, cudaGetDeviceProperties, cudaHostUnregister\n```\n\n----------------------------------------\n\nTITLE: Using CUDA Runtime API for Sobol QRNG\nDESCRIPTION: This snippet outlines the CUDA Runtime API functions used in the SobolQRNG sample. It includes memory management, error handling, device synchronization, and device property queries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/SobolQRNG/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMemcpy\ncudaGetErrorString\ncudaFree\ncudaDeviceSynchronize\ncudaGetDevice\ncudaMalloc\ncudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Functions Used in NVJPEG Sample\nDESCRIPTION: A list of CUDA Runtime API functions used in the NVJPEG sample application, including memory management, stream operations, event handling, and device property querying functions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/nvJPEG/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaHostAlloc, cudaStreamCreateWithFlags, cudaStreamDestroy, cudaFree, cudaEventSynchronize, cudaEventRecord, cudaFreeHost, cudaStreamSynchronize, cudaMalloc, cudaEventElapsedTime, cudaGetDeviceProperties, cudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Reduction Project\nDESCRIPTION: Sets up the CMake project for a CUDA-based reduction algorithm. It specifies CUDA architectures, compiler flags, and includes necessary dependencies. The script also configures the main executable target with appropriate compile options and features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/reduction/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(reduction LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for reduction\nadd_executable(reduction reduction.cpp reduction_kernel.cu)\n\ntarget_compile_options(reduction PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(reduction PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(reduction PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(reduction PUBLIC\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA simpleVoteIntrinsics Sample\nDESCRIPTION: This CMake configuration sets up a CUDA project that demonstrates vote intrinsics. It specifies CUDA architectures to target, compiler flags, and dependencies. The configuration enables C++17 and CUDA 17 standards and sets up separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleVoteIntrinsics/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleVoteIntrinsics LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleVoteIntrinsics\nadd_executable(simpleVoteIntrinsics simpleVoteIntrinsics.cu)\n\ntarget_compile_options(simpleVoteIntrinsics PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleVoteIntrinsics PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleVoteIntrinsics PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA Box Filter\nDESCRIPTION: Sets up the CMake project with CUDA, C, and C++ language support. It also configures CUDA architecture targets and compiler flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/boxFilter/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(boxFilter LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA Particles\nDESCRIPTION: Sets up the CMake project, defines CUDA architectures, and configures compiler flags for the particles sample.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/particles/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(particles LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Scan Project with CMake\nDESCRIPTION: Sets up a CUDA project named 'scan' with specific CUDA architectures, compiler flags, and dependencies. It includes configuration for debug builds, CUDA-specific compile options, and C++17 features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/scan/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(scan LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for scan\nadd_executable(scan main.cpp scan_gold.cpp scan.cu)\n\ntarget_compile_options(scan PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(scan PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(scan PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(scan PUBLIC\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Creating matrixMul_nvrtc Executable Target\nDESCRIPTION: Sets up the include directories, creates the executable target, and configures compiler options. Specifies C++17 and CUDA 17 standards and links against required NVRTC libraries for runtime compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/matrixMul_nvrtc/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add sample target executable\nadd_executable(matrixMul_nvrtc matrixMul.cpp)\n\ntarget_compile_options(matrixMul_nvrtc PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(matrixMul_nvrtc PRIVATE cxx_std_17 cuda_std_17)\n\ntarget_link_libraries(matrixMul_nvrtc PRIVATE\n    CUDA::nvrtc\n    CUDA::cuda_driver\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA Scalar Product Execution Log\nDESCRIPTION: Console output showing initialization, execution and validation steps of a CUDA scalar product calculation. The program runs on a Hopper GPU with compute capability 9.0 and validates results against a CPU implementation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_scalarProd.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n./scalarProd Starting...\n\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nInitializing data...\n...allocating CPU memory.\n...allocating GPU memory.\n...generating input data in CPU mem.\n...copying input data to GPU mem.\nData init done.\nExecuting GPU kernel...\nGPU time: 0.042000 msecs.\nReading back GPU result...\nChecking GPU results...\n..running CPU scalar product calculation\n...comparing the results\nShutting down...\nL1 error: 2.745062E-08\nTest passed\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Usage for Binary Partition Operations\nDESCRIPTION: List of CUDA Runtime API functions used in the sample including stream management, memory allocation, and asynchronous operations. The implementation requires CUDA Toolkit 12.5 and supports SM architectures from 5.0 to 9.0.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/binaryPartitionCG/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaStreamCreateWithFlags\ncudaFree\ncudaMallocHost\ncudaFreeHost\ncudaStreamSynchronize\ncudaMalloc\ncudaMemsetAsync\ncudaMemcpyAsync\ncudaOccupancyMaxPotentialBlockSize\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Clock Sample Project\nDESCRIPTION: Sets up the CMake project for a CUDA clock sample, including CUDA architecture targets, compiler flags, and dependencies. It defines the project structure, sets CUDA-specific options, and creates the executable target.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/clock/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(clock LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for asyncAPI\nadd_executable(clock clock.cu)\n\ntarget_compile_options(clock PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(clock PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(clock PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Freeing GPU Memory in CUDA\nDESCRIPTION: This snippet demonstrates the use of cudaFree to release memory allocated on the GPU. It's important for proper memory management and preventing memory leaks.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/scalarProd/README.md#2025-04-21_snippet_3\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaFree\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the sample project. These functions are essential for device synchronization, memory allocation, device property retrieval, and memory deallocation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/systemWideAtomics/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n### [CUDA Runtime API](http://docs.nvidia.com/cuda/cuda-runtime-api/index.html)\ncudaDeviceSynchronize, cudaMallocManaged, cudaGetDeviceProperties, cudaFree\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architecture and Compilation Flags\nDESCRIPTION: Specifies CUDA architecture targets and compilation flags, including debug options and deprecated GPU target warnings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/FDTD3d/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Build for CUDA GLES EGL Sample\nDESCRIPTION: Sets up a CMake build configuration for a CUDA sample project that uses OpenGL ES and EGL. Includes CUDA architecture settings, dependency checks for EGL/X11/OpenGL, and target configuration with necessary libraries and include paths. Specifically designed for Linux systems with proper graphics drivers and libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/simpleGLES_EGLOutput/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../../cmake/Modules\")\n\nproject(simpleGLES_EGLOutput LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../../Common)\n\nfind_package(EGL)\nfind_package(X11)\nfind_package(OpenGL)\n\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    if(${OpenGL_FOUND})\n        if(${EGL_FOUND})\n            if(${X11_FOUND})\n                set(DRM_INCLUDE_PATH \"/usr/include/drm\" \"/usr/include/libdrm\")\n\n                # use CMAKE_LIBRARY_PATH so that users can also specify the NVSCI lib path in cmake command\n                set(CMAKE_LIBRARY_PATH \"/usr/lib/${CMAKE_SYSTEM_PROCESSOR}-linux-gnu\" ${CMAKE_LIBRARY_PATH})\n                find_library(DRM_LIB drm PATHS ${CMAKE_LIBRARY_PATH})\n\n                # Source file\n                # Add target for simpleGLES_EGLOutput\n                add_executable(simpleGLES_EGLOutput simpleGLES_EGLOutput.cu)\n                target_compile_options(simpleGLES_EGLOutput PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n                target_compile_features(simpleGLES_EGLOutput PRIVATE cxx_std_17 cuda_std_17)\n\n                set_target_properties(simpleGLES_EGLOutput PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n                target_include_directories(simpleGLES_EGLOutput PUBLIC\n                    ${EGL_INCLUDE_DIR}\n                    ${OPENGL_INCLUDE_DIR}\n                    ${CUDAToolkit_INCLUDE_DIR}\n                    ${DRM_INCLUDE_PATH}\n                )\n\n                target_link_libraries(simpleGLES_EGLOutput\n                    ${EGL_LIBRARY}\n                    ${X11_LIBRARIES}\n                    ${OPENGL_LIBRARIES}\n                    ${DRM_LIB}\n                )\n\n                # Copy the .glsl files to the output directory\n                add_custom_command(TARGET simpleGLES_EGLOutput POST_BUILD\n                    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n                    ${CMAKE_CURRENT_SOURCE_DIR}/mesh.frag.glsl\n                    ${CMAKE_CURRENT_SOURCE_DIR}/mesh.vert.glsl\n                    ${CMAKE_CURRENT_BINARY_DIR}\n                )\n            else()\n                message(STATUS \"X11 libraries not found - will not build sample 'simpleGLES_EGLOutput'\")\n            endif()\n        else()\n            message(STATUS \"EGL not found - will not build sample 'simpleGLES_EGLOutput'\")\n        endif()\n    else()\n        message(STATUS \"OpenGL not found - will not build sample 'simpleGLES_EGLOutput'\")\n    endif()\nelse()\n    message(STATUS \"Will not build sample simpleGLES_EGLOutput - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Function List\nDESCRIPTION: List of CUDA Runtime API functions used in the sample, including memory management and device synchronization functions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/inlinePTX/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMemcpy\ncudaFree\ncudaMallocHost\ncudaGetLastError\ncudaGridSize\ncudaBlockSize\ncudaDeviceSynchronize\ncudaFreeHost\ncudaMalloc\n```\n\n----------------------------------------\n\nTITLE: Running radixSort with Default Options\nDESCRIPTION: Command to run the radixSort executable with default settings, which sorts 1M unsigned integer key-value pairs.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/radixSortThrust/doc/readme.txt#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nradixSort.exe\n```\n\n----------------------------------------\n\nTITLE: Launching CUDA Kernel for Complex Pointwise Multiplication and Scaling\nDESCRIPTION: This snippet shows the launch of a CUDA kernel named ComplexPointwiseMulAndScale. The kernel likely performs element-wise multiplication and scaling operations on complex data after FFT transformation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleCUFFT.txt#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\nLaunching ComplexPointwiseMulAndScale<<< >>>\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Usage for NV12 to BGR Conversion\nDESCRIPTION: List of CUDA Runtime API functions used in the implementation for memory management, stream handling, texture operations, and event synchronization. These APIs are essential for GPU-based video frame processing.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/NV12toBGRandResize/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMemcpy\ncudaStreamDestroy\ncudaMalloc\ncudaFree\ncudaMallocManaged\ncudaStreamAttachMemAsync\ncudaDestroyTextureObject\ncudaEventSynchronize\ncudaDeviceSynchronize\ncudaCreateTextureObject\ncudaEventRecord\ncudaEventDestroy\ncudaEventElapsedTime\ncudaStreamCreate\ncudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake and CUDA for cuSolverSp_LowlevelQR Project\nDESCRIPTION: This snippet sets up the CMake project, finds the CUDA toolkit, and configures CUDA-specific settings including architecture targets and compiler flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cuSolverSp_LowlevelQR LANGUAGES C CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Multi-GPU FFT Project Build\nDESCRIPTION: Sets up a CMake build configuration for a CUDA FFT example targeting multiple GPU architectures. Configures CUDA compiler flags, includes required dependencies, and sets up build targets with specific compilation features and linking requirements.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCUFFT_MGPU LANGUAGES CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleCUFFT_MGPU\nadd_executable(simpleCUFFT_MGPU simpleCUFFT_MGPU.cu)\n\ntarget_compile_options(simpleCUFFT_MGPU PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleCUFFT_MGPU PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleCUFFT_MGPU PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_link_libraries(simpleCUFFT_MGPU PRIVATE\n    CUDA::cufft\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA SimpleGLES Project Build Settings\nDESCRIPTION: Sets up the basic project configuration including CUDA architecture targets, compiler flags, and required dependencies. Configures position-independent code and adds debug options if needed.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/simpleGLES/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../../cmake/Modules\")\n\nproject(simpleGLES LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\ninclude_directories(../../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture Targets for randomFog Sample\nDESCRIPTION: Configures the CUDA architectures to be supported by the build, including compute capabilities from 5.0 to 12.0. Sets CUDA compiler flags including a warning suppression for deprecated GPU targets.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/randomFog/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Using CUDA Runtime API for Eigenvalue Computation\nDESCRIPTION: This snippet outlines the CUDA Runtime API functions used in the eigenvalues sample. It includes memory allocation, device synchronization, memory copying, and deallocation operations essential for GPU-based computations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/eigenvalues/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMalloc, cudaDeviceSynchronize, cudaMemcpy, cudaFree\n```\n\n----------------------------------------\n\nTITLE: Required CUDA Runtime API Functions\nDESCRIPTION: List of essential CUDA Runtime API functions used in the implementation of texture-based convolution. These functions handle memory management, texture operations, and device synchronization.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/convolutionTexture/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMemcpy\ncudaMallocArray\ncudaFreeArray\ncudaFree\ncudaMemcpyToArray\ncudaDeviceSynchronize\ncudaCreateTextureObject\ncudaMemcpyToSymbol\ncudaMalloc\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Simple Quicksort Project\nDESCRIPTION: Sets up the CMake project for a CUDA-based simple quicksort implementation. It configures CUDA architectures based on the system processor, sets compiler flags, and defines build options for the executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpSimpleQuicksort/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cdpSimpleQuicksort LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    # Need to differentiate Tegra_aarch64 and other aarch64 systems(sbsa_aarch64) as they have different CUDA_ARCHITECTURES list\n    if(${BUILD_TEGRA})\n        set(CMAKE_CUDA_ARCHITECTURES 72 87 101)\n    else()\n        set(CMAKE_CUDA_ARCHITECTURES 61 70 75 80 86 90)\n    endif()\nelse()\n    set(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 75 80 86 89 90 100 101 120)\nendif()\n\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for cdpSimpleQuicksort\nadd_executable(cdpSimpleQuicksort cdpSimpleQuicksort.cu)\n\ntarget_compile_options(cdpSimpleQuicksort PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cdpSimpleQuicksort PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cdpSimpleQuicksort PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for EGLSync_CUDAEvent_Interop CUDA Project\nDESCRIPTION: Sets up the CMake project for EGLSync_CUDAEvent_Interop, including CUDA architectures, compilation flags, and required packages. It also defines the target executable and its dependencies, with conditional compilation based on the presence of required libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/EGLSync_CUDAEvent_Interop/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../../cmake/Modules\")\n\nproject(EGLSync_CUDAEvent_Interop LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nfind_package(EGL)\nfind_package(X11)\nfind_package(OpenGL)\n\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    # Source file\n    if(${OpenGL_FOUND})\n        if(${EGL_FOUND})\n            if(${X11_FOUND})\n                # Add target for EGLSync_CUDAEvent_Interop\n                add_executable(EGLSync_CUDAEvent_Interop EGLSync_CUDAEvent_Interop.cu)\n\n                target_compile_options(EGLSync_CUDAEvent_Interop PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n                target_compile_features(EGLSync_CUDAEvent_Interop PRIVATE cxx_std_17 cuda_std_17)\n\n                set_target_properties(EGLSync_CUDAEvent_Interop PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n                target_include_directories(EGLSync_CUDAEvent_Interop PUBLIC\n                    ${CUDAToolkit_INCLUDE_DIRS}\n                    ${EGL_INCLUDE_DIR}\n                    ${X11_INCLUDE_DIR}\n                    ${OPENGL_INCLUDE_DIR}\n                )\n\n                target_link_libraries(EGLSync_CUDAEvent_Interop\n                    CUDA::cuda_driver\n                    #CUDA::cudart\n                    ${EGL_LIBRARY}\n                    ${X11_LIBRARIES}\n                    ${OPENGL_LIBRARIES}\n                )\n            else()\n                message(STATUS \"X11 libraries not found - will not build sample 'EGLSyncCUDAEvent_Interop'\")\n            endif()\n        else()\n            message(STATUS \"EGL not found - will not build sample 'EGLSync_CUDAEvent_Interop'\")\n        endif()\n    else()\n        message(STATUS \"OpenGL not found - will not build sample 'EGLSync_CUDAEvent_Interop'\")\n    endif()\nelse()\n    message(STATUS \"Will not build sample EGLSync_CUDAEvent_Interop\\n - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Sorting Networks Executable Target\nDESCRIPTION: Configures the main executable target with source files, compilation options, and C++/CUDA standard requirements.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/sortingNetworks/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(sortingNetworks main.cpp bitonicSort.cu sortingNetworks_validate.cpp)\n\ntarget_compile_options(sortingNetworks PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(sortingNetworks PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(sortingNetworks PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(sortingNetworks PUBLIC\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Samples Project with CMake\nDESCRIPTION: This CMake script sets up the CUDA Samples project, configuring C++, CUDA, and build settings. It specifies language standards, CUDA architectures, and compiler flags for the project.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cuda-samples LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\n\nset(CMAKE_CUDA_STANDARD 17)\nset(CMAKE_CUDA_STANDARD_REQUIRED ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} --extended-lambda\")\n\nadd_subdirectory(Samples)\n```\n\n----------------------------------------\n\nTITLE: Initializing CUDA Runtime API Functions\nDESCRIPTION: Core CUDA Runtime API functions used in the project for memory management and error handling. These functions handle device memory allocation, data transfer between host and device, and cleanup operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/randomFog/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMalloc\ncudaGetErrorString\ncudaMemcpy\ncudaFree\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Build Settings\nDESCRIPTION: Sets up basic CMake and CUDA configuration including supported architectures and compiler flags. Establishes project languages and finds required CUDA toolkit.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/oceanFFT/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(oceanFFT LANGUAGES CUDA CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake CUDA Project Settings\nDESCRIPTION: Initial CMake configuration including minimum version, project languages, and CUDA toolkit dependencies. Sets up position independent code and CUDA architecture targets.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(MC_EstimatePiP LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Initializing CUDA FDTD3d Project Configuration\nDESCRIPTION: Sets up basic CMake project configuration including required version, project languages, and CUDA toolkit dependency.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/FDTD3d/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(FDTD3d LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architectures and Compilation Flags\nDESCRIPTION: Sets supported CUDA architectures, disables deprecated GPU target warnings, and configures debug compilation options\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/binomialOptions_nvrtc/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Build Settings\nDESCRIPTION: Sets up basic CMake configuration including CUDA architecture targets and compiler flags. Establishes project languages and minimum CMake version requirements.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/bindlessTexture/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(bindlessTexture LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Verifying Managed Memory Status with CUDA Runtime\nDESCRIPTION: Shows how to query if a pointer points to managed memory using cuPointerGetAttribute() with the CU_POINTER_ATTRIBUTE_IS_MANAGED attribute. Returns 1 if the memory is managed or 0 otherwise.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/uvmlite/README.md#2025-04-21_snippet_2\n\nLANGUAGE: C\nCODE:\n```\nunsigned int attrVal;\nresult = cuPointerGetAttribute(&attrVal, CU_POINTER_ATTRIBUTE_IS_MANAGED, devp_xxx);\n// result will be 1 if the pointer is managed or zero otherwise.\n```\n\n----------------------------------------\n\nTITLE: CUDA API Dependencies\nDESCRIPTION: Lists the required CUDA Driver and Runtime API functions needed for memory management, kernel execution, and synchronization.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/clock_nvrtc/README.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncuMemcpyDtoH, cuLaunchKernel, cuMemcpyHtoD, cuCtxSynchronize, cuMemAlloc, cuMemFree, cuModuleGetFunction, cudaBlockSize, cudaGridSize\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Black-Scholes Project\nDESCRIPTION: Sets up the CMake project for a CUDA-based Black-Scholes model. It specifies the minimum CMake version, project languages, finds the CUDA toolkit, and sets various CUDA-related flags and architectures.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/BlackScholes/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(BlackScholes LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Command for CUDA Kernel Compilation\nDESCRIPTION: Defines a custom command to compile the CUDA kernel into a fatbin file using nvcc.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTextureDrv/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nset(CUDA_FATBIN_FILE \"${CMAKE_CURRENT_BINARY_DIR}/simpleTexture_kernel64.fatbin\")\nset(CUDA_KERNEL_SOURCE \"${CMAKE_CURRENT_SOURCE_DIR}/simpleTexture_kernel.cu\")\n\nadd_custom_command(\n    OUTPUT ${CUDA_FATBIN_FILE}\n    COMMAND ${CMAKE_CUDA_COMPILER} ${INCLUDES} ${ALL_CCFLAGS} -Wno-deprecated-gpu-targets  ${GENCODE_FLAGS} -o ${CUDA_FATBIN_FILE} -fatbin ${CUDA_KERNEL_SOURCE}\n    DEPENDS ${CUDA_KERNEL_SOURCE}\n    COMMENT \"Building CUDA fatbin: ${CUDA_FATBIN_FILE}\"\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Function References\nDESCRIPTION: List of CUDA Runtime API functions used in the sample for memory management, device synchronization, event handling, and occupancy calculation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleOccupancy/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMemcpy\ncudaFree\ncudaDeviceSynchronize\ncudaEventRecord\ncudaGetDevice\ncudaMalloc\ncudaEventElapsedTime\ncudaOccupancyMaxActiveBlocksPerMultiprocessor\ncudaGetDeviceProperties\ncudaOccupancyMaxPotentialBlockSize\ncudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Primary CUDA Runtime API Calls for FFT-based 2D Convolution\nDESCRIPTION: List of essential CUDA Runtime API functions used in the implementation including memory management, texture handling, and device synchronization operations. These APIs are crucial for performing FFT-based 2D convolution operations on CUDA-enabled devices.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/convolutionFFT2D/README.md#2025-04-21_snippet_0\n\nLANGUAGE: cuda\nCODE:\n```\ncudaMemcpy\ncudaFree\ncudaDestroyTextureObject\ncudaDeviceSynchronize\ncudaCreateTextureObject\ncudaMemset\ncudaMalloc\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Sample Projects with CMake\nDESCRIPTION: CMake configuration that adds multiple CUDA sample projects as subdirectories for building. Includes various examples demonstrating CUDA functionality like EGL integration, Monte Carlo methods, image processing algorithms, and parallel computing patterns.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(EGLStream_CUDA_CrossGPU)\nadd_subdirectory(EGLStream_CUDA_Interop)\nadd_subdirectory(FunctionPointers)\nadd_subdirectory(MC_EstimatePiInlineP)\nadd_subdirectory(MC_EstimatePiInlineQ)\nadd_subdirectory(MC_EstimatePiP)\nadd_subdirectory(MC_EstimatePiQ)\nadd_subdirectory(MC_SingleAsianOptionP)\nadd_subdirectory(boxFilter)\nadd_subdirectory(convolutionSeparable)\nadd_subdirectory(convolutionTexture)\nadd_subdirectory(dct8x8)\nadd_subdirectory(eigenvalues)\nadd_subdirectory(histogram)\nadd_subdirectory(imageDenoising)\nadd_subdirectory(inlinePTX)\nadd_subdirectory(inlinePTX_nvrtc)\nadd_subdirectory(interval)\nadd_subdirectory(particles)\nadd_subdirectory(radixSortThrust)\nadd_subdirectory(reduction)\nadd_subdirectory(reductionMultiBlockCG)\nadd_subdirectory(scalarProd)\nadd_subdirectory(scan)\nadd_subdirectory(segmentationTreeThrust)\nadd_subdirectory(shfl_scan)\nadd_subdirectory(sortingNetworks)\nadd_subdirectory(streamOrderedAllocation)\nadd_subdirectory(streamOrderedAllocationIPC)\nadd_subdirectory(streamOrderedAllocationP2P)\nadd_subdirectory(threadFenceReduction)\nadd_subdirectory(threadMigration)\n```\n\n----------------------------------------\n\nTITLE: Utilizing CUDA Runtime API for Stream Ordered Allocation and P2P Access\nDESCRIPTION: This code snippet demonstrates the use of various CUDA Runtime API functions for stream ordered memory allocation, peer-to-peer access, and related operations. It includes functions for device management, memory pool operations, stream creation, and asynchronous memory operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaDeviceGetDefaultMemPool, cudaFreeAsync, cudaStreamCreateWithFlags, cudaMemPoolSetAccess, cudaStreamDestroy, cudaDeviceGetAttribute, cudaMallocAsync, cudaSetDevice, cudaGetDeviceCount, cudaEventRecord, cudaStreamSynchronize, cudaStreamWaitEvent, cudaMemcpyAsync, cudaDeviceCanAccessPeer, cudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Watershed Segmentation Project with CMake\nDESCRIPTION: Sets up a CMake project for CUDA watershed segmentation with NPP libraries. Configures CUDA architectures, compiler flags, and links required CUDA libraries. Includes commands to copy test data files to the build directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/watershedSegmentationNPP/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(watershedSegmentationNPP LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for watershedSegmentationNPP\nadd_executable(watershedSegmentationNPP watershedSegmentationNPP.cpp)\n\ntarget_compile_options(watershedSegmentationNPP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(watershedSegmentationNPP PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(watershedSegmentationNPP PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(watershedSegmentationNPP PRIVATE\n        ${CUDAToolkit_INCLUDE_DIRS}\n)\ntarget_link_libraries(watershedSegmentationNPP PRIVATE\n        CUDA::nppc\n        CUDA::nppisu\n        CUDA::nppif\n        CUDA::cudart\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET watershedSegmentationNPP POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/data/teapot_512x512_8u_Gray.raw\n    $<TARGET_FILE_DIR:watershedSegmentationNPP>/\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET watershedSegmentationNPP POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/data/CT_skull_512x512_8u_Gray.raw\n    $<TARGET_FILE_DIR:watershedSegmentationNPP>/\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET watershedSegmentationNPP POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/data/Rocks_512x512_8u_Gray.raw\n    $<TARGET_FILE_DIR:watershedSegmentationNPP>/\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA NvSCI Project Build Settings with CMake\nDESCRIPTION: This CMake script configures the build environment for the CUDA NvSCI sample. It sets the minimum required CMake version, defines CUDA architecture targets, locates NvSCI libraries and headers, and sets up compilation flags and dependencies.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cudaNvSci/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cudaNvSci LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 53 61 70 72 75 80 86 87 90)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    # Find the NVSCI libraries\n    # use CMAKE_LIBRARY_PATH so that users can also specify the NVSCI lib path in cmake command\n    set(CMAKE_LIBRARY_PATH \"/usr/lib\" ${CMAKE_LIBRARY_PATH})\n    foreach(LIBRARY_PATH ${CMAKE_LIBRARY_PATH})\n        file(GLOB_RECURSE NVSCIBUF_LIB\n            ${LIBRARY_PATH}/libnvscibuf.so\n            ${LIBRARY_PATH}/*/libnvscibuf.so\n        )\n        file(GLOB_RECURSE NVSCISYNC_LIB\n            ${LIBRARY_PATH}/libnvscisync.so\n            ${LIBRARY_PATH}/*/libnvscisync.so\n        )\n        if(NVSCIBUF_LIB AND NVSCISYNC_LIB)\n            break()\n        endif()\n    endforeach()\n\n    # Find the NVSCI header files\n    # use CMAKE_INCLUDE_PATH so that users can also specify the NVSCI include path in cmake command\n    set(CMAKE_INCLUDE_PATH \"/usr/include\" ${CMAKE_LIBRARY_PATH})\n    find_path(NVSCIBUF_INCLUDE_DIR nvscibuf.h PATHS ${CMAKE_INCLUDE_PATH})\n    find_path(NVSCISYNC_INCLUDE_DIR nvscisync.h PATHS ${CMAKE_INCLUDE_PATH})\n\n    if(NVSCIBUF_LIB AND NVSCISYNC_LIB AND NVSCIBUF_INCLUDE_DIR AND NVSCISYNC_INCLUDE_DIR)\n        message(STATUS \"FOUND NVSCI libs: ${NVSCIBUF_LIB} ${NVSCISYNC_LIB}\")\n        message(STATUS \"Using NVSCI headers path: ${NVSCIBUF_INCLUDE_DIR} ${NVSCIBUF_INCLUDE_DIR}\")\n        # Source file\n        # Add target for cudaNvSci\n        add_executable(cudaNvSci imageKernels.cu cudaNvSci.cpp main.cpp)\n\n        target_compile_options(cudaNvSci PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(cudaNvSci PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(cudaNvSci PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(cudaNvSci PUBLIC\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${NVSCIBUF_INCLUDE_DIR}\n            ${NVSCISYNC_INCLUDE_DIR}\n        )\n\n        target_link_libraries(cudaNvSci\n            CUDA::cuda_driver\n            ${NVSCIBUF_LIB}\n            ${NVSCISYNC_LIB}\n        )\n        # Copy teapot1024.ppm to the output directory\n        add_custom_command(TARGET cudaNvSci POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_if_different\n            ${CMAKE_CURRENT_SOURCE_DIR}/teapot1024.ppm ${CMAKE_CURRENT_BINARY_DIR}/teapot1024.ppm\n        )\n\n        # Specify additional clean files\n        set_target_properties(cudaNvSci PROPERTIES\n            ADDITIONAL_CLEAN_FILES \"teapot1024_out.ppm\"\n        )\n    else()\n        message(STATUS \"NvSCI not found - will not build sample 'cudaNvSci'\")\n    endif()\nelse()\n    message(STATUS \"Will not build sample cudaNvSci - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture Targets and Compiler Flags\nDESCRIPTION: Configures CUDA architecture targets from compute capability 5.0 to 12.0, and sets compiler flags including deprecated GPU target warnings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/graphMemoryFootprint/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA MonteCarloMultiGPU\nDESCRIPTION: Sets up the CMake project, specifies minimum CMake version, adds module path, and defines project languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/MonteCarloMultiGPU/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(MonteCarloMultiGPU LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Configuring deviceQueryDrv Executable Target in CMake\nDESCRIPTION: Creates the executable target for the deviceQueryDrv application and configures its compilation options, including enabling extended lambda support for CUDA and setting C++17/CUDA 17 as the required standard.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/deviceQueryDrv/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(deviceQueryDrv deviceQueryDrv.cpp)\n\ntarget_compile_options(deviceQueryDrv PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(deviceQueryDrv PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: Supported CUDA Runtime API Calls for Graphics Interop\nDESCRIPTION: List of CUDA Runtime API functions used for managing graphics resources, memory allocation, and data transfer between CUDA and OpenGL contexts. These APIs enable efficient image processing and rendering pipeline integration.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleCUDA2GL/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaHostAlloc\ncudaGraphicsUnmapResources\ncudaMalloc\ncudaFree\ncudaGraphicsResourceGetMappedPointer\ncudaGraphicsMapResources\ncudaMemcpyToArray\ncudaDeviceSynchronize\ncudaProcess\ncudaGraphicsUnregisterResource\ncudaGraphicsSubResourceGetMappedArray\ncudaGraphicsGLRegisterBuffer\ncudaGraphicsGLRegisterImage\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Settings and Compiler Flags\nDESCRIPTION: Specifies CUDA architectures, sets compiler flags, and enables position-independent code. Optionally enables CUDA debugging in Debug mode.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/MonteCarloMultiGPU/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Interop Image Processing\nDESCRIPTION: Demonstrates CUDA runtime API interactions for graphics resource management and image processing across multiple CUDA runtime functions including resource mapping, memory allocation, and texture object creation\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaGraphicsGLRegisterImage, cudaGraphicsMapResources, cudaGraphicsResourceGetMappedPointer, cudaCreateTextureObject\n```\n\n----------------------------------------\n\nTITLE: Building CUDA Samples on Windows\nDESCRIPTION: Commands for building CUDA samples on Windows using CMake and Visual Studio. Creates a build directory and generates a Visual Studio solution file targeting x64 architecture.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmkdir build && cd build\ncmake .. -G \"Visual Studio 16 2019\" -A x64\n```\n\n----------------------------------------\n\nTITLE: Getting Host Pointers for Managed Memory with CUDA Runtime\nDESCRIPTION: Demonstrates how to obtain a host pointer from a device pointer to managed memory using cuPointerGetAttribute() with CU_POINTER_ATTRIBUTE_HOST_POINTER, allowing direct access without explicit memory copies.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/uvmlite/README.md#2025-04-21_snippet_3\n\nLANGUAGE: C\nCODE:\n```\nvoid *host_ptr_xxx;\nint *p_xxx;\n\nresult = cuPointerGetAttribute(&host_ptr_xxx, CU_POINTER_ATTRIBUTE_HOST_POINTER, devp_xxx);\np_xxx = (int *)devp_xxx;\n*p_xxx += 1;   // read & write without explicit copying\n```\n\n----------------------------------------\n\nTITLE: Adding Post-Build Commands for Windows\nDESCRIPTION: These commands add custom post-build commands for the 'nbody' target on Windows. They copy the freeglut.dll and glew64.dll files from the specified location to the output directory after the build is complete.  This ensures that the executable can find the necessary DLLs at runtime.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_16\n\nLANGUAGE: cmake\nCODE:\n```\nadd_custom_command(TARGET nbody\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n\n            add_custom_command(TARGET nbody\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Project with CMake\nDESCRIPTION: A complete CMake configuration for building a CUDA sample project called 'simpleAttributes'. It sets up the minimum CMake version, project languages, finds CUDA dependencies, configures CUDA architecture targets, and creates an executable with specific compiler options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleAttributes/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleAttributes LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleAttributes\nadd_executable(simpleAttributes simpleAttributes.cu)\n\ntarget_compile_options(simpleAttributes PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleAttributes PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleAttributes PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Displaying CUDA Reduction Benchmark Results\nDESCRIPTION: Console output showing the execution of a CUDA reduction operation on an H100 GPU, including device information, configuration parameters, performance metrics, and result validation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_reduction.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n./reduction Starting...\n\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nUsing Device 0: NVIDIA H100 PCIe\n\nReducing array of type int\n\n16777216 elements\n256 threads (max)\n64 blocks\n\nReduction, Throughput = 49.0089 GB/s, Time = 0.00137 s, Size = 16777216 Elements, NumDevsUsed = 1, Workgroup = 256\n\nGPU result = 2139353471\nCPU result = 2139353471\n\nTest passed\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Quadtree Project\nDESCRIPTION: Sets up the CMake project for cdpQuadtree, including CUDA toolkit requirements, architecture targets, and compiler flags. It also defines the executable target with specific CUDA and C++ compiler options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpQuadtree/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cdpQuadtree LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    # Need to differentiate Tegra_aarch64 and other aarch64 systems(sbsa_aarch64) as they have different CUDA_ARCHITECTURES list\n    if(${BUILD_TEGRA})\n        set(CMAKE_CUDA_ARCHITECTURES 72 87 101)\n    else()\n        set(CMAKE_CUDA_ARCHITECTURES 61 70 75 80 86 90)\n    endif()\nelse()\n    set(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 75 80 86 89 90 100 101 120)\nendif()\n\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for cdpQuadtree\nadd_executable(cdpQuadtree cdpQuadtree.cu)\n\ntarget_compile_options(cdpQuadtree PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cdpQuadtree PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cdpQuadtree PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA SystemWideAtomics Sample\nDESCRIPTION: Sets up a CMake build configuration for a CUDA sample program that demonstrates system-wide atomic operations. The configuration includes CUDA architecture targets from compute capability 60 to 120, requires C++17 and CUDA 17 support, and limits builds to Linux on x86_64 platforms.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/systemWideAtomics/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(systemWideAtomics LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 60 61 70 72 75 80 86 87 89 90 100 101 120)\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    message(STATUS \"Will not build sample systemWideAtomics - not supported on aarch64\")\nelse()\n    if(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n        # Source file\n        # Add target for systemWideAtomics\n        add_executable(systemWideAtomics systemWideAtomics.cu)\n\n        target_compile_options(systemWideAtomics PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(systemWideAtomics PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(systemWideAtomics PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n    else()\n        message(STATUS \"Will not build sample systemWideAtomics - requires Linux OS\")\n    endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Settings and Architecture Support\nDESCRIPTION: Sets CUDA compilation flags, supported architectures, and debug options for the simpleCUDA2GL project.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleCUDA2GL/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA simpleTexture Project\nDESCRIPTION: Sets up the CMake configuration for the CUDA simpleTexture example, including minimum CMake version, project languages, and module paths.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTexture/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleTexture LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Setting target compile features\nDESCRIPTION: This command specifies the C++ standard version to be used when compiling the target.  It enables C++17 and CUDA 17 features for the 'cudaGraphsPerfScaling' target, ensuring compatibility with modern C++ and CUDA features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/cudaGraphsPerfScaling/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_compile_features(cudaGraphsPerfScaling PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Calls for Pitch Linear Texture\nDESCRIPTION: Collection of CUDA Runtime API functions used for texture object management, memory allocation, and event handling. These APIs are essential for implementing pitch linear textures in CUDA applications.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simplePitchLinearTexture/README.md#2025-04-21_snippet_0\n\nLANGUAGE: cuda\nCODE:\n```\ncudaMallocArray\ncudaFreeArray\ncudaFree\ncudaMallocPitch\ncudaDestroyTextureObject\ncudaEventSynchronize\ncudaMemcpyToArray\ncudaEventRecord\ncudaCreateTextureObject\ncudaEventDestroy\ncudaEventElapsedTime\ncudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Enabling NVIDIA DRM Module for Orin Platform\nDESCRIPTION: This command enables the NVIDIA DRM module with modeset option, which is required before running the sample on the Orin platform.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/simpleGLES_EGLOutput/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\n$ sudo modprobe nvidia-drm modeset=1\n```\n\n----------------------------------------\n\nTITLE: CUDA API Function List\nDESCRIPTION: List of CUDA Runtime API functions used in the sample for handling external memory, semaphores, and synchronization operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cudaNvSciNvMedia/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaImportExternalSemaphore, cudaGetMipmappedArrayLevel, cudaSetDevice, cudaDestroySurfaceObject, cudaCreateSurfaceObject, cudaImportNvSciImage, cudaCreateChannelDesc, cudaMallocHost, cudaSignalExternalSemaphoresAsync, cudaFreeHost, cudaMemcpyAsync, cudaStreamCreateWithFlags, cudaExternalMemoryGetMappedMipmappedArray, cudaMallocArray, cudaFreeArray, cudaStreamDestroy, cudaDeviceGetNvSciSyncAttributes, cudaDestroyExternalMemory, cudaImportExternalMemory, cudaDestroyExternalSemaphore, cudaFreeMipmappedArray, cudaImportNvSciSync, cudaFree, cudaStreamSynchronize, cudaMalloc, cudaWaitExternalSemaphoresAsync\n```\n\n----------------------------------------\n\nTITLE: Creating custom command for CUDA kernel fatbin generation\nDESCRIPTION: Defines a custom build process to compile a CUDA kernel into a fatbin file that can be loaded by the driver API at runtime. Creates dependencies to ensure the fatbin is generated before the main executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/matrixMulDrv/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nset(CUDA_FATBIN_FILE \"${CMAKE_CURRENT_BINARY_DIR}/matrixMul_kernel64.fatbin\")\nset(CUDA_KERNEL_SOURCE \"${CMAKE_CURRENT_SOURCE_DIR}/matrixMul_kernel.cu\")\n\nadd_custom_command(\n    OUTPUT ${CUDA_FATBIN_FILE}\n    COMMAND ${CMAKE_CUDA_COMPILER} ${INCLUDES} ${ALL_CCFLAGS} -Wno-deprecated-gpu-targets  ${GENCODE_FLAGS} -o ${CUDA_FATBIN_FILE} -fatbin ${CUDA_KERNEL_SOURCE}\n    DEPENDS ${CUDA_KERNEL_SOURCE}\n    COMMENT \"Building CUDA fatbin: ${CUDA_FATBIN_FILE}\"\n)\n\n# Create a dummy target for fatbin generation\nadd_custom_target(generate_fatbin_matmulDrv ALL DEPENDS ${CUDA_FATBIN_FILE})\n\n# Ensure matrixMulDrv depends on the fatbin\nadd_dependencies(matrixMulDrv generate_fatbin_matmulDrv)\n```\n\n----------------------------------------\n\nTITLE: Configuring Target Build Settings\nDESCRIPTION: Sets up the executable target with C++17 and CUDA 17 standards, enables extended lambda support, and configures separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/graphMemoryFootprint/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(graphMemoryFootprint graphMemoryFootprint.cu)\n\ntarget_compile_options(graphMemoryFootprint PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(graphMemoryFootprint PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(graphMemoryFootprint PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for NVIDIA CUDA histEqualizationNPP Sample\nDESCRIPTION: Complete CMake configuration for the histEqualizationNPP CUDA sample. It sets up CUDA architectures (50-120), includes necessary dependencies like FreeImage and NPP libraries, and configures post-build steps to copy required data files.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/histEqualizationNPP/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(histEqualizationNPP LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(\n    ../../../Common\n    ../../../Common/UtilNPP\n)\n\n# Source file\nfind_package(FreeImage)\n\nif(${FreeImage_FOUND})\n    # Add target for histEqualizationNPP\n    add_executable(histEqualizationNPP histEqualizationNPP.cpp)\n\n    target_compile_options(histEqualizationNPP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(histEqualizationNPP PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(histEqualizationNPP PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n    target_include_directories(histEqualizationNPP PRIVATE\n        ${CUDAToolkit_INCLUDE_DIRS}\n        ${FreeImage_INCLUDE_DIRS}\n    )\n\n    target_link_libraries(histEqualizationNPP PRIVATE\n        CUDA::nppc\n        CUDA::nppisu\n        CUDA::nppist\n        CUDA::nppicc\n        CUDA::cudart\n        ${FreeImage_LIBRARIES}\n    )\n\n    # Copy data files to output directory\n    add_custom_command(TARGET histEqualizationNPP POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy_if_different\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/data/teapot512.pgm\n        ${CMAKE_CURRENT_BINARY_DIR}/\n    )\n    if(WIN32)\n        add_custom_command(TARGET histEqualizationNPP\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${FreeImage_LIBRARY}/../FreeImage.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n        )\n    endif()\nelse()\n    message(STATUS \"FreeImage not found - will not build sample 'histEqualizationNPP'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Post-Build Commands for Data File Copy\nDESCRIPTION: This snippet adds custom commands to copy necessary data files to the build output directory after the target is built.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET cuSolverSp_LowlevelQR POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/lap2D_5pt_n32.mtx\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\nadd_custom_command(TARGET cuSolverSp_LowlevelQR POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/lap2D_5pt_n100.mtx\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\nadd_custom_command(TARGET cuSolverSp_LowlevelQR POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/lap3D_7pt_n20.mtx\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Conditional Target Building for Linux Systems with Required Dependencies\nDESCRIPTION: Creates the nbody_opengles executable target if running on Linux with all required dependencies (OpenGL, EGL, X11). Sets up the necessary compiler options, C++17 and CUDA C++17 features, and CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/nbody_opengles/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    # Source file\n    if(${OpenGL_FOUND})\n        if(${EGL_FOUND})\n            if(${X11_FOUND})\n                # Add target for nbody_opengles\n                add_executable(nbody_opengles bodysystemcuda.cu render_particles.cpp nbody_opengles.cpp)\n\n                target_compile_options(nbody_opengles PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n                target_compile_features(nbody_opengles PRIVATE cxx_std_17 cuda_std_17)\n\n                set_target_properties(nbody_opengles PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n                target_include_directories(nbody_opengles PUBLIC\n                    ${EGL_INCLUDE_DIR}\n                    ${OPENGL_INCLUDE_DIR}\n                    ${CUDAToolkit_INCLUDE_DIRS}\n                )\n\n                target_link_libraries(nbody_opengles\n                    ${EGL_LIBRARY}\n                    ${X11_LIBRARIES}\n                    ${OPENGL_LIBRARIES}\n                )\n            else()\n                message(STATUS \"X11 libraries not found - will not build sample 'nbody_opengles'\")\n            endif()\n        else()\n            message(STATUS \"EGL not found - will not build sample 'nbody_opengles'\")\n        endif()\n    else()\n        message(STATUS \"OpenGL not found - will not build sample 'nbody_opengles'\")\n    endif()\nelse()\n    message(STATUS \"Will not build sample nbody_opengles - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA memMapIPCDrv\nDESCRIPTION: Sets up the CMake project, defines the minimum CMake version, adds module paths, and specifies the project name and languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/memMapIPCDrv/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(memMapIPCDrv LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA simpleAtomicIntrinsics Project\nDESCRIPTION: This CMake script configures the build environment for a CUDA sample demonstrating atomic intrinsics. It sets CUDA architecture targets from compute capability 5.0 to 12.0, configures compiler flags, and builds an executable from both CUDA and C++ source files with C++17 standard support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleAtomicIntrinsics/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleAtomicIntrinsics LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES  50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleAtomicIntrinsics\nadd_executable(simpleAtomicIntrinsics simpleAtomicIntrinsics.cu simpleAtomicIntrinsics_cpu.cpp)\n\ntarget_compile_options(simpleAtomicIntrinsics PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleAtomicIntrinsics PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleAtomicIntrinsics PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: CUDA Declaration for cudaLaunchDeviceV2\nDESCRIPTION: This CUDA-level declaration maps to the NVVM IR declaration for cudaLaunchDeviceV2. It is found in the cuda_device_runtime_api.h header and requires linking with cudadevrt. The function facilitates device-side kernel launches by accepting a parameter buffer and a stream.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/device-side-launch/README.md#2025-04-21_snippet_1\n\nLANGUAGE: C\nCODE:\n```\nextern __device__ __cudart_builtin__ cudaError_t CUDARTAPI\ncudaLaunchDeviceV2(void *parameterBuffer, cudaStream_t stream);\n```\n\n----------------------------------------\n\nTITLE: Configuring Build Target and Compilation Options\nDESCRIPTION: Sets up the executable target with required include directories, compilation options for extended lambda support, and C++17/CUDA 17 feature requirements.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simplePrintf/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(simplePrintf simplePrintf.cu)\n\ntarget_compile_options(simplePrintf PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simplePrintf PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simplePrintf PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture Targets and Compiler Flags\nDESCRIPTION: Configures CUDA architecture targets and sets compiler flags, including options for debug builds. It covers a wide range of CUDA architectures from 5.0 to 12.0.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/threadFenceReduction/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Set Target Compile Features\nDESCRIPTION: Sets required C++ and CUDA standard features for the target. This ensures that the code is compiled with the correct language standard.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_features(quasirandomGenerator_nvrtc PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA DLA Hybrid Mode\nDESCRIPTION: Sets up the CMake project for cuDLAHybridMode with CUDA language support. Configures the minimum required version, project languages, and custom module paths for the NVIDIA CUDA sample.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLAHybridMode/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../../cmake/Modules\")\n\nproject(cuDLAHybridMode LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Building simpleTexture3D Target with OpenGL and GLUT Dependencies\nDESCRIPTION: Configures the simpleTexture3D executable target, setting compile options, features, and linking necessary libraries. It also sets up post-build commands for copying data files and DLLs on Windows.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTexture3D/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        add_executable(simpleTexture3D simpleTexture3D_kernel.cu simpleTexture3D.cpp)\n\n        target_compile_options(simpleTexture3D PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(simpleTexture3D PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(simpleTexture3D PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(simpleTexture3D PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(simpleTexture3D\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n\n        add_custom_command(TARGET simpleTexture3D POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_directory\n            ${CMAKE_CURRENT_SOURCE_DIR}/data\n            ${CMAKE_CURRENT_BINARY_DIR}\n        )\n\n         if(WIN32)\n            target_link_libraries(simpleTexture3D\n                ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n                ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n            )\n\n            add_custom_command(TARGET simpleTexture3D\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n\n            add_custom_command(TARGET simpleTexture3D\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n        endif()\n\n    else()\n        message(STATUS \"GLUT not found - will not build sample 'simpleTexture3D'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'simpleTexture3D'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA BF16 Tensor Core GEMM\nDESCRIPTION: This CMake snippet sets up the project, finds the CUDA toolkit, and configures various build settings including CUDA architectures and compilation flags. It also defines the main executable target with specific compiler options and features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/bf16TensorCoreGemm/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(bf16TensorCoreGemm LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 70 72 75 80 86 87 89 90 100 101 120)\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for bf16TensorCoreGemm\nadd_executable(bf16TensorCoreGemm bf16TensorCoreGemm.cu)\n\ntarget_compile_options(bf16TensorCoreGemm PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(bf16TensorCoreGemm PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(bf16TensorCoreGemm PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: CUDA Stream Performance Test Output\nDESCRIPTION: Terminal output showing device detection, memory allocation and performance metrics for CUDA streams. Tests compare memory copy, kernel execution, non-streamed and 4-stream performance on an H100 GPU.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleStreams.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n[ simpleStreams ]\n\nDevice synchronization method set to = 0 (Automatic Blocking)\nSetting reps to 100 to demonstrate steady state\n\n> GPU Device 0: \"Hopper\" with compute capability 9.0\n\nDevice: <NVIDIA H100 PCIe> canMapHostMemory: Yes\n> CUDA Capable: SM 9.0 hardware\n> 114 Multiprocessor(s) x 128 (Cores/Multiprocessor) = 14592 (Cores)\n> scale_factor = 1.0000\n> array_size   = 16777216\n\n> Using CPU/GPU Device Synchronization method (cudaDeviceScheduleAuto)\n> mmap() allocating 64.00 Mbytes (generic page-aligned system memory)\n> cudaHostRegister() registering 64.00 Mbytes of generic allocated system memory\n\nStarting Test\nmemcopy:\t2.45\nkernel:\t\t0.12\nnon-streamed:\t2.80\n4 streams:\t2.66\n-------------------------------\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions for Stream Priorities\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the StreamPriorities sample. It includes functions for memory operations, stream creation, event handling, and device property queries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\ncudaMemcpy, cudaStreamCreateWithPriority, cudaDeviceGetStreamPriorityRange, cudaEventSynchronize, cudaEventRecord, cudaMalloc, cudaEventElapsedTime, cudaGetDeviceProperties, cudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: CUDA Graph Memory Management Overview\nDESCRIPTION: Markdown documentation outlining the CUDA sample project structure, supported architectures, and API references for graph memory management operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/graphMemoryNodes/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# graphMemoryNodes - Graph Memory Nodes\n\n## Description\n\nA demonstration of memory allocations and frees within CUDA graphs using Graph APIs and Stream Capture APIs.\n\n## Key Concepts\n\nCUDA Graphs, Stream Capture\n\n## Supported SM Architectures\n\n[SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.9 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)\n\n## Supported OSes\n\nLinux, Windows\n\n## Supported CPU Architecture\n\nx86_64, armv7l\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Sample Subdirectories in CMake\nDESCRIPTION: CMake configuration that adds multiple CUDA sample projects as subdirectories to be built. Each subdirectory contains a separate CUDA sample demonstrating various features like matrix multiplication, atomic operations, textures, and other CUDA programming concepts.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(UnifiedMemoryStreams)\nadd_subdirectory(asyncAPI)\nadd_subdirectory(clock)\nadd_subdirectory(clock_nvrtc)\nadd_subdirectory(cudaOpenMP)\nadd_subdirectory(fp16ScalarProduct)\nadd_subdirectory(matrixMul)\nadd_subdirectory(matrixMulDrv)\nadd_subdirectory(matrixMulDynlinkJIT)\nadd_subdirectory(matrixMul_nvrtc)\nadd_subdirectory(mergeSort)\nadd_subdirectory(simpleAWBarrier)\nadd_subdirectory(simpleAssert)\nadd_subdirectory(simpleAssert_nvrtc)\nadd_subdirectory(simpleAtomicIntrinsics)\nadd_subdirectory(simpleAtomicIntrinsics_nvrtc)\nadd_subdirectory(simpleAttributes)\nadd_subdirectory(simpleCUDA2GL)\nadd_subdirectory(simpleCallback)\nadd_subdirectory(simpleCooperativeGroups)\nadd_subdirectory(simpleCubemapTexture)\nadd_subdirectory(simpleDrvRuntime)\nadd_subdirectory(simpleHyperQ)\nadd_subdirectory(simpleIPC)\nadd_subdirectory(simpleLayeredTexture)\nadd_subdirectory(simpleMPI)\nadd_subdirectory(simpleMultiCopy)\nadd_subdirectory(simpleMultiGPU)\nadd_subdirectory(simpleOccupancy)\nadd_subdirectory(simpleP2P)\nadd_subdirectory(simplePitchLinearTexture)\nadd_subdirectory(simplePrintf)\nadd_subdirectory(simpleStreams)\nadd_subdirectory(simpleSurfaceWrite)\nadd_subdirectory(simpleTemplates)\nadd_subdirectory(simpleTexture)\nadd_subdirectory(simpleTexture3D)\nadd_subdirectory(simpleTextureDrv)\nadd_subdirectory(simpleVoteIntrinsics)\nadd_subdirectory(simpleZeroCopy)\nadd_subdirectory(template)\nadd_subdirectory(systemWideAtomics)\nadd_subdirectory(vectorAdd)\nadd_subdirectory(vectorAddDrv)\nadd_subdirectory(vectorAddMMAP)\nadd_subdirectory(vectorAdd_nvrtc)\n```\n\n----------------------------------------\n\nTITLE: Setting Up simpleTextureDrv Executable Target\nDESCRIPTION: Creates the executable target for simpleTextureDrv, sets compilation options, features, and links necessary libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTextureDrv/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(simpleTextureDrv simpleTextureDrv.cpp)\n\ntarget_compile_options(simpleTextureDrv PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleTextureDrv PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleTextureDrv PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\ntarget_include_directories(simpleTextureDrv PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(simpleTextureDrv PUBLIC\n    CUDA::cuda_driver\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA simpleTexture3D Sample\nDESCRIPTION: Sets up the CMake project for simpleTexture3D, including minimum CMake version, project languages, and CUDA toolkit requirement. It also configures CUDA architecture targets and compiler flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTexture3D/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleTexture3D LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Monte Carlo Pi Estimation Project with CMake\nDESCRIPTION: Comprehensive CMake configuration for a CUDA Monte Carlo Pi estimation project. Sets minimum CMake version, defines CUDA architectures (compute capabilities 50-120), configures compiler flags including lambda support, and links the required source files into an executable with proper include paths.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(MC_EstimatePiInlineP LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for MC_EstimatePiInlineP\nadd_executable(MC_EstimatePiInlineP src/main.cpp src/piestimator.cu src/test.cpp)\n\ntarget_compile_options(MC_EstimatePiInlineP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(MC_EstimatePiInlineP PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(MC_EstimatePiInlineP PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(MC_EstimatePiInlineP PUBLIC\n    ${CMAKE_CURRENT_SOURCE_DIR}/inc\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA GEMM Performance Output\nDESCRIPTION: Console output showing matrix multiplication benchmark results on NVIDIA Hopper GPU with compute capability 9.0. Shows matrix dimensions (4096x4096), shared memory requirements (64Kb), and performance metrics (0.629184ms, 218.44 TOPS).\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_immaTensorCoreGemm.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nInitializing...\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nM: 4096 (16 x 256)\nN: 4096 (16 x 256)\nK: 4096 (16 x 256)\nPreparing data for GPU...\nRequired shared memory size: 64 Kb\nComputing... using high performance kernel compute_gemm_imma \nTime: 0.629184 ms\nTOPS: 218.44\n```\n\n----------------------------------------\n\nTITLE: Setting up CMake configuration for CUDA simpleOccupancy project\nDESCRIPTION: Configures CMake project settings for building the simpleOccupancy CUDA sample. It specifies minimum CMake version, project languages, module paths, and sets up CUDA-specific build properties.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleOccupancy/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleOccupancy LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleOccupancy\nadd_executable(simpleOccupancy simpleOccupancy.cu)\n\ntarget_compile_options(simpleOccupancy PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleOccupancy PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleOccupancy PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Project Build Settings with CMake\nDESCRIPTION: Configures a CMake build for a CUDA sample project. Sets minimum CMake version, defines CUDA architecture targets, configures compiler flags, and establishes build properties for the simplePitchLinearTexture executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simplePitchLinearTexture/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simplePitchLinearTexture LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simplePitchLinearTexture\nadd_executable(simplePitchLinearTexture simplePitchLinearTexture.cu)\n\ntarget_compile_options(simplePitchLinearTexture PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simplePitchLinearTexture PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simplePitchLinearTexture PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Defining SobolQRNG Executable Target\nDESCRIPTION: This snippet creates the executable target for SobolQRNG. It specifies the source files to be compiled and linked, including both C++ and CUDA files. It also sets compiler options, language standards, and CUDA-specific properties.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/SobolQRNG/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(SobolQRNG sobol_gold.cpp sobol_gpu.cu sobol_primitives.cpp sobol.cpp)\n\ntarget_compile_options(SobolQRNG PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(SobolQRNG PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(SobolQRNG PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(SobolQRNG PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Setting up include directories and linking CUDA libraries\nDESCRIPTION: Configures include directories and links required CUDA libraries including cudart, cublas, and cusolver. These are essential dependencies for the linear solver functionality.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_include_directories(cuSolverDn_LinearSolver PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(cuSolverDn_LinearSolver PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n    CUDA::cusolver\n)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Separable Compilation and Including CUDA Toolkit\nDESCRIPTION: Enables separable compilation for the CUDA code and includes the necessary CUDA Toolkit directories for the deviceQueryDrv target.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/deviceQueryDrv/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nset_target_properties(deviceQueryDrv PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\ntarget_include_directories(deviceQueryDrv PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Target Configuration and Build Rules\nDESCRIPTION: Configures the build target with required compiler options, include directories, and linked libraries. Sets up post-build commands for resource copying and cleanup.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cudaNvSciNvMedia/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nadd_executable(cudaNvSciNvMedia imageKernels.cu cudaNvSciNvMedia.cpp main.cpp)\n\ntarget_compile_options(cudaNvSciNvMedia PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cudaNvSciNvMedia PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cudaNvSciNvMedia PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(cudaNvSciNvMedia PUBLIC\n    ${CUDAToolkit_INCLUDE_DIRS}\n    ${NVSCIBUF_INCLUDE_DIR}\n    ${NVSCISYNC_INCLUDE_DIR}\n    ${NVMEDIA_INCLUDE_DIR}\n)\n\ntarget_link_libraries(cudaNvSciNvMedia\n    CUDA::cuda_driver\n    ${NVSCIBUF_LIB}\n    ${NVSCISYNC_LIB}\n    ${NVMEDIA_LIB}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Build for CUDA CUBLAS Sample\nDESCRIPTION: Complete CMake configuration for building a CUDA CUBLAS sample application. Sets minimum CMake version, configures CUDA architectures, compiler flags, and links required CUDA libraries including cudart and cublas. Enables C++17 and CUDA 17 standards with position-independent code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUBLAS/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCUBLAS LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleCUBLAS\nadd_executable(simpleCUBLAS simpleCUBLAS.cpp)\n\ntarget_compile_options(simpleCUBLAS PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleCUBLAS PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleCUBLAS PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(simpleCUBLAS PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(simpleCUBLAS PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n)\n```\n\n----------------------------------------\n\nTITLE: Creating CUDA Context\nDESCRIPTION: Creates a CUDA context using cuCtxCreate() and pushes it onto the current thread using cuCtxPushCurrent(). This establishes a CUDA context for GPU operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/threadMigration/README.md#2025-04-21_snippet_1\n\nLANGUAGE: CUDA\nCODE:\n```\ncuCtxCreate(&context, 0, dev);\ncuCtxPushCurrent(context);\n```\n\n----------------------------------------\n\nTITLE: Using CUDA Runtime API for Reduction with MultiBlock Cooperative Groups\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the sample for memory management, device synchronization, kernel launching, and device property querying. It includes functions for cooperative kernel launch and occupancy calculation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMemcpy, cudaFree, cudaSetDevice, cudaDeviceSynchronize, cudaLaunchCooperativeKernel, cudaMalloc, cudaOccupancyMaxActiveBlocksPerMultiprocessor, cudaGetDeviceProperties, cudaOccupancyMaxPotentialBlockSize\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture and Compiler Flags\nDESCRIPTION: Configures CUDA architecture targets and compiler flags, including position-independent code and debug options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/jacobiCudaGraphs/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Build for CUDA UnifiedMemoryStreams\nDESCRIPTION: Sets up a CMake build configuration for a CUDA project with unified memory streams. Configures CUDA architecture targets, compiler flags, and dependencies including OpenMP and cuBLAS. Enables C++17 and CUDA 17 features with extended lambda support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/UnifiedMemoryStreams/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(UnifiedMemoryStreams LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\nfind_package(OpenMP REQUIRED)\n\nif(${OpenMP_FOUND})\n    # Add target for UnifiedMemoryStreams\n    add_executable(UnifiedMemoryStreams UnifiedMemoryStreams.cu)\n\ntarget_compile_options(UnifiedMemoryStreams PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(UnifiedMemoryStreams PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(UnifiedMemoryStreams PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n    target_link_libraries(UnifiedMemoryStreams PUBLIC\n        CUDA::cublas\n        OpenMP::OpenMP_CXX\n    )\nelse()\n    message(STATUS \"OpenMP not found - will not build sample 'UnifiedMemoryStreams'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Installing Additional Linux Dependencies\nDESCRIPTION: Install supplementary development libraries required for GLFW3 functionality on Linux systems\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkanMMAP/Build_instructions.txt#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get install libxcb1-dev\nsudo apt-get install xorg-dev\n```\n\n----------------------------------------\n\nTITLE: Synchronizing GPU Operations in CUDA\nDESCRIPTION: This snippet demonstrates the use of cudaDeviceSynchronize to ensure all preceding CUDA calls have completed. It's crucial for maintaining synchronization between CPU and GPU operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/scalarProd/README.md#2025-04-21_snippet_1\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaDeviceSynchronize\n```\n\n----------------------------------------\n\nTITLE: Adding Executable Target\nDESCRIPTION: This code block conditionally adds an executable target named 'nbody' if both OpenGL and GLUT are found. It specifies the source files for the executable and defines compilation options, features, and include directories.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: cmake\nCODE:\n```\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        # Add target for nbody\n        add_executable(nbody bodysystemcuda.cu render_particles.cpp nbody.cpp)\n\n        target_compile_options(nbody PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(nbody PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(nbody PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(nbody PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(nbody\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n\n        if(WIN32)\n            target_link_libraries(nbody\n                ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n                ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n            )\n\n            add_custom_command(TARGET nbody\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n\n            add_custom_command(TARGET nbody\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n        endif()\n\n    else()\n        message(STATUS \"GLUT not found - will not build sample 'nbody'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'nbody'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Include Directories and Finding CUDLA Library\nDESCRIPTION: Configures include paths for common CUDA sample code and searches for the CUDLA library in the CUDA Toolkit library directory. This library is required for DLA (Deep Learning Accelerator) functionality.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLAHybridMode/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../../Common)\n\nfind_library(CUDLA_LIB cudla PATHS ${CUDAToolkit_LIBRARY_DIR})\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Convolution Texture Project Build\nDESCRIPTION: Complete CMake configuration for building a CUDA convolution texture application. Sets minimum CMake version, configures CUDA architectures, compiler flags, and builds an executable from source files with specific compile options and features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/convolutionTexture/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(convolutionTexture LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for convolutionTexture\nadd_executable(convolutionTexture convolutionTexture.cu convolutionTexture_gold.cpp main.cpp)\n\ntarget_compile_options(convolutionTexture PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(convolutionTexture PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(convolutionTexture PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(convolutionTexture PUBLIC\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA Callback Program Output\nDESCRIPTION: Console output showing detection of CUDA-capable GPU (H100 PCIe), initialization of callback functionality, and successful execution of 8 heterogeneous computing workloads.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleCallback.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nStarting simpleCallback\nFound 1 CUDA capable GPUs\nGPU[0] NVIDIA H100 PCIe supports SM 9.0, capable GPU Callback Functions\n1 GPUs available to run Callback Functions\nStarting 8 heterogeneous computing workloads\nTotal of 8 workloads finished:\nSuccess\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake and CUDA Project Settings\nDESCRIPTION: Sets up basic CMake configuration, CUDA language support, and project dependencies. Includes configuration for CUDA architecture targets and compiler flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(segmentationTreeThrust LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA dependencies and compilation flags\nDESCRIPTION: Sets up the CUDA Toolkit dependency and configures compilation settings including position-independent code and target CUDA architectures. This ensures the application can run on various NVIDIA GPU generations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Defining CUDA Executable Target in CMake\nDESCRIPTION: Adds the executable target for the streamOrderedAllocation CUDA sample. It specifies the source file, sets compiler options for extended lambda support, and enables CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\n# Source file\n# Add target for streamOrderedAllocation\nadd_executable(streamOrderedAllocation streamOrderedAllocation.cu)\n\ntarget_compile_options(streamOrderedAllocation PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(streamOrderedAllocation PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(streamOrderedAllocation PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Dependencies and Include Paths\nDESCRIPTION: Configures include directories and handles platform-specific GLUT paths for Windows. Sets up OpenGL and GLUT package requirements.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/oceanFFT/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA SimpleSurfaceWrite\nDESCRIPTION: Sets up the CMake project with CUDA support, specifies the minimum CMake version, and defines the project name and languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleSurfaceWrite/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleSurfaceWrite LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA simpleCUFFT_callback\nDESCRIPTION: Sets up the CMake project, specifies the minimum CMake version, adds module paths, and declares the project language as CUDA. It also finds the CUDA toolkit package which is required for the project.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUFFT_callback/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCUFFT_callback LANGUAGES CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Convolution Separable Project Build\nDESCRIPTION: CMake configuration that sets up a CUDA project with specific GPU architecture targets, compiler flags, and build requirements. It configures an executable target for convolution separable implementation with CUDA and C++ support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/convolutionSeparable/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(convolutionSeparable LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for convolutionSeparable\nadd_executable(convolutionSeparable convolutionSeparable.cu convolutionSeparable_gold.cpp main.cpp)\n\ntarget_compile_options(convolutionSeparable PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(convolutionSeparable PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(convolutionSeparable PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(convolutionSeparable PUBLIC\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Executable Target Configuration\nDESCRIPTION: Configures the main executable target with necessary compile options, features, and library dependencies.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleDrvRuntime/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(simpleDrvRuntime simpleDrvRuntime.cpp)\n\ntarget_compile_options(simpleDrvRuntime PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleDrvRuntime PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleDrvRuntime PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(simpleDrvRuntime PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(simpleDrvRuntime PUBLIC\n    CUDA::cudart\n    CUDA::cuda_driver\n)\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions Used in Interval Computing\nDESCRIPTION: This snippet enumerates the CUDA Runtime API functions utilized in the interval computing project. These functions handle various CUDA operations including memory management, device properties, event handling, and kernel execution configuration.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/interval/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\ncudaMemcpy, cudaFuncSetCacheConfig, cudaMalloc, cudaFree, cudaGetLastError, cudaSetDevice, cudaDeviceSynchronize, cudaEventRecord, cudaDeviceSetLimit, cudaEventDestroy, cudaEventElapsedTime, cudaGetDeviceProperties, cudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architecture Settings for matrixMul_nvrtc\nDESCRIPTION: Specifies the minimum CMake version, sets up module paths, and configures CUDA architectures. The snippet establishes project settings, finds the CUDA toolkit, and enables position-independent code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/matrixMul_nvrtc/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(matrixMul_nvrtc LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Defining vectorAddMMAP Target and Compilation Options\nDESCRIPTION: Creates the vectorAddMMAP executable target, sets its compilation options, features, and links necessary libraries. This section is conditionally executed based on the system architecture.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/vectorAddMMAP/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    message(STATUS \"Will not build sample vectorAddMMAP - not supported on aarch64\")\nelse()\n    add_executable(vectorAddMMAP vectorAddMMAP.cpp multidevicealloc_memmap.cpp)\n\n    target_compile_options(vectorAddMMAP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(vectorAddMMAP PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(vectorAddMMAP PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n    target_include_directories(vectorAddMMAP PRIVATE\n        ${CUDAToolkit_INCLUDE_DIRS}\n    )\n\n    target_link_libraries(vectorAddMMAP PUBLIC\n        CUDA::cuda_driver\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Include Directories and Conditional Compilation\nDESCRIPTION: Includes necessary directories and sets up conditional compilation based on the system processor. For non-aarch64 systems, it defines the simpleIPC executable target.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleIPC/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    message(STATUS \"Will not build sample simpleIPC - not supported on aarch64\")\nelse()\n    # Source file\n    # Add target for simpleIPC\n    add_executable(simpleIPC simpleIPC.cu ../../../Common/helper_multiprocess.cpp)\n\n    target_compile_options(simpleIPC PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(simpleIPC PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(simpleIPC PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA Merge Sort\nDESCRIPTION: Comprehensive CMake configuration for a CUDA-based merge sort implementation. It sets up CUDA architectures targeting a wide range of NVIDIA GPUs (from Compute Capability 5.0 to 12.0), specifies compiler flags, and configures a mixed C++/CUDA executable with required feature support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/mergeSort/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(mergeSort LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for mergeSort\nadd_executable(mergeSort mergeSort.cu main.cpp mergeSort_host.cpp mergeSort_validate.cpp)\n\ntarget_compile_options(mergeSort PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(mergeSort PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(mergeSort PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\ntarget_include_directories(mergeSort PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions Used\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the HSOpticalFlow sample. These functions are essential for memory management and data transfer in CUDA applications.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/HSOpticalFlow/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\ncudaMalloc, cudaMemcpy, cudaMemset, cudaFree\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API functions used in Simple CUBLAS XT\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the Simple CUBLAS XT example. These functions are essential for device management and memory operations in CUDA programming.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUBLASXT/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\ncudaGetDeviceProperties, cudaGetDeviceCount, cudaFree\n```\n\n----------------------------------------\n\nTITLE: Setting Up Build Target for SimpleSurfaceWrite CUDA Project\nDESCRIPTION: Defines the executable target, sets compiler options and features, and enables CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleSurfaceWrite/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(simpleSurfaceWrite simpleSurfaceWrite.cu)\n\ntarget_compile_options(simpleSurfaceWrite PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleSurfaceWrite PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleSurfaceWrite PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Setting up include directories and linking libraries for Mandelbrot\nDESCRIPTION: Configures include directories for OpenGL, CUDA, and GLUT headers, then links against the required libraries. This ensures the application can properly access rendering APIs and CUDA functionality.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/Mandelbrot/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_include_directories(Mandelbrot PUBLIC\n    ${OPENGL_INCLUDE_DIR}\n    ${CUDAToolkit_INCLUDE_DIRS}\n    ${GLUT_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(Mandelbrot\n    ${OPENGL_LIBRARIES}\n    ${GLUT_LIBRARIES}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Dependencies and Include Directories for simpleTexture3D\nDESCRIPTION: Sets up include directories and finds required packages like OpenGL and GLUT. It also configures Windows-specific paths for GLUT libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTexture3D/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: Linking Windows-Specific Libraries\nDESCRIPTION: This snippet links Windows-specific libraries (freeglut.lib and glew64.lib) to the target. It uses conditional logic to only link these libraries when building on the Windows platform.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_16\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    target_link_libraries(postProcessGL\n        ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n        ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n    )\n\n    add_custom_command(TARGET postProcessGL\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\n\n    add_custom_command(TARGET postProcessGL\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Defining HSOpticalFlow Executable Target with Source Files\nDESCRIPTION: Creates the HSOpticalFlow executable target with its source files. Includes flowCUDA.cu for CUDA implementation, flowGold.cpp for CPU implementation, and main.cpp as the entry point.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/HSOpticalFlow/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# Source file\n# Add target for HSOpticalFlow\nadd_executable(HSOpticalFlow flowCUDA.cu flowGold.cpp main.cpp)\n```\n\n----------------------------------------\n\nTITLE: Initializing CUDA Driver API\nDESCRIPTION: Initializes the CUDA Driver API using cuInit(). This is a required step before using any CUDA driver functions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/threadMigration/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncuInit(0);\n```\n\n----------------------------------------\n\nTITLE: Declaring cudaLaunchDeviceV2 in NVVM IR\nDESCRIPTION: This snippet shows how to declare the cudaLaunchDeviceV2 function at the NVVM IR level. This declaration is necessary for using device-side kernel launch functionality. This requires linking with the cudadevrt system library. The input parameters include a pointer to the parameter buffer and the associated stream.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/device-side-launch/README.md#2025-04-21_snippet_0\n\nLANGUAGE: NVVM IR\nCODE:\n```\n; NVVM IR level declaration of cudaLaunchDeviceV2\ndeclare i32 @cudaLaunchDeviceV2(i8*, %struct.CUstream_st*)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA with OpenMP CMake Project\nDESCRIPTION: Configures a CMake project for building CUDA code with OpenMP support. The file sets minimum CMake version, configures CUDA architecture targets, adds compiler flags, and conditionally builds the project if OpenMP is available.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/cudaOpenMP/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cudaOpenMP LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nfind_package(OpenMP)\n\n# Source file\nif(OpenMP_CXX_FOUND)\n# Add target for asyncAPI\n    add_executable(cudaOpenMP cudaOpenMP.cu)\n\ntarget_compile_options(cudaOpenMP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cudaOpenMP PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(cudaOpenMP PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n    target_link_libraries(cudaOpenMP PUBLIC\n        OpenMP::OpenMP_CXX\n    )\nelse()\n    message(STATUS \"OpenMP not found - will not build sample 'cudaOpenMP'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Dependencies\nDESCRIPTION: List of required CUDA Runtime API functions used in the implementation including memory management and device property queries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpBezierTessellation/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaMemcpy, cudaFree, cudaGetDeviceCount, cudaMalloc, cudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions Used in cdpSimplePrint\nDESCRIPTION: This snippet lists the CUDA Runtime API functions utilized in the cdpSimplePrint sample. These functions are essential for device synchronization, error handling, property retrieval, and setting device limits.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpSimplePrint/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n### [CUDA Runtime API](http://docs.nvidia.com/cuda/cuda-runtime-api/index.html)\ncudaDeviceSynchronize, cudaGetLastError, cudaGetDeviceProperties, cudaDeviceSetLimit\n```\n\n----------------------------------------\n\nTITLE: Setting up CUDA Project Build Target\nDESCRIPTION: Configures the executable target with source files, compiler options, and C++/CUDA standard requirements. Includes necessary directories and links CUDA libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(MC_EstimatePiP src/main.cpp src/piestimator.cu src/test.cpp)\n\ntarget_compile_options(MC_EstimatePiP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(MC_EstimatePiP PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(MC_EstimatePiP PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(MC_EstimatePiP PUBLIC\n    ${CMAKE_CURRENT_SOURCE_DIR}/inc\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(MC_EstimatePiP PUBLIC\n    CUDA::curand\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA Sample\nDESCRIPTION: Sets up the project with minimum CMake version, CUDA language support, and module path configuration\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/recursiveGaussian/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(recursiveGaussian LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA Monte Carlo Pi Estimation\nDESCRIPTION: Complete CMake configuration for building a CUDA-accelerated Monte Carlo Pi Estimation application. It defines the minimum required CMake version, configures CUDA architectures, sets compiler flags, includes dependencies, and defines the build target with source files and linking options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(MC_EstimatePiQ LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for MC_EstimatePiQ\nadd_executable(MC_EstimatePiQ src/main.cpp src/piestimator.cu src/test.cpp)\n\ntarget_compile_options(MC_EstimatePiQ PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(MC_EstimatePiQ PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(MC_EstimatePiQ PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(MC_EstimatePiQ PUBLIC\n    ${CMAKE_CURRENT_SOURCE_DIR}/inc\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(MC_EstimatePiQ PUBLIC\n    CUDA::curand\n)\n```\n\n----------------------------------------\n\nTITLE: Executing Radix Sort with Thrust on CUDA GPU\nDESCRIPTION: This snippet shows the output of running a radix sort algorithm using the Thrust library on a CUDA-enabled GPU. It sorts 1,048,576 32-bit unsigned integer keys and values, reporting the device information, throughput, execution time, and test result.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_radixSortThrust.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n./radixSortThrust Starting...\n\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n\nSorting 1048576 32-bit unsigned int keys and values\n\nradixSortThrust, Throughput = 2276.9744 MElements/s, Time = 0.00046 s, Size = 1048576 elements\nTest passed\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architectures and Flags\nDESCRIPTION: This code snippet sets the CUDA architectures to target during compilation and adds a compiler flag to suppress warnings about deprecated GPU targets. It also conditionally sets a flag for debugging if the build type is Debug.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Build Target for Linux with CUDLA\nDESCRIPTION: Creates and configures the cuDLAHybridMode executable when building on Linux with the CUDLA library available. Sets up compiler options including extended lambda support and C++17/CUDA 17 standards, and links against the CUDLA library.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLAHybridMode/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    if(CUDLA_LIB)\n        # Source file\n        # Add target for cuDLAHybridMode\n        add_executable(cuDLAHybridMode main.cu)\n\n        target_compile_options(cuDLAHybridMode PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(cuDLAHybridMode PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(cuDLAHybridMode PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(cuDLAHybridMode PUBLIC\n            ${CUDAToolkit_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(cuDLAHybridMode\n            ${CUDLA_LIB}\n        )\n    else()\n        message(STATUS \"CUDLA not found - will not build sample 'cuDLAHybridMode'\")\n    endif()\nelse()\n    message(STATUS \"Will not build sample cuDLAHybridMode - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Including Directories for Compilation\nDESCRIPTION: This snippet includes necessary directories and source files for the project, specifically setting paths for header files and defining an executable target for MersenneTwisterGP11213.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for MersenneTwisterGP11213\nadd_executable(MersenneTwisterGP11213 MersenneTwister.cpp)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architectures and Compiler Flags\nDESCRIPTION: Specifies the CUDA architectures to build for and sets compiler flags, including debug options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleIPC/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architecture Targets and Compiler Flags\nDESCRIPTION: Defines the supported CUDA architectures (compute capabilities) and sets compiler flags including warnings about deprecated GPU targets. Contains conditional debug settings for CUDA-GDB.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/HSOpticalFlow/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Build for NVIDIA CUDA simpleMultiCopy Sample\nDESCRIPTION: Complete CMake configuration that sets up build requirements for a CUDA sample application. It specifies CUDA architectures (compute capabilities 5.0 through 12.0), includes common directories, and configures compiler options including C++17 and CUDA 17 standards with extended lambda support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleMultiCopy/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleMultiCopy LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleMultiCopy\nadd_executable(simpleMultiCopy simpleMultiCopy.cu)\n\ntarget_compile_options(simpleMultiCopy PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleMultiCopy PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleMultiCopy PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: CUDA Merge Sort Console Output\nDESCRIPTION: Console output showing the execution flow of a CUDA merge sort implementation on a Hopper GPU. The output includes initialization steps, execution timing of 1.344ms, and validation checks confirming correct sorting and stability.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_mergeSort.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n./mergeSort Starting...\n\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nAllocating and initializing host arrays...\n\nAllocating and initializing CUDA arrays...\n\nInitializing GPU merge sort...\nRunning GPU merge sort...\nTime: 1.344000 ms\nReading back GPU merge sort results...\nInspecting the results...\n...inspecting keys array: OK\n...inspecting keys and values array: OK\n...stability property: stable!\nShutting down...\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions Used in Quad Tree Implementation\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the Quad Tree implementation. These functions are essential for memory management, error handling, device configuration, and property querying in CUDA programming.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpQuadtree/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\ncudaMemcpy, cudaFree, cudaGetLastError, cudaDeviceSetLimit, cudaMalloc, cudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation for CUDA Texture Sample\nDESCRIPTION: Documentation describing a CUDA texture processing example that demonstrates the usage of CUDA Driver API for texture operations. The sample supports multiple SM architectures from 5.0 to 9.0 and runs on Linux and Windows platforms.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTextureDrv/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# simpleTextureDrv - Simple Texture (Driver Version)\n\n## Description\n\nSimple example that demonstrates use of Textures in CUDA.  This sample uses the new CUDA 4.0 kernel launch Driver API.\n\n## Key Concepts\n\nCUDA Driver API, Texture, Image Processing\n\n## Supported SM Architectures\n\n[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.9 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)\n\n## Supported OSes\n\nLinux, Windows\n\n## Supported CPU Architecture\n\nx86_64, armv7l\n\n## CUDA APIs involved\n\n### [CUDA Driver API](http://docs.nvidia.com/cuda/cuda-driver-api/index.html)\ncuMemcpyDtoH, cuLaunchKernel, cuModuleLoadData, cuDeviceGetName, cuDeviceGetAttribute, cuCtxSynchronize, cuMemAlloc, cuArrayCreate, cuMemFree, cuCtxDestroy, cuTexObjectDestroy, cuTexObjectCreate, cuCtxCreate, cuModuleGetFunction, cuArrayDestroy\n\n## Prerequisites\n\nDownload and install the [CUDA Toolkit 12.5](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.\n\n## References (for more details)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Matrix Multiplication Project\nDESCRIPTION: Sets up the CMake project, finds CUDA toolkit, and configures CUDA architectures and flags. It also sets up include directories and defines the main executable target.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/matrixMulDynlinkJIT/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(matrixMulDynlinkJIT LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for matrixMulDynlinkJIT\nadd_executable(matrixMulDynlinkJIT cuda_drvapi_dynlink.c matrixMulDynlinkJIT.cpp matrixMul_gold.cpp matrixMul_kernel_32_ptxdump.c matrixMul_kernel_64_ptxdump.c)\n```\n\n----------------------------------------\n\nTITLE: Building with Vulkan SDK Path on aarch64 (Linux)\nDESCRIPTION: This snippet details how to add the Vulkan SDK path when building a project on aarch64 Linux systems. The provided make command inputs the path to the Vulkan SDK, ensuring proper linkage during the build.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/Build_instructions.txt#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmake VULKAN_SDK_PATH=<PATH_TO_VULKAN_SDK>\n```\n\n----------------------------------------\n\nTITLE: NvSCI Library and Header Detection\nDESCRIPTION: Searches for required NVIDIA SCI (nvscibuf and nvscisync) libraries and headers in system paths. Includes logic for custom search paths via CMAKE_LIBRARY_PATH and CMAKE_INCLUDE_PATH.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLAStandaloneMode/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_LIBRARY_PATH \"/usr/lib\" ${CMAKE_LIBRARY_PATH})\nforeach(LIBRARY_PATH ${CMAKE_LIBRARY_PATH})\n    file(GLOB_RECURSE NVSCIBUF_LIB\n        ${LIBRARY_PATH}/libnvscibuf.so\n        ${LIBRARY_PATH}/*/libnvscibuf.so\n    )\n    file(GLOB_RECURSE NVSCISYNC_LIB\n        ${LIBRARY_PATH}/libnvscisync.so\n        ${LIBRARY_PATH}/*/libnvscisync.so\n    )\n    if(NVSCIBUF_LIB AND NVSCISYNC_LIB)\n        break()\n    endif()\nendforeach()\n\nset(CMAKE_INCLUDE_PATH \"/usr/include\" ${CMAKE_LIBRARY_PATH})\nfind_path(NVSCIBUF_INCLUDE_DIR nvscibuf.h PATHS ${CMAKE_INCLUDE_PATH})\nfind_path(NVSCISYNC_INCLUDE_DIR nvscisync.h PATHS ${CMAKE_INCLUDE_PATH})\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Project with CMake\nDESCRIPTION: Sets up a CUDA project with CMake including required CUDA toolkit, architecture targets, and compiler flags. Configures build settings for a template-based application using both CUDA and C++ source files.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/template/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(template LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for template\nadd_executable(template template.cu template_cpu.cpp)\n\ntarget_compile_options(template PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(template PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(template PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Linear Solver Execution Log\nDESCRIPTION: Console output showing the execution steps of a linear solver comparing CPU and GPU implementations. Includes matrix dimensions, solution accuracy metrics, and timing comparisons.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_cuSolverSp_LinearSolver.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nUsing default input file [../../../../Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/lap2D_5pt_n100.mtx]\nstep 1: read matrix market format\nsparse matrix A is 10000 x 10000 with 49600 nonzeros, base=1\nstep 2: reorder the matrix A to minimize zero fill-in\n        if the user choose a reordering by -P=symrcm, -P=symamd or -P=metis\nstep 2.1: no reordering is chosen, Q = 0:n-1 \nstep 2.2: B = A(Q,Q) \nstep 3: b(j) = 1 + j/n \nstep 4: prepare data on device\nstep 5: solve A*x = b on CPU \nstep 6: evaluate residual r = b - A*x (result on CPU)\n(CPU) |b - A*x| = 5.393685E-12 \n(CPU) |A| = 8.000000E+00 \n(CPU) |x| = 1.136492E+03 \n(CPU) |b| = 1.999900E+00 \n(CPU) |b - A*x|/(|A|*|x| + |b|) = 5.931079E-16 \nstep 7: solve A*x = b on GPU\nstep 8: evaluate residual r = b - A*x (result on GPU)\n(GPU) |b - A*x| = 1.970424E-12 \n(GPU) |A| = 8.000000E+00 \n(GPU) |x| = 1.136492E+03 \n(GPU) |b| = 1.999900E+00 \n(GPU) |b - A*x|/(|A|*|x| + |b|) = 2.166745E-16 \ntiming chol: CPU =   0.097956 sec , GPU =   0.103812 sec\nshow last 10 elements of solution vector (GPU) \nconsistent result for different reordering and solver \nx[9990] = 3.000016E+01\nx[9991] = 2.807343E+01\nx[9992] = 2.601354E+01\nx[9993] = 2.380285E+01\nx[9994] = 2.141866E+01\nx[9995] = 1.883070E+01\nx[9996] = 1.599668E+01\nx[9997] = 1.285365E+01\nx[9998] = 9.299423E+00\nx[9999] = 5.147265E+00\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for cuDLALayerwiseStatsHybrid CUDA Sample\nDESCRIPTION: Sets up the CMake project with minimum version, project name, and languages. It also configures the CUDA toolkit and sets CUDA architectures and flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLALayerwiseStatsHybrid/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../../cmake/Modules\")\n\nproject(cuDLALayerwiseStatsHybrid LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Compiler Options and Features for cuSolverRf\nDESCRIPTION: Configures compiler options including extended lambda support for CUDA and sets C++17 and CUDA C++17 as the required language standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverRf/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_options(cuSolverRf PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cuSolverRf PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cuSolverRf PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring Dependencies and Include Directories\nDESCRIPTION: Sets up include directories and finds OpenGL and GLUT dependencies. For Windows, it also specifies custom paths for GLUT libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bicubicTexture/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: Set CUDA Architectures\nDESCRIPTION: This sets the target CUDA architectures for compilation. It specifies the compute capabilities that the compiled code should support (50 52 60 61 70 72 75 80 86 87 89 90 100 101 120).\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\n```\n\n----------------------------------------\n\nTITLE: Windows-Specific Build Configuration\nDESCRIPTION: Adds Windows-specific library linking and post-build commands for copying required DLLs\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/recursiveGaussian/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    target_link_libraries(recursiveGaussian\n        ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n        ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n    )\n\n    add_custom_command(TARGET recursiveGaussian\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\n\n    add_custom_command(TARGET recursiveGaussian\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Conditional MPI Application Build Configuration\nDESCRIPTION: Conditionally builds the simpleMPI application if MPI is found on the system. Configures the executable with source files, C++17/CUDA 17 standards, and enables CUDA extended lambda support and separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleMPI/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif(${MPI_FOUND})\n    # Add target for simpleMPI\n    add_executable(simpleMPI simpleMPI.cpp simpleMPI.cu)\n\ntarget_compile_options(simpleMPI PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleMPI PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(simpleMPI PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n    target_include_directories(simpleMPI PUBLIC\n        ${MPI_INCLUDE_PATH}\n    )\n\n    target_link_libraries(simpleMPI PUBLIC\n        ${MPI_CXX_LIBRARIES}\n    )\n\nelse()\n    message(STATUS \"MPI not found - will not build sample 'simpleMPI'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA NVRTC Black-Scholes Project with CMake\nDESCRIPTION: This CMake script configures a CUDA project that implements the Black-Scholes financial model using NVRTC for runtime compilation. It sets up required CUDA architectures, compiler flags, dependencies, and ensures that kernel files are properly deployed alongside the executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/BlackScholes_nvrtc/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(BlackScholes_nvrtc LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for BlackScholes_nvrtc\nadd_executable(BlackScholes_nvrtc BlackScholes.cpp BlackScholes_gold.cpp)\n\ntarget_compile_options(BlackScholes_nvrtc PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(BlackScholes_nvrtc PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(BlackScholes_nvrtc PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_link_libraries(BlackScholes_nvrtc PRIVATE\n    CUDA::nvrtc\n    CUDA::cuda_driver\n)\n\n# Copy kernel to the output directory\nadd_custom_command(TARGET BlackScholes_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/BlackScholes_kernel.cuh ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Target Build Settings\nDESCRIPTION: Creates and configures the bindlessTexture executable target with necessary compiler options, features, and dependencies.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/bindlessTexture/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nadd_executable(bindlessTexture bindlessTexture.cpp bindlessTexture_kernel.cu)\n\ntarget_compile_options(bindlessTexture PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(bindlessTexture PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(bindlessTexture PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(bindlessTexture PUBLIC\n    ${OPENGL_INCLUDE_DIR}\n    ${CUDAToolkit_INCLUDE_DIRS}\n    ${GLUT_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(bindlessTexture\n    ${OPENGL_LIBRARIES}\n    ${GLUT_LIBRARIES}\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Function List\nDESCRIPTION: List of core CUDA Runtime API functions used in the implementation of Monte Carlo Single Asian Option simulation. These functions handle device management, memory operations, and error handling.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/README.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncudaMemcpy, cudaGetErrorString, cudaFree, cudaSetDevice, cudaGetDeviceCount, cudaMalloc, cudaFuncGetAttributes, cudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Compilation Options and Architectures\nDESCRIPTION: Configures CUDA-specific compilation options including target architectures, position-independent code, and compiler flags. It also sets up debug options conditionally.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/graphConditionalNodes/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Set Position Independent Code\nDESCRIPTION: Enables position-independent code (PIC) generation. This is often required for shared libraries and can improve security and compatibility.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Building CUDA Samples for Automotive Linux Platforms\nDESCRIPTION: Commands to build CUDA samples for Automotive Linux platforms. This requires specifying architecture-specific include and library paths to CMake.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/README.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nmkdir build\ncd build\n\ncmake -DCMAKE_CUDA_COMPILER=/usr/local/cuda/bin/nvcc -DCMAKE_LIBRARY_PATH=/usr/local/cuda/orin/lib64/ -DCMAKE_INCLUDE_PATH=/usr/local/cuda/orin/include -DBUILD_TEGRA=True ..\n```\n\n----------------------------------------\n\nTITLE: Configuring Dependencies for Box Filter Project\nDESCRIPTION: Sets up include directories and finds required packages like OpenGL and GLUT. It also handles Windows-specific configurations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/boxFilter/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: NvSci and NvMedia Library Detection\nDESCRIPTION: Searches for required NvSci and NvMedia shared libraries and headers in system paths. Uses glob patterns to find library files and configures include paths.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cudaNvSciNvMedia/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    set(CMAKE_LIBRARY_PATH \"/usr/lib\" ${CMAKE_LIBRARY_PATH})\n    foreach(LIBRARY_PATH ${CMAKE_LIBRARY_PATH})\n        file(GLOB_RECURSE NVSCIBUF_LIB\n            ${LIBRARY_PATH}/libnvscibuf.so\n            ${LIBRARY_PATH}/*/libnvscibuf.so\n        )\n        file(GLOB_RECURSE NVSCISYNC_LIB\n            ${LIBRARY_PATH}/libnvscisync.so\n            ${LIBRARY_PATH}/*/libnvscisync.so\n        )\n        file(GLOB_RECURSE NVMEDIA_LIB\n            ${LIBRARY_PATH}/libnvmedia.so\n            ${LIBRARY_PATH}/*/libnvmedia.so\n        )\n        if(NVSCIBUF_LIB AND NVSCISYNC_LIB AND NVMEDIA_LIB)\n            break()\n        endif()\n    endforeach()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Sample Project Build Settings with CMake\nDESCRIPTION: Sets up a CMake build configuration for a CUDA reduction multi-block conjugate gradient sample. Configures CUDA architecture targets, compiler flags, and project dependencies. Includes settings for debug builds and C++17/CUDA 17 language features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(reductionMultiBlockCG LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for reductionMultiBlockCG\nadd_executable(reductionMultiBlockCG reductionMultiBlockCG.cu)\n\ntarget_compile_options(reductionMultiBlockCG PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(reductionMultiBlockCG PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(reductionMultiBlockCG PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Project with CMake\nDESCRIPTION: This snippet sets up a CUDA project called 'alignedTypes' using CMake. It specifies minimum CMake version, CUDA Toolkit dependency, and compilation settings like CUDA architectures and compiler flags. Key parameters include CUDA architecture versions and flags for managing deprecated GPU targets.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/alignedTypes/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(alignedTypes LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for alignedTypes\nadd_executable(alignedTypes alignedTypes.cu)\n\ntarget_compile_options(alignedTypes PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(alignedTypes PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(alignedTypes PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring Dependencies and Build Target for cuDLALayerwiseStatsHybrid\nDESCRIPTION: Sets up include directories, finds the CUDLA library, and creates the build target for the cuDLALayerwiseStatsHybrid executable. It also configures compiler options, features, and links necessary libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLALayerwiseStatsHybrid/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../../Common)\n\nfind_library(CUDLA_LIB cudla PATHS ${CUDAToolkit_LIBRARY_DIR})\n\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    if(CUDLA_LIB)\n        # Source file\n        # Add target for cuDLALayerwiseStatsHybrid\n        add_executable(cuDLALayerwiseStatsHybrid main.cu)\n\n        target_compile_options(cuDLALayerwiseStatsHybrid PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(cuDLALayerwiseStatsHybrid PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(cuDLALayerwiseStatsHybrid PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(cuDLALayerwiseStatsHybrid PUBLIC\n            ${CUDAToolkit_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(cuDLALayerwiseStatsHybrid\n            ${CUDLA_LIB}\n        )\n    else()\n        message(STATUS \"CUDLA not found - will not build sample 'cuDLALayerwiseStatsHybrid'\")\n    endif()\nelse()\n    message(STATUS \"Will not build sample cuDLALayerwiseStatsHybrid - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project with CUDA Support\nDESCRIPTION: Basic CMake setup including minimum version requirement, module path configuration, and project language specifications.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleLayeredTexture/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleLayeredTexture LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Setting Target Properties for CUDA\nDESCRIPTION: This sets target properties for the StreamPriorities executable.  CUDA_SEPARABLE_COMPILATION is set to ON.  This enables separable compilation for CUDA, which can improve build times by allowing independent compilation of device code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_11\n\nLANGUAGE: cmake\nCODE:\n```\nset_target_properties(StreamPriorities PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Copying data matrix files to build directory\nDESCRIPTION: Creates post-build commands to copy required matrix data files to the build directory. These files contain the matrix data that will be processed by the linear solver application.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\n# Copy data files to output directory\nadd_custom_command(TARGET cuSolverDn_LinearSolver POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/gr_900_900_crg.mtx\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\nadd_custom_command(TARGET cuSolverDn_LinearSolver POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/lap3D_7pt_n20.mtx\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Compiling Options and Features\nDESCRIPTION: This snippet specifies additional compile options for the target executable based on the language used and establishes required C++ and CUDA standard versions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_options(MersenneTwisterGP11213 PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(MersenneTwisterGP11213 PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture Targets and Flags\nDESCRIPTION: Configures CUDA-specific build settings including supported architecture versions and compiler flags. Includes optional debug settings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleLayeredTexture/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Binomial Options Project with CMake\nDESCRIPTION: This CMake script sets up the build configuration for a CUDA Binomial Options project. It specifies CUDA architectures, compiler flags, and includes necessary dependencies. The script creates an executable target 'binomialOptions' with C++17 and CUDA 17 standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/binomialOptions/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(binomialOptions LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for binomialOptions\nadd_executable(binomialOptions binomialOptions.cpp binomialOptions_gold.cpp binomialOptions_kernel.cu)\n\ntarget_compile_options(binomialOptions PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(binomialOptions PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(binomialOptions PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(binomialOptions PUBLIC\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA Architecture and Compiler Flags Configuration\nDESCRIPTION: Sets up supported CUDA architectures and compiler flags including debug options and deprecated GPU target warnings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/jitLto/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Performing GPU Row Convolution in CUDA\nDESCRIPTION: This code performs row convolution on the GPU using CUDA. It runs multiple iterations and calculates the average execution time and performance in Mpix/s.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_convolutionTexture.txt#2025-04-21_snippet_1\n\nLANGUAGE: CUDA\nCODE:\n```\nRunning GPU rows convolution (10 identical iterations)...\nAverage convolutionRowsGPU() time: 0.117200 msecs; //40261.023178 Mpix/s\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Stream Ordered Allocation Project\nDESCRIPTION: Sets up the CMake project for the streamOrderedAllocation CUDA sample. It defines the project, finds the CUDA toolkit, sets CUDA architectures, and configures compiler flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(streamOrderedAllocation LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architectures and Flags\nDESCRIPTION: Defines the CUDA architectures to compile for and sets CUDA compilation flags, including debug options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTextureDrv/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Build Target for CUDA Application\nDESCRIPTION: Sets up the executable target with necessary compile options, C++17 and CUDA 17 features, and enables separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleLayeredTexture/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(simpleLayeredTexture simpleLayeredTexture.cu)\n\ntarget_compile_options(simpleLayeredTexture PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleLayeredTexture PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleLayeredTexture PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA simpleAssert_nvrtc Project\nDESCRIPTION: Sets up the CMake project for simpleAssert_nvrtc, including CUDA toolkit requirements, architecture settings, and compiler flags. It also defines the executable target and its dependencies.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleAssert_nvrtc/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleAssert_nvrtc LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add sample target executable\nadd_executable(simpleAssert_nvrtc simpleAssert.cpp)\n\ntarget_compile_options(simpleAssert_nvrtc PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleAssert_nvrtc PRIVATE cxx_std_17 cuda_std_17)\n\ntarget_link_libraries(simpleAssert_nvrtc PRIVATE\n    CUDA::nvrtc\n    CUDA::cuda_driver\n)\n\n# Copy clock_kernel.cu to the output directory\nadd_custom_command(TARGET simpleAssert_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/simpleAssert_kernel.cu ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Build for CUDA CUFFT Project\nDESCRIPTION: Configures CMake build settings for a CUDA CUFFT example, including CUDA architecture targets, compiler flags, and necessary dependencies. Sets up C++17 and CUDA 17 standards with extended lambda support and CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUFFT/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCUFFT LANGUAGES CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleCUFFT\nadd_executable(simpleCUFFT simpleCUFFT.cu)\n\ntarget_compile_options(simpleCUFFT PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleCUFFT PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleCUFFT PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_link_libraries(simpleCUFFT PRIVATE\n    CUDA::cufft\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring nvJPEG Encoder Target for x86_64 Platforms\nDESCRIPTION: This snippet defines the build target for the nvJPEG encoder executable on x86_64 platforms. It sets compile options, features, and links necessary libraries. The code also includes post-build commands for copying data to the output directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/nvJPEG_encoder/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    message(STATUS \"Will not build sample nvJPEG_encoder - not supported on aarch64\")\nelse()\n\n    # Source file\n    # Add target for nvJPEG_encoder\n    add_executable(nvJPEG_encoder nvJPEG_encoder.cpp)\n\n    target_compile_options(nvJPEG_encoder PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(nvJPEG_encoder PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(nvJPEG_encoder PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n    target_include_directories(nvJPEG_encoder PRIVATE\n        ${CUDAToolkit_INCLUDE_DIRS}\n    )\n\n    target_link_libraries(nvJPEG_encoder PRIVATE\n        CUDA::cudart\n        CUDA::nvjpeg\n    )\n\n    # Copy data to the output directory\n    add_custom_command(TARGET nvJPEG_encoder POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy_directory\n        ${CMAKE_CURRENT_SOURCE_DIR}/images\n        ${CMAKE_CURRENT_BINARY_DIR}/images\n    )\n\n    add_custom_command(TARGET nvJPEG_encoder POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy_directory\n        ${CMAKE_CURRENT_SOURCE_DIR}/encode_output\n        ${CMAKE_CURRENT_BINARY_DIR}/encode_output\n    )\n\nendif()\n```\n\n----------------------------------------\n\nTITLE: Including common headers and defining project source files\nDESCRIPTION: Sets up include directories for common header files and defines the main executable with its source files. This section establishes the core components of the application.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for cuSolverDn_LinearSolver\nadd_executable(cuSolverDn_LinearSolver cuSolverDn_LinearSolver.cpp mmio.c mmio_wrapper.cpp)\n```\n\n----------------------------------------\n\nTITLE: Adding executable target for StreamPriorities\nDESCRIPTION: This adds an executable target named StreamPriorities using the StreamPriorities.cu source file. It uses add_executable to define the executable and specify the source file to compile. This is the core command for building the executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: cmake\nCODE:\n```\nadd_executable(StreamPriorities StreamPriorities.cu)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Post-Build LLVM File Copy in CMake\nDESCRIPTION: Creates a post-build command to copy the LLVM bitcode file to the build directory, ensuring it's available where tests are executed.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/uvmlite/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(\n    TARGET uvmlite\n    POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n            \"${CMAKE_CURRENT_SOURCE_DIR}/uvmlite64.ll\" \"$<TARGET_FILE_DIR:uvmlite>\"\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Dependencies and Build Settings\nDESCRIPTION: Sets up CUDA Toolkit dependencies, enables position-independent code, and configures CUDA architecture targets. Sets specific CUDA flags including warning suppression for deprecated GPU targets.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLAHybridMode/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architectures and Compilation Flags\nDESCRIPTION: Defines supported CUDA architecture versions and sets compilation flags for the project, with optional debug configuration\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/recursiveGaussian/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA CMake project for simpleStreams\nDESCRIPTION: Complete CMake configuration for building the simpleStreams CUDA sample. It sets minimum CMake version, project languages, CUDA architectures, compilation flags, and creates the executable target with appropriate settings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleStreams/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleStreams LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleStreams\nadd_executable(simpleStreams simpleStreams.cu)\n\ntarget_compile_options(simpleStreams PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleStreams PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleStreams PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architectures and Flags\nDESCRIPTION: This code snippet sets the supported CUDA architectures for the project and optionally adds specific compilation flags for debugging build types.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Compiler Options and Features for CUDA Target\nDESCRIPTION: Sets compiler options for the CUDA target, including enabling extended lambda support and C++17 features. It also configures separable compilation and position-independent code settings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/matrixMulDynlinkJIT/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_options(matrixMulDynlinkJIT PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(matrixMulDynlinkJIT PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(matrixMulDynlinkJIT PROPERTIES\n    CUDA_SEPARABLE_COMPILATION ON\n    POSITION_INDEPENDENT_CODE OFF\n)\nset(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -no-pie\")\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Build Commands for Data and DLL Files\nDESCRIPTION: Copies teapot image file and FreeImage DLL to the build directory, with special handling for Windows\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/boxFilterNPP/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET boxFilterNPP POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/teapot512.pgm\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n\nif(WIN32)\n    add_custom_command(TARGET boxFilterNPP\n    POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy\n    ${FreeImage_LIBRARY}/../FreeImage.dll\n    ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Defining a Structure in C for CUDA\nDESCRIPTION: This snippet defines a simple structure with two float members for use in CUDA programs. It highlights the importance of defining structured types while considering memory alignment to enhance load/store efficiency when interacting with global memory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/alignedTypes/doc/alignedTypes.txt#2025-04-21_snippet_0\n\nLANGUAGE: C\nCODE:\n```\ntypedef struct{\n    float a;\n    float b;\n} testStructure;\n```\n\n----------------------------------------\n\nTITLE: Using ptxgen command to generate PTX code for compute_50 architecture\nDESCRIPTION: Example command showing how to use ptxgen to link two NVVM IR files (a.ll in text format and b.bc in bitcode format) and generate PTX code for the compute_50 architecture.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/ptxgen/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ptxgen a.ll -arch=compute_50 b.bc\n```\n\n----------------------------------------\n\nTITLE: Finding OpenGL and GLUT Packages\nDESCRIPTION: This snippet uses the `find_package` command to locate the OpenGL and GLUT libraries. These are essential for rendering and window management within the application.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA FunctionPointers Sample\nDESCRIPTION: This CMake snippet sets up the project, finds required packages, and configures CUDA-specific settings. It sets CUDA architectures, compiler flags, and includes necessary directories.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/FunctionPointers/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(FunctionPointers LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for simpleCUBLAS_LU CUDA Project\nDESCRIPTION: Sets up the CMake project for simpleCUBLAS_LU, including CUDA toolkit requirements, architecture targets, and compiler flags. It creates an executable target with CUDA and C++17 support, linking necessary CUDA libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCUBLAS_LU LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleCUBLAS_LU\nadd_executable(simpleCUBLAS_LU simpleCUBLAS_LU.cpp)\n\ntarget_compile_options(simpleCUBLAS_LU PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleCUBLAS_LU PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleCUBLAS_LU PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(simpleCUBLAS_LU PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(simpleCUBLAS_LU PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Settings for EGLStream CUDA Interop Project\nDESCRIPTION: Sets up CUDA-specific configurations including target architectures and compiler flags. It also enables CUDA separable compilation and sets C++ and CUDA standards to 17.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\ntarget_compile_options(EGLStream_CUDA_Interop PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(EGLStream_CUDA_Interop PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(EGLStream_CUDA_Interop PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Setting Compile Features\nDESCRIPTION: This command sets the compile features for the target 'simpleVulkan'. It specifies that C++17 and CUDA 17 standards should be used.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_13\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_compile_features(simpleVulkan PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: Setting Compile Features\nDESCRIPTION: This sets compile features required by the target. target_compile_features enables cxx_std_17 and cuda_std_17. These indicate that C++17 and CUDA 17 standards are used, ensuring compatibility with specific language features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_compile_features(StreamPriorities PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: Installing UVMLite Components in CMake\nDESCRIPTION: Configures the installation of the UVMLite executable and its required LLVM bitcode file to the bin directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/uvmlite/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\ninstall(TARGETS uvmlite DESTINATION bin)\ninstall(FILES uvmlite64.ll DESTINATION bin)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Minimum Version and Project Setup\nDESCRIPTION: Sets the minimum required CMake version, adds module paths, and defines the project with CUDA language support\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/boxFilterNPP/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(boxFilterNPP LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture Targets in CMake\nDESCRIPTION: Specifies the CUDA architectures to compile for, spanning multiple generations of NVIDIA GPUs from compute capability 5.0 to 12.0. Also sets compiler flags including a warning suppression for deprecated GPU targets.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleMPI/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Project with CMake\nDESCRIPTION: Sets up a CUDA project named 'simpleCallback' with specific CUDA architectures and compiler flags. It includes necessary directories and configures the build for a CUDA executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleCallback/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCallback LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleCallback\nadd_executable(simpleCallback simpleCallback.cu multithreading.cpp)\n\ntarget_compile_options(simpleCallback PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleCallback PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleCallback PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Initializing CUDA Project with Compiler Settings\nDESCRIPTION: Defines the project name, language, CUDA architectures, and compiler flags for CUDA development\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/FilterBorderControlNPP/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nproject(FilterBorderControlNPP LANGUAGES CXX)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project with CUDA Support\nDESCRIPTION: Sets up a CMake project with CUDA support, configuring minimum version requirements and project languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/jacobiCudaGraphs/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(jacobiCudaGraphs LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Using CUDA Runtime API Functions in Conjugate Gradient Solver\nDESCRIPTION: A list of the CUDA Runtime API functions used in the conjugate gradient solver implementation, including memory management (cudaMalloc, cudaMemcpy, cudaFree) and synchronization functions (cudaDeviceSynchronize).\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/conjugateGradient/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaMalloc, cudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architectures and Compilation Flags\nDESCRIPTION: Defines supported CUDA compute architectures and sets compilation flags to suppress deprecated GPU target warnings. Provides optional debug configuration.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/LargeKernelParameter/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 70 72 75 80 86 87 89 90 100 101 120)\n```\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n```\n\n----------------------------------------\n\nTITLE: Required CUDA Runtime API Functions\nDESCRIPTION: List of essential CUDA Runtime API functions used in the reduction implementation, including memory management and device operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/reduction/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMemcpy\ncudaFree\ncudaSetDevice\ncudaDeviceSynchronize\ncudaGetDevice\ncudaMalloc\ncudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Adding Post-Build Commands to Copy Data Files\nDESCRIPTION: Adds post-build commands to copy required matrix data files (lap2D_5pt_n100.mtx and lap3D_7pt_n20.mtx) to the output directory after successful build.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverRf/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\n# Copy data files to output directory\nadd_custom_command(TARGET cuSolverRf POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/lap2D_5pt_n100.mtx\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET cuSolverRf POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/lap3D_7pt_n20.mtx\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Project Setup and Dependencies\nDESCRIPTION: Initializes the CMake project, sets up module paths, and configures basic project requirements including CUDA toolkit dependency and position-independent code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpSimplePrint/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cdpSimplePrint LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring Project with CMake for CUDA in CMake\nDESCRIPTION: This CMake script configures build settings for the 'quasirandomGenerator' project, which involves CUDA programming. It specifies the supported CUDA architectures, sets flags for the CUDA compiler, includes necessary directories, and defines an executable target with its source files. 'CUDAToolkit' is a prerequisite here, and the build supports both C++ and CUDA standards version 17.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(quasirandomGenerator LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for quasirandomGenerator\nadd_executable(quasirandomGenerator quasirandomGenerator.cpp quasirandomGenerator_gold.cpp quasirandomGenerator_kernel.cu)\n\ntarget_compile_options(quasirandomGenerator PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(quasirandomGenerator PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(quasirandomGenerator PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(quasirandomGenerator PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architectures and Flags\nDESCRIPTION: This snippet defines the CUDA architectures to build for, including various NVIDIA GPU architectures. It also sets CUDA compiler flags to suppress warnings about deprecated GPU targets. A debug configuration might enable CUDA debugging flags, but this is commented out due to its performance impact.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Target Compile Options\nDESCRIPTION: This command sets compile options for the 'stereoDisparity' target, specifically enabling extended lambda support for CUDA compilation. It applies only when the compile language is CUDA.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_options(stereoDisparity PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n```\n\n----------------------------------------\n\nTITLE: Setting target properties\nDESCRIPTION: This command sets properties for the specified target. In this case, it enables CUDA separable compilation for the 'cudaGraphsPerfScaling' target. This allows for separate compilation of CUDA device code, which can improve build times and reduce code size.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/cudaGraphsPerfScaling/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: cmake\nCODE:\n```\nset_target_properties(cudaGraphsPerfScaling PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Build Targets - CMake\nDESCRIPTION: This snippet defines custom targets 'clobber' and 'testrun' in CMake, allowing users to run specific build commands while organizing the build process. No specific dependencies are required, and the targets can be invoked without additional parameters.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/cuda-shared-memory/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_target(clobber)\nadd_custom_target(testrun)\n```\n\n----------------------------------------\n\nTITLE: Configuring Include Directories for fluidsGLES\nDESCRIPTION: Adds the required include directories to the fluidsGLES target, including EGL, OpenGL, and CUDA toolkit headers. These are necessary for compiling the application with graphics and CUDA support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/fluidsGLES/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_include_directories(fluidsGLES PUBLIC\n    ${EGL_INCLUDE_DIR}\n    ${OPENGL_INCLUDE_DIR}\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Post-Build Steps for Particles Project\nDESCRIPTION: Sets up post-build commands to copy necessary data and DLL files for the particles project, with special handling for Windows platforms.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/particles/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET particles POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n\nif(WIN32)\n    target_link_libraries(particles\n        ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n        ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n    )\n\n    add_custom_command(TARGET particles\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\n\n    add_custom_command(TARGET particles\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Describing deviceQueryDrv Utility in Markdown\nDESCRIPTION: This snippet describes the deviceQueryDrv utility, which enumerates CUDA device properties using the CUDA Driver API calls.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/README.md#2025-04-21_snippet_2\n\nLANGUAGE: Markdown\nCODE:\n```\n### [deviceQueryDrv](./deviceQueryDrv)\nThis sample enumerates the properties of the CUDA devices present using CUDA Driver API calls\n```\n\n----------------------------------------\n\nTITLE: CUDA Solver Execution Log\nDESCRIPTION: Program output showing the execution steps of sparse Cholesky decomposition and linear system solving, including accuracy measurements for both CPU and GPU implementations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_cuSolverSp_LowlevelCholesky.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nUsing default input file [../../../../Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/lap2D_5pt_n100.mtx]\nstep 1: read matrix market format\nsparse matrix A is 10000 x 10000 with 49600 nonzeros, base=1\nstep 2: create opaque info structure\nstep 3: analyze chol(A) to know structure of L\nstep 4: workspace for chol(A)\nstep 5: compute A = L*L^T \nstep 6: check if the matrix is singular \nstep 7: solve A*x = b \nstep 8: evaluate residual r = b - A*x (result on CPU)\n(CPU) |b - A*x| = 3.637979E-12 \n(CPU) |A| = 8.000000E+00 \n(CPU) |x| = 7.513384E+02 \n(CPU) |b - A*x|/(|A|*|x|) = 6.052497E-16 \nstep 9: create opaque info structure\nstep 10: analyze chol(A) to know structure of L\nstep 11: workspace for chol(A)\nstep 12: compute A = L*L^T \nstep 13: check if the matrix is singular \nstep 14: solve A*x = b \n(GPU) |b - A*x| = 1.477929E-12 \n(GPU) |b - A*x|/(|A|*|x|) = 2.458827E-16\n```\n\n----------------------------------------\n\nTITLE: Setting up CMake project for cuSolverDn_LinearSolver CUDA application\nDESCRIPTION: Configures the CMake project with minimum required version, module paths, and C/C++ language support. This is the initial setup for the CUDA-based linear solver application.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cuSolverDn_LinearSolver LANGUAGES C CXX)\n```\n\n----------------------------------------\n\nTITLE: Configuring Mandelbrot executable target with CUDA and C++ support\nDESCRIPTION: Creates the Mandelbrot executable target with CUDA and C++ source files. Enables extended lambda support for CUDA, sets C++17 and CUDA 17 standards, and configures separable compilation for better performance.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/Mandelbrot/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(Mandelbrot Mandelbrot_cuda.cu Mandelbrot_gold.cpp Mandelbrot.cpp)\n\ntarget_compile_options(Mandelbrot PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(Mandelbrot PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(Mandelbrot PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Linking CUDA C with LLVM IR Module in C++\nDESCRIPTION: The main file 'cuda-c-linking.cpp' demonstrates generating PTX files using libnvvm and linking them with a CUDA C device library. It generates an LLVM IR module with a call to an externally defined function. Dependencies include LLVM C++ API, libnvvm, and CUDA Driver API. Inputs involve a CUDA C library and an LLVM IR module; output is a linked CUBIN image. Constraints involve CUDA-compatible devices and libraries conforming to NVVM IR specifications.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/cuda-c-linking/README.md#2025-04-21_snippet_0\n\nLANGUAGE: C++\nCODE:\n```\n// cuda-c-linking.cpp file demonstrating the creation of PTX and linking\n// No specific code snippet provided; inferred description from file list\n```\n\n----------------------------------------\n\nTITLE: Monte Carlo Pi Estimation Results\nDESCRIPTION: Terminal output showing the results and performance metrics of a CUDA-based Monte Carlo simulation for estimating Pi. The output includes precision settings, simulation count, error tolerances, and performance metrics.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_MC_EstimatePiQ.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nPrecision:      single\nNumber of sims: 100000\nTolerance:      1.000000e-02\nGPU result:     3.141840e+00\nExpected:       3.141593e+00\nAbsolute error: 2.472401e-04\nRelative error: 7.869895e-05\n\nMonteCarloEstimatePiQ, Performance = 821146.16 sims/s, Time = 121.78(ms), NumDevsUsed = 1, Blocksize = 128\n```\n\n----------------------------------------\n\nTITLE: Compiling Shaders with glslc\nDESCRIPTION: Instructions for using the glslc compiler from the Vulkan SDK to compile vertex and fragment shader source files. Requires the Vulkan SDK to be installed and available in the system's PATH.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/vulkanImageCUDA/Build_instructions.txt#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nglslc shader.vert -o vert.spv\nglslc shader.frag -o frag.spv\n\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Topology Query Application with CMake\nDESCRIPTION: This CMake configuration sets up a CUDA application for querying GPU topology. It specifies CUDA architectures from compute capability 5.0 to 12.0, configures compiler flags, and includes necessary dependencies. The build is conditionally skipped on aarch64 processors where the application is not supported.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/topologyQuery/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(topologyQuery LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    message(STATUS \"Will not build sample topologyQuery - not supported on aarch64\")\nelse()\n    # Source file\n    # Add target for topologyQuery\n    add_executable(topologyQuery topologyQuery.cu)\n\n    target_compile_options(topologyQuery PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(topologyQuery PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(topologyQuery PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Finding the CUDA Toolkit\nDESCRIPTION: This uses the find_package command to locate the CUDA toolkit.  The REQUIRED keyword ensures that the build fails if the CUDA toolkit is not found. This is crucial for projects using CUDA, as it provides the necessary libraries and tools.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Set CUDA Architectures and Flags\nDESCRIPTION: Sets the target CUDA architectures for compilation and adds a compiler flag to suppress warnings about deprecated GPU targets. It also includes conditional setting of CUDA flags for debug builds.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Include Directories for Target\nDESCRIPTION: This snippet sets the include directories for the target. It specifies where the compiler should look for header files required by the target's source code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_13\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_include_directories(postProcessGL PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n```\n\n----------------------------------------\n\nTITLE: Configuring Include Directories and Linking Libraries\nDESCRIPTION: Adds include directories for the project and links necessary CUDA libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/MonteCarloMultiGPU/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_include_directories(MonteCarloMultiGPU PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(MonteCarloMultiGPU PRIVATE\n    CUDA::curand\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Post-Build Copy Commands for PTX Generator\nDESCRIPTION: Defines post-build commands to copy necessary files to the target directory. For all platforms, copies the test.ll file, and for Windows specifically, copies the NVVM DLL to the target directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/ptxgen/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(\n    TARGET ptxgen\n    POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n            \"${CMAKE_CURRENT_SOURCE_DIR}/test.ll\" \"$<TARGET_FILE_DIR:ptxgen>\"\n)\nif (WIN32)\n  add_custom_command(\n      TARGET ptxgen\n      POST_BUILD\n      COMMAND ${CMAKE_COMMAND} -E copy_if_different\n              \"${CMAKE_BINARY_DIR}/nvvm64_40_0.dll\" \"$<TARGET_FILE_DIR:ptxgen>\"\n  )\nendif ()\n```\n\n----------------------------------------\n\nTITLE: Configuring Target Build with FreeImage Dependency\nDESCRIPTION: Conditional target configuration that proceeds only if FreeImage is found. Sets up the executable target with appropriate compiler options, C++17/CUDA standards, and links required libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/freeImageInteropNPP/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif(${FreeImage_FOUND})\n    # Add target for freeImageInteropNPP\n    add_executable(freeImageInteropNPP freeImageInteropNPP.cpp)\n\n    target_compile_options(freeImageInteropNPP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(freeImageInteropNPP PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(freeImageInteropNPP PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n    target_include_directories(freeImageInteropNPP PRIVATE\n        ${CUDAToolkit_INCLUDE_DIRS}\n        ${FreeImage_INCLUDE_DIRS}\n    )\n\n    target_link_libraries(freeImageInteropNPP PRIVATE\n        CUDA::nppc\n        CUDA::nppisu\n        CUDA::nppif\n        CUDA::cudart\n        ${FreeImage_LIBRARIES}\n    )\n```\n\n----------------------------------------\n\nTITLE: Setting Test Properties in CMake\nDESCRIPTION: Sets properties for both syscall tests, specifying that they require the PTXGENTEST fixture to be available before execution.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/syscalls/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nset_tests_properties(test-syscalls-vprintf test-syscalls-malloc-free\n                     PROPERTIES FIXTURES_REQUIRED PTXGENTEST)\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA Thread Migration\nDESCRIPTION: Sets up the CMake project, finds CUDA toolkit, and configures basic project settings. It sets CUDA architectures and compiler flags for the project.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/threadMigration/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(threadMigration LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Settings and Build Properties\nDESCRIPTION: Sets up build properties including CUDA Toolkit dependencies, position-independent code, target CUDA architectures, and compiler flags including conditional debug options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/freeImageInteropNPP/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Defining the CUDA project\nDESCRIPTION: This command defines the CUDA project with the name 'cudaGraphsPerfScaling' and specifies the supported languages: C, C++, and CUDA. It initializes the project and enables CMake to handle source files written in these languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/cudaGraphsPerfScaling/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nproject(cudaGraphsPerfScaling LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Creating BicubicTexture Executable Target\nDESCRIPTION: Adds the executable target for bicubicTexture, sets compiler options, features, and properties. It also specifies include directories and links required libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bicubicTexture/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        add_executable(bicubicTexture bicubicTexture.cpp bicubicTexture_cuda.cu)\n\n        target_compile_options(bicubicTexture PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(bicubicTexture PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(bicubicTexture PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(bicubicTexture PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(bicubicTexture\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n```\n\n----------------------------------------\n\nTITLE: Add Executable Target\nDESCRIPTION: This snippet creates an executable target named `UnifiedMemoryPerf` and specifies the source files that will be compiled to create the executable. The source files include `helperFunctions.cpp`, `matrixMultiplyPerf.cu`, and `commonKernels.cu`.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: cmake\nCODE:\n```\nadd_executable(UnifiedMemoryPerf helperFunctions.cpp matrixMultiplyPerf.cu commonKernels.cu)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Build Settings\nDESCRIPTION: Configures CUDA-specific build settings including architecture targets, compiler flags, and debug options. It sets position-independent code and defines CUDA architectures to build for.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/scalarProd/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Copying Data between CPU and GPU in CUDA\nDESCRIPTION: This snippet shows the use of cudaMemcpy for transferring data between host (CPU) and device (GPU) memory. It's essential for moving input data to the GPU and retrieving results.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/scalarProd/README.md#2025-04-21_snippet_2\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMemcpy\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture Targets in CMake\nDESCRIPTION: Configures the CUDA architectures to be supported by the application, spanning from Compute Capability 5.0 to 12.0. It also sets warning suppression for deprecated GPU targets.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/deviceQueryDrv/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n```\n\n----------------------------------------\n\nTITLE: Finding CUDA Toolkit Package\nDESCRIPTION: This snippet requires the CUDA Toolkit as a dependency for the project, ensuring that necessary CUDA components are available for building.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Defining and Configuring cuSolverSp_LowlevelQR Executable Target\nDESCRIPTION: This snippet defines the cuSolverSp_LowlevelQR executable target, sets its source files, and configures compilation options including C++ and CUDA standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(cuSolverSp_LowlevelQR cuSolverSp_LowlevelQR.cpp mmio.c mmio_wrapper.cpp)\n\ntarget_compile_options(cuSolverSp_LowlevelQR PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cuSolverSp_LowlevelQR PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cuSolverSp_LowlevelQR PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(cuSolverSp_LowlevelQR PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(cuSolverSp_LowlevelQR PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n    CUDA::cusolver\n)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Separable Compilation Property\nDESCRIPTION: This snippet sets the `CUDA_SEPARABLE_COMPILATION` property for the target.  This enables separable compilation for CUDA code, which can improve build times for large projects.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_12\n\nLANGUAGE: CMake\nCODE:\n```\nset_target_properties(postProcessGL PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Set Target Compile Features\nDESCRIPTION: This snippet sets the C++ and CUDA standard to C++17 and CUDA 17 respectively for the `UnifiedMemoryPerf` target. This enables the use of features introduced in these standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_11\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_compile_features(UnifiedMemoryPerf PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: Append Module Path for CMake\nDESCRIPTION: Appends a custom module path to CMAKE_MODULE_PATH. This allows CMake to find custom modules located in the specified directory. The path is relative to the current source directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: Configuring and Building with CMake\nDESCRIPTION: This CMake script configures the build process for a CUDA sample executable named 'dsl'. It specifies the runtime search path, links necessary libraries, defines platform-specific compilation and linking flags, and ensures that required files are copied post build. Dependencies include NVVM and CUDA libraries. The script handles the loading of an LLVM file during test execution and adjusts settings for Windows compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/device-side-launch/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_INSTALL_RPATH ${LIBNVVM_HOME})\nset(CMAKE_INCLUDE_CURRENT_DIR YES)\nset_property(SOURCE dsl.c\n             PROPERTY COMPILE_DEFINITIONS LIBCUDADEVRT=\\\"${CUDADEVRT_LIB}\\\")\n\nadd_executable(dsl dsl.c)\n\nadd_test(NAME device-side-launch COMMAND dsl\n\tWORKING_DIRECTORY \\\"${CMAKE_CURRENT_BINARY_DIR}\\\")\ntarget_link_libraries(dsl ${NVVM_LIB} ${CUDA_LIB})\n\nif (WIN32)\n  set_target_properties(dsl PROPERTIES COMPILE_FLAGS \\\"/wd4996\\\")\nelse (WIN32)\n  set_target_properties(dsl PROPERTIES LINK_FLAGS \\\"-Wl,-rpath,${LIBNVVM_RPATH}\\\")\nendif (WIN32)\n\ninstall(TARGETS dsl DESTINATION bin)\ninstall(FILES dsl-gpu64.ll DESTINATION bin)\n\n# 'dsl' will load dsl-gpu64.ll from the current working directory. That\n# .ll file should be present where tests are executed (the build directory).\nadd_custom_command(\n    TARGET dsl\n    POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n            \\\"${CMAKE_CURRENT_SOURCE_DIR}/dsl-gpu64.ll\\\" \\\"$<TARGET_FILE_DIR:dsl>\\\"\n)\nif (WIN32)\n  add_custom_command(\n      TARGET dsl\n      POST_BUILD\n      COMMAND ${CMAKE_COMMAND} -E copy_if_different\n              \\\"${CMAKE_BINARY_DIR}/nvvm64_40_0.dll\\\" \\\"$<TARGET_FILE_DIR:dsl>\\\"\n  )\nendif ()\n```\n\n----------------------------------------\n\nTITLE: Windows-Specific Library Linking and DLL Copying\nDESCRIPTION: Configures Windows-specific library linking for freeglut and GLEW. Adds post-build commands to copy required DLLs to the build directory for runtime dependency resolution on Windows platforms.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/randomFog/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    target_link_libraries(randomFog\n        ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n        ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n    )\n\n    add_custom_command(TARGET randomFog\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\n\n    add_custom_command(TARGET randomFog\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA Monte Carlo Pi Estimation\nDESCRIPTION: Sets up a CMake project for Monte Carlo Pi estimation using CUDA, including module paths, language requirements, and project naming.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(MC_EstimatePiInlineQ LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Building FunctionPointers CUDA Sample with OpenGL and GLUT\nDESCRIPTION: This CMake snippet adds the FunctionPointers executable target, sets compilation options, and links necessary libraries. It also handles copying data files and DLLs for Windows builds.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/FunctionPointers/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        # Add target for FunctionPointers\n        add_executable(FunctionPointers FunctionPointers.cpp FunctionPointers_kernels.cu)\n\n        target_compile_options(FunctionPointers PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(FunctionPointers PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(FunctionPointers PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(FunctionPointers PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(FunctionPointers\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n\n        # Copy data files to output directory\n        add_custom_command(TARGET FunctionPointers POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_directory\n            ${CMAKE_CURRENT_SOURCE_DIR}/data\n            ${CMAKE_CURRENT_BINARY_DIR}\n        )\n\n        if(WIN32)\n            target_link_libraries(FunctionPointers\n                ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n                ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n            )\n\n            add_custom_command(TARGET FunctionPointers\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n\n            add_custom_command(TARGET FunctionPointers\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n        endif()\n\n    else()\n        message(STATUS \"GLUT not found - will not build sample 'FunctionPointers'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'FunctionPointers'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Project Definition and Language Support\nDESCRIPTION: This command defines the project name as 'nbody' and specifies that the project uses the C, C++, and CUDA languages. This allows CMake to configure the build system to handle files written in these languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nproject(nbody LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Target for Fatbin Generation\nDESCRIPTION: Defines a custom target for generating the CUDA fatbin file and ensures the main target depends on it.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTextureDrv/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_target(generate_fatbin_textureDrv ALL DEPENDS ${CUDA_FATBIN_FILE})\n\nadd_dependencies(simpleTextureDrv generate_fatbin_textureDrv)\n```\n\n----------------------------------------\n\nTITLE: Setting Up CMake Project for HSOpticalFlow with CUDA Support\nDESCRIPTION: Configures a CMake project named HSOpticalFlow with C, C++, and CUDA language support. Sets the minimum CMake version requirement and establishes the module path for custom modules.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/HSOpticalFlow/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(HSOpticalFlow LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Enabling CUDA Separable Compilation\nDESCRIPTION: This command sets the CUDA_SEPARABLE_COMPILATION property to ON for the 'nbody' target. This enables separable compilation for CUDA code, which can improve build times for large projects.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_12\n\nLANGUAGE: cmake\nCODE:\n```\nset_target_properties(nbody PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions Used in Simple CUBLAS Example\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the Simple CUBLAS example, specifically cudaMalloc and cudaFree for GPU memory management.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUBLAS/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n### [CUDA Runtime API](http://docs.nvidia.com/cuda/cuda-runtime-api/index.html)\ncudaMalloc, cudaFree\n```\n\n----------------------------------------\n\nTITLE: Installing GLFW3 on Ubuntu\nDESCRIPTION: Commands to install the GLFW3 library and its development packages on an Ubuntu system using apt-get. This snippet assumes the presence of a standard Linux package management system.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/vulkanImageCUDA/Build_instructions.txt#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsudo apt-get install libglfw3\nsudo apt-get install libglfw3-dev\n\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture Targets for Different Platforms\nDESCRIPTION: Configures CUDA architecture targets based on system processor type, differentiating between Tegra ARM64 and other platforms. Sets appropriate compute capabilities for each platform type.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpSimplePrint/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    # Need to differentiate Tegra_aarch64 and other aarch64 systems(sbsa_aarch64) as they have different CUDA_ARCHITECTURES list\n    if(${BUILD_TEGRA})\n        set(CMAKE_CUDA_ARCHITECTURES 72 87 101)\n    else()\n        set(CMAKE_CUDA_ARCHITECTURES 61 70 75 80 86 90)\n    endif()\nelse()\n    set(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 75 80 86 89 90 100 101 120)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA Sample\nDESCRIPTION: Sets up a CUDA project with minimum version requirements, defines project languages, and configures CUDA toolkit dependencies\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/dxtc/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(dxtc LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Configuring Linux-specific Build Target for SimpleGLES\nDESCRIPTION: Configures the build target specifically for Linux systems, including dependency checks for OpenGL, EGL, and X11. Sets up compilation features, linking libraries, and handles GLSL shader file copying.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/simpleGLES/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(EGL)\nfind_package(X11)\nfind_package(OpenGL)\n\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    if(${OpenGL_FOUND})\n        if(${EGL_FOUND})\n            if(${X11_FOUND})\n                add_executable(simpleGLES simpleGLES.cu)\n\n                target_compile_options(simpleGLES PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n                target_compile_features(simpleGLES PRIVATE cxx_std_17 cuda_std_17)\n\n                set_target_properties(simpleGLES PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n                target_include_directories(simpleGLES PUBLIC\n                    ${EGL_INCLUDE_DIR}\n                    ${OPENGL_INCLUDE_DIR}\n                    ${CUDAToolkit_INCLUDE_DIRS}\n                )\n\n                target_link_libraries(simpleGLES\n                    ${EGL_LIBRARY}\n                    ${X11_LIBRARIES}\n                    ${OPENGL_LIBRARIES}\n                )\n\n                add_custom_command(TARGET simpleGLES POST_BUILD\n                    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n                    ${CMAKE_CURRENT_SOURCE_DIR}/mesh.frag.glsl\n                    ${CMAKE_CURRENT_SOURCE_DIR}/mesh.vert.glsl\n                    ${CMAKE_CURRENT_BINARY_DIR}\n                )\n\n            else()\n                message(STATUS \"X11 libraries not found - will not build sample 'simpleGLES'\")\n            endif()\n        else()\n            message(STATUS \"EGL not found - will not build sample 'simpleGLES'\")\n        endif()\n    else()\n        message(STATUS \"OpenGL not found - will not build sample 'simpleGLES'\")\n    endif()\nelse()\n    message(STATUS \"Will not build sample simpleGLES - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Target Properties for CUDA Separable Compilation\nDESCRIPTION: This command sets target properties for 'stereoDisparity', enabling CUDA separable compilation. Separable compilation can improve build times for large CUDA projects.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: CMake\nCODE:\n```\nset_target_properties(stereoDisparity PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring Platform-Specific Build Settings in CMake\nDESCRIPTION: Sets up platform-specific build settings for Windows and Linux. On Windows, it disables warning 4996 and sets the architecture suffix, while on Linux it configures RPATH settings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/uvmlite/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif (WIN32)\n  set (LIB_ARCH_SUFFIX \"/x64\")\n  set_target_properties(uvmlite PROPERTIES COMPILE_FLAGS \"/wd4996\")\nelse (WIN32)\n  set (LIB_ARCH_SUFFIX \"64\")\n  set_target_properties(uvmlite PROPERTIES\n                        LINK_FLAGS \"-Wl,-rpath,${LIBNVVM_RPATH}\")\nendif ()\n```\n\n----------------------------------------\n\nTITLE: Include Directories\nDESCRIPTION: This snippet adds a directory to the include path.  This allows the compiler to find header files located in the specified directory during compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Configuring Post-Build Commands for SobelFilter in CMake\nDESCRIPTION: Sets up post-build commands to copy necessary data and DLL files. For Windows, it copies freeglut.dll and glew64.dll to the build directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/SobelFilter/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET SobelFilter POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n\nif(WIN32)\n    target_link_libraries(SobelFilter\n        ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n        ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n    )\n\n    add_custom_command(TARGET SobelFilter\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\n\n    add_custom_command(TARGET SobelFilter\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting up Post-Build Actions for Resource Copying\nDESCRIPTION: Configures post-build commands to copy required data files to the output directory. On Windows systems, it additionally copies the FreeImage DLL to the output directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/freeImageInteropNPP/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\n    # Copy data files to output directory\n    add_custom_command(TARGET freeImageInteropNPP POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy_if_different\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/data/teapot512.pgm\n        ${CMAKE_CURRENT_BINARY_DIR}/\n    )\n    if(WIN32)\n        add_custom_command(TARGET freeImageInteropNPP\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${FreeImage_LIBRARY}/../FreeImage.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n        )\n    endif()\nelse()\n    message(STATUS \"FreeImage not found - will not build sample 'freeImageInteropNPP'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Defining CUDA Black-Scholes Build Target\nDESCRIPTION: Specifies the build target for the Black-Scholes model, including source files, compiler options, and CUDA-specific settings. It enables C++17 and CUDA 17 features, and sets up separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/BlackScholes/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\n# Source file\n# Add target for BlackScholes\nadd_executable(BlackScholes BlackScholes.cu BlackScholes_gold.cpp)\n\ntarget_compile_options(BlackScholes PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(BlackScholes PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(BlackScholes PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Build Settings and Architectures\nDESCRIPTION: Configures CUDA-specific build settings including target architectures (compute capabilities 72, 87, 101), position-independent code, and compiler flags. Includes conditional debug settings commented out by default.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLALayerwiseStatsStandalone/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Build Settings and Target Architectures\nDESCRIPTION: Sets the CUDA target architectures (compute capabilities 72, 87, 101) and compilation flags. Optionally enables CUDA debug symbols in debug builds.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cudaNvSciBufMultiplanar/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Bilateral Filter Target\nDESCRIPTION: Creates the executable target for the bilateral filter, sets compilation options, and links necessary libraries. Includes post-build commands for copying data files.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bilateralFilter/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        add_executable(bilateralFilter bilateralFilter.cpp bilateralFilter_cpu.cpp bilateral_kernel.cu bmploader.cpp)\n\ntarget_compile_options(bilateralFilter PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(bilateralFilter PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(bilateralFilter PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(bilateralFilter PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(bilateralFilter\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n\n        add_custom_command(TARGET bilateralFilter POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_directory\n            ${CMAKE_CURRENT_SOURCE_DIR}/data\n            ${CMAKE_CURRENT_BINARY_DIR}/data\n        )\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions\nDESCRIPTION: This snippet enumerates the CUDA Runtime API functions utilized in the sample for stream management, memory allocation, and data transfer.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/README.md#2025-04-21_snippet_1\n\nLANGUAGE: Markdown\nCODE:\n```\n### [CUDA Runtime API](http://docs.nvidia.com/cuda/cuda-runtime-api/index.html)\ncudaStreamDestroy, cudaFree, cudaDeviceSynchronize, cudaMalloc, cudaStreamCreate, cudaMemcpyAsync\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Bandwidth Test Project with CMake\nDESCRIPTION: Sets up a CMake project for a CUDA bandwidth test. It specifies CUDA architectures, compiler flags, and creates an executable target. The project requires the CUDA Toolkit and uses C++17 and CUDA 17 standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/bandwidthTest/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(bandwidthTest LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for bandwidthTest\nadd_executable(bandwidthTest bandwidthTest.cu)\n\ntarget_compile_options(bandwidthTest PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(bandwidthTest PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(bandwidthTest PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Compiling Shaders with glslc\nDESCRIPTION: This snippet shows how to compile vertex and fragment shader files using the glslc command from the Vulkan SDK. It's crucial for preparing shaders for use in Vulkan applications.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/Build_instructions.txt#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nglslc sinewave.vert -o vert.spv\nglslc sinewave.frag -o frag.spv\n```\n\n----------------------------------------\n\nTITLE: Basic CMake Project Setup\nDESCRIPTION: Initializes the CMake project with CUDA support and sets basic configuration options including CUDA architectures and compiler flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleDrvRuntime/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleDrvRuntime LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA BicubicTexture\nDESCRIPTION: Sets up the CMake project for bicubicTexture, specifying minimum CMake version, project languages, and CUDA requirements. It also configures CUDA architecture targets and compiler flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bicubicTexture/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(bicubicTexture LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Compilation Settings\nDESCRIPTION: Specifies CUDA architectures, sets CUDA flags, and configures debug options for the project.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/memMapIPCDrv/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Target Properties (CUDA)\nDESCRIPTION: This command sets the CUDA_SEPARABLE_COMPILATION property to ON for the 'simpleVulkan' target.  This enables separable compilation for CUDA code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_14\n\nLANGUAGE: cmake\nCODE:\n```\nset_target_properties(simpleVulkan PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Debug Build Configuration\nDESCRIPTION: This conditional block modifies the CUDA flags based on the build type. If the build type is Debug, it enables support for CUDA debugging with cuda-gdb.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fastWalshTransform/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n```\n\nLANGUAGE: CMake\nCODE:\n```\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\n```\n\nLANGUAGE: CMake\nCODE:\n```\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Include Directories for SobolQRNG\nDESCRIPTION: This snippet specifies the include directories for the project. It adds a relative path to the Common directory, which likely contains shared header files or utilities.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/SobolQRNG/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Define Project\nDESCRIPTION: This snippet defines the project name and specifies the programming languages used in the project. It sets the project name to \"UnifiedMemoryPerf\" and indicates that the project uses C, C++, and CUDA languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nproject(UnifiedMemoryPerf LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Defining CUDA Executable Target for Bezier Tessellation\nDESCRIPTION: This CMake snippet defines the executable target for the Bezier tessellation project. It specifies the source file, sets compile options for extended lambda support, and enables CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpBezierTessellation/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\n# Source file\n# Add target for cdpBezierTessellation\nadd_executable(cdpBezierTessellation BezierLineCDP.cu)\n\ntarget_compile_options(cdpBezierTessellation PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cdpBezierTessellation PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cdpBezierTessellation PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA DCT8x8 Project with CMake\nDESCRIPTION: Sets up the CUDA DCT8x8 project, including CUDA architecture targets, compiler flags, and dependencies. It also configures post-build commands to copy necessary data files.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/dct8x8/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(dct8x8 LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for dct8x8\nadd_executable(dct8x8 dct8x8.cu BmpUtil.cpp DCT8x8_Gold.cpp)\n\ntarget_compile_options(dct8x8 PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(dct8x8 PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(dct8x8 PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(dct8x8 PUBLIC\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\nfile(GLOB REF_DATA \"teapot512*\")\nadd_custom_command(TARGET dct8x8 POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${REF_DATA}\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET dct8x8 POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/teapot512.ppm\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET dct8x8 POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/teapot512.bmp\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Settings\nDESCRIPTION: Sets CUDA architecture targets, compiler flags, and debug options for the project.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Target Properties and Linking Libraries\nDESCRIPTION: This section sets specific properties for CUDA separable compilation and links the necessary CUDA runtime and random number generation libraries to the target.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nset_target_properties(MersenneTwisterGP11213 PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(MersenneTwisterGP11213 PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(MersenneTwisterGP11213 PRIVATE\n    CUDA::cudart\n    CUDA::curand\n)\n```\n\n----------------------------------------\n\nTITLE: Including Common Headers and Creating cuSolverRf Executable\nDESCRIPTION: Sets up include directories for common CUDA sample headers and defines the cuSolverRf executable target with its source files.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverRf/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for cuSolverRf\nadd_executable(cuSolverRf cuSolverRf.cpp mmio.c mmio_wrapper.cpp)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project Settings for CUDA SimpleAssert\nDESCRIPTION: Initializes CMake project configuration with CUDA support and sets minimum version requirements. Configures project languages and finds required CUDA toolkit.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleAssert/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleAssert LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Using CUDA Runtime API for memory operations and device properties\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the project for memory allocation, copying, and retrieving device properties.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUFFT_callback/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMemcpy\ncudaFree\ncudaMemcpyFromSymbol\ncudaGetDevice\ncudaMalloc\ncudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Configuring Build Target for Jacobi CUDA Graphs\nDESCRIPTION: Sets up the executable target with required source files, compile options, and C++/CUDA standard requirements.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/jacobiCudaGraphs/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(jacobiCudaGraphs jacobi.cu main.cpp)\n\ntarget_compile_options(jacobiCudaGraphs PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(jacobiCudaGraphs PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(jacobiCudaGraphs PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(jacobiCudaGraphs PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Platform Specific GLUT Paths\nDESCRIPTION: This snippet sets GLUT include and library directories for Windows. It uses conditional logic to only set these variables when building on the Windows platform.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Thread Fence Reduction Project\nDESCRIPTION: Sets up the CMake project for a CUDA-based thread fence reduction sample. It specifies the minimum CMake version, project languages, and adds custom module paths.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/threadFenceReduction/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(threadFenceReduction LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Target Configuration and Compilation Settings\nDESCRIPTION: Configures the executable target with necessary compiler options, C++17 and CUDA 17 features, and separable compilation settings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/jitLto/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(jitLto jitLto.cpp)\n\ntarget_compile_options(jitLto PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(jitLto PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(jitLto PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(jitLto PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Include Directories and Building Executable\nDESCRIPTION: Sets up include directories, adds the main executable target, and configures its compilation options. It enables C++17 and CUDA 17 features, extended lambda support, and separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/graphConditionalNodes/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(graphConditionalNodes graphConditionalNodes.cu)\n\ntarget_compile_options(graphConditionalNodes PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(graphConditionalNodes PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(graphConditionalNodes PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Including Directories and Building Executable\nDESCRIPTION: Includes common directories and defines the simpleTexture executable target with its source file and compilation options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTexture/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleTexture\nadd_executable(simpleTexture simpleTexture.cu)\n\ntarget_compile_options(simpleTexture PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleTexture PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleTexture PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Including Directories\nDESCRIPTION: This command includes directories with header files needed for the project's compilation, allowing the source files to reference shared code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fastWalshTransform/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Including Directories\nDESCRIPTION: This command includes a directory in the include path for the compiler. This allows the compiler to find header files in the specified directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_18\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(histEqualizationNPP)\n```\n\n----------------------------------------\n\nTITLE: Launching CUDA Kernel\nDESCRIPTION: Launches a CUDA kernel using cuLaunchKernel(). This function allows specifying grid and block dimensions, shared memory size, and kernel parameters.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/threadMigration/README.md#2025-04-21_snippet_3\n\nLANGUAGE: CUDA\nCODE:\n```\ncuLaunchKernel(function, grid.x, grid.y, grid.z,\n               block.x, block.y, block.z,\n               0, NULL, args, NULL);\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake and CUDA Project Settings\nDESCRIPTION: Sets up basic CMake configuration including minimum version, project languages, and CUDA toolkit requirements.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simplePrintf/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simplePrintf LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: CUDA Device Detection and CUBLAS Test Output\nDESCRIPTION: Console output showing detection of an NVIDIA Hopper GPU with compute capability 9.0, followed by CUBLAS test execution and success status.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleCUBLAS.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nsimpleCUBLAS test running..\nsimpleCUBLAS test passed.\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project Settings for CUDA Stream Ordered Allocation\nDESCRIPTION: Sets up basic CMake project configuration including minimum version, project languages, and CUDA toolkit requirements.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(streamOrderedAllocationIPC LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture Targets and Compiler Flags\nDESCRIPTION: Configures CUDA architecture targets from compute capability 5.0 to 12.0 and sets compiler flags. Includes special handling for debug builds and NDEBUG macro removal.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleAssert/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Removes -DNDEBUG For Print specific logs in this sample.\nstring(REPLACE \"-DNDEBUG\" \"\" CMAKE_CUDA_FLAGS_RELEASE \"${CMAKE_CUDA_FLAGS_RELEASE}\")\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Function Usage\nDESCRIPTION: List of CUDA Runtime API functions used in the implementation of separable convolution, including memory management and device synchronization operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/convolutionSeparable/README.md#2025-04-21_snippet_0\n\nLANGUAGE: cuda\nCODE:\n```\ncudaMemcpy\ncudaFree\ncudaDeviceSynchronize\ncudaMemcpyToSymbol\ncudaMalloc\n```\n\n----------------------------------------\n\nTITLE: CUDA Performance Test Output\nDESCRIPTION: Performance test results showing memory copy speeds between host and device, kernel execution times, and comparison of serialized vs overlapped execution using CUDA streams on an H100 PCIe GPU.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleMultiCopy.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n[simpleMultiCopy] - Starting...\n> Using CUDA device [0]: NVIDIA H100 PCIe\n[NVIDIA H100 PCIe] has 114 MP(s) x 128 (Cores/MP) = 14592 (Cores)\n> Device name: NVIDIA H100 PCIe\n> CUDA Capability 9.0 hardware with 114 multi-processors\n> scale_factor = 1.00\n> array_size   = 4194304\n\nRelevant properties of this CUDA device\n(X) Can overlap one CPU<>GPU data transfer with GPU kernel execution (device property \"deviceOverlap\")\n(X) Can overlap two CPU<>GPU data transfers with GPU kernel execution\n    (Compute Capability >= 2.0 AND (Tesla product OR Quadro 4000/5000/6000/K5000)\n\nMeasured timings (throughput):\n Memcpy host to device\t: 0.610592 ms (27.476966 GB/s)\n Memcpy device to host\t: 0.694048 ms (24.172991 GB/s)\n Kernel\t\t\t: 0.033408 ms (5021.915549 GB/s)\n\nTheoretical limits for speedup gained from overlapped data transfers:\nNo overlap at all (transfer-kernel-transfer): 1.338048 ms \nCompute can overlap with one transfer: 1.304640 ms\nCompute can overlap with both data transfers: 0.694048 ms\n\nAverage measured timings over 10 repetitions:\n Avg. time when execution fully serialized\t: 1.325424 ms\n Avg. time when overlapped using 4 streams\t: 1.203120 ms\n Avg. speedup gained (serialized - overlapped)\t: 0.122304 ms\n\nMeasured throughput:\n Fully serialized execution\t\t: 25.315998 GB/s\n Overlapped using 4 streams\t\t: 27.889513 GB/s\n```\n\n----------------------------------------\n\nTITLE: Set Target Compile Options\nDESCRIPTION: Sets compile options for the quasirandomGenerator_nvrtc target, specifically enabling extended lambda support for CUDA compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_options(quasirandomGenerator_nvrtc PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architecture Targets and Compiler Flags\nDESCRIPTION: Specifies CUDA architecture targets and compiler flags for the project, including position-independent code and deprecated GPU target warnings suppression. Contains a commented debug option for CUDA debugging.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Finding CUDA Toolkit\nDESCRIPTION: This command uses the find_package command to locate the CUDA Toolkit on the system. The REQUIRED keyword ensures that CMake will generate an error if the CUDA Toolkit is not found.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA and C++ Compilation Options and Features\nDESCRIPTION: Configures compilation options for the HSOpticalFlow target including extended lambda support for CUDA. Sets C++17 and CUDA 17 as the required standard and enables CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/HSOpticalFlow/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_options(HSOpticalFlow PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(HSOpticalFlow PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(HSOpticalFlow PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Generating CUDA PTX File\nDESCRIPTION: Sets up a custom command to generate a CUDA PTX file from the kernel source, and creates a custom target for the PTX generation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/memMapIPCDrv/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nset(CUDA_PTX_FILE \"${CMAKE_CURRENT_BINARY_DIR}/memMapIpc_kernel64.ptx\")\nset(CUDA_KERNEL_SOURCE \"${CMAKE_CURRENT_SOURCE_DIR}/memMapIpc_kernel.cu\")\n\nadd_custom_command(\n    OUTPUT ${CUDA_PTX_FILE}\n    COMMAND ${CMAKE_CUDA_COMPILER} ${INCLUDES} ${ALL_CCFLAGS} -Wno-deprecated-gpu-targets  ${GENCODE_FLAGS} -o ${CUDA_PTX_FILE} -ptx ${CUDA_KERNEL_SOURCE}\n    DEPENDS ${CUDA_KERNEL_SOURCE}\n    COMMENT \"Building CUDA PTX: ${CUDA_PTX_FILE}\"\n)\n\n# Create a dummy target for fatbin generation\nadd_custom_target(generate_memMapIpc_ptx ALL DEPENDS ${CUDA_PTX_FILE})\n\n# Ensure memMapIPCDrv depends on the fatbin\nadd_dependencies(memMapIPCDrv generate_memMapIpc_ptx)\n```\n\n----------------------------------------\n\nTITLE: Configuring SobelFilter Target in CMake\nDESCRIPTION: Sets up the SobelFilter executable target with CUDA and C++17 features. It configures include directories, links necessary libraries, and sets up CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/SobelFilter/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(SobelFilter SobelFilter.cpp SobelFilter_kernels.cu)\n\ntarget_compile_options(SobelFilter PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(SobelFilter PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(SobelFilter PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(SobelFilter PUBLIC\n    ${OPENGL_INCLUDE_DIR}\n    ${CUDAToolkit_INCLUDE_DIRS}\n    ${GLUT_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(SobelFilter\n    ${OPENGL_LIBRARIES}\n    ${GLUT_LIBRARIES}\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Project\nDESCRIPTION: This command defines the project name and the languages used in the project. In this case, the project is named 'simpleVulkan' and uses C, C++, and CUDA languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nproject(simpleVulkan LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Windows-specific library linking and DLL deployment for Mandelbrot\nDESCRIPTION: Configures Windows-specific library linking for freeglut and GLEW, and sets up post-build commands to copy required DLLs to the build output directory. This ensures the application can find the necessary runtime dependencies on Windows.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/Mandelbrot/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    target_link_libraries(Mandelbrot\n        ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n        ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n    )\n\n    add_custom_command(TARGET Mandelbrot\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\n\n    add_custom_command(TARGET Mandelbrot\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Build Environment Configuration for CUDA Samples\nDESCRIPTION: Configuration of environment variables required for building CUDA samples, including paths for CUDA toolkit, libNVVM, and optional LLVM dependencies\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Required Environment Variables\nCUDA_HOME=/usr/local/cuda\nLIBNVVM_HOME=$CUDA_HOME/nvvm\n\n# Optional LLVM Dependencies\nLLVM_HOME=/path/to/llvm/install\n```\n\n----------------------------------------\n\nTITLE: Setting Up CUDA Architecture Targets and Compiler Flags\nDESCRIPTION: Configures the CUDA architectures to target (compute capabilities 72, 87, and 101) and sets compiler flags including warning suppressions. Conditionally enables CUDA debugging in Debug builds (currently commented out).\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/fluidsGLES/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Windows-Specific Configuration\nDESCRIPTION: Handles Windows-specific library linking and DLL copying for GLUT and GLEW dependencies.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/oceanFFT/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nif(WIN32)\n    target_link_libraries(oceanFFT\n        ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n        ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n    )\n\n    add_custom_command(TARGET oceanFFT\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\n\n    add_custom_command(TARGET oceanFFT\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Post-Build Commands\nDESCRIPTION: Configures post-build steps to copy necessary data files and Windows-specific DLL dependencies to the output directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/bindlessTexture/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nadd_custom_command(TARGET bindlessTexture POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n\nif(WIN32)\n    target_link_libraries(bindlessTexture\n        ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n        ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n    )\n\n    add_custom_command(TARGET bindlessTexture\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\n\n    add_custom_command(TARGET bindlessTexture\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Up MonteCarloMultiGPU Executable Target\nDESCRIPTION: Defines the executable target, specifies source files, sets compile options and features, and enables CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/MonteCarloMultiGPU/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(MonteCarloMultiGPU MonteCarlo_gold.cpp MonteCarlo_kernel.cu multithreading.cpp MonteCarloMultiGPU.cpp)\n\ntarget_compile_options(MonteCarloMultiGPU PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(MonteCarloMultiGPU PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(MonteCarloMultiGPU PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the histogram sample. It includes memory management, device synchronization, and device property retrieval functions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/histogram/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\ncudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaMalloc, cudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Graph Conditional Nodes Project\nDESCRIPTION: Sets up the CMake project for a CUDA sample, including minimum CMake version, project languages, and module path. It also finds the CUDA Toolkit package which is required for the project.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/graphConditionalNodes/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(graphConditionalNodes LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Executable Target\nDESCRIPTION: Creates an executable target for the LargeKernelParameter sample, configures compilation options, and sets target properties for CUDA compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/LargeKernelParameter/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(LargeKernelParameter LargeKernelParameter.cu)\n```\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_options(LargeKernelParameter PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n```\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_features(LargeKernelParameter PRIVATE cxx_std_17 cuda_std_17)\n```\n\nLANGUAGE: CMake\nCODE:\n```\nset_target_properties(LargeKernelParameter PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Set Target Properties for CUDA\nDESCRIPTION: Sets the CUDA_SEPARABLE_COMPILATION property to ON for the target. This enables separable compilation for CUDA code, which can improve build times.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: CMake\nCODE:\n```\nset_target_properties(quasirandomGenerator_nvrtc PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA compilation settings and dependencies\nDESCRIPTION: Sets CUDA architecture targets, compilation flags, and position independent code option. Includes required CUDA packages and common directories.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/matrixMulDrv/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA architecture flags\nDESCRIPTION: This snippet sets the CUDA architecture flags for the project.  It specifies the target CUDA architectures (compute capabilities) for which the code will be compiled, and also disables warnings for deprecated GPU targets. This ensures the generated code is optimized for the specified architectures.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/cudaGraphsPerfScaling/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architectures and Flags\nDESCRIPTION: This snippet sets the CUDA architecture targets and compiler flags. It specifies which GPU architectures the code should be compiled for and disables a deprecated target warning.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenGL and GLUT Dependencies\nDESCRIPTION: Finds and configures OpenGL and GLUT libraries, with special handling for Windows platform include and library paths\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/recursiveGaussian/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: Finding CUDA Toolkit\nDESCRIPTION: This command uses the find_package command to locate the CUDA Toolkit. The REQUIRED keyword specifies that the build should fail if the CUDA Toolkit is not found.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring the conjugateGradientCudaGraphs Target\nDESCRIPTION: Creates an executable target for the conjugate gradient CUDA application, setting C++17 and CUDA 17 language standards. Enables CUDA extended lambda support and separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(conjugateGradientCudaGraphs conjugateGradientCudaGraphs.cu)\n\ntarget_compile_options(conjugateGradientCudaGraphs PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(conjugateGradientCudaGraphs PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(conjugateGradientCudaGraphs PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Set Position Independent Code\nDESCRIPTION: This snippet sets the `CMAKE_POSITION_INDEPENDENT_CODE` variable to `ON`. This enables position-independent code generation, which is often required when building shared libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA Vector Addition Driver\nDESCRIPTION: Sets up the CMake project, finds the CUDA toolkit, and configures basic CUDA compilation flags. It specifies CUDA architectures and sets position-independent code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/vectorAddDrv/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(vectorAddDrv LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Defining fluidsGLES Executable Target with Dependencies\nDESCRIPTION: Creates the fluidsGLES executable target with its source files and configures necessary compiler options. Sets up C++17 and CUDA 17 standard features and enables CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/fluidsGLES/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(fluidsGLES fluidsGLES.cpp fluidsGLES_kernels.cu)\n\ntarget_compile_options(fluidsGLES PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(fluidsGLES PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(fluidsGLES PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Adding Executable Target\nDESCRIPTION: This snippet adds an executable target named 'fastWalshTransform', specifying the source files needed for its compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fastWalshTransform/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(fastWalshTransform fastWalshTransform.cu fastWalshTransform_gold.cpp)\n```\n\n----------------------------------------\n\nTITLE: Adding Executable Target\nDESCRIPTION: This snippet adds an executable target named `postProcessGL` to the project. It specifies the source files (`main.cpp` and `postProcessGL.cu`) that will be compiled and linked to create the executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: CMake\nCODE:\n```\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        # Add target for postProcessGL\n        add_executable(postProcessGL main.cpp postProcessGL.cu)\n\n        target_compile_options(postProcessGL PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(postProcessGL PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(postProcessGL PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(postProcessGL PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(postProcessGL\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n\n        add_custom_command(TARGET postProcessGL POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_directory\n            ${CMAKE_CURRENT_SOURCE_DIR}/data\n            ${CMAKE_CURRENT_BINARY_DIR}/data\n        )\n\n        if(WIN32)\n            target_link_libraries(postProcessGL\n                ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n                ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n            )\n\n            add_custom_command(TARGET postProcessGL\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n\n            add_custom_command(TARGET postProcessGL\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n        endif()\n\n    else()\n        message(STATUS \"GLUT not found - will not build sample 'postProcessGL'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'postProcessGL'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Math Library Build Configuration for CUDA\nDESCRIPTION: This snippet configures the build process for a math library supporting different GPU architectures using CUDA. The math library is built using the 'nvcc' compiler with architecture-specific options, outputting a static library 'libmathfuncs64.a'. The CMake is configured to set appropriate flags for device-only compilation and enable separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/cuda-c-linking/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nenable_language(CUDA)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -dc\") # -dc: Build for device only.\nif (${CMAKE_VERSION} VERSION_GREATER_EQUAL 3.18.0)\n  set(CMAKE_CUDA_ARCHITECTURES 50)\n  set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nendif ()\nif (WIN32)\n  set(CMAKE_CUDA_USE_RESPONSE_FILE_FOR_INCLUDES 0)\n  set(CMAKE_CUDA_USE_RESPONSE_FILE_FOR_LIBRARIES 0)\n  set(CMAKE_CUDA_USE_RESPONSE_FILE_FOR_OBJECTS 0)\nendif ()\nadd_library(mathfuncs64 STATIC math-funcs.cu)\nset_target_properties(mathfuncs64 PROPERTIES PREFIX \"lib\"\n                      OUTPUT_NAME \"mathfuncs64\"\n                      SUFFIX \".a\" CUDA_SEPERABLE_COMPILATION ON)\ninstall(TARGETS cuda-c-linking mathfuncs64 DESTINATION bin)\n\nif (WIN32)\n  add_custom_command(\n      TARGET cuda-c-linking\n      POST_BUILD\n      COMMAND ${CMAKE_COMMAND} -E copy_if_different\n              \"${CMAKE_BINARY_DIR}/nvvm64_40_0.dll\" \"$<TARGET_FILE_DIR:cuda-c-linking>\"\n  )\nendif ()\n```\n\n----------------------------------------\n\nTITLE: Set CUDA Flags\nDESCRIPTION: This snippet adds a compiler flag to suppress warnings related to deprecated GPU targets. This helps to avoid unnecessary warnings during the build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for dwtHaar1D Project\nDESCRIPTION: Defines the necessary configurations for building the dwtHaar1D CUDA project. Requires CMake 3.20 or higher, the CUDAToolkit package, and CUDA architectures. Specifies compilation options and setup for running a CUDA project in a CMake environment.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/dwtHaar1D/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(dwtHaar1D LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for dwtHaar1D\nadd_executable(dwtHaar1D dwtHaar1D.cu)\n\ntarget_compile_options(dwtHaar1D PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(dwtHaar1D PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(dwtHaar1D PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\nadd_custom_command(TARGET dwtHaar1D POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n```\n\n----------------------------------------\n\nTITLE: Linking Libraries to Target\nDESCRIPTION: This snippet links the necessary libraries to the target. It specifies the libraries that the linker should use to resolve external symbols during the linking process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_14\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(postProcessGL\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Extended Lambda and Language Standard Support\nDESCRIPTION: Sets up compiler options for CUDA extended lambda support, C++17 and CUDA C++17 standards, and enables separable compilation for the CUDA code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_compile_options(MC_EstimatePiInlineQ PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(MC_EstimatePiInlineQ PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(MC_EstimatePiInlineQ PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Setting Compile Options\nDESCRIPTION: This command sets specific compile options for the 'fastWalshTransform' target, utilizing CUDA features such as extended lambda expressions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fastWalshTransform/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_options(fastWalshTransform PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n```\n\n----------------------------------------\n\nTITLE: Organizing CUDA Samples Project Structure with CMake\nDESCRIPTION: This CMake configuration adds subdirectories to organize the CUDA Samples project by category and complexity level. It structures the project into sections including introductory samples, utilities, concept demonstrations, CUDA features, library integrations, domain-specific applications, performance examples, and libNVVM samples. It conditionally includes Tegra-specific examples based on the BUILD_TEGRA variable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(0_Introduction)\nadd_subdirectory(1_Utilities)\nadd_subdirectory(2_Concepts_and_Techniques)\nadd_subdirectory(3_CUDA_Features)\nadd_subdirectory(4_CUDA_Libraries)\nadd_subdirectory(5_Domain_Specific)\nadd_subdirectory(6_Performance)\nadd_subdirectory(7_libNVVM)\nif(BUILD_TEGRA)\n    add_subdirectory(8_Platform_Specific/Tegra)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Defining Project and Finding CUDA Dependencies\nDESCRIPTION: Sets up the project with C and C++ language support and locates the CUDA Toolkit which is required for building the application.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverRf/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nproject(cuSolverRf LANGUAGES C CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Defining stereoDisparity Project\nDESCRIPTION: This command defines the project name and the languages used in the project (C, C++, and CUDA). The project name is set to 'stereoDisparity'.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nproject(stereoDisparity LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Project Initialization and Settings\nDESCRIPTION: Initializes the project, enables testing, and sets the C standard.  It sets the C standard to C11.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\n\"project(libnvvm-samples)\nenable_testing()\n#set_property(GLOBAL PROPERTY ALLOW_DUPLICATE_CUSTOM_TARGETS TRUE)\nset(CMAKE_C_STANDARD 11)\"\n```\n\n----------------------------------------\n\nTITLE: Setting Minimum CMake Version\nDESCRIPTION: This snippet sets the minimum required CMake version for the project to 3.20. This ensures that the CMake version used to build the project is compatible with the commands and features used in the CMakeLists.txt file.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n```\n\n----------------------------------------\n\nTITLE: Linking CUDA Driver Library\nDESCRIPTION: Links the CUDA driver library to the deviceQueryDrv executable, which is required for CUDA driver API functions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/deviceQueryDrv/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(deviceQueryDrv PUBLIC\n    CUDA::cuda_driver\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Compilation Architectures\nDESCRIPTION: Defines supported CUDA GPU architectures and sets compilation flags to suppress deprecated GPU target warnings\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/dxtc/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenGL and GLUT Dependencies\nDESCRIPTION: Locates and configures OpenGL and GLUT libraries for cross-platform compatibility, with special handling for Windows\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/marchingCubes/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA Sample\nDESCRIPTION: Sets up a CUDA project with minimum CMake version, project definition, and CUDA toolkit requirements. Configures compilation flags and target properties for a CUDA executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/LargeKernelParameter/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n```\n\nLANGUAGE: CMake\nCODE:\n```\nproject(LargeKernelParameter LANGUAGES C CXX CUDA)\n```\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Set Position Independent Code\nDESCRIPTION: This enables position-independent code generation. This is often necessary for shared libraries and can improve security.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: QRNG Performance Log Output\nDESCRIPTION: Terminal output showing the execution flow, performance metrics, and accuracy validation of a CUDA QRNG implementation. The log includes memory allocation steps, throughput measurements, and L1 norm comparisons between CPU and GPU results.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_quasirandomGenerator.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n./quasirandomGenerator Starting...\n\nAllocating GPU memory...\nAllocating CPU memory...\nInitializing QRNG tables...\n\nTesting QRNG...\n\nquasirandomGenerator, Throughput = 51.2334 GNumbers/s, Time = 0.00006 s, Size = 3145728 Numbers, NumDevsUsed = 1, Workgroup = 384\n\nReading GPU results...\nComparing to the CPU results...\n\nL1 norm: 7.275964E-12\n\nTesting inverseCNDgpu()...\n\nquasirandomGenerator-inverse, Throughput = 116.2931 GNumbers/s, Time = 0.00003 s, Size = 3145728 Numbers, NumDevsUsed = 1, Workgroup = 128\nReading GPU results...\n\nComparing to the CPU results...\nL1 norm: 9.439909E-08\n\nShutting down...\n```\n\n----------------------------------------\n\nTITLE: Setting up data file copying for Mandelbrot application\nDESCRIPTION: Creates a post-build command that copies the data directory to the build output directory. This ensures the application has access to any required data files at runtime.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/Mandelbrot/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET Mandelbrot POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Command for Data Copy\nDESCRIPTION: This snippet adds a custom command to copy the `data` directory to the build directory after the target is built. This ensures that the necessary data files are available at runtime.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_15\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET postProcessGL POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_directory\n            ${CMAKE_CURRENT_SOURCE_DIR}/data\n            ${CMAKE_CURRENT_BINARY_DIR}/data\n        )\n```\n\n----------------------------------------\n\nTITLE: Setting Include Directories and Linking CUDA Libraries\nDESCRIPTION: Configures the include directories for the project and links against the CUDA CURAND library, which is required for generating random numbers in Monte Carlo simulations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_include_directories(MC_EstimatePiInlineQ PUBLIC\n    ${CMAKE_CURRENT_SOURCE_DIR}/inc\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(MC_EstimatePiInlineQ PUBLIC\n    CUDA::curand\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architecture Targets and Compiler Flags\nDESCRIPTION: Specifies the CUDA architecture targets (compute capabilities) to build for and sets additional CUDA compiler flags including handling for deprecated GPU targets and debug mode.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverRf/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Executable Target\nDESCRIPTION: This conditional block adds the executable target 'simpleVulkan' if Vulkan, OpenGL, and GLFW are found. It defines compile options, compile features, target properties, include directories and libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_11\n\nLANGUAGE: cmake\nCODE:\n```\nif(${Vulkan_FOUND})\n    if(${OPENGL_FOUND})\n        if(${HAVE_GLFW3_H})\n            # Add target for simpleVulkan\n            add_executable(simpleVulkan main.cpp SineWaveSimulation.cu VulkanBaseApp.cpp)\n\n            target_compile_options(simpleVulkan PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n            target_compile_features(simpleVulkan PRIVATE cxx_std_17 cuda_std_17)\n\n            set_target_properties(simpleVulkan PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n            target_include_directories(simpleVulkan PUBLIC\n                ${Vulkan_INCLUDE_DIRS}\n                ${CUDAToolkit_INCLUDE_DIRS}\n            )\n            target_link_libraries(simpleVulkan\n                ${Vulkan_LIBRARIES}\n                OpenGL::GL\n            )\n            if(WIN32)\n                target_include_directories(simpleVulkan PUBLIC\n                    ${GLFW_INCLUDE_DIR}\n                )\n                target_link_libraries(simpleVulkan\n                    ${GLFW3_LIB}\n                )\n            else()\n                target_link_libraries(simpleVulkan\n                    glfw\n                )\n            endif()\n            add_custom_command(TARGET simpleVulkan POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy_if_different\n                ${CMAKE_CURRENT_SOURCE_DIR}/sinewave.frag\n                ${CMAKE_CURRENT_SOURCE_DIR}/sinewave.vert\n                ${CMAKE_CURRENT_SOURCE_DIR}/vert.spv\n                ${CMAKE_CURRENT_SOURCE_DIR}/frag.spv\n                ${CMAKE_CURRENT_BINARY_DIR}\n            )\n        else()\n            message(STATUS \"glfw3 not found - will not build sample 'simpleVulkan'\")\n        endif()\n    else()\n        message(STATUS \"OpenGL not found - will not build sample 'simpleVulkan'\")\n    endif()\nelse()\n    message(STATUS \"Vulkan not found - will not build sample 'simpleVulkan'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Post Build Command\nDESCRIPTION: This command adds a custom command that will be executed after the target 'simpleVulkan' is built. It copies fragment shaders, vertex shaders, and SPIR-V compiled shaders into the binary directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_17\n\nLANGUAGE: cmake\nCODE:\n```\nadd_custom_command(TARGET simpleVulkan POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy_if_different\n                ${CMAKE_CURRENT_SOURCE_DIR}/sinewave.frag\n                ${CMAKE_CURRENT_SOURCE_DIR}/sinewave.vert\n                ${CMAKE_CURRENT_SOURCE_DIR}/vert.spv\n                ${CMAKE_CURRENT_SOURCE_DIR}/frag.spv\n                ${CMAKE_CURRENT_BINARY_DIR}\n            )\n```\n\n----------------------------------------\n\nTITLE: Adding Custom CMake Modules Path\nDESCRIPTION: This snippet appends a custom path to the CMAKE_MODULE_PATH variable. This allows CMake to find custom modules located in the specified directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_24\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(oceanFFT)\n```\n\n----------------------------------------\n\nTITLE: Configuring Include Directories and Finding Dependencies\nDESCRIPTION: Sets up include paths for common utilities and locates the required FreeImage library dependency using find_package.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/freeImageInteropNPP/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(\n    ../../../Common\n    ../../../Common/UtilNPP\n)\n\n# Source file\nfind_package(FreeImage)\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Command for DLL Copy (Windows)\nDESCRIPTION: This snippet adds custom commands to copy the freeglut.dll and glew64.dll files to the build directory after the target is built on Windows. This ensures the necessary DLLs are present at runtime, and uses generator expressions to account for different build configurations (Debug, Release).\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_17\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET postProcessGL\n    POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy\n    ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n    ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n)\n\nadd_custom_command(TARGET postProcessGL\n    POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy\n    ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n    ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architectures and Compiler Flags\nDESCRIPTION: Specifies the CUDA architectures to compile for and sets compiler flags, including warnings and debug options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleSurfaceWrite/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Include Directories and Dependencies\nDESCRIPTION: Sets up include directories for project headers and searches for FreeImage library\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/FilterBorderControlNPP/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(\n    ../../../Common\n    ../../../Common/UtilNPP\n)\n\nfind_package(FreeImage)\n```\n\n----------------------------------------\n\nTITLE: Including CUDA Toolkit Headers and Copying Data Files\nDESCRIPTION: Adds CUDA Toolkit include directories to the project and sets up a post-build command to copy the data directory to the build directory for runtime usage.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/HSOpticalFlow/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_include_directories(HSOpticalFlow PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\nadd_custom_command(TARGET HSOpticalFlow POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n```\n\n----------------------------------------\n\nTITLE: Locating the NVVM Directory\nDESCRIPTION: Finds the NVVM directory using the `LIBNVVM_HOME` environment variable or the `CUDA_HOME` variable.  It then prints a status message indicating the NVVM home directory being used.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\n\"# Find the nvvm directory in the toolkit.\nfind_file(LIBNVVM_HOME nvvm PATHS \\\"$ENV{LIBNVVM_HOME}\\\" \\\"${CUDA_HOME}\\\")\nmessage(STATUS \\\"Using LIBNVVM_HOME: ${LIBNVVM_HOME}\\\")\"\n```\n\n----------------------------------------\n\nTITLE: CUDA Sample Program Output Log\nDESCRIPTION: Console output showing the execution of a Fast Walsh Transform algorithm on a CUDA-enabled GPU, including memory allocation, data generation, performance metrics, and validation results.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_fastWalshTransform.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n./fastWalshTransform Starting...\n\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nInitializing data...\n...allocating CPU memory\n...allocating GPU memory\n...generating data\nData length: 8388608; kernel length: 128\nRunning GPU dyadic convolution using Fast Walsh Transform...\nGPU time: 0.751000 ms; GOP/s: 385.362158\nReading back GPU results...\nRunning straightforward CPU dyadic convolution...\nComparing the results...\nShutting down...\nL2 norm: 1.021579E-07\nTest passed\n```\n\n----------------------------------------\n\nTITLE: Find CUDA Toolkit\nDESCRIPTION: This uses the `find_package` command to locate the CUDA toolkit. It is a required dependency for building CUDA-enabled projects.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Defining the matrixMulDrv executable target\nDESCRIPTION: Creates the main executable target and configures its properties including C++/CUDA standard versions, compilation options, and required include directories.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/matrixMulDrv/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# Source file\n# Add target for matrixMulDrv\nadd_executable(matrixMulDrv matrixMulDrv.cpp)\n\ntarget_compile_options(matrixMulDrv PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(matrixMulDrv PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(matrixMulDrv PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(matrixMulDrv PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(matrixMulDrv PUBLIC\n    CUDA::cuda_driver\n)\n```\n\n----------------------------------------\n\nTITLE: Setting up CMake and CUDA Build Configuration\nDESCRIPTION: Initializes CMake project with CUDA support and configures basic build settings including CUDA architectures and compiler flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLAStandaloneMode/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../../cmake/Modules\")\n\nproject(cuDLAStandaloneMode LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n```\n\n----------------------------------------\n\nTITLE: Creating CUDA Executable Target with FreeImage\nDESCRIPTION: Configures executable target with CUDA compilation features, include directories, and library linkage\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/FilterBorderControlNPP/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(FilterBorderControlNPP FilterBorderControlNPP.cpp)\n\ntarget_compile_options(FilterBorderControlNPP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(FilterBorderControlNPP PRIVATE cxx_std_17 cuda_std_17)\n\ntarget_link_libraries(FilterBorderControlNPP PRIVATE\n    CUDA::nppc\n    CUDA::nppisu\n    CUDA::nppif\n    CUDA::nppitc\n    CUDA::nppidei\n    CUDA::nppial\n    CUDA::cudart\n    ${FreeImage_LIBRARIES}\n)\n```\n\n----------------------------------------\n\nTITLE: Checking for GLFW Header\nDESCRIPTION: This command uses the check_include_file macro to check for the existence of the GLFW/glfw3.h header file. The result is stored in the HAVE_GLFW3_H variable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: cmake\nCODE:\n```\ncheck_include_file(\"GLFW/glfw3.h\" HAVE_GLFW3_H)\n```\n\n----------------------------------------\n\nTITLE: Setting Up CMake Project for CUDA-OpenGL Interoperability\nDESCRIPTION: Configures the CMake project with required minimum version, module paths, and project languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleCUDA2GL/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleCUDA2GL LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(batchCUBLAS)\n```\n\n----------------------------------------\n\nTITLE: Measuring GPU Memory Bandwidth with CUDA Runtime API\nDESCRIPTION: This snippet outlines the CUDA Runtime API functions used in the bandwidthTest sample. It includes memory allocation, copying, device management, and event handling for performance measurement.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/bandwidthTest/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaHostAlloc, cudaMemcpy, cudaMalloc, cudaMemcpyAsync, cudaFree, cudaGetErrorString, cudaMallocHost, cudaSetDevice, cudaGetDeviceProperties, cudaDeviceSynchronize, cudaEventRecord, cudaFreeHost, cudaEventDestroy, cudaEventElapsedTime, cudaGetDeviceCount, cudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: Setting Target Properties for CUDA\nDESCRIPTION: This command configures specific properties for the 'fastWalshTransform' target, enabling separable compilation for CUDA files.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fastWalshTransform/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: CMake\nCODE:\n```\nset_target_properties(fastWalshTransform PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Compilation Settings\nDESCRIPTION: Sets CUDA-specific compilation options including target architectures (CUDA compute capabilities 72, 87, 101), position independent code flag, and warning suppressions. Includes conditional debug settings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/nbody_opengles/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 72 87 101)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: CUDA P2P Test Output Log\nDESCRIPTION: Console output showing the results of attempting to run the simpleP2P CUDA sample. The output indicates that the test requires at least two GPUs with peer-to-peer capabilities, but only one CUDA-capable device was found.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleP2P.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n[./simpleP2P] - Starting...\nChecking for multiple GPUs...\nCUDA-capable device count: 1\nTwo or more GPUs with Peer-to-Peer access capability are required for ./simpleP2P.\nWaiving test.\n```\n\n----------------------------------------\n\nTITLE: Windows-Specific Configuration for Bilateral Filter\nDESCRIPTION: Adds Windows-specific library linkage and post-build commands for copying necessary DLLs to the output directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bilateralFilter/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n            target_link_libraries(bilateralFilter\n                ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n                ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n            )\n\n            add_custom_command(TARGET bilateralFilter\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n\n            add_custom_command(TARGET bilateralFilter\n                POST_BUILD\n                COMMAND ${CMAKE_COMMAND} -E copy\n                ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n                ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n            )\n        endif()\n```\n\n----------------------------------------\n\nTITLE: Defining the Project and Languages\nDESCRIPTION: This snippet defines the project name and specifies that it will utilize C, C++, and CUDA programming languages for its implementation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fastWalshTransform/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nproject(fastWalshTransform LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Creating CUDA Executable Target\nDESCRIPTION: Adds an executable target for the DXTC project, configures compilation features, and sets compilation properties\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/dxtc/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nadd_executable(dxtc dxtc.cu)\n\ntarget_compile_options(dxtc PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(dxtc PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(dxtc PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Setting Position Independent Code\nDESCRIPTION: This command sets the CMAKE_POSITION_INDEPENDENT_CODE variable to ON, enabling position-independent code generation. This is often required for shared libraries and can improve security.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture Targets and Compiler Flags\nDESCRIPTION: Configures CUDA architecture targets from compute capability 5.0 to 12.0 and sets compiler flags including debug options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Displaying CUDA Device Information and Clock Performance\nDESCRIPTION: This output shows the selected CUDA device (NVIDIA H100 PCIe), its compute capability (SM 9.0), and the average clock cycles per block execution.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_clock_nvrtc.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nCUDA Clock sample\n> Using CUDA Device [0]: NVIDIA H100 PCIe\n> Using CUDA Device [0]: NVIDIA H100 PCIe\n> GPU Device has SM 9.0 compute capability\nAverage clocks/block = 1839.750000\n```\n\n----------------------------------------\n\nTITLE: Set CUDA Architectures\nDESCRIPTION: This snippet defines the target CUDA architectures for the project. It specifies a list of GPU architectures (e.g., 50, 52, 60) that the CUDA code will be compiled for.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Build Target for EGLStream_CUDA_CrossGPU\nDESCRIPTION: Defines the executable target, sets compiler options, and links necessary libraries for Linux builds with EGL support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    # Source file\n    if(${EGL_FOUND})\n            # Add target for EGLStream_CUDA_CrossGPU\n            add_executable(EGLStream_CUDA_CrossGPU cuda_consumer.cpp cuda_producer.cpp eglstrm_common.cpp kernel.cu main.cpp)\n\n            target_compile_options(EGLStream_CUDA_CrossGPU PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n            target_compile_features(EGLStream_CUDA_CrossGPU PRIVATE cxx_std_17 cuda_std_17)\n\n            set_target_properties(EGLStream_CUDA_CrossGPU PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n            target_include_directories(EGLStream_CUDA_CrossGPU PUBLIC\n                ${EGL_INCLUDE_DIR}\n                ${CUDAToolkit_INCLUDE_DIRS}\n            )\n\n            target_link_libraries(EGLStream_CUDA_CrossGPU\n                ${EGL_LIBRARY}\n                CUDA::cuda_driver\n            )\n    else()\n        message(STATUS \"EGL not found - will not build sample 'EGLStream_CUDA_CrossGPU'\")\n    endif()\nelse()\n    message(STATUS \"Will not build sample EGLStream_CUDA_CrossGPU - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Building simpleCUFFT_callback Executable for Linux\nDESCRIPTION: Adds the executable target for simpleCUFFT_callback, sets compilation options including C++ and CUDA standards, enables separable compilation, and links necessary CUDA libraries. This section is only executed on Linux systems.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUFFT_callback/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    # Source file\n    # Add target for simpleCUFFT_callback\n    add_executable(simpleCUFFT_callback simpleCUFFT_callback.cu)\n\n    target_compile_options(simpleCUFFT_callback PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(simpleCUFFT_callback PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(simpleCUFFT_callback PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n    target_link_libraries(simpleCUFFT_callback PRIVATE\n        CUDA::cufft_static\n        culibos\n    )\nelse()\n    message(STATUS \"Will not build sample simpleCUFFT_callback - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Position Independent Code\nDESCRIPTION: This command sets the CMAKE_POSITION_INDEPENDENT_CODE variable to ON. This enables position-independent code generation, which is often required for shared libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Sample Subdirectories in CMake\nDESCRIPTION: CMake configuration that includes multiple CUDA sample projects in the build system. Each subdirectory contains a separate CUDA example demonstrating features like tensor operations, CUDA graphs, memory management, and parallel algorithms.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(StreamPriorities)\nadd_subdirectory(bf16TensorCoreGemm)\nadd_subdirectory(binaryPartitionCG)\nadd_subdirectory(bindlessTexture)\nadd_subdirectory(cdpAdvancedQuicksort)\nadd_subdirectory(cdpBezierTessellation)\nadd_subdirectory(cdpQuadtree)\nadd_subdirectory(cdpSimplePrint)\nadd_subdirectory(cdpSimpleQuicksort)\nadd_subdirectory(cudaCompressibleMemory)\nadd_subdirectory(cudaTensorCoreGemm)\nadd_subdirectory(dmmaTensorCoreGemm)\nadd_subdirectory(globalToShmemAsyncCopy)\nadd_subdirectory(graphConditionalNodes)\nadd_subdirectory(graphMemoryFootprint)\nadd_subdirectory(graphMemoryNodes)\nadd_subdirectory(immaTensorCoreGemm)\nadd_subdirectory(jacobiCudaGraphs)\nadd_subdirectory(memMapIPCDrv)\nadd_subdirectory(newdelete)\nadd_subdirectory(ptxjit)\nadd_subdirectory(simpleCudaGraphs)\nadd_subdirectory(tf32TensorCoreGemm)\nadd_subdirectory(warpAggregatedAtomicsCG)\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Dependencies with Status Messages\nDESCRIPTION: Provides informative status messages when dependencies are missing or when building on unsupported platforms. This helps users understand why the target might not be built in their environment.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLALayerwiseStatsStandalone/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\n        else()\n            message(STATUS \"NvSCI not found - will not build sample 'cuDLALayerwiseStatsStandalone'\")\n        endif()\n    else()\n        message(STATUS \"CUDLA not found - will not build sample 'cuDLALayerwiseStatsStandalone'\")\n    endif()\nelse()\n    message(STATUS \"Will not build sample cuDLALayerwiseStatsStandalone - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Sample Project Overview: CUDA libNVVM Components\nDESCRIPTION: A collection of sample projects demonstrating various CUDA and NVVM IR programming techniques, including shared memory usage, kernel linking, device-side launching, and unified virtual memory\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- cuda-shared-memory: NVVM IR programs demonstrating CUDA 'shared' memory usage\n- cuda-c-linking: Builds NVVM IR program using LLVM IR build APIs\n- device-side-launch: Demonstrates kernel launching within a kernel\n- ptxgen: Standalone NVVM IR to PTX compiler\n- simple: Reads NVVM IR program, compiles to PTX, launches on GPU\n- syscalls: Demonstrates device-side malloc/free/vprintf functions\n- uvmlite: Demonstrates unified virtual memory\n```\n\n----------------------------------------\n\nTITLE: Setting Build Configuration Flags\nDESCRIPTION: This setting enables position-independent code generation and specifies architectural support for CUDA. It also sets flags to suppress warnings on deprecated GPU targets.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fastWalshTransform/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\n```\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up Dependencies and Include Paths\nDESCRIPTION: Configures include directories and sets up platform-specific paths for GLUT libraries on Windows systems.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/bindlessTexture/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project with CUDA Support\nDESCRIPTION: Sets up basic CMake configuration including minimum version, project languages, and CUDA toolkit requirements.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/sortingNetworks/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(sortingNetworks LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Compile Options\nDESCRIPTION: This command sets a compile option specific to CUDA language files for the 'nbody' target. `--extended-lambda` enables support for extended lambda expressions within CUDA code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_compile_options(nbody PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n```\n\n----------------------------------------\n\nTITLE: Building Particles Executable with CUDA and OpenGL\nDESCRIPTION: Defines the particles executable target, sets compiler options, and links necessary libraries for CUDA, OpenGL, and GLUT integration.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/particles/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        add_executable(particles particleSystem.cpp particleSystem_cuda.cu particles.cpp render_particles.cpp shaders.cpp)\n\n        target_compile_options(particles PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(particles PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(particles PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(particles PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(particles\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n```\n\n----------------------------------------\n\nTITLE: Project Definition with Languages\nDESCRIPTION: This snippet defines the project name and specifies the programming languages to be used: C, C++, and CUDA. This allows CMake to configure the build system accordingly.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nproject(postProcessGL LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Finding Required Dependencies for cuDLALayerwiseStatsStandalone\nDESCRIPTION: Sets up include directories and finds required libraries including CUDLA and NVSCI components (nvscibuf and nvscisync) on Linux systems. This section searches for libraries in standard locations and custom paths specified by the user.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLALayerwiseStatsStandalone/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../../Common)\n\nfind_library(CUDLA_LIB cudla PATHS ${CUDAToolkit_LIBRARY_DIR})\n\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    if(CUDLA_LIB)\n        # Find the NVSCI libraries\n        # use CMAKE_LIBRARY_PATH so that users can also specify the NVSCI lib path in cmake command\n        set(CMAKE_LIBRARY_PATH \"/usr/lib\" ${CMAKE_LIBRARY_PATH})\n        foreach(LIBRARY_PATH ${CMAKE_LIBRARY_PATH})\n            file(GLOB_RECURSE NVSCIBUF_LIB\n                ${LIBRARY_PATH}/libnvscibuf.so\n                ${LIBRARY_PATH}/*/libnvscibuf.so\n            )\n            file(GLOB_RECURSE NVSCISYNC_LIB\n                ${LIBRARY_PATH}/libnvscisync.so\n                ${LIBRARY_PATH}/*/libnvscisync.so\n            )\n            if(NVSCIBUF_LIB AND NVSCISYNC_LIB)\n                break()\n            endif()\n        endforeach()\n\n        # Find the NVSCI header files\n        # use CMAKE_INCLUDE_PATH so that users can also specify the NVSCI include path in cmake command\n        set(CMAKE_INCLUDE_PATH \"/usr/include\" ${CMAKE_LIBRARY_PATH})\n        find_path(NVSCIBUF_INCLUDE_DIR nvscibuf.h PATHS ${CMAKE_INCLUDE_PATH})\n        find_path(NVSCISYNC_INCLUDE_DIR nvscisync.h PATHS ${CMAKE_INCLUDE_PATH})\n```\n\n----------------------------------------\n\nTITLE: Setting CMake Minimum Version\nDESCRIPTION: This command sets the minimum required CMake version for the project. It ensures that the CMake version used to build the project is at least 3.20 or higher.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n```\n\n----------------------------------------\n\nTITLE: Configuring EGLStream CUDA Interop Project Build\nDESCRIPTION: Sets up the EGLStream CUDA Interop project, including source files, include directories, and linking libraries. This configuration is specific to Linux systems with EGL support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    # Source file\n    if(${EGL_FOUND})\n        # Add target for EGLStream_CUDA_Interop\n        add_executable(EGLStream_CUDA_Interop cuda_consumer.cpp cuda_producer.cpp eglstrm_common.cpp main.cpp)\n\n        target_include_directories(EGLStream_CUDA_Interop PUBLIC\n            ${EGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(EGLStream_CUDA_Interop\n            ${EGL_LIBRARY}\n            CUDA::cuda_driver\n        )\n\n    else()\n        message(STATUS \"EGL not found - will not build sample 'EGLStream_CUDA_Interop'\")\n    endif()\nelse()\n    message(STATUS \"Will not build sample EGLStream_CUDA_Interop - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Linking Libraries for fluidsGLES\nDESCRIPTION: Links the required libraries to the fluidsGLES target, including CUDA driver, CUDA FFT, EGL, X11, and OpenGL libraries. These provide the necessary functionality for GPU computation and rendering.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/fluidsGLES/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(fluidsGLES\n    CUDA::cuda_driver\n    CUDA::cufft\n    ${EGL_LIBRARY}\n    ${X11_LIBRARIES}\n    ${OPENGL_LIBRARIES}\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Minimum CMake Version\nDESCRIPTION: This snippet sets the minimum required CMake version for the project. It ensures that the CMake version used to build the project is at least 3.20 or higher.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(conjugateGradientCudaGraphs)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Sample Projects with CMake\nDESCRIPTION: CMake configuration that specifies which CUDA sample projects should be included in the build process. The file lists various subdirectories containing sample applications that demonstrate CUDA integration with NvSci, DLA, and OpenGL ES technologies. One entry (EGLSync_CUDAEvent_Interop) is commented out and will not be built.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(cudaNvSciNvMedia)\nadd_subdirectory(cudaNvSciBufMultiplanar)\nadd_subdirectory(cuDLAErrorReporting)\nadd_subdirectory(cuDLAHybridMode)\nadd_subdirectory(cuDLALayerwiseStatsHybrid)\nadd_subdirectory(cuDLALayerwiseStatsStandalone)\nadd_subdirectory(cuDLAStandaloneMode)\n#add_subdirectory(EGLSync_CUDAEvent_Interop)\nadd_subdirectory(fluidsGLES)\nadd_subdirectory(nbody_opengles)\nadd_subdirectory(simpleGLES)\nadd_subdirectory(simpleGLES_EGLOutput)\n```\n\n----------------------------------------\n\nTITLE: CUDA API Dependencies\nDESCRIPTION: List of CUDA Runtime API functions required for 3D texture handling and graphics interop operations. These functions handle texture creation, memory management, and graphics resource mapping.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTexture3D/README.md#2025-04-21_snippet_0\n\nLANGUAGE: cuda\nCODE:\n```\ncudaGraphicsUnmapResources\ncudaMemcpy\ncudaFreeArray\ncudaFree\ncudaPitchedPtr\ncudaGraphicsResourceGetMappedPointer\ncudaGraphicsMapResources\ncudaDestroyTextureObject\ncudaExtent\ncudaDeviceSynchronize\ncudaCreateTextureObject\ncudaGraphicsUnregisterResource\ncudaMalloc\ncudaGraphicsGLRegisterBuffer\n```\n\n----------------------------------------\n\nTITLE: Setting CMake Requirements and Module Path for cuSolverRf\nDESCRIPTION: Specifies the minimum CMake version required and adds the CUDA samples module path to the CMake module search path.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverRf/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Dependencies for Particles Project\nDESCRIPTION: Sets up include directories and finds necessary packages like OpenGL and GLUT for the particles project.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/particles/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for EGLStream_CUDA_CrossGPU\nDESCRIPTION: Sets up the CMake project, defines the minimum required version, and specifies the project name and languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(EGLStream_CUDA_CrossGPU LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Finding NvSCI Libraries for Linux Systems\nDESCRIPTION: Searches for NvSciBuf and NvSciSync libraries in system paths and any user-specified library paths. Uses file globbing to find library files and supports both direct and nested directory structures.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cudaNvSciBufMultiplanar/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    # Find the NVSCI libraries\n    # use CMAKE_LIBRARY_PATH so that users can also specify the NVSCI lib path in cmake command\n    set(CMAKE_LIBRARY_PATH \"/usr/lib\" ${CMAKE_LIBRARY_PATH})\n    foreach(LIBRARY_PATH ${CMAKE_LIBRARY_PATH})\n        file(GLOB_RECURSE NVSCIBUF_LIB\n            ${LIBRARY_PATH}/libnvscibuf.so\n            ${LIBRARY_PATH}/*/libnvscibuf.so\n        )\n        file(GLOB_RECURSE NVSCISYNC_LIB\n            ${LIBRARY_PATH}/libnvscisync.so\n            ${LIBRARY_PATH}/*/libnvscisync.so\n        )\n        if(NVSCIBUF_LIB AND NVSCISYNC_LIB)\n            break()\n        endif()\n    endforeach()\n```\n\n----------------------------------------\n\nTITLE: Creating Executable Target for Binomial Options\nDESCRIPTION: Adds an executable target for the binomial options project, configuring CUDA compilation features and linking NVRTC libraries\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/binomialOptions_nvrtc/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(binomialOptions_nvrtc binomialOptions.cpp binomialOptions_gold.cpp binomialOptions_gpu.cpp)\n\ntarget_compile_options(binomialOptions_nvrtc PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(binomialOptions_nvrtc PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(binomialOptions_nvrtc PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_link_libraries(binomialOptions_nvrtc PRIVATE\n    CUDA::nvrtc\n    CUDA::cuda_driver\n)\n```\n\n----------------------------------------\n\nTITLE: Benchmarking Matrix Transpose Methods on NVIDIA GPU\nDESCRIPTION: Compares multiple matrix transpose techniques including simple copy, shared memory, naive, coalesced, optimized, coarse-grained, fine-grained, and diagonal approaches. Tests performance on a 1024x1024 matrix with 16x16 tile size.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_transpose.txt#2025-04-21_snippet_0\n\nLANGUAGE: cuda\nCODE:\n```\ntranspose simple copy       , Throughput = 1530.1826 GB/s, Time = 0.00511 ms, Size = 1048576 fp32 elements, NumDevsUsed = 1, Workgroup = 256\ntranspose shared memory copy, Throughput = 1489.9342 GB/s, Time = 0.00524 ms, Size = 1048576 fp32 elements, NumDevsUsed = 1, Workgroup = 256\ntranspose naive             , Throughput = 721.3705 GB/s, Time = 0.01083 ms, Size = 1048576 fp32 elements, NumDevsUsed = 1, Workgroup = 256\ntranspose coalesced         , Throughput = 1346.6855 GB/s, Time = 0.00580 ms, Size = 1048576 fp32 elements, NumDevsUsed = 1, Workgroup = 256\ntranspose optimized         , Throughput = 1510.6776 GB/s, Time = 0.00517 ms, Size = 1048576 fp32 elements, NumDevsUsed = 1, Workgroup = 256\ntranspose coarse-grained    , Throughput = 1514.5199 GB/s, Time = 0.00516 ms, Size = 1048576 fp32 elements, NumDevsUsed = 1, Workgroup = 256\ntranspose fine-grained      , Throughput = 1509.3702 GB/s, Time = 0.00518 ms, Size = 1048576 fp32 elements, NumDevsUsed = 1, Workgroup = 256\ntranspose diagonal          , Throughput = 1308.4336 GB/s, Time = 0.00597 ms, Size = 1048576 fp32 elements, NumDevsUsed = 1, Workgroup = 256\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architectures and Flags in CMake\nDESCRIPTION: Sets up CUDA architecture targets and compilation flags. It specifies a range of CUDA architectures from 5.0 to 12.0 and adds a warning suppression flag for deprecated GPU targets. Debug mode configuration is commented out.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/SobelFilter/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Creating Executable Target for Thread Fence Reduction\nDESCRIPTION: Adds an executable target for the thread fence reduction sample, setting compiler options and features. It enables C++17 and CUDA 17 standards, and turns on CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/threadFenceReduction/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(threadFenceReduction threadFenceReduction.cu)\n\ntarget_compile_options(threadFenceReduction PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(threadFenceReduction PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(threadFenceReduction PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Appending to CMake Module Path\nDESCRIPTION: This command appends a path to the CMAKE_MODULE_PATH variable. This allows CMake to find custom modules in the specified directory during the build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: Generating CUDA Fatbin for Vector Addition Kernel\nDESCRIPTION: Creates a custom command to generate a CUDA fatbin file for the vector addition kernel. It specifies the output file, input source, and compilation flags. A custom target is created to ensure the fatbin is generated before the main executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/vectorAddDrv/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nset(CUDA_FATBIN_FILE \"${CMAKE_CURRENT_BINARY_DIR}/vectorAdd_kernel64.fatbin\")\nset(CUDA_KERNEL_SOURCE \"${CMAKE_CURRENT_SOURCE_DIR}/vectorAdd_kernel.cu\")\n\nadd_custom_command(\n    OUTPUT ${CUDA_FATBIN_FILE}\n    COMMAND ${CMAKE_CUDA_COMPILER} ${INCLUDES} ${ALL_CCFLAGS} -Wno-deprecated-gpu-targets  ${GENCODE_FLAGS} -o ${CUDA_FATBIN_FILE} -fatbin ${CUDA_KERNEL_SOURCE}\n    DEPENDS ${CUDA_KERNEL_SOURCE}\n    COMMENT \"Building CUDA fatbin: ${CUDA_FATBIN_FILE}\"\n)\n\nadd_custom_target(generate_fatbin_vectorAdd ALL DEPENDS ${CUDA_FATBIN_FILE})\n\nadd_dependencies(vectorAddDrv generate_fatbin_vectorAdd)\n```\n\n----------------------------------------\n\nTITLE: Configuring Thread Migration Executable Target\nDESCRIPTION: Defines the threadMigration executable target, sets its properties, and links necessary libraries. It also configures include directories and compiler features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/threadMigration/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(threadMigration threadMigration.cpp)\n\ntarget_compile_options(threadMigration PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(threadMigration PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(threadMigration PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(threadMigration PUBLIC\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(threadMigration PUBLIC\n    CUDA::cuda_driver\n)\n\nif(UNIX)\n    target_link_libraries(threadMigration PUBLIC pthread)\nendif()\n```\n\n----------------------------------------\n\nTITLE: CUDA Fatbin Generation\nDESCRIPTION: Creates custom commands and targets to generate a CUDA fatbin file from the kernel source and establishes build dependencies.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleDrvRuntime/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nset(CUDA_FATBIN_FILE \"${CMAKE_CURRENT_BINARY_DIR}/vectorAdd_kernel64.fatbin\")\nset(CUDA_KERNEL_SOURCE \"${CMAKE_CURRENT_SOURCE_DIR}/vectorAdd_kernel.cu\")\n\nadd_custom_command(\n    OUTPUT ${CUDA_FATBIN_FILE}\n    COMMAND ${CMAKE_CUDA_COMPILER} ${INCLUDES} ${ALL_CCFLAGS} -Wno-deprecated-gpu-targets  ${GENCODE_FLAGS} -o ${CUDA_FATBIN_FILE} -fatbin ${CUDA_KERNEL_SOURCE}\n    DEPENDS ${CUDA_KERNEL_SOURCE}\n    COMMENT \"Building CUDA fatbin: ${CUDA_FATBIN_FILE}\"\n)\n\nadd_custom_target(generate_fatbin_simpleDrv ALL DEPENDS ${CUDA_FATBIN_FILE})\n\nadd_dependencies(simpleDrvRuntime generate_fatbin_simpleDrv)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_12\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(cuSolverDn_LinearSolver)\n```\n\n----------------------------------------\n\nTITLE: Displaying Status Messages\nDESCRIPTION: These commands display status messages if OpenGL or GLUT are not found. This informs the user that the 'nbody' sample will not be built due to missing dependencies.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_17\n\nLANGUAGE: cmake\nCODE:\n```\nelse()\n        message(STATUS \"GLUT not found - will not build sample 'nbody'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'nbody'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Function References\nDESCRIPTION: Essential CUDA Runtime API functions used in the template for basic GPU memory operations: cudaMalloc for device memory allocation, cudaMemcpy for host-device data transfer, and cudaFree for memory deallocation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/template/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaMalloc, cudaMemcpy, cudaFree\n```\n\n----------------------------------------\n\nTITLE: Using CUDA Runtime API for Memory Operations\nDESCRIPTION: Lists the CUDA Runtime API functions used in this sample, specifically cudaMalloc for allocating GPU memory, cudaMemcpy for transferring data between host and device, and cudaFree for releasing allocated GPU memory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/clock/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaMalloc, cudaMemcpy, cudaFree\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Build Commands for Data and DLL Files\nDESCRIPTION: Copies project data files and Windows DLL dependencies to the build output directory\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/FilterBorderControlNPP/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET FilterBorderControlNPP POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n\nif(WIN32)\n    add_custom_command(TARGET FilterBorderControlNPP\n    POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy\n    ${FreeImage_LIBRARY}/../FreeImage.dll\n    ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Windows-Specific Library and DLL Handling\nDESCRIPTION: Adds Windows-specific library links and copies necessary DLLs to the output directory\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/marchingCubes/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    target_link_libraries(marchingCubes\n        ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n        ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n    )\n\n    add_custom_command(TARGET marchingCubes\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\n\n    add_custom_command(TARGET marchingCubes\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Finding CUDA Toolkit\nDESCRIPTION: This command uses the `find_package` command to locate the CUDA toolkit.  The `REQUIRED` keyword ensures that the configuration will fail if the CUDA toolkit is not found.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Linking CUDA Libraries and Platform-Specific Dependencies\nDESCRIPTION: Links the necessary CUDA libraries to the target. For Unix systems, it also links the dynamic linking library (dl).\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/matrixMulDynlinkJIT/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(matrixMulDynlinkJIT PUBLIC\n    CUDA::cudart\n    CUDA::cuda_driver\n)\n\nif(UNIX)\n    target_link_libraries(matrixMulDynlinkJIT PUBLIC dl)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Finding OpenGL and GLUT\nDESCRIPTION: These commands use the find_package command to locate the OpenGL and GLUT libraries on the system.  These libraries are essential for rendering the particles in the nbody simulation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: PTX JIT Compilation Output\nDESCRIPTION: Console output showing PTX kernel compilation metrics including register usage, memory allocation, and compilation status. The kernel 'myKernel' is compiled for sm_90a architecture using 8 registers with minimal resource usage.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_ptxjit.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n[PTX Just In Time (JIT) Compilation (no-qatest)] - Starting...\n> Using CUDA Device [0]: NVIDIA H100 PCIe\n> findModulePath <./ptxjit_kernel64.ptx>\n> initCUDA loading module: <./ptxjit_kernel64.ptx>\nLoading ptxjit_kernel[] program\nCUDA Link Completed in 0.000000ms. Linker Output:\nptxas info    : 0 bytes gmem\nptxas info    : Compiling entry function 'myKernel' for 'sm_90a'\nptxas info    : Function properties for myKernel\nptxas         .     0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 8 registers\ninfo    : 0 bytes gmem\ninfo    : Function properties for 'myKernel':\ninfo    : used 8 registers, 0 stack, 0 bytes smem, 536 bytes cmem[0], 0 bytes lmem\nCUDA kernel launched\n```\n\n----------------------------------------\n\nTITLE: Simultaneous Streams Memory Footprint\nDESCRIPTION: Shows memory footprint growth when running graphs concurrently in separate streams\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_graphMemoryFootprint.txt#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n01:     FOOTPRINT: 67108864 bytes\n02:     FOOTPRINT: 134217728 bytes\n03:     FOOTPRINT: 201326592 bytes\n04:     FOOTPRINT: 268435456 bytes\n05:     FOOTPRINT: 335544320 bytes\n06:     FOOTPRINT: 402653184 bytes\n07:     FOOTPRINT: 402653184 bytes\n```\n\n----------------------------------------\n\nTITLE: Finding Packages (Vulkan, OpenGL)\nDESCRIPTION: These commands use the find_package command to locate the Vulkan and OpenGL libraries. These libraries are required for rendering in the application.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(Vulkan)\nfind_package(OpenGL)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Include Directories and Platform-Specific Settings\nDESCRIPTION: Configures include paths and sets Windows-specific GLUT directory locations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleCUDA2GL/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\n\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: Building randomFog Target with CUDA and OpenGL Dependencies\nDESCRIPTION: Creates the randomFog executable target with source files, configures compiler options including C++17 and CUDA 17 standards, and sets up CUDA compilation properties. Links against OpenGL, GLUT, and CUDA libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/randomFog/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(randomFog randomFog.cpp rng.cpp)\n\ntarget_compile_options(randomFog PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(randomFog PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(randomFog PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(randomFog PUBLIC\n    ${OPENGL_INCLUDE_DIR}\n    ${CUDAToolkit_INCLUDE_DIRS}\n    ${GLUT_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(randomFog\n    ${OPENGL_LIBRARIES}\n    ${GLUT_LIBRARIES}\n    CUDA::curand\n    CUDA::cudart\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Subdirectory: transpose\nDESCRIPTION: This line adds the 'transpose' directory as a subdirectory to the current CMake project. The CMakeLists.txt file in the 'transpose' directory will be processed, and its targets will be integrated into the project build.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(transpose)\n```\n\n----------------------------------------\n\nTITLE: Configuring cuDLA Target Build\nDESCRIPTION: Sets up the executable target with appropriate compiler options, C++17/CUDA 17 features, and links required libraries when all dependencies are found.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLAStandaloneMode/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nadd_executable(cuDLAStandaloneMode main.cpp)\n\ntarget_compile_options(cuDLAStandaloneMode PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cuDLAStandaloneMode PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cuDLAStandaloneMode PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(cuDLAStandaloneMode PUBLIC\n    ${CUDAToolkit_INCLUDE_DIRS}\n    ${NVSCIBUF_INCLUDE_DIR}\n    ${NVSCISYNC_INCLUDE_DIR}\n)\n\ntarget_link_libraries(cuDLAStandaloneMode\n    ${CUDLA_LIB}\n    ${NVSCIBUF_LIB}\n    ${NVSCISYNC_LIB}\n)\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the sample program. These functions are essential for memory management, device synchronization, and retrieving device properties in CUDA programming.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleVoteIntrinsics/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaMalloc, cudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: Using CUDA Runtime API for Binomial Option Pricing\nDESCRIPTION: This snippet showcases the CUDA Runtime API calls used in the binomial options pricing sample. It includes synchronization and memory copy operations between host and device.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/binomialOptions/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaDeviceSynchronize();\ncudaMemcpyToSymbol();\ncudaMemcpyFromSymbol();\n```\n\n----------------------------------------\n\nTITLE: Finding CUDA Toolkit Package\nDESCRIPTION: This snippet uses the `find_package` command to locate the CUDA Toolkit. The `REQUIRED` keyword ensures that the configuration fails if the CUDA Toolkit is not found.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Setting up CMake Project for CUDA freeImageInteropNPP\nDESCRIPTION: Initial CMake configuration including minimum version requirement, module path setup, and project definition with C++ language support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/freeImageInteropNPP/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(freeImageInteropNPP LANGUAGES CXX)\n```\n\n----------------------------------------\n\nTITLE: Setting Target Include Directories\nDESCRIPTION: This command sets the include directories for the target 'simpleVulkan'. It includes the Vulkan and CUDA Toolkit include directories.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_15\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_include_directories(simpleVulkan PUBLIC\n                ${Vulkan_INCLUDE_DIRS}\n                ${CUDAToolkit_INCLUDE_DIRS}\n            )\n```\n\n----------------------------------------\n\nTITLE: Including Directories\nDESCRIPTION: This command adds the specified directory to the include path, allowing the compiler to find header files in that location. This is necessary to include common project headers.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Defining memMapIPCDrv Executable Target\nDESCRIPTION: Creates the main executable target for memMapIPCDrv, specifying source files, compile options, and linking libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/memMapIPCDrv/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(memMapIPCDrv memMapIpc.cpp ../../../Common/helper_multiprocess.cpp)\n\ntarget_compile_options(memMapIPCDrv PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(memMapIPCDrv PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(memMapIPCDrv PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(memMapIPCDrv PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(memMapIPCDrv PUBLIC\n    CUDA::cuda_driver\n)\n\nif(UNIX)\n    target_link_libraries(memMapIPCDrv PUBLIC rt)\nendif()\n```\n\n----------------------------------------\n\nTITLE: GPU Device Information and Text Analysis Output\nDESCRIPTION: Shows the execution results of a CUDA program that first identifies the GPU device ('Hopper' with compute capability 9.0) and then analyzes a text file (War and Peace), counting the occurrences of specific characters ('x', 'y', 'z', and 'w').\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_c++11_cuda.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nRead 3223503 byte corpus from ../../../../Samples/0_Introduction/c++11_cuda/warandpeace.txt\ncounted 107310 instances of 'x', 'y', 'z', or 'w' in \"../../../../Samples/0_Introduction/c++11_cuda/warandpeace.txt\"\n```\n\n----------------------------------------\n\nTITLE: Initializing GPU Device for CUDA Convolution\nDESCRIPTION: This snippet initializes the GPU device and displays its capabilities. It sets up the environment for the convolution operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_convolutionTexture.txt#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n```\n\n----------------------------------------\n\nTITLE: Setting up FDTD3d Target Configuration\nDESCRIPTION: Configures the FDTD3d executable target with source files, compilation options, C++17/CUDA 17 features, and include directories.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/FDTD3d/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(FDTD3d src/FDTD3d.cpp src/FDTD3dGPU.cu src/FDTD3dReference.cpp)\n\ntarget_compile_options(FDTD3d PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(FDTD3d PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(FDTD3d PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(FDTD3d PRIVATE\n    inc\n)\n```\n\n----------------------------------------\n\nTITLE: Finding GLFW (Windows Specific)\nDESCRIPTION: This conditional block finds GLFW header and library for Windows systems specifically. It uses find_file and find_library commands. If both header and library are found, HAVE_GLFW3_H is set to 1.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: cmake\nCODE:\n```\nif(WIN32)\n    find_file(GLFW3_H \"GLFW/glfw3.h\" PATH \"${GLFW_INCLUDE_DIR}\")\n    find_library(GLFW3_LIB \"glfw3\" PATH \"${GLFW_LIB_DIR}\")\n    if(GLFW3_H AND GLFW3_LIB) \n        message(STATUS \"Found GLFW/glfw3.h and GLFW library.\")\n        set(HAVE_GLFW3_H 1)\n    endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Target Build with Dependencies\nDESCRIPTION: Defines the build target with source files, compiler options, and architecture-specific conditions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleCUDA2GL/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\n# Source file\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        if(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n            message(STATUS \"Will not build sample simpleCUDA2GL - not supported on aarch64\")\n        else()\n            # Add target for simpleCUDA2GL\n            add_executable(simpleCUDA2GL simpleCUDA2GL.cu main.cpp)\n\n            target_compile_options(simpleCUDA2GL PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n            target_compile_features(simpleCUDA2GL PRIVATE cxx_std_17 cuda_std_17)\n\n            set_target_properties(simpleCUDA2GL PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n            target_include_directories(simpleCUDA2GL PUBLIC\n                ${OPENGL_INCLUDE_DIR}\n                ${CUDAToolkit_INCLUDE_DIRS}\n                ${GLUT_INCLUDE_DIRS}\n            )\n\n            target_link_libraries(simpleCUDA2GL\n                ${OPENGL_LIBRARIES}\n                ${GLUT_LIBRARIES}\n            )\n            if(WIN32)\n                target_link_libraries(simpleCUDA2GL\n                    ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n                    ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n                )\n\n                add_custom_command(TARGET simpleCUDA2GL\n                    POST_BUILD\n                    COMMAND ${CMAKE_COMMAND} -E copy ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll ${CMAKE_CURRENT_BINARY_DIR}\n                )\n\n                add_custom_command(TARGET simpleCUDA2GL\n                    POST_BUILD\n                    COMMAND ${CMAKE_COMMAND} -E copy ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll ${CMAKE_CURRENT_BINARY_DIR}\n                )\n            endif()\n        endif()\n    else()\n        message(STATUS \"GLUT not found - will not build sample 'simpleCUDA2GL'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'simpleCUDA2GL'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Creating Marching Cubes Executable Target\nDESCRIPTION: Configures executable target with CUDA and C++ compiler options, includes OpenGL dependencies and links libraries\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/marchingCubes/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(marchingCubes marchingCubes_kernel.cu marchingCubes.cpp)\n\ntarget_compile_options(marchingCubes PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(marchingCubes PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(marchingCubes PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(marchingCubes PUBLIC\n    ${OPENGL_INCLUDE_DIR}\n    ${CUDAToolkit_INCLUDE_DIRS}\n    ${GLUT_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(marchingCubes\n    ${OPENGL_LIBRARIES}\n    ${GLUT_LIBRARIES}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Post-Build Data Copy for SimpleSurfaceWrite\nDESCRIPTION: Sets up a post-build command to copy data files to the output directory after the build process completes.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleSurfaceWrite/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET simpleSurfaceWrite POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA Driver API Implementation\nDESCRIPTION: Core CUDA Driver API functions used for module management and kernel execution. The implementation includes cuModuleGetFunction for function lookup, cuLaunchKernel for kernel execution, and cuCtxSynchronize for synchronization.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleAssert_nvrtc/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncuModuleGetFunction\ncuLaunchKernel\ncuCtxSynchronize\n```\n\n----------------------------------------\n\nTITLE: Documented CUDA Runtime API Dependencies\nDESCRIPTION: List of required CUDA Runtime API functions for implementing multi-GPU CUFFT operations. These APIs handle device management, memory operations, and synchronization across multiple GPUs.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/README.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncudaXtFree, cudaMemcpy, cudaFree, cudaSetDevice, cudaGetDeviceCount, cudaDeviceSynchronize, cudaMalloc, cudaGetDeviceProperties\n```\n\n----------------------------------------\n\nTITLE: CUDA Graph API List\nDESCRIPTION: List of CUDA Runtime API functions used in the implementation of graph conditional nodes\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/graphConditionalNodes/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaDeviceSynchronize\ncudaDriverGetVersion\ncudaFree\ncudaGraphAddNode\ncudaGraphConditionalHandleCreate\ncudaGraphCreate\ncudaGraphDestroy\ncudaGraphExecDestroy\ncudaGraphInstantiate\ncudaGraphLaunch\ncudaGraphSetConditional\ncudaMalloc\ncudaMemset\ncudaStreamBeginCapture\ncudaStreamBeginCaptureToGraph\ncudaStreamCreate\ncudaStreamDestroy\ncudaStreamEndCapture\ncudaStreamGetCaptureInfo\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Dependencies\nDESCRIPTION: Provides status messages if OpenGL or GLUT are not found, indicating that the bilateral filter sample will not be built.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bilateralFilter/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\n    else()\n        message(STATUS \"GLUT not found - will not build sample 'bilateralFilter'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'bilateralFilter'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Find CUDAToolkit Package\nDESCRIPTION: Locates the CUDA Toolkit using CMake's find_package command. The REQUIRED keyword ensures that the configuration will fail if the CUDA Toolkit is not found.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Define Project with Languages\nDESCRIPTION: Defines the project name and specifies the programming languages used in the project (C, C++, and CUDA). The project command is essential for setting up the CMake project environment.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nproject(quasirandomGenerator_nvrtc LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Configuring Include Directories and FreeImage Dependencies\nDESCRIPTION: Sets include directories and checks for FreeImage library availability\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/boxFilterNPP/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(\n    ../../../Common\n    ../../../Common/UtilNPP\n)\n\nfind_package(FreeImage)\n\nif(${FreeImage_FOUND})\n    add_executable(boxFilterNPP boxFilterNPP.cpp)\n\n    target_compile_options(boxFilterNPP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n    target_compile_features(boxFilterNPP PRIVATE cxx_std_17 cuda_std_17)\n\n    set_target_properties(boxFilterNPP PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Including CUDA Driver API Functions for Complex Numbers\nDESCRIPTION: This snippet shows the CUDA Driver API functions used for complex number operations in the sample.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n### [CUDA Driver API](http://docs.nvidia.com/cuda/cuda-driver-api/index.html)\ncuDoubleComplex, cuComplex\n```\n\n----------------------------------------\n\nTITLE: Linking CUDA Libraries to the conjugateGradientCudaGraphs Target\nDESCRIPTION: Links the cuBLAS and cuSPARSE libraries to the conjugate gradient application. These libraries provide optimized linear algebra and sparse matrix operations needed for the conjugate gradient algorithm.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(conjugateGradientCudaGraphs PRIVATE\n    CUDA::cublas\n    CUDA::cusparse\n)\n```\n\n----------------------------------------\n\nTITLE: Displaying CUDA GPU Information and Test Results\nDESCRIPTION: This snippet shows the output of a CUDA program that detects available GPUs, identifies the GPU model, and runs a simpleCUBLASXT test. It demonstrates successful GPU detection and test execution.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleCUBLASXT.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nUsing 1 GPUs\nGPU ID = 0, Name = NVIDIA H100 PCIe \nsimpleCUBLASXT test running..\nsimpleCUBLASXT test passed.\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architectures and Flags\nDESCRIPTION: This section defines the target CUDA architectures and adds compiler flags.  CMAKE_CUDA_ARCHITECTURES specifies the CUDA architectures to compile for (e.g., 50, 52, 60).  CMAKE_CUDA_FLAGS appends the \"-Wno-deprecated-gpu-targets\" flag to suppress warnings about deprecated GPU targets.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Test for vprintf Syscalls in CMake\nDESCRIPTION: Adds a test for vprintf syscalls using the ptxgen tool. The test executes ptxgen on the vprintf.ll LLVM IR file in the specified working directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/syscalls/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_test(NAME test-syscalls-vprintf\n\tCOMMAND \"${CMAKE_CURRENT_BINARY_DIR}/../ptxgen/ptxgen\" \"${CMAKE_CURRENT_SOURCE_DIR}/vprintf.ll\"\n  WORKING_DIRECTORY \"${CMAKE_CURRENT_BINARY_DIR}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Platform-Specific Build Rules\nDESCRIPTION: Sets up conditional build rules for Linux platforms, excluding aarch64 architecture, and configures target properties and dependencies.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    if(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n        message(STATUS \"Will not build sample streamOrderedAllocationIPC - not supported on aarch64\")\n    else()\n        add_executable(streamOrderedAllocationIPC streamOrderedAllocationIPC.cu ../../../Common/helper_multiprocess.cpp)\n\n        target_compile_options(streamOrderedAllocationIPC PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(streamOrderedAllocationIPC PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(streamOrderedAllocationIPC PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_link_libraries(streamOrderedAllocationIPC PUBLIC\n            CUDA::cuda_driver\n        )\n    endif()\nelse()\n    message(STATUS \"Will not build sample streamOrderedAllocationIPC - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Creating Executable Target with OpenGL and CUDA\nDESCRIPTION: Defines the executable target for the recursive Gaussian sample, configuring CUDA compilation features, include directories, and library linking\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/recursiveGaussian/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(recursiveGaussian recursiveGaussian_cuda.cu recursiveGaussian.cpp)\n\ntarget_compile_options(recursiveGaussian PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(recursiveGaussian PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(recursiveGaussian PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(recursiveGaussian PUBLIC\n    ${OPENGL_INCLUDE_DIR}\n    ${CUDAToolkit_INCLUDE_DIRS}\n    ${GLUT_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(recursiveGaussian\n    ${OPENGL_LIBRARIES}\n    ${GLUT_LIBRARIES}\n)\n```\n\n----------------------------------------\n\nTITLE: Link Target Libraries\nDESCRIPTION: Links the quasirandomGenerator_nvrtc executable against the CUDA::nvrtc and CUDA::cuda_driver libraries. These libraries provide the necessary runtime support for CUDA.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_11\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(quasirandomGenerator_nvrtc PRIVATE\n    CUDA::nvrtc\n    CUDA::cuda_driver\n)\n```\n\n----------------------------------------\n\nTITLE: Executing Black-Scholes GPU Kernel in CUDA\nDESCRIPTION: This snippet shows the performance results of running the Black-Scholes algorithm on a GPU. It includes the number of options processed, execution time, memory bandwidth, and options processed per second.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_BlackScholes.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nOptions count             : 8000000     \nBlackScholesGPU() time    : 0.048059 msec\nEffective memory bandwidth: 1664.634581 GB/s\nGigaoptions per second    : 166.463458     \n\nBlackScholes, Throughput = 166.4635 GOptions/s, Time = 0.00005 s, Size = 8000000 options, NumDevsUsed = 1, Workgroup = 128\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Usage\nDESCRIPTION: List of CUDA Runtime API functions used in the sample for event handling, memory management, and profiling. These APIs enable asynchronous data transfers, event management, and device synchronization.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/asyncAPI/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaProfilerStop\ncudaMalloc\ncudaMemcpyAsync\ncudaFree\ncudaMallocHost\ncudaProfilerStart\ncudaDeviceSynchronize\ncudaEventRecord\ncudaFreeHost\ncudaMemset\ncudaEventDestroy\ncudaEventQuery\ncudaEventElapsedTime\ncudaGetDeviceProperties\ncudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Functions for Matrix Multiplication\nDESCRIPTION: List of CUDA Runtime API functions used in the matrix multiplication implementation, including memory allocation, copying, event handling, and device property queries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/matrixMulCUBLAS/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\ncudaMemcpy, cudaFree, cudaEventSynchronize, cudaEventRecord, cudaMalloc, cudaEventElapsedTime, cudaGetDeviceProperties, cudaEventCreate\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Usage for Graphics Interop and Memory Management\nDESCRIPTION: Lists the CUDA Runtime API functions used in the sample for graphics interoperability, memory allocation, copying, and synchronization. These functions are essential for managing GPU resources and data transfer in the particle simulation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/particles/README.md#2025-04-21_snippet_1\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaGraphicsUnmapResources, cudaMemcpy, cudaFree, cudaGraphicsResourceGetMappedPointer, cudaGraphicsMapResources, cudaDeviceSynchronize, cudaMemset, cudaMemcpyToSymbol, cudaGraphicsGLRegisterBuffer, cudaGraphicsUnregisterResource, cudaMalloc, cudaInit, cudaGLInit\n```\n\n----------------------------------------\n\nTITLE: Locating CUDA Toolkit (CMake >= 3.18)\nDESCRIPTION: Locates the CUDA Toolkit using `find_package(CUDAToolkit REQUIRED)` for CMake versions 3.18 and later. Sets CMake policy CMP0074 to use `CUDAToolkit_ROOT` as a CMake prefix.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\n  \"cmake_policy(SET CMP0074 NEW) # Use CUDAToolkit_ROOT as a cmake prefix.\n  find_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n  set(CUDA_LIB \\\"${CUDA_cuda_driver_LIBRARY}\\\")\n  include_directories(\\\"${CUDAToolkit_INCLUDE_DIRS}\\\")\n  get_filename_component(CUDA_HOME \\\"${CUDAToolkit_BIN_DIR}\\\" DIRECTORY)\n  find_library(CUDADEVRT_LIB cudadevrt PATH \\\"${CUDAToolkit_LIBRARY_DIR}\\\")\nendif ()\"\n```\n\n----------------------------------------\n\nTITLE: Find CUDA Toolkit\nDESCRIPTION: This snippet uses the `find_package` command to locate the CUDA Toolkit. It marks the CUDA Toolkit as a required dependency, meaning that the build process will fail if the CUDA Toolkit cannot be found.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Setting C++ and CUDA Standard\nDESCRIPTION: This command specifies the C++ and CUDA standards to be used for compiling the 'nbody' target.  It sets both to version 17.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_11\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_compile_features(nbody PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Compile Options\nDESCRIPTION: This command sets the compile options for the target 'simpleVulkan' specifically for CUDA language files.  It enables extended lambda support for CUDA.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_12\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_compile_options(simpleVulkan PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n```\n\n----------------------------------------\n\nTITLE: Configuring Target Link Libraries and Include Directories\nDESCRIPTION: Links necessary CUDA libraries and sets include directories for the project\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/boxFilterNPP/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_include_directories(boxFilterNPP PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n    ${FreeImage_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(boxFilterNPP PRIVATE\n    CUDA::nppc\n    CUDA::nppisu\n    CUDA::nppif\n    CUDA::cudart\n    ${FreeImage_LIBRARIES}\n)\n```\n\n----------------------------------------\n\nTITLE: CUFFT Multi-GPU Sample Output Log\nDESCRIPTION: Console output showing the initialization attempt and error message when trying to run the simpleCUFFT_MGPU sample with insufficient GPUs. The sample requires two GPUs but only one was detected.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleCUFFT_MGPU.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n[simpleCUFFT_MGPU] is starting...\n\nNo. of GPU on node 1\nTwo GPUs are required to run simpleCUFFT_MGPU sample code\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architectures and Compilation Flags\nDESCRIPTION: Sets supported CUDA compute architectures and compilation flags, with optional debug configuration\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/boxFilterNPP/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring vectorAddDrv Executable Target\nDESCRIPTION: Adds the vectorAddDrv executable target, sets its compilation options, features, and links necessary libraries. It also configures include directories and enables CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/vectorAddDrv/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\nadd_executable(vectorAddDrv vectorAddDrv.cpp)\n\ntarget_compile_options(vectorAddDrv PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(vectorAddDrv PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(vectorAddDrv PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\ntarget_include_directories(vectorAddDrv PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(vectorAddDrv PUBLIC\n    CUDA::cuda_driver\n)\n```\n\n----------------------------------------\n\nTITLE: Copying LLVM IR Files to Build Directory in CMake\nDESCRIPTION: Copies the LLVM IR files (malloc-free.ll and vprintf.ll) to the current binary directory for testing purposes.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/syscalls/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nfile(COPY malloc-free.ll DESTINATION \"${CMAKE_CURRENT_BINARY_DIR}\")\nfile(COPY vprintf.ll DESTINATION \"${CMAKE_CURRENT_BINARY_DIR}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Post-Build Commands for CUDA Headers\nDESCRIPTION: Sets up post-build commands to copy the required CUDA kernel source and header files to the build directory. This enables runtime compilation to access necessary CUDA headers.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/matrixMul_nvrtc/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# Copy clock_kernel.cu to the output directory\nadd_custom_command(TARGET matrixMul_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/matrixMul_kernel.cu ${CUDAToolkit_BIN_DIR}/../include/cooperative_groups.h ${CMAKE_CURRENT_BINARY_DIR}\n)\n\nadd_custom_command(TARGET matrixMul_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CUDAToolkit_BIN_DIR}/../include/cooperative_groups ${CMAKE_CURRENT_BINARY_DIR}/cooperative_groups\n)\n\nadd_custom_command(TARGET matrixMul_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CUDAToolkit_BIN_DIR}/../include/nv ${CMAKE_CURRENT_BINARY_DIR}/nv\n)\n\nadd_custom_command(TARGET matrixMul_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CUDAToolkit_BIN_DIR}/../include/cuda ${CMAKE_CURRENT_BINARY_DIR}/cuda\n)\n```\n\n----------------------------------------\n\nTITLE: Building Box Filter Executable with CUDA and OpenGL\nDESCRIPTION: Adds the boxFilter executable target, sets compiler options, and links necessary libraries. It also copies required data files to the output directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/boxFilter/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        add_executable(boxFilter boxFilter.cpp boxFilter_cpu.cpp boxFilter_kernel.cu)\n\n        target_compile_options(boxFilter PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(boxFilter PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(boxFilter PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\n        target_include_directories(boxFilter PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n\n        target_link_libraries(boxFilter\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n\n        # Copy data files to output directory\n        add_custom_command(TARGET boxFilter POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_if_different\n            ${CMAKE_CURRENT_SOURCE_DIR}/data/teapot1024.ppm\n            ${CMAKE_CURRENT_BINARY_DIR}/\n        )\n\n        # Copy data files to output directory\n        add_custom_command(TARGET boxFilter POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_if_different\n            ${CMAKE_CURRENT_SOURCE_DIR}/data/ref_14.ppm\n            ${CMAKE_CURRENT_BINARY_DIR}/\n        )\n\n        # Copy data files to output directory\n        add_custom_command(TARGET boxFilter POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_if_different\n            ${CMAKE_CURRENT_SOURCE_DIR}/data/ref_22.ppm\n            ${CMAKE_CURRENT_BINARY_DIR}/\n        )\n```\n\n----------------------------------------\n\nTITLE: Setting Compile Features for Target\nDESCRIPTION: This snippet sets the C++ and CUDA standard compile features for the target. It specifies that the code should be compiled using C++17 and CUDA 17 standards.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_11\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_features(postProcessGL PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: CUDA Clock Sample Console Output\nDESCRIPTION: Console output showing GPU device identification and clock measurement results from running the CUDA clock sample on an NVIDIA Hopper GPU.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_clock.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCUDA Clock sample\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nAverage clocks/block = 1904.875000\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions Used in Simple CUFFT Example\nDESCRIPTION: This snippet lists the CUDA Runtime API functions used in the Simple CUFFT example. These functions are essential for memory allocation, data transfer, and memory deallocation on the GPU.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUFFT/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n### [CUDA Runtime API](http://docs.nvidia.com/cuda/cuda-runtime-api/index.html)\ncudaMalloc, cudaMemcpy, cudaFree\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions Used\nDESCRIPTION: This snippet lists the CUDA Runtime API functions utilized in the sample, including memory management and device synchronization functions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/newdelete/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n### [CUDA Runtime API](http://docs.nvidia.com/cuda/cuda-runtime-api/index.html)\ncudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaDeviceSetLimit, cudaMalloc\n```\n\n----------------------------------------\n\nTITLE: CUDA Concurrent Kernels Execution Log\nDESCRIPTION: Console output showing detection of NVIDIA Hopper GPU with compute capability 9.0 and performance comparison between serial and concurrent kernel execution. The test demonstrates 8x theoretical speedup from concurrent execution.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_concurrentKernels.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n[./concurrentKernels] - Starting...\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n> Detected Compute SM 9.0 hardware with 114 multi-processors\nExpected time for serial execution of 8 kernels = 0.080s\nExpected time for concurrent execution of 8 kernels = 0.010s\nMeasured time for sample = 0.010s\nTest passed\n```\n\n----------------------------------------\n\nTITLE: Locating CUDA Toolkit (CMake < 3.18)\nDESCRIPTION: Locates the CUDA Toolkit using `find_package(CUDA REQUIRED)` for CMake versions less than 3.18. Sets CUDA-related variables like `CUDA_HOME`, include directories, and libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\n\"if (${CMAKE_VERSION} VERSION_LESS 3.18.0)\n  find_package(CUDA REQUIRED)\n  set(CUDA_HOME \\\"${CUDA_TOOLKIT_ROOT_DIR}\\\")\n  get_filename_component(CUDA_LIB_ROOT \\\"${CUDA_cudart_static_LIBRARY}\\\" DIRECTORY)\n  find_library(CUDA_LIB NAMES cuda cuda.lib PATHS \\\"${CUDA_LIB_ROOT}\\\" \\\"${CUDA_LIB_ROOT}/stubs\\\")\n  include_directories(\\\"${CUDA_INCLUDE_DIRS}\\\")\n  find_library(CUDADEVRT_LIB cudadevrt PATHS \\\"${CUDA_LIB_ROOT}\\\" \\\"${CUDA_LIB_ROOT}/stubs\\\")\nelse () # Else, we're using cmake versions >= 3.18.\"\n```\n\n----------------------------------------\n\nTITLE: Setting Include Directories\nDESCRIPTION: This command adds include directories for the 'nbody' target. These directories contain header files needed for compilation, specifically for OpenGL, the CUDA Toolkit, and GLUT.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_13\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_include_directories(nbody PUBLIC\n            ${OPENGL_INCLUDE_DIR}\n            ${CUDAToolkit_INCLUDE_DIRS}\n            ${GLUT_INCLUDE_DIRS}\n        )\n```\n\n----------------------------------------\n\nTITLE: Set Target Include Directories\nDESCRIPTION: This snippet adds the CUDA Toolkit include directory to the include path for the `UnifiedMemoryPerf` target. This ensures that the compiler can find CUDA header files during compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_13\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_include_directories(UnifiedMemoryPerf PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Target Link Libraries\nDESCRIPTION: This command sets the link libraries for the target 'simpleVulkan'. It links against the Vulkan libraries and OpenGL.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_16\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_link_libraries(simpleVulkan\n                ${Vulkan_LIBRARIES}\n                OpenGL::GL\n            )\n```\n\n----------------------------------------\n\nTITLE: Setting Up Project Structure and Dependencies\nDESCRIPTION: Defines the project structure by specifying include directories and source files. It also sets up the main executable target with appropriate compiler options and features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/scalarProd/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for scalarProd\nadd_executable(scalarProd scalarProd_cpu.cpp scalarProd.cu)\n\ntarget_compile_options(scalarProd PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(scalarProd PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(scalarProd PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Minimum Version and Modules\nDESCRIPTION: Sets the minimum required CMake version and adds custom module paths for project configuration\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/FilterBorderControlNPP/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architecture Targets and Flags\nDESCRIPTION: Configures the CUDA architectures to target and sets compiler flags, including warning suppressions and debug options.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTexture/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Executing CUDA Matrix Multiplication Sample\nDESCRIPTION: This snippet shows the output of running a CUDA matrix multiplication sample. It includes device information, memory usage, module loading, processing time, and result verification.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_matrixMulDrv.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n[ matrixMulDrv (Driver API) ]\n> Using CUDA Device [0]: NVIDIA H100 PCIe\n> GPU Device has SM 9.0 compute capability\n  Total amount of global memory:     85021163520 bytes\n> findModulePath found file at <./matrixMul_kernel64.fatbin>\n> initCUDA loading module: <./matrixMul_kernel64.fatbin>\n> 32 block size selected\nProcessing time: 0.058000 (ms)\nChecking computed result for correctness: Result = PASS\n\nNOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.\n```\n\n----------------------------------------\n\nTITLE: Including Common Directory for CUDA Project\nDESCRIPTION: Adds the common directory to the include path for the CUDA project, providing access to shared utility functions and headers.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenGL and GLUT Dependencies in CMake\nDESCRIPTION: Finds and configures OpenGL and GLUT packages. For Windows, it sets custom include and library directories for GLUT. The build process continues only if both OpenGL and GLUT are found.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/SobelFilter/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n\nif(${OpenGL_FOUND})\n    if (${GLUT_FOUND})\n        # Add target for SobelFilter\n        add_executable(SobelFilter SobelFilter.cpp SobelFilter_kernels.cu)\n        # ... (additional configuration)\n    else()\n        message(STATUS \"GLUT not found - will not build sample 'SobelFilter'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'SobelFilter'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Displaying GPU Device Information for CUDA Jacobi Solver\nDESCRIPTION: This snippet shows the output of querying the GPU device information, including the device name, compute capability, and number of multi-processors.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_conjugateGradient.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n> GPU device has 114 Multi-Processors, SM 9.0 compute capabilities\n```\n\n----------------------------------------\n\nTITLE: Loading CUDA Module\nDESCRIPTION: Loads a CUDA module from PTX or CUBIN data using cuModuleLoadData(). This allows the program to access kernels and global variables in the module.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/threadMigration/README.md#2025-04-21_snippet_2\n\nLANGUAGE: CUDA\nCODE:\n```\ncuModuleLoadData(&module, PTX_STRING);\n```\n\n----------------------------------------\n\nTITLE: Allocating GPU Memory in CUDA\nDESCRIPTION: This snippet shows the use of cudaMalloc for allocating memory on the GPU. It's a fundamental CUDA Runtime API function for memory management.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/scalarProd/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMalloc\n```\n\n----------------------------------------\n\nTITLE: CUDA Conjugate Gradient Execution Output\nDESCRIPTION: Console output showing the execution of a conjugate gradient solver on an NVIDIA Hopper GPU with compute capability 9.0. The output includes device information, computation results, and performance metrics.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_conjugateGradientMultiBlockCG.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nStarting [conjugateGradientMultiBlockCG]...\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n> GPU device has 114 Multi-Processors, SM 9.0 compute capabilities\n\nGPU Final, residual = 1.600115e-06, kernel execution time = 16.014656 ms\nTest Summary:  Error amount = 0.000000 \n&&&& conjugateGradientMultiBlockCG PASSED\n```\n\n----------------------------------------\n\nTITLE: Setting Minimum CMake Version\nDESCRIPTION: Specifies the minimum required version of CMake for the project. This ensures that the CMake version used to build the project is compatible with the commands and features used in the CMakeLists.txt file.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\n\"cmake_minimum_required(VERSION 3.10.0)\"\n```\n\n----------------------------------------\n\nTITLE: Add Executable Target\nDESCRIPTION: This adds an executable target named 'batchCUBLAS'. The source file used to build the executable is 'batchCUBLAS.cpp'.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(batchCUBLAS batchCUBLAS.cpp)\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Commands for Data File Copying\nDESCRIPTION: Creates custom commands to copy necessary data files to the output directory after building the target.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTextureDrv/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET simpleTextureDrv POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/teapot512.pgm\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n\nadd_custom_command(TARGET simpleTextureDrv POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/ref_rotated.pgm\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n```\n\n----------------------------------------\n\nTITLE: Creating UVMLite Executable Target in CMake\nDESCRIPTION: Defines the UVMLite executable target and configures a test for it, specifying the working directory for the test execution.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/uvmlite/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(uvmlite uvmlite.c)\n\nadd_test(NAME uvmlite COMMAND uvmlite WORKING_DIRECTORY \"${CMAKE_CURRENT_BINARY_DIR}\")\n```\n\n----------------------------------------\n\nTITLE: Generating CUDA Fatbin for Thread Migration\nDESCRIPTION: Sets up a custom command to generate a CUDA fatbin file for the thread migration kernel. It creates a custom target for fatbin generation and ensures the main target depends on it.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/threadMigration/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nset(CUDA_FATBIN_FILE \"${CMAKE_CURRENT_BINARY_DIR}/threadMigration_kernel64.fatbin\")\nset(CUDA_KERNEL_SOURCE \"${CMAKE_CURRENT_SOURCE_DIR}/threadMigration_kernel.cu\")\n\nadd_custom_command(\n    OUTPUT ${CUDA_FATBIN_FILE}\n    COMMAND ${CMAKE_CUDA_COMPILER} ${INCLUDES} ${ALL_CCFLAGS} -Wno-deprecated-gpu-targets  ${GENCODE_FLAGS} -o ${CUDA_FATBIN_FILE} -fatbin ${CUDA_KERNEL_SOURCE}\n    DEPENDS ${CUDA_KERNEL_SOURCE}\n    COMMENT \"Building CUDA fatbin: ${CUDA_FATBIN_FILE}\"\n)\n\n# Create a dummy target for fatbin generation\nadd_custom_target(generate_fatbin_threadMigration ALL DEPENDS ${CUDA_FATBIN_FILE})\n\n# Ensure matrixMulDrv depends on the fatbin\nadd_dependencies(threadMigration generate_fatbin_threadMigration)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(boxFilterNPP)\n```\n\n----------------------------------------\n\nTITLE: Platform-Specific Library Linking\nDESCRIPTION: Sets up platform-specific library linking for CUDA driver, NVRTC, and nvJitLink libraries on both Linux and Windows systems.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/jitLto/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_link_libraries(jitLto PRIVATE\n    CUDA::cuda_driver\n    CUDA::nvrtc\n)\n\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    target_link_libraries(jitLto PRIVATE\n        ${CUDAToolkit_LIBRARY_DIR}/libnvJitLink.so\n    )\nendif()\n\nif(CMAKE_SYSTEM_NAME STREQUAL \"Windows\")\n    target_link_libraries(jitLto PRIVATE\n        ${CUDAToolkit_LIBRARY_DIR}/nvJitLink.lib\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Include Directories and Library Dependencies\nDESCRIPTION: Sets up the include directories for CUDA toolkit headers and links the necessary CUDA libraries (cudart, cublas, and cusolver) to the executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverRf/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_include_directories(cuSolverRf PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n\ntarget_link_libraries(cuSolverRf PRIVATE\n    CUDA::cudart\n    CUDA::cublas\n    CUDA::cusolver\n)\n```\n\n----------------------------------------\n\nTITLE: Executing CUDA Kernel for Matrix Multiplication with Async Copy\nDESCRIPTION: This snippet shows the execution of a CUDA kernel named 'AsyncCopyMultiStageLargeChunk' for matrix multiplication. It performs the computation and measures the performance in GFlop/s.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_globalToShmemAsyncCopy.txt#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\nRunning kernel = 0 - AsyncCopyMultiStageLargeChunk\nComputing result using CUDA Kernel...\ndone\nPerformance= 5289.33 GFlop/s, Time= 0.793 msec, Size= 4194304000 Ops, WorkgroupSize= 256 threads/block\n```\n\n----------------------------------------\n\nTITLE: Adding and Configuring CUDA Tests - CMake\nDESCRIPTION: This snippet adds two CUDA tests using the CMake add_test command, specifying the command to run PTX generation for the respective source files. It also sets properties for test setup dependencies, ensuring tests run with attention to required fixtures.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/cuda-shared-memory/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_test(NAME test-cuda-shared-memory-shared_memory\n\tCOMMAND \"${CMAKE_CURRENT_BINARY_DIR}/../ptxgen/ptxgen\" \"${CMAKE_CURRENT_SOURCE_DIR}/shared_memory.ll\"\n\tWORKING_DIRECTORY \"${CMAKE_CURRENT_BINARY_DIR}\")\n\nadd_test(NAME test-cuda-shared-memory-extern_shared_memory\n\tCOMMAND \"${CMAKE_CURRENT_BINARY_DIR}/../ptxgen/ptxgen\" \"${CMAKE_CURRENT_SOURCE_DIR}/extern_shared_memory.ll\"\n\tWORKING_DIRECTORY \"${CMAKE_CURRENT_BINARY_DIR}\")\n\nset_tests_properties(test-cuda-shared-memory-shared_memory\n                     test-cuda-shared-memory-extern_shared_memory\n                     PROPERTIES FIXTURES_REQUIRED PTXGENTEST)\n```\n\n----------------------------------------\n\nTITLE: Conditional Compilation Based on OS and Architecture\nDESCRIPTION: This section conditionally compiles the StreamPriorities sample based on the operating system and architecture. If the system is Linux and not aarch64, an executable target is added. Otherwise, a message is printed indicating that the sample will not be built.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: cmake\nCODE:\n```\nif(CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    # Source file\n    # Add target for StreamPriorities\n    if(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n        message(STATUS \"Will not build sample streamPriorities - not supported on aarch64\")\n    else()\n        add_executable(StreamPriorities StreamPriorities.cu)\n\n        target_compile_options(StreamPriorities PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\n        target_compile_features(StreamPriorities PRIVATE cxx_std_17 cuda_std_17)\n\n        set_target_properties(StreamPriorities PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n    endif()\nelse()\n    message(STATUS \"Will not build sample StreamPriorities - requires Linux OS\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Declaring cudaGetParameterBufferV2 in NVVM IR\nDESCRIPTION: This snippet provides the declaration for cudaGetParameterBufferV2 at the NVVM IR level, necessary for initializing the parameter buffer for device-side kernel launches. The function accepts the kernel pointer, grid and block dimensions, and shared memory size.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/device-side-launch/README.md#2025-04-21_snippet_2\n\nLANGUAGE: NVVM IR\nCODE:\n```\n; NVVM IR level declaration of cudaGetParameterBufferV2\ndeclare i8* @cudaGetParameterBufferV2(i8*, %struct.dim3, %struct.dim3, i32)\n```\n\n----------------------------------------\n\nTITLE: Executing simpleAWBarrier CUDA Sample on Hopper GPU\nDESCRIPTION: This snippet shows the output of running the simpleAWBarrier CUDA sample. It identifies the GPU device, launches a kernel with specific parameters, and reports the execution result.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleAWBarrier.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n./simpleAWBarrier starting...\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nLaunching normVecByDotProductAWBarrier kernel with numBlocks = 228 blockSize = 576\nResult = PASSED\n./simpleAWBarrier completed, returned OK\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up CUDA Resources\nDESCRIPTION: Cleans up CUDA resources by unloading the module, destroying the context, and freeing memory. This ensures proper resource management and prevents memory leaks.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/threadMigration/README.md#2025-04-21_snippet_4\n\nLANGUAGE: CUDA\nCODE:\n```\ncuModuleUnload(module);\ncuCtxDestroy(context);\ncuMemFree(d_data);\n```\n\n----------------------------------------\n\nTITLE: Running Particle Simulation with Custom Particle Count\nDESCRIPTION: Demonstrates how to set a custom number of particles for the simulation using a command-line argument. This allows users to control the scale of the simulation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/particles/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\n-particles=<N>\n```\n\n----------------------------------------\n\nTITLE: Displaying P2P GPU Bandwidth and Latency Test Results\nDESCRIPTION: This snippet shows the output of a CUDA program testing peer-to-peer (P2P) GPU bandwidth and latency. It includes device information, connectivity matrix, bandwidth measurements (unidirectional and bidirectional, with P2P enabled and disabled), and latency measurements for both GPU and CPU operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_p2pBandwidthLatencyTest.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n[P2P (Peer-to-Peer) GPU Bandwidth Latency Test]\nDevice: 0, NVIDIA H100 PCIe, pciBusID: c1, pciDeviceID: 0, pciDomainID:0\n\n***NOTE: In case a device doesn't have P2P access to other one, it falls back to normal memcopy procedure.\nSo you can see lesser Bandwidth (GB/s) and unstable Latency (us) in those cases.\n\nP2P Connectivity Matrix\n     D\\D     0\n     0\t     1\nUnidirectional P2P=Disabled Bandwidth Matrix (GB/s)\n   D\\D     0 \n     0 1628.72 \nUnidirectional P2P=Enabled Bandwidth (P2P Writes) Matrix (GB/s)\n   D\\D     0 \n     0 1625.75 \nBidirectional P2P=Disabled Bandwidth Matrix (GB/s)\n   D\\D     0 \n     0 1668.11 \nBidirectional P2P=Enabled Bandwidth Matrix (GB/s)\n   D\\D     0 \n     0 1668.39 \nP2P=Disabled Latency Matrix (us)\n   GPU     0 \n     0   2.67 \n\n   CPU     0 \n     0   2.04 \nP2P=Enabled Latency (P2P Writes) Matrix (us)\n   GPU     0 \n     0   2.68 \n\n   CPU     0 \n     0   2.02 \n\nNOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.\n```\n\n----------------------------------------\n\nTITLE: Project definition\nDESCRIPTION: This defines the project name and specifies the programming languages used. The project name is set to 'batchCUBLAS', and the languages are specified as CXX.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nproject(batchCUBLAS LANGUAGES CXX)\n```\n\n----------------------------------------\n\nTITLE: Set Target Properties for CUDA Separable Compilation\nDESCRIPTION: This snippet sets the `CUDA_SEPARABLE_COMPILATION` property to `ON` for the `UnifiedMemoryPerf` target. This enables separable compilation for CUDA code, which can improve build times.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_12\n\nLANGUAGE: cmake\nCODE:\n```\nset_target_properties(UnifiedMemoryPerf PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Setting RPATH for libnvvm\nDESCRIPTION: Sets the RPATH to the libnvvm directory, ensuring that the library can be found at runtime. Prints a status message indicating the RPATH being used.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: CMake\nCODE:\n```\n\"# Set the rpath to libnvvm.\nfind_path(LIBNVVM_RPATH lib lib64 PATHS \\\"$ENV{LIBNVVM_HOME}\\\" \\\"${CUDA_HOME}\\\")\nget_filename_component(LIBNVVM_RPATH ${NVVM_LIB} DIRECTORY)\nset(CMAKE_INSTALL_RPATH \\\"${LIBNVVM_RPATH}\\\")\nmessage(STATUS \\\"Using rpath: ${CMAKE_INSTALL_RPATH}\\\")\"\n```\n\n----------------------------------------\n\nTITLE: Target Link Libraries\nDESCRIPTION: This links the 'batchCUBLAS' target with the CUDA cuBLAS and CUDA runtime libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_14\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(batchCUBLAS PRIVATE\n    CUDA::cublas\n    CUDA::cudart\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Build Target for SimpleAssert\nDESCRIPTION: Sets up the executable target with include directories, compiler options, and C++17/CUDA 17 feature requirements. Enables CUDA separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleAssert/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for simpleAssert\nadd_executable(simpleAssert simpleAssert.cu)\n\ntarget_compile_options(simpleAssert PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(simpleAssert PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(simpleAssert PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(cannyEdgeDetectorNPP)\n```\n\n----------------------------------------\n\nTITLE: Configuring Dependencies and Include Directories\nDESCRIPTION: Sets up include directories and handles platform-specific configurations for GLUT. Finds and includes OpenGL and GLUT packages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bilateralFilter/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n\nfind_package(OpenGL)\nfind_package(GLUT)\n```\n\n----------------------------------------\n\nTITLE: Matrix Output on NVIDIA H100 GPU\nDESCRIPTION: Console output showing device information for an NVIDIA H100 PCIe GPU with Hopper architecture, followed by a 4x8 matrix where each element has the value 10. The output demonstrates the execution of a CUDA program across a grid of thread blocks.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simplePrintf.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nDevice 0: \"NVIDIA H100 PCIe\" with Compute 9.0 capability\nprintf() is called. Output:\n\n[0, 0]:\t\tValue is:10\n[0, 1]:\t\tValue is:10\n[0, 2]:\t\tValue is:10\n[0, 3]:\t\tValue is:10\n[0, 4]:\t\tValue is:10\n[0, 5]:\t\tValue is:10\n[0, 6]:\t\tValue is:10\n[0, 7]:\t\tValue is:10\n[1, 0]:\t\tValue is:10\n[1, 1]:\t\tValue is:10\n[1, 2]:\t\tValue is:10\n[1, 3]:\t\tValue is:10\n[1, 4]:\t\tValue is:10\n[1, 5]:\t\tValue is:10\n[1, 6]:\t\tValue is:10\n[1, 7]:\t\tValue is:10\n[2, 0]:\t\tValue is:10\n[2, 1]:\t\tValue is:10\n[2, 2]:\t\tValue is:10\n[2, 3]:\t\tValue is:10\n[2, 4]:\t\tValue is:10\n[2, 5]:\t\tValue is:10\n[2, 6]:\t\tValue is:10\n[2, 7]:\t\tValue is:10\n[3, 0]:\t\tValue is:10\n[3, 1]:\t\tValue is:10\n[3, 2]:\t\tValue is:10\n[3, 3]:\t\tValue is:10\n[3, 4]:\t\tValue is:10\n[3, 5]:\t\tValue is:10\n[3, 6]:\t\tValue is:10\n[3, 7]:\t\tValue is:10\n```\n\n----------------------------------------\n\nTITLE: Copying Data Files for BicubicTexture\nDESCRIPTION: Adds a custom command to copy data files to the output directory after building the target.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bicubicTexture/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET bicubicTexture POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n```\n\n----------------------------------------\n\nTITLE: Finding libNVVM and nvvm.h\nDESCRIPTION: Locates the libNVVM library and nvvm.h header file. Sets the include directory for nvvm.h and prints status messages for the library, header file, and header path.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: CMake\nCODE:\n```\n\"# Find libNVVM and nvvm.h.\n# (Linux: nvvm/lib64, windows: nvvm/lib/x64)\nfind_library(NVVM_LIB nvvm PATHS \\\"${LIBNVVM_HOME}/lib64\\\" \\\"${LIBNVVM_HOME}/lib/x64\\\")\nfind_file(NVVM_H nvvm.h PATH \\\"${LIBNVVM_HOME}/include\\\")\nget_filename_component(NVVM_INCLUDE_DIR ${NVVM_H} DIRECTORY)\ninclude_directories(${NVVM_INCLUDE_DIR})\nmessage(STATUS \\\"Using libnvvm header:      ${NVVM_H}\\\")\nmessage(STATUS \\\"Using libnvvm header path: ${NVVM_INCLUDE_DIR}\\\")\nmessage(STATUS \\\"Using libnvvm library:     ${NVVM_LIB}\\\")\"\n```\n\n----------------------------------------\n\nTITLE: Linking Windows-Specific Libraries\nDESCRIPTION: This code block conditionally links Windows-specific libraries for the 'nbody' target if the WIN32 macro is defined. It links with freeglut.lib and glew64.lib, which are required for graphics on Windows.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_15\n\nLANGUAGE: cmake\nCODE:\n```\nif(WIN32)\n            target_link_libraries(nbody\n                ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n                ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n            )\n        endif()\n```\n\n----------------------------------------\n\nTITLE: CUDA Sample Program Output\nDESCRIPTION: Console output showing the execution of simpleAttributes CUDA sample, displaying GPU device information and processing time.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleAttributes.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n./simpleAttributes Starting...\n\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nProcessing time: 3934.539062 (ms)\n```\n\n----------------------------------------\n\nTITLE: Core CUDA Runtime API Usage\nDESCRIPTION: Essential CUDA Runtime API calls used in the implementation including memory allocation, data transfer, and device synchronization. These functions form the backbone of GPU memory management and execution control.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/scan/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMalloc\ncudaDeviceSynchronize\ncudaMemcpy\ncudaFree\n```\n\n----------------------------------------\n\nTITLE: CUDA Declaration for cudaGetParameterBufferV2\nDESCRIPTION: The CUDA-level declaration of cudaGetParameterBufferV2 maps to its NVVM IR counterpart, facilitating the creation and configuration of a parameter buffer for launching kernels. Parameters include a pointer to the function, grid dimensions, block dimensions, and shared memory size.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/device-side-launch/README.md#2025-04-21_snippet_3\n\nLANGUAGE: C\nCODE:\n```\nextern __device__ __cudart_builtin__ void * CUDARTAPI \ncudaGetParameterBufferV2(void *func, dim3 gridDimension, \n                         dim3 blockDimension,\n                         unsigned int sharedMemSize);\n```\n\n----------------------------------------\n\nTITLE: CUDA Device Query Output\nDESCRIPTION: Terminal output showing detailed specifications of an NVIDIA H100 PCIe GPU including memory capacity, clock speeds, CUDA cores, and various hardware capabilities. The output demonstrates successful device detection and querying using the CUDA Driver API.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_deviceQueryDrv.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n./deviceQueryDrv Starting...\\n\\nCUDA Device Query (Driver API) statically linked version \\nDetected 1 CUDA Capable device(s)\\n\\nDevice 0: \"NVIDIA H100 PCIe\"\\n  CUDA Driver Version:                           12.0\\n  CUDA Capability Major/Minor version number:    9.0\\n  Total amount of global memory:                 81082 MBytes (85021163520 bytes)\\n  (114) Multiprocessors, (128) CUDA Cores/MP:     14592 CUDA Cores\\n  GPU Max Clock rate:                            1650 MHz (1.65 GHz)\\n  Memory Clock rate:                             1593 Mhz\\n  Memory Bus Width:                              5120-bit\\n  L2 Cache Size:                                 52428800 bytes\\n  Max Texture Dimension Sizes                    1D=(131072) 2D=(131072, 65536) 3D=(16384, 16384, 16384)\\n  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\\n  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\\n  Total amount of constant memory:               65536 bytes\\n  Total amount of shared memory per block:       49152 bytes\\n  Total number of registers available per block: 65536\\n  Warp size:                                     32\\n  Maximum number of threads per multiprocessor:  2048\\n  Maximum number of threads per block:           1024\\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\\n  Max dimension size of a grid size (x,y,z):    (2147483647, 65535, 65535)\\n  Texture alignment:                             512 bytes\\n  Maximum memory pitch:                          2147483647 bytes\\n  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\\n  Run time limit on kernels:                     No\\n  Integrated GPU sharing Host Memory:            No\\n  Support host page-locked memory mapping:       Yes\\n  Concurrent kernel execution:                   Yes\\n  Alignment requirement for Surfaces:            Yes\\n  Device has ECC support:                        Enabled\\n  Device supports Unified Addressing (UVA):      Yes\\n  Device supports Managed Memory:                Yes\\n  Device supports Compute Preemption:            Yes\\n  Supports Cooperative Kernel Launch:            Yes\\n  Supports MultiDevice Co-op Kernel Launch:      Yes\\n  Device PCI Domain ID / Bus ID / location ID:   0 / 193 / 0\\n  Compute Mode:\\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\\nResult = PASS\n```\n\n----------------------------------------\n\nTITLE: CUDA Program Output Log\nDESCRIPTION: Program output showing GPU device detection, reporting an NVIDIA H100 PCIe GPU with Hopper architecture (SM 9.0) and successful launch of a CDP kernel for quadtree computation\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_cdpQuadtree.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nGPU device NVIDIA H100 PCIe has compute capabilities (SM 9.0)\nLaunching CDP kernel to build the quadtree\nResults: OK\n```\n\n----------------------------------------\n\nTITLE: Setting Up Windows-Specific DLL Copy in CMake\nDESCRIPTION: Creates a Windows-specific post-build command to copy the required NVVM DLL to the target directory, ensuring runtime dependencies are available.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/uvmlite/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\nif (WIN32)\n  add_custom_command(\n      TARGET uvmlite\n      POST_BUILD\n      COMMAND ${CMAKE_COMMAND} -E copy_if_different\n              \"${CMAKE_BINARY_DIR}/nvvm64_40_0.dll\" \"$<TARGET_FILE_DIR:uvmlite>\"\n  )\nendif ()\n```\n\n----------------------------------------\n\nTITLE: Setting Windows-Specific Include and Library Directories\nDESCRIPTION: These commands set variables for include and library directories specifically for Windows.  They define the paths to GLUT headers and libraries, which are used for creating graphical user interfaces.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: cmake\nCODE:\n```\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Minimum Requirements\nDESCRIPTION: This snippet sets the minimum required version of CMake for the project and appends a custom module path. The project is defined to use C++ as the programming language.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(MersenneTwisterGP11213 LANGUAGES CXX)\n```\n\n----------------------------------------\n\nTITLE: Basic CMake and CUDA Project Setup\nDESCRIPTION: Initializes CMake project with minimum version requirement, sets up module paths, and configures CUDA toolkit requirements.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/jitLto/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(jitLto LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(conjugateGradientMultiBlockCG)\n```\n\n----------------------------------------\n\nTITLE: Linking Libraries to UVMLite in CMake\nDESCRIPTION: Links the NVVM and CUDA libraries to the UVMLite executable, which are required dependencies for its functionality.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/uvmlite/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(uvmlite ${NVVM_LIB} ${CUDA_LIB})\n```\n\n----------------------------------------\n\nTITLE: Setting Compile Options for CUDA\nDESCRIPTION: This sets compile options specific to CUDA.  target_compile_options adds the \"--extended-lambda\" flag when compiling CUDA code.  This flag enables extended lambda support in CUDA, which is a feature that allows for more flexible and expressive code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_compile_options(StreamPriorities PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n```\n\n----------------------------------------\n\nTITLE: Preparing Data for LU Decomposition in CUDA\nDESCRIPTION: This section prepares the data for LU decomposition. It generates random matrices and copies the data from host memory to GPU memory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleCUBLAS_LU.txt#2025-04-21_snippet_2\n\nLANGUAGE: CUDA\nCODE:\n```\n> generating random matrices..\n> copying data from host memory to GPU memory..\n```\n\n----------------------------------------\n\nTITLE: Setting position independent code\nDESCRIPTION: This sets the CMAKE_POSITION_INDEPENDENT_CODE variable to ON.  This enables position-independent code generation, which is generally recommended for shared libraries and can improve security.  It ensures the generated code can be loaded at any memory address.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Add Executable Target\nDESCRIPTION: Adds an executable target named quasirandomGenerator_nvrtc.  Specifies the source files that will be compiled and linked to create the executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(quasirandomGenerator_nvrtc quasirandomGenerator.cpp quasirandomGenerator_gold.cpp)\n```\n\n----------------------------------------\n\nTITLE: Set Target Compile Options\nDESCRIPTION: This snippet sets a compile option for the `UnifiedMemoryPerf` target specifically when compiling CUDA code.  It enables extended lambda support by passing the `--extended-lambda` flag to the CUDA compiler.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_compile_options(UnifiedMemoryPerf PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n```\n\n----------------------------------------\n\nTITLE: CUDA Program Output Log\nDESCRIPTION: Console output showing execution of a CUDA assertion test program on a Hopper GPU. The program intentionally triggers a device-side assertion and captures the expected failure.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleAssert.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nsimpleAssert starting...\nOS_System_Type.release = 5.4.0-131-generic\nOS Info: <#147-Ubuntu SMP Fri Oct 14 17:07:22 UTC 2022>\n\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nLaunch kernel to generate assertion failures\n\n-- Begin assert output\n\n\n-- End assert output\n\nDevice assert failed as expected, CUDA error message is: device-side assert triggered\n\nsimpleAssert completed, returned OK\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Function Calls\nDESCRIPTION: Essential CUDA runtime API functions used in the implementation including memory allocation, synchronization, data transfer, and cleanup operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/sortingNetworks/README.md#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\ncudaMalloc\ncudaDeviceSynchronize\ncudaMemcpy\ncudaFree\n```\n\n----------------------------------------\n\nTITLE: Accessing Managed Variables from Host Code using CUDA Runtime\nDESCRIPTION: Demonstrates how to retrieve a device pointer to a managed variable using cuModuleGetGlobal() and check if a pointer is managed using cuPointerGetAttribute() with the CU_POINTER_ATTRIBUTE_IS_MANAGED flag.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/uvmlite/README.md#2025-04-21_snippet_1\n\nLANGUAGE: C\nCODE:\n```\nCUdeviceptr devp_xxx; // device pointer to xxx\nsize_t      size_xxx; // size of xxx\nresult = cuModuleGetGlobal(&devp_xxx, &size_xxx, hModule, \"xxx\");\n```\n\n----------------------------------------\n\nTITLE: Preparing and Executing CUDA DGEMM Kernel\nDESCRIPTION: This snippet prepares the data for GPU computation, calculates the required shared memory size, and executes a high-performance DGEMM kernel using asynchronous copy. It then reports the execution time and performance in TFLOPS.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_dmmaTensorCoreGemm.txt#2025-04-21_snippet_1\n\nLANGUAGE: CUDA\nCODE:\n```\nPreparing data for GPU...\nRequired shared memory size: 68 Kb\nComputing using high performance kernel = 0 - compute_dgemm_async_copy\nTime: 30.856800 ms\nFP64 TFLOPS: 17.82\n```\n\n----------------------------------------\n\nTITLE: CUDA Task Execution Log\nDESCRIPTION: This snippet displays the execution log of 40 tasks across multiple threads, showing which tasks are executed on the device (GPU) or host (CPU). Each line includes the task number, thread number, and execution location with a timing value.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_UnifiedMemoryStreams.txt#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nExecuting tasks on host / device\nTask [0], thread [0] executing on device (569)\nTask [1], thread [1] executing on device (904)\nTask [2], thread [2] executing on device (529)\nTask [3], thread [3] executing on device (600)\nTask [4], thread [0] executing on device (975)\nTask [5], thread [2] executing on device (995)\nTask [6], thread [1] executing on device (576)\nTask [7], thread [3] executing on device (700)\nTask [8], thread [0] executing on device (716)\nTask [9], thread [2] executing on device (358)\nTask [10], thread [3] executing on device (941)\nTask [11], thread [1] executing on device (403)\nTask [12], thread [0] executing on host (97)\nTask [13], thread [2] executing on device (451)\nTask [14], thread [1] executing on device (789)\nTask [15], thread [0] executing on device (810)\nTask [16], thread [2] executing on device (807)\nTask [17], thread [3] executing on device (756)\nTask [18], thread [0] executing on device (509)\nTask [19], thread [1] executing on device (252)\nTask [20], thread [2] executing on device (515)\nTask [21], thread [3] executing on device (676)\nTask [22], thread [0] executing on device (948)\nTask [23], thread [1] executing on device (944)\nTask [24], thread [3] executing on device (974)\nTask [25], thread [2] executing on device (513)\nTask [26], thread [0] executing on device (207)\nTask [27], thread [1] executing on device (509)\nTask [28], thread [2] executing on device (344)\nTask [29], thread [3] executing on device (198)\nTask [30], thread [0] executing on device (223)\nTask [31], thread [1] executing on device (382)\nTask [32], thread [3] executing on device (980)\nTask [33], thread [2] executing on device (519)\nTask [34], thread [0] executing on host (92)\nTask [35], thread [1] executing on device (677)\nTask [36], thread [2] executing on device (769)\nTask [37], thread [0] executing on device (199)\nTask [38], thread [3] executing on device (845)\nTask [39], thread [0] executing on device (844)\nAll Done!\n```\n\n----------------------------------------\n\nTITLE: Setting Position Independent Code\nDESCRIPTION: This snippet enables position-independent code generation for the project. This is often required for shared libraries and can improve security.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Conditional Debug Flags\nDESCRIPTION: This conditionally sets CUDA flags for debug builds.  The commented out line would enable cuda-gdb, but is noted as expensive.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: CMake\nCODE:\n```\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Subdirectories for Samples\nDESCRIPTION: Adds subdirectories for the various samples in the project, including `cuda-shared-memory`, `device-side-launch`, `simple`, `syscalls`, `ptxgen`, and `uvmlite`.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_12\n\nLANGUAGE: CMake\nCODE:\n```\n\"# Samples\nadd_subdirectory(cuda-shared-memory)\nadd_subdirectory(device-side-launch)\nadd_subdirectory(simple)\nadd_subdirectory(syscalls)\nadd_subdirectory(ptxgen)\nadd_subdirectory(uvmlite)\"\n```\n\n----------------------------------------\n\nTITLE: Including common directories\nDESCRIPTION: This includes a common directory in the build process. The include_directories command adds the specified directory to the compiler's include path.  This allows the compiler to find header files located in that directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Setting up CMake Project with CUDA for nbody_opengles Sample\nDESCRIPTION: Initializes the CMake project for nbody_opengles with C, C++, and CUDA language support. Sets the minimum CMake version requirement and adds custom module paths.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/nbody_opengles/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../../cmake/Modules\")\n\nproject(nbody_opengles LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_15\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(cuSolverSp_LowlevelCholesky)\n```\n\n----------------------------------------\n\nTITLE: Setting up CMake Project for cuDLALayerwiseStatsStandalone CUDA Application\nDESCRIPTION: Initializes the CMake project with C, C++, and CUDA languages, sets the minimum CMake version, and configures paths for custom modules. This establishes the foundation for the build configuration.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLALayerwiseStatsStandalone/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../../cmake/Modules\")\n\nproject(cuDLALayerwiseStatsStandalone LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: CUDA Scan Test Output\nDESCRIPTION: Test output showing scan summation performance for 65536 elements and integral image computation on 1920x1080 synthetic data. Includes timing metrics and validation against CPU results.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_shfl_scan.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nStarting shfl_scan\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n> Detected Compute SM 9.0 hardware with 114 multi-processors\nStarting shfl_scan\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n> Detected Compute SM 9.0 hardware with 114 multi-processors\nComputing Simple Sum test\n---------------------------------------------------\nInitialize test data [1, 1, 1...]\nScan summation for 65536 elements, 256 partial sums\nPartial summing 256 elements with 1 blocks of size 256\nTest Sum: 65536\nTime (ms): 0.021504\n65536 elements scanned in 0.021504 ms -> 3047.619141 MegaElements/s\nCPU verify result diff (GPUvsCPU) = 0\nCPU sum (naive) took 0.017810 ms\n\nComputing Integral Image Test on size 1920 x 1080 synthetic data\n---------------------------------------------------\nMethod: Fast  Time (GPU Timer): 0.008032 ms Diff = 0\nMethod: Vertical Scan  Time (GPU Timer): 0.068576 ms \nCheckSum: 2073600, (expect 1920x1080=2073600)\n```\n\n----------------------------------------\n\nTITLE: Set CUDA Flags\nDESCRIPTION: This sets CUDA compiler flags.  Specifically, it suppresses warnings related to deprecated GPU targets.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n```\n\n----------------------------------------\n\nTITLE: Copying Project Files to Build Directory\nDESCRIPTION: Adds custom commands to copy kernel and header files to the output directory during the build process\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/binomialOptions_nvrtc/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET binomialOptions_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/binomialOptions_kernel.cu ${CMAKE_CURRENT_BINARY_DIR}\n)\n\nadd_custom_command(TARGET binomialOptions_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/common_gpu_header.h ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Finding the CUDA toolkit\nDESCRIPTION: This command uses CMake's find_package command to locate the CUDA toolkit. The REQUIRED keyword ensures that the configuration process fails if the CUDA toolkit is not found, indicating a necessary dependency is missing.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/cudaGraphsPerfScaling/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Test Summary for CUDA Jacobi Solver\nDESCRIPTION: This snippet shows the final test summary, indicating the error amount of the solver. In this case, the error is reported as zero, suggesting a successful convergence.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_conjugateGradient.txt#2025-04-21_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nTest Summary:  Error amount = 0.000000\n```\n\n----------------------------------------\n\nTITLE: Listing CUDA Runtime API Functions Used in cuDLA Error Reporting\nDESCRIPTION: This code block lists the CUDA Runtime API functions used in the cuDLA Error Reporting sample. These functions are essential for stream management, memory operations, device selection, and error handling in CUDA programming.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cuDLAErrorReporting/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncudaStreamCreateWithFlags, cudaStreamDestroy, cudaFree, cudaGetErrorName, cudaSetDevice, cudaStreamSynchronize, cudaMalloc, cudaMemsetAsync, cudaMemcpyAsync\n```\n\n----------------------------------------\n\nTITLE: Displaying CUDA Bandwidth Test Results for NVIDIA H100 PCIe\nDESCRIPTION: This snippet shows the output of a CUDA bandwidth test, including transfer sizes and bandwidth measurements for different memory transfer scenarios using pinned memory on an NVIDIA H100 PCIe GPU.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_bandwidthTest.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n[CUDA Bandwidth Test] - Starting...\nRunning on...\n\n Device 0: NVIDIA H100 PCIe\n Quick Mode\n\n Host to Device Bandwidth, 1 Device(s)\n PINNED Memory Transfers\n   Transfer Size (Bytes)\tBandwidth(GB/s)\n   32000000\t\t\t27.9\n\n Device to Host Bandwidth, 1 Device(s)\n PINNED Memory Transfers\n   Transfer Size (Bytes)\tBandwidth(GB/s)\n   32000000\t\t\t25.0\n\n Device to Device Bandwidth, 1 Device(s)\n PINNED Memory Transfers\n   Transfer Size (Bytes)\tBandwidth(GB/s)\n   32000000\t\t\t1421.4\n\nResult = PASS\n\nNOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.\n```\n\n----------------------------------------\n\nTITLE: CUDA Template Test Output Log\nDESCRIPTION: Console output showing the execution of templated CUDA tests with float and int data types, including device detection, compute capability check, and performance metrics.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleTemplates_nvrtc.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n> runTest<float,32>\n> Using CUDA Device [0]: NVIDIA H100 PCIe\n> Using CUDA Device [0]: NVIDIA H100 PCIe\n> GPU Device has SM 9.0 compute capability\nProcessing time: 0.102000 (ms)\nCompare OK\n\n> runTest<int,64>\nProcessing time: 0.077000 (ms)\nCompare OK\n\n[simpleTemplates_nvrtc] -> Test Results: 0 Failures\n```\n\n----------------------------------------\n\nTITLE: Displaying CUDA Sample Output for Atomic Intrinsics\nDESCRIPTION: This snippet shows the console output of a CUDA sample program that demonstrates atomic intrinsics. It includes the program start, GPU device information, processing time, and completion status.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleAtomicIntrinsics.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nsimpleAtomicIntrinsics starting...\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nProcessing time: 2.438000 (ms)\nsimpleAtomicIntrinsics completed, returned OK\n```\n\n----------------------------------------\n\nTITLE: Conditional Build Based on OpenGL and GLUT\nDESCRIPTION: This snippet conditionally builds the `postProcessGL` target based on whether OpenGL and GLUT are found. If either OpenGL or GLUT is not found, a message is printed to the console indicating that the sample will not be built.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_18\n\nLANGUAGE: CMake\nCODE:\n```\nelse()\n    message(STATUS \"GLUT not found - will not build sample 'postProcessGL'\")\nendif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'postProcessGL'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Windows-Specific NVVM DLL Handling\nDESCRIPTION: On Windows, locates and installs the nvvm.dll file.  It copies the DLL to the binary directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: CMake\nCODE:\n```\n\"# On Windows, locate the nvvm.dll so we can install it.\nif (WIN32)\n  find_file(NVVM_DLL nvvm64_40_0.dll PATHS \\\"${LIBNVVM_HOME}/bin\\\")\n  if (NOT NVVM_DLL)\n    message(FATAL_ERROR \\\"Found nvvm .h/.lib, but not .dll\\\")\n  endif()\n  install(FILES ${NVVM_DLL} DESTINATION bin)\n  file(COPY ${NVVM_DLL} DESTINATION \\\"${CMAKE_BINARY_DIR}\\\")\nendif (WIN32)\"\n```\n\n----------------------------------------\n\nTITLE: Conditional CUDA-C-Linking Sample\nDESCRIPTION: Conditionally includes the `cuda-c-linking` sample if the `ENABLE_CUDA_C_LINKING_SAMPLE` variable is set.  It also checks for the LLVM package.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_11\n\nLANGUAGE: CMake\nCODE:\n```\n\"# If you wish to build the cuda-c-linking sample and have the LLVM dependencies\n# met, then set the ENABLE_CUDA_C_LINKING_SAMPLE variable. This variable can be\n# set locally or by adding \\\"-DENABLE_CUDA_C_LINKING_SAMPLE=1\\\" to your cmake\n# invocation. See the note about \\\"cuda-c-linking\\\" in README.md.\nif (ENABLE_CUDA_C_LINKING_SAMPLE)\n  # Include the LLVM dev package which is required to build cuda-c-linking.\n  find_package(LLVM CONFIG PATHS \\\"$ENV{LLVM_HOME}\\\")\n  if (LLVM_FOUND)\n    add_subdirectory(cuda-c-linking)\n  else ()\n    message(STATUS \\\"Skipping the build of the cuda-c-linking sample: Failed to locate the LLVM package.\\\")\n  endif ()\nelse ()\n  message(STATUS \\\"Skipping the build of the cuda-c-linking sample.\\\")\nendif ()\"\n```\n\n----------------------------------------\n\nTITLE: Include Directories\nDESCRIPTION: Specifies additional include directories for the project. This allows the compiler to find header files located in the specified directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_20\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(lineOfSight)\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA simpleIPC\nDESCRIPTION: Sets up the CMake project for simpleIPC, specifying the required CMake version, project languages, and CUDA Toolkit dependency.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleIPC/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleIPC LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Compile Options for Target\nDESCRIPTION: This snippet sets specific compile options for CUDA code within the target. It uses generator expressions to apply the option only when compiling CUDA code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_options(postProcessGL PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n```\n\n----------------------------------------\n\nTITLE: HyperQ Execution Output Log\nDESCRIPTION: Console output showing GPU device detection and performance timing results comparing serial vs concurrent kernel execution using CUDA HyperQ. Running on a Hopper GPU with compute capability 9.0.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleHyperQ.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nstarting hyperQ...\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n> Detected Compute SM 9.0 hardware with 114 multi-processors\nExpected time for serial execution of 32 sets of kernels is between approx. 0.330s and 0.640s\nExpected time for fully concurrent execution of 32 sets of kernels is approx. 0.020s\nMeasured time for sample = 0.053s\n```\n\n----------------------------------------\n\nTITLE: Setting CMake Minimum Version and Project Configuration\nDESCRIPTION: Initializes the CMake project for binomial options NVRTC, specifying languages and module paths\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/binomialOptions_nvrtc/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(binomialOptions_nvrtc LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Post-Build Data File Copying\nDESCRIPTION: Adds a post-build command to copy data files from the source directory to the build directory, ensuring that the executable has access to necessary data files at runtime.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/randomFog/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET randomFog POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n```\n\n----------------------------------------\n\nTITLE: Unfreed Streams Memory Footprint\nDESCRIPTION: Demonstrates memory footprint behavior with unfreed allocations across multiple graph launches\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_graphMemoryFootprint.txt#2025-04-21_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n00:     FOOTPRINT: 67108864 bytes\n01:     FOOTPRINT: 134217728 bytes\n02:     FOOTPRINT: 201326592 bytes\n03:     FOOTPRINT: 268435456 bytes\n04:     FOOTPRINT: 335544320 bytes\n05:     FOOTPRINT: 402653184 bytes\n06:     FOOTPRINT: 469762048 bytes\n07:     FOOTPRINT: 536870912 bytes\n```\n\n----------------------------------------\n\nTITLE: CUDA Driver API Function\nDESCRIPTION: CUDA Driver API function used for device UUID retrieval.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cudaNvSciNvMedia/README.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\ncuDeviceGetUuid\n```\n\n----------------------------------------\n\nTITLE: CUDA Sample Program Output\nDESCRIPTION: Console output showing the execution results of simplePitchLinearTexture CUDA sample, including device detection and performance metrics comparing pitch linear textures versus arrays.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simplePitchLinearTexture.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nsimplePitchLinearTexture starting...\n\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n\nBandwidth (GB/s) for pitch linear: 1.59e+03; for array: 1.69e+03\n\nTexture fetch rate (Mpix/s) for pitch linear: 1.99e+05; for array: 2.12e+05\n\nsimplePitchLinearTexture completed, returned OK\n```\n\n----------------------------------------\n\nTITLE: CUDA Device Detection Output\nDESCRIPTION: Output showing the detected CUDA device (Hopper) with compute capability 9.0 and driver version 12.0\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_graphMemoryFootprint.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nDriver version is: 12.0\n```\n\n----------------------------------------\n\nTITLE: CUDA Sample Execution Log\nDESCRIPTION: Console output showing the execution of a CUDA sample application, including GPU device detection and completion status.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleSeparateCompilation.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nsimpleSeparateCompilation starting...\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nsimpleSeparateCompilation completed, returned OK\n```\n\n----------------------------------------\n\nTITLE: Finding NvSCI Header Files\nDESCRIPTION: Searches for NvSciBuf and NvSciSync header files in system include paths and user-specified include paths.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cudaNvSciBufMultiplanar/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n    # Find the NVSCI header files\n    # use CMAKE_INCLUDE_PATH so that users can also specify the NVSCI include path in cmake command\n    set(CMAKE_INCLUDE_PATH \"/usr/include\" ${CMAKE_LIBRARY_PATH})\n    find_path(NVSCIBUF_INCLUDE_DIR nvscibuf.h PATHS ${CMAKE_INCLUDE_PATH})\n    find_path(NVSCISYNC_INCLUDE_DIR nvscisync.h PATHS ${CMAKE_INCLUDE_PATH})\n```\n\n----------------------------------------\n\nTITLE: Include Directories\nDESCRIPTION: This specifies the include directories for the project.  It includes a common directory for shared headers.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Set CUDA Flags for Debug Build\nDESCRIPTION: This snippet conditionally adds the `-G` flag to the CUDA compiler flags when the build type is set to \"Debug\". This flag enables CUDA debugging support, but it is commented out as it can be expensive.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: cmake\nCODE:\n```\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Project\nDESCRIPTION: This snippet configures a CMake project for compiling a CUDA sample which involves setting the minimum required CMake version, adding directories to the module path, and defining the project name along with supported languages. It also includes finding the CUDA Toolkit, setting position-independent code, defining CUDA architectures, and handling deprecated GPU targets. When in Debug mode, additional flags for debugging may be enabled.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/tf32TensorCoreGemm/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(tf32TensorCoreGemm LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding an executable target\nDESCRIPTION: This command adds an executable target to the project. It defines the executable's name ('cudaGraphsPerfScaling') and specifies the source file ('cudaGraphPerfScaling.cu') that will be compiled and linked to create the executable.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/cudaGraphsPerfScaling/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: cmake\nCODE:\n```\nadd_executable(cudaGraphsPerfScaling cudaGraphPerfScaling.cu)\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for vectorAddMMAP CUDA Sample\nDESCRIPTION: Sets up the CMake project, specifies required CMake version, and defines project languages. It also finds the CUDA Toolkit package and sets position-independent code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/vectorAddMMAP/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(vectorAddMMAP LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: CUDA Device Detection Output\nDESCRIPTION: Terminal output showing the initialization process of a CUDA application with OpenMP, displaying system CPU count, available CUDA devices, and thread mapping information.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_cudaOpenMP.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n./cudaOpenMP Starting...\n\nnumber of host CPUs:\t32\nnumber of CUDA devices:\t1\n   0: NVIDIA H100 PCIe\n---------------------------\nCPU thread 0 (of 1) uses CUDA device 0\n---------------------------\n```\n\n----------------------------------------\n\nTITLE: Setting position independent code\nDESCRIPTION: This command sets the CMAKE_POSITION_INDEPENDENT_CODE variable to ON. This enables position-independent code generation, which is often required for shared libraries or executables that need to be loaded at different memory addresses.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/cudaGraphsPerfScaling/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Installing GLFW3 and Vulkan on Linux aarch64\nDESCRIPTION: Command for installing GLFW3 on a Linux aarch64 platform using apt-get. The installation typically also includes libvulkan-dev as a dependency. Requires a functioning package manager.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/vulkanImageCUDA/Build_instructions.txt#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nsudo apt-get install libglfw3-dev\n\n```\n\n----------------------------------------\n\nTITLE: Command-line Options for radixSort\nDESCRIPTION: Available command-line options for customizing the radixSort execution, including specifying the number of elements, key type, and sorting mode.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/radixSortThrust/doc/readme.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n-n=<N>        : number of elements to sort\n-keysonly     : sort only an array of keys (the default is to sort key-value pairs)\n-float        : use 32-bit float keys\n-keybits=<B>  : Use only the B least-significant bits of the keys for the sort\n               : B must be a multiple of 4.  This option does not apply to float keys\n-quiet        : Output only the number of elements and the time to sort\n-help         : Output a help message\n```\n\n----------------------------------------\n\nTITLE: CUDA Solver Output Log\nDESCRIPTION: Console output showing the execution steps of the cuSolverRf solver, including matrix properties, solution accuracy, and timing statistics for different solver phases.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_cuSolverRf.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nUsing default input file [../../../../Samples/4_CUDA_Libraries/cuSolverRf/lap2D_5pt_n100.mtx]\nWARNING: cusolverRf only works for base-0 \nsparse matrix A is 10000 x 10000 with 49600 nonzeros, base=0\nstep 1.2: set right hand side vector (b) to 1\nstep 2: reorder the matrix to reduce zero fill-in\n        Q = symrcm(A) or Q = symamd(A) \nstep 3: B = Q*A*Q^T\nstep 4: solve A*x = b by LU(B) in cusolverSp\nstep 4.1: create opaque info structure\nstep 4.2: analyze LU(B) to know structure of Q and R, and upper bound for nnz(L+U)\nstep 4.3: workspace for LU(B)\nstep 4.4: compute Ppivot*B = L*U \nstep 4.5: check if the matrix is singular \nstep 4.6: solve A*x = b \n    i.e.  solve B*(Qx) = Q*b \nstep 4.7: evaluate residual r = b - A*x (result on CPU)\n(CPU) |b - A*x| = 4.547474E-12 \n(CPU) |A| = 8.000000E+00 \n(CPU) |x| = 7.513384E+02 \n(CPU) |b - A*x|/(|A|*|x|) = 7.565621E-16 \nstep 5: extract P, Q, L and U from P*B*Q^T = L*U \n        L has implicit unit diagonal\nnnzL = 671550, nnzU = 681550\nstep 6: form P*A*Q^T = L*U\nstep 6.1: P = Plu*Qreroder\nstep 6.2: Q = Qlu*Qreorder \nstep 7: create cusolverRf handle\nstep 8: set parameters for cusolverRf \nstep 9: assemble P*A*Q = L*U \nstep 10: analyze to extract parallelism \nstep 11: import A to cusolverRf \nstep 12: refactorization \nstep 13: solve A*x = b \nstep 14: evaluate residual r = b - A*x (result on GPU)\n(GPU) |b - A*x| = 4.320100E-12 \n(GPU) |A| = 8.000000E+00 \n(GPU) |x| = 7.513384E+02 \n(GPU) |b - A*x|/(|A|*|x|) = 7.187340E-16 \n===== statistics \n nnz(A) = 49600, nnz(L+U) = 1353100, zero fill-in ratio = 27.280242\n\n===== timing profile \n reorder A   : 0.003304 sec\n B = Q*A*Q^T : 0.000761 sec\n\n cusolverSp LU analysis: 0.000188 sec\n cusolverSp LU factor  : 0.069354 sec\n cusolverSp LU solve   : 0.001780 sec\n cusolverSp LU extract : 0.005654 sec\n\n cusolverRf assemble : 0.002426 sec\n cusolverRf reset    : 0.000021 sec\n cusolverRf refactor : 0.097122 sec\n cusolverRf solve    : 0.123813 sec\n```\n\n----------------------------------------\n\nTITLE: Physical Memory Reuse Memory Footprint\nDESCRIPTION: Demonstrates memory footprint changes during physical memory reuse across multiple graph executions in the same stream\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_graphMemoryFootprint.txt#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n    FOOTPRINT: 0 bytes\n    FOOTPRINT: 67108864 bytes\n01:     FOOTPRINT: 67108864 bytes\n02:     FOOTPRINT: 67108864 bytes\n03:     FOOTPRINT: 67108864 bytes\n04:     FOOTPRINT: 67108864 bytes\n05:     FOOTPRINT: 67108864 bytes\n06:     FOOTPRINT: 67108864 bytes\n07:     FOOTPRINT: 67108864 bytes\n```\n\n----------------------------------------\n\nTITLE: Building with Vulkan SDK Path on Linux aarch64\nDESCRIPTION: Compilation command specifying explicit path to Vulkan SDK during build process\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkanMMAP/Build_instructions.txt#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmake VULKAN_SDK_PATH=<PATH_TO_VULKAN_SDK>\n```\n\n----------------------------------------\n\nTITLE: Configuring Windows-Specific Include and Library Paths\nDESCRIPTION: Sets platform-specific paths for GLUT includes and libraries when building on Windows systems. Points to Common directory and lib/x64 subdirectory for required dependencies.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/randomFog/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    set(PC_GLUT_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common\")\n    set(PC_GLUT_LIBRARY_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/../../../Common/lib/x64\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(conjugateGradientPrecond)\n```\n\n----------------------------------------\n\nTITLE: Set Minimum CMake Version\nDESCRIPTION: This snippet sets the minimum required CMake version for the project. It ensures that the CMake version used to build the project is at least 3.20 or higher.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n```\n\n----------------------------------------\n\nTITLE: Appending CMake module path\nDESCRIPTION: This command appends a path to the CMAKE_MODULE_PATH variable, allowing CMake to find custom modules in the specified directory. This is useful for including project-specific CMake modules.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: Setting Minimum CMake Version and Preparing Project\nDESCRIPTION: This snippet sets the minimum required CMake version, appends the module path, specifies project languages, and finds the required CUDA Toolkit. It ensures proper compatibility for building a CUDA project for D3D11 texture rendering.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleD3D11Texture/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleD3D11Texture LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Compile Features\nDESCRIPTION: This snippet specifies the required C++ and CUDA standards for the target 'fastWalshTransform', enforcing use of C++17 and CUDA17 features.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fastWalshTransform/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_features(fastWalshTransform PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: CUDA Sample Program Output Log\nDESCRIPTION: Console output showing GPU device detection (Hopper GPU), CUDA module loading from fatbin file, and successful execution result\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleDrvRuntime.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n> findModulePath found file at <./vectorAdd_kernel64.fatbin>\n> initCUDA loading module: <./vectorAdd_kernel64.fatbin>\nResult = PASS\n```\n\n----------------------------------------\n\nTITLE: Adding Post-Build Command for GLSL Shader Files\nDESCRIPTION: Sets up a post-build command to copy the required GLSL shader files (vertex and fragment shaders) to the output directory. These shaders are needed by the application at runtime for rendering the fluid simulation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/fluidsGLES/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET fluidsGLES POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/mesh.frag.glsl\n    ${CMAKE_CURRENT_SOURCE_DIR}/mesh.vert.glsl\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Project definition with CUDA support\nDESCRIPTION: This command defines the CMake project named StreamPriorities and specifies that it uses C, C++, and CUDA languages.  It sets up the project to be built using these languages. The CUDA language support is essential for building CUDA-based applications.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nproject(StreamPriorities LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Installing GLFW3 on Ubuntu with APT\nDESCRIPTION: This snippet covers the commands to install the GLFW3 library and its development files on Ubuntu using APT. It includes dependencies required for GLFW3 operation, ensuring a proper setup for Vulkan development.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/Build_instructions.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get install libglfw3\nsudo apt-get install libglfw3-dev\nsudo apt-get install libxcb1-dev\nsudo apt-get install xorg-dev\n```\n\n----------------------------------------\n\nTITLE: CUDA dwtHaar1D Sample Output Log\nDESCRIPTION: Console output showing GPU device detection, file paths for input/output, and execution status of the dwtHaar1D CUDA sample program. Shows successful test completion on a Hopper GPU with compute capability 9.0.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_dwtHaar1D.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n./dwtHaar1D Starting...\n\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nsource file    = \"../../../../Samples/5_Domain_Specific/dwtHaar1D/data/signal.dat\"\nreference file = \"result.dat\"\ngold file      = \"../../../../Samples/5_Domain_Specific/dwtHaar1D/data/regression.gold.dat\"\nReading signal from \"../../../../Samples/5_Domain_Specific/dwtHaar1D/data/signal.dat\"\nWriting result to \"result.dat\"\nReading reference result from \"../../../../Samples/5_Domain_Specific/dwtHaar1D/data/regression.gold.dat\"\nTest success!\n```\n\n----------------------------------------\n\nTITLE: Console Output from CUDA Surface Write Sample\nDESCRIPTION: Console output showing execution results including GPU device detection (Hopper H100), image loading (teapot512.pgm), processing performance metrics (16384 Mpixels/sec), and output verification.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleSurfaceWrite.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nsimpleSurfaceWrite starting...\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nCUDA device [NVIDIA H100 PCIe] has 114 Multi-Processors, SM 9.0\nLoaded 'teapot512.pgm', 512 x 512 pixels\nProcessing time: 0.016000 (ms)\n16384.00 Mpixels/sec\nWrote 'output.pgm'\nComparing files\n\toutput:    <output.pgm>\n\treference: <../../../../Samples/0_Introduction/simpleSurfaceWrite/data/ref_rotated.pgm>\nsimpleSurfaceWrite completed, returned OK\n```\n\n----------------------------------------\n\nTITLE: Performing GPU Column Convolution in CUDA\nDESCRIPTION: This code executes column convolution on the GPU using CUDA. It runs multiple iterations and calculates the average execution time and performance in Mpix/s.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_convolutionTexture.txt#2025-04-21_snippet_3\n\nLANGUAGE: CUDA\nCODE:\n```\nRunning GPU columns convolution (10 iterations)\nAverage convolutionColumnsGPU() time: 0.116000 msecs; //40677.518412 Mpix/s\n```\n\n----------------------------------------\n\nTITLE: Installing GLFW3 on Ubuntu Linux\nDESCRIPTION: Command sequence to install GLFW3 library and its development dependencies on Ubuntu Linux systems\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkanMMAP/Build_instructions.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get install libglfw3\nsudo apt-get install libglfw3-dev\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Sample Subdirectories in CMake\nDESCRIPTION: This CMake snippet adds subdirectories for various CUDA sample projects. It includes directories for bandwidth testing, device querying (both runtime and driver API versions), and topology querying. These subdirectories likely contain the source code and build configurations for each respective CUDA sample.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(bandwidthTest)\nadd_subdirectory(deviceQuery)\nadd_subdirectory(deviceQueryDrv)\nadd_subdirectory(topologyQuery)\n```\n\n----------------------------------------\n\nTITLE: Setting minimum CMake version\nDESCRIPTION: This sets the minimum required version of CMake to 3.20.  This ensures that the CMake build system has the necessary features to process the file correctly.  Older CMake versions might not be compatible.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_30\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(simpleCUFFT_2d_MGPU)\n```\n\n----------------------------------------\n\nTITLE: Setting Target Compile Features\nDESCRIPTION: This command sets the compile features for the 'stereoDisparity' target.  It specifies that C++17 and CUDA 17 standards are required.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_9\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_features(stereoDisparity PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: Configuring PTX Generator Executable and Test in CMake\nDESCRIPTION: Creates a ptxgen executable from ptxgen.c, sets up a test that runs the generator on a test.ll file, and links it with NVVM libraries. Includes platform-specific compiler and linker flags for Windows and non-Windows environments.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/ptxgen/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(ptxgen ptxgen.c)\n\nadd_test(NAME ptxgenTest\n   COMMAND ptxgen \"${CMAKE_CURRENT_SOURCE_DIR}/test.ll\"\n   WORKING_DIRECTORY \"${CMAKE_CURRENT_BINARY_DIR}\")\nset_tests_properties(ptxgenTest PROPERTIES FIXTURES_SETUP PTXGENTEST)\n\ntarget_link_libraries(ptxgen ${NVVM_LIB})\n\nif (WIN32)\n  set_target_properties(ptxgen PROPERTIES\n                        COMPILE_FLAGS \"/wd4996 -DLIBNVVM_HOME=\\\"${LIBNVVM_HOME}\\\"\")\nelse (WIN32)\n  set_target_properties(ptxgen PROPERTIES\n                        COMPILE_FLAGS \"-DLIBNVVM_HOME=\\\"${LIBNVVM_HOME}\\\"\"\n                        LINK_FLAGS    \"-Wl,-rpath,${LIBNVVM_RPATH}\")\nendif (WIN32)\n\ninstall(TARGETS ptxgen DESTINATION bin)\n```\n\n----------------------------------------\n\nTITLE: CUDA Process Output Log\nDESCRIPTION: Log output showing execution steps of a CUDA process including device initialization, step execution, verification and completion. The process runs on device 0.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleIPC.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nProcess 0: Starting on device 0...\nStep 0 done\nProcess 0: verifying...\nProcess 0 complete!\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Monte Carlo Project with CMake\nDESCRIPTION: Complete CMake configuration that sets up a CUDA project for Monte Carlo simulation. Configures multiple CUDA architectures, compiler flags, and includes required dependencies. Builds an executable from multiple source files including CUDA and C++ code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(MC_SingleAsianOptionP LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for MC_SingleAsianOptionP\nadd_executable(MC_SingleAsianOptionP src/main.cpp src/pricingengine.cu src/test.cpp)\n\ntarget_compile_options(MC_SingleAsianOptionP PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(MC_SingleAsianOptionP PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(MC_SingleAsianOptionP PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n\ntarget_include_directories(MC_SingleAsianOptionP PUBLIC\n    ${CMAKE_CURRENT_SOURCE_DIR}/inc\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Post-Build Steps and Clean Files\nDESCRIPTION: Adds a post-build command to copy a YUV sample image to the build directory and configures additional files to be removed during clean operations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/8_Platform_Specific/Tegra/cudaNvSciBufMultiplanar/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\n        # Copy yuv_planar_img1.yuv to the output directory\n        add_custom_command(TARGET cudaNvSciBufMultiplanar POST_BUILD\n            COMMAND ${CMAKE_COMMAND} -E copy_if_different\n            ${CMAKE_CURRENT_SOURCE_DIR}/yuv_planar_img1.yuv ${CMAKE_CURRENT_BINARY_DIR}/yuv_planar_img1.yuv\n        )\n        # Specify additional clean files\n        set_target_properties(cudaNvSciBufMultiplanar PROPERTIES\n            ADDITIONAL_CLEAN_FILES \"image_out.yuv\"\n        )\n```\n\n----------------------------------------\n\nTITLE: Compiling Vulkan Shaders with glslc\nDESCRIPTION: Shader compilation commands using glslc compiler from Vulkan SDK for vertex and fragment shaders\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkanMMAP/Build_instructions.txt#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nglslc montecarlo.vert -o vert.spv\nglslc montecarlo.frag -o frag.spv\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_23\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(nvJPEG_encoder)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_13\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(cuSolverRf)\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Command (Post Build)\nDESCRIPTION: This command adds a custom command to be executed after the target 'stereoDisparity' is built. It copies the 'data' directory from the source directory to the binary directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_11\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET stereoDisparity POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for simpleTextureDrv CUDA Sample\nDESCRIPTION: Sets up the CMake project, defines the minimum CMake version, adds module paths, and configures the project languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTextureDrv/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(simpleTextureDrv LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Architecture and Compilation Settings\nDESCRIPTION: Defines CUDA architecture targets and compilation flags including position independent code and debug settings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/sortingNetworks/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Logging CUDA Process Progress\nDESCRIPTION: Captures the sequential steps of a CUDA processing workflow, showing step completion and process verification\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_streamOrderedAllocationIPC.txt#2025-04-21_snippet_0\n\nLANGUAGE: log\nCODE:\n```\nStep 0 done\\nProcess 0: verifying...\\nProcess 0 complete!\n```\n\n----------------------------------------\n\nTITLE: Copying Data Files for CUDA Sample Project\nDESCRIPTION: Adds custom commands to copy data files (lap2D_5pt_n100.mtx and lap3D_7pt_n20.mtx) to the output directory after building the cuSolverSp_LowlevelCholesky target.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\n# Copy data files to output directory\nadd_custom_command(TARGET cuSolverSp_LowlevelCholesky POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/lap2D_5pt_n100.mtx\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET cuSolverSp_LowlevelCholesky POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/lap3D_7pt_n20.mtx\n    ${CMAKE_CURRENT_BINARY_DIR}\n)\n```\n\n----------------------------------------\n\nTITLE: Setting up CMake project for CUDA Matrix Multiplication Driver\nDESCRIPTION: Initializes a CMake project with CUDA language support, setting minimum CMake version and establishing project languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/matrixMulDrv/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(matrixMulDrv LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_22\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(nvJPEG)\n```\n\n----------------------------------------\n\nTITLE: FDTD3D Program Output Log\nDESCRIPTION: Terminal output showing the execution flow of an FDTD3D simulation comparing CPU and GPU implementations. Demonstrates device detection, memory allocation, and parallel computation setup with a Hopper GPU.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_FDTD3d.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n./FDTD3d Starting...\n\nSet-up, based upon target device GMEM size...\n getTargetDeviceGlobalMemSize\n cudaGetDeviceCount\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n cudaGetDeviceProperties\n generateRandomData\n\nFDTD on 376 x 376 x 376 volume with symmetric filter radius 4 for 5 timesteps...\n\nfdtdReference...\n calloc intermediate\n Host FDTD loop\n\tt = 0\n\tt = 1\n\tt = 2\n\tt = 3\n\tt = 4\n\nfdtdReference complete\nfdtdGPU...\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n set block size to 32x16\n set grid size to 12x24\n GPU FDTD loop\n\tt = 0 launch kernel\n\tt = 1 launch kernel\n\tt = 2 launch kernel\n\tt = 3 launch kernel\n\tt = 4 launch kernel\n\nfdtdGPU complete\n\nCompareData (tolerance 0.000100)...\n```\n\n----------------------------------------\n\nTITLE: Append to CMake module path\nDESCRIPTION: This appends a custom module path to the CMake module search path. This allows CMake to find custom modules located in the specified directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: Setting target compile options\nDESCRIPTION: This command sets compile options for the specified target. In this case, it adds the '--extended-lambda' option specifically when compiling CUDA code. This option enables support for extended lambda expressions in CUDA code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/cudaGraphsPerfScaling/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_compile_options(cudaGraphsPerfScaling PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n```\n\n----------------------------------------\n\nTITLE: Virtual Address Reuse Memory Footprint\nDESCRIPTION: Shows memory footprint output for virtual address reuse scenario where sequential allocations and frees within a single graph allow CUDA to reuse virtual addresses\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_graphMemoryFootprint.txt#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n    FOOTPRINT: 67108864 bytes\n    FOOTPRINT: 0 bytes\n```\n\n----------------------------------------\n\nTITLE: Target Compile Features\nDESCRIPTION: This enables C++17 and CUDA 17 language standards for the 'batchCUBLAS' target.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_11\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_features(batchCUBLAS PRIVATE cxx_std_17 cuda_std_17)\n```\n\n----------------------------------------\n\nTITLE: Finding Required Packages\nDESCRIPTION: This command searches for the CUDA Toolkit package as a project dependency, ensuring that the necessary libraries are available for compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fastWalshTransform/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(conjugateGradientUM)\n```\n\n----------------------------------------\n\nTITLE: Displaying CUDA Sample Program Output\nDESCRIPTION: This snippet shows the output of a CUDA program running on a GPU. It includes device information, execution details, and computation results.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_binaryPartitionCG.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n\nLaunching 228 blocks with 1024 threads...\n\nArray size = 102400 Num of Odds = 50945 Sum of Odds = 1272565 Sum of Evens 1233938\n\n...Done.\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_29\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(simpleCUFFT)\n```\n\n----------------------------------------\n\nTITLE: Setting CUDA Architectures\nDESCRIPTION: This command sets the CMAKE_CUDA_ARCHITECTURES variable to a list of CUDA architectures. This specifies which architectures the CUDA code should be compiled for. It also sets a flag to suppress deprecated GPU target warnings.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Generating CUDA Fatbin File\nDESCRIPTION: Sets up custom commands to generate a CUDA fatbin file from the kernel source. It creates a custom target for fatbin generation and ensures the main target depends on it.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/vectorAddMMAP/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nset(CUDA_FATBIN_FILE \"${CMAKE_CURRENT_BINARY_DIR}/vectorAdd_kernel64.fatbin\")\nset(CUDA_KERNEL_SOURCE \"${CMAKE_CURRENT_SOURCE_DIR}/vectorAdd_kernel.cu\")\n\nadd_custom_command(\n    OUTPUT ${CUDA_FATBIN_FILE}\n    COMMAND ${CMAKE_CUDA_COMPILER} ${INCLUDES} ${ALL_CCFLAGS} -Wno-deprecated-gpu-targets  ${GENCODE_FLAGS} -o ${CUDA_FATBIN_FILE} -fatbin ${CUDA_KERNEL_SOURCE}\n    DEPENDS ${CUDA_KERNEL_SOURCE}\n    COMMENT \"Building CUDA fatbin: ${CUDA_FATBIN_FILE}\"\n)\n\n# Create a dummy target for fatbin generation\nadd_custom_target(generate_fatbin_vectorAddMMAP ALL DEPENDS ${CUDA_FATBIN_FILE})\n\n# Ensure matrixMulDrv depends on the fatbin\nadd_dependencies(vectorAddMMAP generate_fatbin_vectorAddMMAP)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(MersenneTwisterGP11213)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(FilterBorderControlNPP)\n```\n\n----------------------------------------\n\nTITLE: Appending to CMake Module Path\nDESCRIPTION: This code appends a path to the CMAKE_MODULE_PATH variable, which allows CMake to find custom modules in the specified directory. The path points to a directory containing CMake modules relative to the current source directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Graph Memory Nodes Sample\nDESCRIPTION: This CMake script sets up the build environment for a CUDA sample project. It specifies the minimum CMake version, project languages, required CUDA toolkit, and various CUDA compilation flags. The script also defines the build target and its properties.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/graphMemoryNodes/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(graphMemoryNodes LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n\n# Source file\n# Add target for graphMemoryNodes\nadd_executable(graphMemoryNodes graphMemoryNodes.cu)\n\ntarget_compile_options(graphMemoryNodes PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(graphMemoryNodes PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(graphMemoryNodes PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_32\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(simpleCUFFT_callback)\n```\n\n----------------------------------------\n\nTITLE: Target Compile Options\nDESCRIPTION: This sets compile options for the 'batchCUBLAS' target specifically for CUDA language files. It enables extended lambda support.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_options(batchCUBLAS PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n```\n\n----------------------------------------\n\nTITLE: Adding Subdirectory: LargeKernelParameter\nDESCRIPTION: This line adds the 'LargeKernelParameter' directory as a subdirectory to the current CMake project. This allows CMake to process the CMakeLists.txt file within that subdirectory and include its targets in the overall build.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(LargeKernelParameter)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_16\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(cuSolverSp_LowlevelQR)\n```\n\n----------------------------------------\n\nTITLE: Append to CMake Module Path\nDESCRIPTION: This snippet appends a directory containing custom CMake modules to the `CMAKE_MODULE_PATH` variable. This allows CMake to find custom modules in the specified directory during the configuration process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/UnifiedMemoryPerf/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_11\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(cudaNvSci)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for CUDA Bezier Tessellation Project\nDESCRIPTION: This CMake snippet sets up the project, finds the CUDA toolkit, and configures CUDA architecture settings based on the system processor. It also sets compiler flags and includes necessary directories.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/cdpBezierTessellation/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(cdpBezierTessellation LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nif(CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\")\n    # Need to differentiate Tegra_aarch64 and other aarch64 systems(sbsa_aarch64) as they have different CUDA_ARCHITECTURES list\n    if(${BUILD_TEGRA})\n        set(CMAKE_CUDA_ARCHITECTURES 72 87 101)\n    else()\n        set(CMAKE_CUDA_ARCHITECTURES 61 70 75 80 86 90)\n    endif()\nelse()\n    set(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 75 80 86 89 90 100 101 120)\nendif()\n\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Executing cuSolverSp QR Decomposition and Linear System Solving in CUDA\nDESCRIPTION: This code snippet demonstrates the process of reading a sparse matrix, performing QR decomposition, and solving a linear system using NVIDIA's cuSolverSp library. It includes both CPU and GPU implementations for comparison. The code reads a matrix market format file, creates necessary data structures, analyzes the matrix, computes the decomposition, and solves the system, finally evaluating the residual error.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_cuSolverSp_LowlevelQR.txt#2025-04-21_snippet_0\n\nLANGUAGE: cuda\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nUsing default input file [../../../../Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/lap2D_5pt_n32.mtx]\nstep 1: read matrix market format\nsparse matrix A is 1024 x 1024 with 3008 nonzeros, base=1\nstep 2: create opaque info structure\nstep 3: analyze qr(A) to know structure of L\nstep 4: workspace for qr(A)\nstep 5: compute A = L*L^T \nstep 6: check if the matrix is singular \nstep 7: solve A*x = b \nstep 8: evaluate residual r = b - A*x (result on CPU)\n(CPU) |b - A*x| = 5.329071E-15 \n(CPU) |A| = 6.000000E+00 \n(CPU) |x| = 5.000000E-01 \n(CPU) |b - A*x|/(|A|*|x|) = 1.776357E-15 \nstep 9: create opaque info structure\nstep 10: analyze qr(A) to know structure of L\nstep 11: workspace for qr(A)\nGPU buffer size = 3751424 bytes\nstep 12: compute A = L*L^T \nstep 13: check if the matrix is singular \nstep 14: solve A*x = b \n(GPU) |b - A*x| = 4.218847E-15 \n(GPU) |b - A*x|/(|A|*|x|) = 1.406282E-15\n```\n\n----------------------------------------\n\nTITLE: Configuring Windows-Specific Libraries for Box Filter\nDESCRIPTION: Sets up additional library links and DLL copying for Windows builds of the boxFilter project.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/boxFilter/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    target_link_libraries(boxFilter\n        ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n        ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n    )\n\n    add_custom_command(TARGET boxFilter\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy \n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\n\n    add_custom_command(TARGET boxFilter\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Executing Optical Flow Computation on CPU and GPU using CUDA\nDESCRIPTION: This code snippet demonstrates the execution of optical flow computation on both CPU and GPU. It likely involves parallel processing on the GPU using CUDA to accelerate the computation compared to the CPU version.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_HSOpticalFlow.txt#2025-04-21_snippet_1\n\nLANGUAGE: C++\nCODE:\n```\nComputing optical flow on CPU...\nComputing optical flow on GPU...\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_19\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(jitLto)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_26\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(simpleCUBLAS)\n```\n\n----------------------------------------\n\nTITLE: Including Common Directories\nDESCRIPTION: This snippet adds a common include directory to the project. This allows the project to find header files located in the specified directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/postProcessGL/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_14\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(cuSolverSp_LinearSolver)\n```\n\n----------------------------------------\n\nTITLE: CUDA Kernel Execution Log with Function Overloading\nDESCRIPTION: Console output showing execution results of three overloaded CUDA kernel functions with different parameter types. Each execution shows memory allocation details, thread limits, register usage, and PTX/Binary versions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_cppOverload.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nC++ Function Overloading starting...\nDevice Count: 1\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nShared Size:   1024\nConstant Size: 0\nLocal Size:    0\nMax Threads Per Block: 1024\nNumber of Registers: 12\nPTX Version: 90\nBinary Version: 90\nsimple_kernel(const int *pIn, int *pOut, int a) PASSED\n\nShared Size:   2048\nConstant Size: 0\nLocal Size:    0\nMax Threads Per Block: 1024\nNumber of Registers: 14\nPTX Version: 90\nBinary Version: 90\nsimple_kernel(const int2 *pIn, int *pOut, int a) PASSED\n\nShared Size:   2048\nConstant Size: 0\nLocal Size:    0\nMax Threads Per Block: 1024\nNumber of Registers: 14\nPTX Version: 90\nBinary Version: 90\nsimple_kernel(const int *pIn1, const int *pIn2, int *pOut, int a) PASSED\n```\n\n----------------------------------------\n\nTITLE: Displaying GPU Device Information and Computation Results\nDESCRIPTION: This snippet shows the output of a CUDA program, including GPU device information and iterative computation results. It demonstrates the GPU's compute capability and the convergence of a numerical algorithm.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_conjugateGradientCudaGraphs.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\n> GPU device has 114 Multi-Processors, SM 9.0 compute capabilities\n\niteration =   1, residual = 4.449882e+01\niteration =   2, residual = 3.245218e+00\niteration =   3, residual = 2.690220e-01\niteration =   4, residual = 2.307639e-02\niteration =   5, residual = 1.993140e-03\niteration =   6, residual = 1.846193e-04\niteration =   7, residual = 1.693379e-05\niteration =   8, residual = 1.600115e-06\nTest Summary:  Error amount = 0.000000\n```\n\n----------------------------------------\n\nTITLE: Adding Executable Target\nDESCRIPTION: This command adds an executable target named 'stereoDisparity', built from the source file 'stereoDisparity.cu'. This defines how the executable is created from the source code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_7\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(stereoDisparity stereoDisparity.cu)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_25\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(randomFog)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_28\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(simpleCUBLAS_LU)\n```\n\n----------------------------------------\n\nTITLE: CUDA Toolkit Search Initialization\nDESCRIPTION: Initializes the CUDA Toolkit search using the `CUDA_HOME` environment variable if it is defined. It differentiates between CMake versions before and after 3.18 due to the introduction of `FindCUDAToolkit`.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n\"if (DEFINED ENV{CUDA_HOME})\n  if (${CMAKE_VERSION} VERSION_LESS 3.18.0)\n    set(CUDA_TOOLKIT_ROOT_DIR  \\\"$ENV{CUDA_HOME}\\\" CACHE PATH \\\"Path to CUDA Toolkit.\\\")\n  else ()  # cmake 3.17 introduced FindCUDAToolkit\n    set(CUDAToolkit_ROOT \\\"$ENV{CUDA_HOME}\\\" CACHE PATH \\\"Path to CUDA Toolkit.\\\")\n  endif ()\nendif ()\"\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_31\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(simpleCUFFT_MGPU)\n```\n\n----------------------------------------\n\nTITLE: Execution Output for CUDA Bezier Line Computation\nDESCRIPTION: Execution log showing program running on an NVIDIA H100 PCIe GPU (GPU 0) and completing Bezier line calculations using CUDA Dynamic Parallelism.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_cdpBezierTessellation.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nRunning on GPU 0 (NVIDIA H100 PCIe)\nComputing Bezier Lines (CUDA Dynamic Parallelism Version) ... Done!\n```\n\n----------------------------------------\n\nTITLE: Configuring UVMLite Build Environment in CMake\nDESCRIPTION: Sets up the build environment for UVMLite by configuring installation paths, RPATH settings, and defining compiler definitions for the source file.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/uvmlite/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nset(CMAKE_INSTALL_RPATH ${LIBNVVM_HOME})\nset(CMAKE_INCLUDE_CURRENT_DIR YES)\nset_property(SOURCE uvmlite.c\n             PROPERTY COMPILE_DEFINITIONS LIBCUDADEVRT=\"${CUDADEVRT_LIB}\")\n```\n\n----------------------------------------\n\nTITLE: Copying GPU Row Convolution Output to Texture in CUDA\nDESCRIPTION: This snippet copies the output of the GPU row convolution back to a texture. It measures the time taken for the memory copy operation and calculates the performance.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_convolutionTexture.txt#2025-04-21_snippet_2\n\nLANGUAGE: CUDA\nCODE:\n```\nCopying convolutionRowGPU() output back to the texture...\ncudaMemcpyToArray() time: 0.067000 msecs; //70426.744514 Mpix/s\n```\n\n----------------------------------------\n\nTITLE: Including Check Include File\nDESCRIPTION: This command includes the CheckIncludeFile module, which provides a macro for checking if a header file exists.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/simpleVulkan/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: cmake\nCODE:\n```\ninclude(CheckIncludeFile)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_33\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(watershedSegmentationNPP)\n```\n\n----------------------------------------\n\nTITLE: Iterative Convergence Output for CUDA Jacobi Solver\nDESCRIPTION: This snippet displays the output of the Jacobi solver iterations, showing the convergence of the residual over 8 iterations. It demonstrates the rapid decrease in the residual value.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_conjugateGradient.txt#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\niteration =   1, residual = 4.449882e+01\niteration =   2, residual = 3.245218e+00\niteration =   3, residual = 2.690220e-01\niteration =   4, residual = 2.307639e-02\niteration =   5, residual = 1.993140e-03\niteration =   6, residual = 1.846193e-04\niteration =   7, residual = 1.693379e-05\niteration =   8, residual = 1.600115e-06\n```\n\n----------------------------------------\n\nTITLE: Copying Data Files to Build Directory\nDESCRIPTION: Creates post-build commands to copy required data files (teapot512.pgm and ref_rotated.pgm) to the output directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/0_Introduction/simpleTexture/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\n# Copy data files to output directory\nadd_custom_command(TARGET simpleTexture POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/teapot512.pgm\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n\n# Copy data files to output directory\nadd_custom_command(TARGET simpleTexture POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/ref_rotated.pgm\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_8\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(conjugateGradientMultiDeviceCG)\n```\n\n----------------------------------------\n\nTITLE: CUDA Line of Sight Sample Output\nDESCRIPTION: Terminal output showing execution of line of sight CUDA sample on an NVIDIA Hopper GPU with compute capability 9.0. Reports average execution time of 0.020620 ms with successful test completion.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_lineOfSight.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n[./lineOfSight] - Starting...\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nLine of sight\nAverage time: 0.020620 ms\n\nTest passed\n```\n\n----------------------------------------\n\nTITLE: Set Minimum CMake Version\nDESCRIPTION: Specifies the minimum required CMake version for the project.  This ensures that the CMake version used to build the project is compatible with the commands and features used in the CMakeLists.txt file.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n```\n\n----------------------------------------\n\nTITLE: Defining Executable Target with C++ and CUDA Source Files\nDESCRIPTION: Creates the executable target for the Monte Carlo Pi estimation application, specifying the source files including main.cpp, piestimator.cu and test.cpp.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\n# Source file\n# Add target for MC_EstimatePiInlineQ\nadd_executable(MC_EstimatePiInlineQ src/main.cpp src/piestimator.cu src/test.cpp)\n```\n\n----------------------------------------\n\nTITLE: Adding Subdirectory: cudaGraphsPerfScaling\nDESCRIPTION: This line adds the 'cudaGraphsPerfScaling' directory as a subdirectory to the current CMake project. CMake processes the CMakeLists.txt in that directory to include its targets for the overall build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(cudaGraphsPerfScaling)\n```\n\n----------------------------------------\n\nTITLE: Displaying CUDA Device Information\nDESCRIPTION: This snippet shows the detected CUDA-capable GPU, identifying it as a \"Hopper\" device with compute capability 9.0.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_UnifiedMemoryStreams.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n```\n\n----------------------------------------\n\nTITLE: Copying Project Data Files\nDESCRIPTION: Adds a post-build custom command to copy project data directory to the binary output directory\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/dxtc/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nadd_custom_command(TARGET dxtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n    ${CMAKE_CURRENT_SOURCE_DIR}/data\n    ${CMAKE_CURRENT_BINARY_DIR}/data\n)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_27\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(simpleCUBLASXT)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Data File Copy Commands\nDESCRIPTION: Configures post-build commands to copy required PPM data files to the binary output directory for testing and reference purposes.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nadd_custom_command(TARGET segmentationTreeThrust POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/test.ppm\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n\nadd_custom_command(TARGET segmentationTreeThrust POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/ref_00.ppm\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n\nadd_custom_command(TARGET segmentationTreeThrust POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/data/ref_09.ppm\n    ${CMAKE_CURRENT_BINARY_DIR}/\n)\n```\n\n----------------------------------------\n\nTITLE: Copying Source Files - CMake\nDESCRIPTION: This snippet copies shared memory related source files into the current binary directory before executing tests, thus ensuring that the necessary input files are available during the test execution phase. It eliminates the need for additional file path configurations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/cuda-shared-memory/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nfile(COPY shared_memory.ll DESTINATION \"${CMAKE_CURRENT_BINARY_DIR}\")\nfile(COPY extern_shared_memory.ll DESTINATION \"${CMAKE_CURRENT_BINARY_DIR}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Test for malloc-free Syscalls in CMake\nDESCRIPTION: Adds a test for malloc-free syscalls using the ptxgen tool. The test executes ptxgen on the malloc-free.ll LLVM IR file in the specified working directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/syscalls/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_test(NAME test-syscalls-malloc-free\n\tCOMMAND \"${CMAKE_CURRENT_BINARY_DIR}/../ptxgen/ptxgen\" \"${CMAKE_CURRENT_SOURCE_DIR}/malloc-free.ll\"\n  WORKING_DIRECTORY \"${CMAKE_CURRENT_BINARY_DIR}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for nvJPEG Encoder CUDA Sample\nDESCRIPTION: This snippet sets up the CMake project for the nvJPEG encoder CUDA sample. It defines the project, finds required packages, and sets global compile options. The code also configures CUDA architectures and flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/nvJPEG_encoder/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(nvJPEG_encoder LANGUAGES CXX)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n\n# Include directories and libraries\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Appending Custom Module Path\nDESCRIPTION: This line appends a custom module path to the CMake search path, allowing CMake to find additional modules required for the build.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fastWalshTransform/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Windows-Specific Libraries and DLLs\nDESCRIPTION: For Windows builds, links additional libraries and copies required DLLs to the output directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bicubicTexture/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    target_link_libraries(bicubicTexture\n        ${PC_GLUT_LIBRARY_DIRS}/freeglut.lib\n        ${PC_GLUT_LIBRARY_DIRS}/glew64.lib\n    )\n\n    add_custom_command(TARGET bicubicTexture\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/freeglut.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\n\n    add_custom_command(TARGET bicubicTexture\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_SOURCE_DIR}/../../../bin/win64/$<CONFIGURATION>/glew64.dll\n        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIGURATION>\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Minimum Version\nDESCRIPTION: This snippet specifies the minimum required version of CMake needed to build the project. It ensures compatibility with features used in the project configuration.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/fastWalshTransform/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n```\n\n----------------------------------------\n\nTITLE: Adding Compiler Definitions and Include Directories\nDESCRIPTION: Adds compiler definitions for libdevice major and minor versions and includes the common include directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_10\n\nLANGUAGE: CMake\nCODE:\n```\n\"add_definitions(-DLIBDEVICE_MAJOR_VERSION=1)\nadd_definitions(-DLIBDEVICE_MINOR_VERSION=0)\ninclude_directories(\\\"${CMAKE_CURRENT_SOURCE_DIR}/common/include\\\")\"\n```\n\n----------------------------------------\n\nTITLE: Handling Missing Dependencies\nDESCRIPTION: Provides status messages if OpenGL or GLUT are not found, indicating that the sample will not be built.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bicubicTexture/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\n    else()\n        message(STATUS \"GLUT not found - will not build sample 'bicubicTexture'\")\n    endif()\nelse()\n    message(STATUS \"OpenGL not found - will not build sample 'bicubicTexture'\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Performance Output for Jacobi Solver\nDESCRIPTION: Program output comparing performance metrics between CPU and GPU implementations of a Jacobi solver. The GPU (Hopper with compute capability 9.0) achieves approximately 43x speedup over CPU implementation while maintaining the same numerical accuracy.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_jacobiCudaGraphs.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n\nCPU iterations : 2954\nCPU error : 4.988e-03\nCPU Processing time: 2525.311035 (ms)\nGPU iterations : 2954\nGPU error : 4.988e-03\nGPU Processing time: 57.967999 (ms)\n&&&& jacobiCudaGraphs PASSED\n```\n\n----------------------------------------\n\nTITLE: CUDA Path Verification\nDESCRIPTION: Verifies that the paths to the CUDA toolkit and nvcc have been successfully located.  If not, it throws a fatal error.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/7_libNVVM/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\n\"message(STATUS \\\"Using CUDA_HOME: ${CUDA_HOME}\\\")\nmessage(STATUS \\\"Using CUDA_LIB:  ${CUDA_LIB}\\\")\nif ((\\\"${CUDA_HOME}\\\" STREQUAL \\\"\\\") OR (\\\"${CUDA_LIB}\\\" STREQUAL \\\"\\\"))\n  message(FATAL_ERROR \\\"Failed to locate paths to the CUDA toolkit and nvcc.\\\")\nendif ()\"\n```\n\n----------------------------------------\n\nTITLE: CUDA Sample Program Output\nDESCRIPTION: Console output showing performance comparison between GPU and CPU processing, including execution times and numerical accuracy. The output indicates detection of 1 CUDA device, processing times, and a comparison of sum calculations showing minimal relative difference between GPU and CPU results.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleMultiGPU.txt#2025-04-21_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\nStarting simpleMultiGPU\nCUDA-capable device count: 1\nGenerating input data...\n\nComputing with 1 GPUs...\n  GPU Processing time: 6.047000 (ms)\n\nComputing with Host CPU...\n\nComparing GPU and Host CPU results...\n  GPU sum: 16777296.000000\n  CPU sum: 16777294.395033\n  Relative difference: 9.566307E-08\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_21\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(matrixMulCUBLAS)\n```\n\n----------------------------------------\n\nTITLE: Building Platform-Specific CUDA Samples\nDESCRIPTION: CMake command for building samples specific to certain platforms like Tegra. This example enables compilation of Tegra-specific CUDA samples.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/README.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncmake -DBUILD_TEGRA=True ..\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA Bilateral Filter\nDESCRIPTION: Sets up the CMake project, specifies languages, and configures CUDA-specific settings including architecture targets and compiler flags.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/bilateralFilter/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(bilateralFilter LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\nif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    # set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -G\")  # enable cuda-gdb (expensive)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Loading Image Files for Optical Flow Computation in CUDA\nDESCRIPTION: This snippet shows the process of loading two image files (frame10.ppm and frame11.ppm) for optical flow computation. It's a prerequisite step before performing the actual optical flow calculations.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_HSOpticalFlow.txt#2025-04-21_snippet_0\n\nLANGUAGE: C++\nCODE:\n```\nLoading \"frame10.ppm\" ...\nLoading \"frame11.ppm\" ...\n```\n\n----------------------------------------\n\nTITLE: Configuring compiler options and target properties\nDESCRIPTION: Sets up compiler options, C++/CUDA standards, and build properties for the target executable. This ensures proper compilation with extended lambda support and separable compilation.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/CMakeLists.txt#2025-04-21_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_options(cuSolverDn_LinearSolver PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:--extended-lambda>)\n\ntarget_compile_features(cuSolverDn_LinearSolver PRIVATE cxx_std_17 cuda_std_17)\n\nset_target_properties(cuSolverDn_LinearSolver PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Set Target Properties\nDESCRIPTION: This sets properties for the 'batchCUBLAS' target. Specifically, it enables separable compilation for CUDA code.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_12\n\nLANGUAGE: CMake\nCODE:\n```\nset_target_properties(batchCUBLAS PROPERTIES CUDA_SEPARABLE_COMPILATION ON)\n```\n\n----------------------------------------\n\nTITLE: Target Include Directories\nDESCRIPTION: This specifies include directories for the 'batchCUBLAS' target. It includes the CUDA toolkit's include directories.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_13\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_include_directories(batchCUBLAS PRIVATE\n    ${CUDAToolkit_INCLUDE_DIRS}\n)\n```\n\n----------------------------------------\n\nTITLE: Set minimum CMake version\nDESCRIPTION: This sets the minimum required CMake version for the project. It ensures that the project is built with a compatible CMake version (3.20 or higher).\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/batchCUBLAS/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n```\n\n----------------------------------------\n\nTITLE: Linking Libraries\nDESCRIPTION: This command links the 'nbody' target with the OpenGL and GLUT libraries. This ensures that the executable can use the functions provided by these libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_14\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_link_libraries(nbody\n            ${OPENGL_LIBRARIES}\n            ${GLUT_LIBRARIES}\n        )\n```\n\n----------------------------------------\n\nTITLE: Including Common Directories\nDESCRIPTION: This command adds a directory to the include search path, allowing the compiler to find header files located in the specified directory. This is often used to include common header files shared across multiple projects or modules.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Validating Black-Scholes GPU Results in CUDA\nDESCRIPTION: This snippet shows the validation of GPU results against CPU calculations. It includes the L1 norm and maximum absolute error between GPU and CPU results.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_BlackScholes.txt#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nComparing the results...\nL1 norm: 1.741792E-07\nMax absolute error: 1.192093E-05\n```\n\n----------------------------------------\n\nTITLE: Setting Position Independent Code\nDESCRIPTION: This command sets the CMAKE_POSITION_INDEPENDENT_CODE variable to ON, which enables position-independent code generation. This is often required for shared libraries.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/nbody/CMakeLists.txt#2025-04-21_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n```\n\n----------------------------------------\n\nTITLE: Adding CMake module path\nDESCRIPTION: This appends a path to the CMAKE_MODULE_PATH variable.  This allows CMake to find custom modules in the specified directory, which can contain helper functions or definitions used in the build process. The specified path is relative to the current source directory.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/StreamPriorities/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: Initializing GPU Device for CUDA\nDESCRIPTION: This snippet initializes the GPU device and displays its compute capability. It's using a Hopper architecture GPU with compute capability 9.0.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleCUBLAS_LU.txt#2025-04-21_snippet_0\n\nLANGUAGE: CUDA\nCODE:\n```\nGPU Device 0: \"Hopper\" with compute capability 9.0\n```\n\n----------------------------------------\n\nTITLE: Configuring LU Decomposition Parameters in CUDA\nDESCRIPTION: This snippet shows the configuration of the LU decomposition algorithm. It's using double precision and enabling pivoting for improved numerical stability.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_simpleCUBLAS_LU.txt#2025-04-21_snippet_1\n\nLANGUAGE: CUDA\nCODE:\n```\n> using DOUBLE precision..\n> pivot ENABLED..\n```\n\n----------------------------------------\n\nTITLE: CUDA Module Loading Log\nDESCRIPTION: Terminal output showing the process of finding and loading a CUDA PTX module file, followed by verification step\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_memMapIPCDrv.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n> findModulePath found file at <./memMapIpc_kernel64.ptx>\n> initCUDA loading module: <./memMapIpc_kernel64.ptx>\n> PTX JIT log:\n\nStep 0 done\nProcess 0: verifying...\n```\n\n----------------------------------------\n\nTITLE: Validating GPU Convolution Results in CUDA\nDESCRIPTION: This snippet compares the GPU convolution results with CPU implementations. It calculates the relative L2 norm to measure the accuracy of the GPU results.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/bin/x86_64/linux/release/APM_convolutionTexture.txt#2025-04-21_snippet_4\n\nLANGUAGE: CUDA\nCODE:\n```\nChecking the results...\n...running convolutionRowsCPU()\n...running convolutionColumnsCPU()\nRelative L2 norm: 0.000000E+00\n```\n\n----------------------------------------\n\nTITLE: Cross-Compiling CUDA Samples for Tegra Platforms\nDESCRIPTION: Commands for cross-compiling CUDA samples for Tegra devices. The process requires specifying a Tegra-specific toolchain file to CMake.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/README.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmkdir build && cd build\ncmake .. -DCMAKE_TOOLCHAIN_FILE=/path/to/tegra/toolchain.cmake\nmake -j$(nproc)\n```\n\n----------------------------------------\n\nTITLE: Setting minimum CMake version\nDESCRIPTION: This command specifies the minimum required version of CMake for the project. It ensures that the CMake version used to build the project is at least 3.20.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/stereoDisparity/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n```\n\n----------------------------------------\n\nTITLE: Including directories\nDESCRIPTION: This command adds a directory to the include search path for the compiler. It allows the compiler to find header files located in the specified directory during compilation, which is necessary for using external libraries or project-specific headers.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/cudaGraphsPerfScaling/CMakeLists.txt#2025-04-21_snippet_6\n\nLANGUAGE: cmake\nCODE:\n```\ninclude_directories(../../../Common)\n```\n\n----------------------------------------\n\nTITLE: Installing CMake on Linux for CUDA Samples\nDESCRIPTION: Command to install CMake package on Linux systems, which is required for building CUDA samples. Version 3.20 or later is needed.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt install cmake\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Function List\nDESCRIPTION: List of CUDA Runtime API functions used in the sample implementation for memory management and error handling.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/README.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncudaGetErrorEnum\ncudaMalloc\ncudaMemcpy\ncudaFree\n```\n\n----------------------------------------\n\nTITLE: Setting minimum CMake version\nDESCRIPTION: This command specifies the minimum required version of CMake for the project. It ensures that the CMake version used to build the project is at least 3.20, preventing compatibility issues with older CMake versions.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/cudaGraphsPerfScaling/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n```\n\n----------------------------------------\n\nTITLE: Appending CMake module path\nDESCRIPTION: This command appends a directory to the CMake module path. This allows CMake to find custom modules or Find modules in the specified directory during the configuration process, which is useful for including project-specific CMake modules.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/cudaGraphsPerfScaling/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n```\n\n----------------------------------------\n\nTITLE: CUDA Runtime API Function Reference\nDESCRIPTION: CUDA Runtime API function used in the sample for device management\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/1_Utilities/deviceQueryDrv/README.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\ncudaSetDevice\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project with CUDA Support\nDESCRIPTION: Sets up basic CMake configuration including minimum version, project languages, and module paths.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/3_CUDA_Features/graphMemoryFootprint/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(graphMemoryFootprint LANGUAGES C CXX CUDA)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for CUDA Marching Cubes\nDESCRIPTION: Sets up project configuration, CUDA architecture targets, and compiler flags for the Marching Cubes sample\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/marchingCubes/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(marchingCubes LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\nset(CMAKE_CUDA_ARCHITECTURES 50 52 60 61 70 72 75 80 86 87 89 90 100 101 120)\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wno-deprecated-gpu-targets\")\n```\n\n----------------------------------------\n\nTITLE: Initializing CMake Project for CUDA Scalar Product\nDESCRIPTION: Sets up the CMake project with CUDA support, defines the minimum CMake version, and specifies the project name and languages.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/2_Concepts_and_Techniques/scalarProd/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.20)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/../../../cmake/Modules\")\n\nproject(scalarProd LANGUAGES C CXX CUDA)\n\nfind_package(CUDAToolkit REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_5\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(conjugateGradient)\n```\n\n----------------------------------------\n\nTITLE: Adding a Subdirectory with CMake\nDESCRIPTION: This CMake command adds a subdirectory to the current project build. The specified subdirectory should contain its own CMakeLists.txt file to define its build process.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/4_CUDA_Libraries/CMakeLists.txt#2025-04-21_snippet_17\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(freeImageInteropNPP)\n```\n\n----------------------------------------\n\nTITLE: Adding Subdirectory: alignedTypes\nDESCRIPTION: This line adds the 'alignedTypes' directory as a subdirectory to the current CMake project. This allows CMake to process the CMakeLists.txt file within, integrating its build targets.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/CMakeLists.txt#2025-04-21_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(alignedTypes)\n```\n\n----------------------------------------\n\nTITLE: Adding Subdirectory: UnifiedMemoryPerf\nDESCRIPTION: This line adds the 'UnifiedMemoryPerf' directory as a subdirectory to the current CMake project.  CMake will process the CMakeLists.txt in that directory, adding its targets to the overall build.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/6_Performance/CMakeLists.txt#2025-04-21_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(UnifiedMemoryPerf)\n```\n\n----------------------------------------\n\nTITLE: Add Custom Command to Copy Kernel Files\nDESCRIPTION: Adds a custom command to copy kernel files to the output directory after the target is built. This ensures that the kernel files are available at runtime.\nSOURCE: https://github.com/nvidia/cuda-samples/blob/master/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/CMakeLists.txt#2025-04-21_snippet_12\n\nLANGUAGE: CMake\nCODE:\n```\nadd_custom_command(TARGET quasirandomGenerator_nvrtc POST_BUILD\n    COMMAND ${CMAKE_COMMAND} -E copy_if_different\n    ${CMAKE_CURRENT_SOURCE_DIR}/quasirandomGenerator_kernel.cu ${CMAKE_CURRENT_SOURCE_DIR}/quasirandomGenerator_gpu.cuh ${CMAKE_CURRENT_SOURCE_DIR}/quasirandomGenerator_common.h ${CMAKE_CURRENT_BINARY_DIR}\n)\n```"
  }
]