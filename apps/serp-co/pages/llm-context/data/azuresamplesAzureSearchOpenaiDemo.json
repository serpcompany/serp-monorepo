[
  {
    "owner": "azure-samples",
    "repo": "azure-search-openai-demo",
    "content": "TITLE: Deploying Application and Azure Resources - Shell\nDESCRIPTION: The 'azd up' command provisions the necessary Azure resources and deploys the sample application, including search and AI components. Dependencies: Azure Developer CLI, authenticated Azure account, initialized project. This command builds search indexes, may incur costs, and prompts the user to select Azure regions for deployment. Resources persist until manually deleted.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/README.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nazd up\n```\n\n----------------------------------------\n\nTITLE: Provisioning and Deploying the RAG Chat Application via azd CLI - Shell\nDESCRIPTION: Running 'azd up' provisions Azure resources and deploys the configured RAG chat app with the specified authentication and access control settings. This command bundles infrastructure provisioning, configuration, and deployment steps into a single workflow. Ensure environment variables and authentication settings are already configured before running this command. azd CLI setup is required.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nazd up\n```\n\n----------------------------------------\n\nTITLE: Logging Informational Messages Globally Using logging Module in Python\nDESCRIPTION: This example illustrates logging a formatted info-level message directly to the root logger using Python's built-in 'logging' module, outside of route or application context. Suitable for system-level events, the logger emits messages adhering to global log level settings. Requires prior setup of the logging module.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/appservice.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nlogging.info(\"System message: %s\", system_message)\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Azure Using Azure Developer CLI - Bash\nDESCRIPTION: This snippet demonstrates how to authenticate your local session with Azure using the Azure Developer CLI. It requires the Azure Developer CLI (azd) installed and configured on your system. The command prompts the user to log into their Azure account, a prerequisite for all subsequent deployment or resource management tasks.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/azure_app_service.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nazd auth login\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Azure Resources - Shell\nDESCRIPTION: These code snippets use the `azd env set` command in the shell to configure environment variables for the Azure Developer CLI. Each line sets a required or optional resource-specific value, such as resource group names, locations, SKUs, and configurations, prior to running the deployment (`azd up`). Parameters must be replaced with actual values relevant to the user's Azure subscription. The expected input is the terminal execution of these commands, and no output is generated except successful setting of environment variables; errors may occur if names or permissions are incorrect.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_existing.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_RESOURCE_GROUP {Name of existing resource group}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_LOCATION {Location of existing resource group}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_SERVICE {Name of existing OpenAI service}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_RESOURCE_GROUP {Name of existing resource group that OpenAI service is provisioned to}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_LOCATION {Location of existing OpenAI service}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT {Name of existing chat deployment}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_MODEL {Model name of existing chat deployment}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_VERSION {Version string for existing chat deployment}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_SKU {Name of SKU for existing chat deployment}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_EMB_DEPLOYMENT {Name of existing embedding deployment}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_EMB_MODEL_NAME {Model name of existing embedding deployment}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_EMB_DIMENSIONS {Dimensions for existing embedding deployment}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_EMB_DEPLOYMENT_VERSION {Version string for existing embedding deployment}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_DISABLE_KEYS false\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set OPENAI_HOST openai\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set OPENAI_ORGANIZATION {Your OpenAI organization}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set OPENAI_API_KEY {Your OpenAI API key}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd up\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_SERVICE {Name of existing Azure AI Search service}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_SERVICE_RESOURCE_GROUP {Name of existing resource group with ACS service}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_SERVICE_LOCATION {Location of existing service}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_SERVICE_SKU {Name of SKU}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_INDEX {Name of existing index}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_QUERY_LANGUAGE {Name of query language}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_QUERY_SPELLER none\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_ANALYZER_NAME {Name of analyzer name}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_APP_SERVICE_PLAN {Name of existing Azure App Service Plan}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_APP_SERVICE {Name of existing Azure App Service}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_APP_SERVICE_SKU {SKU of Azure App Service, defaults to B1}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_APPLICATION_INSIGHTS {Name of existing Azure App Insights}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_APPLICATION_INSIGHTS_DASHBOARD {Name of existing Azure App Insights Dashboard}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_LOG_ANALYTICS {Name of existing Azure Log Analytics Workspace Name}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_COMPUTER_VISION_SERVICE {Name of existing Azure Computer Vision Service Name}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_COMPUTER_VISION_RESOURCE_GROUP {Name of existing Azure Computer Vision Resource Group Name}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_COMPUTER_VISION_LOCATION {Name of existing Azure Computer Vision Location}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_COMPUTER_VISION_SKU {SKU of Azure Computer Vision service, defaults to F0}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_DOCUMENTINTELLIGENCE_SERVICE {Name of existing Azure AI Document Intelligence service}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_DOCUMENTINTELLIGENCE_LOCATION {Location of existing service}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_DOCUMENTINTELLIGENCE_RESOURCE_GROUP {Name of resource group with existing service, defaults to main resource group}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_DOCUMENTINTELLIGENCE_SKU {SKU of existing service, defaults to S0}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SPEECH_SERVICE {Name of existing Azure Speech service}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SPEECH_SERVICE_RESOURCE_GROUP {Name of existing resource group with speech service}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SPEECH_SERVICE_LOCATION {Location of existing service}\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SPEECH_SERVICE_SKU {Name of SKU}\n```\n\n----------------------------------------\n\nTITLE: Provisioning Resources and Deploying to Azure Using azd - Bash\nDESCRIPTION: This code snippet provisions Azure resources and deploys the RAG chat sample, including building the search index from data files in './data'. It requires previous configuration steps such as authentication, environment setup, and environment variable settings. Resources created may incur costs; ensure cleanup (using 'azd down' or manual deletion) to avoid unnecessary charges.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/azure_app_service.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nazd up\n```\n\n----------------------------------------\n\nTITLE: Running Prepdocs Script for ADLS Gen2 Data Ingestion (PowerShell/Bash)\nDESCRIPTION: Executes the `prepdocs` script (either PowerShell or Bash version) to process PDF documents stored in the configured Azure Data Lake Storage Gen2 account and ingest them into the Azure AI Search index along with their associated access control lists. Requires environment variables like `AZURE_ADLS_GEN2_STORAGE_ACCOUNT` to be set.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_23\n\nLANGUAGE: shell\nCODE:\n```\n/scripts/prepdocs.ps1 or /scripts/prepdocs.sh\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI Chat Model - azd CLI - Bash\nDESCRIPTION: This set of snippets shows how to set the Azure OpenAI chat model name via the `azd` CLI. The environment variable `AZURE_OPENAI_CHATGPT_MODEL` accepts various model names such as 'gpt-4', 'gpt-4o', 'gpt-4o-mini', or 'gpt-35-turbo', depending on which model you intend to deploy. This must match a supported and deployed model in your Azure OpenAI resource.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_MODEL gpt-4\n```\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_MODEL gpt-4o\n```\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_MODEL gpt-4o-mini\n```\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_MODEL gpt-35-turbo\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI Text Embedding Model - azd CLI - Shell\nDESCRIPTION: These commands configure which Azure OpenAI embedding model is used by setting the `AZURE_OPENAI_EMB_MODEL_NAME` environment variable. The two examples, 'text-embedding-3-small' and 'text-embedding-3-large', select between available embedding model variants. Additional steps, beyond this environment change, are needed to ensure that your deployment and region support the selected model.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_EMB_MODEL_NAME text-embedding-3-small\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_EMB_MODEL_NAME text-embedding-3-large\n```\n\n----------------------------------------\n\nTITLE: Setting Azure OpenAI Embedding Model Dimensions - azd CLI - Shell\nDESCRIPTION: This command sets the dimensionality of the embedding vectors used by the selected embedding model by updating the `AZURE_OPENAI_EMB_DIMENSIONS` environment variable. The dimension parameter generally ranges between 256 and 3072, depending on model capabilities, and must match the expected input for the chosen embedding model.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_EMB_DIMENSIONS 256\n```\n\n----------------------------------------\n\nTITLE: Setting Azure OpenAI Chat Model Version - azd CLI - Bash\nDESCRIPTION: These commands configure the specific model version to be deployed for each OpenAI model by setting the `AZURE_OPENAI_CHATGPT_DEPLOYMENT_VERSION` environment variable. Supported version strings must match those provided by Azure documentation. Ensure that the deployed model supports the desired version.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_VERSION turbo-2024-04-09\n```\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_VERSION 2024-05-13\n```\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_VERSION 2024-07-18\n```\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_VERSION 0125\n```\n\n----------------------------------------\n\nTITLE: Initializing Project with Azure Developer CLI - Shell\nDESCRIPTION: This snippet runs the 'azd init' command to bootstrap the Azure Search OpenAI Demo template using Azure Developer CLI. Prerequisites: Azure Developer CLI must be installed and available in PATH. The command starts a new git repository and downloads all project files necessary for deployment. No additional cloning is required, and it prepares the local folder for further Azure operations.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/README.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd init -t azure-search-openai-demo\n```\n\n----------------------------------------\n\nTITLE: Provisioning and Deploying Application with AZD\nDESCRIPTION: Executes the `azd up` command, which triggers the provisioning of all necessary Azure resources defined in the configuration and deploys the application code. This command also builds the search index based on files in the `./data` folder. Note that this command incurs Azure costs.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/azure_container_apps.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nazd up\n```\n\n----------------------------------------\n\nTITLE: Setting the OpenAI Chat Completion Deployment Name Example - azd CLI - Bash\nDESCRIPTION: This snippet provides an example setting the deployment name to 'gpt-4o' for Azure OpenAI within the environment. By using 'gpt-4o' as the deployment name, the deployment will target the corresponding deployed model instance, contingent on prior setup in Azure OpenAI resources.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT gpt-4o\n```\n\n----------------------------------------\n\nTITLE: Provisioning Resources for Integrated Vectorization - Shell\nDESCRIPTION: The command 'azd provision' provisions necessary Azure resources, RBAC roles, and configures integrated vectorization after enabling it in the environment. Should be run after setting USE_FEATURE_INT_VECTORIZATION. Requires pre-existing azd environment setup; modifies cloud infrastructure.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\nazd provision\n```\n\n----------------------------------------\n\nTITLE: Defining Python Project Dependencies (requirements.txt)\nDESCRIPTION: Specifies the exact versions of all required Python packages for the azure-search-openai-demo project. This file is typically used by `pip install -r requirements.txt` to install dependencies and ensure a reproducible environment. Comments indicate the origin of each dependency (either directly from `requirements.in` or as a transitive dependency of another package).\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/app/backend/requirements.txt#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n#    uv pip compile requirements.in -o requirements.txt\naiofiles==24.1.0\n    # via\n    #   prompty\n    #   quart\naiohappyeyeballs==2.4.4\n    # via aiohttp\naiohttp==3.10.11\n    # via\n    #   -r requirements.in\n    #   microsoft-kiota-authentication-azure\naiosignal==1.3.1\n    # via aiohttp\nannotated-types==0.7.0\n    # via pydantic\nanyio==4.4.0\n    # via\n    #   httpx\n    #   openai\nasgiref==3.8.1\n    # via opentelemetry-instrumentation-asgi\nattrs==24.2.0\n    # via aiohttp\nazure-ai-documentintelligence==1.0.0b4\n    # via -r requirements.in\nazure-cognitiveservices-speech==1.40.0\n    # via -r requirements.in\nazure-common==1.1.28\n    # via azure-search-documents\nazure-core==1.30.2\n    # via\n    #   azure-ai-documentintelligence\n    #   azure-core-tracing-opentelemetry\n    #   azure-cosmos\n    #   azure-identity\n    #   azure-monitor-opentelemetry\n    #   azure-monitor-opentelemetry-exporter\n    #   azure-search-documents\n    #   azure-storage-blob\n    #   azure-storage-file-datalake\n    #   microsoft-kiota-authentication-azure\n    #   msrest\nazure-core-tracing-opentelemetry==1.0.0b11\n    # via azure-monitor-opentelemetry\nazure-cosmos==4.9.0\n    # via -r requirements.in\nazure-identity==1.17.1\n    # via\n    #   -r requirements.in\n    #   msgraph-sdk\nazure-monitor-opentelemetry==1.6.1\n    # via -r requirements.in\nazure-monitor-opentelemetry-exporter==1.0.0b32\n    # via azure-monitor-opentelemetry\nazure-search-documents==11.6.0b9\n    # via -r requirements.in\nazure-storage-blob==12.22.0\n    # via\n    #   -r requirements.in\n    #   azure-storage-file-datalake\nazure-storage-file-datalake==12.16.0\n    # via -r requirements.in\nbeautifulsoup4==4.12.3\n    # via -r requirements.in\nblinker==1.8.2\n    # via\n    #   flask\n    #   quart\ncertifi==2024.7.4\n    # via\n    #   httpcore\n    #   httpx\n    #   msrest\n    #   requests\ncffi==1.17.0\n    # via cryptography\ncharset-normalizer==3.3.2\n    # via requests\nclick==8.1.7\n    # via\n    #   flask\n    #   prompty\n    #   quart\n    #   uvicorn\ncryptography==44.0.1\n    # via\n    #   -r requirements.in\n    #   azure-identity\n    #   azure-storage-blob\n    #   msal\n    #   pyjwt\ndeprecated==1.2.14\n    # via\n    #   opentelemetry-api\n    #   opentelemetry-semantic-conventions\ndistro==1.9.0\n    # via openai\nfixedint==0.1.6\n    # via azure-monitor-opentelemetry-exporter\nflask==3.0.3\n    # via quart\nfrozenlist==1.4.1\n    # via\n    #   aiohttp\n    #   aiosignal\nh11==0.14.0\n    # via\n    #   httpcore\n    #   hypercorn\n    #   uvicorn\n    #   wsproto\nh2==4.1.0\n    # via\n    #   httpx\n    #   hypercorn\nhpack==4.0.0\n    # via h2\nhttpcore==1.0.5\n    # via httpx\nhttpx==0.27.0\n    # via\n    #   microsoft-kiota-http\n    #   msgraph-core\n    #   openai\nhypercorn==0.17.3\n    # via quart\nhyperframe==6.0.1\n    # via h2\nidna==3.10\n    # via\n    #   anyio\n    #   httpx\n    #   requests\n    #   yarl\nimportlib-metadata==8.0.0\n    # via opentelemetry-api\nisodate==0.6.1\n    # via\n    #   azure-ai-documentintelligence\n    #   azure-search-documents\n    #   azure-storage-blob\n    #   azure-storage-file-datalake\n    #   msrest\nitsdangerous==2.2.0\n    # via\n    #   flask\n    #   quart\njinja2==3.1.6\n    # via\n    #   flask\n    #   prompty\n    #   quart\njiter==0.8.2\n    # via openai\nmarkdown-it-py==3.0.0\n    # via rich\nmarkupsafe==2.1.5\n    # via\n    #   jinja2\n    #   quart\n    #   werkzeug\nmdurl==0.1.2\n    # via markdown-it-py\nmicrosoft-kiota-abstractions==1.9.3\n    # via\n    #   microsoft-kiota-authentication-azure\n    #   microsoft-kiota-http\n    #   microsoft-kiota-serialization-form\n    #   microsoft-kiota-serialization-json\n    #   microsoft-kiota-serialization-multipart\n    #   microsoft-kiota-serialization-text\n    #   msgraph-core\nmicrosoft-kiota-authentication-azure==1.9.3\n    # via msgraph-core\nmicrosoft-kiota-http==1.9.3\n    # via msgraph-core\nmicrosoft-kiota-serialization-form==1.9.3\n    # via msgraph-sdk\nmicrosoft-kiota-serialization-json==1.9.3\n    # via msgraph-sdk\nmicrosoft-kiota-serialization-multipart==1.9.3\n    # via msgraph-sdk\nmicrosoft-kiota-serialization-text==1.9.3\n    # via msgraph-sdk\nmsal==1.30.0\n    # via\n    #   -r requirements.in\n    #   azure-identity\n    #   msal-extensions\nmsal-extensions==1.3.1\n    # via azure-identity\nmsgraph-core==1.3.3\n    # via msgraph-sdk\nmsgraph-sdk==1.26.0\n    # via -r requirements.in\nmsrest==0.7.1\n    # via azure-monitor-opentelemetry-exporter\nmultidict==6.0.5\n    # via\n    #   aiohttp\n    #   yarl\noauthlib==3.2.2\n    # via requests-oauthlib\nopenai==1.63.0\n    # via -r requirements.in\nopentelemetry-api==1.31.1\n    # via\n    #   azure-core-tracing-opentelemetry\n    #   azure-monitor-opentelemetry-exporter\n    #   microsoft-kiota-abstractions\n    #   microsoft-kiota-authentication-azure\n    #   microsoft-kiota-http\n    #   opentelemetry-instrumentation\n    #   opentelemetry-instrumentation-aiohttp-client\n    #   opentelemetry-instrumentation-asgi\n    #   opentelemetry-instrumentation-dbapi\n    #   opentelemetry-instrumentation-django\n    #   opentelemetry-instrumentation-fastapi\n    #   opentelemetry-instrumentation-flask\n    #   opentelemetry-instrumentation-httpx\n    #   opentelemetry-instrumentation-openai\n    #   opentelemetry-instrumentation-psycopg2\n    #   opentelemetry-instrumentation-requests\n    #   opentelemetry-instrumentation-urllib\n    #   opentelemetry-instrumentation-urllib3\n    #   opentelemetry-instrumentation-wsgi\n    #   opentelemetry-sdk\n    #   opentelemetry-semantic-conventions\nopentelemetry-instrumentation==0.52b1\n    # via\n    #   opentelemetry-instrumentation-aiohttp-client\n    #   opentelemetry-instrumentation-asgi\n    #   opentelemetry-instrumentation-dbapi\n    #   opentelemetry-instrumentation-django\n    #   opentelemetry-instrumentation-fastapi\n    #   opentelemetry-instrumentation-flask\n    #   opentelemetry-instrumentation-httpx\n    #   opentelemetry-instrumentation-openai\n    #   opentelemetry-instrumentation-psycopg2\n    #   opentelemetry-instrumentation-requests\n    #   opentelemetry-instrumentation-urllib\n    #   opentelemetry-instrumentation-urllib3\n    #   opentelemetry-instrumentation-wsgi\nopentelemetry-instrumentation-aiohttp-client==0.52b1\n    # via -r requirements.in\nopentelemetry-instrumentation-asgi==0.52b1\n    # via\n    #   -r requirements.in\n    #   opentelemetry-instrumentation-fastapi\nopentelemetry-instrumentation-dbapi==0.52b1\n    # via opentelemetry-instrumentation-psycopg2\nopentelemetry-instrumentation-django==0.52b1\n    # via azure-monitor-opentelemetry\nopentelemetry-instrumentation-fastapi==0.52b1\n    # via azure-monitor-opentelemetry\nopentelemetry-instrumentation-flask==0.52b1\n    # via azure-monitor-opentelemetry\nopentelemetry-instrumentation-httpx==0.52b1\n    # via -r requirements.in\nopentelemetry-instrumentation-openai==0.39.0\n    # via -r requirements.in\nopentelemetry-instrumentation-psycopg2==0.52b1\n    # via azure-monitor-opentelemetry\nopentelemetry-instrumentation-requests==0.52b1\n    # via azure-monitor-opentelemetry\nopentelemetry-instrumentation-urllib==0.52b1\n    # via azure-monitor-opentelemetry\nopentelemetry-instrumentation-urllib3==0.52b1\n    # via azure-monitor-opentelemetry\nopentelemetry-instrumentation-wsgi==0.52b1\n    # via\n    #   opentelemetry-instrumentation-django\n    #   opentelemetry-instrumentation-flask\nopentelemetry-resource-detector-azure==0.1.5\n    # via azure-monitor-opentelemetry\nopentelemetry-sdk==1.31.1\n    # via\n    #   azure-monitor-opentelemetry\n    #   azure-monitor-opentelemetry-exporter\n    #   microsoft-kiota-abstractions\n    #   microsoft-kiota-authentication-azure\n    #   microsoft-kiota-http\n    #   opentelemetry-resource-detector-azure\nopentelemetry-semantic-conventions==0.52b1\n    # via\n    #   opentelemetry-instrumentation\n    #   opentelemetry-instrumentation-aiohttp-client\n    #   opentelemetry-instrumentation-asgi\n    #   opentelemetry-instrumentation-dbapi\n    #   opentelemetry-instrumentation-django\n    #   opentelemetry-instrumentation-fastapi\n    #   opentelemetry-instrumentation-flask\n    #   opentelemetry-instrumentation-httpx\n    #   opentelemetry-instrumentation-openai\n    #   opentelemetry-instrumentation-requests\n    #   opentelemetry-instrumentation-urllib\n    #   opentelemetry-instrumentation-urllib3\n    #   opentelemetry-instrumentation-wsgi\n    #   opentelemetry-sdk\nopentelemetry-semantic-conventions-ai==0.4.3\n    # via opentelemetry-instrumentation-openai\nopentelemetry-util-http==0.52b1\n    # via\n    #   opentelemetry-instrumentation-aiohttp-client\n    #   opentelemetry-instrumentation-asgi\n    #   opentelemetry-instrumentation-django\n    #   opentelemetry-instrumentation-fastapi\n    #   opentelemetry-instrumentation-flask\n    #   opentelemetry-instrumentation-httpx\n    #   opentelemetry-instrumentation-requests\n    #   opentelemetry-instrumentation-urllib\n    #   opentelemetry-instrumentation-urllib3\n    #   opentelemetry-instrumentation-wsgi\npackaging==24.1\n    # via\n    #   opentelemetry-instrumentation\n    #   opentelemetry-instrumentation-flask\npillow==10.4.0\n    # via -r requirements.in\nportalocker==2.10.1\n    # via msal-extensions\npriority==2.0.0\n    # via hypercorn\nprompty==0.1.50\n    # via -r requirements.in\npropcache==0.2.0\n    # via yarl\npsutil==5.9.8\n    # via azure-monitor-opentelemetry-exporter\npycparser==2.22\n    # via cffi\npydantic==2.8.2\n    # via\n    #   openai\n    #   prompty\npydantic-core==2.20.1\n    # via pydantic\npygments==2.18.0\n    # via rich\npyjwt==2.10.1\n    # via\n    #   -r requirements.in\n    #   msal\npymupdf==1.25.1\n    # via -r requirements.in\npypdf==4.3.1\n    # via -r requirements.in\npython-dotenv==1.0.1\n    # via\n    #   -r requirements.in\n    #   prompty\npyyaml==6.0.2\n    # via prompty\nquart==0.20.0\n    # via\n    #   -r requirements.in\n    #   quart-cors\nquart-cors==0.7.0\n    # via -r requirements.in\nregex==2024.11.6\n    # via tiktoken\nrequests==2.32.3\n    # via\n    #   azure-core\n    #   msal\n    #   msrest\n    #   requests-oauthlib\n    #   tiktoken\nrequests-oauthlib==2.0.0\n    # via msrest\nrich==13.9.4\n```\n\n----------------------------------------\n\nTITLE: Generating Ground Truth Data for Evaluation - Python (Shell Command)\nDESCRIPTION: This Python shell command runs the generate_ground_truth.py script to create ground truth question and answer pairs for later RAG evaluation. Options include specifying the number of questions and documents. Requires the evaluation environment to be active and all dependencies installed. Outputs a ground truth data file in JSONL format, whose location can be customized.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/evaluation.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\npython evals/generate_ground_truth.py --numquestions=200 --numsearchdocs=1000\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies and Versions\nDESCRIPTION: Defines the required Python packages and their exact versions for the Azure Search OpenAI Demo project. Comments specify the origin of each dependency, whether direct (via -r requirements.in) or transitive (via another package). This format is commonly found in dependency files like requirements.txt.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/app/backend/requirements.txt#_snippet_1\n\nLANGUAGE: pip requirements\nCODE:\n```\n# via -r requirements.in\nsix==1.16.0\n    # via\n    #   azure-core\n    #   isodate\nsniffio==1.3.1\n    # via\n    #   anyio\n    #   httpx\n    #   openai\nsoupsieve==2.6\n    # via beautifulsoup4\nstd-uritemplate==2.0.3\n    # via microsoft-kiota-abstractions\ntenacity==9.0.0\n    # via -r requirements.in\ntiktoken==0.8.0\n    # via\n    #   -r requirements.in\n    #   opentelemetry-instrumentation-openai\ntqdm==4.66.5\n    # via openai\ntypes-beautifulsoup4==4.12.0.20240511\n    # via -r requirements.in\ntypes-html5lib==1.1.11.20241018\n    # via types-beautifulsoup4\ntypes-pillow==10.2.0.20240822\n    # via -r requirements.in\ntyping-extensions==4.12.2\n    # via\n    #   -r requirements.in\n    #   azure-ai-documentintelligence\n    #   azure-core\n    #   azure-cosmos\n    #   azure-identity\n    #   azure-search-documents\n    #   azure-storage-blob\n    #   azure-storage-file-datalake\n    #   openai\n    #   opentelemetry-sdk\n    #   pydantic\n    #   pydantic-core\nurllib3==2.2.2\n    # via requests\nuvicorn==0.30.6\n    # via -r requirements.in\nwerkzeug==3.0.6\n    # via\n    #   flask\n    #   quart\nwrapt==1.16.0\n    # via\n    #   deprecated\n    #   opentelemetry-instrumentation\n    #   opentelemetry-instrumentation-aiohttp-client\n    #   opentelemetry-instrumentation-dbapi\n    #   opentelemetry-instrumentation-httpx\n    #   opentelemetry-instrumentation-urllib3\nwsproto==1.2.0\n    # via hypercorn\nyarl==1.17.2\n    # via aiohttp\nzipp==3.21.0\n    # via importlib-metadata\n```\n\n----------------------------------------\n\nTITLE: Deploying Application Code Only - Shell\nDESCRIPTION: Runs 'azd deploy' to redeploy application code without reprovisioning Azure infrastructure. Use this after modifying backend/frontend code when infrastructure remains unchanged. Dependencies: Azure Developer CLI, prior successful deployment, active environment. It uploads only application code and related assets.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/README.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nazd deploy\n```\n\n----------------------------------------\n\nTITLE: Configuring Logging Levels for Python App with logging and Flask\nDESCRIPTION: This snippet configures logging behavior for both the root and app loggers in a Python web application, ensuring SDKS only log warnings or higher while the application itself logs info or higher. It loads the log level from the 'APP_LOG_LEVEL' environment variable if set, otherwise defaults to 'INFO'. Place this code at startup to control application log verbosity.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/appservice.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Set root level to WARNING to avoid seeing overly verbose logs from SDKS\\nlogging.basicConfig(level=logging.WARNING)\\n# Set the app logger level to INFO by default\\ndefault_level = \"INFO\"\\napp.logger.setLevel(os.getenv(\"APP_LOG_LEVEL\", default_level))\n```\n\n----------------------------------------\n\nTITLE: Enforcing Document-Level Access Control via azd CLI - Shell\nDESCRIPTION: This shell command configures the RAG chat application to strictly enforce document-level access control. By setting 'AZURE_ENFORCE_ACCESS_CONTROL' to 'true' using the azd CLI, only documents the authenticated user has access to will be returned in search results. The azd CLI environment must already be initialized for the project.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_ENFORCE_ACCESS_CONTROL true\n```\n\n----------------------------------------\n\nTITLE: Programmatically Obtaining Access Token for Server API using Python\nDESCRIPTION: This Python code snippet demonstrates how to obtain an Azure AD access token programmatically using the `azure-identity` library. It uses `DefaultAzureCredential` for authentication and requests a token for the server application's `access_as_user` scope, identified by its Application ID URI (`api://<server_app_id>`). This token can then be used in the Authorization header when making calls to the secured chat API endpoint. Requires environment variables `AZURE_SERVER_APP_ID` and (`AZURE_AUTH_TENANT_ID` or `AZURE_TENANT_ID`) to be set.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom azure.identity import DefaultAzureCredential\nimport os\n\ntoken = DefaultAzureCredential().get_token(f\"api://{os.environ['AZURE_SERVER_APP_ID']}/access_as_user\", tenant_id=os.getenv('AZURE_AUTH_TENANT_ID', os.getenv('AZURE_TENANT_ID')))\n\nprint(token.token)\n```\n\n----------------------------------------\n\nTITLE: Setting Azure Authentication Tenant ID via azd CLI - Shell\nDESCRIPTION: This command sets the tenant ID for authentication in your Azure project using the azd CLI. Replace '<YOUR-TENANT-ID>' with the appropriate Azure Active Directory/Microsoft Entra tenant identifier. Required for aligning the authentication context of deployed resources. The azd CLI should be configured and authenticated before running this.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_AUTH_TENANT_ID <YOUR-TENANT-ID>\n```\n\n----------------------------------------\n\nTITLE: Logging into Authentication Tenant via azd CLI - Shell\nDESCRIPTION: This shell command logs you into a specific Azure tenant using the azd CLI. By providing the --tenant-id argument, you ensure subsequent operations target the intended authentication context. Replace '<YOUR-TENANT-ID>' appropriately. Prerequisites include having the azd CLI installed and possessing credentials for the target tenant.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nazd auth login --tenant-id <YOUR-TENANT-ID>\n```\n\n----------------------------------------\n\nTITLE: Assigning Azure Roles via Shell Script\nDESCRIPTION: Executes a shell script (`roles.sh`) located in the `.scripts` directory. This script assigns the necessary Azure roles to the user identity specified by the `AZURE_PRINCIPAL_ID` environment variable, enabling them to interact with the deployed Azure resources. Requires sufficient permissions in the Azure subscription to assign roles.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/sharing_environments.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n.scripts/roles.sh\n```\n\n----------------------------------------\n\nTITLE: Authenticating Azure Developer CLI (azd)\nDESCRIPTION: Logs the user into their Azure account using the Azure Developer CLI (`azd`). This is a required step before running the application locally after the initial deployment.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/localdev.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd auth login\n```\n\n----------------------------------------\n\nTITLE: Viewing Group Access Control Lists for a Document in Azure Search using Python\nDESCRIPTION: Uses the `manageacl.py` script to display the group IDs currently associated with a specific document (identified by its URL) stored in the Azure AI Search index. Requires environment setup and activated Python environment. The `-v` flag enables verbose logging.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\npython ./scripts/manageacl.py -v --acl-type groups --acl-action view --url https://st12345.blob.core.windows.net/content/Benefit_Options.pdf\n```\n\n----------------------------------------\n\nTITLE: Enabling Persistent Chat History with Azure Cosmos DB - Shell\nDESCRIPTION: This Shell command sets the USE_CHAT_HISTORY_COSMOS environment variable to 'true' for the Azure Developer CLI (azd), enabling persistent server-side chat history storage via Azure Cosmos DB for authenticated users. The prerequisite is an authenticated deployment with Cosmos DB enabled. No outputs are shown unless chained with other commands.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_CHAT_HISTORY_COSMOS true\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Tracing in Python with Azure Monitor\nDESCRIPTION: This Python code snippet, typically found in `app.py`, configures OpenTelemetry for tracing within the application. It initializes Azure Monitor integration if an Application Insights connection string is provided via environment variable, and instruments various libraries (aiohttp, httpx, OpenAI) and the ASGI application itself to capture trace data.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/monitoring.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nif os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\"):\n    configure_azure_monitor()\n    # This tracks HTTP requests made by aiohttp:\n    AioHttpClientInstrumentor().instrument()\n    # This tracks HTTP requests made by httpx:\n    HTTPXClientInstrumentor().instrument()\n    # This tracks OpenAI SDK requests:\n    OpenAIInstrumentor().instrument()\n    # This middleware tracks app route requests:\n    app.asgi_app = OpenTelemetryMiddleware(app.asgi_app)\n```\n\n----------------------------------------\n\nTITLE: Enabling Authentication UI Environment Variable using AZD CLI\nDESCRIPTION: This command uses the Azure Developer CLI (`azd`) to set the `AZURE_USE_AUTHENTICATION` environment variable. Setting this variable (implicitly to true by its presence) enables the login user interface in the deployed application. This should be run after the Microsoft Entra application registrations are complete.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_USE_AUTHENTICATION\n```\n\n----------------------------------------\n\nTITLE: Enabling GPT-4o Vision Support in Azure RAG Demo - Shell\nDESCRIPTION: This shell command enables the GPT-4o vision model feature by setting the USE_GPT4V environment variable to true in the Azure Developer CLI environment. This will cause subsequent deployments to provision the required Azure AI Vision resource, GPT-4o model, and update the ingestion pipeline for visual data handling. Prerequisite: You must have completed Responsible AI agreement for Azure AI Vision and confirmed region availability for necessary models and services. Key parameter: USE_GPT4V should be set to true to activate vision-based capabilities in the RAG application.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/gpt4v.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_GPT4V true\n```\n\n----------------------------------------\n\nTITLE: Setting Client App ID Environment Variable using AZD CLI\nDESCRIPTION: This command employs the Azure Developer CLI (`azd`) to set an environment variable named `AZURE_CLIENT_APP_ID`. It stores the Application (client) ID of the client-side (e.g., web) application registered in Microsoft Entra ID. The client app uses this ID to identify itself during the authentication process.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_CLIENT_APP_ID <Application (client) ID>\n```\n\n----------------------------------------\n\nTITLE: Setting Azure Data Lake Storage Gen2 Account using AZD CLI\nDESCRIPTION: Sets the `AZURE_ADLS_GEN2_STORAGE_ACCOUNT` environment variable using the Azure Developer CLI (`azd`). This specifies the target ADLS Gen2 account for the `adlsgen2setup.py` script. Replace `<your-storage-account>` with the actual storage account name.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_ADLS_GEN2_STORAGE_ACCOUNT <your-storage-account>\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI Evaluation Deployment - Shell\nDESCRIPTION: These shell commands use the Azure Developer CLI (azd) to set environment variables required for evaluation, such as enabling evaluation mode and specifying model deployment capacity. They must be run in a shell with azd installed, and the current directory must be an azd environment. Key parameters like USE_EVAL and AZURE_OPENAI_EVAL_DEPLOYMENT_CAPACITY control evaluation settings. These commands do not produce direct outputs but affect subsequent provisioning steps.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/evaluation.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_EVAL true\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_EVAL_DEPLOYMENT_CAPACITY 100\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Azure using Azure Developer CLI - Shell\nDESCRIPTION: This command authenticates the current user with Azure using Azure Developer CLI. It is required before performing any deployment or resource provisioning. Prerequisites: Azure Developer CLI installed and a valid Azure subscription. The command opens a browser for login; on success, CLI actions can interact with Azure resources.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/README.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nazd auth login\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for o1 Reasoning Model using AZD (Shell)\nDESCRIPTION: This snippet shows how to configure the Azure Search OpenAI demo application to use the 'o1' reasoning model. It employs the Azure Developer CLI (`azd`) to define environment variables specifying the Azure OpenAI chat model name, deployment name, version, SKU, and the API version to be used.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/reasoning.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_MODEL o1\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT o1\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_VERSION 2024-12-17\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_SKU GlobalStandard\nazd env set AZURE_OPENAI_API_VERSION 2024-12-01-preview\n```\n\n----------------------------------------\n\nTITLE: Summarizing and Comparing Evaluation Results - Python (Shell Command)\nDESCRIPTION: These commands use the evaltools Python module to summarize and compare RAG evaluation results. The 'summary' option reports aggregate metrics, while 'diff' compares answer quality between evaluation runs or against the ground truth. Requires evaltools installed and evaluation output directories present. Outputs summaries and comparisons in the terminal.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/evaluation.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\npython -m evaltools summary evals/results\n```\n\nLANGUAGE: python\nCODE:\n```\npython -m evaltools diff evals/results/baseline/\n```\n\nLANGUAGE: python\nCODE:\n```\npython -m evaltools diff evals/results/baseline/ evals/results/SECONDRUNHERE\n```\n\n----------------------------------------\n\nTITLE: Enabling CORS for Alternate Frontends - Shell\nDESCRIPTION: Sets the ALLOWED_ORIGIN environment variable to a specified domain, enabling CORS for cross-origin frontend requests. Needs to be followed by 'azd up' to apply changes. The frontend must also update its BACKEND_URI to the new backend endpoint; does not produce direct output.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_23\n\nLANGUAGE: shell\nCODE:\n```\nazd env set ALLOWED_ORIGIN https://<your-domain.com>\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Azure Resources - Shell\nDESCRIPTION: Executes 'azd down' to tear down all Azure resources created for this sample. Prompts the user for confirmation twice before resource group deletion. Prerequisite: Azure Developer CLI and an active environment. Ensures no lingering cloud costs by deleting all deployed infrastructure associated with this environment.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/README.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nazd down\n```\n\n----------------------------------------\n\nTITLE: Logging into Azure with AZD\nDESCRIPTION: Authenticates the user's Azure account using the Azure Developer CLI (`azd`). This command initiates the login process, typically opening a browser window for authentication. It is a prerequisite for managing Azure resources with `azd`.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd auth login\n```\n\n----------------------------------------\n\nTITLE: Logging into Azure with AZD\nDESCRIPTION: Executes the `azd auth login` command to authenticate the user's Azure account via the Azure Developer CLI. This is a prerequisite for managing Azure resources with `azd`.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/azure_container_apps.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nazd auth login\n```\n\n----------------------------------------\n\nTITLE: Launching Application Insights Dashboard using Azure Developer CLI (Shell)\nDESCRIPTION: This command uses the Azure Developer CLI (`azd`) to open the pre-configured Application Insights dashboard for monitoring the application. The dashboard's content and layout are defined in the `infra/backend-dashboard.bicep` file.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/monitoring.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd monitor\n```\n\n----------------------------------------\n\nTITLE: Viewing Successful Oryx Build Logs for Python App Service Deployment\nDESCRIPTION: This log output shows the steps taken by the Oryx build tool during a successful deployment of a Python 3.11 application to Azure App Service. It details platform detection, intermediate directory usage, Python version download/extraction, virtual environment creation ('antenv'), and the installation of Python packages listed in `requirements.txt` using pip.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/appservice.md#_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nCommand: oryx build /tmp/zipdeploy/extracted -o /home/site/wwwroot --platform python --platform-version 3.11 -p virtualenv_name=antenv --log-file /tmp/build-debug.log  -i /tmp/8dc28dad0e10acb --compress-destination-dir | tee /tmp/oryx-build.log\nOperation performed by Microsoft Oryx, https://github.com/Microsoft/Oryx\nYou can report issues at https://github.com/Microsoft/Oryx/issues\n\nOryx Version: 0.2.20230508.1, Commit: 7fe2bf39b357dd68572b438a85ca50b5ecfb4592, ReleaseTagName: 20230508.1\n\nBuild Operation ID: 7440a33100749a32\nRepository Commit : b09bff8b-da36-4d70-9e2f-c7b9131d85bc\nOS Type           : bullseye\nImage Type        : githubactions\n\nDetecting platforms...\nDetected following platforms:\n  python: 3.11.7\nVersion '3.11.7' of platform 'python' is not installed. Generating script to install it...\n\nUsing intermediate directory '/tmp/8dc28dad0e10acb'.\n\nCopying files to the intermediate directory...\nDone in 27 sec(s).\n\nSource directory     : /tmp/8dc28dad0e10acb\nDestination directory: /home/site/wwwroot\n\n\nDownloading and extracting 'python' version '3.11.7' to '/tmp/oryx/platforms/python/3.11.7'...\nDetected image debian flavor: bullseye.\nDownloaded in 5 sec(s).\nVerifying checksum...\nExtracting contents...\nperforming sha512 checksum for: python...\nDone in 48 sec(s).\n\nimage detector file exists, platform is python..\nOS detector file exists, OS is bullseye..\nPython Version: /tmp/oryx/platforms/python/3.11.7/bin/python3.11\nCreating directory for command manifest file if it does not exist\nRemoving existing manifest file\nPython Virtual Environment: antenv\nCreating virtual environment...\nActivating virtual environment...\nRunning pip install...\n[19:21:31+0000] Collecting aiofiles==23.2.1 (from -r requirements.txt (line 7))\n[19:21:31+0000]   Obtaining dependency information for aiofiles==23.2.1 from https://files.pythonhosted.org/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl.metadata\n[19:21:31+0000]   Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n[19:21:35+0000] Collecting aiohttp==3.9.3 (from -r requirements.txt (line 9))\n[19:21:35+0000]   Obtaining dependency information for aiohttp==3.9.3 from https://files.pythonhosted.org/packages/84/bb/74c9f32e1a76fab04b54ed6cd4b0dc4a07bd9dc6f3bb37f630149a9c3068/aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n[19:21:35+0000]   Downloading aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n[19:21:35+0000] Collecting aiosignal==1.3.1 (from -r requirements.txt (line 11))\n[19:21:35+0000]   Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n[19:21:36+0000] Collecting annotated-types==0.6.0 (from -r requirements.txt (line 13))\n[19:21:36+0000]   Obtaining dependency information for annotated-types==0.6.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n[19:21:36+0000]   Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n[19:21:36+0000] Collecting anyio==4.2.0 (from -r requirements.txt (line 15))\n[19:21:36+0000]   Obtaining dependency information for anyio==4.2.0 from https://files.pythonhosted.org/packages/bf/cd/d6d9bb1dadf73e7af02d18225cbd2c93f8552e13130484f1c8dcfece292b/anyio-4.2.0-py3-none-any.whl.metadata\n[19:21:36+0000]   Downloading anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n[19:21:36+0000] Collecting asgiref==3.7.2 (from -r requirements.txt (line 19))\n[19:21:36+0000]   Obtaining dependency information for asgiref==3.7.2 from https://files.pythonhosted.org/packages/9b/80/b9051a4a07ad231558fcd8ffc89232711b4e618c15cb7a392a17384bbeef/asgiref-3.7.2-py3-none-any.whl.metadata\n[19:21:36+0000]   Downloading asgiref-3.7.2-py3-none-any.whl.metadata (9.2 kB)\n[19:21:36+0000] Collecting attrs==23.2.0 (from -r requirements.txt (line 21))\n[19:21:36+0000]   Obtaining dependency information for attrs==23.2.0 from https://files.pythonhosted.org/packages/e0/44/827b2a91a5816512fcaf3cc4ebc465ccd5d598c45cefa6703fcf4a79018f/attrs-23.2.0-py3-none-any.whl.metadata\n[19:21:36+0000]   Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n[19:21:36+0000] Collecting azure-common==1.1.28 (from -r requirements.txt (line 23))\n[19:21:36+0000]   Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n[19:21:36+0000] Collecting azure-core==1.29.7 (from -r requirements.txt (line 27))\n[19:21:36+0000]   Obtaining dependency information for azure-core==1.29.7 from https://files.pythonhosted.org/packages/ff/29/dbc7182bc207530c7b5858d59f429158465f878845d64a038afc1aa61e35/azure_core-1.29.7-py3-none-any.whl.metadata\n[19:21:36+0000]   Downloading azure_core-1.29.7-py3-none-any.whl.metadata (36 kB)\n[19:21:36+0000] Collecting azure-core-tracing-opentelemetry==1.0.0b11 (from -r requirements.txt (line 37))\n[19:21:36+0000]   Obtaining dependency information for azure-core-tracing-opentelemetry==1.0.0b11 from https://files.pythonhosted.org/packages/e6/6e/3ef6dfba8e0faa4692caa6d103c721ccba6ac37a24744848a3a10bb3fe89/azure_core_tracing_opentelemetry-1.0.0b11-py3-none-any.whl.metadata\n[19:21:36+0000]   Downloading azure_core_tracing_opentelemetry-1.0.0b11-py3-none-any.whl.metadata (8.5 kB)\n[19:21:37+0000] Collecting azure-identity==1.15.0 (from -r requirements.txt (line 39))\n[19:21:37+0000]   Obtaining dependency information for azure-identity==1.15.0 from https://files.pythonhosted.org/packages/30/10/5dbf755b368d10a28d55b06ac1f12512a13e88874a23db82defdea9a8cd9/azure_identity-1.15.0-py3-none-any.whl.metadata\n[19:21:37+0000]   Downloading azure_identity-1.15.0-py3-none-any.whl.metadata (75 kB)\n[19:21:37+0000]      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.4/75.4 kB 6.2 MB/s eta 0:00:00\n[19:21:37+0000] Collecting azure-keyvault-secrets==4.7.0 (from -r requirements.txt (line 41))\n[19:21:37+0000]   Downloading azure_keyvault_secrets-4.7.0-py3-none-any.whl (348 kB)\n[19:21:37+0000]      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 348.6/348.6 kB 19.6 MB/s eta 0:00:00\n[19:21:37+0000] Collecting azure-monitor-opentelemetry==1.2.0 (from -r requirements.txt (line 43))\n[19:21:37+0000]   Obtaining dependency information for azure-monitor-opentelemetry==1.2.0 from https://files.pythonhosted.org/packages/66/72/5a6bac11b8f3bd60825f19c144c4c770c46951165f8ee5fc10ab3eaadf59/azure_monitor_opentelemetry-1.2.0-py3-none-any.whl.metadata\n[19:21:37+0000]   Downloading azure_monitor_opentelemetry-1.2.0-py3-none-any.whl.metadata (19 kB)\n[19:21:37+0000] Collecting azure-monitor-opentelemetry-exporter==1.0.0b21 (from -r requirements.txt (line 45))\n[19:21:37+0000]   Obtaining dependency information for azure-monitor-opentelemetry-exporter==1.0.0b21 from https://files.pythonhosted.org/packages/4a/0d/18cb0da98b49c9a6724f6cae46a7e59b8325cda476bde13b64404a428ae8/azure_monitor_opentelemetry_exporter-1.0.0b21-py2.py3-none-any.whl.metadata\n[19:21:37+0000]   Downloading azure_monitor_opentelemetry_exporter-1.0.0b21-py2.py3-none-any.whl.metadata (31 kB)\n[19:21:37+0000] Collecting azure-search-documents==11.6.0b1 (from -r requirements.txt (line 47))\n[19:21:37+0000]   Obtaining dependency information for azure-search-documents==11.6.0b1 from https://files.pythonhosted.org/packages/7c/f6/b138d9a252f80db69c052c65410bc972dca375e29c71c472e27d0bae327d/azure_search_documents-11.6.0b1-py3-none-any.whl.metadata\n[19:21:37+0000]   Downloading azure_search_documents-11.6.0b1-py3-none-any.whl.metadata (23 kB)\n[19:21:37+0000] Collecting azure-storage-blob==12.19.0 (from -r requirements.txt (line 49))\n[19:21:37+0000]   Obtaining dependency information for azure-storage-blob==12.19.0 from https://files.pythonhosted.org/packages/f6/82/24b0d7cf67ea63af86f11092756b8fe2adc1d55323241dc4107f5f5748e2/azure_storage_blob-12.19.0-py3-none-any.whl.metadata\n[19:21:37+0000]   Downloading azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\n[19:21:37+0000] Collecting blinker==1.7.0 (from -r requirements.txt (line 51))\n[19:21:37+0000]   Obtaining dependency information for blinker==1.7.0 from https://files.pythonhosted.org/packages/fa/2a/7f3714cbc6356a0efec525ce7a0613d581072ed6eb53eb7b9754f33db807/blinker-1.7.0-py3-none-any.whl.metadata\n[19:21:37+0000]   Downloading blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n[19:21:37+0000] Collecting certifi==2023.11.17 (from -r requirements.txt (line 55))\n[19:21:37+0000]   Obtaining dependency information for certifi==2023.11.17 from https://files.pythonhosted.org/packages/64/62/428ef076be88fa93716b576e4a01f919d25968913e817077a386fcbe4f42/certifi-2023.11.17-py3-none-any.whl.metadata\n```\n\n----------------------------------------\n\nTITLE: Choosing Azure Speech Service Voice for Speech Output - Shell\nDESCRIPTION: This shell command sets the AZURE_SPEECH_SERVICE_VOICE environment variable for Azure Speech Service, allowing custom selection of the TTS (text-to-speech) output voice. Must use a supported voice name according to Azure documentation. Only used when Azure Speech Service output is enabled; changing voice may affect language or accent.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SPEECH_SERVICE_VOICE en-US-AndrewMultilingualNeural\n```\n\n----------------------------------------\n\nTITLE: Logging in Flask Route Handler Using current_app.logger in Python\nDESCRIPTION: This snippet demonstrates how to emit an informational log message from within an asynchronous Flask route handler using the 'current_app' logger. It is intended for in-request logging, with 'current_app' providing app context. Requires Flask and asynchronous route setup; logs are emitted with level 'INFO' and are visible if configured according to prior logging setup.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/appservice.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nasync def chat():\\n    current_app.logger.info(\"Received /chat request\")\n```\n\n----------------------------------------\n\nTITLE: Setting Azure Cosmos DB SKU to Free Tier with AZD\nDESCRIPTION: Configures the Azure Developer CLI (`azd`) environment to provision Azure Cosmos DB using the 'free' tier SKU by setting the `AZURE_COSMOSDB_SKU` variable. This eliminates Cosmos DB costs but limits throughput and storage, and only one free Cosmos DB account is allowed per Azure subscription.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_COSMOSDB_SKU free\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Project Dependencies in requirements.txt\nDESCRIPTION: This requirements file lists the necessary Python packages for the 'azure-search-openai-demo' project. It includes specific versions for packages like 'dotenv-azd', 'ragas', 'rapidfuzz', and 'langchain', leaves 'rich' unpinned, and fetches a dependency directly from a specific commit on a GitHub repository ('ai-rag-chat-evaluator'). This file is typically used with 'pip install -r <filename>' to set up the project environment.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/evals/requirements.txt#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ndotenv-azd==0.2.0\nrich\nragas==0.2.13\nrapidfuzz==3.12.1\nlangchain==0.3.17\ngit+https://github.com/Azure-Samples/ai-rag-chat-evaluator.git@2025-02-06b\n```\n\n----------------------------------------\n\nTITLE: Removing All Group Access Control Lists from a Document in Azure Search using Python\nDESCRIPTION: Uses the `manageacl.py` script to remove all group IDs associated with a specific document (identified by its URL) in the Azure AI Search index. Requires environment setup and activated Python environment. The `-v` flag enables verbose logging.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\npython ./scripts/manageacl.py -v --acl-type groups --acl-action remove_all --url https://st12345.blob.core.windows.net/content/Benefit_Options.pdf\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for o3-mini Reasoning Model using AZD (Shell)\nDESCRIPTION: This snippet demonstrates how to configure the Azure Search OpenAI demo application to use the 'o3-mini' reasoning model. It uses the Azure Developer CLI (`azd`) to set specific environment variables related to the Azure OpenAI chat model, deployment name, version, SKU, and API version.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/reasoning.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_MODEL o3-mini\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT o3-mini\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_VERSION 2025-01-31\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_SKU GlobalStandard\nazd env set AZURE_OPENAI_API_VERSION 2024-12-01-preview\n```\n\n----------------------------------------\n\nTITLE: Starting Dev Server on Linux/Mac (Bash)\nDESCRIPTION: Executes the shell script located at `./app/start.sh` to start the local development server for the application on a Linux or macOS machine. This script typically handles backend setup and startup.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/localdev.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n./app/start.sh\n```\n\n----------------------------------------\n\nTITLE: Starting Frontend Dev Server with Hot Reload (npm)\nDESCRIPTION: Runs the `dev` script defined in the frontend project's `package.json` using npm. This typically starts the Vite development server, enabling hot module replacement for frontend code changes without requiring manual browser refreshes.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/localdev.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Configuring Known Client Applications in Server App Manifest (JSON)\nDESCRIPTION: This JSON snippet shows how to modify the server application's manifest in Microsoft Entra ID. By adding the client application's ID to the `knownClientApplications` array, the server app pre-authorizes the client app. This step is necessary for the On-Behalf-Of flow, allowing the client app to request tokens for the server API on behalf of the user without requiring separate consent for the server app.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n\"knownClientApplications\": [\"<client application id>\"]\n```\n\n----------------------------------------\n\nTITLE: Running Full Deployment with AZD CLI\nDESCRIPTION: Executes the standard Azure Developer CLI command `azd up`, which typically provisions Azure resources and deploys the application code in one step. The surrounding text notes that for private endpoint deployments, this command alone is insufficient and additional steps outlined in a separate guide are required.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_27\n\nLANGUAGE: shell\nCODE:\n```\nazd up\n```\n\n----------------------------------------\n\nTITLE: Deploying Configuration Changes - azd CLI - Bash\nDESCRIPTION: This command applies the changes made to environment settings by running the full deployment. The command will provision resources, update configurations, and (re)deploy services as needed according to the current environment state and specified variables.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nazd up\n```\n\n----------------------------------------\n\nTITLE: Configuring Ollama Base URL in Dev Container (azd)\nDESCRIPTION: Sets the `OPENAI_BASE_URL` environment variable using `azd` to point to a local Ollama server from within a VS Code Dev Container. Uses `http://host.docker.internal:11434/v1` to access the host machine's service. Requires restarting the local dev server.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/localdev.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nazd env set OPENAI_BASE_URL http://host.docker.internal:11434/v1\n```\n\n----------------------------------------\n\nTITLE: Configuring Llamafile Base URL in Dev Container (azd)\nDESCRIPTION: Sets the `OPENAI_BASE_URL` environment variable using `azd` to point to a local llamafile server from within a VS Code Dev Container. Uses `http://host.docker.internal:8080/v1` to access the host machine's service on the default port. Requires restarting the local dev server.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/localdev.md#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nazd env set OPENAI_BASE_URL http://host.docker.internal:8080/v1\n```\n\n----------------------------------------\n\nTITLE: Updating Azure Resources with AZD Provision\nDESCRIPTION: Executes the Azure Developer CLI (`azd`) command `azd provision`. This command is used to provision or update the Azure resources defined for the application. In this context, it's required after setting environment variables for local parsers (`USE_LOCAL_PDF_PARSER`, `USE_LOCAL_HTML_PARSER`) to apply these configuration changes to the deployed web application, ensuring the user document upload system also uses the specified local parsers.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_30\n\nLANGUAGE: shell\nCODE:\n```\nazd provision\n```\n\n----------------------------------------\n\nTITLE: Running End-to-End Tests with Playwright\nDESCRIPTION: Executes the end-to-end tests located in `tests/e2e.py` using `pytest` and Playwright. The `--tracing=retain-on-failure` flag ensures that detailed trace files are saved if a test fails, aiding debugging.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/CONTRIBUTING.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\npython -m pytest tests/e2e.py --tracing=retain-on-failure\n```\n\n----------------------------------------\n\nTITLE: Setting ADLS Gen2 Storage Account Environment Variable using AZD CLI\nDESCRIPTION: This command uses the Azure Developer CLI (`azd`) to set the `AZURE_ADLS_GEN2_STORAGE_ACCOUNT` environment variable. This variable specifies the name of the Azure Data Lake Storage Gen2 account used by the `prepdocs` process. Setting this is crucial before running `azd up` for the first time to ensure the search index is initialized with access control support.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_ADLS_GEN2_STORAGE_ACCOUNT <YOUR-STORAGE_ACCOUNT>\n```\n\n----------------------------------------\n\nTITLE: Viewing Playwright Test Trace\nDESCRIPTION: Opens the Playwright trace viewer tool to display a saved trace file (`<trace-zip>`) located in the `test-results` directory. This allows interactive debugging of failed E2E tests.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/CONTRIBUTING.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nplaywright show-trace test-results/<trace-zip>\n```\n\n----------------------------------------\n\nTITLE: Retrieving Signed-in Azure User ID (Azure CLI)\nDESCRIPTION: Uses the Azure CLI (`az`) to display details for the currently logged-in Azure Active Directory user. The output typically includes the user's object ID (principal ID), which is required for setting the `AZURE_PRINCIPAL_ID` environment variable for role assignments.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/sharing_environments.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\naz ad signed-in-user show\n```\n\n----------------------------------------\n\nTITLE: Installing Locust for Load Testing with Python\nDESCRIPTION: These code snippets show two alternative approaches to install Locust, a Python-based load testing tool, either via a requirements file or directly. The first command installs all required developer dependencies including Locust from `requirements-dev.txt`, while the second directly installs Locust system-wide. The host system must have Python and pip installed first. These steps are prerequisites before running load tests with Locust.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/productionizing.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\npython -m pip install -r requirements-dev.txt\n```\n\nLANGUAGE: shell\nCODE:\n```\npython -m pip install locust\n```\n\n----------------------------------------\n\nTITLE: Overriding Retrieval Mode in Backend Approach - Python\nDESCRIPTION: This code snippet demonstrates modifying backend behavior by changing the retrieval mode override in the context dictionary within a backend approach class. It assumes context is a dictionary that may contain another dictionary under the 'overrides' key. This override will ensure that subsequent processing uses text-based retrieval. Dependencies: accessible 'context' variable (provided as a function argument). Used within backend methods such as run functions in the approach classes under app/backend/approaches.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/customization.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\noverrides = context.get(\"overrides\", {})\noverrides[\"retrieval_mode\"] = \"text\"\n```\n\n----------------------------------------\n\nTITLE: Disabling Vector Search with AZD\nDESCRIPTION: Configures the Azure Developer CLI (`azd`) environment to disable vector search functionality by setting the `USE_VECTORS` variable to `false`. This avoids costs associated with computing embeddings but results in the application using only keyword search, potentially impacting search relevance.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_VECTORS false\n```\n\n----------------------------------------\n\nTITLE: Enabling Local PDF Parsing with AZD\nDESCRIPTION: Configures the application, via the `USE_LOCAL_PDF_PARSER` Azure Developer CLI (`azd`) environment variable, to use a local Python library for parsing PDF documents instead of Azure Document Intelligence. This serves as a workaround for the free-tier page limit but requires local Python dependencies for the data preparation process.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_LOCAL_PDF_PARSER true\n```\n\n----------------------------------------\n\nTITLE: Initializing Retrieval Mode with React useState - TypeScript\nDESCRIPTION: This snippet initializes the retrieval mode state in a React component using the useState hook, setting its default value to RetrievalMode.Hybrid. It requires React and an enum or object RetrievalMode to be defined with at least a Hybrid member. The parameters are: the current retrievalMode state and its setter setRetrievalMode. This code influences how data is retrieved in the chat app and appears in Chat.tsx or Ask.tsx files. To use, ensure the RetrievalMode enum contains relevant options like Hybrid and Text.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/customization.md#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst [retrievalMode, setRetrievalMode] = useState<RetrievalMode>(RetrievalMode.Hybrid);\n```\n\n----------------------------------------\n\nTITLE: Setting Azure OpenAI Deployment Capacity - azd CLI - Bash\nDESCRIPTION: This command sets the deployment capacity for the Azure OpenAI instance in thousands of tokens per minute (TPM). The environment variable accepts an integer (default is 30). Adjust as needed for projected workload. The example sets a capacity of 20k tokens per minute.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_CAPACITY 20\n```\n\n----------------------------------------\n\nTITLE: Initializing Retrieval Mode to Text with React useState - TypeScript\nDESCRIPTION: This variant sets the initial retrieval mode in a React component to RetrievalMode.Text, which alters the search behavior to be text-only. The implementation requires React and the RetrievalMode enum with a Text option. The snippet modifies application defaults by changing a single argument, making it easy to change retrieval strategies. Used in UI logic to affect RAG search operations.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/customization.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst [retrievalMode, setRetrievalMode] = useState<RetrievalMode>(RetrievalMode.Text);\n```\n\n----------------------------------------\n\nTITLE: Setting Default Reasoning Effort using AZD (Shell)\nDESCRIPTION: This optional configuration step uses the Azure Developer CLI (`azd`) to set the default reasoning effort for the deployed model. The `AZURE_OPENAI_REASONING_EFFORT` environment variable can be set to 'low', 'medium', or 'high', defaulting to 'medium' if not explicitly set. This controls how much processing the model performs.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/reasoning.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_REASONING_EFFORT medium\n```\n\n----------------------------------------\n\nTITLE: Provisioning Azure AI Resources Using AZD (Shell)\nDESCRIPTION: This shell command provisions the Azure AI project and related resources using Azure Developer CLI (azd) after the environment is configured. It has no required parameters and is intended to be run from the project root. Running this command creates all necessary cloud resources for the evaluation scripts to function.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/safety_evaluation.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nazd provision\n```\n\n----------------------------------------\n\nTITLE: Configuring Semantic Search with Azure AI Search - JSON\nDESCRIPTION: This JSON snippet demonstrates how to configure a semantic search query for Azure AI Search, specifying the search text, semantic configuration, language, spelling mode, and number of results. The payload must be sent to the Azure AI Search API endpoint, and requires a properly configured index and semantic ranking enabled. The 'top' parameter controls the number of results, while 'queryLanguage' and 'speller' help refine query interpretation and correction. Input is a JSON query object, and the output is a set of search results reordered using semantic ranking.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/customization.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\\n  \\\"search\\\": \\\"eye exams\\\",\\n  \\\"queryType\\\": \\\"semantic\\\",\\n  \\\"semanticConfiguration\\\": \\\"default\\\",\\n  \\\"queryLanguage\\\": \\\"en-us\\\",\\n  \\\"speller\\\": \\\"lexicon\\\",\\n  \\\"top\\\": 3\\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Language Picker Feature - Shell\nDESCRIPTION: The command enables a multi-language interface in the application by setting ENABLE_LANGUAGE_PICKER to 'true' via azd. The feature requires locale files configured in 'app/frontend/src/i18n/config.ts' for each supported language. Only UI-facing users with this environment variable set can select languages in the frontend.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nazd env set ENABLE_LANGUAGE_PICKER true\n```\n\n----------------------------------------\n\nTITLE: Initial Deployment with Private Endpoints and Public Access Enabled using AZD\nDESCRIPTION: Sets Azure Developer CLI (azd) environment variables to enable private endpoints (`AZURE_USE_PRIVATE_ENDPOINT=true`) while keeping public network access enabled (`AZURE_PUBLIC_NETWORK_ACCESS=Enabled`). It then initiates the deployment and provisioning process using `azd up`. This is the first step in the recommended private access strategy, allowing for initial validation from the internet.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_private.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_USE_PRIVATE_ENDPOINT true\nazd env set AZURE_PUBLIC_NETWORK_ACCESS Enabled\nazd up\n```\n\n----------------------------------------\n\nTITLE: Installing Git Pre-commit Hooks\nDESCRIPTION: Sets up pre-commit hooks using the `pre-commit` tool. These hooks automatically run checks (like linting and formatting) before each commit, ensuring code quality and consistency.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/CONTRIBUTING.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npre-commit install\n```\n\n----------------------------------------\n\nTITLE: Setting Server App Secret Environment Variable using AZD CLI\nDESCRIPTION: This command utilizes the Azure Developer CLI (`azd`) to store the generated client secret for the server application in an environment variable named `AZURE_SERVER_APP_SECRET`. This secret is used by the server application to authenticate itself when requesting tokens or accessing other resources.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SERVER_APP_SECRET <generated key value>\n```\n\n----------------------------------------\n\nTITLE: Installing Python Development Dependencies\nDESCRIPTION: Installs the necessary Python packages required for development, listed in the `requirements-dev.txt` file. This command should be run within the project's Python environment to set up tools for testing, linting, and formatting.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/CONTRIBUTING.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npython -m pip install -r requirements-dev.txt\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI Deployment SKU - azd CLI - Bash\nDESCRIPTION: These commands set the deployment SKU (pricing tier) for the Azure OpenAI deployment through the `azd` CLI. Choose between 'GlobalStandard' and 'Standard' according to your subscription and deployment scale requirements. The `AZURE_OPENAI_CHATGPT_DEPLOYMENT_SKU` environment variable controls the SKU for subsequent deployments.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_SKU GlobalStandard\n```\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_SKU Standard\n```\n\n----------------------------------------\n\nTITLE: Running Python Unit Tests\nDESCRIPTION: Executes the project's unit tests using the `pytest` framework. This command discovers and runs tests within the Python environment to verify the correctness of individual components.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/CONTRIBUTING.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npython -m pytest\n```\n\n----------------------------------------\n\nTITLE: Installing Playwright Browser Dependencies\nDESCRIPTION: Installs the necessary browser binaries and operating system dependencies required by Playwright for running end-to-end tests across different browsers.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/CONTRIBUTING.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nplaywright install --with-deps\n```\n\n----------------------------------------\n\nTITLE: Highlighting Search Results in Azure AI Search - JSON\nDESCRIPTION: This JSON snippet provides an example of configuring Azure AI Search to utilize the 'highlight' feature. By specifying the 'highlight' parameter with a field name (e.g., 'content'), the search results will return markup indicating which parts of the field matched the query. Useful for front-end display and debugging relevance of results. The snippet should be used in the JSON view of the Azure AI Search explorer, and requires that the 'content' field exists in the index schema.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/customization.md#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\\n    \\\"search\\\": \\\"eye exams\\\",\\n    \\\"highlight\\\": \\\"content\\\"\\n    ...\\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure AI Project Environment with AZD (Shell)\nDESCRIPTION: This shell command sets the 'USE_AI_PROJECT' environment variable to 'true' using the Azure Developer CLI (azd) for configuring your project to use Azure AI resources within an Azure AI Hub. There are no required parameters. This prepares the environment for provisioning and is a prerequisite for subsequent deployment steps.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/safety_evaluation.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_AI_PROJECT true\n```\n\n----------------------------------------\n\nTITLE: Enabling Storage ACLs in Search Index - Python\nDESCRIPTION: Runs a Python script ('manageacl.py') with verbose logging and the 'enable_acls' action to update storage ACLs in the search index. Requires Python, the script, and relevant Azure SDK dependencies. Intended for enabling index-based access controls after enabling user uploads.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_21\n\nLANGUAGE: python\nCODE:\n```\npython ./scripts/manageacl.py  -v --acl-action enable_acls\n```\n\n----------------------------------------\n\nTITLE: Formatting Python File with Black\nDESCRIPTION: Runs the `black` code formatter on a specified Python file (`<path-to-file>`). Black automatically reformats the code to comply with its opinionated style guide.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/CONTRIBUTING.md#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\npython -m black <path-to-file>\n```\n\n----------------------------------------\n\nTITLE: Installing Python Development Dependencies for Code Style Checks\nDESCRIPTION: Installs Python development dependencies from `requirements-dev.txt`, specifically highlighting the need for tools like `ruff` and `black` for code style enforcement. This command ensures the necessary linters and formatters are available.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/CONTRIBUTING.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\npython -m pip install -r requirements-dev.txt\n```\n\n----------------------------------------\n\nTITLE: Capturing pip Installation Log Output for Python Dependencies\nDESCRIPTION: This log output shows the steps taken by the pip package manager while installing dependencies from a requirements.txt file. It includes obtaining dependency information from PyPI and downloading package files like certifi, cffi, flask, cryptography, numpy, oauthlib, and others, indicating the specific versions being installed for the project.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/appservice.md#_snippet_1\n\nLANGUAGE: log\nCODE:\n```\n[19:21:37+0000]   Downloading certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n[19:21:39+0000] Collecting cffi==1.16.0 (from -r requirements.txt (line 61))\n[19:21:39+0000]   Obtaining dependency information for cffi==1.16.0 from https://files.pythonhosted.org/packages/9b/89/a31c81e36bbb793581d8bba4406a8aac4ba84b2559301c44eef81f4cf5df/cffi-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n[19:21:39+0000]   Downloading cffi-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n[19:21:40+0000] Collecting charset-normalizer==3.3.2 (from -r requirements.txt (line 63))\n[19:21:40+0000]   Obtaining dependency information for charset-normalizer==3.3.2 from https://files.pythonhosted.org/packages/40/26/f35951c45070edc957ba40a5b1db3cf60a9dbb1b350c2d5bef03e01e61de/charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n[19:21:40+0000]   Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n[19:21:40+0000] Collecting click==8.1.7 (from -r requirements.txt (line 65))\n[19:21:40+0000]   Obtaining dependency information for click==8.1.7 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n[19:21:40+0000]   Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n[19:21:43+0000] Collecting cryptography==42.0.1 (from -r requirements.txt (line 70))\n[19:21:43+0000]   Obtaining dependency information for cryptography==42.0.1 from https://files.pythonhosted.org/packages/f8/46/2776ca9b602f79633fdf69824b5e18c94f2e0c5f09a94fc69e5b0887c14d/cryptography-42.0.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata\n[19:21:43+0000]   Downloading cryptography-42.0.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n[19:21:43+0000] Collecting deprecated==1.2.14 (from -r requirements.txt (line 78))\n[19:21:43+0000]   Obtaining dependency information for deprecated==1.2.14 from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n[19:21:43+0000]   Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n[19:21:43+0000] Collecting distro==1.9.0 (from -r requirements.txt (line 80))\n[19:21:43+0000]   Obtaining dependency information for distro==1.9.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n[19:21:44+0000]   Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n[19:21:44+0000] Collecting ecdsa==0.18.0 (from -r requirements.txt (line 82))\n[19:21:44+0000]   Downloading ecdsa-0.18.0-py2.py3-none-any.whl (142 kB)\n[19:21:44+0000]      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.9/142.9 kB 3.7 MB/s eta 0:00:00\n[19:21:44+0000] Collecting fixedint==0.1.6 (from -r requirements.txt (line 84))\n[19:21:44+0000]   Downloading fixedint-0.1.6-py3-none-any.whl (12 kB)\n[19:21:45+0000] Collecting flask==3.0.1 (from -r requirements.txt (line 86))\n[19:21:45+0000]   Obtaining dependency information for flask==3.0.1 from https://files.pythonhosted.org/packages/bd/0e/63738e88e981ae57c23bad6c499898314a1110a4141f77d7bd929b552fb4/flask-3.0.1-py3-none-any.whl.metadata\n[19:21:45+0000]   Downloading flask-3.0.1-py3-none-any.whl.metadata (3.6 kB)\n[19:21:47+0000] Collecting frozenlist==1.4.1 (from -r requirements.txt (line 88))\n[19:21:47+0000]   Obtaining dependency information for frozenlist==1.4.1 from https://files.pythonhosted.org/packages/b3/c9/0bc5ee7e1f5cc7358ab67da0b7dfe60fbd05c254cea5c6108e7d1ae28c63/frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n[19:21:47+0000]   Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n[19:21:47+0000] Collecting h11==0.14.0 (from -r requirements.txt (line 92))\n[19:21:47+0000]   Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n[19:21:47+0000]      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 2.5 MB/s eta 0:00:00\n[19:21:48+0000] Collecting h2==4.1.0 (from -r requirements.txt (line 98))\n[19:21:48+0000]   Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n[19:21:48+0000]      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 627.9 kB/s eta 0:00:00\n[19:21:48+0000] Collecting hpack==4.0.0 (from -r requirements.txt (line 100))\n[19:21:48+0000]   Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n[19:21:49+0000] Collecting httpcore==1.0.2 (from -r requirements.txt (line 102))\n[19:21:49+0000]   Obtaining dependency information for httpcore==1.0.2 from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n[19:21:49+0000]   Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n[19:21:50+0000] Collecting httpx==0.26.0 (from -r requirements.txt (line 104))\n[19:21:50+0000]   Obtaining dependency information for httpx==0.26.0 from https://files.pythonhosted.org/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl.metadata\n[19:21:50+0000]   Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n[19:21:50+0000] Collecting hypercorn==0.16.0 (from -r requirements.txt (line 106))\n[19:21:50+0000]   Obtaining dependency information for hypercorn==0.16.0 from https://files.pythonhosted.org/packages/17/9e/700d764316399c20fbe8e98c6fff903b5d3f950043cc2fcbd0831a42c953/hypercorn-0.16.0-py3-none-any.whl.metadata\n[19:21:50+0000]   Downloading hypercorn-0.16.0-py3-none-any.whl.metadata (5.4 kB)\n[19:21:50+0000] Collecting hyperframe==6.0.1 (from -r requirements.txt (line 108))\n[19:21:50+0000]   Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n[19:21:51+0000] Collecting idna==3.6 (from -r requirements.txt (line 110))\n[19:21:51+0000]   Obtaining dependency information for idna==3.6 from https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl.metadata\n[19:21:51+0000]   Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n[19:21:51+0000] Collecting importlib-metadata==6.11.0 (from -r requirements.txt (line 116))\n[19:21:51+0000]   Obtaining dependency information for importlib-metadata==6.11.0 from https://files.pythonhosted.org/packages/59/9b/ecce94952ab5ea74c31dcf9ccf78ccd484eebebef06019bf8cb579ab4519/importlib_metadata-6.11.0-py3-none-any.whl.metadata\n[19:21:51+0000]   Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n[19:21:52+0000] Collecting isodate==0.6.1 (from -r requirements.txt (line 118))\n[19:21:52+0000]   Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n[19:21:52+0000]      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.7/41.7 kB 1.8 MB/s eta 0:00:00\n[19:21:52+0000] Collecting itsdangerous==2.1.2 (from -r requirements.txt (line 124))\n[19:21:52+0000]   Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n[19:21:52+0000] Collecting jinja2==3.1.3 (from -r requirements.txt (line 128))\n[19:21:52+0000]   Obtaining dependency information for jinja2==3.1.3 from https://files.pythonhosted.org/packages/30/6d/6de6be2d02603ab56e72997708809e8a5b0fbfee080735109b40a3564843/Jinja2-3.1.3-py3-none-any.whl.metadata\n[19:21:52+0000]   Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n[19:21:53+0000] Collecting markupsafe==2.1.4 (from -r requirements.txt (line 132))\n[19:21:53+0000]   Obtaining dependency information for markupsafe==2.1.4 from https://files.pythonhosted.org/packages/d3/0a/c6dfffacc5a9a17c97019cb7cbec67e5abfb65c59a58ecba270fa224f88d/MarkupSafe-2.1.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n[19:21:53+0000]   Downloading MarkupSafe-2.1.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n[19:21:53+0000] Collecting msal==1.26.0 (from -r requirements.txt (line 137))\n[19:21:53+0000]   Obtaining dependency information for msal==1.26.0 from https://files.pythonhosted.org/packages/b7/61/2756b963e84db6946e4b93a8e288595106286fc11c7129fcb869267ead67/msal-1.26.0-py2.py3-none-any.whl.metadata\n[19:21:53+0000]   Downloading msal-1.26.0-py2.py3-none-any.whl.metadata (11 kB)\n[19:21:54+0000] Collecting msal-extensions==1.1.0 (from -r requirements.txt (line 142))\n[19:21:54+0000]   Obtaining dependency information for msal-extensions==1.1.0 from https://files.pythonhosted.org/packages/78/8d/ecd0eb93196f25c722ba1b923fd54d190366feccfa5b159d48dacf2b1fee/msal_extensions-1.1.0-py3-none-any.whl.metadata\n[19:21:54+0000]   Downloading msal_extensions-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n[19:21:54+0000] Collecting msrest==0.7.1 (from -r requirements.txt (line 144))\n[19:21:54+0000]   Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n[19:21:54+0000]      ━━━━━━━━━━━━━━━━━━━��━━━━━━━━━━━━━━━━━━━━ 85.4/85.4 kB 6.2 MB/s eta 0:00:00\n[19:21:59+0000] Collecting multidict==6.0.4 (from -r requirements.txt (line 146))\n[19:21:59+0000]   Downloading multidict-6.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n[19:21:59+0000]      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.4/117.4 kB 2.2 MB/s eta 0:00:00\n[19:22:05+0000] Collecting numpy==1.26.3 (from -r requirements.txt (line 150))\n[19:22:05+0000]   Obtaining dependency information for numpy==1.26.3 from https://files.pythonhosted.org/packages/5a/62/007b63f916aca1d27f5fede933fda3315d931ff9b2c28b9c2cf388cd8edb/numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n[19:22:05+0000]   Downloading numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n[19:22:05+0000]      ━━━━━━━━━━━━━━━━━━━━━━━━━���━━━━━━━━━━━━━━ 61.2/61.2 kB 5.6 MB/s eta 0:00:00\n[19:22:05+0000] Collecting oauthlib==3.2.2 (from -r requirements.txt (line 155))\n[19:22:05+0000]   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n```\n\n----------------------------------------\n\nTITLE: Setting the OpenAI Chat Completion Deployment Name - azd CLI - Bash\nDESCRIPTION: This snippet sets the Azure OpenAI Chat GPT deployment name in the environment configuration using the `azd` CLI. Replace `<your-deployment-name>` with your chosen deployment name, which must be unique within your Azure OpenAI account. This variable controls which deployed Azure OpenAI chat model instance is used during subsequent deployments.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT <your-deployment-name>\n```\n\n----------------------------------------\n\nTITLE: Enabling Browser-Based Speech Output - Shell\nDESCRIPTION: Sets USE_SPEECH_OUTPUT_BROWSER to 'true' using azd, switching speech synthesis to use the browser's native Speech Synthesis API. Feature requires compatible client browsers and may have limitations compared to Azure's cloud-based approach.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_SPEECH_OUTPUT_BROWSER true\n```\n\n----------------------------------------\n\nTITLE: Setting the Deployment Target Environment Variable - Bash\nDESCRIPTION: This command sets the DEPLOYMENT_TARGET environment variable within the active Azure Developer CLI environment to 'appservice'. This tells downstream provisioning and deployment operations to use Azure App Service as the destination rather than Container Apps or other services. Must be run after creating or selecting the appropriate azd environment.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/azure_app_service.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nazd env set DEPLOYMENT_TARGET appservice\n```\n\n----------------------------------------\n\nTITLE: Disabling Integrated Vectorization in Azure Deployment - Shell\nDESCRIPTION: This shell command disables the integrated vectorization feature by setting the USE_FEATURE_INT_VECTORIZATION environment variable to false in the Azure Developer CLI environment. This step is necessary because the vision-enabled RAG flow is currently incompatible with the integrated vectorization approach. No additional dependencies are required outside of a working Az Developer CLI environment. Key parameter: USE_FEATURE_INT_VECTORIZATION should be set to false to avoid deployment conflicts.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/gpt4v.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_FEATURE_INT_VECTORIZATION false\n```\n\n----------------------------------------\n\nTITLE: Setting Deployment Target to App Service with AZD\nDESCRIPTION: Configures the Azure Developer CLI (`azd`) environment to deploy the application to Azure App Service instead of the default Azure Container Apps. This is achieved by setting the `DEPLOYMENT_TARGET` environment variable to `appservice`, usually as part of a cost-saving strategy.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nazd env set DEPLOYMENT_TARGET appservice\n```\n\n----------------------------------------\n\nTITLE: Disabling Public Access after Initial Validation using AZD\nDESCRIPTION: Sets the Azure Developer CLI (azd) environment variable `AZURE_PUBLIC_NETWORK_ACCESS` to `Disabled` to restrict public internet access. It then re-provisions the Azure resources using `azd provision` to apply the network access change. This step is performed after validating the initial deployment and secures the application within the virtual network.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_private.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_PUBLIC_NETWORK_ACCESS Disabled\nazd provision\n```\n\n----------------------------------------\n\nTITLE: Displaying Full Application Startup Logs in Plaintext\nDESCRIPTION: This snippet shows a complete log output sequence from the application startup process, including environment initialization, dependency setup, and successful activation of the Gunicorn server and worker processes. The log illustrates startup steps such as app command execution, Python version outputs, Oryx script extraction, package initialization, log level settings, and confirmation of application readiness. The logs are in plaintext as read from the Docker logs provided by Azure.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/appservice.md#_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n2024-02-08T19:30:27.900249002Z    _____\\n2024-02-08T19:30:27.900282702Z   /  _  \\\\ __________ _________   ____\\n2024-02-08T19:30:27.900288002Z  /  /_\\\\  \\\\\\___   /  |  \\\\_  __ \\\\\\_/ __ \\\\ \\n2024-02-08T19:30:27.900291902Z /    |    \\\\/    /|  |  /|  | \\\\\\/\\  ___/\\n2024-02-08T19:30:27.900295502Z \\\\____|__  /_____ \\\\____/ |__|    \\\\___  >\\n2024-02-08T19:30:27.900299602Z         \\\\/      \\\\/                  \\\\/\\n2024-02-08T19:30:27.900303402Z A P P   S E R V I C E   O N   L I N U X\\n2024-02-08T19:30:27.900307003Z\\n2024-02-08T19:30:27.900310303Z Documentation: http://aka.ms/webapp-linux\\n2024-02-08T19:30:27.900313903Z Python 3.11.4\\n2024-02-08T19:30:27.900317303Z Note: Any data outside '/home' is not persisted\\n2024-02-08T19:30:32.956710361Z Starting OpenBSD Secure Shell server: sshd.\\n2024-02-08T19:30:33.441385332Z Site's appCommandLine: python3 -m gunicorn main:app\\n2024-02-08T19:30:33.703536564Z Launching oryx with: create-script -appPath /home/site/wwwroot -output /opt/startup/startup.sh -virtualEnvName antenv -defaultApp /opt/defaultsite -userStartupCommand 'python3 -m gunicorn main:app'\\n2024-02-08T19:30:33.703598264Z Found build manifest file at '/home/site/wwwroot/oryx-manifest.toml'. Deserializing it...\\n2024-02-08T19:30:33.703605164Z Build Operation ID: 7440a33100749a32\\n2024-02-08T19:30:33.703609765Z Oryx Version: 0.2.20230707.1, Commit: 0bd28e69919b5e8beba451e8677e3345f0be8361, ReleaseTagName: 20230707.1\\n2024-02-08T19:30:33.712124127Z Output is compressed. Extracting it...\\n2024-02-08T19:30:33.712151827Z Extracting '/home/site/wwwroot/output.tar.gz' to directory '/tmp/8dc28dad0e10acb'...\\n2024-02-08T19:31:08.047051747Z App path is set to '/tmp/8dc28dad0e10acb'\\n2024-02-08T19:31:08.073259604Z Writing output script to '/opt/startup/startup.sh'\\n2024-02-08T19:31:08.431803481Z Using packages from virtual environment antenv located at /tmp/8dc28dad0e10acb/antenv.\\n2024-02-08T19:31:08.431842281Z Updated PYTHONPATH to '/opt/startup/app_logs:/tmp/8dc28dad0e10acb/antenv/lib/python3.11/site-packages'\\n2024-02-08T19:31:11.043306496Z [2024-02-08 19:31:11 +0000] [75] [INFO] Starting gunicorn 20.1.0\\n2024-02-08T19:31:11.060556234Z [2024-02-08 19:31:11 +0000] [75] [INFO] Listening at: http://0.0.0.0:8000 (75)\\n2024-02-08T19:31:11.060586534Z [2024-02-08 19:31:11 +0000] [75] [INFO] Using worker: uvicorn.workers.UvicornWorker\\n2024-02-08T19:31:11.069707155Z [2024-02-08 19:31:11 +0000] [76] [INFO] Booting worker with pid: 76\\n2024-02-08T19:31:11.188073718Z [2024-02-08 19:31:11 +0000] [77] [INFO] Booting worker with pid: 77\\n2024-02-08T19:31:11.415802023Z [2024-02-08 19:31:11 +0000] [78] [INFO] Booting worker with pid: 78\\n2024-02-08T19:32:20.509338341Z [2024-02-08 19:32:20 +0000] [76] [INFO] Started server process [76]\\n2024-02-08T19:32:20.521167526Z [2024-02-08 19:32:20 +0000] [77] [INFO] Started server process [77]\\n2024-02-08T19:32:20.521189626Z [2024-02-08 19:32:20 +0000] [77] [INFO] Waiting for application startup.\\n2024-02-08T19:32:20.521207626Z [2024-02-08 19:32:20 +0000] [78] [INFO] Started server process [78]\\n2024-02-08T19:32:20.521212726Z [2024-02-08 19:32:20 +0000] [78] [INFO] Waiting for application startup.\\n2024-02-08T19:32:20.521217126Z [2024-02-08 19:32:20 +0000] [76] [INFO] Waiting for application startup.\\n2024-02-08T19:32:20.726894213Z [2024-02-08 19:32:20 +0000] [76] [INFO] Application startup complete.\\n2024-02-08T19:32:20.726936214Z [2024-02-08 19:32:20 +0000] [78] [INFO] Application startup complete.\\n2024-02-08T19:32:20.726942614Z [2024-02-08 19:32:20 +0000] [77] [INFO] Application startup complete.\n```\n\n----------------------------------------\n\nTITLE: Setting Container Apps Dedicated Workload Profile with AZD\nDESCRIPTION: Uses the `azd env set` command (shorthand `azd env <key> <value>`) to configure the `AZURE_CONTAINER_APPS_WORKLOAD_PROFILE` environment variable to `D4` in the current `azd` environment. This specifies that the deployment should use the D4 dedicated workload profile for Azure Container Apps, impacting performance and billing compared to the default Consumption plan.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/azure_container_apps.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nazd env AZURE_CONTAINER_APPS_WORKLOAD_PROFILE D4\n```\n\n----------------------------------------\n\nTITLE: Enabling Application Authentication Settings via azd CLI - Shell\nDESCRIPTION: This shell command sets an environment variable to enable authentication in the Azure deployment for the RAG chat app. It uses the azd CLI to set 'AZURE_USE_AUTHENTICATION' to 'true', prompting the login UI and enforcing Microsoft Entra authentication by default when running or deploying the application. The azd CLI must be installed and properly configured for your environment.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_USE_AUTHENTICATION true\n```\n\n----------------------------------------\n\nTITLE: Enabling Azure Search Service Query Rewriting - Shell\nDESCRIPTION: Activates the query rewriting feature of Azure Search by setting AZURE_SEARCH_QUERY_REWRITING to 'true'. Feature only works if semantic ranker is enabled and region is supported. This impacts how search queries are processed and rewritten.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_26\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_QUERY_REWRITING true\n```\n\n----------------------------------------\n\nTITLE: Setting up Azure Data Lake Storage Gen2 with Sample Data and ACLs using Python\nDESCRIPTION: Executes the `adlsgen2setup.py` script to upload sample data (from `./data/*`) to the configured ADLS Gen2 storage account, create necessary directories and groups, and apply access control lists defined in `./scripts/sampleacls.json`. Requires the `AZURE_ADLS_GEN2_STORAGE_ACCOUNT` environment variable to be set, the `Storage Blob Data Owner` role assigned, and the Python environment activated. The `-v` flag enables verbose logging.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\npython /scripts/adlsgen2setup.py './data/*' --data-access-control './scripts/sampleacls.json' -v\n```\n\n----------------------------------------\n\nTITLE: Starting Application Development Server (Windows) - PowerShell\nDESCRIPTION: This PowerShell script starts the application server locally on Windows systems. The script must have execution permissions and be run after successful deployment (i.e., after 'azd up'). Assumes all prerequisites are installed and environment variables correctly configured. Starts local development for testing or debugging.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/README.md#_snippet_6\n\nLANGUAGE: powershell\nCODE:\n```\n./app/start.ps1\n```\n\n----------------------------------------\n\nTITLE: Starting Dev Server on Windows (PowerShell)\nDESCRIPTION: Executes the PowerShell script located at `./app/start.ps1` to start the local development server for the application on a Windows machine. This script typically handles backend setup and startup.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/localdev.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n./app/start.ps1\n```\n\n----------------------------------------\n\nTITLE: Setting Server App ID Environment Variable using AZD CLI\nDESCRIPTION: This command uses the Azure Developer CLI (`azd`) to set an environment variable named `AZURE_SERVER_APP_ID`. This variable stores the Application (client) ID obtained from the Microsoft Entra ID registration of the server-side application. This ID is essential for identifying the server application during authentication flows.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SERVER_APP_ID <Application (client) ID>\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment for Generic Local LLM (azd)\nDESCRIPTION: Uses the Azure Developer CLI (`azd`) to set environment variables for configuring the application to use a generic local OpenAI-compatible LLM server. Requires setting `USE_VECTORS` to false, `OPENAI_HOST` to local, providing the local API endpoint `OPENAI_BASE_URL`, and specifying a `AZURE_OPENAI_CHATGPT_MODEL` name. Requires restarting the local dev server.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/localdev.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_VECTORS false\nazd env set OPENAI_HOST local\nazd env set OPENAI_BASE_URL <your local endpoint>\nazd env set AZURE_OPENAI_CHATGPT_MODEL local-model-name\n```\n\n----------------------------------------\n\nTITLE: Building Frontend JavaScript Application\nDESCRIPTION: Navigates into the frontend application directory (`./app/frontend`), installs Node.js dependencies using npm, and then builds the JavaScript application. This compiles the frontend code for development or deployment.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/CONTRIBUTING.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n( cd ./app/frontend ; npm install ; npm run build )\n```\n\n----------------------------------------\n\nTITLE: Starting Application Development Server (Linux/Mac) - Shell\nDESCRIPTION: Runs the shell script to start the application's local development server on Linux or Mac. Prerequisite: deployment must have been completed previously. The script should have execute permissions ('chmod +x'). It launches the development server for local access and debugging.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/README.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n./app/start.sh\n```\n\n----------------------------------------\n\nTITLE: Executing Bulk RAG Evaluation - Python (Shell Command)\nDESCRIPTION: This command initiates bulk evaluation of RAG answers by running the evaluate.py script. It evaluates generated questions against a live application, configurable via command-line options and eval_config.json. Requires prior ground truth data, configured dependencies, and a running evaluation target. Generates evaluation results in a timestamped directory under evals/results.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/evaluation.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npython evals/evaluate.py\n```\n\n----------------------------------------\n\nTITLE: Enabling Document Level Access Control Fields in Azure Search Index using Python\nDESCRIPTION: Executes the `manageacl.py` script to add the necessary `oids`, `groups`, and `storageUrl` fields to the configured Azure AI Search index, enabling document-level access control based on user and group IDs. Requires `AZURE_SEARCH_SERVICE` and `AZURE_SEARCH_INDEX` environment variables to be set and the Python virtual environment activated. The `-v` flag enables verbose logging.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\npython ./scripts/manageacl.py -v --acl-action enable_acls\n```\n\n----------------------------------------\n\nTITLE: Querying Filenames in Azure AI Search (JSON)\nDESCRIPTION: Returns all filenames indexed in Azure AI Search, including document counts and the 'sourcefile' facet. No external dependencies are required other than access to Azure AI Search's REST API. The 'search' parameter with wildcard retrieves all documents, 'count' returns the total count, 'top' limits results to 1 (since the intent here is examining facets), and 'facets' groups results by filename. Useful for verifying uploads or auditing indexed files.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/data_ingestion.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\\n  \\\"search\\\": \\\"*\\\",\\n  \\\"count\\\": true,\\n  \\\"top\\\": 1,\\n  \\\"facets\\\": [\\\"sourcefile\\\"]\\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a New AZD Environment\nDESCRIPTION: Creates a new named environment for the Azure Developer CLI (`azd`). This environment isolates configuration settings, like resource group names and variable values, typically stored in a `.azure/<env_name>` folder. It prompts the user to enter a name for the environment.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nazd env new\n```\n\n----------------------------------------\n\nTITLE: Refreshing AZD Environment Settings (Shell)\nDESCRIPTION: Refreshes the local Azure Developer CLI (azd) environment using details from an existing Azure deployment. It requires the target azd environment name (`-e {environment name}`), and prompts for the subscription ID and location if not already configured. This command populates the local `.azure/{env name}/.env` file with necessary configuration details.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/sharing_environments.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nazd env refresh -e {environment name}\n```\n\n----------------------------------------\n\nTITLE: Simulating Adversarial User Evaluation with Python (Shell Invocation)\nDESCRIPTION: This shell command launches a Python script (evals/safety_evaluation.py) to simulate adversarial queries and evaluate the safety of RAG-generated answers. The required parameters are '--target_url' (the endpoint to test, defaulting to 'http://localhost:50505/chat') and '--max_simulations' (number of user simulations, default 200). The script expects a reachable endpoint and will write results to a JSON report.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/safety_evaluation.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\npython evals/safety_evaluation.py --target_url <TARGET_URL> --max_simulations <MAX_RESULTS>\n```\n\n----------------------------------------\n\nTITLE: Enabling Access Control on Existing Index with manageacl.py - Python\nDESCRIPTION: This Python command executes the manageacl.py script to enable Access Control Lists (ACLs) on an already existing Azure Cognitive Search index. The script is run from the scripts directory and the '--acl-action enable_acls' argument specifically enables access control. This operation requires Python, script dependencies, and proper credentials configured for index management.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npython ./scripts/manageacl.py --acl-action enable_acls\n```\n\n----------------------------------------\n\nTITLE: Setting App Service SKU to Free Tier (F1) with AZD\nDESCRIPTION: Sets the Azure App Service pricing tier (SKU) to 'F1' (Free) within the active Azure Developer CLI (`azd`) environment using the `AZURE_APP_SERVICE_SKU` variable. This minimizes costs for the App Service instance but imposes limitations on resources and features. A limited number of free instances are allowed per region.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_APP_SERVICE_SKU F1\n```\n\n----------------------------------------\n\nTITLE: Setting Azure AI Search SKU to Free Tier with AZD\nDESCRIPTION: Configures the Azure Developer CLI (`azd`) environment to provision the Azure AI Search service using the 'free' SKU by setting the `AZURE_SEARCH_SERVICE_SKU` variable. This eliminates search service costs but limits features (e.g., no semantic ranker) and allows only one free service per subscription.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_SERVICE_SKU free\n```\n\n----------------------------------------\n\nTITLE: Enabling Local HTML Parsing with AZD\nDESCRIPTION: Sets the `USE_LOCAL_HTML_PARSER` Azure Developer CLI (`azd`) environment variable to instruct the application to use a local Python library for parsing HTML files. This bypasses the Azure Document Intelligence free-tier page limit but requires appropriate local Python packages for data ingestion.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_LOCAL_HTML_PARSER true\n```\n\n----------------------------------------\n\nTITLE: Initializing AZD Environment from Template (Shell)\nDESCRIPTION: Initializes a new local Azure Developer CLI (azd) environment using the `azure-search-openai-demo` template. This command clones the necessary project structure locally, preparing it for synchronization with an existing Azure deployment.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/sharing_environments.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd init -t azure-search-openai-demo\n```\n\n----------------------------------------\n\nTITLE: Provisioning Evaluation Model with Azure Developer CLI - Shell\nDESCRIPTION: This shell command provisions the required evaluation model within Azure using azd. It applies the current environment settings (including model type and capacity) to deploy resources, such as a GPT-4o model for RAG answer evaluation. Requires azd installed and configured with appropriate cloud credentials. Completion of this command prepares the environment for subsequent evaluation tasks.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/evaluation.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nazd provision\n```\n\n----------------------------------------\n\nTITLE: Configuring Local PDF Parser via AZD Env Var\nDESCRIPTION: Uses the Azure Developer CLI (`azd`) to set the environment variable `USE_LOCAL_PDF_PARSER` to `true`. This configuration directs the data ingestion script to use a local PDF parser instead of Azure Document Intelligence, which can help decrease service charges. This setting takes effect the next time the data ingestion script runs.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_28\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_LOCAL_PDF_PARSER true\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment for Local Ollama Server (azd)\nDESCRIPTION: Uses the Azure Developer CLI (`azd`) to set environment variables specifically for connecting to a local Ollama server running the `llama3.1:8b` model. It configures the host, base URL (defaulting to `http://localhost:11434/v1`), model name, and disables vector usage. Requires restarting the local dev server.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/localdev.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nazd env set OPENAI_HOST local\nazd env set OPENAI_BASE_URL http://localhost:11434/v1\nazd env set AZURE_OPENAI_CHATGPT_MODEL llama3.1:8b\nazd env set USE_VECTORS false\n```\n\n----------------------------------------\n\nTITLE: Removing a Specific User (OID) Access Control List from a Document in Azure Search using Python\nDESCRIPTION: Executes the `manageacl.py` script to remove a specific user ID (OID) (`--acl`) from the access control list of a document specified by its URL (`--url`) in the Azure AI Search index. Requires environment setup and activated Python environment. The `-v` flag enables verbose logging.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\npython ./scripts/manageacl.py -v --acl-type oids --acl-action remove --acl xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx --url https://st12345.blob.core.windows.net/content/Benefit_Options.pdf\n```\n\n----------------------------------------\n\nTITLE: Configuring Pipeline for GitHub Actions via Azure Developer CLI - Shell\nDESCRIPTION: This shell command initializes and configures a pipeline for GitHub Actions continuous deployment by setting up a Service Principal account and storing Azure Developer CLI environment variables as GitHub Actions secrets. It requires the Azure Developer CLI ('azd') to be installed and authenticated. Running this command updates the secrets in your GitHub repository to ensure Azure resources can be deployed via CI workflows.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/azd.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd pipeline config\n```\n\n----------------------------------------\n\nTITLE: Setting Azure OpenAI Embedding Model Version - azd CLI - Shell\nDESCRIPTION: This command configures the model version for Azure OpenAI embeddings via the `AZURE_OPENAI_EMB_DEPLOYMENT_VERSION` environment variable. For text-embedding-3 models, only version '1' is available as of March 2024.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_EMB_DEPLOYMENT_VERSION 1\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI.com Usage with AZD\nDESCRIPTION: Sets multiple Azure Developer CLI (`azd`) environment variables (`OPENAI_HOST`, `OPENAI_ORGANIZATION`, `OPENAI_API_KEY`) to configure the application to use the OpenAI.com API endpoint instead of Azure OpenAI. This requires providing a valid OpenAI organization ID and API key. Costs are incurred based on token usage.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nazd env set OPENAI_HOST openai\nazd env set OPENAI_ORGANIZATION {Your OpenAI organization}\nazd env set OPENAI_API_KEY {Your OpenAI API key}\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI.com Account using azd (Shell)\nDESCRIPTION: These shell commands configure the application to use a non-Azure OpenAI.com account instead of Azure OpenAI Service. This serves as an alternative to dealing with Azure free trial quota limitations. It requires providing your OpenAI organization ID and API key via `azd env set` commands.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_freetrial.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nazd env set OPENAI_HOST openai\nazd env set OPENAI_ORGANIZATION {Your OpenAI organization}\nazd env set OPENAI_API_KEY {Your OpenAI API key}\n```\n\n----------------------------------------\n\nTITLE: Configuring Pipeline for Azure DevOps via Azure Developer CLI - Shell\nDESCRIPTION: This shell command configures a pipeline for Azure DevOps by setting up a Service Principal for continuous integration and storing Azure Developer CLI environment variables as secrets for Azure DevOps pipelines. It requires the Azure Developer CLI ('azd') and access to an Azure DevOps organization. The '--provider azdo' flag specifies that the pipeline should target Azure DevOps rather than the default GitHub Actions.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/azd.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nazd pipeline config --provider azdo\n```\n\n----------------------------------------\n\nTITLE: Enable Client-side Chat History - azd CLI - Shell\nDESCRIPTION: This command enables persistent chat history within the user's browser using IndexedDB. By setting the `USE_CHAT_HISTORY_BROWSER` variable to 'true', chat logs are written locally and are specific to the user device. No server-side history is enabled by this setting.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_CHAT_HISTORY_BROWSER true\n```\n\n----------------------------------------\n\nTITLE: Navigating to Frontend Directory (Shell)\nDESCRIPTION: Changes the current working directory in the terminal to the `app/frontend` subdirectory. This is necessary before running frontend-specific commands like `npm run dev`.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/localdev.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncd app/frontend\n```\n\n----------------------------------------\n\nTITLE: Creating a New azd Deployment Environment - Bash\nDESCRIPTION: This snippet illustrates how to create a new Azure Developer CLI environment for storing deployment parameters. When executed, you'll be prompted to enter an environment name, resulting in the creation of a dedicated folder under '.azure' to store environment-specific settings. This is required for segregation and reuse of configuration per deployment session.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/azure_app_service.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nazd env new\n```\n\n----------------------------------------\n\nTITLE: Creating a New AZD Environment\nDESCRIPTION: Runs the `azd env new` command to initiate the creation of a new Azure Developer CLI environment. The user will be prompted for an environment name, which will be used for the resource group name and create a corresponding configuration folder under `.azure`.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/azure_container_apps.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nazd env new\n```\n\n----------------------------------------\n\nTITLE: Creating a New Azure Developer Environment - Shell\nDESCRIPTION: This command creates a new environment for Azure Developer CLI operations. Environments isolate resource groups and configurations for deployment. The user will be prompted for an environment name, which determines the resource group name. Required dependency: Azure Developer CLI. The environment will be set as active for future azd commands.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/README.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nazd env new\n```\n\n----------------------------------------\n\nTITLE: Running a Locust Load Test with a Custom User Class\nDESCRIPTION: This shell command launches a Locust load test using a specific User class (e.g., `ChatUser`) defined in the `locustfile.py` script. Before running this command, Locust must be installed and the current directory should contain a properly configured `locustfile.py`. After execution, the Locust web UI becomes accessible for configuring and starting tests. Parameters set in the UI (such as target URI, user count, and spawn rate) control runtime behavior.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/productionizing.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nlocust ChatUser\n```\n\n----------------------------------------\n\nTITLE: Setting Azure AI Search Semantic Ranker Mode via Shell Commands\nDESCRIPTION: These shell code snippets show how to enable or disable the Azure AI Search semantic ranker for your application using environment variables set with the Azure Developer CLI (`azd`). The `AZURE_SEARCH_SEMANTIC_RANKER` variable can be set to `standard` to upgrade from the default free tier or to `disabled` to turn off semantic search. This applies immediately to the environment managed by the CLI. Requires azd to be installed and logged in, and assumes you are in a properly initialized project directory.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/productionizing.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_SEMANTIC_RANKER standard\n```\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_SEMANTIC_RANKER disabled\n```\n\n----------------------------------------\n\nTITLE: Enabling Semantic Ranker (Standard Tier) for Query Rewriting - Shell\nDESCRIPTION: Alternative command for setting AZURE_SEARCH_SEMANTIC_RANKER to 'standard' tier, used for advanced semantic ranking and query rewriting configurations within Azure AI Search ecosystems.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_25\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_SEMANTIC_RANKER standard\n```\n\n----------------------------------------\n\nTITLE: Enabling Semantic Ranker for Query Rewriting - Shell\nDESCRIPTION: Sets the AZURE_SEARCH_SEMANTIC_RANKER variable to the tier ('free' or 'standard') for Azure AI Search via azd, a prerequisite for enabling the search service query rewriting feature. Choose the appropriate tier based on requirements and pricing.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_24\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_SEMANTIC_RANKER free\n```\n\n----------------------------------------\n\nTITLE: Adding a Group Access Control List to a Document in Azure Search using Python\nDESCRIPTION: Executes the `manageacl.py` script to add a specific group ID (`--acl`) to the access control list of a document specified by its URL (`--url`) in the Azure AI Search index. Requires environment setup and activated Python environment. The `-v` flag enables verbose logging.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\npython ./scripts/manageacl.py -v --acl-type groups --acl-action add --acl xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx --url https://st12345.blob.core.windows.net/content/Benefit_Options.pdf\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment for Local Llamafile Server (azd)\nDESCRIPTION: Uses the Azure Developer CLI (`azd`) to set environment variables for connecting to a local llamafile server running on its default port (`8080`). It configures the host, base URL, and disables vector usage. No specific model name is required for llamafile. Requires restarting the local dev server.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/localdev.md#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nazd env set OPENAI_HOST local\nazd env set OPENAI_BASE_URL http://localhost:8080/v1\nazd env set USE_VECTORS false\n```\n\n----------------------------------------\n\nTITLE: Assigning Azure Roles via PowerShell Script\nDESCRIPTION: Executes a PowerShell script (`roles.ps1`) located in the `./scripts` directory. This script assigns the necessary Azure roles to the user identity specified by the `AZURE_PRINCIPAL_ID` environment variable, enabling them to interact with the deployed Azure resources. Requires sufficient permissions in the Azure subscription to assign roles.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/sharing_environments.md#_snippet_3\n\nLANGUAGE: powershell\nCODE:\n```\n./scripts/roles.ps1\n```\n\n----------------------------------------\n\nTITLE: Setting Azure AI Search Service SKU via Shell Command\nDESCRIPTION: This shell snippet demonstrates updating the Azure AI Search service SKU by setting the `AZURE_SEARCH_SERVICE_SKU` environment variable using the Azure Developer CLI (`azd`). Changing this variable determines the SKU used for subsequent deployments, but note that the SKU of an existing Azure AI Search resource cannot be changed in place—this must be done before deployment or by re-creating the resource. Make sure to use a valid SKU value based on Azure documentation.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/productionizing.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_SEARCH_SERVICE_SKU standard\n```\n\n----------------------------------------\n\nTITLE: Enabling Integrated Vectorization in Azure AI Search - Shell\nDESCRIPTION: This command enables the preview integrated vectorization feature in Azure AI Search by setting USE_FEATURE_INT_VECTORIZATION to 'true'. Feature must be supported in the deployed search instance, and may require additional steps such as deleting previous indexes and running provisioning commands. Intended for more advanced data processing in search pipelines.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_FEATURE_INT_VECTORIZATION true\n```\n\n----------------------------------------\n\nTITLE: Enable Media Description with Azure Content Understanding - azd CLI - Shell\nDESCRIPTION: This command enables the Azure Content Understanding service to automatically generate textual descriptions for figure and image media within documents during ingestion. The feature is controlled using the `USE_MEDIA_DESCRIBER_AZURE_CU` environment variable. Set it to 'true' to allow ingestion to send image content for media description. Note the feature constraints, such as unsupported DOCX/PPTX/XLSX formats.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_MEDIA_DESCRIBER_AZURE_CU true\n```\n\n----------------------------------------\n\nTITLE: Allowing Unauthenticated Access via azd CLI - Shell\nDESCRIPTION: This command configures the app to allow unauthenticated users, by setting 'AZURE_ENABLE_UNAUTHENTICATED_ACCESS' to 'true' via the azd CLI. Unauthenticated users cannot access protected documents, so it is typically used with global document access enabled. Requires azd CLI setup in the Azure project context.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_ENABLE_UNAUTHENTICATED_ACCESS true\n```\n\n----------------------------------------\n\nTITLE: Setting AZD Deployment Target to Container Apps\nDESCRIPTION: Uses the `azd env set` command to define the `DEPLOYMENT_TARGET` environment variable as `containerapps` within the current `azd` environment. This configuration directs `azd` to deploy the application specifically to Azure Container Apps.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/azure_container_apps.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nazd env set DEPLOYMENT_TARGET containerapps\n```\n\n----------------------------------------\n\nTITLE: Updating Storage URLs for Search Documents - Python\nDESCRIPTION: Runs the same Python script, this time to update pre-existing indexed documents with the storage URL of the main Azure Blob container. Requires specifying the --url argument with the correct Blob URL. Ensures user-uploaded and admin-uploaded documents can be differentiated moving forward.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_22\n\nLANGUAGE: python\nCODE:\n```\npython ./scripts/manageacl.py  -v --acl-action update_storage_urls --url <https://YOUR-MAIN-STORAGE-ACCOUNT.blob.core.windows.net/content/>\n```\n\n----------------------------------------\n\nTITLE: Allowing Global Document Access via azd CLI - Shell\nDESCRIPTION: This azd CLI command allows users to access documents without access controls applied by setting 'AZURE_ENABLE_GLOBAL_DOCUMENT_ACCESS' to 'true'. This is useful when you want search to include documents outside access-controlled documents even when enforcement is enabled. The azd CLI and environment setup are prerequisites.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_ENABLE_GLOBAL_DOCUMENT_ACCESS true\n```\n\n----------------------------------------\n\nTITLE: Enabling User Document Upload Feature - Shell\nDESCRIPTION: This shell command enables the user document upload system by setting USE_USER_UPLOAD to 'true'. Requires authentication and document-level access control to be previously enabled. No output is produced; feature may trigger provisioning of Azure Data Lake Storage Gen2 and related ACL directories on 'azd up'.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_USER_UPLOAD true\n```\n\n----------------------------------------\n\nTITLE: Disabling Application Insights with AZD\nDESCRIPTION: Sets the `AZURE_USE_APPLICATION_INSIGHTS` Azure Developer CLI (`azd`) environment variable to `false`, preventing the deployment and configuration of Azure Monitor Application Insights. This reduces monitoring costs but removes application telemetry. Note that this option is mentioned as potentially only working when deploying to App Service.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_USE_APPLICATION_INSIGHTS false\n```\n\n----------------------------------------\n\nTITLE: Setting Low Azure OpenAI TPM Quotas using azd (Shell)\nDESCRIPTION: These shell commands use the Azure Developer CLI (`azd`) to set environment variables that reduce the requested Tokens-Per-Minute (TPM) capacity for Azure OpenAI deployments. This is necessary for Azure free trial accounts which have lower default quotas (e.g., 1K TPM) than typically requested by the application's Bicep templates (e.g., 30K TPM). Setting capacity to '1' corresponds to 1K TPM.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_freetrial.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT_CAPACITY 1\nazd env set AZURE_OPENAI_EMB_DEPLOYMENT_CAPACITY 1\n```\n\n----------------------------------------\n\nTITLE: Querying for a Specific Filename in Azure AI Search (JSON)\nDESCRIPTION: Searches the Azure AI Search index for entries where the filename matches 'employee_handbook.pdf', returning the count and 'sourcefile' facet. Relies on standard Azure AI Search REST API semantics. Set 'filter' to the exact filename to restrict results. Key for troubleshooting or inspecting specific document ingestions; ensure the 'sourcefile' field is indexed and filterable.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/data_ingestion.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\\n  \\\"search\\\": \\\"*\\\",\\n  \\\"count\\\": true,\\n  \\\"top\\\": 1,\\n  \\\"filter\\\": \\\"sourcefile eq 'employee_handbook.pdf'\\\",\\n  \\\"facets\\\": [\\\"sourcefile\\\"]\\n}\n```\n\n----------------------------------------\n\nTITLE: Running Python Unit Tests with Coverage\nDESCRIPTION: Runs the unit tests using `pytest` and generates a code coverage report using the `pytest-cov` plugin. This helps identify which parts of the codebase are exercised by the tests.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/CONTRIBUTING.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\npython -m pytest --cov\n```\n\n----------------------------------------\n\nTITLE: Enabling Speech Output with Azure Speech Service - Shell\nDESCRIPTION: This azd command activates speech output through Azure Speech Service for the application by enabling USE_SPEECH_OUTPUT_AZURE. The Azure Cognitive Services Speech SDK and pricing considerations apply. Used for converting text responses to speech through Azure cloud; relies on correct Azure subscription setup.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_SPEECH_OUTPUT_AZURE true\n```\n\n----------------------------------------\n\nTITLE: Configuring Local HTML Parser via AZD Env Var\nDESCRIPTION: Uses the Azure Developer CLI (`azd`) to set the environment variable `USE_LOCAL_HTML_PARSER` to `true`. This configuration instructs the data ingestion script to utilize a local HTML parser as an alternative to cloud services, potentially lowering costs. This setting applies during the subsequent run of the data ingestion script.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_29\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_LOCAL_HTML_PARSER true\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Azure via Device Code (GitHub Codespaces) - Shell\nDESCRIPTION: Alternative authentication for Azure Developer CLI using device code. Useful in remote environments like GitHub Codespaces where standard browser-based login may not be available. User follows instructions to enter the code at a specified URL for authentication. Prerequisite: Azure Developer CLI installed.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/README.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nazd auth login --use-device-code\n```\n\n----------------------------------------\n\nTITLE: Setting Azure Auth Tenant ID using AZD CLI\nDESCRIPTION: Sets the `AZURE_AUTH_TENANT_ID` environment variable using the Azure Developer CLI (`azd`). This is necessary when the primary tenant restricts Entra application creation, requiring the use of a separate tenant for authentication configuration. Replace `<YOUR-AUTH-TENANT-ID>` with the actual tenant ID.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/login_and_acl.md#_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_AUTH_TENANT_ID <YOUR-AUTH-TENANT-ID>\n```\n\n----------------------------------------\n\nTITLE: Enabling Speech Input via Browser - Shell\nDESCRIPTION: This azd command enables speech input using the browser's built-in Speech Recognition API by setting USE_SPEECH_INPUT_BROWSER to 'true'. The browser must support the API for this to function; not all browser/OS combinations are compatible. No output is expected; just modifies environment settings.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_features.md#_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\nazd env set USE_SPEECH_INPUT_BROWSER true\n```\n\n----------------------------------------\n\nTITLE: Setting Document Intelligence SKU to Free Tier (F0) with AZD\nDESCRIPTION: Sets the Azure Document Intelligence service SKU to 'F0' (Free) in the active Azure Developer CLI (`azd`) environment via the `AZURE_DOCUMENTINTELLIGENCE_SKU` variable. This reduces document analysis costs but restricts processing to the first two pages of PDF and HTML files.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_lowcost.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nazd env set AZURE_DOCUMENTINTELLIGENCE_SKU F0\n```\n\n----------------------------------------\n\nTITLE: Setting Deployment Target to App Service using azd (Shell)\nDESCRIPTION: This shell command uses the Azure Developer CLI (`azd`) to set the deployment target environment variable to 'appservice'. This is required when deploying on an Azure free trial account if choosing the option to use Azure App Service instead of Azure Container Apps, due to restrictions on the remote build process for Container Apps in free trials. This command should be run after modifying the `azure.yaml` file to uncomment the `host: appservice` line.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/deploy_freetrial.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nazd env set DEPLOYMENT_TARGET appservice\n```\n\n----------------------------------------\n\nTITLE: Linting Python File with Ruff\nDESCRIPTION: Runs the `ruff` linter on a specified Python file (`<path-to-file>`). Ruff checks the code for style guide violations and potential errors.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/CONTRIBUTING.md#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\npython -m ruff <path-to-file>\n```\n\n----------------------------------------\n\nTITLE: Sample Safety Evaluation Results Format (JSON)\nDESCRIPTION: This JSON block exemplifies the structure of the 'safety_results.json' output from the safety_evaluation.py script. It summarizes the evaluation metrics for various safety categories ('hate_unfairness', 'sexual', 'violence', 'self_harm'), reporting the count of low-risk responses, total score, average safety score, and the low-risk rate. Consumers of this result should look for 'low_rate' of 1.0 and 'mean_score' of 0.0 for ideal safety. Results must be handled as structured JSON for further analysis or review.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/safety_evaluation.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\\n  \\\"hate_unfairness\\\": {\\n    \\\"low_count\\\": 20,\\n    \\\"score_total\\\": 8,\\n    \\\"mean_score\\\": 0.4,\\n    \\\"low_rate\\\": 1.0\\n  },\\n  \\\"sexual\\\": {\\n    \\\"low_count\\\": 20,\\n    \\\"score_total\\\": 9,\\n    \\\"mean_score\\\": 0.45,\\n    \\\"low_rate\\\": 1.0\\n  },\\n  \\\"violence\\\": {\\n    \\\"low_count\\\": 20,\\n    \\\"score_total\\\": 9,\\n    \\\"mean_score\\\": 0.45,\\n    \\\"low_rate\\\": 1.0\\n  },\\n  \\\"self_harm\\\": {\\n    \\\"low_count\\\": 20,\\n    \\\"score_total\\\": 10,\\n    \\\"mean_score\\\": 0.5,\\n    \\\"low_rate\\\": 1.0\\n  }\\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Python Development Dependencies using pip Requirements Format\nDESCRIPTION: This requirements file specifies development-related Python packages. It includes dependencies for testing (`pytest`, `pytest-asyncio`, `pytest-snapshot`, `coverage`, `pytest-cov`), code quality (`ruff`, `black`, `mypy`), browser automation (`playwright`, `pytest-playwright`), load testing (`locust`), dependency management (`pip-tools`), and pre-commit hooks (`pre-commit`). It also incorporates the main application dependencies by referencing `app/backend/requirements.txt`. The specific version `1.14.1` is pinned for `mypy`.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/requirements-dev.txt#_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\n-r app/backend/requirements.txt\nruff\nblack\npytest\npytest-asyncio\npytest-snapshot\ncoverage\nplaywright\npytest-cov\npytest-playwright\npytest-snapshot\npre-commit\nlocust\npip-tools\nmypy==1.14.1\n```\n\n----------------------------------------\n\nTITLE: Installing Evaluation Dependencies - Bash\nDESCRIPTION: This bash command installs all required Python dependencies for the evaluation script using pip. It reads the requirements from the evals/requirements.txt file, ensuring the evaluation environment has all necessary packages. Expects an active virtual environment and pip to be available.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/evaluation.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install -r evals/requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Creating and Activating Python Virtual Environment - Bash\nDESCRIPTION: These bash commands create a new Python virtual environment named .evalenv and activate it to isolate evaluation dependencies from the main project. Requires Python and virtual environment support on the system. After activation, the shell session uses the isolated Python interpreter and packages installed within .evalenv.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/evaluation.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv .evalenv\n```\n\nLANGUAGE: bash\nCODE:\n```\nsource .evalenv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Example Vite Frontend Server Startup Output\nDESCRIPTION: Displays typical console output after successfully starting the Vite frontend development server using `npm run dev`. It indicates the server is ready and provides the local URL (e.g., `http://localhost:5173/`) to access the frontend.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/docs/localdev.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n> frontend@0.0.0 dev\n> vite\n\n\n  VITE v4.5.1  ready in 957 ms\n\n  ➜  Local:   http://localhost:5173/\n  ➜  Network: use --host to expose\n  ➜  press h to show help\n```\n\n----------------------------------------\n\nTITLE: Rendering a Simple Table - HTML\nDESCRIPTION: This snippet demonstrates the creation of a basic static HTML table with two header columns and two rows of data. No additional dependencies or styling are used, making it suitable for fundamental web page layouts or instructional purposes. Inputs are fixed within the code, and the output is a rendered table in the browser; the primary constraint is that the table is entirely static with no dynamic behavior.\nSOURCE: https://github.com/azure-samples/azure-search-openai-demo/blob/main/tests/test-data/Simple Table_content.txt#_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<table>\\n<tr>\\n<th>Header 1</th>\\n<th>Header 2</th>\\n</tr>\\n<tr>\\n<td>Cell 1</td>\\n<td>Cell 2</td>\\n</tr>\\n<tr>\\n<td>Cell 3</td>\\n<td>Cell 4</td>\\n</tr>\\n</table>\n```"
  }
]