[
  {
    "owner": "segmentio",
    "repo": "kafka-go",
    "content": "TITLE: Producing Messages with Kafka Connection\nDESCRIPTION: Example showing how to establish a connection and produce messages to a Kafka topic using the Conn type. Demonstrates connection setup, message writing with deadlines, and proper connection cleanup.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_0\n\nLANGUAGE: go\nCODE:\n```\ntopic := \"my-topic\"\npartition := 0\n\nconn, err := kafka.DialLeader(context.Background(), \"tcp\", \"localhost:9092\", topic, partition)\nif err != nil {\n    log.Fatal(\"failed to dial leader:\", err)\n}\n\nconn.SetWriteDeadline(time.Now().Add(10*time.Second))\n_, err = conn.WriteMessages(\n    kafka.Message{Value: []byte(\"one!\")},\n    kafka.Message{Value: []byte(\"two!\")},\n    kafka.Message{Value: []byte(\"three!\")},\n)\nif err != nil {\n    log.Fatal(\"failed to write messages:\", err)\n}\n\nif err := conn.Close(); err != nil {\n    log.Fatal(\"failed to close writer:\", err)\n}\n```\n\n----------------------------------------\n\nTITLE: Using Kafka Consumer Groups\nDESCRIPTION: Example demonstrating how to use Kafka consumer groups for message consumption. Shows configuration with GroupID and automatic offset management.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_6\n\nLANGUAGE: go\nCODE:\n```\nr := kafka.NewReader(kafka.ReaderConfig{\n    Brokers:   []string{\"localhost:9092\", \"localhost:9093\", \"localhost:9094\"},\n    GroupID:   \"consumer-group-id\",\n    Topic:     \"topic-A\",\n    MaxBytes:  10e6, // 10MB\n})\n\nfor {\n    m, err := r.ReadMessage(context.Background())\n    if err != nil {\n        break\n    }\n    fmt.Printf(\"message at topic/partition/offset %v/%v/%v: %s = %s\\n\", m.Topic, m.Partition, m.Offset, string(m.Key), string(m.Value))\n}\n\nif err := r.Close(); err != nil {\n    log.Fatal(\"failed to close reader:\", err)\n}\n```\n\n----------------------------------------\n\nTITLE: Using Kafka Reader for Message Consumption\nDESCRIPTION: Example showing how to use the Reader type for consuming messages from a specific topic-partition. Demonstrates configuration, offset management, and proper cleanup.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_5\n\nLANGUAGE: go\nCODE:\n```\nr := kafka.NewReader(kafka.ReaderConfig{\n    Brokers:   []string{\"localhost:9092\",\"localhost:9093\", \"localhost:9094\"},\n    Topic:     \"topic-A\",\n    Partition: 0,\n    MaxBytes:  10e6, // 10MB\n})\nr.SetOffset(42)\n\nfor {\n    m, err := r.ReadMessage(context.Background())\n    if err != nil {\n        break\n    }\n    fmt.Printf(\"message at offset %d: %s = %s\\n\", m.Offset, string(m.Key), string(m.Value))\n}\n\nif err := r.Close(); err != nil {\n    log.Fatal(\"failed to close reader:\", err)\n}\n```\n\n----------------------------------------\n\nTITLE: Establishing Kafka Connection with SCRAM Authentication\nDESCRIPTION: Creates a secure connection to Kafka broker using SCRAM-SHA-512 authentication mechanism. Demonstrates dialer configuration with timeout and dual stack settings.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_15\n\nLANGUAGE: go\nCODE:\n```\nmechanism, err := scram.Mechanism(scram.SHA512, \"username\", \"password\")\nif err != nil {\n    panic(err)\n}\n\ndialer := &kafka.Dialer{\n    Timeout:       10 * time.Second,\n    DualStack:     true,\n    SASLMechanism: mechanism,\n}\n\nconn, err := dialer.DialContext(ctx, \"tcp\", \"localhost:9093\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Reader with Authentication\nDESCRIPTION: Sets up a Kafka reader with SCRAM authentication, connecting to multiple brokers. Includes consumer group configuration and topic specification.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_16\n\nLANGUAGE: go\nCODE:\n```\nmechanism, err := scram.Mechanism(scram.SHA512, \"username\", \"password\")\nif err != nil {\n    panic(err)\n}\n\ndialer := &kafka.Dialer{\n    Timeout:       10 * time.Second,\n    DualStack:     true,\n    SASLMechanism: mechanism,\n}\n\nr := kafka.NewReader(kafka.ReaderConfig{\n    Brokers:        []string{\"localhost:9092\",\"localhost:9093\", \"localhost:9094\"},\n    GroupID:        \"consumer-group-id\",\n    Topic:          \"topic-A\",\n    Dialer:         dialer,\n})\n```\n\n----------------------------------------\n\nTITLE: TLS Configuration for Kafka Reader\nDESCRIPTION: Demonstrates setting up TLS security for a Kafka reader instance\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_13\n\nLANGUAGE: go\nCODE:\n```\ndialer := &kafka.Dialer{\n    Timeout:   10 * time.Second,\n    DualStack: true,\n    TLS:       &tls.Config{...tls config...},\n}\n\nr := kafka.NewReader(kafka.ReaderConfig{\n    Brokers:        []string{\"localhost:9092\", \"localhost:9093\", \"localhost:9094\"},\n    GroupID:        \"consumer-group-id\",\n    Topic:          \"topic-A\",\n    Dialer:         dialer,\n})\n```\n\n----------------------------------------\n\nTITLE: Implementing Kafka Writer with Shared Transport\nDESCRIPTION: Configures a Kafka writer with shared transport and SCRAM authentication. Uses hash-based message balancing across multiple brokers.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_17\n\nLANGUAGE: go\nCODE:\n```\nmechanism, err := scram.Mechanism(scram.SHA512, \"username\", \"password\")\nif err != nil {\n    panic(err)\n}\n\n// Transports are responsible for managing connection pools and other resources,\n// it's generally best to create a few of these and share them across your\n// application.\nsharedTransport := &kafka.Transport{\n    SASL: mechanism,\n}\n\nw := kafka.Writer{\n\tAddr:      kafka.TCP(\"localhost:9092\", \"localhost:9093\", \"localhost:9094\"),\n\tTopic:     \"topic-A\",\n\tBalancer:  &kafka.Hash{},\n\tTransport: sharedTransport,\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Explicit Commits with Kafka-Go\nDESCRIPTION: Example showing how to explicitly commit messages using FetchMessage and CommitMessages instead of automatic commits with ReadMessage.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_7\n\nLANGUAGE: go\nCODE:\n```\nctx := context.Background()\nfor {\n    m, err := r.FetchMessage(ctx)\n    if err != nil {\n        break\n    }\n    fmt.Printf(\"message at topic/partition/offset %v/%v/%v: %s = %s\\n\", m.Topic, m.Partition, m.Offset, string(m.Key), string(m.Value))\n    if err := r.CommitMessages(ctx, m); err != nil {\n        log.Fatal(\"failed to commit messages:\", err)\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Kafka Writer Configuration and Message Production\nDESCRIPTION: Demonstrates setting up a Kafka writer with least-bytes distribution and writing multiple messages\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_9\n\nLANGUAGE: go\nCODE:\n```\nw := &kafka.Writer{\n\tAddr:     kafka.TCP(\"localhost:9092\", \"localhost:9093\", \"localhost:9094\"),\n\tTopic:   \"topic-A\",\n\tBalancer: &kafka.LeastBytes{},\n}\n\nerr := w.WriteMessages(context.Background(),\n\tkafka.Message{\n\t\tKey:   []byte(\"Key-A\"),\n\t\tValue: []byte(\"Hello World!\"),\n\t},\n\tkafka.Message{\n\t\tKey:   []byte(\"Key-B\"),\n\t\tValue: []byte(\"One!\"),\n\t},\n\tkafka.Message{\n\t\tKey:   []byte(\"Key-C\"),\n\t\tValue: []byte(\"Two!\"),\n\t},\n)\nif err != nil {\n    log.Fatal(\"failed to write messages:\", err)\n}\n\nif err := w.Close(); err != nil {\n    log.Fatal(\"failed to close writer:\", err)\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Topics Explicitly\nDESCRIPTION: Example showing how to create Kafka topics programmatically when auto-creation is disabled. Demonstrates connecting to the controller node and creating topics with specific configurations.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_2\n\nLANGUAGE: go\nCODE:\n```\ntopic := \"my-topic\"\n\nconn, err := kafka.Dial(\"tcp\", \"localhost:9092\")\nif err != nil {\n    panic(err.Error())\n}\ndefer conn.Close()\n\ncontroller, err := conn.Controller()\nif err != nil {\n    panic(err.Error())\n}\nvar controllerConn *kafka.Conn\ncontrollerConn, err = kafka.Dial(\"tcp\", net.JoinHostPort(controller.Host, strconv.Itoa(controller.Port)))\nif err != nil {\n    panic(err.Error())\n}\ndefer controllerConn.Close()\n\n\ntopicConfigs := []kafka.TopicConfig{\n    {\n        Topic:             topic,\n        NumPartitions:     1,\n        ReplicationFactor: 1,\n    },\n}\n\nerr = controllerConn.CreateTopics(topicConfigs...)\nif err != nil {\n    panic(err.Error())\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Kafka Topics\nDESCRIPTION: Example showing how to list all available topics in a Kafka cluster. Demonstrates connecting to a broker and reading partition information to extract unique topic names.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_4\n\nLANGUAGE: go\nCODE:\n```\nconn, err := kafka.Dial(\"tcp\", \"localhost:9092\")\nif err != nil {\n    panic(err.Error())\n}\ndefer conn.Close()\n\npartitions, err := conn.ReadPartitions()\nif err != nil {\n    panic(err.Error())\n}\n\nm := map[string]struct{}{}\n\nfor _, p := range partitions {\n    m[p.Topic] = struct{}{}\n}\nfor k := range m {\n    fmt.Println(k)\n}\n```\n\n----------------------------------------\n\nTITLE: Reading Time-Range Messages from Kafka\nDESCRIPTION: Demonstrates reading messages from a specific time range with batch size control. Includes error handling and proper resource cleanup.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_19\n\nLANGUAGE: go\nCODE:\n```\nstartTime := time.Now().Add(-time.Hour)\nendTime := time.Now()\nbatchSize := int(10e6) // 10MB\n\nr := kafka.NewReader(kafka.ReaderConfig{\n    Brokers:   []string{\"localhost:9092\", \"localhost:9093\", \"localhost:9094\"},\n    Topic:     \"my-topic1\",\n    Partition: 0,\n    MaxBytes:  batchSize,\n})\n\nr.SetOffsetAt(context.Background(), startTime)\n\nfor {\n    m, err := r.ReadMessage(context.Background())\n\n    if err != nil {\n        break\n    }\n    if m.Time.After(endTime) {\n        break\n    }\n    // TODO: process message\n    fmt.Printf(\"message at offset %d: %s = %s\\n\", m.Offset, string(m.Key), string(m.Value))\n}\n\nif err := r.Close(); err != nil {\n    log.Fatal(\"failed to close reader:\", err)\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Periodic Commits in Kafka-Go Reader\nDESCRIPTION: Shows how to set up a Kafka reader with periodic commit intervals for improved performance\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_8\n\nLANGUAGE: go\nCODE:\n```\nr := kafka.NewReader(kafka.ReaderConfig{\n    Brokers:        []string{\"localhost:9092\", \"localhost:9093\", \"localhost:9094\"},\n    GroupID:        \"consumer-group-id\",\n    Topic:          \"topic-A\",\n    MaxBytes:       10e6, // 10MB\n    CommitInterval: time.Second, // flushes commits to Kafka every second\n})\n```\n\n----------------------------------------\n\nTITLE: TLS Configuration for Kafka Writer\nDESCRIPTION: Shows multiple approaches to configure TLS security for Kafka writer instances\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_14\n\nLANGUAGE: go\nCODE:\n```\nw := kafka.Writer{\n    Addr: kafka.TCP(\"localhost:9092\", \"localhost:9093\", \"localhost:9094\"), \n    Topic:   \"topic-A\",\n    Balancer: &kafka.Hash{},\n    Transport: &kafka.Transport{\n        TLS: &tls.Config{},\n      },\n    }\n```\n\n----------------------------------------\n\nTITLE: TLS Configuration for Kafka Connection\nDESCRIPTION: Shows how to configure TLS security for direct Kafka connections\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_12\n\nLANGUAGE: go\nCODE:\n```\ndialer := &kafka.Dialer{\n    Timeout:   10 * time.Second,\n    DualStack: true,\n    TLS:       &tls.Config{...tls config...},\n}\n\nconn, err := dialer.DialContext(ctx, \"tcp\", \"localhost:9093\")\n```\n\n----------------------------------------\n\nTITLE: Auto Topic Creation with Retry Logic\nDESCRIPTION: Shows how to configure a writer with automatic topic creation and implements retry logic for handling leader election scenarios\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_10\n\nLANGUAGE: go\nCODE:\n```\nw := &Writer{\n    Addr:                   kafka.TCP(\"localhost:9092\", \"localhost:9093\", \"localhost:9094\"),\n    Topic:                  \"topic-A\",\n    AllowAutoTopicCreation: true,\n}\n\nmessages := []kafka.Message{\n    {\n        Key:   []byte(\"Key-A\"),\n        Value: []byte(\"Hello World!\"),\n    },\n    {\n        Key:   []byte(\"Key-B\"),\n        Value: []byte(\"One!\"),\n    },\n    {\n        Key:   []byte(\"Key-C\"),\n        Value: []byte(\"Two!\"),\n    },\n}\n\nvar err error\nconst retries = 3\nfor i := 0; i < retries; i++ {\n    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n    defer cancel()\n    \n    err = w.WriteMessages(ctx, messages...)\n    if errors.Is(err, kafka.LeaderNotAvailable) || errors.Is(err, context.DeadlineExceeded) {\n        time.Sleep(time.Millisecond * 250)\n        continue\n    }\n\n    if err != nil {\n        log.Fatalf(\"unexpected error %v\", err)\n    }\n    break\n}\n\nif err := w.Close(); err != nil {\n    log.Fatal(\"failed to close writer:\", err)\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-Topic Kafka Writer Configuration\nDESCRIPTION: Demonstrates how to write messages to multiple topics using a single writer instance by specifying topics per message\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_11\n\nLANGUAGE: go\nCODE:\n```\nw := &kafka.Writer{\n\tAddr:     kafka.TCP(\"localhost:9092\", \"localhost:9093\", \"localhost:9094\"),\n\tBalancer: &kafka.LeastBytes{},\n}\n\nerr := w.WriteMessages(context.Background(),\n\tkafka.Message{\n        Topic: \"topic-A\",\n\t\tKey:   []byte(\"Key-A\"),\n\t\tValue: []byte(\"Hello World!\"),\n\t},\n\tkafka.Message{\n        Topic: \"topic-B\",\n\t\tKey:   []byte(\"Key-B\"),\n\t\tValue: []byte(\"One!\"),\n\t},\n\tkafka.Message{\n        Topic: \"topic-C\",\n\t\tKey:   []byte(\"Key-C\"),\n\t\tValue: []byte(\"Two!\"),\n\t},\n)\nif err != nil {\n    log.Fatal(\"failed to write messages:\", err)\n}\n\nif err := w.Close(); err != nil {\n    log.Fatal(\"failed to close writer:\", err)\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up Kafka Client with Shared Transport\nDESCRIPTION: Initializes a Kafka client with timeout configuration and shared transport layer. Uses SCRAM authentication for secure communication.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_18\n\nLANGUAGE: go\nCODE:\n```\nmechanism, err := scram.Mechanism(scram.SHA512, \"username\", \"password\")\nif err != nil {\n    panic(err)\n}\n\n// Transports are responsible for managing connection pools and other resources,\n// it's generally best to create a few of these and share them across your\n// application.\nsharedTransport := &kafka.Transport{\n    SASL: mechanism,\n}\n\nclient := &kafka.Client{\n    Addr:      kafka.TCP(\"localhost:9092\", \"localhost:9093\", \"localhost:9094\"),\n    Timeout:   10 * time.Second,\n    Transport: sharedTransport,\n}\n```\n\n----------------------------------------\n\nTITLE: Connecting to Kafka Leader via Non-leader Connection\nDESCRIPTION: Example demonstrating how to establish a connection to a Kafka leader broker through an existing non-leader connection. Shows the process of finding the controller and establishing a new connection.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_3\n\nLANGUAGE: go\nCODE:\n```\nconn, err := kafka.Dial(\"tcp\", \"localhost:9092\")\nif err != nil {\n    panic(err.Error())\n}\ndefer conn.Close()\ncontroller, err := conn.Controller()\nif err != nil {\n    panic(err.Error())\n}\nvar connLeader *kafka.Conn\nconnLeader, err = kafka.Dial(\"tcp\", net.JoinHostPort(controller.Host, strconv.Itoa(controller.Port)))\nif err != nil {\n    panic(err.Error())\n}\ndefer connLeader.Close()\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Reader with Logging\nDESCRIPTION: Sets up a Kafka reader with custom logging functionality for both regular and error logs.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_20\n\nLANGUAGE: go\nCODE:\n```\nfunc logf(msg string, a ...interface{}) {\n\tfmt.Printf(msg, a...)\n\tfmt.Println()\n}\n\nr := kafka.NewReader(kafka.ReaderConfig{\n\tBrokers:     []string{\"localhost:9092\", \"localhost:9093\", \"localhost:9094\"},\n\tTopic:       \"my-topic1\",\n\tPartition:   0,\n\tLogger:      kafka.LoggerFunc(logf),\n\tErrorLogger: kafka.LoggerFunc(logf),\n})\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Writer with Logging\nDESCRIPTION: Implements a Kafka writer with custom logging for both regular operations and errors.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_21\n\nLANGUAGE: go\nCODE:\n```\nfunc logf(msg string, a ...interface{}) {\n\tfmt.Printf(msg, a...)\n\tfmt.Println()\n}\n\nw := &kafka.Writer{\n\tAddr:        kafka.TCP(\"localhost:9092\"),\n\tTopic:       \"topic\",\n\tLogger:      kafka.LoggerFunc(logf),\n\tErrorLogger: kafka.LoggerFunc(logf),\n}\n```\n\n----------------------------------------\n\nTITLE: Consuming Messages with Kafka Connection\nDESCRIPTION: Example demonstrating how to consume messages from a Kafka topic using the Conn type. Shows connection establishment, batch reading with size limits, and proper cleanup of resources.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_1\n\nLANGUAGE: go\nCODE:\n```\ntopic := \"my-topic\"\npartition := 0\n\nconn, err := kafka.DialLeader(context.Background(), \"tcp\", \"localhost:9092\", topic, partition)\nif err != nil {\n    log.Fatal(\"failed to dial leader:\", err)\n}\n\nconn.SetReadDeadline(time.Now().Add(10*time.Second))\nbatch := conn.ReadBatch(10e3, 1e6) // fetch 10KB min, 1MB max\n\nb := make([]byte, 10e3) // 10KB max per message\nfor {\n    n, err := batch.Read(b)\n    if err != nil {\n        break\n    }\n    fmt.Println(string(b[:n]))\n}\n\nif err := batch.Close(); err != nil {\n    log.Fatal(\"failed to close batch:\", err)\n}\n\nif err := conn.Close(); err != nil {\n    log.Fatal(\"failed to close connection:\", err)\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka server.properties for kafka-go Testing\nDESCRIPTION: The server.properties configuration required for kafka-go test cases to succeed. This includes advertised listeners, SASL configurations, and other necessary Kafka broker settings.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/docker_compose_versions/README.md#2025-04-14_snippet_0\n\nLANGUAGE: properties\nCODE:\n```\nadvertised.host.name=localhost\nadvertised.listeners=PLAINTEXT://localhost:9092,SASL_PLAINTEXT://localhost:9093\nadvertised.port=9092\nauto.create.topics.enable=true\nbroker.id=1\ndelete.topic.enable=true\ngroup.initial.rebalance.delay.ms=0\nlisteners=PLAINTEXT://:9092,SASL_PLAINTEXT://:9093\nlog.dirs=/kafka/kafka-logs-1d5951569d78\nlog.retention.check.interval.ms=300000\nlog.retention.hours=168\nlog.segment.bytes=1073741824\nmessage.max.bytes=200000000\nnum.io.threads=8\nnum.network.threads=3\nnum.partitions=1\nnum.recovery.threads.per.data.dir=1\noffsets.topic.replication.factor=1\nport=9092\nsasl.enabled.mechanisms=PLAIN,SCRAM-SHA-256,SCRAM-SHA-512\nsocket.receive.buffer.bytes=102400\nsocket.request.max.bytes=104857600\nsocket.send.buffer.bytes=102400\ntransaction.state.log.min.isr=1\ntransaction.state.log.replication.factor=1\nzookeeper.connect=zookeeper:2181\nzookeeper.connection.timeout.ms=6000\n```\n\n----------------------------------------\n\nTITLE: Installing AWS MSK IAM V2 Extension for Kafka-Go in Go\nDESCRIPTION: Command to add the AWS MSK IAM V2 extension to your project dependencies using the go get command. This extension enables AWS IAM authentication with AWS Managed Apache Kafka services.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/sasl/aws_msk_iam_v2/README.md#2025-04-14_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngo get github.com/segmentio/kafka-go/sasl/aws_msk_iam_v2\n```\n\n----------------------------------------\n\nTITLE: Required Environment Variables for Kafka 2.3+ Authentication\nDESCRIPTION: Environment variables required in docker-compose for Kafka v2.3 and above to generate the kafka_jaas.conf file correctly. These settings ensure proper authentication configuration for the broker.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/docker_compose_versions/README.md#2025-04-14_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nKAFKA_INTER_BROKER_USER: adminplain\nKAFKA_INTER_BROKER_PASSWORD: admin-secret\nKAFKA_BROKER_USER: adminplain\nKAFKA_BROKER_PASSWORD: admin-secret\n```\n\n----------------------------------------\n\nTITLE: Running Kafka Tests in Docker\nDESCRIPTION: Commands for setting up local Kafka testing environment using Docker and running tests with specific version constraints.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/README.md#2025-04-14_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\nLANGUAGE: bash\nCODE:\n```\nKAFKA_VERSION=2.3.1 \\\n  KAFKA_SKIP_NETTEST=1 \\\n  go test -race ./...\n```\n\nLANGUAGE: bash\nCODE:\n```\ngo clean -cache && make test\n```\n\n----------------------------------------\n\nTITLE: Running Kafka Docker Compose for Testing\nDESCRIPTION: Command to start a specific version of Kafka using docker-compose. This launches the Kafka cluster in detached mode using the appropriate version-specific compose file.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/docker_compose_versions/README.md#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# docker-compose -f ./docker_compose_versions/docker-compose-<kafka_version>.yml up -d\n```\n\n----------------------------------------\n\nTITLE: Running kafka-go Test Cases with Specific Kafka Version\nDESCRIPTION: Command to run kafka-go test cases against a specific Kafka version. It cleans the Go cache first, skips network tests, and specifies the Kafka version to test against.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/docker_compose_versions/README.md#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# go clean -cache; KAFKA_SKIP_NETTEST=1 KAFKA_VERSION=<a.b.c> go test -race -cover ./...;\n```\n\n----------------------------------------\n\nTITLE: Example Go Module File with kafka-go Dependency\nDESCRIPTION: Example go.mod file snippet showing a dependency on the kafka-go library. This demonstrates how an application would normally include the library.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/CONTRIBUTING.md#2025-04-14_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmodule github.com/myusername/myapp\n\nrequire (\n    ...\n    github.com/segmentio/kafka-go v1.2.3\n    ...\n)\n```\n\n----------------------------------------\n\nTITLE: Fetching kafka-go Source Code from GitHub\nDESCRIPTION: Commands to clone the kafka-go repository outside of GOPATH and build it using Go Modules. This is the recommended approach for contributors wanting to work with the codebase.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/CONTRIBUTING.md#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir $HOME/src\ncd $HOME/src\ngit clone https://github.com/segmentio/kafka-go.git\ncd kafka-go\ngo build ./...\n```\n\n----------------------------------------\n\nTITLE: Go Module File with Local kafka-go Replacement\nDESCRIPTION: Example go.mod file showing how to replace the standard kafka-go dependency with a local version, useful for testing your modifications before submitting them.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/CONTRIBUTING.md#2025-04-14_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nmodule github.com/myusername/myapp\n\nreplace github.com/segmentio/kafka-go v1.2.3 => ../local/directory\n\nrequire (\n    ...\n    github.com/segmentio/kafka-go v1.2.3\n    ...\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Branch for Changes in kafka-go\nDESCRIPTION: Command to create a new branch for making changes to the kafka-go codebase. This is the first step in the contribution workflow.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/CONTRIBUTING.md#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b branch1234\n```\n\n----------------------------------------\n\nTITLE: Committing Changes to kafka-go\nDESCRIPTION: Command to commit changes to your local branch with a descriptive message. The -a flag adds all modified files and -v provides verbose output during commit.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/CONTRIBUTING.md#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit commit -a -v\n```\n\n----------------------------------------\n\nTITLE: Adding a Fork Remote for kafka-go\nDESCRIPTION: Command to add your GitHub fork as a remote repository. This allows you to push your local changes to your fork in preparation for creating a pull request.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/CONTRIBUTING.md#2025-04-14_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit remote add upstream git@github.com:USERNAME/kafka-go.git\n```\n\n----------------------------------------\n\nTITLE: Pushing Branch to Fork for kafka-go PR\nDESCRIPTION: Command to push your local branch to your fork on GitHub. After this, you can create a pull request from your fork to the main repository.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/CONTRIBUTING.md#2025-04-14_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit push upstream\n```\n\n----------------------------------------\n\nTITLE: Updating Vendor Directory with Local kafka-go Changes\nDESCRIPTION: Command to update the vendor directory after replacing kafka-go with a local version. This ensures your application uses your modified version of the library.\nSOURCE: https://github.com/segmentio/kafka-go/blob/main/CONTRIBUTING.md#2025-04-14_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n> go mod vendor\n```"
  }
]